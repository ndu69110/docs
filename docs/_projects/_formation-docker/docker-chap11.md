# Citations
- https://www.aqsone.com/fr/blog/mettre-en-production-vos-applications-avec-docker
- https://www.orpheebesson.fr/blog/mettre-en-production-une-application-web-avec-docker
- https://www.datacamp.com/fr/tutorial/docker-tutorial
- https://www.hostinger.com/fr/tutoriels/tutoriel-docker
- https://senza-formations.com/nos-articles/comment-installer-docker-et-configurer-ses-premiers-conteneurs-pas-a-pas
- https://blog.stephane-robert.info/docs/conteneurs/moteurs-conteneurs/docker/
- https://www.alfa-safety.fr/blog/docker-en-production-les-bonnes-pratiques/
- https://www.nas-forum.com/forum/topic/65309-tuto-docker-introduction/
- https://www.youtube.com/watch?v=f2-XKw-bkSM


# Tokens
- prompt_tokens: 306
- completion_tokens: 4770
- total_tokens: 5076
- search_context_size: low
- cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.072, 'request_cost': 0.006, 'total_cost': 0.078}


# Content
# üì¶ Guide Complet : Mise en Production avec Docker et Docker Compose

## Introduction √† la Mise en Production

La mise en production constitue une √©tape critique dans le cycle de vie d'une application. Elle implique de passer d'un environnement de d√©veloppement local √† un environnement accessible aux utilisateurs finaux. Docker facilite grandement ce processus en garantissant la coh√©rence entre les environnements de d√©veloppement et de production[1][2].

La conteneurisation avec Docker offre plusieurs avantages pour la mise en production :

- **Portabilit√©** : Les conteneurs s'ex√©cutent de mani√®re identique sur n'importe quel serveur
- **Isolement** : Chaque application fonctionne dans son propre environnement isol√©
- **Scalabilit√©** : Il est facile de dupliquer et de g√©rer plusieurs instances
- **Maintenabilit√©** : Les d√©pendances sont fig√©es dans l'image Docker

## Cr√©ation du VPS (Virtual Private Server)

### Pr√©paration du Serveur

Avant de d√©ployer une application Docker en production, il convient de pr√©parer correctement le serveur qui l'h√©bergera. Cette pr√©paration inclut plusieurs √©tapes essentielles[2].

**Pr√©requis mat√©riels recommand√©s** :

- Processeur 64 bits
- 4 Go de RAM minimum
- 10 Go d'espace disque disponible
- Acc√®s root ou acc√®s sudo

### Installation de Docker sur le Serveur

L'installation de Docker sur le serveur de production suit une proc√©dure standardis√©e. Apr√®s avoir provisionn√©e une instance VPS aupr√®s d'un fournisseur d'h√©bergement (OVH, Hetzner, DigitalOcean, etc.), l'administrateur doit se connecter au serveur via SSH et ex√©cuter les commandes d'installation appropri√©es.

Sur un syst√®me bas√© sur Debian/Ubuntu, la proc√©dure ressemble √† ceci :

```bash
# Mise √† jour du syst√®me
sudo apt-get update
sudo apt-get upgrade -y

# Installation des d√©pendances n√©cessaires
sudo apt-get install -y \
  apt-transport-https \
  ca-certificates \
  curl \
  gnupg \
  lsb-release

# Ajout de la cl√© GPG officielle de Docker
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# Ajout du repository Docker
echo \
  "deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Installation de Docker Engine
sudo apt-get update
sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin

# V√©rification de l'installation
docker --version
```

### Configuration de l'Acc√®s Utilisateur

Par d√©faut, seul l'utilisateur root peut ex√©cuter les commandes Docker. Pour am√©liorer l'ergonomie et la s√©curit√©, il est recommand√© d'ajouter l'utilisateur de d√©ploiement au groupe Docker[5] :

```bash
# Cr√©ation d'un utilisateur de d√©ploiement
sudo useradd -m -s /bin/bash deployer

# Ajout du utilisateur au groupe docker
sudo usermod -aG docker deployer

# Application des modifications au groupe
newgrp docker
```

## Structure du Projet et Pr√©paration

### Organisation des Fichiers

Une application destin√©e √† la production doit suivre une structure organis√©e. Voici une organisation recommand√©e :

```
mon-application/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ templates/
‚îú‚îÄ‚îÄ .github/
‚îÇ   ‚îî‚îÄ‚îÄ workflows/
‚îÇ       ‚îî‚îÄ‚îÄ deploy.yml
‚îú‚îÄ‚îÄ docker-compose.yml
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ .dockerignore
‚îú‚îÄ‚îÄ .env.production
‚îî‚îÄ‚îÄ README.md
```

### Cr√©ation du Dockerfile pour la Production

Le Dockerfile constitue le c≈ìur de la conteneurisation. Contrairement aux Dockerfiles de d√©veloppement, ceux destin√©s √† la production doivent √™tre optimis√©s pour la taille, les performances et la s√©curit√©[1][3].

Voici un exemple complet pour une application Python avec Streamlit :

```dockerfile
FROM python:3.10-alpine

EXPOSE 8501

WORKDIR /app

COPY requirements.txt ./requirements.txt

RUN pip3 install -r requirements.txt

COPY . .

CMD streamlit run my_app.py
```

Explicitation des instructions :

- **FROM** : Sp√©cifie l'image de base. `python:3.10-alpine` offre une image l√©g√®re optimis√©e pour la production
- **EXPOSE** : Documente le port sur lequel l'application √©coute
- **WORKDIR** : D√©finit le r√©pertoire de travail dans le conteneur
- **COPY** : Copie les fichiers du contexte de construction vers l'image
- **RUN** : Ex√©cute les commandes pendant la construction de l'image
- **CMD** : D√©finit la commande lanc√©e au d√©marrage du conteneur

### Construction de l'Image Docker

Une fois le Dockerfile d√©fini, la construction de l'image s'effectue via la commande suivante[1] :

```bash
# Construction de l'image
docker build -t streamlit_app .

# V√©rification de la cr√©ation
docker images | grep streamlit_app
```

L'option `-t` ajoute un tag √† l'image, facilitant son identification. Le point final (`.`) indique que le Dockerfile se trouve dans le r√©pertoire courant.

## Utilisation de Docker Compose en Production

### Concept Fondamental

Docker Compose permet de g√©rer plusieurs conteneurs interd√©pendants avec une seule commande. En production, ce fichier doit d√©finir l'ensemble de la pile applicative[2][3].

### Architecture Multi-Conteneur

Une application en production typique comprend plusieurs composants :

| Composant | R√¥le | Image | Port |
|-----------|------|-------|------|
| Frontend | Interface utilisateur | Application frontend | 3000 |
| Backend | Logique applicative | Application backend | 3333 |
| Base de donn√©es | Persistance des donn√©es | PostgreSQL/MySQL | 5432/3306 |
| Reverse proxy | Routage et SSL | Traefik | 80/443 |
| Cache | Performance | Redis | 6379 |

### Exemple de docker-compose.yml

```yaml
version: '3.9'

services:
  backend:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: app_backend
    ports:
      - "3333:3333"
    environment:
      - DATABASE_URL=postgresql://user:password@db:5432/appdb
      - REDIS_URL=redis://cache:6379
    depends_on:
      - db
      - cache
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped
    networks:
      - app_network

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: app_frontend
    ports:
      - "3000:3000"
    depends_on:
      - backend
    environment:
      - REACT_APP_API_URL=http://backend:3333
    restart: unless-stopped
    networks:
      - app_network

  db:
    image: postgres:15-alpine
    container_name: app_db
    environment:
      - POSTGRES_USER=user
      - POSTGRES_PASSWORD=password
      - POSTGRES_DB=appdb
    volumes:
      - db_data:/var/lib/postgresql/data
    restart: unless-stopped
    networks:
      - app_network
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U user"]
      interval: 10s
      timeout: 5s
      retries: 5

  cache:
    image: redis:7-alpine
    container_name: app_cache
    restart: unless-stopped
    networks:
      - app_network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  reverse_proxy:
    image: traefik:v2.10
    container_name: app_reverse_proxy
    ports:
      - "80:80"
      - "443:443"
      - "8080:8080"
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - ./traefik/traefik.yml:/traefik.yml:ro
      - ./traefik/config.yml:/config.yml:ro
      - letsencrypt:/letsencrypt
    restart: unless-stopped
    networks:
      - app_network

volumes:
  db_data:
  letsencrypt:

networks:
  app_network:
    driver: bridge
```

### Lancement de la Production

Avec Docker Compose configur√©, le lancement de l'ensemble de la pile s'effectue simplement[2][3] :

```bash
# Lancement en mode d√©tach√©
docker compose up -d

# Affichage des logs
docker compose logs -f

# Arr√™t des services
docker compose down

# Arr√™t avec suppression des volumes
docker compose down -v
```

## Mise en Place du Certificat TLS

### Concepts de Base

TLS (Transport Layer Security) chiffre les communications entre le client et le serveur. En production, tout site web accessible publiquement doit utiliser HTTPS. Let's Encrypt fournit des certificats TLS gratuits, largement utilis√©s avec Certbot[2].

### Configuration de Traefik avec Let's Encrypt

Traefik est un reverse proxy moderne qui automatise la gestion des certificats TLS. Voici la configuration recommand√©e :

**traefik/traefik.yml** :

```yaml
api:
  insecure: true
  dashboard: true

entryPoints:
  http:
    address: ":80"
    http:
      redirections:
        entrypoint:
          to: https
          scheme: https
  https:
    address: ":443"

certificatesResolvers:
  letsencrypt:
    acme:
      email: admin@example.com
      storage: /letsencrypt/acme.json
      httpChallenge:
        entryPoint: http
      certificatesDuration: 2160h

providers:
  docker:
    endpoint: "unix:///var/run/docker.sock"
    exposedByDefault: false
  file:
    filename: /config.yml
    watch: true
```

**traefik/config.yml** :

```yaml
http:
  routers:
    backend:
      rule: "Host(`api.example.com`)"
      service: backend_service
      entryPoints:
        - https
      tls:
        certResolver: letsencrypt

    frontend:
      rule: "Host(`example.com`)"
      service: frontend_service
      entryPoints:
        - https
      tls:
        certResolver: letsencrypt

  services:
    backend_service:
      loadBalancer:
        servers:
          - url: "http://backend:3333"

    frontend_service:
      loadBalancer:
        servers:
          - url: "http://frontend:3000"
```

### Renouvellement Automatique des Certificats

Let's Encrypt √©met des certificats valides 90 jours. Le renouvellement automatique constitue une n√©cessit√© op√©rationnelle[2].

Traefik g√®re automatiquement ce renouvellement si configur√© correctement. Les certificats sont stock√©s dans `/letsencrypt/acme.json`. Il est crucial de persister ce volume :

```bash
# V√©rification du statut du certificat
docker compose exec reverse_proxy cat /letsencrypt/acme.json | grep -o '"NotAfter":"[^"]*"' | head -1

# For√ßage du renouvellement (si n√©cessaire)
docker compose restart reverse_proxy
```

## Utilisation de PM2

### Concepts Fondamentaux

PM2 constitue un gestionnaire de processus pour Node.js permettant de maintenir les applications en ligne. Bien que Docker soit pr√©f√©r√© pour la conteneurisation en production, PM2 reste utile dans certains contextes hybrides ou pour des d√©ploiements l√©gers[2].

### Int√©gration PM2 dans Docker

Pour une application Node.js d√©ploy√©e avec PM2 :

**Dockerfile** :

```dockerfile
FROM node:18-alpine

WORKDIR /app

COPY package*.json ./

RUN npm ci --only=production
RUN npm install -g pm2

COPY . .

EXPOSE 3000

CMD ["pm2-runtime", "start", "ecosystem.config.js"]
```

**ecosystem.config.js** :

```javascript
module.exports = {
  apps: [
    {
      name: 'app',
      script: './src/app.js',
      instances: 'max',
      exec_mode: 'cluster',
      env: {
        NODE_ENV: 'production',
        PORT: 3000
      },
      error_file: './logs/pm2-error.log',
      out_file: './logs/pm2-out.log',
      log_date_format: 'YYYY-MM-DD HH:mm:ss Z',
      merge_logs: true,
      autorestart: true,
      max_memory_restart: '500M',
      watch: false
    }
  ]
};
```

## Environnement de Production

### Configuration des Variables d'Environnement

La gestion des secrets et des configurations d√©pend de l'environnement. En production, les donn√©es sensibles ne doivent jamais √™tre commises dans le d√©p√¥t Git[2].

**.env.production** :

```bash
# Configuration g√©n√©rale
NODE_ENV=production
DEBUG=false

# Bases de donn√©es
DATABASE_URL=postgresql://prod_user:secure_password@db:5432/production_db
REDIS_URL=redis://cache:6379

# Authentification
JWT_SECRET=your_super_secret_key_here
API_KEY=production_api_key

# Services externes
SMTP_HOST=smtp.example.com
SMTP_PORT=587
SMTP_USER=noreply@example.com
SMTP_PASSWORD=email_password

# Domaines
FRONTEND_URL=https://example.com
BACKEND_URL=https://api.example.com
```

### Chargement des Variables

Dans docker-compose.yml :

```yaml
services:
  backend:
    env_file:
      - .env.production
```

## Mise du Projet sur GitLab

### Configuration du D√©p√¥t

L'h√©bergement du code source sur une plateforme comme GitLab facilite le versioning et l'int√©gration continue[2].

```bash
# Initialisation du d√©p√¥t Git
git init
git remote add origin https://gitlab.com/username/mon-application.git

# Premier commit
git add .
git commit -m "Initial commit: application structure"
git push -u origin main
```

### Fichier .gitignore pour Docker

```
# Fichiers environnement
.env
.env.local
.env.*.local

# D√©pendances
node_modules/
__pycache__/
*.pyc
venv/

# Logs et donn√©es
logs/
*.log
npm-debug.log

# Volumes Docker
volumes/
db_data/

# IDE
.vscode/
.idea/
*.swp
*.swo
```

## Lancement de la Production

### D√©ploiement Initial

Le d√©ploiement d'une application en production implique plusieurs v√©rifications pr√©alables :

```bash
# Acc√®s au serveur
ssh deployer@your_server_ip

# Clonage du d√©p√¥t
git clone https://gitlab.com/username/mon-application.git
cd mon-application

# Cr√©ation du fichier .env avec les secrets de production
nano .env.production

# Lancement de l'application
docker compose -f docker-compose.yml up -d

# V√©rification du statut
docker compose ps
docker compose logs -f
```

### Mise √† Jour de l'Application

Lors d'une mise √† jour :

```bash
# R√©cup√©ration des derni√®res modifications
git pull origin main

# Reconstruction des images si le Dockerfile a chang√©
docker compose up -d --build

# Nettoyage des ressources obsol√®tes
docker system prune -a -f
```

### Monitoring et Maintenance

```bash
# Affichage des logs en temps r√©el
docker compose logs -f backend

# Statistiques d'utilisation des ressources
docker stats

# Inspection d'un conteneur
docker compose exec backend sh

# Red√©marrage d'un service
docker compose restart backend
```

## Automatisation avec GitHub Actions/GitLab CI

### Workflow de D√©ploiement Automatis√©

L'automatisation du d√©ploiement r√©duit les erreurs humaines et acc√©l√®re les mises en production[2].

**.github/workflows/deploy.yml** :

```yaml
name: Build, push, and deploy Docker images to the server

on:
  push:
    branches: ["main"]

env:
  REGISTRY: ghcr.io
  DOCKER_IMAGE_PRODUCTION_TAG: production

jobs:
  build_and_push:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      - name: Login to GitHub Container Registry
        uses: docker/login-action@v2
        with:
          registry: ${{ env.REGISTRY }}
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v4
        with:
          context: .
          push: true
          tags: |
            ${{ env.REGISTRY }}/${{ github.repository }}:${{ env.DOCKER_IMAGE_PRODUCTION_TAG }}
            ${{ env.REGISTRY }}/${{ github.repository }}:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

  deploy:
    needs: build_and_push
    runs-on: ubuntu-latest
    
    steps:
      - name: Deploy to production server
        uses: appleboy/ssh-action@master
        with:
          host: ${{ secrets.PRODUCTION_SERVER_IP }}
          username: ${{ secrets.PRODUCTION_SERVER_USER }}
          key: ${{ secrets.PRODUCTION_SERVER_SSH_KEY }}
          script: |
            cd /home/deployer/mon-application
            git pull origin main
            docker compose pull
            docker compose up -d
            docker compose logs backend
```

## Bonnes Pratiques en Production

### S√©curit√©

- **Principe du moindre privil√®ge** : N'exposer que les ports n√©cessaires
- **Secrets management** : Utiliser des gestionnaires de secrets (HashiCorp Vault, AWS Secrets Manager)
- **Mises √† jour r√©guli√®res** : Maintenir les images de base √† jour
- **Scanning d'images** : Analyser les images pour les vuln√©rabilit√©s

### Performance

- **Limites de ressources** : D√©finir des limites CPU et m√©moire

```yaml
services:
  backend:
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 512M
        reservations:
          cpus: '0.5'
          memory: 256M
```

- **Healthchecks** : V√©rifier la disponibilit√© des services
- **Caching** : Utiliser Redis ou Memcached pour le cache applicatif

### Observabilit√©

- **Logs centralis√©s** : Aggr√©ger les logs avec ELK ou Loki
- **Monitoring** : Utiliser Prometheus et Grafana
- **Tracing distribu√©** : Impl√©menter Jaeger pour suivre les requ√™tes

### Disaster Recovery

- **Sauvegardes r√©guli√®res** : Exporter les volumes de donn√©es

```bash
# Sauvegarde d'une base de donn√©es
docker compose exec db mysqldump -u user -p password dbname > backup.sql

# Sauvegarde d'un volume Docker
docker run --rm -v db_data:/data -v $(pwd):/backup \
  alpine tar czf /backup/db_data_backup.tar.gz -C /data .
```

- **R√©plication** : Mettre en place une strat√©gie multi-r√©gions
- **Rollback rapide** : Conserver les versions pr√©c√©dentes des images

## Optimisation et √âvolution

### Scaling Horizontal

Pour g√©rer une charge croissante, il faut ajouter plusieurs instances :

```yaml
services:
  backend:
    deploy:
      replicas: 3
      update_config:
        parallelism: 1
        delay: 10s
      restart_policy:
        condition: on-failure
```

### Orchestration avec Docker Swarm

Pour des d√©ploiements √† plus grande √©chelle :

```bash
# Initialisation du Swarm
docker swarm init

# D√©ploiement d'un stack
docker stack deploy -c docker-compose.yml mon_app
```

### Migration vers Kubernetes

Pour des besoins de scalabilit√© massifs et d'orchestration avanc√©e, Kubernetes repr√©sente l'√©tape suivante naturelle apr√®s Docker Compose et Docker Swarm.

## Conclusion

La mise en production d'applications avec Docker et Docker Compose offre une base solide pour des d√©ploiements fiables et reproductibles. L'ensemble des √©l√©ments pr√©sent√©s‚Äîconfiguration d'infrastructure, gestion des certificats TLS, automatisation des d√©ploiements, et monitoring‚Äîconstituent les piliers d'une strat√©gie de production robuste. L'apprentissage progressif de ces concepts, combin√© √† une compr√©hension des bonnes pratiques, permet de b√¢tir des syst√®mes production-ready, maintenables et √©volutifs.
