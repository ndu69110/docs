{"config":{"lang":["fr"],"separator":"[\\s\\u200b\\-_,:!=\\[\\]()\"`/]+|\\.(?!\\d)|&[lg]t;|(?!\\b)(?=[A-Z][a-z])","pipeline":["stemmer","stopWordFilter","trimmer"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Material for MkDocs","text":"<p>Welcome to Material for MkDocs.</p> <p> Partager sur X</p>"},{"location":"tags/","title":"Tags \ud83d\udd17","text":""},{"location":"tags/#tag:candy","title":"Candy","text":"<ul> <li>            Gestion du site          </li> </ul>"},{"location":"tags/#tag:gestion","title":"gestion","text":"<ul> <li>            Gestion du site \u2699\ufe0f          </li> </ul>"},{"location":"tags/#tag:site","title":"site","text":"<ul> <li>            Gestion du site \u2699\ufe0f          </li> </ul>"},{"location":"tags/#tag:univers","title":"univers","text":"<ul> <li>            Gestion du site          </li> </ul> <p> Partager sur X</p>"},{"location":"_buymeacoffee/buymeacoffee/","title":"Pour me soutenir dans mon travail \ud83d\udc4d\ud83d\udc4d\ud83d\udc4d","text":"<p>Si vous avez aim\u00e9 le contenu de ce site, vous pouvez m'offir un caf\u00e9 \u2615 en suivant le lien ci-dessous : \u2935\ufe0f</p> <p></p>"},{"location":"_buymeacoffee/buymeacoffee/#pourquoi-me-soutenir","title":"Pourquoi me soutenir ? \ud83e\udd14","text":"<p>Vous l\u2019avez peut-\u00eatre remarqu\u00e9, ce site ne diffuse aucune publicit\u00e9 \ud83d\udeab. Pour le financer, je compte essentiellement sur le soutien de mes lecteurs. \u2764\ufe0f</p>"},{"location":"_buymeacoffee/buymeacoffee/#pour-quels-objectifs","title":"Pour quels objectifs ? \ud83c\udfaf","text":"<p>Mon principal objectif est de fournir un contenu accessible et utile \u00e0 tous.</p>"},{"location":"_buymeacoffee/buymeacoffee/#comment-me-soutenir","title":"Comment me soutenir ? \ud83d\ude4c","text":"<p>Chaque don compte, les petits comme les gros. Vous pouvez effectuer un don :</p> <ul> <li>Ponctuel ou mensuel sur mon compte ko-fi \u2197\ufe0f.</li> </ul>"},{"location":"_buymeacoffee/buymeacoffee/#pourquoi","title":"Pourquoi ?","text":"<p>Vous allez me dire, mais pourquoi te soutenir ? Quelles sont tes d\u00e9penses ? \ud83e\udd37\u200d\u2642\ufe0f Vos dons permettent de couvrir les d\u00e9penses li\u00e9es \u00e0 l\u2019h\u00e9bergement du blog ainsi qu'au maintien de mon homelab \ud83d\udcbc (tout cela pour un montant mensuel de 100\u20ac environ pour les d\u00e9penses fixes).</p> <p>Merci \u00e0 tous ceux qui m\u2019ont soutenu et \u00e0 ceux qui vont le faire. \ud83d\udc4f</p> <p> Partager sur X</p>"},{"location":"_contact/contact/","title":"Formulaire de contact \u2709\ufe0f","text":"<p>Merci de bien saisir vos coordonn\u00e9es pour que je puisse vous lire et vous r\u00e9pondre en retour.</p> Loading\u2026 <p> Partager sur X</p>"},{"location":"_gestionsite/gestionsite/","title":"Outils utilis\u00e9s pour la cr\u00e9ation et la gestion du site","text":"","tags":["gestion","site"]},{"location":"_gestionsite/gestionsite/#typora","title":"Typora","text":"<p>Typora est l'\u00e9diteur de texte principal utilis\u00e9 pour l'\u00e9dition des pages du site. Il permet d'\u00e9crire en Markdown avec un rendu en temps r\u00e9el, ce qui facilite la mise en forme des contenus sans avoir \u00e0 jongler entre l'\u00e9dition et l'aper\u00e7u. Son interface minimaliste et intuitive favorise la productivit\u00e9 et rend l'\u00e9criture fluide et agr\u00e9able, tout en assurant une compatibilit\u00e9 parfaite avec les formats utilis\u00e9s pour le site.</p> <p>Il est sp\u00e9cialis\u00e9 dans la r\u00e9daction et la mise en forme de fichiers Markdown. Il offre une exp\u00e9rience d\u2019\u00e9dition fluide, en affichant en temps r\u00e9el le rendu final du Markdown, ce qui permet de se concentrer sur le contenu sans se perdre dans les balises ou la syntaxe. </p> <p>https://typora.io/</p> <p></p>","tags":["gestion","site"]},{"location":"_gestionsite/gestionsite/#visual-studio-code-avec-lextension-front-matter","title":"Visual Studio Code avec l'extension Front Matter","text":"<p>Visual Studio Code, souvent abr\u00e9g\u00e9 VS Code, est un \u00e9diteur de code moderne, l\u00e9ger et extr\u00eamement personnalisable.</p> <p>Pour la gestion plus avanc\u00e9e des contenus, Visual Studio Code est utilis\u00e9, il peut \u00eatre install\u00e9e l\u2019extension Front Matter. Cet outil permet d\u2019administrer plus facilement les m\u00e9tadonn\u00e9es en YAML en d\u00e9but de fichier, de g\u00e9rer des collections de contenus et de b\u00e9n\u00e9ficier de fonctions utiles comme l\u2019aper\u00e7u de page, les liens internes ou encore le tri par date. C\u2019est un environnement robuste pour organiser et maintenir un site structur\u00e9.</p> <p>Ainsi avec VS Code + l\u2019extension Front Matter, on a ici un outil puissant pour la gestion de contenu sous forme de Markdown, le support des m\u00e9tadonn\u00e9es et l\u2019organisation des articles ou des pages du site. </p> <p>Cette combinaison permet une gestion structur\u00e9e et professionnelle du contenu tout en b\u00e9n\u00e9ficiant de toutes les fonctionnalit\u00e9s avanc\u00e9es de VS Code. </p> <p>https://code.visualstudio.com/</p> <p></p>","tags":["gestion","site"]},{"location":"_gestionsite/gestionsite/#github","title":"GitHub","text":"<p>GitHub est utilis\u00e9 comme syst\u00e8me de versioning pour le projet. Il permet de garder un historique clair de toutes les modifications apport\u00e9es aux fichiers du site, de collaborer efficacement et de restaurer des versions pr\u00e9c\u00e9dentes si n\u00e9cessaire. C\u2019est un outil essentiel pour assurer une gestion fiable du code source et des contenus.</p> <p>C'est la plateforme collaborative incontournable pour le versioning du code. En utilisant un d\u00e9p\u00f4t GitHub, toutes les modifications du site sont historis\u00e9es, permettant de revenir facilement \u00e0 un \u00e9tat ant\u00e9rieur si n\u00e9cessaire ou de collaborer efficacement sur les changements. La mise \u00e0 jour du site s\u2019effectue en poussant les nouvelles versions, garantissant ainsi la tra\u00e7abilit\u00e9 et la s\u00fbret\u00e9 des \u00e9volutions.</p> <p>https://github.com/</p> <p></p>","tags":["gestion","site"]},{"location":"_gestionsite/gestionsite/#github-pages","title":"GitHub Pages","text":"<p>Le site est h\u00e9berg\u00e9 via GitHub Pages, un service d\u2019h\u00e9bergement statique int\u00e9gr\u00e9 \u00e0 GitHub. Il permet de publier facilement le site directement depuis le d\u00e9p\u00f4t en ligne, sans avoir besoin d\u2019un serveur web complexe. Les mises \u00e0 jour sont automatiquement d\u00e9ploy\u00e9es \u00e0 chaque push vers la branche principale ou d\u00e9di\u00e9e.</p> <p>Ainsi, il automatise le d\u00e9ploiement \u00e0 chaque modification du code, assurant ainsi une mise \u00e0 jour rapide et fiable du site sans intervention manuelle sur un serveur.</p> <p>https://pages.github.com/</p> <p></p>","tags":["gestion","site"]},{"location":"_gestionsite/gestionsite/#flameshot","title":"Flameshot","text":"<p>Pour illustrer les contenus du site, Flameshot est utilis\u00e9 comme outil principal de capture d\u2019\u00e9cran. Il permet de prendre des captures rapides et de les annoter directement, avec des options pratiques comme le floutage, les fl\u00e8ches ou les encadrements. Ces captures enrichissent les pages et facilitent la compr\u00e9hension pour les visiteurs.</p> <p>https://flameshot.org/</p> <p></p>","tags":["gestion","site"]},{"location":"_gestionsite/gestionsite/#serveur-ftp","title":"Serveur FTP","text":"<p>Un serveur FTP est utilis\u00e9 pour h\u00e9berger les copies d\u2019\u00e9cran r\u00e9alis\u00e9es avec Flameshot. Ces images ne sont pas stock\u00e9es directement dans le d\u00e9p\u00f4t GitHub afin d\u2019en all\u00e9ger la taille. Le FTP permet une gestion centralis\u00e9e des m\u00e9dias tout en gardant les pages web l\u00e9g\u00e8res et rapides \u00e0 charger.</p> <p>Le serveur sert ainsi d\u2019espace de stockage distant, accessible depuis n\u2019importe quelle machine, facilitant ainsi l\u2019int\u00e9gration rapide des images captur\u00e9es dans les articles ou pages du site.</p>","tags":["gestion","site"]},{"location":"_gestionsite/gestionsite/#_1","title":"Gestion du site","text":"<p> Partager sur X</p>","tags":["gestion","site"]},{"location":"_projects/_formation-azure/azure-chap01/","title":"Citations","text":"<ul> <li>https://learn.microsoft.com/fr-fr/training/paths/introduction-to-ai-on-azure/</li> <li>https://learn.microsoft.com/fr-fr/training/paths/microsoft-azure-fundamentals-describe-cloud-concepts/</li> <li>https://learn.microsoft.com/fr-fr/training/courses/az-900t00</li> <li>https://learn.microsoft.com/fr-fr/training/azure/</li> <li>https://learn.microsoft.com/fr-fr/azure/</li> <li>https://learn.microsoft.com/fr-fr/credentials/certifications/azure-fundamentals/</li> <li>https://learn.microsoft.com/fr-fr/training/paths/azure-data-fundamentals-explore-core-data-concepts/</li> <li>https://azure.microsoft.com/fr-fr/get-started</li> <li>https://learn.microsoft.com/fr-fr/shows/on-demand-instructor-led-training-series/az-204-module-1</li> <li>https://learn.microsoft.com/fr-fr/shows/azure-videos/intro-to-azure-ai</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap01/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 242</li> <li>completion_tokens: 5290</li> <li>total_tokens: 5532</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.079, 'request_cost': 0.006, 'total_cost': 0.086}</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap01/#content","title":"Content","text":""},{"location":"_projects/_formation-azure/azure-chap01/#introduction-au-cloud-et-a-azure","title":"Introduction au Cloud et \u00e0 Azure","text":""},{"location":"_projects/_formation-azure/azure-chap01/#a-labordage","title":"\u00c0 l'abordage ! \ud83d\ude80","text":"<p>Le cloud computing repr\u00e9sente l'une des transformations technologiques les plus significatives de la d\u00e9cennie. Cette section inaugure un parcours p\u00e9dagogique structur\u00e9 autour de Microsoft Azure, une plateforme cloud computing qui offre un ensemble croissant de services pour cr\u00e9er des solutions r\u00e9pondant \u00e0 des objectifs commerciaux vari\u00e9s[4].</p> <p>Avant de se plonger dans les sp\u00e9cificit\u00e9s d'Azure, il convient de comprendre les fondamentaux du cloud. Le cloud ne constitue pas simplement une infrastructure informatique externalis\u00e9e, mais plut\u00f4t un paradigme permettant d'acc\u00e9der \u00e0 des ressources informatiques \u00e0 la demande, avec une facturation \u00e0 l'usage et une scalabilit\u00e9 automatique. Cette approche transforme radicalement la mani\u00e8re dont les organisations d\u00e9ploient, g\u00e8rent et maintiennent leurs applications et donn\u00e9es.</p> <p>L'importance croissante du cloud dans l'\u00e9cosyst\u00e8me IT justifie l'acquisition de comp\u00e9tences solides dans ce domaine. Les professionnels IT, d\u00e9veloppeurs et architectes de solutions doivent ma\u00eetriser ces concepts pour rester comp\u00e9titifs sur le march\u00e9 du travail. Microsoft Azure, en tant que plateforme majeure, offre une exposition aux technologies cloud contemporaines, aux patterns d'architecture modernes et aux outils de gestion d'infrastructure nouvelle g\u00e9n\u00e9ration.</p>"},{"location":"_projects/_formation-azure/azure-chap01/#introduction-au-cloud","title":"Introduction au Cloud \ud83c\udf10","text":""},{"location":"_projects/_formation-azure/azure-chap01/#concept-fondamental-du-cloud-computing","title":"Concept Fondamental du Cloud Computing","text":"<p>Le cloud computing repose sur la livraison de services informatiques via Internet. Contrairement aux mod\u00e8les traditionnels o\u00f9 les organisations ach\u00e8tent, installent et maintiennent des serveurs physiques localement, le cloud permet de louer des ressources informatiques selon les besoins.</p> <p>Les trois piliers fondamentaux du cloud computing sont :</p> <ul> <li> <p>Infrastructure as a Service (IaaS) : Fournit des ressources informatiques virtualis\u00e9es (serveurs, stockage, r\u00e9seaux) accessibles via Internet. Les clients g\u00e8rent les applications et donn\u00e9es tandis que le fournisseur g\u00e8re l'infrastructure physique.</p> </li> <li> <p>Platform as a Service (PaaS) : Fournit un environnement complet de d\u00e9veloppement et de d\u00e9ploiement. Les d\u00e9veloppeurs peuvent cr\u00e9er, tester et d\u00e9ployer des applications sans g\u00e9rer l'infrastructure sous-jacente.</p> </li> <li> <p>Software as a Service (SaaS) : Fournit des applications logicielles compl\u00e8tes accessibles via un navigateur web. Les utilisateurs n'ont pas besoin d'installer ou de maintenir le logiciel.</p> </li> </ul>"},{"location":"_projects/_formation-azure/azure-chap01/#avantages-du-cloud","title":"Avantages du Cloud","text":"<p>Le cloud computing offre plusieurs avantages substantiels par rapport aux infrastructures traditionnelles :</p> Aspect Avantage Description Co\u00fbts R\u00e9duction des d\u00e9penses capitales Pas d'achat de serveurs physiques co\u00fbteux Scalabilit\u00e9 \u00c9lasticit\u00e9 automatique Augmentation ou diminution rapide des ressources selon la demande Disponibilit\u00e9 Haute disponibilit\u00e9 Redondance g\u00e9ographique et continuit\u00e9 de service Flexibilit\u00e9 Adaptation rapide D\u00e9ploiement d'applications en minutes, pas en mois S\u00e9curit\u00e9 Expertise centralis\u00e9e Fournisseurs cloud investissent massivement en s\u00e9curit\u00e9 Maintenance R\u00e9duction de la charge IT Les mises \u00e0 jour et patches sont g\u00e9r\u00e9s automatiquement Accessibilit\u00e9 Acc\u00e8s global Disponibilit\u00e9 depuis n'importe quel endroit avec Internet"},{"location":"_projects/_formation-azure/azure-chap01/#modeles-de-deploiement-cloud","title":"Mod\u00e8les de D\u00e9ploiement Cloud","text":"<p>Au-del\u00e0 des mod\u00e8les de service (IaaS, PaaS, SaaS), le cloud se d\u00e9cline selon plusieurs mod\u00e8les de d\u00e9ploiement :</p> <p>Cloud Public : Les ressources sont partag\u00e9es entre plusieurs organisations. Offre maximum de scalabilit\u00e9 et r\u00e9duction de co\u00fbts. Exemples : Azure, AWS, Google Cloud.</p> <p>Cloud Priv\u00e9 : Les ressources sont d\u00e9di\u00e9es \u00e0 une seule organisation, soit h\u00e9berg\u00e9es sur site, soit chez un fournisseur sp\u00e9cialis\u00e9. Offre contr\u00f4le maximum et conformit\u00e9 r\u00e9glementaire.</p> <p>Cloud Hybride : Combinaison de ressources cloud public et priv\u00e9, permettant une flexibilit\u00e9 optimale. Permet de conserver les donn\u00e9es sensibles en priv\u00e9 tout en b\u00e9n\u00e9ficiant de la scalabilit\u00e9 du public.</p> <p>Cloud Multicloud : Utilisation de services de plusieurs fournisseurs cloud simultaneously. R\u00e9duit la d\u00e9pendance \u00e0 un seul fournisseur et optimise les co\u00fbts.</p>"},{"location":"_projects/_formation-azure/azure-chap01/#cas-dusage-du-cloud","title":"Cas d'Usage du Cloud","text":"<p>Les organisations adopte le cloud pour des cas d'usage vari\u00e9s :</p> <ul> <li>H\u00e9bergement d'applications web : Sites e-commerce, applications m\u00e9tier, portails d'entreprise</li> <li>Big Data et Analytics : Traitement massif de donn\u00e9es sans investissement infrastructure</li> <li>Intelligence Artificielle et Machine Learning : Entra\u00eenement de mod\u00e8les sans GPU on\u00e9reuses</li> <li>D\u00e9veloppement et test : Environnements \u00e9ph\u00e9m\u00e8res pour tester rapidement</li> <li>Archivage et sauvegarde : Stockage durable et \u00e9conomique des donn\u00e9es</li> <li>Internet des Objets (IoT) : Collection et traitement de donn\u00e9es de dispositifs connect\u00e9s</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap01/#introduction-a-azure","title":"Introduction \u00e0 Azure \ud83d\udc99","text":""},{"location":"_projects/_formation-azure/azure-chap01/#presentation-generale-dazure","title":"Pr\u00e9sentation g\u00e9n\u00e9rale d'Azure","text":"<p>Microsoft Azure est une plateforme de cloud computing qui offre un ensemble croissant de services pour cr\u00e9er des solutions r\u00e9pondant \u00e0 des objectifs commerciaux[4]. Azure prend en charge tous les niveaux de complexit\u00e9, du simple h\u00e9bergement web aux solutions logicielles personnalis\u00e9es sur des ordinateurs enti\u00e8rement virtualis\u00e9s[4].</p> <p>Azure propose une infrastructure cloud compl\u00e8te couvrant :</p> <ul> <li>Calcul : Machines virtuelles, conteneurs, fonction sans serveur</li> <li>Stockage : Stockage d'objets, bases de donn\u00e9es, archivage</li> <li>Mise en r\u00e9seau : R\u00e9seaux virtuels, \u00e9quilibrage de charge, CDN</li> <li>Analytics : Traitement de donn\u00e9es massives, data warehousing, visualisation</li> <li>Intelligence Artificielle : Services IA pr\u00e9-construits, Machine Learning personnalis\u00e9</li> <li>Internet des Objets : Gestion de dispositifs connect\u00e9s</li> <li>Int\u00e9gration : Middleware pour connecter syst\u00e8mes disparates</li> <li>S\u00e9curit\u00e9 et gestion : Conformit\u00e9, gouvernance, monitoring</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap01/#architecture-de-azure","title":"Architecture de Azure","text":"<p>Azure fonctionne selon une architecture distribu\u00e9e mondialement. Les utilisateurs acc\u00e8dent aux services via le portail Azure (interface web de gestion) ou via des outils en ligne de commande comme Azure CLI ou Azure PowerShell.</p> <p>L'infrastructure Azure s'organise autour de concepts cl\u00e9s :</p> <p>R\u00e9gions Azure : Emplacements g\u00e9ographiques dispers\u00e9s mondialement contenant des datacenters Azure. Chaque r\u00e9gion offre une latence faible pour les utilisateurs de cette zone et la conformit\u00e9 aux r\u00e9glementations locales. Exemples : Europe Ouest (Amsterdam), France Central (Paris), Asie-Pacifique (Sydney).</p> <p>Zones de disponibilit\u00e9 : Au sein de chaque r\u00e9gion, plusieurs zones de disponibilit\u00e9 physiquement s\u00e9par\u00e9es offrent une redondance locale pour haute disponibilit\u00e9 et tol\u00e9rance aux pannes.</p> <p>Groupes de ressources : Conteneurs logiques regroupant les ressources Azure (machines virtuelles, bases de donn\u00e9es, comptes de stockage, etc.) associ\u00e9es \u00e0 une solution particuli\u00e8re.</p> <p>Abonnements : Entit\u00e9s de facturation et d'organisation contenant les groupes de ressources. Une organisation peut avoir plusieurs abonnements pour diff\u00e9rents d\u00e9partements ou projets.</p>"},{"location":"_projects/_formation-azure/azure-chap01/#services-azure-essentiels","title":"Services Azure Essentiels","text":""},{"location":"_projects/_formation-azure/azure-chap01/#calcul-compute-services","title":"Calcul (Compute Services)","text":"<p>Machines virtuelles (VMs) : Serveurs virtuels personnalisables o\u00f9 ex\u00e9cuter des applications existantes ou d\u00e9velopper de nouvelles applications. Les clients choisissent le syst\u00e8me d'exploitation, le processeur, la RAM et le stockage.</p> <p>Azure App Service : Plateforme g\u00e9r\u00e9e pour h\u00e9berger des applications web, des applications mobiles et des API sans g\u00e9rer l'infrastructure sous-jacente.</p> <p>Azure Container Instances et Kubernetes Service : Ex\u00e9cution de conteneurs pour applications modernes avec orchestration automatique.</p> <p>Azure Functions : Ex\u00e9cution de code sans serveur r\u00e9agissant \u00e0 des \u00e9v\u00e9nements, avec facturation bas\u00e9e uniquement sur l'ex\u00e9cution r\u00e9elle.</p>"},{"location":"_projects/_formation-azure/azure-chap01/#stockage-storage-services","title":"Stockage (Storage Services)","text":"<p>Blob Storage : Stockage d'objets massif pour donn\u00e9es non structur\u00e9es (images, vid\u00e9os, documents, sauvegardes).</p> <p>File Storage : Partages de fichiers g\u00e9r\u00e9s accessibles via SMB ou NFS.</p> <p>Disk Storage : Disques g\u00e9r\u00e9s pour machines virtuelles offrant performance et r\u00e9silience.</p> <p>Table Storage : Base de donn\u00e9es NoSQL pour donn\u00e9es structur\u00e9es avec sch\u00e9ma flexible.</p>"},{"location":"_projects/_formation-azure/azure-chap01/#bases-de-donnees-database-services","title":"Bases de donn\u00e9es (Database Services)","text":"<p>SQL Database : Base de donn\u00e9es relationnelle manag\u00e9e compatible SQL Server.</p> <p>Azure Cosmos DB : Base de donn\u00e9es NoSQL mondialement distribu\u00e9e avec faible latence.</p> <p>Azure Database for PostgreSQL/MySQL : Services de bases de donn\u00e9es open-source manag\u00e9s.</p>"},{"location":"_projects/_formation-azure/azure-chap01/#mise-en-reseau-networking-services","title":"Mise en r\u00e9seau (Networking Services)","text":"<p>Virtual Networks : R\u00e9seaux priv\u00e9s virtuels pour connecter ressources Azure de mani\u00e8re s\u00e9curis\u00e9e.</p> <p>VPN Gateway : Connexions chiffr\u00e9es entre r\u00e9seaux locaux et r\u00e9seaux Azure.</p> <p>Azure Load Balancer : Distribution du trafic entrant entre plusieurs ressources.</p> <p>Azure Application Gateway : \u00c9quilibrage de charge applicatif avec routage avanc\u00e9.</p>"},{"location":"_projects/_formation-azure/azure-chap01/#analytics-et-big-data","title":"Analytics et Big Data","text":"<p>Azure Synapse Analytics : Plateforme unifi\u00e9e pour data warehousing, big data analytics et real-time analytics.</p> <p>Azure Databricks : Plateforme Apache Spark manag\u00e9e pour data engineering et machine learning \u00e0 grande \u00e9chelle.</p> <p>Azure Stream Analytics : Traitement en temps r\u00e9el de flux de donn\u00e9es.</p>"},{"location":"_projects/_formation-azure/azure-chap01/#intelligence-artificielle-et-machine-learning","title":"Intelligence Artificielle et Machine Learning","text":"<p>Azure AI Services : Suite compl\u00e8te de services IA pr\u00e9-construits couvrant vision par ordinateur, traitement du langage naturel, traitement vocale et d\u00e9cisions intelligentes[10].</p> <p>Azure Machine Learning : Plateforme compl\u00e8te pour construire, entra\u00eener et d\u00e9ployer des mod\u00e8les ML personnalis\u00e9s.</p> <p>Azure OpenAI Service : Acc\u00e8s aux mod\u00e8les d'IA g\u00e9n\u00e9rative d'OpenAI, permettant d'int\u00e9grer des capacit\u00e9s d'IA g\u00e9n\u00e9rative dans les applications.</p>"},{"location":"_projects/_formation-azure/azure-chap01/#exemple-deploiement-dune-application-web-simple","title":"Exemple : D\u00e9ploiement d'une Application Web Simple","text":"<p>Pour illustrer concr\u00e8tement l'utilisation d'Azure, consid\u00e9rons le d\u00e9ploiement d'une application web node.js :</p> Bash<pre><code># Installation d'Azure CLI\n# https://learn.microsoft.com/fr-fr/cli/azure/install-azure-cli\n\n# Connexion \u00e0 Azure\naz login\n\n# Cr\u00e9ation d'un groupe de ressources\naz group create --name MonApplicationeRG --location \"France Central\"\n\n# Cr\u00e9ation d'un plan App Service (infrastructure de calcul)\naz appservice plan create \\\n  --name MonPlanAppService \\\n  --resource-group MonApplicationeRG \\\n  --sku B1 \\\n  --is-linux\n\n# D\u00e9ploiement d'une application web\naz webapp create \\\n  --resource-group MonApplicationeRG \\\n  --plan MonPlanAppService \\\n  --name MonAppWeb-unique123 \\\n  --runtime \"node|18-lts\"\n\n# D\u00e9ploiement du code depuis un d\u00e9p\u00f4t Git\naz webapp deployment source config-zip \\\n  --resource-group MonApplicationeRG \\\n  --name MonAppWeb-unique123 \\\n  --src app.zip\n\n# Visualisation de l'URL de l'application\naz webapp show \\\n  --resource-group MonApplicationeRG \\\n  --name MonAppWeb-unique123 \\\n  --query defaultHostName \\\n  --output tsv\n</code></pre> <p>Cet exemple illustre comment, en quelques commandes, une application est d\u00e9ploy\u00e9e et accessible mondialement via Azure, sans gestion d'infrastructure serveur.</p>"},{"location":"_projects/_formation-azure/azure-chap01/#modele-de-responsabilite-partagee","title":"Mod\u00e8le de Responsabilit\u00e9 Partag\u00e9e","text":"<p>Un concept fondamental pour comprendre Azure et le cloud en g\u00e9n\u00e9ral est le mod\u00e8le de responsabilit\u00e9 partag\u00e9e. Les responsabilit\u00e9s en mati\u00e8re de s\u00e9curit\u00e9 et de conformit\u00e9 se r\u00e9partissent entre Microsoft et le client selon le mod\u00e8le de service :</p> Composant IaaS PaaS SaaS Applications Client Client Microsoft Donn\u00e9es Client Client Client Authentification Client Client Microsoft R\u00e9seau Client Microsoft Microsoft Syst\u00e8me d'exploitation Client Microsoft Microsoft Infrastructure physique Microsoft Microsoft Microsoft <p>En IaaS, le client g\u00e8re davantage de couches. En PaaS, Microsoft g\u00e8re la plateforme. En SaaS, seules les donn\u00e9es client restent sous sa responsabilit\u00e9.</p>"},{"location":"_projects/_formation-azure/azure-chap01/#introduction-aux-certifications-azure","title":"Introduction aux Certifications Azure \ud83c\udfc6","text":""},{"location":"_projects/_formation-azure/azure-chap01/#importance-des-certifications-cloud","title":"Importance des Certifications Cloud","text":"<p>Les certifications Azure valident les comp\u00e9tences et connaissances des professionnels IT, \u00e9tablissant une cr\u00e9dibilit\u00e9 aupr\u00e8s des employeurs et clients. Pour une organisation, les \u00e9quipes certifi\u00e9es Azure garantissent une utilisation optimale et s\u00e9curis\u00e9e de la plateforme.</p>"},{"location":"_projects/_formation-azure/azure-chap01/#chemins-de-certification-azure","title":"Chemins de Certification Azure","text":"<p>Microsoft propose plusieurs parcours de certification correspondant \u00e0 diff\u00e9rents r\u00f4les professionnels :</p>"},{"location":"_projects/_formation-azure/azure-chap01/#fondamentaux-niveau-debutant","title":"Fondamentaux (Niveau D\u00e9butant)","text":"<p>Microsoft Certified : Principes de base d'Azure (AZ-900)</p> <p>Cette certification constitue le point de d\u00e9part id\u00e9al pour toute personne d\u00e9butant avec Azure[3][6]. L'examen AZ-900 couvre trois domaines principaux[6] :</p> <ol> <li>D\u00e9crire les concepts cloud : Principes fondamentaux du cloud computing, mod\u00e8les de service, mod\u00e8les de d\u00e9ploiement</li> <li>D\u00e9crire l'architecture et les services Azure : Services Azure majeurs, solutions de calcul, stockage, mise en r\u00e9seau, bases de donn\u00e9es, analytics et IA</li> <li>D\u00e9crire la gestion et la gouvernance Azure : Gestion des co\u00fbts, outils d'administration, conformit\u00e9 r\u00e9glementaire, gouvernance</li> </ol> <p>Profil du public : Cette certification convient au personnel informatique commen\u00e7ant \u00e0 peine \u00e0 utiliser Azure et souhaitant acqu\u00e9rir une exp\u00e9rience pratique avec la plateforme[3]. Elle pr\u00e9pare \u00e9galement \u00e0 des certifications bas\u00e9es sur des r\u00f4les sp\u00e9cifiques.</p> <p>Dur\u00e9e du cours : Le cours AZ-900T00 associ\u00e9 s'\u00e9tend sur 1 jour[3], proposant une introduction acc\u00e9l\u00e9r\u00e9e et pratique via le portail Azure et Azure CLI.</p> <p>Ressources de formation : Microsoft Learn propose un parcours d'apprentissage structur\u00e9 en trois parties align\u00e9 sur l'examen[2] : - Partie 1 : D\u00e9crire les concepts cloud - Partie 2 : D\u00e9crire l'architecture et les services Azure - Partie 3 : D\u00e9crire la gestion et la gouvernance Azure</p>"},{"location":"_projects/_formation-azure/azure-chap01/#roles-professionnels-specialises","title":"R\u00f4les Professionnels Sp\u00e9cialis\u00e9s","text":"<p>Au-del\u00e0 des fondamentaux, Azure propose des certifications sp\u00e9cialis\u00e9es correspondant \u00e0 diff\u00e9rents r\u00f4les professionnels[6] :</p> <p>Administrateur Azure : Gestion quotidienne des ressources Azure, supervision, optimisation des co\u00fbts, conformit\u00e9</p> <p>D\u00e9veloppeur Azure : Conception et d\u00e9veloppement d'applications cloud natives utilisant les services Azure</p> <p>Architecte de Solutions Azure : Conception d'architectures cloud scalables, s\u00e9curis\u00e9es et performantes</p> <p>Ing\u00e9nieur de donn\u00e9es Azure : Impl\u00e9mentation de solutions de donn\u00e9es sur Azure</p> <p>Ing\u00e9nieur DevOps Azure : Orchestration des processus de d\u00e9ploiement et d'infrastructure</p>"},{"location":"_projects/_formation-azure/azure-chap01/#parcours-dapprentissage-structure","title":"Parcours d'Apprentissage Structur\u00e9","text":"<p>Microsoft Learn propose des parcours d'apprentissage organis\u00e9s par domaines[1][4]. Pour d\u00e9buter efficacement avec Azure, le parcours recommand\u00e9 inclut :</p>"},{"location":"_projects/_formation-azure/azure-chap01/#1-concepts-cloud-fondamentaux","title":"1. Concepts Cloud Fondamentaux","text":"<p>Le parcours \u00ab Pr\u00e9sentation de Microsoft Azure : D\u00e9crire les concepts cloud \u00bb[2] fournit une base solide couvrant : - D\u00e9finition du cloud et ses b\u00e9n\u00e9fices - Mod\u00e8les de service (IaaS, PaaS, SaaS) - Mod\u00e8les de d\u00e9ploiement (Public, Priv\u00e9, Hybride, Multicloud) - Architecture g\u00e9n\u00e9rale d'Azure</p>"},{"location":"_projects/_formation-azure/azure-chap01/#2-services-et-architecture-azure","title":"2. Services et Architecture Azure","text":"<p>Apr\u00e8s ma\u00eetriser les concepts fondamentaux, le parcours \u00ab Partie 2 : D\u00e9crire l'architecture et les services Azure \u00bb[2] couvre les services Azure sp\u00e9cifiques et leur utilisation appropri\u00e9e.</p>"},{"location":"_projects/_formation-azure/azure-chap01/#3-gestion-et-gouvernance","title":"3. Gestion et Gouvernance","text":"<p>Le parcours \u00ab Partie 3 : D\u00e9crire la gestion et la gouvernance Azure \u00bb[2] aborde : - Gestion des co\u00fbts et budgetisation - Conformit\u00e9 r\u00e9glementaire - Outils d'administration et monitoring - Strat\u00e9gies d'acc\u00e8s et s\u00e9curit\u00e9</p>"},{"location":"_projects/_formation-azure/azure-chap01/#4-specialisations-optionnel","title":"4. Sp\u00e9cialisations (optionnel)","text":"<p>Pour les d\u00e9veloppeurs, le parcours inclut des modules sp\u00e9cialis\u00e9s[1] :</p> <ul> <li>Intelligence Artificielle dans Azure : Concepts fondamentaux de l'IA et services Azure AI[1]</li> <li>Machine Learning : Conception de solutions d'entra\u00eenement de mod\u00e8les pour projets ML[1]</li> <li>IA G\u00e9n\u00e9rative : Utilisation de mod\u00e8les de langage pour g\u00e9n\u00e9rer du contenu[1]</li> <li>Traitement du Langage Naturel : Applications comprenant et g\u00e9n\u00e9rant du langage naturel[1]</li> <li>Vision par Ordinateur : Extraction d'informations \u00e0 partir d'images[1]</li> <li>Reconnaissance Vocale : Reconnaissance et synth\u00e8se du contenu vocal[1]</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap01/#structure-recommandee-pour-la-formation","title":"Structure Recommand\u00e9e pour la Formation","text":"<p>Un apprenant typique suivrait ce chemin :</p> Text Only<pre><code>Niveau 1 : Fondamentaux\n\u251c\u2500\u2500 Concepts cloud (semaine 1)\n\u251c\u2500\u2500 Services Azure (semaine 2)\n\u2514\u2500\u2500 Gestion et gouvernance (semaine 3)\n    \u2193\nNiveau 2 : AZ-900 Certification (semaine 4)\n    \u2193\nNiveau 3 : R\u00f4le Sp\u00e9cialis\u00e9 (selon objectif)\n\u251c\u2500\u2500 D\u00e9veloppeur \u2192 AZ-204\n\u251c\u2500\u2500 Administrateur \u2192 AZ-104\n\u251c\u2500\u2500 Architecte \u2192 AZ-305\n\u2514\u2500\u2500 Donn\u00e9es \u2192 DP-900 + DP-203\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap01/#ressources-de-formation-et-support","title":"Ressources de Formation et Support","text":"<p>Microsoft propose plusieurs formats de formation pour s'adapter aux diff\u00e9rents styles d'apprentissage :</p> <p>Formation Auto-rythm\u00e9e (Self-paced) : Modules Microsoft Learn interactifs permettant d'apprendre \u00e0 son rythme avec exercices pratiques.</p> <p>Formation Dirig\u00e9e par Instructeur : Cours en ligne synchrone ou en pr\u00e9sentiel avec instructeurs certifi\u00e9s.</p> <p>Journ\u00e9es de Formation Virtuelle : \u00c9v\u00e9nements gratuits dirig\u00e9s par des instructeurs, couvrant diff\u00e9rents sujets et fuseaux horaires[4].</p> <p>\u00c9valuations Pratiques : Tests pratiques pour valider la ma\u00eetrise avant de passer l'examen de certification.</p> <p>Documentation Azure : R\u00e9f\u00e9rence compl\u00e8te incluant guides, tutoriels, exemples de code et meilleures pratiques pour tous les services[5].</p>"},{"location":"_projects/_formation-azure/azure-chap01/#demarrage-pratique","title":"D\u00e9marrage Pratique","text":"<p>Pour commencer imm\u00e9diatement :</p> <ol> <li> <p>Cr\u00e9er un compte Azure gratuit : Microsoft offre 200 USD de cr\u00e9dit gratuitement durant 30 jours, sans exiger de carte de cr\u00e9dit obligatoire.</p> </li> <li> <p>Acc\u00e9der \u00e0 Microsoft Learn : S'inscrire \u00e0 Microsoft Learn pour acc\u00e9der aux modules d'apprentissage interactifs[4][5].</p> </li> <li> <p>Explorer le portail Azure : Se familiariser avec l'interface Azure en cr\u00e9ant des ressources simples.</p> </li> <li> <p>Essayer Azure CLI : Apprendre la gestion d'Azure via ligne de commande pour gain de productivit\u00e9.</p> </li> <li> <p>Suivre un chemin d'apprentissage : S\u00e9lectionner le parcours correspondant \u00e0 son objectif professionnel.</p> </li> </ol>"},{"location":"_projects/_formation-azure/azure-chap01/#exemples-de-services-azure-dans-des-scenarios-reels","title":"Exemples de Services Azure dans des Sc\u00e9narios R\u00e9els","text":"<p>Pour illustrer l'application pratique d'Azure, voici des exemples concrets d'architecture :</p>"},{"location":"_projects/_formation-azure/azure-chap01/#scenario-1-plateforme-e-commerce","title":"Sc\u00e9nario 1 : Plateforme E-commerce","text":"<p>Une entreprise de vente en ligne utiliserait : - Azure App Service : H\u00e9berger le site web front-end - Azure SQL Database : Stocker les donn\u00e9es produits et clients - Azure Blob Storage : Images de produits - Azure Cosmos DB : Panier d'achat (donn\u00e9es temps r\u00e9el) - Azure Cache for Redis : Sessions utilisateur et cache - Azure Content Delivery Network : Distribuire contenu images rapidement globalement - Azure Application Insights : Monitoring de la performance et diagnostic des erreurs</p>"},{"location":"_projects/_formation-azure/azure-chap01/#scenario-2-analyse-de-donnees-massives","title":"Sc\u00e9nario 2 : Analyse de Donn\u00e9es Massives","text":"<p>Une agence marketing analysant millions de points de donn\u00e9es utiliserait : - Azure Data Lake Storage : Stockage centralis\u00e9 de donn\u00e9es brutes massives - Azure Synapse Analytics : Warehouse de donn\u00e9es pour requ\u00eates analytiques - Azure Data Factory : Pipelines ETL pour transformer et charger donn\u00e9es - Power BI : Visualisation et dashboards interactifs - Azure Machine Learning : Pr\u00e9dictions et mod\u00e8les analytiques avanc\u00e9s</p>"},{"location":"_projects/_formation-azure/azure-chap01/#scenario-3-application-iot","title":"Sc\u00e9nario 3 : Application IoT","text":"<p>Une entreprise de capteurs environnementaux d\u00e9ploierait : - Azure IoT Hub : Ingestion de millions de messages de capteurs - Azure Stream Analytics : Traitement en temps r\u00e9el des flux - Time Series Insights : Analyse et visualisation de s\u00e9ries temporelles - Azure Cognitive Services : D\u00e9tection d'anomalies via IA - Azure Functions : Actions automatiques en r\u00e9action aux anomalies</p>"},{"location":"_projects/_formation-azure/azure-chap01/#tableau-recapitulatif-du-parcours-dapprentissage","title":"Tableau R\u00e9capitulatif du Parcours d'Apprentissage","text":"\u00c9tape Domaine Dur\u00e9e estim\u00e9e Objectifs cl\u00e9s 1 Concepts cloud fondamentaux 1-2 semaines Comprendre IaaS, PaaS, SaaS, mod\u00e8les de d\u00e9ploiement 2 Services et architecture Azure 2-3 semaines Conna\u00eetre services majeurs, cas d'usage appropri\u00e9s 3 Gestion et gouvernance 1-2 semaines Ma\u00eetriser co\u00fbts, conformit\u00e9, s\u00e9curit\u00e9, monitoring 4 Certification AZ-900 1 semaine Validation des connaissances fondamentales 5 Sp\u00e9cialisation (optionnel) 4-8 semaines Expertise dans r\u00f4le sp\u00e9cifique : d\u00e9veloppeur, administrateur, etc."},{"location":"_projects/_formation-azure/azure-chap01/#conclusion-du-chapitre-1","title":"Conclusion du Chapitre 1","text":"<p>L'introduction au cloud et \u00e0 Azure pose les fondations essentielles pour une carri\u00e8re r\u00e9ussie dans l'informatique cloud contemporaine. Le cloud computing n'est plus une technologie \u00e9mergente mais un \u00e9l\u00e9ment central de l'infrastructure IT moderne. Microsoft Azure offre une plateforme compl\u00e8te couvrant tous les niveaux de complexit\u00e9, du d\u00e9veloppeur d\u00e9butant \u00e0 l'architecte d'entreprise.</p> <p>Le chemin d'apprentissage recommand\u00e9 d\u00e9bute avec les concepts fondamentaux du cloud, progresse vers la ma\u00eetrise sp\u00e9cifique des services Azure, et culmine dans l'obtention de certifications professionnelles validant les comp\u00e9tences acquises. Cette approche structur\u00e9e, combin\u00e9e \u00e0 la pratique pratique via l'interface Azure et Azure CLI, pr\u00e9pare efficacement les apprenants \u00e0 d\u00e9ployer, g\u00e9rer et optimiser des solutions cloud dans des environnements professionnels r\u00e9els.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure/azure-chap02/","title":"Citations","text":"<ul> <li>https://www.pierre-giraud.com/http-reseau-securite-cours/modele-reseau-osi-tcp-ip/</li> <li>https://docs.oracle.com/cd/E19957-01/820-2982/6nei1phdf/index.html</li> <li>https://aws.amazon.com/fr/what-is/osi-model/</li> <li>https://www.fortinet.com/fr/resources/cyberglossary/tcp-ip-model-vs-osi-model</li> <li>https://cisco.goffinet.org/ccna/fondamentaux/modeles-tcp-ip-osi/</li> <li>https://lfasquelle.forge.apps.education.fr/transmission/modele.html</li> <li>https://www.youtube.com/watch?v=26jazyc7VNk</li> <li>https://blog.stephane-robert.info/docs/reseaux/protocole-ip/</li> <li>https://www.reseaucerta.org/sites/default/files/modelesDeReference_etudiant.pdf</li> <li>https://btssri13.files.wordpress.com/2013/04/les-modc3a8les-osi-et-tcp-ip.pdf</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap02/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 316</li> <li>completion_tokens: 7968</li> <li>total_tokens: 8284</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.12, 'request_cost': 0.006, 'total_cost': 0.126}</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap02/#content","title":"Content","text":""},{"location":"_projects/_formation-azure/azure-chap02/#chapitre-2-introduction-aux-protocoles-reseaux","title":"Chapitre 2 : Introduction aux protocoles r\u00e9seaux","text":""},{"location":"_projects/_formation-azure/azure-chap02/#le-reseau-internet","title":"Le r\u00e9seau Internet","text":"<p>Internet repr\u00e9sente une infrastructure mondiale de communication bas\u00e9e sur un ensemble de protocoles standardis\u00e9s permettant l'interconnexion de millions d'ordinateurs et de dispositifs. Cette infrastructure s'appuie sur une architecture d\u00e9centralis\u00e9e o\u00f9 les donn\u00e9es circulent en empruntant les chemins les plus efficaces \u00e0 travers des routeurs interconnect\u00e9s[1].</p> <p>Le fonctionnement d'Internet repose sur une philosophie fondamentale : la transmission de donn\u00e9es en paquets. Contrairement aux syst\u00e8mes de communication traditionnels utilisant des connexions d\u00e9di\u00e9es (comme le r\u00e9seau t\u00e9l\u00e9phonique), Internet fragmentmente les informations en petites unit\u00e9s appel\u00e9es paquets, chacun voyageant ind\u00e9pendamment vers sa destination[1]. Cette approche conf\u00e8re \u00e0 Internet une r\u00e9silience remarquable : si un chemin devient indisponible, les paquets peuvent emprunter des routes alternatives sans interruption majeure du service.</p> <p>L'infrastructure Internet s'organise selon une hi\u00e9rarchie de r\u00e9seaux. Les fournisseurs d'acc\u00e8s Internet (FAI) interconnectent leurs r\u00e9seaux aux points d'\u00e9change Internet (IXP), cr\u00e9ant ainsi une toile complexe permettant \u00e0 n'importe quel ordinateur de communiquer avec n'importe quel autre[1]. Les protocoles TCP/IP constituent le fondement technique de cette interconnexion, d\u00e9finissant les r\u00e8gles d'\u00e9change des donn\u00e9es entre les ordinateurs.</p>"},{"location":"_projects/_formation-azure/azure-chap02/#presentation-du-modele-osi-et-introduction-a-tcpip","title":"Pr\u00e9sentation du mod\u00e8le OSI et introduction \u00e0 TCP/IP","text":"<p>La compr\u00e9hension des mod\u00e8les r\u00e9seau constitue une \u00e9tape essentielle pour ma\u00eetriser les technologies cloud d'Azure. Deux mod\u00e8les th\u00e9oriques dominent ce domaine : le mod\u00e8le OSI et le mod\u00e8le TCP/IP[1].</p>"},{"location":"_projects/_formation-azure/azure-chap02/#le-modele-osi-open-systems-interconnection","title":"Le mod\u00e8le OSI (Open Systems Interconnection)","text":"<p>Le mod\u00e8le OSI repr\u00e9sente une approche conceptuelle id\u00e9alis\u00e9e de la communication r\u00e9seau. Il d\u00e9compose le processus de communication en sept couches distinctes, permettant d'analyser et d'optimiser chaque aspect de la transmission de donn\u00e9es de mani\u00e8re isol\u00e9e[1][3].</p> N\u00b0 Couche Nom de la couche Unit\u00e9 de donn\u00e9es R\u00f4le principal 7 Application Donn\u00e9es brutes Protocoles utilisateur (HTTP, SMTP, FTP, DNS) 6 Pr\u00e9sentation Donn\u00e9es brutes Conversion de format, chiffrement, compression 5 Session Donn\u00e9es brutes Gestion des sessions et dialogues 4 Transport Segments TCP, UDP, garantie de livraison 3 R\u00e9seau Paquets Routage, adressage IP 2 Liaison des donn\u00e9es Frames Adressage MAC, d\u00e9tection d'erreurs 1 Physique Bits Transmission \u00e9lectrique/optique <p>La couche application (7) comprend les protocoles de haut niveau destin\u00e9s aux utilisateurs et aux applications. HTTP permet la consultation de pages web, SMTP g\u00e8re l'envoi de courriels, FTP assure le transfert de fichiers, et DNS traduit les noms de domaine en adresses IP[1].</p> <p>La couche pr\u00e9sentation (6) transforme les donn\u00e9es en un format lisible par l'application destinataire. Elle g\u00e8re la conversion de codage de caract\u00e8res, la compression des donn\u00e9es et le chiffrement des informations sensibles[1].</p> <p>La couche session (5) \u00e9tablit, maintient et termine les connexions entre applications. Elle contr\u00f4le le dialogue entre deux syst\u00e8mes, \u00e9vitant les conflits de transmission[1].</p> <p>La couche transport (4) garantit le transport fiable des donn\u00e9es entre deux ordinateurs. Les protocoles TCP et UDP op\u00e8rent \u00e0 ce niveau, avec TCP offrant une transmission garantie et UDP privil\u00e9giant la rapidit\u00e9[1].</p> <p>La couche r\u00e9seau (3) d\u00e9termine le meilleur chemin pour acheminer les paquets \u00e0 travers le r\u00e9seau. Le protocole IP assigne les adresses uniques et g\u00e8re le routage des donn\u00e9es[1][3].</p> <p>La couche liaison des donn\u00e9es (2) g\u00e8re les communications entre deux machines directement connect\u00e9es. Elle d\u00e9coupe les donn\u00e9es en frames de tailles variables et d\u00e9tecte les erreurs survenant lors de la transmission[1]. Les adresses MAC (Media Access Control) op\u00e8rent \u00e0 ce niveau, permettant l'identification unique de chaque p\u00e9riph\u00e9rique sur un segment r\u00e9seau.</p> <p>La couche physique (1) repr\u00e9sente le niveau mat\u00e9riel o\u00f9 les bits (0 et 1) sont encod\u00e9s sous forme de signaux \u00e9lectriques ou d'impulsions lumineuses dans les c\u00e2bles ou la fibre optique[1].</p>"},{"location":"_projects/_formation-azure/azure-chap02/#le-modele-tcpip-transmission-control-protocol-internet-protocol","title":"Le mod\u00e8le TCP/IP (Transmission Control Protocol / Internet Protocol)","text":"<p>Le mod\u00e8le TCP/IP constitue une impl\u00e9mentation pratique des principes de communication r\u00e9seau. Contrairement au mod\u00e8le OSI, il regroup\u00e9 les sept couches conceptuelles en un nombre r\u00e9duit de couches op\u00e9rationnelles[1][4].</p> <p>Des sources officielles mentionnent quatre couches tandis que d'autres en d\u00e9crivent cinq, selon le degr\u00e9 de d\u00e9tail retenu[1][3][5]. La version \u00e0 quatre couches agr\u00e8ge la couche physique avec la couche liaison des donn\u00e9es dans une couche unique appel\u00e9e \"Acc\u00e8s r\u00e9seau\"[5].</p> Couche TCP/IP \u00c9quivalent OSI Protocoles associ\u00e9s Application Couches 5, 6, 7 (Session, Pr\u00e9sentation, Application) HTTP, HTTPS, SMTP, POP3, IMAP, FTP, DNS, SSH, Telnet Transport Couche 4 (Transport) TCP, UDP, QUIC, SCTP Internet Couche 3 (R\u00e9seau) IP (IPv4, IPv6), ICMP, IGMP Acc\u00e8s r\u00e9seau Couches 1, 2 (Physique, Liaison de donn\u00e9es) Ethernet, Wi-Fi, PPP, SLIP <p>La distinction majeure entre les deux mod\u00e8les r\u00e9side dans la granularit\u00e9 : le mod\u00e8le TCP/IP regroupe certaines fonctions du mod\u00e8le OSI en couches unifi\u00e9es pour refl\u00e9ter la r\u00e9alit\u00e9 pratique des impl\u00e9mentations r\u00e9seau contemporaines[1][4].</p>"},{"location":"_projects/_formation-azure/azure-chap02/#le-processus-dencapsulation","title":"Le processus d'encapsulation","text":"<p>La transmission de donn\u00e9es \u00e0 travers le mod\u00e8le TCP/IP suit un processus appel\u00e9 encapsulation. Chaque couche ajoute ses propres en-t\u00eates aux donn\u00e9es, transformant progressivement le message original[1].</p> <p>Lorsqu'un navigateur demande une page web :</p> <ol> <li> <p>Couche Application : Le protocole HTTP cr\u00e9e une requ\u00eate HTTP contenant l'URL et les param\u00e8tres demand\u00e9s.</p> </li> <li> <p>Couche Transport : TCP ajoute un en-t\u00eate de transport contenant le port source et le port destination, transformant le message en segment[1].</p> </li> <li> <p>Couche Internet : IP ajoute un en-t\u00eate avec l'adresse IP source et l'adresse IP destination, cr\u00e9ant un paquet[1].</p> </li> <li> <p>Couche Acc\u00e8s r\u00e9seau : Ethernet ajoute un en-t\u00eate contenant les adresses MAC source et destination, formant une frame. Les donn\u00e9es sont ensuite transform\u00e9es en bits (signaux \u00e9lectriques ou lumineux)[1].</p> </li> </ol> <p>\u00c0 la r\u00e9ception, ce processus s'inverse : les bits se reconstituent en frames, puis en paquets, en segments, et finalement en donn\u00e9es originales que l'application peut traiter[1].</p>"},{"location":"_projects/_formation-azure/azure-chap02/#ladressage-reseau-avec-le-protocole-internet-ip","title":"L'adressage r\u00e9seau avec le protocole Internet (IP)","text":"<p>L'adressage IP repr\u00e9sente le fondement de la routabilit\u00e9 sur Internet. Deux versions du protocole Internet coexistent actuellement : IPv4 et IPv6, chacune utilisant un syst\u00e8me d'adressage distinct[1][3].</p>"},{"location":"_projects/_formation-azure/azure-chap02/#ipv4-internet-protocol-version-4","title":"IPv4 (Internet Protocol version 4)","text":"<p>IPv4 utilise des adresses de 32 bits organis\u00e9es en quatre octets (bytes), chacun pouvant repr\u00e9senter une valeur de 0 \u00e0 255. Cet ensemble de quatre nombres s\u00e9par\u00e9s par des points constitue la notation d\u00e9cimale point\u00e9e[1].</p> <p>Exemple d'adresse IPv4 : <code>192.168.1.100</code></p> <p>Chaque octet repr\u00e9sente 8 bits, permettant 256 valeurs possibles : - <code>192</code> = <code>11000000</code> en binaire - <code>168</code> = <code>10101000</code> en binaire - <code>1</code> = <code>00000001</code> en binaire - <code>100</code> = <code>01100100</code> en binaire</p> <p>Les adresses IPv4 se divisent en deux composants logiques : l'adresse r\u00e9seau et l'adresse d'h\u00f4te. Le masque de sous-r\u00e9seau d\u00e9termine o\u00f9 s'effectue cette division[1].</p> <p>Les classes d'adresses IPv4 (classique, obsol\u00e8te pour les nouvelles allocations) :</p> Classe Plage Masque par d\u00e9faut Usage A 1.0.0.0 \u00e0 126.255.255.255 255.0.0.0 (/8) R\u00e9seaux tr\u00e8s larges B 128.0.0.0 \u00e0 191.255.255.255 255.255.0.0 (/16) R\u00e9seaux de taille moyenne C 192.0.0.0 \u00e0 223.255.255.255 255.255.255.0 (/24) Petits r\u00e9seaux D 224.0.0.0 \u00e0 239.255.255.255 - Multicast E 240.0.0.0 \u00e0 255.255.255.255 - R\u00e9serv\u00e9 <p>Les adresses priv\u00e9es r\u00e9serv\u00e9es (RFC 1918) ne sont pas routables sur Internet :</p> <ul> <li>Classe A priv\u00e9e : <code>10.0.0.0/8</code> (10.0.0.0 \u00e0 10.255.255.255)</li> <li>Classe B priv\u00e9e : <code>172.16.0.0/16</code> (172.16.0.0 \u00e0 172.31.255.255)</li> <li>Classe C priv\u00e9e : <code>192.168.0.0/24</code> (192.168.0.0 \u00e0 192.168.255.255)</li> </ul> <p>Ces plages s'utilisent couramment dans les r\u00e9seaux d'entreprise et les environnements cloud priv\u00e9s.</p>"},{"location":"_projects/_formation-azure/azure-chap02/#ipv6-internet-protocol-version-6","title":"IPv6 (Internet Protocol version 6)","text":"<p>IPv6 r\u00e9sout la limitation majeure d'IPv4 : l'\u00e9puisement des adresses disponibles. Utilisant des adresses de 128 bits, IPv6 offre un espace d'adressage pratiquement illimit\u00e9[1][3].</p> <p>Exemple d'adresse IPv6 : <code>2001:0db8:85a3:0000:0000:8a2e:0370:7334</code></p> <p>La notation IPv6 s'\u00e9crit en hexad\u00e9cimal, avec 8 groupes de 4 chiffres hexad\u00e9cimaux s\u00e9par\u00e9s par des deux-points. Pour simplifier, les z\u00e9ros \u00e0 gauche peuvent s'omettre et les s\u00e9quences de groupes contenant uniquement des z\u00e9ros peuvent se remplacer par <code>::</code></p> <p>Forme simplifi\u00e9e : <code>2001:db8:85a3::8a2e:370:7334</code></p> <p>Les types d'adresses IPv6 :</p> <ul> <li>Unicast : Communication point \u00e0 point (un exp\u00e9diteur, un destinataire)</li> <li>Multicast : Communication un-vers-plusieurs (un exp\u00e9diteur, plusieurs destinataires)</li> <li>Anycast : Communication vers le service le plus proche</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap02/#le-masque-de-sous-reseau-et-la-notation-cidr","title":"Le masque de sous-r\u00e9seau et la notation CIDR","text":"<p>Le masque de sous-r\u00e9seau d\u00e9termine quels bits d'une adresse IP identifient le r\u00e9seau et quels bits identifient l'h\u00f4te. La notation CIDR (Classless Inter-Domain Routing) simplifie cette repr\u00e9sentation en indiquant le nombre de bits r\u00e9seau[1].</p> <p>Notation CIDR : <code>192.168.1.0/24</code></p> <ul> <li><code>/24</code> signifie que les 24 premiers bits identifient le r\u00e9seau</li> <li>Les 8 bits restants (32 - 24) identifient les h\u00f4tes</li> <li>Ce r\u00e9seau peut accueillir 254 adresses d'h\u00f4tes (256 - 2 : une pour le r\u00e9seau, une pour le broadcast)</li> </ul> <p>Exemples de masques courants :</p> Notation CIDR Masque d\u00e9cimal Nombre d'h\u00f4tes /8 255.0.0.0 16 777 214 /16 255.255.0.0 65 534 /24 255.255.255.0 254 /30 255.255.255.252 2 /32 255.255.255.255 1 (h\u00f4te unique)"},{"location":"_projects/_formation-azure/azure-chap02/#le-transport-sur-le-reseau-avec-les-protocoles-tcp-udp-et-quic","title":"Le transport sur le r\u00e9seau avec les protocoles TCP, UDP et QUIC","text":"<p>La couche transport garantit l'acheminement fiable ou rapide des donn\u00e9es entre processus sur diff\u00e9rents ordinateurs. Trois protocoles dominent ce niveau : TCP, UDP et QUIC, chacun adapt\u00e9 \u00e0 des besoins sp\u00e9cifiques[1].</p>"},{"location":"_projects/_formation-azure/azure-chap02/#tcp-transmission-control-protocol","title":"TCP (Transmission Control Protocol)","text":"<p>TCP fournit une communication fiable, ordonn\u00e9e et sans erreur entre deux ordinateurs. Il \u00e9tablit une connexion avant de transmettre les donn\u00e9es et garantit que tous les paquets arrivent \u00e0 destination dans le bon ordre[1][4].</p> <p>Caract\u00e9ristiques de TCP :</p> <ul> <li>Connexion \u00e9tablie : Utilise une poign\u00e9e de main \u00e0 trois \u00e9tapes (three-way handshake) avant transmission</li> <li>Transmission fiable : Retransmission automatique des paquets perdus</li> <li>Contr\u00f4le de flux : R\u00e9gulation de la vitesse de transmission selon la capacit\u00e9 du r\u00e9cepteur</li> <li>D\u00e9tection d'erreurs : V\u00e9rification d'int\u00e9grit\u00e9 des donn\u00e9es via checksums</li> <li>Ordonnancement : Assemblage des segments dans le bon ordre</li> </ul> <p>Le processus de trois-way handshake :</p> Text Only<pre><code>Client                                          Serveur\n  |                                                |\n  |-------- SYN (seq=x) ----------------------&gt;   |\n  |                                                |\n  |  &lt;----- SYN-ACK (seq=y, ack=x+1) ------  |\n  |                                                |\n  |-------- ACK (seq=x+1, ack=y+1) --------&gt;   |\n  |                                                |\n  |--- Connexion \u00e9tablie, transfert de donn\u00e9es -|\n</code></pre> <p>Utilisations courantes : - HTTP/HTTPS (navigation web) - SMTP (envoi de courriels) - FTP (transfert de fichiers) - SSH (acc\u00e8s s\u00e9curis\u00e9 \u00e0 distance) - Bases de donn\u00e9es (MySQL, PostgreSQL, SQL Server)</p>"},{"location":"_projects/_formation-azure/azure-chap02/#udp-user-datagram-protocol","title":"UDP (User Datagram Protocol)","text":"<p>UDP privil\u00e9gie la vitesse plut\u00f4t que la fiabilit\u00e9. Il ne garantit pas la livraison des paquets ni leur ordre d'arriv\u00e9e, mais offre une latence minimale, d'o\u00f9 son utilisation pour les applications temps r\u00e9el[1][4].</p> <p>Caract\u00e9ristiques d'UDP :</p> <ul> <li>Sans connexion : Pas d'\u00e9tablissement de connexion pr\u00e9alable</li> <li>Transmission non fiable : Les paquets perdus ne sont pas retransmis</li> <li>Pas d'ordonnancement : Les paquets peuvent arriver d\u00e9sordonn\u00e9s</li> <li>En-t\u00eates l\u00e9gers : Surcharge minimale par rapport \u00e0 TCP</li> <li>Broadcast et multicast : Support de la transmission \u00e0 plusieurs destinataires</li> </ul> <p>Utilisations courantes : - VoIP (communication vocale) - Vid\u00e9oconf\u00e9rence - Jeux en ligne - Streaming vid\u00e9o - Requ\u00eates DNS - NTP (synchronisation d'horloge)</p>"},{"location":"_projects/_formation-azure/azure-chap02/#quic-quick-udp-internet-connections","title":"QUIC (Quick UDP Internet Connections)","text":"<p>QUIC repr\u00e9sente un protocole moderne qui combine les avantages de TCP et UDP. D\u00e9velopp\u00e9 par Google et standardis\u00e9 par l'IETF, QUIC s'int\u00e8gre \u00e0 HTTP/3 pour offrir des performances am\u00e9lior\u00e9es[4].</p> <p>Caract\u00e9ristiques de QUIC :</p> <ul> <li>Bas\u00e9 sur UDP : H\u00e9rite de la vitesse d'UDP</li> <li>Fiabilit\u00e9 comme TCP : Garantit la livraison et l'ordonnancement</li> <li>\u00c9tablissement de connexion rapide : R\u00e9duit la latence initiale</li> <li>Migration de connexion : Pr\u00e9serve la connexion lors d'un changement de r\u00e9seau (WiFi vers cellulaire)</li> <li>Chiffrement natif : TLS 1.3 int\u00e9gr\u00e9 par d\u00e9faut</li> <li>Multiplexing : Gestion simultan\u00e9e de plusieurs flux de donn\u00e9es</li> </ul> <p>Utilisations courantes : - HTTP/3 et navigation web moderne - Applications cloud - Streaming m\u00e9dia - Applications mobiles</p>"},{"location":"_projects/_formation-azure/azure-chap02/#comparaison-des-protocoles-de-transport","title":"Comparaison des protocoles de transport","text":"Caract\u00e9ristique TCP UDP QUIC Fiabilit\u00e9 Garantie Non garantie Garantie Ordre de livraison Pr\u00e9serv\u00e9 Non pr\u00e9serv\u00e9 Pr\u00e9serv\u00e9 Latence Plus \u00e9lev\u00e9e Minimale Minimale \u00c9tablissement connexion Oui (3 \u00e9tapes) Non Oui (1 RTT) Surcharge en-t\u00eates Moyenne Faible Faible Contr\u00f4le de flux Oui Non Oui Chiffrement natif Non (via TLS) Non Oui (TLS 1.3) Migration connexion Non N/A Oui"},{"location":"_projects/_formation-azure/azure-chap02/#la-couche-applicative-avec-les-protocoles-http-smtp-et-ftp","title":"La couche applicative avec les protocoles HTTP, SMTP et FTP","text":"<p>La couche application englobe tous les protocoles permettant aux utilisateurs et aux applications d'interagir avec le r\u00e9seau. Trois protocoles essentiels dominent ce domaine[1].</p>"},{"location":"_projects/_formation-azure/azure-chap02/#http-hypertext-transfer-protocol-et-https","title":"HTTP (HyperText Transfer Protocol) et HTTPS","text":"<p>HTTP constitue le protocole fondateur du Web. Il d\u00e9finit les r\u00e8gles d'\u00e9change de documents hypertexte entre un client (navigateur) et un serveur[1].</p> <p>Caract\u00e9ristiques de HTTP :</p> <ul> <li>Architecture requ\u00eate/r\u00e9ponse : Le client envoie une requ\u00eate, le serveur r\u00e9pond</li> <li>Sans \u00e9tat : Chaque requ\u00eate s'ex\u00e9cute ind\u00e9pendamment, les cookies et sessions assurent la persistance</li> <li>Bas\u00e9 sur TCP : Utilise TCP comme protocole de transport (port 80 par d\u00e9faut)</li> </ul> <p>Les m\u00e9thodes HTTP principales :</p> M\u00e9thode Description S\u00fbre Idempotente GET R\u00e9cup\u00e8re une ressource Oui Oui POST Cr\u00e9e une ressource Non Non PUT Remplace une ressource Non Oui PATCH Modifie partiellement une ressource Non Non DELETE Supprime une ressource Non Oui HEAD Comme GET mais sans corps de r\u00e9ponse Oui Oui OPTIONS D\u00e9crit les options de communication Oui Oui <p>Exemple d'une requ\u00eate HTTP :</p> Text Only<pre><code>GET /index.html HTTP/1.1\nHost: www.example.com\nUser-Agent: Mozilla/5.0\nAccept: text/html,application/xhtml+xml\nAccept-Language: fr-FR\nConnection: keep-alive\n</code></pre> <p>Exemple d'une r\u00e9ponse HTTP :</p> Text Only<pre><code>HTTP/1.1 200 OK\nContent-Type: text/html; charset=UTF-8\nContent-Length: 1234\nCache-Control: max-age=3600\nConnection: keep-alive\n\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;&lt;title&gt;Accueil&lt;/title&gt;&lt;/head&gt;\n&lt;body&gt;\n...contenu de la page...\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Les codes de statut HTTP :</p> <ul> <li>1xx (Information) : 100 Continue, 101 Switching Protocols</li> <li>2xx (Succ\u00e8s) : 200 OK, 201 Created, 204 No Content</li> <li>3xx (Redirection) : 301 Moved Permanently, 302 Found, 304 Not Modified</li> <li>4xx (Erreur client) : 400 Bad Request, 401 Unauthorized, 403 Forbidden, 404 Not Found</li> <li>5xx (Erreur serveur) : 500 Internal Server Error, 502 Bad Gateway, 503 Service Unavailable</li> </ul> <p>HTTPS (HTTP Secure) chiffre la communication en ajoutant une couche SSL/TLS au-dessus d'HTTP. Cette protection s'av\u00e8re essentielle pour les transactions sensibles[1].</p>"},{"location":"_projects/_formation-azure/azure-chap02/#smtp-simple-mail-transfer-protocol","title":"SMTP (Simple Mail Transfer Protocol)","text":"<p>SMTP g\u00e8re l'envoi de courriels depuis un client vers un serveur de messagerie ou d'un serveur \u00e0 un autre[1].</p> <p>Caract\u00e9ristiques de SMTP :</p> <ul> <li>Port 25 (non chiffr\u00e9), 465 (SMTPS), 587 (SMTP avec STARTTLS) : Ports standards de connexion</li> <li>Bas\u00e9 sur TCP : Utilise TCP comme protocole de transport</li> <li>Architecture requ\u00eate/r\u00e9ponse : Dialogue texte entre client et serveur</li> </ul> <p>Exemple d'une session SMTP :</p> Text Only<pre><code>220 mail.example.com ESMTP server ready\nEHLO client.example.com\n250-mail.example.com\n250-STARTTLS\n250-AUTH LOGIN PLAIN\n250 HELP\nSTARTTLS\n220 Ready to start TLS\nAUTH LOGIN\n334 VXNlcm5hbWU6\ndXNlckBleGFtcGxlLmNvbQ==\n334 UGFzc3dvcmQ6\ncGFzc3dvcmQxMjM=\n235 2.7.0 Accepted\nMAIL FROM:&lt;sender@example.com&gt;\n250 OK\nRCPT TO:&lt;recipient@example.com&gt;\n250 OK\nDATA\n354 Start mail input; end with &lt;CRLF&gt;.&lt;CRLF&gt;\nFrom: sender@example.com\nTo: recipient@example.com\nSubject: Test\nThis is a test email.\n.\n250 OK\nQUIT\n221 Goodbye\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap02/#protocoles-complementaires-de-messagerie","title":"Protocoles compl\u00e9mentaires de messagerie","text":"<p>POP3 (Post Office Protocol version 3) permet le t\u00e9l\u00e9chargement de courriels depuis un serveur. Une fois t\u00e9l\u00e9charg\u00e9s, les messages s'effacent g\u00e9n\u00e9ralement du serveur (bien que cette suppression puisse s'\u00e9viter)[1].</p> <p>IMAP (Internet Message Access Protocol) offre un contr\u00f4le plus granulaire. Les courriels restent sur le serveur, permettant \u00e0 plusieurs clients d'acc\u00e9der \u00e0 la m\u00eame bo\u00eete de r\u00e9ception[1].</p>"},{"location":"_projects/_formation-azure/azure-chap02/#ftp-file-transfer-protocol","title":"FTP (File Transfer Protocol)","text":"<p>FTP assure le transfert de fichiers entre ordinateurs sur un r\u00e9seau. Il utilise deux canaux TCP distincts : un canal de contr\u00f4le (port 21) pour les commandes et un canal de donn\u00e9es (port 20) pour le contenu des fichiers[1].</p> <p>Caract\u00e9ristiques de FTP :</p> <ul> <li>Mode actif et passif : Deux modes de fonctionnement selon que le serveur ou le client \u00e9tablit la connexion de donn\u00e9es</li> <li>Authentification : Nom d'utilisateur et mot de passe g\u00e9n\u00e9ralement requis (transmis en clair, d'o\u00f9 le risque de s\u00e9curit\u00e9)</li> <li>R\u00e9pertoires virtuels : Navigation dans une arborescence de fichiers</li> </ul> <p>Mode passif (recommand\u00e9) :</p> Text Only<pre><code>Client                                   Serveur FTP\n  |                                            |\n  |---- CONNECTION (port 21) ---------&gt;        |\n  |  &lt;------ 220 Service Ready -------         |\n  |                                            |\n  |---- USER anonymous --------&gt;               |\n  |  &lt;------ 331 Password required ---         |\n  |                                            |\n  |---- PASS user@example.com -------&gt;         |\n  |  &lt;------ 230 Logged in --------           |\n  |                                            |\n  |---- PASV (Port passif) --------&gt;           |\n  |  &lt;------ 227 Entering Passive Mode        |\n  |          (192,168,1,100,15,16) ---         |\n  |                                            |\n  |---- Connexion donn\u00e9es (port 3856) -------&gt;|\n  |  &lt;----- 150 Opening data connection       |\n  |                                            |\n  |  &lt;----- Donn\u00e9es de fichier -------        |\n  |                                            |\n  |  &lt;----- 226 Transfer complete ---         |\n  |                                            |\n  |---- QUIT ------------------------------&gt;  |\n  |  &lt;------ 221 Goodbye --------             |\n</code></pre> <p>Commandes FTP courantes :</p> <ul> <li><code>USER</code> : Authentification utilisateur</li> <li><code>PASS</code> : Mot de passe</li> <li><code>LIST</code> : Listing des fichiers du r\u00e9pertoire courant</li> <li><code>CWD</code> : Changement de r\u00e9pertoire</li> <li><code>RETR</code> : T\u00e9l\u00e9chargement (r\u00e9cup\u00e9ration)</li> <li><code>STOR</code> : Upload (stockage)</li> <li><code>DEL</code> : Suppression de fichier</li> <li><code>MKD</code> : Cr\u00e9ation de r\u00e9pertoire</li> <li><code>RMD</code> : Suppression de r\u00e9pertoire</li> <li><code>QUIT</code> : D\u00e9connexion</li> </ul> <p>SFTP (SSH File Transfer Protocol) et SCP (Secure Copy Protocol) constituent des alternatives s\u00e9curis\u00e9es \u00e0 FTP, utilisant SSH pour chiffrer les communications.</p>"},{"location":"_projects/_formation-azure/azure-chap02/#le-protocole-dns-et-serveurs-dns","title":"Le protocole DNS et serveurs DNS","text":"<p>DNS (Domain Name System) traduit les noms de domaine lisibles en adresses IP routables que les ordinateurs peuvent utiliser[1].</p>"},{"location":"_projects/_formation-azure/azure-chap02/#fonctionnement-du-dns","title":"Fonctionnement du DNS","text":"<p>Lorsqu'un navigateur visite <code>www.example.com</code>, plusieurs \u00e9tapes s'ex\u00e9cutent en arri\u00e8re-plan :</p> <ol> <li> <p>Requ\u00eate au r\u00e9solveur local : L'ordinateur client envoie une requ\u00eate DNS \u00e0 son r\u00e9solveur configur\u00e9 (g\u00e9n\u00e9ralement fourni par le FAI)</p> </li> <li> <p>Requ\u00eate aux serveurs racine : Si le r\u00e9solveur ne conna\u00eet pas la r\u00e9ponse, il interroge un serveur racine qui r\u00e9pond avec l'adresse d'un serveur de noms TLD</p> </li> <li> <p>Requ\u00eate au serveur TLD : Le r\u00e9solveur interroge le serveur TLD (com, fr, org, etc.) qui r\u00e9pond avec l'adresse du serveur de noms autoritaire pour example.com</p> </li> <li> <p>Requ\u00eate au serveur autoritaire : Le r\u00e9solveur interroge le serveur de noms autoritaire qui fournit l'adresse IP r\u00e9elle</p> </li> <li> <p>R\u00e9ponse au client : Le r\u00e9solveur renvoie l'adresse IP au client, qui \u00e9tablit une connexion[1]</p> </li> </ol>"},{"location":"_projects/_formation-azure/azure-chap02/#hierarchie-dns-et-types-denregistrements","title":"Hi\u00e9rarchie DNS et types d'enregistrements","text":"<p>La structure DNS s'organise hi\u00e9rarchiquement du plus g\u00e9n\u00e9ral au plus sp\u00e9cifique :</p> Text Only<pre><code>.                          (racine)\n\u251c\u2500\u2500 com\n\u2502   \u2514\u2500\u2500 example.com\n\u2502       \u251c\u2500\u2500 www\n\u2502       \u251c\u2500\u2500 mail\n\u2502       \u2514\u2500\u2500 ftp\n\u251c\u2500\u2500 fr\n\u2502   \u2514\u2500\u2500 example.fr\n\u251c\u2500\u2500 org\n\u2514\u2500\u2500 ...\n</code></pre> <p>Les enregistrements DNS principaux :</p> Type Description Exemple A Adresse IPv4 <code>www.example.com \u2192 192.0.2.1</code> AAAA Adresse IPv6 <code>www.example.com \u2192 2001:db8::1</code> CNAME Alias de domaine <code>alias.example.com \u2192 www.example.com</code> MX Serveur de messagerie <code>example.com \u2192 mail.example.com</code> NS Serveur de noms <code>example.com \u2192 ns1.example.com</code> TXT Enregistrement texte <code>example.com \u2192 SPF, DKIM, etc.</code> SOA Autorit\u00e9 de zone Informations administratives PTR Reverse DNS <code>1.2.0.192.in-addr.arpa \u2192 www.example.com</code> SRV Service <code>_service._proto.name \u2192 serveur:port</code>"},{"location":"_projects/_formation-azure/azure-chap02/#configuration-dns-dans-azure","title":"Configuration DNS dans Azure","text":"<p>Dans Azure, les services DNS se configurent via Azure DNS qui h\u00e9berge les zones DNS avec haute disponibilit\u00e9[1].</p> YAML<pre><code>Zone: example.com\nEnregistrements:\n  - Type: A\n    Nom: www\n    TTL: 3600\n    Valeur: 20.84.156.23\n\n  - Type: A\n    Nom: api\n    TTL: 3600\n    Valeur: 20.84.156.24\n\n  - Type: CNAME\n    Nom: blog\n    TTL: 3600\n    Valeur: www.example.com\n\n  - Type: MX\n    Nom: @\n    TTL: 3600\n    Priorit\u00e9: 10\n    Valeur: mail.example.com\n\n  - Type: TXT\n    Nom: @\n    TTL: 3600\n    Valeur: v=spf1 include:_spf.google.com ~all\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap02/#mise-en-cache-dns","title":"Mise en cache DNS","text":"<p>Le DNS utilise un syst\u00e8me de mise en cache pour r\u00e9duire le trafic r\u00e9seau. Chaque enregistrement poss\u00e8de une valeur TTL (Time To Live) en secondes indiquant la dur\u00e9e pendant laquelle la r\u00e9ponse peut \u00eatre mise en cache[1].</p> TTL Signification 300 5 minutes (changements fr\u00e9quents attendus) 3600 1 heure (configuration stable) 86400 24 heures (configuration tr\u00e8s stable)"},{"location":"_projects/_formation-azure/azure-chap02/#securisation-des-echanges-avec-les-protocoles-ssl-et-tls","title":"S\u00e9curisation des \u00e9changes avec les protocoles SSL et TLS","text":"<p>La s\u00e9curit\u00e9 des communications r\u00e9seau repose sur la chiffrement et l'authentification fournis par SSL (Secure Sockets Layer) et son successeur TLS (Transport Layer Security)[1].</p>"},{"location":"_projects/_formation-azure/azure-chap02/#ssl-et-tls-concepts-fondamentaux","title":"SSL et TLS : concepts fondamentaux","text":"<p>SSL/TLS op\u00e8re \u00e0 la couche 5 ou 6 du mod\u00e8le OSI (entre la couche application et la couche transport), cr\u00e9ant un tunnel s\u00e9curis\u00e9 pour les donn\u00e9es sensibles[1].</p> <p>Versions historiques et actuelles :</p> Version Date Statut Notes SSL 2.0 1995 Obsol\u00e8te De nombreuses vuln\u00e9rabilit\u00e9s SSL 3.0 1996 Obsol\u00e8te Vuln\u00e9rabilit\u00e9s d\u00e9couvertes TLS 1.0 1999 D\u00e9pr\u00e9ci\u00e9e Bas\u00e9e sur SSL 3.0, vuln\u00e9rabilit\u00e9s TLS 1.1 2006 D\u00e9pr\u00e9ci\u00e9e Am\u00e9liorations limit\u00e9es TLS 1.2 2008 Recommand\u00e9e Largement d\u00e9ploy\u00e9e TLS 1.3 2018 Actuelle Plus rapide, plus s\u00fbre"},{"location":"_projects/_formation-azure/azure-chap02/#fonctionnement-de-la-poignee-de-main-tls-12","title":"Fonctionnement de la poign\u00e9e de main TLS 1.2","text":"<p>La poign\u00e9e de main TLS \u00e9tablit une connexion s\u00e9curis\u00e9e entre client et serveur en plusieurs \u00e9tapes :</p> Text Only<pre><code>Client                                  Serveur\n  |                                        |\n  |------ ClientHello --------&gt;            |\n  |   (versions support\u00e9es,                |\n  |    cipher suites, etc.)                |\n  |                                        |\n  |       &lt;------ ServerHello --------     |\n  |       (version TLS choisie,            |\n  |        cipher suite, certificat)       |\n  |                                        |\n  |       &lt;------ ServerKeyExchange       |\n  |       (param\u00e8tres de cl\u00e9)              |\n  |                                        |\n  |       &lt;------ ServerHelloDone -       |\n  |                                        |\n  |------ ClientKeyExchange ------&gt;        |\n  |   (cl\u00e9 de session chiffr\u00e9e)            |\n  |                                        |\n  |------ ChangeCipherSpec ------&gt;        |\n  |------ Finished --------&gt;               |\n  |                                        |\n  |       &lt;------ ChangeCipherSpec       |\n  |       &lt;------ Finished -------        |\n  |                                        |\n  |= = = = Connexion s\u00e9curis\u00e9e = = = = = =|\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap02/#certificats-x509","title":"Certificats X.509","text":"<p>Les certificats X.509 authentifient l'identit\u00e9 d'un serveur. Ils contiennent :</p> <ul> <li>Informations du sujet : Domaine, organisation</li> <li>Cl\u00e9 publique : Utilis\u00e9e pour chiffrer les donn\u00e9es</li> <li>Signature de l'autorit\u00e9 de certification (CA) : Valide le certificat</li> <li>P\u00e9riode de validit\u00e9 : Date de d\u00e9but et d'expiration</li> <li>Extensions : SAN (Subject Alternative Names), contraintes, etc.</li> </ul> <p>Exemple de certificat :</p> Text Only<pre><code>Certificate:\n    Data:\n        Version: 3 (0x2)\n        Serial Number: 03:f5:5f:8b:5d:f3:24:d9\n        Signature Algorithm: sha256WithRSAEncryption\n        Issuer: C=US, O=Let's Encrypt, CN=R3\n        Validity\n            Not Before: Dec  2 07:31:40 2024 GMT\n            Not After : Mar  2 07:31:39 2025 GMT\n        Subject: CN=www.example.com\n        Subject Public Key Info:\n            Public Key Algorithm: rsaEncryption\n                RSA Public-Key: (2048 bit)\n        X509v3 extensions:\n            X509v3 Subject Alternative Name:\n                DNS:www.example.com, DNS:example.com\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap02/#types-de-certificats-ssltls","title":"Types de certificats SSL/TLS","text":"Type Domaines couverts Co\u00fbt Validation Wildcard Un domaine et tous les sous-domaines Mod\u00e9r\u00e9 Domaine Multi-SAN Plusieurs domaines sp\u00e9cifiques Mod\u00e9r\u00e9 \u00e0 \u00e9lev\u00e9 Domaines Single Un seul domaine exact Faible Domaine EV (Extended Validation) Un domaine avec validation approfondie \u00c9lev\u00e9 Organisation"},{"location":"_projects/_formation-azure/azure-chap02/#implementation-de-https-dans-azure","title":"Impl\u00e9mentation de HTTPS dans Azure","text":"<p>Azure fournit des certificats SSL/TLS g\u00e9r\u00e9s pour les services cloud. Azure Application Gateway, Azure CDN et App Service proposent tous des options de certificats gratuits via Let's Encrypt ou des certificats personnalis\u00e9s import\u00e9s[1].</p> YAML<pre><code># Configuration Azure Application Gateway\nListeners:\n  - Protocol: HTTPS\n    Port: 443\n    Certificate: \n      Name: www-example-com-cert\n      Thumbprint: A1B2C3D4E5F6...\n    HostName: www.example.com\n\nBackend Settings:\n  - Protocol: HTTPS\n    Port: 443\n    BackendHttpSettings:\n      CookieBasedAffinity: Enabled\n      RequestTimeout: 30\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap02/#chaine-de-certificats-et-autorites-de-certification","title":"Cha\u00eene de certificats et autorit\u00e9s de certification","text":"<p>Un certificat valide s'accompagne d'une cha\u00eene de confiance reliant le certificat du serveur \u00e0 un certificat racine de confiance du syst\u00e8me d'exploitation ou du navigateur[1].</p> <p>Exemple de cha\u00eene :</p> Text Only<pre><code>Certificat serveur (www.example.com)\n        \u2193\nCertificat interm\u00e9diaire (Let's Encrypt R3)\n        \u2193\nCertificat racine (ISRG Root X1)\n        \u2193\nStore de certificats racines du syst\u00e8me\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap02/#integration-des-protocoles-reseau-dans-azure","title":"Int\u00e9gration des protocoles r\u00e9seau dans Azure","text":"<p>La ma\u00eetrise de ces protocoles r\u00e9seau s'av\u00e8re essentielle pour configurer correctement les services Azure. Les services r\u00e9seau d'Azure s'appuient sur ces protocoles pour assurer la communication s\u00e9curis\u00e9e et efficace.</p> <p>Azure Virtual Network (VNet) g\u00e8re les adresses IP, les sous-r\u00e9seaux et le routage au niveau 3 (r\u00e9seau)[1]. Azure Network Security Groups contr\u00f4le le trafic TCP et UDP au niveau 4 (transport)[1]. Azure Application Gateway assure le routage HTTP/HTTPS au niveau 7 (application)[1].</p> <p>La compr\u00e9hension approfondie de ces protocoles permet de diagnostiquer les probl\u00e8mes de connectivit\u00e9, d'optimiser les performances et de s\u00e9curiser les communications au sein d'une infrastructure cloud d'Azure.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure/azure-chap03/","title":"Citations","text":"<ul> <li>https://www.sentinelone.com/fr/cybersecurity-101/cloud-security/what-is-cloud-shared-responsibility-model/</li> <li>https://rotek.fr/modele-responsabilite-partagee-azure-cloud/</li> <li>https://www.crowdstrike.com/fr-fr/cybersecurity-101/cloud-security/shared-responsibility/</li> <li>https://www.axido.fr/securite-cloud-azure/</li> <li>https://learn.microsoft.com/fr-fr/azure/security/fundamentals/shared-responsibility</li> <li>https://learn.microsoft.com/fr-fr/azure/security/fundamentals/shared-responsibility-ai</li> <li>https://www.wiz.io/fr-fr/academy/shared-responsibility-model</li> <li>https://learn.microsoft.com/fr-fr/azure/reliability/concept-shared-responsibility</li> <li>https://empower.bluesoft-group.com/responsabilite-partagee-cloud/</li> <li>https://www.youtube.com/watch?v=I-Cai6vvReY</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap03/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 253</li> <li>completion_tokens: 6109</li> <li>total_tokens: 6362</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.092, 'request_cost': 0.006, 'total_cost': 0.098}</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap03/#content","title":"Content","text":""},{"location":"_projects/_formation-azure/azure-chap03/#chapitre-3-concepts-du-cloud","title":"Chapitre 3 : Concepts du cloud \u2601\ufe0f","text":""},{"location":"_projects/_formation-azure/azure-chap03/#notions-cles-pour-le-cloud","title":"Notions cl\u00e9s pour le cloud","text":""},{"location":"_projects/_formation-azure/azure-chap03/#definition-et-principes-fondamentaux","title":"D\u00e9finition et principes fondamentaux","text":"<p>Le cloud computing repr\u00e9sente un changement fondamental dans la fa\u00e7on dont les organisations acc\u00e8dent et g\u00e8rent les ressources informatiques. Plut\u00f4t que de poss\u00e9der et de maintenir physiquement des serveurs et des infrastructures, les organisations peuvent acc\u00e9der \u00e0 des ressources informatiques \u00e0 la demande via Internet.</p> <p>Les notions cl\u00e9s du cloud reposent sur plusieurs principes essentiels :</p> <p>Accessibilit\u00e9 et disponibilit\u00e9 : Les ressources cloud sont accessibles de n'importe o\u00f9, \u00e0 tout moment, via une connexion Internet. Cette caract\u00e9ristique \u00e9limine les contraintes g\u00e9ographiques et permet aux \u00e9quipes distribu\u00e9es de collaborer efficacement.</p> <p>Flexibilit\u00e9 et scalabilit\u00e9 : Les organisations peuvent ajuster rapidement la quantit\u00e9 de ressources utilis\u00e9es selon leurs besoins. Il est possible d'augmenter les capacit\u00e9s pendant les pics de demande et de r\u00e9duire pendant les creux, sans investissement mat\u00e9riel pr\u00e9alable.</p> <p>Automatisation et orchestration : Le cloud permet l'automatisation de nombreuses t\u00e2ches r\u00e9p\u00e9titives. Les processus de d\u00e9ploiement, de mise \u00e0 l'\u00e9chelle et de maintenance peuvent \u00eatre orchestr\u00e9s automatiquement, r\u00e9duisant les interventions manuelles.</p> <p>Performance et latence : Les fournisseurs de cloud maintiennent une infrastructure distribu\u00e9e mondialement avec des centres de donn\u00e9es strategiquement situ\u00e9s. Cela permet de r\u00e9duire les latences de r\u00e9seau et d'offrir une meilleure exp\u00e9rience utilisateur.</p>"},{"location":"_projects/_formation-azure/azure-chap03/#les-trois-modeles-de-service-cloud","title":"Les trois mod\u00e8les de service cloud","text":"<p>Azure propose trois mod\u00e8les principaux de service cloud, chacun offrant un niveau diff\u00e9rent de responsabilit\u00e9 et de contr\u00f4le[1][2][5].</p> <p>Infrastructure as a Service (IaaS) : Ce mod\u00e8le fournit les ressources informatiques de base comme les machines virtuelles, le stockage et la mise en r\u00e9seau. L'organisation conserve le contr\u00f4le sur le syst\u00e8me d'exploitation, les applications et les donn\u00e9es. Microsoft Azure propose des services IaaS comme les machines virtuelles Azure.</p> <p>Platform as a Service (PaaS) : Ce mod\u00e8le fournit une plateforme compl\u00e8te pour d\u00e9velopper, tester et d\u00e9ployer des applications. Microsoft g\u00e8re l'infrastructure sous-jacente, les syst\u00e8mes d'exploitation et les outils de d\u00e9veloppement. L'organisation se concentre sur le code et les donn\u00e9es[2].</p> <p>Software as a Service (SaaS) : Ce mod\u00e8le fournit des applications enti\u00e8rement g\u00e9r\u00e9es accessibles via un navigateur web. L'organisation n'a aucune responsabilit\u00e9 concernant l'infrastructure ou les mises \u00e0 jour du logiciel[2]. Gmail en est un exemple classique.</p>"},{"location":"_projects/_formation-azure/azure-chap03/#deploiement-multi-cloud-et-hybride","title":"D\u00e9ploiement multi-cloud et hybride","text":"<p>Au-del\u00e0 de ces trois mod\u00e8les de service, les organisations peuvent choisir diff\u00e9rents mod\u00e8les de d\u00e9ploiement :</p> <p>Cloud public : Les ressources sont partag\u00e9es entre plusieurs organisations. Azure, AWS et GCP sont des exemples de clouds publics[2]. Ce mod\u00e8le offre le meilleur rapport co\u00fbt-efficacit\u00e9 et la plus grande flexibilit\u00e9.</p> <p>Cloud priv\u00e9 : L'infrastructure cloud est d\u00e9di\u00e9e \u00e0 une seule organisation. Cela offre plus de contr\u00f4le et de s\u00e9curit\u00e9 mais n\u00e9cessite un investissement plus important.</p> <p>Cloud hybride : Les organisations utilisent une combinaison de ressources cloud publiques et priv\u00e9es, permettant de b\u00e9n\u00e9ficier des avantages des deux approches.</p>"},{"location":"_projects/_formation-azure/azure-chap03/#le-modele-de-responsabilite-partagee","title":"Le mod\u00e8le de responsabilit\u00e9 partag\u00e9e","text":""},{"location":"_projects/_formation-azure/azure-chap03/#fondamentaux-du-modele","title":"Fondamentaux du mod\u00e8le","text":"<p>Le mod\u00e8le de responsabilit\u00e9 partag\u00e9e est un concept fondamental pour comprendre la s\u00e9curit\u00e9 dans le cloud[2][3][5]. Ce mod\u00e8le \u00e9tablit clairement qui est responsable de la protection de diff\u00e9rents aspects de l'environnement cloud. Microsoft Azure repose sur cette approche : Microsoft s\u00e9curise l'infrastructure physique et les services cloud, tandis que la configuration des ressources, les acc\u00e8s et les donn\u00e9es rel\u00e8vent de la responsabilit\u00e9 du client[1][4].</p> <p>En termes simples, le fournisseur de services cloud (par exemple Azure) doit surveiller et neutraliser les menaces de s\u00e9curit\u00e9 li\u00e9es au cloud et \u00e0 son infrastructure sous-jacente. De leur c\u00f4t\u00e9, les utilisateurs finaux sont responsables de la protection des donn\u00e9es et des autres ressources qu'ils h\u00e9bergent dans cet environnement cloud[3].</p>"},{"location":"_projects/_formation-azure/azure-chap03/#repartition-des-responsabilites-par-type-de-deploiement","title":"R\u00e9partition des responsabilit\u00e9s par type de d\u00e9ploiement","text":"<p>La r\u00e9partition exacte des responsabilit\u00e9s varie consid\u00e9rablement en fonction du type de service choisi (IaaS, PaaS ou SaaS)[2][5].</p>"},{"location":"_projects/_formation-azure/azure-chap03/#pour-infrastructure-as-a-service-iaas","title":"Pour Infrastructure as a Service (IaaS)","text":"<p>Dans un mod\u00e8le IaaS, l'organisation assume davantage de responsabilit\u00e9s puisqu'elle contr\u00f4le le syst\u00e8me d'exploitation et les applications :</p> Responsabilit\u00e9s de Microsoft Azure Responsabilit\u00e9s de l'organisation Infrastructure physique et s\u00e9curit\u00e9 des datacenters S\u00e9curit\u00e9 des donn\u00e9es et informations R\u00e9seau physique Syst\u00e8mes d'exploitation et leurs correctifs Virtualisation et hyperviseurs Applications et leurs correctifs Serveurs et stockage physiques Contr\u00f4le d'acc\u00e8s et authentification Points de terminaison Comptes et identit\u00e9s"},{"location":"_projects/_formation-azure/azure-chap03/#pour-platform-as-a-service-paas","title":"Pour Platform as a Service (PaaS)","text":"<p>Dans un mod\u00e8le PaaS, les responsabilit\u00e9s sont partag\u00e9es de mani\u00e8re plus \u00e9quilibr\u00e9e[2]. Microsoft g\u00e8re davantage de composants, tandis que l'organisation se concentre sur l'application et les donn\u00e9es :</p> Responsabilit\u00e9s de Microsoft Azure Responsabilit\u00e9s partag\u00e9es Responsabilit\u00e9s de l'organisation Infrastructure physique Contr\u00f4le r\u00e9seau D\u00e9veloppement d'applications R\u00e9seau physique Identit\u00e9 et annuaire Donn\u00e9es h\u00e9berg\u00e9es Virtualisation Comptes autoris\u00e9s Syst\u00e8mes d'exploitation Points de terminaison Middleware Runtimes d'application"},{"location":"_projects/_formation-azure/azure-chap03/#pour-software-as-a-service-saas","title":"Pour Software as a Service (SaaS)","text":"<p>Dans un mod\u00e8le SaaS, l'organisation assume le minimum de responsabilit\u00e9s techniques[2]. Elle agit essentiellement comme utilisateur final :</p> Responsabilit\u00e9s de Microsoft Azure Responsabilit\u00e9s de l'organisation Toute l'infrastructure Donn\u00e9es et informations stock\u00e9es Toutes les applications Appareils autoris\u00e9s \u00e0 se connecter Maintenance et mises \u00e0 jour Comptes et identit\u00e9s autoris\u00e9s S\u00e9curit\u00e9 physique Permissions et acc\u00e8s"},{"location":"_projects/_formation-azure/azure-chap03/#responsabilites-permanentes-de-lorganisation","title":"Responsabilit\u00e9s permanentes de l'organisation","text":"<p>Ind\u00e9pendamment du type de d\u00e9ploiement choisi, l'organisation conserve toujours les responsabilit\u00e9s suivantes[5] :</p> <ul> <li>Donn\u00e9es : Protection et gestion des donn\u00e9es h\u00e9berg\u00e9es dans le cloud</li> <li>Points de terminaison : S\u00e9curit\u00e9 des appareils connectant au cloud</li> <li>Compte : Gestion des comptes utilisateurs et administrateurs</li> <li>Gestion de l'acc\u00e8s : Contr\u00f4le des acc\u00e8s et des permissions</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap03/#cas-pratique-la-migration-cloud","title":"Cas pratique : La migration cloud","text":"<p>Quand une organisation migre de datacenters locaux vers Azure, le mod\u00e8le de responsabilit\u00e9 partag\u00e9e facilite la r\u00e9allocation des ressources de s\u00e9curit\u00e9.</p> <p>Approche traditionnelle (on-premises) : L'organisation assume la responsabilit\u00e9 compl\u00e8te de la pile informatique, des serveurs physiques jusqu'aux applications.</p> <p>Approche cloud avec Azure : Microsoft assume les responsabilit\u00e9s li\u00e9es \u00e0 l'infrastructure physique et \u00e0 la maintenance des services cloud, permettant \u00e0 l'organisation de rediriger ses ressources vers des t\u00e2ches de plus haute valeur comme la gouvernance des donn\u00e9es, la conformit\u00e9 et l'optimisation des applications[5].</p>"},{"location":"_projects/_formation-azure/azure-chap03/#securite-des-donnees-et-conformite","title":"S\u00e9curit\u00e9 des donn\u00e9es et conformit\u00e9","text":"<p>Un point critique du mod\u00e8le de responsabilit\u00e9 partag\u00e9e concerne la s\u00e9curit\u00e9 des donn\u00e9es[3]. Puisque Microsoft n'a aucune visibilit\u00e9 sur les donn\u00e9es h\u00e9berg\u00e9es dans le cloud public, il ne peut pas g\u00e9rer leur s\u00e9curit\u00e9 ou leur acc\u00e8s. Par cons\u00e9quent, l'organisation conserve toujours la responsabilit\u00e9 de :</p> <ul> <li>Chiffrer les donn\u00e9es sensibles</li> <li>G\u00e9rer les cl\u00e9s de chiffrement</li> <li>Impl\u00e9menter les contr\u00f4les d'acc\u00e8s appropri\u00e9s</li> <li>Garantir la conformit\u00e9 r\u00e9glementaire (RGPD, HIPAA, etc.)</li> <li>Effectuer les audits de s\u00e9curit\u00e9</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap03/#outils-azure-pour-securiser-lenvironnement","title":"Outils Azure pour s\u00e9curiser l'environnement","text":"<p>Pour aider les organisations \u00e0 r\u00e9pondre \u00e0 leurs responsabilit\u00e9s, Azure fournit plusieurs outils[1] :</p> <p>Azure Security Center : Offre une vue centralis\u00e9e de la s\u00e9curit\u00e9 des ressources et des recommandations de s\u00e9curit\u00e9.</p> <p>Azure Active Directory : G\u00e8re l'authentification et l'autorisation des utilisateurs acc\u00e9dant aux ressources cloud.</p> <p>Azure Security and Compliance : Fournit des outils pour \u00e9valuer et d\u00e9montrer la conformit\u00e9 r\u00e9glementaire.</p>"},{"location":"_projects/_formation-azure/azure-chap03/#le-modele-base-sur-la-consommation","title":"Le mod\u00e8le bas\u00e9 sur la consommation","text":""},{"location":"_projects/_formation-azure/azure-chap03/#principes-du-modele-de-consommation","title":"Principes du mod\u00e8le de consommation","text":"<p>Le mod\u00e8le bas\u00e9 sur la consommation repr\u00e9sente un changement majeur par rapport aux mod\u00e8les informatiques traditionnels. Plut\u00f4t que d'acheter et de maintenir du mat\u00e9riel co\u00fbteux qu'il faudra amortir sur plusieurs ann\u00e9es, les organisations paient uniquement pour les ressources qu'elles consomment r\u00e9ellement.</p> <p>Paiement \u00e0 l'utilisation : Contrairement aux mod\u00e8les on-premises o\u00f9 les investissements initiaux en \u00e9quipement sont importants, le cloud propose un mod\u00e8le o\u00f9 le co\u00fbt est directement proportionnel \u00e0 l'utilisation r\u00e9elle des ressources.</p> <p>Absence de capex \u00e9lev\u00e9 : Les organisations n'ont pas besoin d'investir dans du mat\u00e9riel co\u00fbteux avant de commencer. Cela r\u00e9duit consid\u00e9rablement les barri\u00e8res d'entr\u00e9e et permet aux entreprises de toutes tailles d'acc\u00e9der \u00e0 une infrastructure de classe mondiale.</p> <p>Flexibilit\u00e9 budg\u00e9taire : Le mod\u00e8le de consommation permet une meilleure pr\u00e9dictibilit\u00e9 des co\u00fbts op\u00e9rationnels. Les d\u00e9penses deviennent des co\u00fbts variables plut\u00f4t que fixes, permettant une gestion budg\u00e9taire plus agile.</p>"},{"location":"_projects/_formation-azure/azure-chap03/#comparaison-modele-traditionnel-vs-modele-cloud","title":"Comparaison : Mod\u00e8le traditionnel vs. Mod\u00e8le cloud","text":"Aspect Infrastructure traditionnelle Infrastructure cloud Investissement initial Tr\u00e8s \u00e9lev\u00e9 (capex) Minimal Co\u00fbts op\u00e9rationnels Stables et pr\u00e9visibles Variables selon utilisation (opex) Allocation de ressources Rigide, difficile \u00e0 ajuster Flexible et instantan\u00e9e D\u00e9lai de d\u00e9ploiement Semaines \u00e0 mois Minutes \u00e0 heures Capacit\u00e9 inutilis\u00e9e Souvent importante Minimale Scalabilit\u00e9 Limit\u00e9e et on\u00e9reuse Illimit\u00e9e et rentable Maintenance mat\u00e9rielle N\u00e9cessaire et co\u00fbteuse Enti\u00e8rement g\u00e9r\u00e9e par le fournisseur"},{"location":"_projects/_formation-azure/azure-chap03/#metriques-de-consommation-dans-azure","title":"M\u00e9triques de consommation dans Azure","text":"<p>Azure propose un syst\u00e8me granulaire de facturation bas\u00e9 sur plusieurs m\u00e9triques :</p> <p>Calcul : Les machines virtuelles sont factur\u00e9es \u00e0 la minute en fonction du type d'instance et du syst\u00e8me d'exploitation choisi. Par exemple, une machine virtuelle Standard_D2s_v3 sur Windows Server co\u00fbte diff\u00e9remment selon la r\u00e9gion et la dur\u00e9e d'utilisation.</p> <p>Stockage : Les services de stockage (blobs, files, tables) sont factur\u00e9s selon la quantit\u00e9 de donn\u00e9es stock\u00e9es et le nombre de transactions effectu\u00e9es. Le stockage chaud (fr\u00e9quemment acc\u00e9d\u00e9) co\u00fbte plus cher que le stockage froid (rarement acc\u00e9d\u00e9).</p> <p>Bande passante r\u00e9seau : Le transfert de donn\u00e9es entrant est g\u00e9n\u00e9ralement gratuit, tandis que le transfert sortant est factur\u00e9. Les transferts entre services Azure dans la m\u00eame r\u00e9gion peuvent \u00eatre gratuits.</p> <p>Services g\u00e9r\u00e9s : Les bases de donn\u00e9es, les services d'application et autres services g\u00e9r\u00e9s sont factur\u00e9s selon leurs m\u00e9triques sp\u00e9cifiques (par exemple, nombre de transactions pour SQL Database).</p>"},{"location":"_projects/_formation-azure/azure-chap03/#optimisation-des-couts","title":"Optimisation des co\u00fbts","text":"<p>Reserved Instances : Azure permet de r\u00e9server des ressources pour 1 ou 3 ans, offrant des r\u00e9ductions de 30 \u00e0 70% par rapport aux tarifs \u00e0 la demande. Cette option convient aux charges de travail pr\u00e9visibles et stables.</p> <p>Spot VMs : Les machines virtuelles Spot utilisent la capacit\u00e9 inutilis\u00e9e d'Azure \u00e0 un co\u00fbt 60 \u00e0 90% moins cher que les tarifs standards. Celles-ci conviennent aux charges de travail flexibles pouvant tol\u00e9rer les interruptions.</p> <p>Auto-scaling : L'ajustement automatique des ressources selon la demande garantit que l'organisation paye uniquement pour ce dont elle a besoin \u00e0 tout moment.</p> <p>Arr\u00eat des ressources inutilis\u00e9es : Dans un mod\u00e8le cloud, arr\u00eater une ressource non utilis\u00e9e r\u00e9duit imm\u00e9diatement les co\u00fbts, contrairement aux infrastructures on-premises o\u00f9 les co\u00fbts restent identiques.</p>"},{"location":"_projects/_formation-azure/azure-chap03/#exemple-pratique-scenario-e-commerce","title":"Exemple pratique : Sc\u00e9nario e-commerce","text":"<p>Consid\u00e9rons un site e-commerce ayant des pics de trafic pr\u00e9visibles (p\u00e9riodes de soldes, vacances) :</p> <p>P\u00e9riode creuse : L'organisation ex\u00e9cute 5 machines virtuelles de base pour g\u00e9rer le trafic normal. Co\u00fbt estim\u00e9 : 1 000\u20ac/mois.</p> <p>P\u00e9riode de pic : Lors des soldes, le trafic augmente 10 fois. L'auto-scaling d\u00e9ploie automatiquement 50 machines virtuelles suppl\u00e9mentaires pour quelques jours. Co\u00fbt additionnel : 2 000\u20ac pour ces 3 jours de pic.</p> <p>Total mensuel : Au lieu de payer 5 000\u20ac/mois pour 50 machines virtuelles pendant 12 mois (approche on-premises), l'organisation paie approximativement 1 000\u20ac \u00d7 11 mois + 3 000\u20ac \u00d7 1 mois = 14 000\u20ac/an, soit 1 167\u20ac/mois en moyenne.</p>"},{"location":"_projects/_formation-azure/azure-chap03/#autres-avantages-du-cloud","title":"Autres avantages du cloud","text":""},{"location":"_projects/_formation-azure/azure-chap03/#haute-disponibilite-et-fiabilite","title":"Haute disponibilit\u00e9 et fiabilit\u00e9","text":"<p>Redondance g\u00e9ographique : Azure op\u00e8re des datacenters dans plus de 60 r\u00e9gions \u00e0 travers le monde. Les organisations peuvent r\u00e9pliquer leurs ressources dans plusieurs r\u00e9gions pour assurer la continuit\u00e9 de service m\u00eame en cas de d\u00e9faillance r\u00e9gionale.</p> <p>Groupes \u00e0 haute disponibilit\u00e9 : Au sein d'une m\u00eame r\u00e9gion, les ressources peuvent \u00eatre distribu\u00e9es dans plusieurs domaines de d\u00e9faillance, garantissant que m\u00eame la perte d'un serveur physique ou d'une baie \u00e9lectrique n'interrompt pas le service.</p> <p>Accord de niveau de service (SLA) : Azure garantit une disponibilit\u00e9 de 99,99% pour de nombreux services, ce qui correspond \u00e0 un temps d'arr\u00eat maximum de 4,38 minutes par mois.</p>"},{"location":"_projects/_formation-azure/azure-chap03/#performance-et-optimisation","title":"Performance et optimisation","text":"<p>Mise en cache globale : Azure Content Delivery Network (CDN) distribue le contenu \u00e0 partir de serveurs situ\u00e9s pr\u00e8s des utilisateurs finaux, r\u00e9duisant la latence et am\u00e9liorant les performances.</p> <p>Optimisation automatique : Les services g\u00e9r\u00e9s d'Azure s'optimisent automatiquement en fonction des patterns d'utilisation. Par exemple, SQL Database ajuste automatiquement les ressources et les indices pour optimiser les performances des requ\u00eates.</p> <p>Acc\u00e9l\u00e9ration mat\u00e9rielle : Azure propose des instances de machine virtuelle avec acc\u00e9l\u00e9ration GPU ou FPGA pour les charges de travail n\u00e9cessitant une puissance de calcul intensif.</p>"},{"location":"_projects/_formation-azure/azure-chap03/#securite-renforcee","title":"S\u00e9curit\u00e9 renforc\u00e9e","text":"<p>Chiffrement par d\u00e9faut : Les donn\u00e9es transitant vers et depuis Azure sont chiffr\u00e9es. Le stockage des donn\u00e9es peut \u00e9galement \u00eatre chiffr\u00e9 par d\u00e9faut.</p> <p>Isolation des locataires : Dans un environnement multi-locataire, Azure garantit une isolation compl\u00e8te entre les donn\u00e9es de diff\u00e9rents clients, au niveau du mat\u00e9riel et du logiciel.</p> <p>Authentification multi-facteurs : Azure Active Directory supporte l'authentification multi-facteurs (MFA), r\u00e9duisant significativement les risques de compromission de compte.</p> <p>Audits et certifications : Azure est certifi\u00e9 conform\u00e9ment \u00e0 de nombreux standards de s\u00e9curit\u00e9 internationaux (ISO 27001, SOC 2, etc.) et fournit des rapports d'audit d\u00e9taill\u00e9s.</p>"},{"location":"_projects/_formation-azure/azure-chap03/#innovation-et-mise-a-jour-continue","title":"Innovation et mise \u00e0 jour continue","text":"<p>Services en pr\u00e9version : Azure propose r\u00e9guli\u00e8rement de nouveaux services et fonctionnalit\u00e9s en pr\u00e9version, permettant aux organisations de tester les derni\u00e8res technologies sans attendre les versions stables.</p> <p>Mises \u00e0 jour automatiques : Les services g\u00e9r\u00e9s re\u00e7oivent automatiquement les mises \u00e0 jour de s\u00e9curit\u00e9 et les corrections de bogues sans intervention manuelle n\u00e9cessaire.</p> <p>Investissement R&amp;D : Microsoft investit massivement dans la recherche et d\u00e9veloppement, garantissant que Azure propose les technologies les plus avanc\u00e9es (intelligence artificielle, machine learning, quantique, etc.).</p>"},{"location":"_projects/_formation-azure/azure-chap03/#durabilite-et-responsabilite-ecologique","title":"Durabilit\u00e9 et responsabilit\u00e9 \u00e9cologique","text":"<p>Efficacit\u00e9 \u00e9nerg\u00e9tique : Les datacenters Azure utilisent 1,67 fois moins d'\u00e9nergie que les datacenters on-premises typiques, selon Microsoft.</p> <p>\u00c9nergies renouvelables : Microsoft s'engage \u00e0 utiliser uniquement de l'\u00e9lectricit\u00e9 de sources renouvelables pour tous les datacenters Azure d'ici 2025.</p> <p>R\u00e9duction des \u00e9missions carbone : En consolidant les charges de travail de nombreuses organisations sur une infrastructure partag\u00e9e, Azure r\u00e9duit consid\u00e9rablement l'empreinte carbone par rapport aux infrastructures individuelles.</p>"},{"location":"_projects/_formation-azure/azure-chap03/#conformite-reglementaire-facilitee","title":"Conformit\u00e9 r\u00e9glementaire facilit\u00e9e","text":"<p>Conformit\u00e9 RGPD : Azure offre des outils et des processus pour aider les organisations \u00e0 se conformer au R\u00e8glement g\u00e9n\u00e9ral sur la protection des donn\u00e9es, incluant le droit \u00e0 l'oubli et la portabilit\u00e9 des donn\u00e9es.</p> <p>Conformit\u00e9 HIPAA : Les organisations du secteur de la sant\u00e9 peuvent utiliser les services Azure HIPAA-compliant pour stocker et traiter les donn\u00e9es de sant\u00e9 prot\u00e9g\u00e9es.</p> <p>Conformit\u00e9 FedRAMP et DoD : Le gouvernement am\u00e9ricain peut utiliser Azure Government, une instance d'Azure conform\u00e9ment aux exigences f\u00e9d\u00e9rales strictes.</p> <p>Audits et certifications : Azure fournit des rapports d'audit r\u00e9guliers et maintient les certifications aupr\u00e8s de multiples organismes de normalisation.</p>"},{"location":"_projects/_formation-azure/azure-chap03/#collaboration-et-productivite-ameliorees","title":"Collaboration et productivit\u00e9 am\u00e9lior\u00e9es","text":"<p>Acc\u00e8s mondial : Les \u00e9quipes distribu\u00e9es peuvent acc\u00e9der aux m\u00eames ressources et donn\u00e9es de n'importe o\u00f9, am\u00e9liorant la collaboration et la productivit\u00e9.</p> <p>Synchronisation des donn\u00e9es : Azure sync services garantissent que les donn\u00e9es sont toujours coh\u00e9rentes entre les appareils et les localisations.</p> <p>Int\u00e9gration Microsoft : Azure s'int\u00e8gre nativement avec Microsoft 365, SharePoint, Teams et d'autres outils de productivit\u00e9 populaires, cr\u00e9ant un \u00e9cosyst\u00e8me coh\u00e9rent.</p>"},{"location":"_projects/_formation-azure/azure-chap03/#avantages-pour-les-developpeurs","title":"Avantages pour les d\u00e9veloppeurs","text":"<p>Outils de d\u00e9veloppement int\u00e9gr\u00e9s : Visual Studio et Visual Studio Code offrent une int\u00e9gration native avec Azure, permettant le d\u00e9ploiement et le d\u00e9bogage directs depuis l'IDE.</p> <p>Multiples langages et frameworks : Azure supporte tous les langages populaires (C#, Python, Java, Node.js, Go, etc.) et les frameworks (ASP.NET, Django, Spring, Express.js, etc.).</p> <p>Services d'IA et machine learning : Azure Cognitive Services fournit des APIs pr\u00e9construites pour la vision par ordinateur, le traitement du langage naturel, la traduction, et bien d'autres capacit\u00e9s d'IA sans n\u00e9cessiter expertise approfondie en ML.</p>"},{"location":"_projects/_formation-azure/azure-chap03/#chemin-dapprentissage-detaille","title":"Chemin d'apprentissage d\u00e9taill\u00e9","text":""},{"location":"_projects/_formation-azure/azure-chap03/#phase-1-comprehension-theorique-des-concepts","title":"Phase 1 : Compr\u00e9hension th\u00e9orique des concepts","text":"<p>Semaine 1-2 : Les fondamentaux du cloud</p> <p>L'apprenant commence par comprendre les concepts abstraits du cloud computing. Les trois mod\u00e8les de service (IaaS, PaaS, SaaS) doivent \u00eatre ma\u00eetris\u00e9s, non seulement th\u00e9oriquement mais aussi dans leurs implications pratiques. Par exemple, comprendre pourquoi SaaS impose moins de responsabilit\u00e9s t\u00e9chniques mais plus de contraintes li\u00e9es aux donn\u00e9es.</p> <p>Les trois mod\u00e8les de d\u00e9ploiement (public, priv\u00e9, hybride) doivent \u00eatre clarifi\u00e9s, en particulier les compromis entre co\u00fbt, contr\u00f4le et performance.</p> <p>Semaine 3-4 : Le mod\u00e8le de responsabilit\u00e9 partag\u00e9e</p> <p>Cette partie rev\u00eat une importance critique. L'apprenant doit internaliser que la s\u00e9curit\u00e9 dans le cloud n'est jamais la responsabilit\u00e9 exclusive du fournisseur ni de l'organisation, mais toujours des deux. Les tableaux de r\u00e9partition des responsabilit\u00e9s par type de service doivent \u00eatre consult\u00e9s r\u00e9guli\u00e8rement jusqu'\u00e0 ce qu'ils deviennent intuitifs.</p> <p>Des \u00e9tudes de cas pratiques aident \u00e0 concr\u00e9tiser ces concepts abstraits. Par exemple, si une organisation choisit une machine virtuelle IaaS, elle assume la responsabilit\u00e9 des correctifs du syst\u00e8me d'exploitation, tandis qu'Azure g\u00e8re l'hyperviseur. Ce partage des responsabilit\u00e9s doit \u00eatre clairement compris.</p> <p>Semaine 5-6 : Le mod\u00e8le bas\u00e9 sur la consommation</p> <p>L'apprenant explore comment le cloud change radicalement le mod\u00e8le financier informatique. Au lieu de d\u00e9penses en capital (capex) importantes et pr\u00e9visibles, le cloud propose des d\u00e9penses op\u00e9rationnelles (opex) variables. Cette distinction change fondamentalement la gestion budg\u00e9taire.</p> <p>Des calculs comparatifs entre les mod\u00e8les on-premises et cloud concrets aident \u00e0 d\u00e9montrer les \u00e9conomies potentielles. L'apprenant doit comprendre comment l'auto-scaling permet de r\u00e9duire les co\u00fbts en adaptant les ressources \u00e0 la demande r\u00e9elle.</p>"},{"location":"_projects/_formation-azure/azure-chap03/#phase-2-application-pratique-et-projets-pilots","title":"Phase 2 : Application pratique et projets pilots","text":"<p>Semaine 7-8 : Premiers d\u00e9ploiements</p> <p>L'apprenant commence \u00e0 cr\u00e9er des ressources Azure simples, d'abord une machine virtuelle dans un mod\u00e8le IaaS. L'objectif n'est pas l'efficacit\u00e9 mais la compr\u00e9hension des concepts. En d\u00e9ployant une VM Windows et une application web basique, l'apprenant apprend concr\u00e8tement quelles sont ses responsabilit\u00e9s (OS patching, firewall, donn\u00e9es) et celles d'Azure (infrastructure physique, hyperviseur).</p> <p>Ensuite, un d\u00e9ploiement PaaS avec Azure App Service fournit un contraste saisissant. Soudainement, de nombreuses responsabilit\u00e9s disparaissent, mais le contr\u00f4le sur l'environnement d'ex\u00e9cution est r\u00e9duit.</p> <p>Semaine 9-10 : S\u00e9curit\u00e9 et conformit\u00e9</p> <p>L'apprenant explore les outils Azure Security Center et Azure Policy pour impl\u00e9menter la s\u00e9curit\u00e9. Cr\u00e9er des Azure Security Alerts et comprendre les recommandations de s\u00e9curit\u00e9 aide \u00e0 internaliser les responsabilit\u00e9s de s\u00e9curit\u00e9.</p> <p>La configuration d'Azure Active Directory et l'impl\u00e9mentation de l'authentification multi-facteurs fournissent une exp\u00e9rience pratique des contr\u00f4les d'acc\u00e8s pour lesquels l'organisation reste responsable.</p> <p>Semaine 11-12 : Gestion des co\u00fbts</p> <p>L'apprenant utilise Azure Cost Management + Billing pour analyser les d\u00e9penses r\u00e9elles de ses d\u00e9ploiements pilots. La cr\u00e9ation d'alertes budg\u00e9taires et l'exploration des Reserved Instances aident \u00e0 comprendre comment optimiser les co\u00fbts dans un mod\u00e8le bas\u00e9 sur la consommation.</p>"},{"location":"_projects/_formation-azure/azure-chap03/#phase-3-maitrise-avancee","title":"Phase 3 : Ma\u00eetrise avanc\u00e9e","text":"<p>Semaine 13-16 : Conception d'architecture cloud</p> <p>Avec les concepts fondamentaux ma\u00eetris\u00e9s, l'apprenant progresse vers la conception d'architectures r\u00e9alistes. Cr\u00e9er une architecture multi-couches utilisant plusieurs services Azure (VMs, App Services, SQL Database, Storage) force \u00e0 appliquer le mod\u00e8le de responsabilit\u00e9 partag\u00e9e \u00e0 des sc\u00e9narios complexes.</p> <p>La conception d'une architecture haute disponibilit\u00e9 exige de comprendre la r\u00e9plication, les groupes de disponibilit\u00e9 et les strat\u00e9gies de basculement. Le mod\u00e8le de consommation est appliqu\u00e9 en optimisant cette architecture pour r\u00e9duire les co\u00fbts tout en maintenant les SLA requis.</p> <p>Semaine 17-20 : Cas d'usage professionnels</p> <p>L'apprenant s'engage dans des projets mimant des sc\u00e9narios professionnels. Migration d'une application on-premises vers Azure, mise en \u0153uvre d'une strat\u00e9gie de disaster recovery, ou d\u00e9ploiement d'une solution SaaS pour un sc\u00e9nario multi-locataire.</p> <p>Chaque projet renforce la compr\u00e9hension int\u00e9gr\u00e9e des trois concepts cl\u00e9s : la nature multi-mod\u00e8le du cloud, la responsabilit\u00e9 partag\u00e9e, et la consommation bas\u00e9e sur l'utilisation.</p>"},{"location":"_projects/_formation-azure/azure-chap03/#ressources-dapprentissage-recommandees","title":"Ressources d'apprentissage recommand\u00e9es","text":"<p>L'apprenant consultant r\u00e9guli\u00e8rement la documentation officielle Microsoft Learn progresse de fa\u00e7on syst\u00e9matique. Les parcours d'apprentissage structur\u00e9s fournissent une progression logique plut\u00f4t que de sauter entre des sujets disparates.</p> <p>Les vid\u00e9os explicatives pour visualiser les architectures cloud compl\u00e8tent l'apprentissage textuel. Les exercices pratiques gratuits sur Azure permettent d'exp\u00e9rimenter sans co\u00fbts significatifs gr\u00e2ce aux cr\u00e9dits d'essai gratuits d'Azure.</p>"},{"location":"_projects/_formation-azure/azure-chap03/#synthese-linterconnexion-des-concepts","title":"Synth\u00e8se : L'interconnexion des concepts","text":""},{"location":"_projects/_formation-azure/azure-chap03/#vue-holistique","title":"Vue holistique","text":"<p>Les trois piliers du cloud computing pr\u00e9sent\u00e9s dans ce chapitre ne peuvent \u00eatre vraiment compris que dans leur interconnexion :</p> <p>Le mod\u00e8le multi-service (IaaS/PaaS/SaaS) d\u00e9finit le spectre des capacit\u00e9s disponibles. Chaque mod\u00e8le offre diff\u00e9rents niveaux de commodit\u00e9 et de contr\u00f4le.</p> <p>La responsabilit\u00e9 partag\u00e9e \u00e9tablit les r\u00e8gles du jeu : qui est responsable de quoi. Sans ce mod\u00e8le, l'ambigu\u00eft\u00e9 cr\u00e9erait des failles de s\u00e9curit\u00e9. Avec lui, chaque partie comprend ses obligations.</p> <p>La consommation bas\u00e9e sur l'utilisation rend le cloud \u00e9conomiquement viable pour les organisations de toutes tailles. Elle \u00e9limine les barri\u00e8res d'entr\u00e9e tout en punissant l'inefficacit\u00e9.</p>"},{"location":"_projects/_formation-azure/azure-chap03/#application-pratique-integree","title":"Application pratique int\u00e9gr\u00e9e","text":"<p>Un sc\u00e9nario concret illustre cette interconnexion : une startup d\u00e9veloppe une application web. Elle choisit Azure App Service (PaaS) pour la simplicit\u00e9 et l'\u00e9conomie. Azure g\u00e8re l'infrastructure, les syst\u00e8mes d'exploitation et le runtime. La startup se concentre sur le code. Pour la base de donn\u00e9es, elle utilise Azure SQL Database (PaaS g\u00e9r\u00e9). Pour les fichiers utilisateurs, Azure Blob Storage (Infrastructure).</p> <p>La responsabilit\u00e9 partag\u00e9e clarifi\u00e9e : Azure chiffre les donn\u00e9es en transit et au repos par d\u00e9faut. La startup impl\u00e9menter les contr\u00f4les d'acc\u00e8s via Azure Active Directory. Les deux parties travaillent ensemble pour la s\u00e9curit\u00e9.</p> <p>Le mod\u00e8le de consommation en action : lors du lancement, la startup paie peu. Pendant les pics de charge, l'auto-scaling d'App Service augmente automatiquement les ressources. La facturation augmente proportionnellement. Aucun achat de serveur initial n'\u00e9tait n\u00e9cessaire.</p> <p>Cette int\u00e9gration naturelle des trois concepts d\u00e9montre pourquoi le cloud a r\u00e9volutionn\u00e9 l'informatique d'entreprise.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure/azure-chap04/","title":"Citations","text":"<ul> <li>https://www.datacamp.com/fr/blog/how-to-learn-azure</li> <li>https://www.youtube.com/watch?v=Qgt28QttqoI</li> <li>https://learn.microsoft.com/fr-fr/azure/storage/common/storage-account-create</li> <li>https://learn.microsoft.com/fr-fr/azure/automation/automation-create-standalone-account</li> <li>https://learn.microsoft.com/fr-fr/dotnet/azure/create-azure-account</li> <li>https://azure.microsoft.com/fr-fr/pricing/purchase-options/azure-account</li> <li>https://azure.microsoft.com/fr-fr/get-started</li> <li>https://www.editions-eni.fr/livre/debuter-et-se-perfectionner-avec-azure-concepts-fondamentaux-et-mise-en-uvre-2e-edition-9782409050572/premiere-connexion</li> <li>https://www.youtube.com/watch?v=88kKOaYMAzE</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap04/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 269</li> <li>completion_tokens: 7667</li> <li>total_tokens: 7936</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.115, 'request_cost': 0.006, 'total_cost': 0.122}</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap04/#content","title":"Content","text":""},{"location":"_projects/_formation-azure/azure-chap04/#chapitre-4-principaux-composants-dazure","title":"Chapitre 4 : Principaux composants d'Azure","text":""},{"location":"_projects/_formation-azure/azure-chap04/#1-creer-un-compte-azure","title":"1. Cr\u00e9er un compte Azure","text":""},{"location":"_projects/_formation-azure/azure-chap04/#presentation-generale","title":"Pr\u00e9sentation g\u00e9n\u00e9rale","text":"<p>La cr\u00e9ation d'un compte Azure constitue l'\u00e9tape fondamentale pour acc\u00e9der \u00e0 l'\u00e9cosyst\u00e8me cloud de Microsoft. Un compte Azure repr\u00e9sente l'identit\u00e9 num\u00e9rique permettant d'acc\u00e9der aux services cloud, de g\u00e9rer les ressources et de contr\u00f4ler les co\u00fbts associ\u00e9s \u00e0 l'utilisation des services. Ce compte s'articule autour d'une adresse email Microsoft qui sert de point d'authentification unique pour tous les services Azure[1].</p>"},{"location":"_projects/_formation-azure/azure-chap04/#options-de-creation-de-compte","title":"Options de cr\u00e9ation de compte","text":"<p>Plusieurs chemins d'acc\u00e8s existent pour d\u00e9buter avec Azure, adapt\u00e9s \u00e0 diff\u00e9rents profils d'utilisateurs :</p> <p>Option 1 : Compte Azure gratuit</p> <p>L'option gratuite offre un acc\u00e8s complet \u00e0 Azure sur une p\u00e9riode limit\u00e9e[5]. Cette formule inclut : - 12 mois de services gratuits (comme les machines virtuelles de petite taille, les bases de donn\u00e9es SQL et le stockage) - Un cr\u00e9dit de 200 $ valable 30 jours pour explorer d'autres services - Aucune carte de cr\u00e9dit requise initialement, bien qu'une v\u00e9rification par carte bancaire soit n\u00e9cessaire pour confirmer l'identit\u00e9 et \u00e9viter les abus</p> <p>Option 2 : Compte avec paiement \u00e0 l'utilisation</p> <p>Cette approche convient aux utilisateurs souhaitant d\u00e9ployer imm\u00e9diatement des services en production[5]. Elle propose : - Des services s\u00e9lectionn\u00e9s gratuits chaque mois dans les limites sp\u00e9cifi\u00e9es - Une facturation uniquement pour les ressources consomm\u00e9es au-del\u00e0 des seuils gratuits - Aucun engagement initial et possibilit\u00e9 d'annulation \u00e0 tout moment</p> <p>Option 3 : Cr\u00e9dits Visual Studio</p> <p>Les abonn\u00e9s Visual Studio b\u00e9n\u00e9ficient de cr\u00e9dits Azure mensuels inclus dans leur abonnement[5], offrant un avantage financier significatif pour les d\u00e9veloppeurs.</p> <p>Option 4 : Compte d'entreprise</p> <p>Les organisations ayant une relation directe avec Microsoft acc\u00e8dent \u00e0 des comptes Azure g\u00e9r\u00e9s par leur administrateur cloud, int\u00e9grant des structures de facturation centralis\u00e9es et des contr\u00f4les de s\u00e9curit\u00e9 renforc\u00e9s.</p>"},{"location":"_projects/_formation-azure/azure-chap04/#processus-de-creation-detaille","title":"Processus de cr\u00e9ation d\u00e9taill\u00e9","text":"<p>\u00c9tape 1 : Acc\u00e8s \u00e0 la plateforme d'inscription</p> <p>L'utilisateur se rend sur le portail d'inscription Azure gratuit. La premi\u00e8re action consiste \u00e0 s\u00e9lectionner le lien \"D\u00e9marrer gratuitement\" ou \"Start Free\"[2]. \u00c0 ce stade, une d\u00e9cision s'impose : disposer d'un compte Microsoft existant ou en cr\u00e9er un nouveau. Si aucun compte n'existe, le bouton \"create one\" permet de lancer la proc\u00e9dure de cr\u00e9ation simultan\u00e9e.</p> <p>\u00c9tape 2 : Cr\u00e9ation du compte Microsoft (si n\u00e9cessaire)</p> <p>Pour les nouveaux utilisateurs, la cr\u00e9ation du compte Microsoft pr\u00e9c\u00e8de l'acc\u00e8s \u00e0 Azure[2]. Le processus suit cette progression : - Saisie de l'adresse email destin\u00e9e au compte - Clic sur le bouton \"Next\" - Entr\u00e9e du mot de passe s\u00e9curis\u00e9 - Validation du mot de passe avec un nouveau clic sur \"Next\" - S\u00e9lection du pays de r\u00e9sidence - Indication de la date de naissance pour v\u00e9rification de majorit\u00e9 - R\u00e9solution du CAPTCHA pour confirmer qu'il ne s'agit pas d'un robot</p> <p>\u00c9tape 3 : Fourniture des informations d'identit\u00e9</p> <p>Une fois le compte Microsoft cr\u00e9\u00e9, Azure demande les informations personnelles compl\u00e8tes[2] : - Nom complet - Num\u00e9ro de t\u00e9l\u00e9phone - Adresse postale - Code postal et ville</p> <p>\u00c9tape 4 : V\u00e9rification par carte bancaire</p> <p>L'\u00e9tape critique de v\u00e9rification implique l'entr\u00e9e des informations de carte de cr\u00e9dit ou de d\u00e9bit[2]. Cette v\u00e9rification ne d\u00e9bite pas le compte mais confirme simplement l'identit\u00e9 de l'utilisateur et pr\u00e9vient la cr\u00e9ation en masse de comptes frauduleux. Les informations sont trait\u00e9es de mani\u00e8re s\u00e9curis\u00e9e par les syst\u00e8mes de paiement de Microsoft.</p> <p>\u00c9tape 5 : Acc\u00e8s au portail Azure</p> <p>Une fois toutes les \u00e9tapes valid\u00e9es, un message de confirmation s'affiche avec un bouton \"Go to Azure Portal\" ou \"Aller au portail Azure\"[2]. En cliquant sur ce bouton, l'utilisateur acc\u00e8de au tableau de bord principal d'Azure, marquant ainsi la r\u00e9ussite compl\u00e8te de l'inscription.</p>"},{"location":"_projects/_formation-azure/azure-chap04/#recommandations-pour-linscription","title":"Recommandations pour l'inscription","text":"<p>Lors de la cr\u00e9ation d'un compte Azure, il est conseill\u00e9 de cr\u00e9er une adresse email d\u00e9di\u00e9e sp\u00e9cifiquement \u00e0 Azure plut\u00f4t que d'utiliser une adresse personnelle existante[8]. Cette pratique offre une meilleure s\u00e9paration des domaines d'utilisation et facilite la gestion des notifications et des communications li\u00e9es aux services cloud.</p>"},{"location":"_projects/_formation-azure/azure-chap04/#2-linterface-azure","title":"2. L'interface Azure","text":""},{"location":"_projects/_formation-azure/azure-chap04/#structure-generale-du-portail","title":"Structure g\u00e9n\u00e9rale du portail","text":"<p>Le portail Azure (accessible sur portal.azure.com) constitue l'interface web graphique centralis\u00e9e pour g\u00e9rer toutes les ressources cloud[1]. Cette interface web-responsive s'adapte \u00e0 diff\u00e9rentes r\u00e9solutions d'\u00e9cran et offre une exp\u00e9rience utilisateur coh\u00e9rente sur desktop, tablette et mobile.</p>"},{"location":"_projects/_formation-azure/azure-chap04/#composants-principaux-de-linterface","title":"Composants principaux de l'interface","text":"<p>Barre sup\u00e9rieure et menu de navigation</p> <p>La barre sup\u00e9rieure du portail Azure contient plusieurs \u00e9l\u00e9ments critiques : - Le logo Microsoft Azure \u00e0 gauche - Une barre de recherche centrale permettant de localiser rapidement des ressources, des services ou de la documentation - Des ic\u00f4nes de param\u00e8tres et de notifications \u00e0 droite - L'identifiant utilisateur avec un menu d\u00e9roulant pour g\u00e9rer le profil et les param\u00e8tres de compte</p> <p>Panneau de gauche (panneau de navigation)</p> <p>Le panneau situ\u00e9 sur le c\u00f4t\u00e9 gauche du portail offre une navigation structur\u00e9e[1]. Il contient : - L'option \"Accueil\" ramenant au tableau de bord principal - \"Tous les services\" donnant acc\u00e8s \u00e0 l'int\u00e9gralit\u00e9 du catalogue Azure - Les ressources r\u00e9cemment consult\u00e9es pour un acc\u00e8s rapide - Les favoris personnalis\u00e9s permettant de cr\u00e9er des raccourcis</p> <p>Zone centrale (espace de travail)</p> <p>La zone centrale affiche le contenu dynamique en fonction de la s\u00e9lection effectu\u00e9e. Elle pr\u00e9sente : - Les ressources disponibles avec leurs propri\u00e9t\u00e9s - Les formulaires de cr\u00e9ation ou de modification - Les tableaux de bord personnalisables - Les param\u00e8tres de configuration des services</p>"},{"location":"_projects/_formation-azure/azure-chap04/#flux-de-travail-standard-dans-le-portail","title":"Flux de travail standard dans le portail","text":"<p>Recherche et d\u00e9couverte de services</p> <p>La recherche constitue le m\u00e9canisme principal de navigation. En tapant le nom d'un service (par exemple \"Virtual Machines\" ou \"SQL Database\"), le moteur de recherche retourne les services correspondants avec un acc\u00e8s direct ou des suggestions de documentation.</p> <p>Cr\u00e9ation de ressources</p> <p>Le processus de cr\u00e9ation suit un pattern standardis\u00e9 dans Azure[3][4] : 1. Navigation vers le service ou clic sur \"+ Cr\u00e9er une ressource\" 2. S\u00e9lection du type de ressource \u00e0 cr\u00e9er 3. Affichage du formulaire \"Informations de base\" (Basic tab) contenant les param\u00e8tres obligatoires 4. Remplissage des champs essentiels (abonnement, groupe de ressources, r\u00e9gion) 5. Navigation optionnelle vers les onglets suppl\u00e9mentaires pour configuration avanc\u00e9e 6. Acc\u00e8s \u00e0 l'onglet \"V\u00e9rifier + cr\u00e9er\" (Review + Create tab) 7. Validation automatique par Azure des param\u00e8tres choisis 8. D\u00e9ploiement de la ressource en cas de validation r\u00e9ussie</p>"},{"location":"_projects/_formation-azure/azure-chap04/#onglets-de-configuration-standardises","title":"Onglets de configuration standardis\u00e9s","text":"Tab Fonction Contenu typique Informations de base Configuration initiale Abonnement, groupe de ressources, nom, r\u00e9gion Onglets interm\u00e9diaires Options avanc\u00e9es R\u00e9seau, stockage, s\u00e9curit\u00e9, tags, monitoring V\u00e9rifier + cr\u00e9er Validation finale R\u00e9sum\u00e9 des param\u00e8tres, v\u00e9rification d'erreurs"},{"location":"_projects/_formation-azure/azure-chap04/#gestion-des-abonnements-et-des-groupes-de-ressources","title":"Gestion des abonnements et des groupes de ressources","text":"<p>L'interface Azure facilite la gestion des structures organisationnelles : - Abonnements : Accessibles via les param\u00e8tres de compte, permettant de basculer entre diff\u00e9rents abonnements - Groupes de ressources : Affich\u00e9s dans le panneau de navigation, groupant logiquement les ressources associ\u00e9es</p>"},{"location":"_projects/_formation-azure/azure-chap04/#tableau-de-bord-personnalisable","title":"Tableau de bord personnalisable","text":"<p>Le portail propose un syst\u00e8me de widgets permettant la personnalisation compl\u00e8te du tableau de bord. Les utilisateurs peuvent : - Ajouter des cartes de monitoring pour surveiller les m\u00e9triques cl\u00e9s - Organiser les widgets selon leurs priorit\u00e9s - Cr\u00e9er plusieurs tableaux de bord pour diff\u00e9rents r\u00f4les ou projets</p>"},{"location":"_projects/_formation-azure/azure-chap04/#3-azure-cloud-shell-azure-powershell-et-azure-cli","title":"3. Azure Cloud Shell, Azure PowerShell et Azure CLI","text":""},{"location":"_projects/_formation-azure/azure-chap04/#presentation-des-outils-en-ligne-de-commande","title":"Pr\u00e9sentation des outils en ligne de commande","text":"<p>Au-del\u00e0 de l'interface graphique, Azure propose trois environnements d'ex\u00e9cution permettant l'automation et le scripting : Azure Cloud Shell, Azure PowerShell et Azure CLI. Ces outils offrent une control pr\u00e9cis sur les ressources et permettent l'int\u00e9gration dans des pipelines de d\u00e9ploiement continu.</p>"},{"location":"_projects/_formation-azure/azure-chap04/#azure-cloud-shell","title":"Azure Cloud Shell","text":"<p>D\u00e9finition et accessibilit\u00e9</p> <p>Azure Cloud Shell constitue un interpr\u00e9teur de commandes bas\u00e9 sur le web, directement int\u00e9gr\u00e9 au portail Azure[3]. Cet environnement sandbox\u00e9 s'ex\u00e9cute dans le nuage sans n\u00e9cessiter d'installation locale. L'acc\u00e8s se fait via une ic\u00f4ne de terminal situ\u00e9e dans la barre sup\u00e9rieure du portail Azure.</p> <p>Caract\u00e9ristiques principales</p> <ul> <li>Authentification automatique via les credentials du portail Azure</li> <li>Deux shells disponibles : Bash et PowerShell</li> <li>Stockage persistent de 5 GB pour conserver les scripts et fichiers entre les sessions</li> <li>Pr\u00e9-installation des outils Azure (Azure CLI et Azure PowerShell)</li> <li>Mise \u00e0 jour automatique des outils sans intervention utilisateur</li> </ul> <p>Lancement dans le portail</p> <p>Pour acc\u00e9der \u00e0 Azure Cloud Shell, l'utilisateur doit[3] : 1. Se connecter au portail Azure via portal.azure.com 2. Identifier l'ic\u00f4ne du terminal dans la barre d'outils sup\u00e9rieure 3. Cliquer sur cette ic\u00f4ne pour lancer le shell</p> <p>Le syst\u00e8me propose alors de choisir entre Bash et PowerShell. L'interpr\u00e9teur choisi se charge automatiquement avec tous les outils pr\u00e9configur\u00e9s.</p>"},{"location":"_projects/_formation-azure/azure-chap04/#azure-powershell","title":"Azure PowerShell","text":"<p>Principes fondamentaux</p> <p>Azure PowerShell repr\u00e9sente le module PowerShell permettant d'interact avec les ressources Azure[3]. PowerShell, le langage de scripting de Microsoft, offre une syntaxe orient\u00e9e objet puissante pour l'automation.</p> <p>Installation locale</p> <p>Pour les utilisateurs souhaitant utiliser Azure PowerShell en dehors du Cloud Shell : 1. Installation de PowerShell 7 ou sup\u00e9rieur 2. Installation du module Azure PowerShell via le gestionnaire de packages</p> PowerShell<pre><code># Commande d'installation du module Azure PowerShell\nInstall-Module -Name Az -Repository PSGallery -Force\n</code></pre> <p>Authentification vers Azure</p> <p>Avant toute op\u00e9ration, l'authentification doit \u00eatre \u00e9tablie[3] :</p> PowerShell<pre><code># Commande de connexion \u00e0 Azure\nConnect-AzAccount\n</code></pre> <p>Cette commande ouvre une fen\u00eatre de navigateur demandant les identifiants Azure. Une fois l'authentification r\u00e9ussie, les permissions d'acc\u00e8s sont transmises \u00e0 PowerShell pour l'ex\u00e9cution des commandes ult\u00e9rieures.</p> <p>Structure et cmdlets</p> <p>Les cmdlets Azure PowerShell suivent une nomenclature standardis\u00e9e : <code>Verb-AzNoun</code>. Par exemple : - <code>Get-AzVirtualMachine</code> : r\u00e9cup\u00e8re les machines virtuelles - <code>New-AzResourceGroup</code> : cr\u00e9e un nouveau groupe de ressources - <code>Remove-AzStorageAccount</code> : supprime un compte de stockage</p> <p>Exemple de script de cr\u00e9ation de groupe de ressources</p> PowerShell<pre><code># Variables de configuration\n$resourceGroupName = \"MonGroupeRessources\"\n$location = \"East US\"\n\n# Cr\u00e9ation du groupe de ressources\nNew-AzResourceGroup -Name $resourceGroupName -Location $location\n\n# Affichage des groupes de ressources cr\u00e9\u00e9s\nGet-AzResourceGroup -Name $resourceGroupName\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap04/#azure-cli","title":"Azure CLI","text":"<p>Pr\u00e9sentation g\u00e9n\u00e9rale</p> <p>Azure CLI est une interface de ligne de commande multiplateforme d\u00e9velopp\u00e9e par Microsoft pour g\u00e9rer les ressources Azure[3]. Contrairement \u00e0 PowerShell, Azure CLI utilise une syntaxe inspir\u00e9e des commandes Unix/Linux, la rendant plus intuitive pour les administrateurs syst\u00e8mes en provenance d'environnements Linux.</p> <p>Installation locale</p> <p>Azure CLI s'installe sur Windows, macOS et Linux via le gestionnaire de packages appropri\u00e9 :</p> Bash<pre><code># Installation sur Linux (Debian/Ubuntu)\ncurl -sL https://aka.ms/InstallAzureCLIDeb | sudo bash\n\n# Installation sur macOS via Homebrew\nbrew install azure-cli\n</code></pre> <p>Authentification vers Azure</p> <p>Apr\u00e8s installation, l'authentification s'\u00e9tablit via :</p> Bash<pre><code>az login\n</code></pre> <p>Cette commande ouvre un navigateur pour l'authentification interactive. Les tokens d'acc\u00e8s sont ensuite stock\u00e9s localement pour les commandes ult\u00e9rieures.</p> <p>Structure des commandes</p> <p>Les commandes Azure CLI suivent un pattern hi\u00e9rarchique : <code>az [service] [sous-service] [action] [--parameters]</code>. Par exemple : - <code>az vm list</code> : \u00e9num\u00e8re toutes les machines virtuelles - <code>az storage account create</code> : cr\u00e9e un compte de stockage - <code>az group create</code> : cr\u00e9e un groupe de ressources</p> <p>Exemple de script de cr\u00e9ation de ressources</p> Bash<pre><code>#!/bin/bash\n\n# Variables de configuration\nRESOURCE_GROUP=\"MonGroupeRessources\"\nLOCATION=\"eastus\"\nSTORAGE_ACCOUNT=\"mocomptestock\"\n\n# Cr\u00e9ation du groupe de ressources\naz group create \\\n  --name $RESOURCE_GROUP \\\n  --location $LOCATION\n\n# Cr\u00e9ation d'un compte de stockage\naz storage account create \\\n  --name $STORAGE_ACCOUNT \\\n  --resource-group $RESOURCE_GROUP \\\n  --location $LOCATION \\\n  --sku Standard_LRS\n\n# Affichage des propri\u00e9t\u00e9s du compte cr\u00e9\u00e9\naz storage account show \\\n  --name $STORAGE_ACCOUNT \\\n  --resource-group $RESOURCE_GROUP\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap04/#comparaison-des-trois-approches","title":"Comparaison des trois approches","text":"Aspect Cloud Shell PowerShell Azure CLI Installation Aucune (web) Installation requise Installation requise Syst\u00e8me d'exploitation Windows/Mac/Linux Windows/Mac/Linux Windows/Mac/Linux Authentification Automatique Via Connect-AzAccount Via az login Courbe d'apprentissage Faible Moyenne (PowerShell requis) Faible (syntaxe Unix) Automation complexe Acceptable Excellente Bonne Stockage persistant 5 GB Non (local uniquement) Non (local uniquement) Interaction scripts Bash/PowerShell PowerShell uniquement Bash uniquement"},{"location":"_projects/_formation-azure/azure-chap04/#cas-dusage-recommandes","title":"Cas d'usage recommand\u00e9s","text":"<p>Azure Cloud Shell : tests rapides, exploration des services, petits scripts ponctuels sans d\u00e9pendances locales.</p> <p>Azure PowerShell : automation complexe, gestion d'entreprise, int\u00e9gration avec l'\u00e9cosyst\u00e8me Windows/Active Directory.</p> <p>Azure CLI : scripts d'infrastructure, d\u00e9ploiement CI/CD, environnements multi-platforms, \u00e9quipes Linux/DevOps.</p>"},{"location":"_projects/_formation-azure/azure-chap04/#4-infrastructure-physique-dazure-en-detail","title":"4. Infrastructure physique d'Azure en d\u00e9tail","text":""},{"location":"_projects/_formation-azure/azure-chap04/#architecture-globale","title":"Architecture globale","text":"<p>L'infrastructure physique d'Azure repose sur une architecture distribu\u00e9e mondialement, combinant des centres de donn\u00e9es physiques organis\u00e9s en r\u00e9gions g\u00e9ographiques. Cette architecture garantit la disponibilit\u00e9, la performance et la r\u00e9silience des services.</p>"},{"location":"_projects/_formation-azure/azure-chap04/#regions-azure","title":"R\u00e9gions Azure","text":"<p>Concept de r\u00e9gion</p> <p>Une r\u00e9gion Azure repr\u00e9sente une aire g\u00e9ographique contenant un ou plusieurs centres de donn\u00e9es. Microsoft maintient plus de 60 r\u00e9gions Azure \u00e0 travers le monde, couvrant tous les continents. Chaque r\u00e9gion fonctionne de mani\u00e8re ind\u00e9pendante, avec ses propres ressources de calcul, stockage et r\u00e9seau.</p> <p>S\u00e9lection de r\u00e9gion</p> <p>Le choix de la r\u00e9gion pour d\u00e9ployer les ressources impacte directement : - Latence : Une r\u00e9gion proche r\u00e9duit le temps de r\u00e9ponse - Conformit\u00e9 r\u00e9glementaire : Certains pays imposent la localisation des donn\u00e9es - Disponibilit\u00e9 des services : Tous les services ne sont pas disponibles dans toutes les r\u00e9gions - Co\u00fbt : Les tarifs varient selon les r\u00e9gions</p> <p>R\u00e9gions pair\u00e9es</p> <p>Microsoft associe les r\u00e9gions par paires pour la redondance. Par exemple, \"East US\" est appair\u00e9 avec \"West US\", \"North Europe\" avec \"West Europe\". Cette strat\u00e9gie offre : - R\u00e9cup\u00e9ration apr\u00e8s sinistre automatis\u00e9e - S\u00e9paration g\u00e9ographique minimale - Maintenance coordonn\u00e9e sans interruption simultan\u00e9e</p>"},{"location":"_projects/_formation-azure/azure-chap04/#zones-de-disponibilite","title":"Zones de disponibilit\u00e9","text":"<p>Architecture des zones</p> <p>Au sein d'une m\u00eame r\u00e9gion, Azure propose jusqu'\u00e0 trois zones de disponibilit\u00e9 physiquement s\u00e9par\u00e9es. Chaque zone contient un ou plusieurs centres de donn\u00e9es avec alimentation, refroidissement et connectivit\u00e9 r\u00e9seau ind\u00e9pendants.</p> <p>B\u00e9n\u00e9fices des zones de disponibilit\u00e9</p> <ul> <li>R\u00e9silience am\u00e9lior\u00e9e : Une panne dans une zone n'affecte pas les autres</li> <li>Haute disponibilit\u00e9 : Les applications distribu\u00e9es sur les zones restent accessibles</li> <li>R\u00e9cup\u00e9ration rapide : Redondance int\u00e9gr\u00e9e sans intervention manuelle</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap04/#centres-de-donnees-physiques","title":"Centres de donn\u00e9es physiques","text":"<p>Composition interne</p> <p>Chaque centre de donn\u00e9es Azure contient : - Serveurs physiques h\u00e9bergeant les machines virtuelles et services - Syst\u00e8mes de stockage massivement redondants - \u00c9quipements r\u00e9seau haute performance - Syst\u00e8mes de refroidissement et d'alimentation critiques - Syst\u00e8mes de s\u00e9curit\u00e9 physique multicouches</p> <p>Connectivit\u00e9 intra-centre</p> <p>Les serveurs au sein d'un centre de donn\u00e9es sont interconnect\u00e9s via : - Commutateurs r\u00e9seau redondants - Fibre optique haute vitesse - Architectures mailles pour \u00e9liminer les points uniques de d\u00e9faillance</p>"},{"location":"_projects/_formation-azure/azure-chap04/#infrastructure-reseau-mondiale","title":"Infrastructure r\u00e9seau mondiale","text":"<p>Backbone r\u00e9seau Microsoft</p> <p>Microsoft maintient son propre backbone r\u00e9seau reliant tous les centres de donn\u00e9es. Cette infrastructure propri\u00e9taire \u00e9vite les d\u00e9pendances envers les fournisseurs de connectivit\u00e9 externes et garantit des performances optimales.</p> <p>Chemin de donn\u00e9es</p> <p>Les donn\u00e9es transf\u00e8rent entre r\u00e9gions via ce backbone priv\u00e9 plut\u00f4t que via l'Internet public, offrant : - Latence pr\u00e9dictible et faible - Bande passante garantie - S\u00e9curit\u00e9 renforc\u00e9e</p>"},{"location":"_projects/_formation-azure/azure-chap04/#hyperviseurs-et-virtualisation","title":"Hyperviseurs et virtualisation","text":"<p>Technologie Hyper-V</p> <p>Azure utilise Hyper-V, la plateforme de virtualisation de Microsoft, comme couche d'hyperviseur. Cette technologie permet : - Isolation des machines virtuelles - Partage efficace des ressources mat\u00e9rielles - Migration transparente des instances</p> <p>Contr\u00f4leurs de structure</p> <p>Des contr\u00f4leurs de structure (Fabric Controllers) g\u00e8rent chaque machine h\u00f4te Hyper-V. Ils orchestrent : - L'allocation des ressources - Le placement des machines virtuelles - La surveillance de la sant\u00e9 des serveurs - La r\u00e9cup\u00e9ration automatique en cas de d\u00e9faillance</p>"},{"location":"_projects/_formation-azure/azure-chap04/#redondance-de-stockage","title":"Redondance de stockage","text":"<p>R\u00e9plication des donn\u00e9es</p> <p>Azure impl\u00e9mente plusieurs strat\u00e9gies de r\u00e9plication : - Stockage localement redondant (LRS) : Trois copies dans un m\u00eame centre de donn\u00e9es - Stockage g\u00e9ographiquement redondant (GRS) : LRS + r\u00e9plication dans une r\u00e9gion pair\u00e9e - Stockage g\u00e9ographiquement redondant avec acc\u00e8s en lecture (RA-GRS) : GRS + acc\u00e8s en lecture \u00e0 la copie secondaire</p> <p>G\u00e9olocalisation et r\u00e9sidence des donn\u00e9es</p> <p>Les donn\u00e9es restent dans la r\u00e9gion s\u00e9lectionn\u00e9e lors du d\u00e9ploiement, sauf pour la r\u00e9plication dans les r\u00e9gions pair\u00e9es. Cette approche respecte les exigences de r\u00e9sidence des donn\u00e9es impos\u00e9es par certaines juridictions.</p>"},{"location":"_projects/_formation-azure/azure-chap04/#mise-a-jour-de-linfrastructure","title":"Mise \u00e0 jour de l'infrastructure","text":"<p>Fen\u00eatres de maintenance</p> <p>Microsoft effectue les mises \u00e0 jour du mat\u00e9riel et des firmwares de mani\u00e8re coordonn\u00e9e pour \u00e9viter les interruptions de service. Chaque centre de donn\u00e9es suit un calendrier de maintenance d\u00e9cal\u00e9.</p> <p>Impact sur les clients</p> <p>Pour les services sans haute disponibilit\u00e9 configur\u00e9e, les mises \u00e0 jour peuvent causer une interruption br\u00e8ve. Les clients utilisant des configurations redondantes (plusieurs zones ou r\u00e9gions) ne subissent pas d'interruption perceptible.</p>"},{"location":"_projects/_formation-azure/azure-chap04/#5-infrastructure-de-gestion-organisation-et-hierarchie-des-ressources","title":"5. Infrastructure de gestion : Organisation et hi\u00e9rarchie des ressources","text":""},{"location":"_projects/_formation-azure/azure-chap04/#modele-hierarchique-dazure","title":"Mod\u00e8le hi\u00e9rarchique d'Azure","text":"<p>L'organisation des ressources Azure suit une hi\u00e9rarchie stricte permettant une gestion granulaire, une facturation pr\u00e9cise et le contr\u00f4le d'acc\u00e8s bas\u00e9 sur les r\u00f4les. Cette structure s'\u00e9tend du niveau de locataire au niveau individuel des ressources.</p>"},{"location":"_projects/_formation-azure/azure-chap04/#niveau-1-tenant-azure-ad","title":"Niveau 1 : Tenant Azure AD","text":"<p>Concept fondamental</p> <p>Un tenant Azure AD (anciennement Azure Active Directory) repr\u00e9sente une instance d\u00e9di\u00e9e d'Azure AD associ\u00e9e \u00e0 une organisation. Chaque tenant constitue une limite administrative et de s\u00e9curit\u00e9, contenant tous les utilisateurs, groupes et applications d'une organisation.</p> <p>Cr\u00e9ations et r\u00f4le</p> <ul> <li>Un tenant est cr\u00e9\u00e9 lors de la premi\u00e8re inscription \u00e0 Azure</li> <li>Une organisation peut g\u00e9rer plusieurs tenants (pour diff\u00e9rentes divisions ou filiales)</li> <li>Les utilisateurs d'un tenant ne peuvent acc\u00e9der qu'aux ressources du m\u00eame tenant par d\u00e9faut</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap04/#niveau-2-abonnements-azure","title":"Niveau 2 : Abonnements Azure","text":"<p>D\u00e9finition et r\u00f4le</p> <p>Un abonnement Azure repr\u00e9sente une relation contractuelle et de facturation entre un client et Microsoft. Il constitue le conteneur dans lequel toutes les ressources sont cr\u00e9\u00e9es et factur\u00e9es. Les \u00e9l\u00e9ments cl\u00e9s :</p> <ul> <li>Chaque abonnement dispose de sa propre limite de quotas</li> <li>Les co\u00fbts sont associ\u00e9s et factur\u00e9s par abonnement</li> <li>Diff\u00e9rents types d'abonnements existent (gratuit, paiement \u00e0 l'utilisation, contrats Entreprise)</li> </ul> <p>Types d'abonnements courants</p> Type Utilisation Limite de co\u00fbt Gratuit Test et exploration Cr\u00e9dit 200$ ou 30 jours Paiement \u00e0 l'utilisation Production l\u00e9g\u00e8re Aucune limite fixe Contrat Entreprise Organisations grandes D\u00e9fini par le contrat Azure CSP Revendeurs D\u00e9fini par le partenaire <p>Gestion des abonnements</p> <p>Dans le portail Azure, la gestion des abonnements s'effectue via[3][4] : - L'ic\u00f4ne d'abonnement dans la barre sup\u00e9rieure - La section \"Abonnements\" des param\u00e8tres de compte - Possibilit\u00e9 de basculer entre plusieurs abonnements si l'utilisateur a acc\u00e8s \u00e0 plusieurs</p>"},{"location":"_projects/_formation-azure/azure-chap04/#niveau-3-groupes-de-ressources","title":"Niveau 3 : Groupes de ressources","text":"<p>R\u00f4le organisationnel</p> <p>Un groupe de ressources constitue l'unit\u00e9 logique et organisationnelle contenant des ressources connexes[3][4]. Tous les services Azure doivent r\u00e9sider dans un groupe de ressources. Les caract\u00e9ristiques :</p> <ul> <li>Unit\u00e9 de d\u00e9ploiement : Les templates ARM d\u00e9ploient des ressources group\u00e9es</li> <li>Limite de cycle de vie : La suppression d'un groupe supprime toutes ses ressources</li> <li>Point de facturation : Les co\u00fbts sont agr\u00e9g\u00e9s au niveau du groupe</li> <li>Point de contr\u00f4le d'acc\u00e8s : Les permissions s'appliquent \u00e0 l'ensemble du groupe</li> </ul> <p>Cr\u00e9ation et organisation</p> <p>Pour cr\u00e9er un groupe de ressources via le portail[4] : 1. Cliquer sur \"+ Cr\u00e9er une ressource\" 2. Rechercher \"Groupe de ressources\" 3. Cliquer sur \"Cr\u00e9er\" 4. Fournir un nom (sans espaces, alphanum\u00e9rique) 5. S\u00e9lectionner l'abonnement 6. Choisir la r\u00e9gion (d\u00e9termine l'emplacement par d\u00e9faut des m\u00e9tadonn\u00e9es) 7. Cliquer \"V\u00e9rifier + cr\u00e9er\"</p> <p>Exemple de structure organisationnelle</p> Text Only<pre><code>Abonnement: Production\n\u251c\u2500\u2500 Groupe de ressources: Application-Frontend\n\u2502   \u251c\u2500\u2500 App Service (web app)\n\u2502   \u251c\u2500\u2500 Application Insights (monitoring)\n\u2502   \u2514\u2500\u2500 CDN\n\u251c\u2500\u2500 Groupe de ressources: Application-Backend\n\u2502   \u251c\u2500\u2500 App Service (API)\n\u2502   \u251c\u2500\u2500 SQL Database\n\u2502   \u2514\u2500\u2500 Application Insights\n\u2514\u2500\u2500 Groupe de ressources: Infrastructure-Partag\u00e9e\n    \u251c\u2500\u2500 Virtual Network\n    \u251c\u2500\u2500 Key Vault\n    \u2514\u2500\u2500 Log Analytics\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap04/#niveau-4-ressources-individuelles","title":"Niveau 4 : Ressources individuelles","text":"<p>Nature des ressources</p> <p>Les ressources repr\u00e9sentent les services Azure individuels : machines virtuelles, bases de donn\u00e9es, comptes de stockage, applications web, etc. Les propri\u00e9t\u00e9s cl\u00e9s :</p> <ul> <li>Chaque ressource dispose d'un type (VM, Storage Account, App Service)</li> <li>Un identifiant unique dans le groupe de ressources</li> <li>Des param\u00e8tres de configuration sp\u00e9cifiques</li> <li>Un point de facturation distinct (m\u00eame si agr\u00e9g\u00e9 au niveau du groupe)</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap04/#controle-dacces-base-sur-les-roles-rbac","title":"Contr\u00f4le d'acc\u00e8s bas\u00e9 sur les r\u00f4les (RBAC)","text":"<p>Principes fondamentaux</p> <p>Le RBAC d'Azure impl\u00e9mente un mod\u00e8le d'attribution de permissions granulaire utilisant trois composants :</p> <ol> <li>Principal de s\u00e9curit\u00e9 : Utilisateur, groupe ou application requ\u00e9rant l'acc\u00e8s</li> <li>R\u00f4le : Ensemble de permissions pr\u00e9d\u00e9finies ou personnalis\u00e9es</li> <li>Scope : Niveau hi\u00e9rarchique auquel s'applique l'attribution (subscription, resource group, ressource)</li> </ol> <p>Hi\u00e9rarchie des scopes pour le RBAC</p> Text Only<pre><code>Management Group\n    \u2193\nSubscription\n    \u2193\nResource Group\n    \u2193\nResource\n</code></pre> <p>Les permissions s'h\u00e9ritent du niveau parent au niveau enfant. Une attribution au niveau du groupe de ressources accorde les permissions sur toutes les ressources du groupe.</p> <p>R\u00f4les pr\u00e9d\u00e9finis majeurs</p> R\u00f4le Permissions Cas d'usage Owner Contr\u00f4le complet Administrateurs d'infrastructure Contributor Cr\u00e9ation/modification de ressources Ing\u00e9nieurs d\u00e9ploiement Reader Lecture seule Responsables audits Virtual Machine Contributor Gestion VMs uniquement Administrateurs serveurs Reader et Data Access Lecture + acc\u00e8s donn\u00e9es Analystes donn\u00e9es <p>Attribution de r\u00f4les</p> <p>L'attribution de r\u00f4les s'effectue dans le portail[4] : 1. Acc\u00e9d\u00e9rer au groupe de ressources 2. Cliquer sur \"Access Control (IAM)\" 3. Cliquer sur \"+ Add\" puis \"Add role assignment\" 4. S\u00e9lectionner le r\u00f4le souhait\u00e9 5. S\u00e9lectionner le principal (utilisateur/groupe/application) 6. Cliquer \"Save\"</p>"},{"location":"_projects/_formation-azure/azure-chap04/#etiquettes-et-classification-des-ressources","title":"\u00c9tiquettes et classification des ressources","text":"<p>Objectif des \u00e9tiquettes</p> <p>Les \u00e9tiquettes permettent d'annoter les ressources avec des m\u00e9tadonn\u00e9es personnalis\u00e9es pour l'organisation, la facturation et l'automation. Format : paires cl\u00e9-valeur.</p> <p>Exemples courants</p> Text Only<pre><code>Environment: Production\nCostCenter: Engineering\nOwner: jean.dupont@company.com\nProject: ClientABC\nBackupPolicy: Daily\nEncryption: Required\n</code></pre> <p>Utilisation des \u00e9tiquettes</p> <ul> <li>Facturation : Attribution des co\u00fbts par d\u00e9partement via les \u00e9tiquettes</li> <li>Automation : Scripts ciblent les ressources selon les \u00e9tiquettes</li> <li>Gouvernance : Enforcer certaines \u00e9tiquettes obligatoires</li> <li>Filtrage : Portail et CLI offrent filtrage par \u00e9tiquettes</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap04/#hierarchie-complete-avec-exemple","title":"Hi\u00e9rarchie compl\u00e8te avec exemple","text":"<p>Structure concr\u00e8te d'une entreprise multiniveau</p> Text Only<pre><code>Tenant: contoso.onmicrosoft.com\n\u2502\n\u251c\u2500\u2500 Management Group: Division-EMEA\n\u2502   \u2502\n\u2502   \u2514\u2500\u2500 Subscription: EMEA-Production\n\u2502       \u2502\n\u2502       \u251c\u2500\u2500 Resource Group: Web-Frontend\n\u2502       \u2502   \u251c\u2500\u2500 App Service (frontend-api.azurewebsites.net)\n\u2502       \u2502   \u251c\u2500\u2500 Application Insights\n\u2502       \u2502   \u2514\u2500\u2500 Storage Account (frontend-cdn)\n\u2502       \u2502\n\u2502       \u251c\u2500\u2500 Resource Group: Database-Backend\n\u2502       \u2502   \u251c\u2500\u2500 SQL Server\n\u2502       \u2502   \u251c\u2500\u2500 SQL Database (proddb)\n\u2502       \u2502   \u2514\u2500\u2500 Key Vault\n\u2502       \u2502\n\u2502       \u2514\u2500\u2500 Resource Group: Infrastructure\n\u2502           \u251c\u2500\u2500 Virtual Network\n\u2502           \u251c\u2500\u2500 Network Security Groups\n\u2502           \u2514\u2500\u2500 Log Analytics Workspace\n\u2502\n\u2514\u2500\u2500 Management Group: Division-Americas\n    \u2502\n    \u2514\u2500\u2500 Subscription: Americas-Production\n        \u2502\n        \u251c\u2500\u2500 Resource Group: Compute\n        \u251c\u2500\u2500 Resource Group: Storage\n        \u2514\u2500\u2500 Resource Group: Networking\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap04/#groupes-dadministration-management-groups","title":"Groupes d'administration (Management Groups)","text":"<p>R\u00f4le organisationnel sup\u00e9rieur</p> <p>Les groupes d'administration permettent de regrouper plusieurs abonnements pour l'application de gouvernance et de politiques au niveau d'une organisation enti\u00e8re[4]. Ils offrent :</p> <ul> <li>Application centralis\u00e9e des strat\u00e9gies</li> <li>Facturation consolid\u00e9e</li> <li>Gestion d'acc\u00e8s au niveau organisationnel</li> <li>Hi\u00e9rarchie arbitraire jusqu'\u00e0 6 niveaux de profondeur</li> </ul> <p>Exemple de structure</p> Text Only<pre><code>Root Management Group (Tenant Root)\n\u251c\u2500\u2500 Management Group: France\n\u2502   \u251c\u2500\u2500 Subscription: FR-Production\n\u2502   \u2514\u2500\u2500 Subscription: FR-Development\n\u251c\u2500\u2500 Management Group: Germany\n\u2502   \u251c\u2500\u2500 Subscription: DE-Production\n\u2502   \u2514\u2500\u2500 Subscription: DE-Development\n\u2514\u2500\u2500 Management Group: UK\n    \u251c\u2500\u2500 Subscription: UK-Production\n    \u2514\u2500\u2500 Subscription: UK-Development\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap04/#quotas-et-limites","title":"Quotas et limites","text":"<p>Quotas de ressources</p> <p>Chaque abonnement Azure dispose de quotas limitant le nombre de certaines ressources pour \u00e9viter les d\u00e9ploiements accidentellement excessifs[4] :</p> <ul> <li>Machines virtuelles par r\u00e9gion</li> <li>Comptes de stockage par abonnement</li> <li>Bases de donn\u00e9es par serveur SQL</li> <li>Adresses IP publiques</li> </ul> <p>Augmentation des quotas</p> <p>Azure permet les demandes d'augmentation de quotas par : 1. Navigation vers \"Subscriptions\" 2. S\u00e9lection de l'abonnement 3. Acc\u00e8s \u00e0 \"Usage + quotas\" 4. S\u00e9lection de la ressource \u00e0 augmenter 5. Soumission d'une demande d'augmentation avec justification</p>"},{"location":"_projects/_formation-azure/azure-chap04/#cheminement-dapprentissage-complet","title":"Cheminement d'apprentissage complet","text":""},{"location":"_projects/_formation-azure/azure-chap04/#phase-1-fondations-semaine-1-2","title":"Phase 1 : Fondations (semaine 1-2)","text":"<p>Objectifs</p> <p>Acqu\u00e9rir une compr\u00e9hension solide de la structure d'Azure et des concepts de base de la gestion du cloud.</p> <p>\u00c9tapes recommand\u00e9es</p> <ol> <li>Cr\u00e9er un compte Azure gratuit et explorer l'interface du portail</li> <li>Naviguer dans la structure hi\u00e9rarchique (tenant \u2192 abonnement \u2192 groupe de ressources \u2192 ressources)</li> <li>Identifier les diff\u00e9rentes r\u00e9gions et zones de disponibilit\u00e9</li> <li>Consulter la documentation officielle sur learn.microsoft.com concernant la structure d'Azure</li> </ol>"},{"location":"_projects/_formation-azure/azure-chap04/#phase-2-exploration-des-outils-semaine-3","title":"Phase 2 : Exploration des outils (semaine 3)","text":"<p>Objectifs</p> <p>Ma\u00eetriser les trois interfaces d'interaction avec Azure pour choisir l'approche appropri\u00e9e selon le contexte.</p> <p>\u00c9tapes recommand\u00e9es</p> <ol> <li>Utiliser Azure Cloud Shell pour ex\u00e9cuter des commandes sans installation locale</li> <li>Installer Azure CLI localement et s'authentifier</li> <li>Installer Azure PowerShell et explorer les cmdlets</li> <li>Comparer les approches d\u00e9clarative (CLI) et orient\u00e9e objet (PowerShell)</li> </ol>"},{"location":"_projects/_formation-azure/azure-chap04/#phase-3-infrastructure-physique-semaine-4","title":"Phase 3 : Infrastructure physique (semaine 4)","text":"<p>Objectifs</p> <p>Comprendre l'architecture souterraine permettant la livraison de services cloud fiables.</p> <p>\u00c9tapes recommand\u00e9es</p> <ol> <li>\u00c9tudier la documentation sur les r\u00e9gions, zones de disponibilit\u00e9 et centres de donn\u00e9es</li> <li>Analyser l'impact du choix de r\u00e9gion sur la latence et la conformit\u00e9</li> <li>Planifier une architecture de r\u00e9silience utilisant plusieurs zones/r\u00e9gions</li> <li>Documenter les sc\u00e9narios de r\u00e9cup\u00e9ration apr\u00e8s sinistre</li> </ol>"},{"location":"_projects/_formation-azure/azure-chap04/#phase-4-gouvernance-et-organisation-semaine-5","title":"Phase 4 : Gouvernance et organisation (semaine 5)","text":"<p>Objectifs</p> <p>Mettre en place une structure organisationnelle scalable pour les ressources Azure.</p> <p>\u00c9tapes recommand\u00e9es</p> <ol> <li>Cr\u00e9er une hi\u00e9rarchie de groupes de ressources refl\u00e9tant la structure organisationnelle</li> <li>Configurer les \u00e9tiquettes standardis\u00e9es pour l'organisation et la facturation</li> <li>Attribuer des r\u00f4les RBAC selon les principes du moindre privil\u00e8ge</li> <li>Mettre en place des strat\u00e9gies et des initiatives via Azure Policy</li> </ol>"},{"location":"_projects/_formation-azure/azure-chap04/#pratique-integree","title":"Pratique int\u00e9gr\u00e9e","text":"<p>Les concepts doivent \u00eatre appliqu\u00e9s \u00e0 travers un projet pratique continu : - Concevoir une application multi-niveaux - D\u00e9ployer les composants dans des groupes de ressources organis\u00e9s - Automatiser les d\u00e9ploiements via des scripts PowerShell ou CLI - Surveiller les co\u00fbts par \u00e9tiquette et groupe de ressources - Documenter les d\u00e9cisions architecturales et les apprentissages</p>"},{"location":"_projects/_formation-azure/azure-chap04/#conclusion","title":"Conclusion","text":"<p>La ma\u00eetrise des composants principaux d'Azure constitue la fondation indispensable pour tout projet cloud r\u00e9ussi. De la cr\u00e9ation du compte initial \u00e0 la compr\u00e9hension de l'infrastructure physique en passant par l'organisation hi\u00e9rarchique des ressources, chaque \u00e9l\u00e9ment joue un r\u00f4le critique dans la livraison de solutions cloud performantes, s\u00e9curis\u00e9es et conformes. L'approche syst\u00e9matique combinant la th\u00e9orie (concepts) et la pratique (d\u00e9ploiements r\u00e9els) garantit une internalisation profonde de ces principes fondamentaux.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure/azure-chap05/","title":"Citations","text":"<ul> <li>https://learn.microsoft.com/en-us/azure/virtual-machine-scale-sets/tutorial-create-and-manage-powershell</li> <li>https://www.youtube.com/watch?v=akjcVxHAAM0</li> <li>https://learn.microsoft.com/en-us/azure/virtual-machine-scale-sets/tutorial-create-and-manage-cli</li> <li>https://docs.azure.cn/en-us/virtual-machine-scale-sets/tutorial-create-and-manage-powershell</li> <li>https://learn.microsoft.com/es-es/azure/virtual-machine-scale-sets/tutorial-create-and-manage-cli</li> <li>https://learn.microsoft.com/es-es/azure/virtual-machine-scale-sets/tutorial-create-and-manage-powershell</li> <li>https://learn.microsoft.com/es-es/azure/virtual-machine-scale-sets/</li> <li>https://www.youtube.com/watch?v=0KVNlOStnRY</li> <li>https://learn.microsoft.com/es-es/azure/virtual-machine-scale-sets/tutorial-use-disks-powershell</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap05/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 344</li> <li>completion_tokens: 9487</li> <li>total_tokens: 9831</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.142, 'request_cost': 0.006, 'total_cost': 0.149}</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap05/#content","title":"Content","text":""},{"location":"_projects/_formation-azure/azure-chap05/#les-services-de-calcul-azure-guide-complet-de-formation","title":"Les Services de Calcul Azure : Guide Complet de Formation","text":""},{"location":"_projects/_formation-azure/azure-chap05/#presentation-des-services-de-calcul-azure","title":"Pr\u00e9sentation des Services de Calcul Azure","text":"<p>Les services de calcul Azure repr\u00e9sentent l'ensemble des solutions propos\u00e9es par Microsoft pour ex\u00e9cuter des applications, traiter des donn\u00e9es et h\u00e9berger des services dans le cloud. Ces services se distinguent par leur flexibilit\u00e9, leur scalabilit\u00e9 et leur capacit\u00e9 \u00e0 s'adapter \u00e0 diff\u00e9rents sc\u00e9narios d'utilisation, allant des charges de travail traditionnelles aux architectures serverless modernes.</p> <p>Azure propose une gamme diversifi\u00e9e de services de calcul qui s'\u00e9tendent sur un spectre allant du contr\u00f4le complet de l'infrastructure jusqu'\u00e0 l'abstraction totale de celle-ci. Cette approche multi-niveaux permet aux organisations de choisir le niveau de gestion appropri\u00e9 selon leurs besoins sp\u00e9cifiques, leurs comp\u00e9tences techniques et leur mod\u00e8le de co\u00fbts pr\u00e9f\u00e9r\u00e9.</p>"},{"location":"_projects/_formation-azure/azure-chap05/#presentation-des-machines-virtuelles-azure","title":"Pr\u00e9sentation des Machines Virtuelles Azure","text":""},{"location":"_projects/_formation-azure/azure-chap05/#vue-densemble","title":"Vue d'ensemble","text":"<p>Les Machines Virtuelles Azure constituent le fondement de l'infrastructure cloud propos\u00e9e par Microsoft. Elles offrent un contr\u00f4le complet sur l'environnement d'ex\u00e9cution, permettant aux organisations de d\u00e9ployer des syst\u00e8mes d'exploitation (Windows ou Linux) avec une configuration enti\u00e8rement personnalisable[1].</p> <p>Les machines virtuelles Azure fonctionnent selon un mod\u00e8le de consommation \u00e0 la demande, o\u00f9 les utilisateurs paient exclusivement pour les ressources utilis\u00e9es. Ce mod\u00e8le inclut le temps de calcul, le stockage associ\u00e9 et les transferts de donn\u00e9es r\u00e9seau sortants.</p>"},{"location":"_projects/_formation-azure/azure-chap05/#caracteristiques-principales","title":"Caract\u00e9ristiques principales","text":"<p>Flexibilit\u00e9 de configuration : Les machines virtuelles Azure permettent une personnalisation compl\u00e8te de la configuration mat\u00e9rielle virtuelle, incluant le processeur, la m\u00e9moire RAM, le stockage et les adaptateurs r\u00e9seau. Les administrateurs b\u00e9n\u00e9ficient d'un acc\u00e8s administrateur/root complet au syst\u00e8me d'exploitation.</p> <p>Diversit\u00e9 des syst\u00e8mes d'exploitation : Azure supporte une large gamme de syst\u00e8mes d'exploitation, notamment les distributions Linux populaires (Ubuntu, CentOS, Red Hat) et les variantes Windows (Windows Server 2019, 2022, etc.).</p> <p>Scalabilit\u00e9 verticale et horizontale : Les machines virtuelles peuvent \u00eatre redimensionn\u00e9es pour augmenter ou r\u00e9duire les ressources (scalabilit\u00e9 verticale), ou des instances multiples peuvent \u00eatre d\u00e9ploy\u00e9es derri\u00e8re un \u00e9quilibreur de charge (scalabilit\u00e9 horizontale).</p> <p>Options de stockage avanc\u00e9es : Azure propose plusieurs types de disques manag\u00e9s offrant diff\u00e9rents niveaux de performance (SSD Premium, SSD Standard, HDD Standard), permettant d'optimiser les co\u00fbts selon les exigences d'I/O.</p>"},{"location":"_projects/_formation-azure/azure-chap05/#types-de-machines-virtuelles-disponibles","title":"Types de machines virtuelles disponibles","text":"<p>Azure propose plusieurs gammes de machines virtuelles optimis\u00e9es pour diff\u00e9rentes charges de travail :</p> Gamme Utilisation Exemples Calcul optimis\u00e9 Applications haute performance, analyse de donn\u00e9es F, Fsv2, Fx M\u00e9moire optimis\u00e9e Bases de donn\u00e9es, caches, analyse en m\u00e9moire D, E, M Stockage optimis\u00e9 Data warehouse, bases de donn\u00e9es NoSQL L, Lsv2 GPU optimis\u00e9 Machine Learning, rendu graphique NC, ND, NV Usage g\u00e9n\u00e9ral Applications web, petites bases de donn\u00e9es A, B, D"},{"location":"_projects/_formation-azure/azure-chap05/#creation-dune-premiere-vm-linux-et-connexion-ssh","title":"Cr\u00e9ation d'une Premi\u00e8re VM Linux et Connexion SSH","text":""},{"location":"_projects/_formation-azure/azure-chap05/#processus-de-creation-via-azure-powershell","title":"Processus de cr\u00e9ation via Azure PowerShell","text":"<p>La cr\u00e9ation d'une premi\u00e8re machine virtuelle Linux constitue l'\u00e9tape fondamentale pour d\u00e9buter avec les ressources de calcul Azure. Le processus implique plusieurs \u00e9tapes : pr\u00e9paration des identifiants, cr\u00e9ation du groupe de ressources, configuration de la machine virtuelle et \u00e9tablissement de la connexion.</p>"},{"location":"_projects/_formation-azure/azure-chap05/#etapes-prealables","title":"\u00c9tapes pr\u00e9alables","text":"<p>Avant de cr\u00e9er une machine virtuelle, il faut d'abord \u00e9tablir les \u00e9l\u00e9ments de base de l'infrastructure Azure :</p> PowerShell<pre><code># Configuration initiale - Authentification aupr\u00e8s d'Azure\nConnect-AzAccount\n\n# D\u00e9finition du contexte (abonnement)\nSet-AzContext -SubscriptionId \"votre-id-abonnement\"\n\n# Cr\u00e9ation du groupe de ressources\n$resourceGroupName = \"myResourceGroup\"\n$location = \"EastUS\"\nNew-AzResourceGroup -Name $resourceGroupName -Location $location\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#creation-de-la-machine-virtuelle-linux","title":"Cr\u00e9ation de la machine virtuelle Linux","text":"PowerShell<pre><code># D\u00e9finition des param\u00e8tres de la VM\n$vmName = \"myLinuxVM\"\n$computerName = \"linuxvm01\"\n$vmSize = \"Standard_B2s\"\n\n# Configuration des identifiants administrateur\n$adminUsername = \"azureuser\"\n$adminPassword = ConvertTo-SecureString \"Passw0rd123!\" -AsPlainText -Force\n$credential = New-Object System.Management.Automation.PSCredential($adminUsername, $adminPassword)\n\n# Cr\u00e9ation de la configuration de la VM\n$vmConfig = New-AzVMConfig -VMName $vmName -VMSize $vmSize\n\n# Configuration du syst\u00e8me d'exploitation (Ubuntu 20.04 LTS)\n$vmConfig = Set-AzVMOperatingSystem -VM $vmConfig -Linux -ComputerName $computerName -Credential $credential\n\n# D\u00e9finition de l'image de march\u00e9 (Ubuntu)\n$vmConfig = Set-AzVMSourceImage -VM $vmConfig -PublisherName \"Canonical\" `\n    -Offer \"0001-com-ubuntu-server-focal\" -Skus \"20_04-lts-gen2\" -Version \"latest\"\n\n# Configuration de la carte r\u00e9seau\n$subnetConfig = New-AzVirtualNetworkSubnetConfig -Name \"default\" -AddressPrefix \"10.0.0.0/24\"\n$vnetConfig = New-AzVirtualNetwork -ResourceGroupName $resourceGroupName `\n    -Location $location -Name \"myVnet\" -AddressPrefix \"10.0.0.0/16\" `\n    -Subnet $subnetConfig\n\n$nicConfig = New-AzNetworkInterface -ResourceGroupName $resourceGroupName `\n    -Location $location -Name \"myNIC\" -Subnet $vnetConfig.Subnets[0]\n\n$vmConfig = Add-AzVMNetworkInterface -VM $vmConfig -Id $nicConfig.Id\n\n# Cr\u00e9ation de la machine virtuelle\nNew-AzVM -ResourceGroupName $resourceGroupName -Location $location -VM $vmConfig\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#configuration-ssh-et-connexion","title":"Configuration SSH et connexion","text":"<p>Apr\u00e8s la cr\u00e9ation de la machine virtuelle, l'acc\u00e8s SSH doit \u00eatre configur\u00e9. Azure permet d'utiliser soit des mots de passe, soit des cl\u00e9s publiques SSH pour l'authentification.</p> PowerShell<pre><code># G\u00e9n\u00e9ration d'une paire de cl\u00e9s SSH (sur la machine locale)\n# Sur Linux/Mac\nssh-keygen -t rsa -b 4096 -f ~/.ssh/id_rsa\n\n# R\u00e9cup\u00e9ration de l'adresse IP publique de la VM\n$publicIP = Get-AzPublicIpAddress -ResourceGroupName $resourceGroupName `\n    -Name \"myPublicIP\"\n$ipAddress = $publicIP.IpAddress\n\n# Connexion SSH \u00e0 la machine virtuelle\n# ssh azureuser@votre-adresse-ip-publique\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#connexion-depuis-un-terminal","title":"Connexion depuis un terminal","text":"Bash<pre><code># Connexion SSH basique avec mot de passe\nssh azureuser@&lt;adresse-ip-publique&gt;\n\n# Connexion SSH avec cl\u00e9 priv\u00e9e\nssh -i ~/.ssh/id_rsa azureuser@&lt;adresse-ip-publique&gt;\n</code></pre> <p>Une fois connect\u00e9, l'utilisateur acc\u00e8de \u00e0 un shell Linux avec les droits de l'utilisateur configur\u00e9. Pour effectuer des op\u00e9rations administratives, la commande <code>sudo</code> peut \u00eatre utilis\u00e9e.</p> Bash<pre><code># V\u00e9rification de la version du syst\u00e8me d'exploitation\nlsb_release -a\n\n# Mise \u00e0 jour des packages syst\u00e8me\nsudo apt update &amp;&amp; sudo apt upgrade -y\n\n# Installation d'outils suppl\u00e9mentaires\nsudo apt install -y curl wget git\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#creation-dune-premiere-vm-windows-et-connexion-rdp","title":"Cr\u00e9ation d'une Premi\u00e8re VM Windows et Connexion RDP","text":""},{"location":"_projects/_formation-azure/azure-chap05/#configuration-et-creation-dune-machine-virtuelle-windows","title":"Configuration et cr\u00e9ation d'une machine virtuelle Windows","text":"<p>La cr\u00e9ation d'une machine virtuelle Windows suit un processus similaire \u00e0 celui de Linux, mais avec des sp\u00e9cificit\u00e9s propres \u00e0 Windows et \u00e0 l'authentification RDP.</p>"},{"location":"_projects/_formation-azure/azure-chap05/#preparation-et-creation","title":"Pr\u00e9paration et cr\u00e9ation","text":"PowerShell<pre><code># Param\u00e8tres de la machine virtuelle Windows\n$vmName = \"myWindowsVM\"\n$computerName = \"winvm01\"\n$vmSize = \"Standard_B2s\"\n$resourceGroupName = \"myResourceGroup\"\n$location = \"EastUS\"\n\n# Cr\u00e9ation de la configuration de la VM\n$vmConfig = New-AzVMConfig -VMName $vmName -VMSize $vmSize\n\n# Configuration du syst\u00e8me d'exploitation Windows\n$adminUsername = \"azureuser\"\n$adminPassword = ConvertTo-SecureString \"Passw0rd123!\" -AsPlainText -Force\n$credential = New-Object System.Management.Automation.PSCredential($adminUsername, $adminPassword)\n\n$vmConfig = Set-AzVMOperatingSystem -VM $vmConfig -Windows -ComputerName $computerName `\n    -Credential $credential -ProvisionVMAgent -EnableAutoUpdate\n\n# S\u00e9lection de l'image Windows Server 2022\n$vmConfig = Set-AzVMSourceImage -VM $vmConfig -PublisherName \"MicrosoftWindowsServer\" `\n    -Offer \"WindowsServer\" -Skus \"2022-datacenter-azure-edition\" -Version \"latest\"\n\n# Configuration de la carte r\u00e9seau (r\u00e9utilisation de la config r\u00e9seau pr\u00e9c\u00e9dente)\n$nicConfig = Get-AzNetworkInterface -ResourceGroupName $resourceGroupName -Name \"myNIC-Windows\"\n$vmConfig = Add-AzVMNetworkInterface -VM $vmConfig -Id $nicConfig.Id\n\n# Cr\u00e9ation de la machine virtuelle\nNew-AzVM -ResourceGroupName $resourceGroupName -Location $location -VM $vmConfig\n\n# Configuration du groupe de s\u00e9curit\u00e9 r\u00e9seau pour RDP (port 3389)\n$nsgRuleRDP = New-AzNetworkSecurityRuleConfig -Name \"AllowRDP\" -Protocol Tcp `\n    -Direction Inbound -Priority 1000 -SourceAddressPrefix '*' -SourcePortRange '*' `\n    -DestinationAddressPrefix '*' -DestinationPortRange 3389 -Access Allow\n\n$nsg = New-AzNetworkSecurityGroup -ResourceGroupName $resourceGroupName `\n    -Location $location -Name \"myNSG\" -SecurityRules $nsgRuleRDP\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#connexion-rdp-a-la-machine-virtuelle-windows","title":"Connexion RDP \u00e0 la machine virtuelle Windows","text":"<p>Le protocole RDP (Remote Desktop Protocol) permet une connexion graphique \u00e0 la machine virtuelle Windows.</p> PowerShell<pre><code># R\u00e9cup\u00e9ration de l'adresse IP publique\n$publicIP = Get-AzPublicIpAddress -ResourceGroupName $resourceGroupName `\n    -Name \"myPublicIP-Windows\"\n$ipAddress = $publicIP.IpAddress\n\n# T\u00e9l\u00e9chargement du fichier RDP\nGet-AzRemoteDesktopFile -ResourceGroupName $resourceGroupName `\n    -Name $vmName -LocalPath \"C:\\temp\\myWindowsVM.rdp\"\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#utilisation-de-loutil-rdp-natif","title":"Utilisation de l'outil RDP natif","text":"<p>Sur Windows : Utiliser l'application \"Connexion Bureau \u00e0 distance\" : - Appuyer sur Win + R - Taper : <code>mstsc</code> - Entrer l'adresse IP publique de la VM - Fournir les identifiants : azureuser / Passw0rd123!</p> <p>Sur macOS et Linux : Utiliser un client RDP tiers comme Remmina ou Microsoft Remote Desktop</p> <p>Une fois connect\u00e9 au bureau Windows, tous les outils Windows standards sont disponibles (PowerShell, Gestionnaire des t\u00e2ches, Gestionnaire de fichiers, etc.).</p>"},{"location":"_projects/_formation-azure/azure-chap05/#mise-a-lechelle-automatique-virtual-machine-scale-sets","title":"Mise \u00e0 l'\u00c9chelle Automatique : Virtual Machine Scale Sets","text":""},{"location":"_projects/_formation-azure/azure-chap05/#concept-fondamental","title":"Concept fondamental","text":"<p>Les Virtual Machine Scale Sets (VMSS) repr\u00e9sentent une avanc\u00e9e significative dans la gestion de la scalabilit\u00e9 des applications. Contrairement \u00e0 la cr\u00e9ation manuelle de plusieurs machines virtuelles, un Scale Set automatise le d\u00e9ploiement, la configuration et la gestion d'un groupe de machines virtuelles identiques[1].</p> <p>Les Scale Sets utilisent la scalabilit\u00e9 horizontale pour distribuer automatiquement la charge \u00e0 travers un groupe de machines virtuelles. Cette approche garantit que les applications maintiennent des performances optimales m\u00eame lors de pics de charge impr\u00e9visibles[2].</p>"},{"location":"_projects/_formation-azure/azure-chap05/#architecture-et-composants","title":"Architecture et composants","text":"<p>Un Virtual Machine Scale Set se compose de plusieurs \u00e9l\u00e9ments interconnect\u00e9s :</p> <ul> <li>Instances de VM : Machines virtuelles identiques avec la m\u00eame configuration</li> <li>Profil de VM : D\u00e9finit l'image, la taille, la configuration r\u00e9seau et les extensions</li> <li>R\u00e8gles de mise \u00e0 l'\u00e9chelle : Crit\u00e8res d\u00e9terminant quand augmenter ou r\u00e9duire les instances</li> <li>\u00c9quilibreur de charge : Distribue le trafic entrant entre les instances</li> <li>Groupe de ressources : Conteneur logique pour toutes les ressources du Scale Set</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap05/#creation-dun-scale-set-via-powershell","title":"Cr\u00e9ation d'un Scale Set via PowerShell","text":"PowerShell<pre><code># Authentification et contexte\nConnect-AzAccount\nSet-AzContext -SubscriptionId \"votre-id-abonnement\"\n\n# Cr\u00e9ation du groupe de ressources\n$resourceGroupName = \"myResourceGroup\"\n$location = \"EastUS\"\nNew-AzResourceGroup -Name $resourceGroupName -Location $location\n\n# Configuration des identifiants\n$cred = Get-Credential\n\n# Cr\u00e9ation du Scale Set avec configuration de base\nNew-AzVmss `\n  -ResourceGroupName $resourceGroupName `\n  -VMScaleSetName \"myScaleSet\" `\n  -OrchestrationMode \"Flexible\" `\n  -VMSize \"Standard_B2s\" `\n  -Location $location `\n  -Credential $cred\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#modification-de-la-capacite-du-scale-set","title":"Modification de la capacit\u00e9 du Scale Set","text":"<p>La capacit\u00e9 d'un Scale Set d\u00e9termine le nombre d'instances d\u00e9ploy\u00e9es. Cette valeur peut \u00eatre augment\u00e9e ou diminu\u00e9e selon les besoins[1].</p> PowerShell<pre><code># R\u00e9cup\u00e9ration du Scale Set existant\n$vmss = Get-AzVmss -ResourceGroupName $resourceGroupName -VMScaleSetName \"myScaleSet\"\n\n# Augmentation de la capacit\u00e9 \u00e0 3 instances\n$vmss.sku.capacity = 3\nUpdate-AzVmss -ResourceGroupName $resourceGroupName -Name \"myScaleSet\" `\n  -VirtualMachineScaleSet $vmss\n\n# V\u00e9rification de la nouvelle capacit\u00e9\nGet-AzVmss -ResourceGroupName $resourceGroupName -VMScaleSetName \"myScaleSet\" | \n  Select-Object -ExpandProperty Sku\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#gestion-du-demarrage-et-arret","title":"Gestion du d\u00e9marrage et arr\u00eat","text":"PowerShell<pre><code># D\u00e9marrage de toutes les instances du Scale Set\nStart-AzVmss -ResourceGroupName $resourceGroupName -VMScaleSetName \"myScaleSet\"\n\n# Arr\u00eat de toutes les instances\nStop-AzVmss -ResourceGroupName $resourceGroupName -VMScaleSetName \"myScaleSet\"\n\n# D\u00e9marrage d'une instance sp\u00e9cifique\nStart-AzVM -ResourceGroupName $resourceGroupName -Name \"myScaleSet_0\"\n\n# Arr\u00eat d'une instance sp\u00e9cifique\nStop-AzVM -ResourceGroupName $resourceGroupName -Name \"myScaleSet_0\"\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#regles-de-mise-a-lechelle-automatique","title":"R\u00e8gles de mise \u00e0 l'\u00e9chelle automatique","text":"<p>Les r\u00e8gles de mise \u00e0 l'\u00e9chelle automatique permettent au Scale Set d'ajuster le nombre d'instances en fonction de m\u00e9triques comme l'utilisation CPU ou la m\u00e9moire[2].</p> PowerShell<pre><code># Cr\u00e9ation d'une configuration de mise \u00e0 l'\u00e9chelle automatique\n$autoscaleConfig = New-AzAutoscaleNotification -EmailCustom `\n  -SendEmailToSubscriptionAdministrator\n\n# D\u00e9finition des seuils de mise \u00e0 l'\u00e9chelle\n# Augmentation : &gt; 70% CPU pendant 5 minutes\n# R\u00e9duction : &lt; 30% CPU pendant 10 minutes\n$scaleRuleUp = New-AzAutoscaleRule -MetricName \"Percentage CPU\" `\n  -MetricResourceId \"/subscriptions/votre-id/resourceGroups/$resourceGroupName/providers/Microsoft.Compute/virtualMachineScaleSets/myScaleSet\" `\n  -Operator GreaterThan -MetricStatistic Average -Threshold 70 `\n  -TimeGrain 00:01:00 -TimeWindow 00:05:00 `\n  -ScaleActionDirection Increase -ScaleActionScaleType ChangeCount -ScaleActionValue 1\n\n$scaleRuleDown = New-AzAutoscaleRule -MetricName \"Percentage CPU\" `\n  -MetricResourceId \"/subscriptions/votre-id/resourceGroups/$resourceGroupName/providers/Microsoft.Compute/virtualMachineScaleSets/myScaleSet\" `\n  -Operator LessThan -MetricStatistic Average -Threshold 30 `\n  -TimeGrain 00:01:00 -TimeWindow 00:10:00 `\n  -ScaleActionDirection Decrease -ScaleActionScaleType ChangeCount -ScaleActionValue 1\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#garantir-la-haute-disponibilite-availability-sets","title":"Garantir la Haute Disponibilit\u00e9 : Availability Sets","text":""},{"location":"_projects/_formation-azure/azure-chap05/#principes-de-haute-disponibilite","title":"Principes de haute disponibilit\u00e9","text":"<p>Les Availability Sets constituent une approche fondamentale pour assurer la continuit\u00e9 de service des applications critiques. Contrairement \u00e0 un d\u00e9ploiement concentr\u00e9 sur une seule machine physique, un Availability Set distribue les instances de machines virtuelles sur plusieurs domaines de d\u00e9faillance et domaines de mise \u00e0 jour, minimisant ainsi les risques d'interruption de service[1].</p>"},{"location":"_projects/_formation-azure/azure-chap05/#domaines-de-defaillance-et-mise-a-jour","title":"Domaines de d\u00e9faillance et mise \u00e0 jour","text":"<p>Domaines de d\u00e9faillance : Chaque Availability Set inclut jusqu'\u00e0 3 domaines de d\u00e9faillance, chacun repr\u00e9sentant une unit\u00e9 de mat\u00e9riel physique ind\u00e9pendante. En cas de d\u00e9faillance d'une unit\u00e9, les machines virtuelles dans d'autres domaines continuent de fonctionner sans interruption.</p> <p>Domaines de mise \u00e0 jour : Azure divise \u00e9galement les instances en domaines de mise \u00e0 jour (jusqu'\u00e0 20). Lors de mises \u00e0 jour syst\u00e8me, Azure met \u00e0 jour s\u00e9quentiellement un domaine \u00e0 la fois, assurant qu'au moins une partie de l'application reste disponible.</p>"},{"location":"_projects/_formation-azure/azure-chap05/#creation-et-configuration-dun-availability-set","title":"Cr\u00e9ation et configuration d'un Availability Set","text":"PowerShell<pre><code># Cr\u00e9ation d'un Availability Set\n$availabilitySet = New-AzAvailabilitySet `\n  -ResourceGroupName $resourceGroupName `\n  -Name \"myAvailabilitySet\" `\n  -Location $location `\n  -PlatformFaultDomainCount 3 `\n  -PlatformUpdateDomainCount 5\n\n# Cr\u00e9ation de machines virtuelles dans l'Availability Set\n$vm1Config = New-AzVMConfig -VMName \"myVM1\" -VMSize \"Standard_B2s\"\n$vm1Config = Set-AzVMOperatingSystem -VM $vm1Config -Windows `\n  -ComputerName \"vm1\" -Credential $credential -ProvisionVMAgent -EnableAutoUpdate\n$vm1Config = Set-AzVMSourceImage -VM $vm1Config -PublisherName \"MicrosoftWindowsServer\" `\n  -Offer \"WindowsServer\" -Skus \"2022-datacenter-azure-edition\" -Version \"latest\"\n\n# Association au groupe de disponibilit\u00e9\n$vm1Config = New-AzVMConfig -VMName \"myVM1\" -VMSize \"Standard_B2s\" `\n  -AvailabilitySetId $availabilitySet.Id\n\n# Cr\u00e9ation des autres VMs de mani\u00e8re similaire\nNew-AzVM -ResourceGroupName $resourceGroupName -Location $location -VM $vm1Config\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#comparaison-availability-sets-vs-zones-de-disponibilite","title":"Comparaison : Availability Sets vs Zones de disponibilit\u00e9","text":"Aspect Availability Set Zone de disponibilit\u00e9 Isolation Domaines au sein d'un datacenter Datacenters g\u00e9ographiquement s\u00e9par\u00e9s D\u00e9faillances Pannes mat\u00e9rielles locales D\u00e9faillances de datacenter complet Latence r\u00e9seau Tr\u00e8s faible (&lt; 1ms) Faible (&lt; 2ms) Co\u00fbts de transfer Gratuit Frais applicables Utilisation Applications critiques standard Applications ultra-critiques"},{"location":"_projects/_formation-azure/azure-chap05/#introduction-a-azure-virtual-desktop-avd","title":"Introduction \u00e0 Azure Virtual Desktop (AVD)","text":""},{"location":"_projects/_formation-azure/azure-chap05/#vue-densemble_1","title":"Vue d'ensemble","text":"<p>Azure Virtual Desktop (AVD) constitue une solution compl\u00e8te de virtualisation de bureau fournie par Microsoft, permettant aux organisations de d\u00e9ployer des environnements de bureau Windows s\u00e9curis\u00e9s et scalables dans le cloud[1]. Cette approche \u00e9limine les limitations des solutions traditionnelles de Remote Desktop Protocol en offrant une exp\u00e9rience utilisateur optimis\u00e9e et une gestion simplifi\u00e9e.</p>"},{"location":"_projects/_formation-azure/azure-chap05/#architecture-davd","title":"Architecture d'AVD","text":"<p>Une impl\u00e9mentation Azure Virtual Desktop repose sur plusieurs composants essentiels :</p> <ul> <li>Environnement h\u00f4te de session : Serveurs ex\u00e9cutant Windows 10 Enterprise multi-session ou Windows 11</li> <li>Pools d'h\u00f4tes : Groupements logiques d'h\u00f4tes de session</li> <li>Espace de travail : Point d'acc\u00e8s pour les utilisateurs aux ressources de bureau</li> <li>Application groups : Collections d'applications disponibles pour les utilisateurs</li> <li>Infrastructure r\u00e9seau : R\u00e9seaux virtuels s\u00e9curis\u00e9s et connexions directes</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap05/#avantages-principales-davd","title":"Avantages principales d'AVD","text":"<p>Scalabilit\u00e9 \u00e9lastique : L'infrastructure peut augmenter ou r\u00e9duire dynamiquement en fonction des utilisateurs connect\u00e9s, optimisant les co\u00fbts \u00e9nerg\u00e9tiques et r\u00e9duisant les d\u00e9penses d'exploitation.</p> <p>Acc\u00e8s multi-appareil : Les utilisateurs peuvent acc\u00e9der \u00e0 leurs environnements de bureau depuis n'importe quel appareil (ordinateur, tablette, smartphone) via des clients l\u00e9gers ou des navigateurs web.</p> <p>S\u00e9curit\u00e9 renforc\u00e9e : Toutes les donn\u00e9es restent dans le datacenter Azure, les appareils locaux ne stockent que des donn\u00e9es d'affichage. L'authentification multi-facteurs et l'acc\u00e8s conditionnel renforcent la s\u00e9curit\u00e9.</p> <p>Licences optimis\u00e9es : Les abonnements Microsoft 365 ou Windows existants couvrent souvent les co\u00fbts de licence AVD, r\u00e9duisant les investissements suppl\u00e9mentaires.</p>"},{"location":"_projects/_formation-azure/azure-chap05/#cas-dusage-courants","title":"Cas d'usage courants","text":"<ul> <li>Travail hybride : Fournir un environnement de bureau coh\u00e9rent pour les employ\u00e9s distants et au bureau</li> <li>Environnements de d\u00e9veloppement : Offrir des environnements standardis\u00e9s et isol\u00e9s pour les d\u00e9veloppeurs</li> <li>Acc\u00e8s s\u00e9curis\u00e9 pour contractants : Fournir un acc\u00e8s temporaire et contr\u00f4l\u00e9 sans installer de logiciels localement</li> <li>Applications graphiquement intensives : Ex\u00e9cuter des applications 3D ou de cr\u00e9ation multim\u00e9dia sur du mat\u00e9riel puissant dans le cloud</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap05/#heberger-des-applications-web-avec-azure-app-service","title":"H\u00e9berger des Applications Web avec Azure App Service","text":""},{"location":"_projects/_formation-azure/azure-chap05/#concept-fondamental_1","title":"Concept fondamental","text":"<p>Azure App Service repr\u00e9sente une plateforme d'h\u00e9bergement enti\u00e8rement manag\u00e9e pour construire et h\u00e9berger des applications web, des API REST et des backends mobiles. Contrairement aux machines virtuelles, App Service abstrait la complexit\u00e9 de gestion de l'infrastructure sous-jacente, permettant aux d\u00e9veloppeurs de se concentrer exclusivement sur le code applicatif[1].</p>"},{"location":"_projects/_formation-azure/azure-chap05/#caracteristiques-principales_1","title":"Caract\u00e9ristiques principales","text":"<p>Gestion automatique de l'infrastructure : Azure g\u00e8re enti\u00e8rement la mise \u00e0 jour du syst\u00e8me d'exploitation, les correctifs de s\u00e9curit\u00e9 et la maintenance du serveur web. Les d\u00e9veloppeurs n'interviennent jamais \u00e0 ce niveau.</p> <p>Support multi-langage : App Service supporte nativement .NET, Java, Python, Node.js, PHP, Ruby et Go, permettant une flexibilit\u00e9 technologique consid\u00e9rable.</p> <p>D\u00e9ploiement continu : Int\u00e9gration native avec les d\u00e9p\u00f4ts Git (GitHub, Azure Repos, Bitbucket), permettant un d\u00e9ploiement automatique \u00e0 chaque commit.</p> <p>Scalabilit\u00e9 int\u00e9gr\u00e9e : La plateforme supporte l'auto-scaling horizontal automatique en fonction de m\u00e9triques d\u00e9finies par l'utilisateur.</p>"},{"location":"_projects/_formation-azure/azure-chap05/#plans-app-service-disponibles","title":"Plans App Service disponibles","text":"Plan Description Utilisation Free Partage de ressources, limites strictes D\u00e9veloppement, prototypage Shared Toujours partage, plus de ressources que Free Applications l\u00e9g\u00e8res Basic Calcul d\u00e9di\u00e9, pas d'auto-scaling D\u00e9veloppement, small business Standard Auto-scaling, SSL gratuit Applications de production Premium Environnements isol\u00e9s, hautes performances Applications critiques Isolated Environnement d\u00e9di\u00e9 complet Applications n\u00e9cessitant isolation"},{"location":"_projects/_formation-azure/azure-chap05/#architecture-dapp-service","title":"Architecture d'App Service","text":"<p>Un Plan App Service fournit des ressources de calcul partag\u00e9es entre plusieurs App Services. Plusieurs applications peuvent \u00eatre h\u00e9berg\u00e9es sur un m\u00eame plan, r\u00e9duisant les co\u00fbts. Chaque App Service dispose de son propre espace de noms d'application.</p> Text Only<pre><code>Plan App Service (ressources de calcul partag\u00e9es)\n\u251c\u2500\u2500 Web App 1 (exemple.azurewebsites.net)\n\u251c\u2500\u2500 Web App 2 (exemple2.azurewebsites.net)\n\u2514\u2500\u2500 Web App 3 (exemple3.azurewebsites.net)\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#creer-une-application-web-sur-app-service","title":"Cr\u00e9er une Application Web sur App Service","text":""},{"location":"_projects/_formation-azure/azure-chap05/#creation-via-azure-powershell","title":"Cr\u00e9ation via Azure PowerShell","text":"<p>La cr\u00e9ation d'une premi\u00e8re application web constitue l'\u00e9tape essentielle pour d\u00e9marrer avec la plateforme App Service.</p> PowerShell<pre><code># Authentification\nConnect-AzAccount\n\n# Configuration de base\n$resourceGroupName = \"myResourceGroup\"\n$appServicePlanName = \"myAppServicePlan\"\n$webAppName = \"mywebapp\" # Doit \u00eatre globalement unique\n$location = \"EastUS\"\n\n# Cr\u00e9ation du groupe de ressources\nNew-AzResourceGroup -Name $resourceGroupName -Location $location\n\n# Cr\u00e9ation du plan App Service\n$appServicePlan = New-AzAppServicePlan `\n  -ResourceGroupName $resourceGroupName `\n  -Name $appServicePlanName `\n  -Location $location `\n  -Tier \"Standard\" `\n  -WorkerSize \"Small\" `\n  -NumberofWorkers 1\n\n# Cr\u00e9ation de l'application web\n$webApp = New-AzWebApp `\n  -ResourceGroupName $resourceGroupName `\n  -Name $webAppName `\n  -AppServicePlan $appServicePlan\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#deploiement-du-code-source","title":"D\u00e9ploiement du code source","text":"PowerShell<pre><code># Configuration du d\u00e9ploiement Git local\n$publishingProfile = Get-AzWebAppPublishingProfile `\n  -ResourceGroupName $resourceGroupName `\n  -Name $webAppName `\n  -OutputFile \"publishingprofile.xml\"\n\n# Alternative : D\u00e9ploiement via ZIP\n$sourceCodePath = \"C:\\MonApplicationWeb\\*\"\n$zipPath = \"C:\\temp\\app.zip\"\n\n# Compression du code source\nCompress-Archive -Path $sourceCodePath -DestinationPath $zipPath -Force\n\n# Upload via API\n$resourceId = (Get-AzWebApp -ResourceGroupName $resourceGroupName -Name $webAppName).Id\nPublish-AzWebapp -ResourceGroupName $resourceGroupName -Name $webAppName `\n  -ArchivePath $zipPath\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#configuration-des-parametres-dapplication","title":"Configuration des param\u00e8tres d'application","text":"PowerShell<pre><code># D\u00e9finition de variables d'environnement (App Settings)\n$appSettings = @{\n  \"WEBSITE_NODE_DEFAULT_VERSION\" = \"16.13.0\"\n  \"DATABASE_CONNECTION_STRING\" = \"Server=myserver;Database=mydb\"\n  \"API_KEY\" = \"secret-key-value\"\n}\n\nSet-AzWebApp -ResourceGroupName $resourceGroupName -Name $webAppName `\n  -AppSettings $appSettings\n\n# Configuration des param\u00e8tres de connexion\n$connectionStrings = @{\n  \"DefaultConnection\" = @{\n    \"Value\" = \"Server=myserver;Database=mydb;User=admin;Password=secret;\"\n    \"Type\" = \"SQLServer\"\n  }\n}\n\n# Note : La d\u00e9finition des connection strings n\u00e9cessite l'utilisation du portail\n# ou d'API REST sp\u00e9cifiques\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#activation-de-https-et-certificats-ssl","title":"Activation de HTTPS et certificats SSL","text":"PowerShell<pre><code># R\u00e9cup\u00e9ration du domaine par d\u00e9faut Azure\n$defaultDomain = Get-AzWebApp -ResourceGroupName $resourceGroupName `\n  -Name $webAppName | Select-Object -ExpandProperty DefaultHostName\n\n# Activation du HTTPS minimum TLS 1.2\nSet-AzWebApp -ResourceGroupName $resourceGroupName -Name $webAppName `\n  -MinTlsVersion \"1.2\"\n\n# Import d'un certificat personnalis\u00e9 (si disponible)\n# N\u00e9cessite un certificat PFX pr\u00e9-achet\u00e9\n$certPath = \"C:\\certs\\mycertificate.pfx\"\n$certPassword = ConvertTo-SecureString \"CertPassword123!\" -AsPlainText -Force\n\nNew-AzWebAppSSLBinding -ResourceGroupName $resourceGroupName `\n  -WebAppName $webAppName -CertificateFilePath $certPath `\n  -CertificatePassword $certPassword -Name \"www.mondomaine.com\"\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#monitoring-et-diagnostics","title":"Monitoring et diagnostics","text":"PowerShell<pre><code># Activation des logs d'application\nSet-AzAppServicePlanConfig -ResourceGroupName $resourceGroupName `\n  -Name $appServicePlanName -NumberofWorkers 2\n\n# Configuration des diagnostics\n$diagnostics = New-AzWebAppDiagnosticSetting `\n  -ResourceGroupName $resourceGroupName `\n  -Name $webAppName `\n  -ApplicationLogging $true `\n  -WebServerLogging $true `\n  -DetailedErrorMessages $true `\n  -FailedRequestTracing $true\n\n# R\u00e9cup\u00e9ration des logs\nGet-AzWebAppLog -ResourceGroupName $resourceGroupName -Name $webAppName `\n  -Tail 100\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#le-calcul-serverless-avec-azure-functions","title":"Le Calcul Serverless avec Azure Functions","text":""},{"location":"_projects/_formation-azure/azure-chap05/#concept-du-serverless","title":"Concept du serverless","text":"<p>Azure Functions incarne la philosophie serverless en abstrayant compl\u00e8tement la gestion de l'infrastructure. Les d\u00e9veloppeurs \u00e9crivent uniquement les fonctions m\u00e9tier sans se pr\u00e9occuper des serveurs sous-jacents, de la scalabilit\u00e9 ou de la gestion des patchs syst\u00e8me. Azure g\u00e8re automatiquement l'allocation des ressources, la scalabilit\u00e9 horizontale et la facturation \u00e0 la milliseconde pr\u00e8s[1].</p>"},{"location":"_projects/_formation-azure/azure-chap05/#avantages-du-modele-serverless","title":"Avantages du mod\u00e8le serverless","text":"<p>Scalabilit\u00e9 transparente : Les fonctions s'adaptent automatiquement du n\u00e9ant \u00e0 des milliers d'ex\u00e9cutions parall\u00e8les sans intervention manuelle. Le co\u00fbts suit exactement l'utilisation r\u00e9elle.</p> <p>Co\u00fbts optimis\u00e9s : Facturation uniquement au moment de l'ex\u00e9cution effective. Pour les charges de travail intermittentes ou impr\u00e9visibles, les \u00e9conomies peuvent atteindre 90% par rapport aux architectures traditionnelles.</p> <p>R\u00e9duction de la complexit\u00e9 op\u00e9rationnelle : \u00c9limination compl\u00e8te des t\u00e2ches d'administration syst\u00e8me. Les d\u00e9veloppeurs ne g\u00e8rent que le code et la configuration m\u00e9tier.</p> <p>D\u00e9ploiement rapide : Les fonctions peuvent \u00eatre d\u00e9ploy\u00e9es en secondes depuis un \u00e9diteur en ligne ou via des outils de d\u00e9veloppement standard.</p>"},{"location":"_projects/_formation-azure/azure-chap05/#modeles-de-declenchement","title":"Mod\u00e8les de d\u00e9clenchement","text":"<p>Azure Functions supporte une diversit\u00e9 de d\u00e9clencheurs permettant l'invocation selon diff\u00e9rents contextes :</p> D\u00e9clencheur Cas d'usage Exemple HTTP API REST, webhooks Traitement de requ\u00eates web Timer T\u00e2ches planifi\u00e9es Nettoyage de bases de donn\u00e9es Storage Queue Traitement asynchrone Traitement de fichiers upload\u00e9s Service Bus Int\u00e9gration d'applications Processus m\u00e9tier distribu\u00e9s Event Grid \u00c9v\u00e9nements syst\u00e8me Notifications d'\u00e9v\u00e9nements Cosmos DB R\u00e9activit\u00e9 aux changements Synchronisation de donn\u00e9es Blob Storage R\u00e9action aux modifications Traitement d'images"},{"location":"_projects/_formation-azure/azure-chap05/#creation-dune-fonction-azure-simple","title":"Cr\u00e9ation d'une fonction Azure simple","text":"PowerShell<pre><code># Authentification et setup\nConnect-AzAccount\n\n$resourceGroupName = \"myResourceGroup\"\n$functionAppName = \"myfunctionapp\"\n$storageAccountName = \"myfunctionstg\"\n$location = \"EastUS\"\n\n# Cr\u00e9ation du groupe de ressources\nNew-AzResourceGroup -Name $resourceGroupName -Location $location\n\n# Cr\u00e9ation du compte de stockage (obligatoire pour les Functions)\n$storageAccount = New-AzStorageAccount `\n  -ResourceGroupName $resourceGroupName `\n  -Name $storageAccountName `\n  -SkuName \"Standard_LRS\" `\n  -Location $location\n\n# Cr\u00e9ation du plan de Function App (Consumption = serverless)\n$functionApp = New-AzFunctionApp `\n  -ResourceGroupName $resourceGroupName `\n  -Name $functionAppName `\n  -StorageAccountName $storageAccountName `\n  -Runtime \"PowerShell\" `\n  -RuntimeVersion \"7.2\" `\n  -Location $location `\n  -FunctionsVersion 4\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#exemple-de-fonction-http-en-c","title":"Exemple de fonction HTTP en C","text":"C#<pre><code>using System.Net;\nusing Microsoft.Azure.Functions.Worker;\nusing Microsoft.Azure.Functions.Worker.Http;\nusing Microsoft.Extensions.Logging;\n\npublic static class HttpTriggerFunction\n{\n    [Function(\"HttpTrigger\")]\n    public static HttpResponseData Run(\n        [HttpTrigger(AuthorizationLevel.Anonymous, \"get\", \"post\", Route = null)]\n        HttpRequestData req,\n        FunctionContext executionContext)\n    {\n        var logger = executionContext.GetLogger(\"HttpTrigger\");\n        logger.LogInformation(\"Fonction HTTP d\u00e9clench\u00e9e\");\n\n        // R\u00e9cup\u00e9ration des param\u00e8tres\n        string name = req.Query.GetValues(\"name\").FirstOrDefault() ?? \"World\";\n\n        // Cr\u00e9ation de la r\u00e9ponse\n        var response = req.CreateResponse(HttpStatusCode.OK);\n        response.Headers.Add(\"Content-Type\", \"text/plain; charset=utf-8\");\n        response.WriteString($\"Hello, {name}!\");\n\n        return response;\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#exemple-de-fonction-avec-declencheur-timer","title":"Exemple de fonction avec d\u00e9clencheur Timer","text":"C#<pre><code>using System;\nusing Microsoft.Azure.Functions.Worker;\nusing Microsoft.Extensions.Logging;\n\npublic static class TimerTriggerFunction\n{\n    [Function(\"TimerTrigger\")]\n    public static void Run(\n        [TimerTrigger(\"0 */5 * * * *\")] TimerInfo myTimer,\n        FunctionContext context)\n    {\n        var logger = context.GetLogger(\"TimerTrigger\");\n\n        if (myTimer. isPastDue)\n        {\n            logger.LogWarning(\"La fonction a d\u00e9pass\u00e9 l'horaire pr\u00e9vu\");\n        }\n\n        logger.LogInformation($\"Ex\u00e9cution \u00e0 : {DateTime.Now}\");\n        // Logique m\u00e9tier : nettoyage de base de donn\u00e9es, envoi de rapport, etc.\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#integration-avec-dautres-services-azure","title":"Int\u00e9gration avec d'autres services Azure","text":"C#<pre><code>using Microsoft.Azure.Functions.Worker;\nusing Microsoft.Azure.Cosmos.Table;\nusing Microsoft.Extensions.Logging;\n\npublic static class QueueTriggerFunction\n{\n    [Function(\"ProcessQueueMessage\")]\n    public static async Task Run(\n        [QueueTrigger(\"myqueue-items\")] string queueItem,\n        [Table(\"ProcessedItems\")] IAsyncCollector&lt;ProcessedItem&gt; outputTable,\n        ILogger log)\n    {\n        log.LogInformation($\"Message trait\u00e9 : {queueItem}\");\n\n        // Traitement du message\n        var processedItem = new ProcessedItem \n        { \n            PartitionKey = \"processed\",\n            RowKey = Guid.NewGuid().ToString(),\n            Message = queueItem,\n            ProcessedTime = DateTime.UtcNow\n        };\n\n        // Sauvegarde en Table Storage\n        await outputTable.AddAsync(processedItem);\n    }\n}\n\npublic class ProcessedItem : TableEntity\n{\n    public string Message { get; set; }\n    public DateTime ProcessedTime { get; set; }\n}\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#introduction-aux-conteneurs","title":"Introduction aux Conteneurs","text":""},{"location":"_projects/_formation-azure/azure-chap05/#concept-des-conteneurs","title":"Concept des conteneurs","text":"<p>Les conteneurs repr\u00e9sentent une r\u00e9volution dans le d\u00e9ploiement et la gestion des applications. Contrairement aux machines virtuelles qui virtualisent le mat\u00e9riel complet, les conteneurs virtualisent uniquement le syst\u00e8me d'exploitation, ce qui les rend extr\u00eamement l\u00e9gers et portables[1].</p> <p>Un conteneur encapsule compl\u00e8tement une application avec ses d\u00e9pendances, biblioth\u00e8ques et configurations. Cette encapsulation garantit que l'application fonctionne de mani\u00e8re identique quel que soit l'environnement d'ex\u00e9cution (ordinateur portable du d\u00e9veloppeur, serveur de test, production).</p>"},{"location":"_projects/_formation-azure/azure-chap05/#avantages-des-conteneurs","title":"Avantages des conteneurs","text":"<p>L\u00e9g\u00e8ret\u00e9 : Un conteneur Docker typique occupe 50 \u00e0 100 MB, compar\u00e9 \u00e0 1 \u00e0 10 GB pour une machine virtuelle. Cela permet d'empiler des centaines de conteneurs sur une m\u00eame infrastructure.</p> <p>Portabilit\u00e9 : Construire une fois, ex\u00e9cuter n'importe o\u00f9. Un conteneur fonctionne identiquement sur un ordinateur personnel, un serveur on-premises ou le cloud Azure.</p> <p>D\u00e9ploiement rapide : Les conteneurs d\u00e9marrent en millisecondes compar\u00e9 aux secondes ou minutes n\u00e9cessaires \u00e0 une machine virtuelle.</p> <p>Isolation des processus : Chaque conteneur ex\u00e9cute ses propres processus, fichiers et r\u00e9seau, sans interf\u00e9rer avec les autres conteneurs.</p>"},{"location":"_projects/_formation-azure/azure-chap05/#comparaison-architecturale","title":"Comparaison architecturale","text":"Text Only<pre><code>Architecture Machine Virtuelle :\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Hyperviseur (VMware, Hyper-V, KVM)      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Syst\u00e8me Linux  \u2502 Syst\u00e8me Linux  \u2502  Win  \u2502\n\u2502 Application A  \u2502 Application B  \u2502  Sys  \u2502\n\u2502 D\u00e9pendances    \u2502 D\u00e9pendances    \u2502 Deps  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nArchitecture Conteneur :\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Moteur Conteneur (Docker, etc)   \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 App A \u2502 App B \u2502 App C \u2502   App D  \u2502\n\u2502 Deps  \u2502 Deps  \u2502 Deps  \u2502   Deps   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n(Tous partagent le noyau Linux)\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#solutions-de-conteneurs-azure","title":"Solutions de conteneurs Azure","text":"<p>Azure propose plusieurs services pour ex\u00e9cuter et orchestrer des conteneurs :</p> <p>Azure Container Instances (ACI) : Ex\u00e9cution simple de conteneurs sans orchestration complexe. Id\u00e9al pour les t\u00e2ches ponctuelles ou les applications simples.</p> <p>Azure Kubernetes Service (AKS) : Orchestration de conteneurs \u00e0 grande \u00e9chelle avec Kubernetes. G\u00e8re automatiquement le d\u00e9ploiement, la scalabilit\u00e9 et la mise en r\u00e9seau de centaines ou milliers de conteneurs.</p> <p>App Service for Containers : H\u00e9bergement de conteneurs via App Service, combinant la simplicit\u00e9 d'App Service avec la flexibilit\u00e9 des conteneurs.</p> <p>Azure Container Registry : Registre priv\u00e9 pour stocker et g\u00e9rer les images conteneur, similaire \u00e0 Docker Hub mais avec contr\u00f4le complet et s\u00e9curit\u00e9 am\u00e9lior\u00e9e.</p>"},{"location":"_projects/_formation-azure/azure-chap05/#exemple-dockerfile","title":"Exemple Dockerfile","text":"<p>Un Dockerfile d\u00e9crit les couches constituant une image conteneur :</p> Docker<pre><code># Image de base\nFROM mcr.microsoft.com/windows/servercore:ltsc2022\n\n# D\u00e9finition du r\u00e9pertoire de travail\nWORKDIR /app\n\n# Copie des fichiers d'application\nCOPY ./bin/Release/net6.0/publish/ .\n\n# Configuration du point d'entr\u00e9e\nENTRYPOINT [\"dotnet\", \"MyApplication.dll\"]\n\n# Exposition du port\nEXPOSE 80\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#deploiement-sur-azure-container-instances","title":"D\u00e9ploiement sur Azure Container Instances","text":"PowerShell<pre><code># Authentification\nConnect-AzAccount\n\n# Param\u00e8tres\n$resourceGroupName = \"myResourceGroup\"\n$containerGroupName = \"mycontainergroup\"\n$imageName = \"myregistry.azurecr.io/myapp:latest\"\n$location = \"EastUS\"\n\n# Cr\u00e9ation du groupe de ressources\nNew-AzResourceGroup -Name $resourceGroupName -Location $location\n\n# D\u00e9ploiement du conteneur\n$container = New-AzContainerInstanceObject `\n  -Name \"mycontainer\" `\n  -Image $imageName `\n  -RequestCpu 1 `\n  -RequestMemoryInGb 1.5 `\n  -Port 80\n\nNew-AzContainerGroup `\n  -ResourceGroupName $resourceGroupName `\n  -Name $containerGroupName `\n  -Container $container `\n  -OsType Linux `\n  -IpAddressType Public\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#deploiement-sur-azure-kubernetes-service-aks","title":"D\u00e9ploiement sur Azure Kubernetes Service (AKS)","text":"PowerShell<pre><code># Cr\u00e9ation d'un cluster AKS\n$clusterName = \"myAKSCluster\"\n$nodeCount = 3\n\nNew-AzAksCluster `\n  -ResourceGroupName $resourceGroupName `\n  -Name $clusterName `\n  -NodeCount $nodeCount `\n  -VmSetType \"VirtualMachineScaleSets\" `\n  -NetworkPlugin \"azure\"\n\n# R\u00e9cup\u00e9ration des credentials\nGet-AzAksCluster -ResourceGroupName $resourceGroupName -Name $clusterName |\n  Import-AzAksCredential -Force\n\n# V\u00e9rification du cluster\nkubectl get nodes\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#fichier-de-deploiement-kubernetes-yaml","title":"Fichier de d\u00e9ploiement Kubernetes (YAML)","text":"YAML<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: myapp-deployment\n  labels:\n    app: myapp\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: myapp\n  template:\n    metadata:\n      labels:\n        app: myapp\n    spec:\n      containers:\n      - name: myapp\n        image: myregistry.azurecr.io/myapp:v1\n        ports:\n        - containerPort: 80\n        resources:\n          requests:\n            cpu: \"100m\"\n            memory: \"128Mi\"\n          limits:\n            cpu: \"500m\"\n            memory: \"512Mi\"\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: myapp-service\nspec:\n  selector:\n    app: myapp\n  ports:\n  - protocol: TCP\n    port: 80\n    targetPort: 80\n  type: LoadBalancer\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap05/#resume-du-chemin-dapprentissage","title":"R\u00e9sum\u00e9 du Chemin d'Apprentissage","text":"<p>Le parcours d'apprentissage des services de calcul Azure progresse logiquement de l'infrastructure fondamentale vers les abstractions de plus haut niveau :</p> <ol> <li> <p>Fondations : Les Machines Virtuelles offrent le contr\u00f4le total et constituent le point de d\u00e9part pour comprendre l'infrastructure cloud.</p> </li> <li> <p>Scalabilit\u00e9 : Les Virtual Machine Scale Sets introduisent l'automatisation et la gestion de multiples instances, essentiels pour les applications modernes.</p> </li> <li> <p>Haute disponibilit\u00e9 : Les Availability Sets et les Zones de disponibilit\u00e9 garantissent la continuit\u00e9 de service sans interruption.</p> </li> <li> <p>Abstractions manag\u00e9es : Azure App Service et Azure Virtual Desktop masquent la complexit\u00e9 infrastructure en proposant des services enti\u00e8rement manag\u00e9s.</p> </li> <li> <p>Sans serveur : Azure Functions repr\u00e9sente le degr\u00e9 d'abstraction maximal, permettant de coder sans penser \u00e0 l'infrastructure.</p> </li> <li> <p>Conteneurisation : Les conteneurs et Kubernetes (AKS) introduisent la portabilit\u00e9 et la flexibilit\u00e9 de d\u00e9ploiement.</p> </li> </ol> <p>Ce parcours pr\u00e9pare les architectes et d\u00e9veloppeurs \u00e0 choisir la solution optimale selon les besoins sp\u00e9cifiques de chaque application et charge de travail[1][2][3].</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure/azure-chap06/","title":"Citations","text":"<ul> <li>https://learn.microsoft.com/fr-fr/azure/app-service/overview-name-resolution</li> <li>https://learn.microsoft.com/fr-fr/purview/data-gov-classic-private-link-name-resolution</li> <li>https://learn.microsoft.com/fr-fr/azure/firewall/dns-settings</li> <li>https://learn.microsoft.com/fr-fr/azure/virtual-network/virtual-networks-name-resolution-for-vms-and-role-instances</li> <li>https://blog.cellenza.com/cloud-2/azure-private-dns-resolver-optimiser-la-resolution-dns-dans-un-environnement-azure/</li> <li>https://www.youtube.com/watch?v=aT5f3S0I6Yg</li> <li>https://learn.microsoft.com/fr-fr/azure/architecture/networking/architecture/azure-dns-private-resolver</li> <li>https://learn.microsoft.com/fr-fr/azure/application-gateway/application-gateway-dns-resolution</li> <li>https://learn.microsoft.com/fr-fr/azure/dns/private-resolver-hybrid-dns</li> <li>https://fr.scribd.com/document/861602629/LAB-Configurer-serveurs-de-noms-de-domaine-dans-Azure</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap06/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 337</li> <li>completion_tokens: 9249</li> <li>total_tokens: 9586</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.139, 'request_cost': 0.006, 'total_cost': 0.146}</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap06/#content","title":"Content","text":""},{"location":"_projects/_formation-azure/azure-chap06/#chapitre-6-les-services-de-reseau-azure","title":"Chapitre 6 : Les Services de R\u00e9seau Azure \ud83c\udf10","text":""},{"location":"_projects/_formation-azure/azure-chap06/#introduction-aux-reseaux-virtuels-azure-vnet","title":"Introduction aux R\u00e9seaux Virtuels Azure (VNet)","text":"<p>Les r\u00e9seaux virtuels Azure (VNet) constituent la fondation de l'infrastructure r\u00e9seau sur Azure. Un VNet est une repr\u00e9sentation de la propre infrastructure r\u00e9seau dans le cloud, offrant une isolation compl\u00e8te et un contr\u00f4le granulaire sur la configuration r\u00e9seau.[1] Il permet de cr\u00e9er un environnement r\u00e9seau logique isol\u00e9 dans lequel les ressources Azure peuvent communiquer entre elles de mani\u00e8re s\u00e9curis\u00e9e.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#caracteristiques-principales-des-vnet","title":"Caract\u00e9ristiques Principales des VNet","text":"<p>Un VNet offre plusieurs capacit\u00e9s essentielles pour construire une infrastructure cloud robuste :</p> <p>Isolation et Segmentation : Chaque VNet est isol\u00e9 des autres r\u00e9seaux, ce qui permet de cr\u00e9er des environnements distincts pour le d\u00e9veloppement, la production et les tests. Cette segmentation permet une gestion simplifi\u00e9e et une meilleure s\u00e9curit\u00e9.</p> <p>Adressage IP Personnalis\u00e9 : Les organisations peuvent d\u00e9finir leur propre espace d'adressage IP en utilisant le protocole CIDR (Classless Inter-Domain Routing). Par exemple, un VNet peut utiliser la plage 10.0.0.0/16, ce qui offre 65 536 adresses IP disponibles.</p> <p>Sous-r\u00e9seaux : Au sein d'un VNet, il est possible de cr\u00e9er plusieurs sous-r\u00e9seaux pour segmenter davantage le r\u00e9seau. Chaque sous-r\u00e9seau peut avoir sa propre plage d'adresses IP et ses propres r\u00e8gles de s\u00e9curit\u00e9.</p> <p>Connectivit\u00e9 Multisite : Les VNet peuvent \u00eatre interconnect\u00e9s \u00e0 d'autres VNet ou \u00e0 des r\u00e9seaux locaux via diverses technologies de connexion, permettant une architecture r\u00e9seau hybride compl\u00e8te.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#architecture-fondamentale","title":"Architecture Fondamentale","text":"<p>La structure d'un VNet comprend plusieurs composants :</p> <ul> <li>Espace d'adressage : La plage CIDR totale assign\u00e9e au r\u00e9seau virtuel</li> <li>Sous-r\u00e9seaux : Les divisions du VNet en plages plus petites</li> <li>Adresses IP publiques : Les adresses accessibles depuis Internet</li> <li>Adresses IP priv\u00e9es : Les adresses utilis\u00e9es en interne au sein du VNet</li> <li>Ressources de calcul : Les machines virtuelles, App Services et autres ressources Azure</li> </ul> <p>Un VNet peut contenir des ressources Azure telles que les machines virtuelles, les App Services, les bases de donn\u00e9es Azure SQL, ainsi que d'autres services en tant que service (PaaS) configur\u00e9s pour fonctionner au sein du r\u00e9seau virtuel.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#securiser-vos-reseaux-avec-les-groupes-de-securite-nsg","title":"S\u00e9curiser vos R\u00e9seaux avec les Groupes de S\u00e9curit\u00e9 (NSG)","text":"<p>Les groupes de s\u00e9curit\u00e9 r\u00e9seau (NSG) constituent la couche de s\u00e9curit\u00e9 principale pour contr\u00f4ler le trafic r\u00e9seau dans Azure. Un NSG est un ensemble de r\u00e8gles de s\u00e9curit\u00e9 qui permettent ou refusent le trafic r\u00e9seau entrant et sortant en fonction de crit\u00e8res sp\u00e9cifiques tels que le protocole, le port, l'adresse IP source et l'adresse IP de destination.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#fonctionnement-des-nsg","title":"Fonctionnement des NSG","text":"<p>Un NSG fonctionne en analysant le trafic r\u00e9seau et en appliquant des r\u00e8gles dans un ordre sp\u00e9cifique. Les r\u00e8gles sont trait\u00e9es dans l'ordre de leur priorit\u00e9 num\u00e9rique, du plus bas au plus \u00e9lev\u00e9. Une fois qu'une r\u00e8gle correspond au trafic, aucune autre r\u00e8gle n'est \u00e9valu\u00e9e.</p> <p>R\u00e8gles d'Entr\u00e9e (Inbound) : Contr\u00f4lent le trafic qui entre dans les ressources</p> <p>R\u00e8gles de Sortie (Outbound) : Contr\u00f4lent le trafic qui quitte les ressources</p>"},{"location":"_projects/_formation-azure/azure-chap06/#structure-dune-regle-nsg","title":"Structure d'une R\u00e8gle NSG","text":"<p>Chaque r\u00e8gle NSG contient les param\u00e8tres suivants :</p> Param\u00e8tre Description Priorit\u00e9 Un nombre entre 100 et 4096 (les nombres plus petits ont une priorit\u00e9 plus \u00e9lev\u00e9e) Direction Entrante (Inbound) ou Sortante (Outbound) Source L'adresse IP source, la plage CIDR, l'\u00e9tiquette de service ou un autre NSG Destination L'adresse IP de destination, la plage CIDR, l'\u00e9tiquette de service ou un autre NSG Protocole TCP, UDP, ICMP ou Tous Port Source Un port unique, une plage de ports ou Tous Port Destination Un port unique, une plage de ports ou Tous Action Autoriser (Allow) ou Refuser (Deny)"},{"location":"_projects/_formation-azure/azure-chap06/#exemple-de-configuration-nsg","title":"Exemple de Configuration NSG","text":"<p>Un NSG typique pour une machine virtuelle h\u00e9bergeant un serveur web inclurait :</p> <ul> <li>R\u00e8gle 100 : Autoriser le trafic entrant sur le port 80 (HTTP) depuis n'importe quelle source</li> <li>R\u00e8gle 110 : Autoriser le trafic entrant sur le port 443 (HTTPS) depuis n'importe quelle source</li> <li>R\u00e8gle 120 : Autoriser le trafic entrant sur le port 22 (SSH) depuis une adresse IP sp\u00e9cifique d'administration</li> <li>R\u00e8gle 130 : Refuser tout autre trafic entrant</li> <li>R\u00e8gle 1000 : Autoriser tout le trafic sortant par d\u00e9faut</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap06/#niveaux-dapplication-des-nsg","title":"Niveaux d'Application des NSG","text":"<p>Les NSG peuvent \u00eatre appliqu\u00e9s \u00e0 deux niveaux distincts :</p> <p>Au niveau du sous-r\u00e9seau : Toutes les ressources du sous-r\u00e9seau h\u00e9ritent des r\u00e8gles du NSG</p> <p>Au niveau de l'interface r\u00e9seau : Les r\u00e8gles s'appliquent uniquement \u00e0 la ressource sp\u00e9cifique</p> <p>Lorsque des NSG sont appliqu\u00e9s aux deux niveaux, le trafic doit satisfaire les deux ensembles de r\u00e8gles pour \u00eatre autoris\u00e9.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#creer-un-reseau-virtuel-vnet-sur-azure","title":"Cr\u00e9er un R\u00e9seau Virtuel (VNet) sur Azure","text":"<p>La cr\u00e9ation d'un r\u00e9seau virtuel sur Azure peut \u00eatre effectu\u00e9e via le portail Azure, Azure CLI, PowerShell ou les mod\u00e8les ARM. Chaque m\u00e9thode offre des avantages diff\u00e9rents selon les besoins op\u00e9rationnels.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#creer-un-vnet-via-azure-cli","title":"Cr\u00e9er un VNet via Azure CLI","text":"<p>L'interface de ligne de commande Azure permet une cr\u00e9ation programmatique et r\u00e9p\u00e9table de ressources. Voici les \u00e9tapes pour cr\u00e9er un VNet avec un sous-r\u00e9seau :</p> Bash<pre><code># Cr\u00e9er un groupe de ressources\naz group create --name myResourceGroup --location eastus\n\n# Cr\u00e9er un r\u00e9seau virtuel\naz network vnet create \\\n  --resource-group myResourceGroup \\\n  --name myVNet \\\n  --address-prefix 10.0.0.0/16 \\\n  --location eastus\n\n# Cr\u00e9er un sous-r\u00e9seau\naz network vnet subnet create \\\n  --resource-group myResourceGroup \\\n  --vnet-name myVNet \\\n  --name mySubnet \\\n  --address-prefix 10.0.0.0/24\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap06/#creer-un-vnet-via-powershell","title":"Cr\u00e9er un VNet via PowerShell","text":"<p>Pour les environnements utilisant PowerShell, la cr\u00e9ation de VNet suit une approche similaire :</p> PowerShell<pre><code># Cr\u00e9er un groupe de ressources\nNew-AzResourceGroup -Name myResourceGroup -Location eastus\n\n# Cr\u00e9er la configuration de sous-r\u00e9seau\n$subnetConfig = New-AzVirtualNetworkSubnetConfig `\n  -Name mySubnet `\n  -AddressPrefix 10.0.0.0/24\n\n# Cr\u00e9er le r\u00e9seau virtuel\n$vnet = New-AzVirtualNetwork `\n  -ResourceGroupName myResourceGroup `\n  -Location eastus `\n  -Name myVNet `\n  -AddressPrefix 10.0.0.0/16 `\n  -Subnet $subnetConfig\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap06/#configuration-avancee-du-vnet","title":"Configuration Avanc\u00e9e du VNet","text":"<p>Apr\u00e8s la cr\u00e9ation d'un VNet, plusieurs configurations suppl\u00e9mentaires peuvent \u00eatre appliqu\u00e9es :</p> <p>Ajout de Multiples Sous-r\u00e9seaux : Un VNet peut contenir jusqu'\u00e0 3000 sous-r\u00e9seaux. Une structure commune divise le r\u00e9seau en sous-r\u00e9seaux distincts pour les couches d'application, la base de donn\u00e9es et la gestion.</p> <p>Configuration DNS Personnalis\u00e9e : Les serveurs DNS par d\u00e9faut d'Azure peuvent \u00eatre remplac\u00e9s par des serveurs DNS personnalis\u00e9s pour int\u00e9grer les services DNS existants de l'organisation.</p> <p>Service Endpoints : Permettent une connexion directe et s\u00e9curis\u00e9e aux services Azure PaaS sans passer par Internet.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#structure-recommandee-pour-un-vnet-production","title":"Structure Recommand\u00e9e pour un VNet Production","text":"<p>Une architecture typique pour un environnement de production inclut :</p> <ul> <li>Sous-r\u00e9seau Frontend (10.0.1.0/24) : Contient les \u00e9quilibreurs de charge et les instances d'Application Gateway</li> <li>Sous-r\u00e9seau d'Application (10.0.2.0/24) : H\u00e9berge les machines virtuelles d'application</li> <li>Sous-r\u00e9seau de Base de Donn\u00e9es (10.0.3.0/24) : Contient les instances de base de donn\u00e9es</li> <li>Sous-r\u00e9seau de Gestion (10.0.4.0/24) : R\u00e9serv\u00e9 pour les outils d'administration et de surveillance</li> <li>Sous-r\u00e9seau de Passerelle (10.0.5.0/24) : Utilis\u00e9 pour les passerelles VPN ou ExpressRoute</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap06/#connecter-des-reseaux-virtuels-avec-le-peering-vnet-peering","title":"Connecter des R\u00e9seaux Virtuels avec le Peering (VNet Peering)","text":"<p>Le VNet Peering permet de connecter deux r\u00e9seaux virtuels d'une mani\u00e8re rapide et \u00e0 faible latence. Cette technologie cr\u00e9e une connexion directe entre les r\u00e9seaux, optimisant les performances et les co\u00fbts par rapport \u00e0 d'autres m\u00e9thodes de connexion.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#types-de-vnet-peering","title":"Types de VNet Peering","text":"<p>VNet Peering R\u00e9gional : Connecte deux r\u00e9seaux virtuels situ\u00e9s dans la m\u00eame r\u00e9gion Azure. Cette connexion offre une latence tr\u00e8s faible et une bande passante optimale.</p> <p>VNet Peering Global : Connecte deux r\u00e9seaux virtuels situ\u00e9s dans des r\u00e9gions Azure diff\u00e9rentes. Bien que l\u00e9g\u00e8rement moins performant que le peering r\u00e9gional, il reste tr\u00e8s efficace pour connecter des environnements g\u00e9ographiquement distribu\u00e9s.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#creation-dun-vnet-peering-via-azure-cli","title":"Cr\u00e9ation d'un VNet Peering via Azure CLI","text":"Bash<pre><code># Supposons deux VNet existants : vnet1 et vnet2 dans le m\u00eame groupe de ressources\n\n# Cr\u00e9er le peering de vnet1 vers vnet2\naz network vnet peering create \\\n  --name vnet1-to-vnet2 \\\n  --resource-group myResourceGroup \\\n  --vnet-name vnet1 \\\n  --remote-vnet /subscriptions/{subscription-id}/resourceGroups/myResourceGroup/providers/Microsoft.Network/virtualNetworks/vnet2 \\\n  --allow-vnet-access\n\n# Cr\u00e9er le peering de vnet2 vers vnet1 (bidirectionnel)\naz network vnet peering create \\\n  --name vnet2-to-vnet1 \\\n  --resource-group myResourceGroup \\\n  --vnet-name vnet2 \\\n  --remote-vnet /subscriptions/{subscription-id}/resourceGroups/myResourceGroup/providers/Microsoft.Network/virtualNetworks/vnet1 \\\n  --allow-vnet-access\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap06/#creation-dun-vnet-peering-via-powershell","title":"Cr\u00e9ation d'un VNet Peering via PowerShell","text":"PowerShell<pre><code># R\u00e9cup\u00e9rer les VNet\n$vnet1 = Get-AzVirtualNetwork -Name vnet1 -ResourceGroupName myResourceGroup\n$vnet2 = Get-AzVirtualNetwork -Name vnet2 -ResourceGroupName myResourceGroup\n\n# Cr\u00e9er le peering bidirectionnel\nAdd-AzVirtualNetworkPeering -Name vnet1-to-vnet2 `\n  -VirtualNetwork $vnet1 `\n  -RemoteVirtualNetworkId $vnet2.Id\n\nAdd-AzVirtualNetworkPeering -Name vnet2-to-vnet1 `\n  -VirtualNetwork $vnet2 `\n  -RemoteVirtualNetworkId $vnet1.Id\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap06/#avantages-et-limitations-du-vnet-peering","title":"Avantages et Limitations du VNet Peering","text":"<p>Avantages : - Connexion priv\u00e9e directe sans passer par Internet - Latence tr\u00e8s faible entre les r\u00e9seaux - Trafic non chiffr\u00e9 (am\u00e9liore les performances) - Pas de frais pour le peering dans la m\u00eame r\u00e9gion - Permet la communication transparente entre ressources</p> <p>Limitations : - Les espaces d'adressage des deux VNet ne doivent pas se chevaucher - Le peering ne passe pas par une passerelle (pas de transitivit\u00e9 par d\u00e9faut) - Les routes d\u00e9finies par l'utilisateur ne traversent pas les limites du peering - Les NsG appliqu\u00e9s ne contr\u00f4lent pas le trafic de peering</p>"},{"location":"_projects/_formation-azure/azure-chap06/#configuration-avancee-du-peering","title":"Configuration Avanc\u00e9e du Peering","text":"<p>Le peering peut \u00eatre configur\u00e9 avec plusieurs options additionnelles :</p> <p>Allow Virtual Network Access : Autorise les ressources d'un VNet \u00e0 communiquer avec l'autre VNet</p> <p>Allow Forwarded Traffic : Accepte le trafic provenant d'une passerelle ou d'une machine virtuelle qui fait office de routeur</p> <p>Allow Gateway Transit : Autorise le VNet peering \u00e0 utiliser une passerelle de l'autre VNet</p> <p>Use Remote Gateways : Permet \u00e0 ce VNet d'utiliser la passerelle du VNet peering pour communiquer en dehors de la paire</p>"},{"location":"_projects/_formation-azure/azure-chap06/#gerer-la-resolution-de-noms-avec-azure-dns","title":"G\u00e9rer la R\u00e9solution de Noms avec Azure DNS","text":"<p>La r\u00e9solution de noms est l'\u00e9l\u00e9ment fondamental permettant aux ressources de communiquer via des noms de domaine plut\u00f4t que via des adresses IP. Azure offre plusieurs solutions pour g\u00e9rer cette r\u00e9solution selon les besoins d'acc\u00e8s (public ou priv\u00e9).[1]</p>"},{"location":"_projects/_formation-azure/azure-chap06/#azure-dns-public","title":"Azure DNS Public","text":"<p>Azure DNS Public g\u00e8re les enregistrements DNS publics accessibles via Internet. Cette solution permet de d\u00e9l\u00e9guer la gestion des domaines publics directement \u00e0 Azure sans maintenir d'infrastructure DNS externe.</p> <p>Cr\u00e9ation d'une Zone DNS Publique via Azure CLI :</p> Bash<pre><code># Cr\u00e9er une zone DNS publique\naz network dns zone create \\\n  --resource-group myResourceGroup \\\n  --name contoso.com\n\n# Ajouter un enregistrement A (pointe vers une adresse IPv4)\naz network dns record-set a add-record \\\n  --resource-group myResourceGroup \\\n  --zone-name contoso.com \\\n  --record-set-name www \\\n  --ipv4-address 93.184.216.34\n\n# Ajouter un enregistrement MX (enregistrement de messagerie)\naz network dns record-set mx add-record \\\n  --resource-group myResourceGroup \\\n  --zone-name contoso.com \\\n  --record-set-name @ \\\n  --exchange mail.contoso.com \\\n  --preference 10\n\n# Ajouter un enregistrement CNAME (alias)\naz network dns record-set cname set-record \\\n  --resource-group myResourceGroup \\\n  --zone-name contoso.com \\\n  --record-set-name blog \\\n  --cname contoso.com\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap06/#azure-dns-prive","title":"Azure DNS Priv\u00e9","text":"<p>Azure DNS Priv\u00e9 offre une r\u00e9solution de noms interne pour les ressources situ\u00e9es dans les r\u00e9seaux virtuels. Cette solution permet de cr\u00e9er des domaines priv\u00e9s accessibles uniquement au sein du VNet ou depuis des r\u00e9seaux connect\u00e9s.[2]</p> <p>Cr\u00e9ation d'une Zone DNS Priv\u00e9e via Azure CLI :</p> Bash<pre><code># Cr\u00e9er une zone DNS priv\u00e9e\naz network private-dns zone create \\\n  --resource-group myResourceGroup \\\n  --name contoso.internal\n\n# Associer la zone DNS priv\u00e9e \u00e0 un VNet\naz network private-dns link vnet create \\\n  --resource-group myResourceGroup \\\n  --zone-name contoso.internal \\\n  --name myVNetLink \\\n  --virtual-network /subscriptions/{subscription-id}/resourceGroups/myResourceGroup/providers/Microsoft.Network/virtualNetworks/myVNet \\\n  --registration-enabled true\n\n# Ajouter un enregistrement DNS priv\u00e9\naz network private-dns record-set a add-record \\\n  --resource-group myResourceGroup \\\n  --zone-name contoso.internal \\\n  --record-set-name appserver \\\n  --ipv4-address 10.0.1.10\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap06/#configuration-des-serveurs-dns-personnalises","title":"Configuration des Serveurs DNS Personnalis\u00e9s","text":"<p>Azure App Service permet de configurer des serveurs DNS personnalis\u00e9s pour des r\u00e9solutions sp\u00e9cifiques.[1] Cela s'av\u00e8re utile lorsque l'application doit r\u00e9soudre des domaines internes non accessibles via les serveurs DNS standards.</p> <p>Configuration via Azure CLI :</p> Bash<pre><code># Configurer jusqu'\u00e0 5 serveurs DNS personnalis\u00e9s\naz resource update \\\n  --resource-group myResourceGroup \\\n  --name myAppService \\\n  --resource-type \"Microsoft.Web/sites\" \\\n  --set properties.dnsConfiguration.dnsServers=\"['168.63.129.16','8.8.8.8']\"\n\n# Configurer le comportement de mise en cache DNS (0-60 secondes)\naz resource update \\\n  --resource-group myResourceGroup \\\n  --name myAppService \\\n  --set properties.dnsConfiguration.dnsMaxCacheTimeout=30 \\\n  --resource-type \"Microsoft.Web/sites\"\n\n# Configurer le nombre de tentatives DNS (1-5)\naz resource update \\\n  --resource-group myResourceGroup \\\n  --name myAppService \\\n  --set properties.dnsConfiguration.dnsRetryAttemptCount=3 \\\n  --resource-type \"Microsoft.Web/sites\"\n\n# Configurer le d\u00e9lai d'expiration DNS (1-30 secondes)\naz resource update \\\n  --resource-group myResourceGroup \\\n  --name myAppService \\\n  --set properties.dnsConfiguration.dnsRetryAttemptTimeout=5 \\\n  --resource-type \"Microsoft.Web/sites\"\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap06/#azure-dns-private-resolver","title":"Azure DNS Private Resolver","text":"<p>Azure DNS Private Resolver simplifie la r\u00e9solution DNS hybride en permettant une r\u00e9solution bidirectionnelle entre les ressources Azure et les ressources locales.[9] Cette solution \u00e9limine la n\u00e9cessit\u00e9 de g\u00e9rer des serveurs DNS personnalis\u00e9s pour la r\u00e9solution hybride.</p> <p>Avantages du Private Resolver : - R\u00e9solution sans serveur des noms de domaine Azure et locaux - Support des zones de transfert conditionales - Haute disponibilit\u00e9 et r\u00e9silience int\u00e9gr\u00e9es - Int\u00e9gration transparente avec les zones DNS priv\u00e9es Azure - R\u00e9duction de la complexit\u00e9 op\u00e9rationnelle</p>"},{"location":"_projects/_formation-azure/azure-chap06/#resolution-dns-dans-les-reseaux-virtuels","title":"R\u00e9solution DNS dans les R\u00e9seaux Virtuels","text":"<p>Pour les machines virtuelles et les instances de r\u00f4le Azure, la r\u00e9solution de noms fournit les suffixes DNS appropri\u00e9s permettant une r\u00e9solution simplifi\u00e9e des ressources dans le m\u00eame VNet.[4]</p> <p>R\u00e9solution interne dans le m\u00eame VNet :</p> <p>Les machines virtuelles peuvent se r\u00e9soudre les unes les autres en utilisant uniquement le nom d'h\u00f4te sans domaine complet (FQDN). Azure attribue automatiquement le suffixe DNS interne (.internal.cloudapp.net).</p> Bash<pre><code># Exemple : Acc\u00e8s \u00e0 une machine virtuelle depuis une autre\n# Machine source : vm1\n# Machine cible : vm2.internal.cloudapp.net\n# La commande suivante fonctionnera :\nping vm2\n</code></pre> <p>R\u00e9solution DNS avec Transfert Conditionnel :</p> <p>Pour les environnements hybrides, les serveurs DNS locaux peuvent \u00eatre configur\u00e9s pour transf\u00e9rer les requ\u00eates vers Azure DNS Private Resolver selon le domaine recherch\u00e9.</p> Bash<pre><code># Configuration d'une r\u00e8gle de transfert conditionnelle\n# Domaines : *.database.windows.net\n# Destination : 10.0.4.5 (adresse Private Resolver)\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap06/#les-reseaux-prives-virtuels-azure-vpn","title":"Les R\u00e9seaux Priv\u00e9s Virtuels Azure (VPN)","text":"<p>Un r\u00e9seau priv\u00e9 virtuel (VPN) Azure \u00e9tablit une connexion s\u00e9curis\u00e9e et chiffr\u00e9e entre un r\u00e9seau local et un r\u00e9seau virtuel Azure, ou entre deux r\u00e9seaux virtuels. Cette technologie permet une communication confidentielle sur des r\u00e9seaux publics non s\u00fbrs.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#types-de-connexions-vpn","title":"Types de Connexions VPN","text":"<p>VPN Site-\u00e0-Site (S2S) : Connecte un r\u00e9seau local complet \u00e0 un r\u00e9seau virtuel Azure. Cette configuration permet \u00e0 tous les appareils du r\u00e9seau local d'acc\u00e9der aux ressources du VNet comme s'ils \u00e9taient sur le m\u00eame r\u00e9seau local.</p> <p>VPN Point-\u00e0-Site (P2S) : Connecte un ordinateur individuel \u00e0 un r\u00e9seau virtuel Azure. Cette solution s'adapte parfaitement aux travailleurs distants ou aux administrateurs n\u00e9cessitant un acc\u00e8s occasionnel aux ressources Azure.</p> <p>VPN VNet-\u00e0-VNet : Connecte deux r\u00e9seaux virtuels Azure avec chiffrement. Bien que le VNet Peering soit g\u00e9n\u00e9ralement pr\u00e9f\u00e9r\u00e9, le VPN VNet-\u00e0-VNet s'av\u00e8re utile lorsque le chiffrement du trafic est un imp\u00e9ratif de s\u00e9curit\u00e9.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#architecture-dune-passerelle-vpn","title":"Architecture d'une Passerelle VPN","text":"<p>Une passerelle VPN comporte plusieurs composants critiques :</p> <p>Passerelle VPN (Gateway) : La ressource Azure qui g\u00e8re les connexions VPN</p> <p>Adresse IP Publique : L'adresse accessible depuis le r\u00e9seau distant</p> <p>Configuration de Connexion : Les param\u00e8tres de s\u00e9curit\u00e9 et de routage</p> <p>Subnetwork Gateway : Un sous-r\u00e9seau d\u00e9di\u00e9 (g\u00e9n\u00e9ralement 10.0.255.0/27) pour h\u00e9berger la passerelle</p>"},{"location":"_projects/_formation-azure/azure-chap06/#creation-dune-passerelle-vpn-site-a-site-via-azure-cli","title":"Cr\u00e9ation d'une Passerelle VPN Site-\u00e0-Site via Azure CLI","text":"Bash<pre><code># Cr\u00e9er un sous-r\u00e9seau de passerelle\naz network vnet subnet create \\\n  --resource-group myResourceGroup \\\n  --vnet-name myVNet \\\n  --name GatewaySubnet \\\n  --address-prefix 10.0.255.0/27\n\n# Cr\u00e9er une adresse IP publique pour la passerelle\naz network public-ip create \\\n  --resource-group myResourceGroup \\\n  --name myGatewayIP \\\n  --sku Standard\n\n# Cr\u00e9er la passerelle VPN\naz network vnet-gateway create \\\n  --name myVPNGateway \\\n  --public-ip-address myGatewayIP \\\n  --resource-group myResourceGroup \\\n  --vnet myVNet \\\n  --gateway-type Vpn \\\n  --vpn-type RouteBased \\\n  --sku VpnGw1\n\n# Cr\u00e9er une passerelle r\u00e9seau local repr\u00e9sentant le site distant\naz network local-gateway create \\\n  --name myLocalGateway \\\n  --resource-group myResourceGroup \\\n  --gateway-ip-address 203.0.113.12 \\\n  --local-address-prefixes 192.168.0.0/16\n\n# Cr\u00e9er la connexion VPN\naz network vpn-connection create \\\n  --name myVPNConnection \\\n  --resource-group myResourceGroup \\\n  --vnet-gateway-name myVPNGateway \\\n  --local-gateway-name myLocalGateway \\\n  --shared-key MyVerySecureSharedKey123\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap06/#creation-dune-passerelle-vpn-point-a-site-via-powershell","title":"Cr\u00e9ation d'une Passerelle VPN Point-\u00e0-Site via PowerShell","text":"PowerShell<pre><code># Cr\u00e9er la configuration r\u00e9seau\n$ResourceGroupName = \"myResourceGroup\"\n$VNetName = \"myVNet\"\n$GWSubnetName = \"GatewaySubnet\"\n$VPNClientAddressPool = \"172.16.201.0/24\"\n\n# Cr\u00e9er un sous-r\u00e9seau de passerelle\n$gwSubnetConfig = New-AzVirtualNetworkSubnetConfig `\n  -Name $GWSubnetName `\n  -AddressPrefix 10.0.255.0/27\n\n# Obtenir le VNet existant et ajouter le sous-r\u00e9seau\n$vnet = Get-AzVirtualNetwork -Name $VNetName -ResourceGroupName $ResourceGroupName\nAdd-AzVirtualNetworkSubnetConfig @vnet -@gwSubnetConfig\nSet-AzVirtualNetwork -VirtualNetwork $vnet\n\n# Cr\u00e9er une adresse IP publique\n$pip = New-AzPublicIpAddress `\n  -Name myGatewayIP `\n  -ResourceGroupName $ResourceGroupName `\n  -Location eastus `\n  -AllocationMethod Dynamic\n\n# R\u00e9cup\u00e9rer le sous-r\u00e9seau de passerelle\n$subnet = Get-AzVirtualNetworkSubnetConfig `\n  -Name $GWSubnetName `\n  -VirtualNetwork $vnet\n\n# Cr\u00e9er la configuration IP de la passerelle\n$ipconfig = New-AzVirtualNetworkGatewayIpConfig `\n  -Name gwIPConfig `\n  -Subnet $subnet `\n  -PublicIpAddress $pip\n\n# Cr\u00e9er la passerelle VPN\n$gateway = New-AzVirtualNetworkGateway `\n  -Name myVPNGateway `\n  -ResourceGroupName $ResourceGroupName `\n  -Location eastus `\n  -IpConfiguration $ipconfig `\n  -GatewayType Vpn `\n  -VpnType RouteBased `\n  -GatewaySku VpnGw1\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap06/#protocoles-et-parametres-vpn","title":"Protocoles et Param\u00e8tres VPN","text":"<p>Les connexions VPN Azure utilisent plusieurs protocoles pour assurer la s\u00e9curit\u00e9 et l'interop\u00e9rabilit\u00e9 :</p> Protocole Utilisation Caract\u00e9ristiques IKEv2 Point-\u00e0-Site moderne Reconnexion rapide, support IPv6 SSTP Point-\u00e0-Site sur Windows Compatible avec pare-feu, utilise le port 443 OpenVPN Point-\u00e0-Site multiplateforme Open-source, flexible, performant IPSec Site-\u00e0-Site Chiffrement fort, standard industriel"},{"location":"_projects/_formation-azure/azure-chap06/#la-connexion-privee-dediee-avec-azure-expressroute","title":"La Connexion Priv\u00e9e D\u00e9di\u00e9e avec Azure ExpressRoute","text":"<p>Azure ExpressRoute offre une connexion r\u00e9seau d\u00e9di\u00e9e, priv\u00e9e et non-rout\u00e9e sur Internet vers les services Azure. Contrairement aux connexions VPN qui utilisent Internet public, ExpressRoute \u00e9tablit une connexion directe via des fournisseurs de connectivit\u00e9, \u00e9liminant les risques li\u00e9s \u00e0 Internet public et offrant une performance pr\u00e9visible.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#avantages-dazure-expressroute","title":"Avantages d'Azure ExpressRoute","text":"<p>Bande Passante Garantie : La connexion ExpressRoute fournit une bande passante d\u00e9di\u00e9e sans contention avec d'autres utilisateurs, contrairement \u00e0 Internet public.</p> <p>Latence Faible et Pr\u00e9visible : Une connexion directe assure une latence constante et pr\u00e9visible, am\u00e9liorant les performances des applications critiques.</p> <p>S\u00e9curit\u00e9 Renforc\u00e9e : Le trafic n'emprunte pas Internet public, r\u00e9duisant l'exposition aux attaques. Les donn\u00e9es restent priv\u00e9es dans une connexion d\u00e9di\u00e9e.</p> <p>Haute Disponibilit\u00e9 : ExpressRoute offre une haute disponibilit\u00e9 native avec redondance automatique en cas de d\u00e9faillance.</p> <p>Connexion Multi-R\u00e9gions : Une seule connexion ExpressRoute peut acc\u00e9der \u00e0 tous les services Azure de toutes les r\u00e9gions.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#modeles-de-connectivite-expressroute","title":"Mod\u00e8les de Connectivit\u00e9 ExpressRoute","text":"<p>Co-localisation dans un Exchange Cloud : La ressource physique est co-localis\u00e9e dans un b\u00e2timent d'\u00e9change cloud, offrant l'interconnexion la plus rapide.</p> <p>Ethernet Point-\u00e0-Point : Une connexion Ethernet d\u00e9di\u00e9e relie directement les locaux au r\u00e9seau Azure.</p> <p>Connexion Any-to-Any (IPVPN) : Int\u00e9gre les sites distants via un r\u00e9seau IP virtuel priv\u00e9 g\u00e9r\u00e9 par le fournisseur.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#composants-dune-connexion-expressroute","title":"Composants d'une Connexion ExpressRoute","text":"<p>Une connexion ExpressRoute comprend plusieurs \u00e9l\u00e9ments essentiels :</p> <p>Circuit ExpressRoute : La ressource Azure repr\u00e9sentant la connexion</p> <p>Fournisseur de Connectivit\u00e9 : L'op\u00e9rateur t\u00e9l\u00e9coms fournissant la connectivit\u00e9 physique</p> <p>Appairage Microsoft : Permet l'acc\u00e8s aux services Microsoft (Microsoft 365, Office 365, etc.)</p> <p>Appairage Priv\u00e9 Azure : Permet l'acc\u00e8s aux ressources Azure dans les r\u00e9seaux virtuels</p> <p>Appairage Public Azure : Permet l'acc\u00e8s aux services Azure publics (d\u00e9pr\u00e9ci\u00e9 en faveur de Microsoft Peering)</p>"},{"location":"_projects/_formation-azure/azure-chap06/#creation-dun-circuit-expressroute-via-azure-cli","title":"Cr\u00e9ation d'un Circuit ExpressRoute via Azure CLI","text":"Bash<pre><code># Cr\u00e9er un circuit ExpressRoute\naz network express-route create \\\n  --resource-group myResourceGroup \\\n  --name myExpressRouteCircuit \\\n  --provider \"Equinix\" \\\n  --peering-location \"Silicon Valley\" \\\n  --bandwidth 50 \\\n  --sku Standard \\\n  --family MeteredData\n\n# R\u00e9cup\u00e9rer l'\u00e9tat du circuit\naz network express-route show \\\n  --resource-group myResourceGroup \\\n  --name myExpressRouteCircuit\n\n# Configurer l'appairage priv\u00e9 Azure\naz network express-route peering create \\\n  --circuit-name myExpressRouteCircuit \\\n  --resource-group myResourceGroup \\\n  --name AzurePrivatePeering \\\n  --peering-type AzurePrivatePeering \\\n  --peer-asn 65001 \\\n  --primary-peer-subnet 10.0.0.0/30 \\\n  --secondary-peer-subnet 10.0.0.4/30 \\\n  --vlan-id 200\n\n# Lier une passerelle de r\u00e9seau virtuel au circuit ExpressRoute\naz network vpn-connection create \\\n  --name myVPNConnection \\\n  --resource-group myResourceGroup \\\n  --vnet-gateway-name myVNetGateway \\\n  --express-route-circuit-id /subscriptions/{subscription-id}/resourceGroups/myResourceGroup/providers/Microsoft.Network/expressRouteCircuits/myExpressRouteCircuit\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap06/#configuration-dune-passerelle-expressroute-via-powershell","title":"Configuration d'une Passerelle ExpressRoute via PowerShell","text":"PowerShell<pre><code># Cr\u00e9er une passerelle de r\u00e9seau virtuel pour ExpressRoute\n$ResourceGroupName = \"myResourceGroup\"\n$VNetName = \"myVNet\"\n\n# Cr\u00e9er une adresse IP publique\n$pip = New-AzPublicIpAddress `\n  -Name myGatewayIP `\n  -ResourceGroupName $ResourceGroupName `\n  -Location eastus `\n  -AllocationMethod Dynamic\n\n# Obtenir le VNet\n$vnet = Get-AzVirtualNetwork -Name $VNetName -ResourceGroupName $ResourceGroupName\n\n# Cr\u00e9er la configuration IP\n$ipconfig = New-AzVirtualNetworkGatewayIpConfig `\n  -Name gwIPConfig `\n  -Subnet $vnet.Subnets[0] `\n  -PublicIpAddress $pip\n\n# Cr\u00e9er la passerelle ExpressRoute\n$gateway = New-AzVirtualNetworkGateway `\n  -Name myExpressRouteGateway `\n  -ResourceGroupName $ResourceGroupName `\n  -Location eastus `\n  -IpConfiguration $ipconfig `\n  -GatewayType ExpressRoute `\n  -GatewaySku Standard\n\n# Lier le circuit au VNet\n$circuit = Get-AzExpressRouteCircuit `\n  -Name myExpressRouteCircuit `\n  -ResourceGroupName $ResourceGroupName\n\n$connection = New-AzVirtualNetworkGatewayConnection `\n  -Name myConnection `\n  -ResourceGroupName $ResourceGroupName `\n  -VirtualNetworkGateway1 $gateway `\n  -PeerId $circuit.Id `\n  -ConnectionType ExpressRoute\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap06/#cas-dusage-dexpressroute","title":"Cas d'Usage d'ExpressRoute","text":"<p>ExpressRoute s'av\u00e8re particuli\u00e8rement b\u00e9n\u00e9fique dans les sc\u00e9narios suivants :</p> <p>Applications Critiques : Les applications requ\u00e9rant une latence extr\u00eamement faible et une disponibilit\u00e9 maximale b\u00e9n\u00e9ficient de la connexion d\u00e9di\u00e9e d'ExpressRoute.</p> <p>Transfert de Donn\u00e9es Massif : Les organisations transf\u00e9rant r\u00e9guli\u00e8rement de grandes quantit\u00e9s de donn\u00e9es vers Azure \u00e9conomisent significativement en co\u00fbts de bande passante.</p> <p>Conformit\u00e9 R\u00e9glementaire : Certains secteurs r\u00e9glement\u00e9s pr\u00e9f\u00e8rent ou exigent une connexion priv\u00e9e plut\u00f4t que d'utiliser Internet public.</p> <p>Applications Hybrides : Les environnements o\u00f9 une partie du traitement s'effectue localement et une autre dans Azure b\u00e9n\u00e9ficient d'une interconnexion fiable.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#securiser-lacces-aux-services-avec-les-points-de-terminaison-prives","title":"S\u00e9curiser l'Acc\u00e8s aux Services avec les Points de Terminaison Priv\u00e9s","text":"<p>Les points de terminaison priv\u00e9s (Private Endpoints) permettent une connexion s\u00e9curis\u00e9e et priv\u00e9e aux services Azure directement depuis le VNet, sans exposer l'acc\u00e8s \u00e0 Internet public. Cette technologie cr\u00e9e une interface r\u00e9seau dans le VNet qui se connecte de mani\u00e8re priv\u00e9e au service Azure.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#avantages-des-points-de-terminaison-prives","title":"Avantages des Points de Terminaison Priv\u00e9s","text":"<p>Acc\u00e8s Priv\u00e9 : La connexion reste enti\u00e8rement priv\u00e9e au sein du VNet, sans passer par Internet.</p> <p>\u00c9limination des Risques Internet : Les services ne sont pas expos\u00e9s \u00e0 Internet public, r\u00e9duisant la surface d'attaque.</p> <p>Conformit\u00e9 R\u00e9glementaire : Permet de satisfaire les exigences de conformit\u00e9 exigeant l'isolement r\u00e9seau.</p> <p>Contr\u00f4le d'Acc\u00e8s Granulaire : Les NSG et les r\u00e8gles de pare-feu peuvent contr\u00f4ler le trafic vers les points de terminaison priv\u00e9s.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#services-azure-supportant-les-points-de-terminaison-prives","title":"Services Azure Supportant les Points de Terminaison Priv\u00e9s","text":"<p>Les points de terminaison priv\u00e9s peuvent \u00eatre cr\u00e9\u00e9s pour une large gamme de services Azure :</p> <ul> <li>Stockage Azure (Blob, Queue, Table, File)</li> <li>Base de donn\u00e9es Azure SQL</li> <li>Azure Cosmos DB</li> <li>Azure Database pour MySQL/PostgreSQL/MariaDB</li> <li>Azure Key Vault</li> <li>Azure App Services</li> <li>Azure Container Registry</li> <li>Azure Service Bus</li> <li>Azure Event Hubs</li> <li>Azure Data Lake Storage</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap06/#architecture-dun-point-de-terminaison-prive","title":"Architecture d'un Point de Terminaison Priv\u00e9","text":"<p>Un point de terminaison priv\u00e9 comprend plusieurs composants :</p> <p>Interface R\u00e9seau Priv\u00e9e : Cr\u00e9\u00e9e dans le VNet avec une adresse IP priv\u00e9e</p> <p>Liaison de Service : \u00c9tablit la connexion au service Azure cible</p> <p>Zones DNS Priv\u00e9es : G\u00e8re la r\u00e9solution de noms du point de terminaison priv\u00e9</p> <p>Groupe de Ressources du Service : Identifie le service Azure sp\u00e9cifique acc\u00e9d\u00e9</p>"},{"location":"_projects/_formation-azure/azure-chap06/#creation-dun-point-de-terminaison-prive-via-azure-cli","title":"Cr\u00e9ation d'un Point de Terminaison Priv\u00e9 via Azure CLI","text":"Bash<pre><code># Cr\u00e9er un point de terminaison priv\u00e9 pour Azure Storage\naz network private-endpoint create \\\n  --resource-group myResourceGroup \\\n  --name myStorageEndpoint \\\n  --vnet-name myVNet \\\n  --subnet mySubnet \\\n  --private-connection-resource-id /subscriptions/{subscription-id}/resourceGroups/myResourceGroup/providers/Microsoft.Storage/storageAccounts/mystorageaccount \\\n  --group-ids blob \\\n  --connection-name myStorageConnection\n\n# Cr\u00e9er une zone DNS priv\u00e9e pour le stockage\naz network private-dns zone create \\\n  --resource-group myResourceGroup \\\n  --name privatelink.blob.core.windows.net\n\n# Lier la zone DNS priv\u00e9e au VNet\naz network private-dns link vnet create \\\n  --resource-group myResourceGroup \\\n  --zone-name privatelink.blob.core.windows.net \\\n  --name myDNSLink \\\n  --virtual-network /subscriptions/{subscription-id}/resourceGroups/myResourceGroup/providers/Microsoft.Network/virtualNetworks/myVNet \\\n  --registration-enabled false\n\n# Cr\u00e9er un enregistrement DNS priv\u00e9\naz network private-dns record-set a create \\\n  --resource-group myResourceGroup \\\n  --zone-name privatelink.blob.core.windows.net \\\n  --name mystorageaccount \\\n  --ttl 300\n\n# Ajouter l'adresse IP du point de terminaison priv\u00e9 \u00e0 l'enregistrement DNS\naz network private-dns record-set a add-record \\\n  --resource-group myResourceGroup \\\n  --zone-name privatelink.blob.core.windows.net \\\n  --record-set-name mystorageaccount \\\n  --ipv4-address 10.0.1.5\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap06/#creation-dun-point-de-terminaison-prive-via-powershell","title":"Cr\u00e9ation d'un Point de Terminaison Priv\u00e9 via PowerShell","text":"PowerShell<pre><code># Obtenir le VNet et le sous-r\u00e9seau\n$ResourceGroupName = \"myResourceGroup\"\n$VNetName = \"myVNet\"\n$SubnetName = \"mySubnet\"\n\n$vnet = Get-AzVirtualNetwork -Name $VNetName -ResourceGroupName $ResourceGroupName\n$subnet = $vnet.Subnets | Where-Object { $_.Name -eq $SubnetName }\n\n# Cr\u00e9er la configuration du point de terminaison priv\u00e9\n$privateEndpointConfig = New-AzPrivateLinkServiceConnection `\n  -Name myStorageConnection `\n  -PrivateLinkServiceId /subscriptions/{subscription-id}/resourceGroups/myResourceGroup/providers/Microsoft.Storage/storageAccounts/mystorageaccount `\n  -GroupId blob\n\n# Cr\u00e9er le point de terminaison priv\u00e9\n$privateEndpoint = New-AzPrivateEndpoint `\n  -Name myStorageEndpoint `\n  -ResourceGroupName $ResourceGroupName `\n  -Location eastus `\n  -Subnet $subnet `\n  -PrivateLinkServiceConnection $privateEndpointConfig\n\n# Obtenir les informations du point de terminaison priv\u00e9\nGet-AzPrivateEndpoint -Name myStorageEndpoint -ResourceGroupName $ResourceGroupName\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap06/#resolution-dns-pour-les-points-de-terminaison-prives","title":"R\u00e9solution DNS pour les Points de Terminaison Priv\u00e9s","text":"<p>Les points de terminaison priv\u00e9s n\u00e9cessitent une r\u00e9solution DNS sp\u00e9ciale pour fonctionner correctement. Azure fournit des zones DNS priv\u00e9es pr\u00e9configur\u00e9es pour chaque type de service.</p> <p>Zones DNS Priv\u00e9es Standard :</p> Service Azure Zone DNS Priv\u00e9e Stockage Azure (Blob) privatelink.blob.core.windows.net Azure SQL Database privatelink.database.windows.net Azure Key Vault privatelink.vaultcore.azure.net Azure Container Registry privatelink.azurecr.io Azure Service Bus privatelink.servicebus.windows.net Azure Event Hubs privatelink.eventhubs.windows.net Azure Cosmos DB privatelink.documents.azure.com Azure App Services privatelink.azurewebsites.net"},{"location":"_projects/_formation-azure/azure-chap06/#configuration-avancee-des-points-de-terminaison-prives","title":"Configuration Avanc\u00e9e des Points de Terminaison Priv\u00e9s","text":"<p>Groupes d'Application de Point de Terminaison : Lorsqu'un service supporte plusieurs sous-ressources, le groupe d'application d\u00e9termine laquelle est accessible.</p> <p>Approbation des Connexions : Les administrateurs peuvent exiger l'approbation manuelle avant qu'une connexion au point de terminaison priv\u00e9 soit \u00e9tablie.</p> <p>Int\u00e9gration avec les Pare-feu de Services : Les points de terminaison priv\u00e9s contournent les restrictions de pare-feu du service, offrant un acc\u00e8s direct.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#exemple-complet-point-de-terminaison-prive-pour-azure-key-vault","title":"Exemple Complet : Point de Terminaison Priv\u00e9 pour Azure Key Vault","text":"Bash<pre><code># Cr\u00e9er un Azure Key Vault\naz keyvault create \\\n  --name myKeyVault \\\n  --resource-group myResourceGroup \\\n  --location eastus\n\n# Cr\u00e9er un point de terminaison priv\u00e9\naz network private-endpoint create \\\n  --resource-group myResourceGroup \\\n  --name myKeyVaultEndpoint \\\n  --vnet-name myVNet \\\n  --subnet mySubnet \\\n  --private-connection-resource-id /subscriptions/{subscription-id}/resourceGroups/myResourceGroup/providers/Microsoft.KeyVault/vaults/myKeyVault \\\n  --group-ids vault \\\n  --connection-name myKeyVaultConnection\n\n# Cr\u00e9er la zone DNS priv\u00e9e pour Key Vault\naz network private-dns zone create \\\n  --resource-group myResourceGroup \\\n  --name privatelink.vaultcore.azure.net\n\n# Lier la zone DNS au VNet\naz network private-dns link vnet create \\\n  --resource-group myResourceGroup \\\n  --zone-name privatelink.vaultcore.azure.net \\\n  --name myKeyVaultDNSLink \\\n  --virtual-network /subscriptions/{subscription-id}/resourceGroups/myResourceGroup/providers/Microsoft.Network/virtualNetworks/myVNet\n\n# D\u00e9sactiver l'acc\u00e8s public au Key Vault\naz keyvault update \\\n  --name myKeyVault \\\n  --resource-group myResourceGroup \\\n  --public-network-access false\n\n# Ajouter une machine virtuelle au sous-r\u00e9seau pour tester\n# (\u00c0 partir de la machine virtuelle dans le VNet, on peut acc\u00e9der au Key Vault via le point de terminaison priv\u00e9)\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap06/#resume-et-integration-des-services-de-reseau-azure","title":"R\u00e9sum\u00e9 et Int\u00e9gration des Services de R\u00e9seau Azure","text":"<p>Les services de r\u00e9seau Azure forment un \u00e9cosyst\u00e8me complet permettant de construire des architectures robustes, s\u00e9curis\u00e9es et performantes. L'int\u00e9gration de ces services cr\u00e9e une fondation r\u00e9seau pour toute infrastructure cloud Azure.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#flux-dapprentissage-recommande","title":"Flux d'Apprentissage Recommand\u00e9","text":"<p>Fondamentaux : Commencer par comprendre les r\u00e9seaux virtuels (VNet), les sous-r\u00e9seaux et l'adressage IP. Ces concepts constituent la base sur laquelle reposent tous les autres services r\u00e9seau.</p> <p>S\u00e9curit\u00e9 de Base : Ma\u00eetriser les groupes de s\u00e9curit\u00e9 r\u00e9seau (NSG) pour contr\u00f4ler le trafic et comprendre comment les r\u00e8gles de pare-feu prot\u00e8gent les ressources.</p> <p>Connectivit\u00e9 Intra-Azure : Apprendre le VNet Peering pour connecter plusieurs r\u00e9seaux virtuels et comprendre comment faciliter la communication entre ressources Azure.</p> <p>R\u00e9solution de Noms : Configurer Azure DNS pour g\u00e9rer la r\u00e9solution de noms \u00e0 la fois publiquement et en priv\u00e9, permettant un acc\u00e8s convivial aux ressources.</p> <p>Connectivit\u00e9 Hybride : Progresser vers les VPN et ExpressRoute pour connecter les environnements locaux \u00e0 Azure, cr\u00e9ant ainsi une infrastructure v\u00e9ritablement hybride.</p> <p>Acc\u00e8s S\u00e9curis\u00e9 : Finalement, impl\u00e9menter les points de terminaison priv\u00e9s pour s\u00e9curiser l'acc\u00e8s aux services Azure, \u00e9liminant l'exposition \u00e0 Internet public.</p>"},{"location":"_projects/_formation-azure/azure-chap06/#considerations-darchitecture","title":"Consid\u00e9rations d'Architecture","text":"<p>Segmentation R\u00e9seau : Utiliser plusieurs sous-r\u00e9seaux et NSG pour cr\u00e9er des zones de s\u00e9curit\u00e9 distinctes dans le VNet.</p> <p>Haute Disponibilit\u00e9 : D\u00e9ployer les ressources critiques dans plusieurs zones de disponibilit\u00e9 et utiliser les \u00e9quilibreurs de charge pour distribuer le trafic.</p> <p>Conformit\u00e9 et S\u00e9curit\u00e9 : Impl\u00e9menter les points de terminaison priv\u00e9s, les zones DNS priv\u00e9es et les connexions ExpressRoute pour satisfaire les exigences r\u00e9glementaires.</p> <p>Performance : S\u00e9lectionner entre VNet Peering (faible latence) et VPN (chiffrement) selon les besoins, ou utiliser ExpressRoute pour les applications critiques.</p> <p>Gestion Op\u00e9rationnelle : Utiliser Azure CLI, PowerShell ou les mod\u00e8les ARM pour une gestion infrastructure-as-code, facilitant la r\u00e9p\u00e9tabilit\u00e9 et la maintenance.</p> <p>Cette compr\u00e9hension globale des services de r\u00e9seau Azure offre la base n\u00e9cessaire pour concevoir et d\u00e9ployer des architectures cloud d'entreprise robustes et s\u00e9curis\u00e9es.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure/azure-chap07/","title":"Citations","text":"<ul> <li>https://www.youtube.com/watch?v=QLbZyCLK39g</li> <li>https://learn.microsoft.com/fr-fr/azure/storage/blobs/storage-quickstart-blobs-java</li> <li>https://learn.microsoft.com/fr-fr/sql/relational-databases/tutorial-use-azure-blob-storage-service-with-sql-server?view=sql-server-ver17</li> <li>https://learn.microsoft.com/fr-fr/azure/storage/blobs/quickstart-storage-explorer</li> <li>https://www.varonis.com/fr/blog/azure-blob-storage</li> <li>https://learn.microsoft.com/fr-fr/azure/storage/blobs/storage-blobs-introduction</li> <li>https://learn.microsoft.com/fr-fr/azure/storage/blobs/</li> <li>https://learn.microsoft.com/fr-fr/shows/azure-videos/introduction-to-azure-blob-storage</li> <li>https://microsoftlearning.github.io/Secure-storage-for-Azure-Files-and-Azure-Blob-Storage.fr-fr/Instructions/Demos/DEMO_02_blob_storage.html</li> <li>https://help.qlik.com/talend/fr-FR/connectors-guide/Cloud/connector-azureblob</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap07/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 374</li> <li>completion_tokens: 5168</li> <li>total_tokens: 5542</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.078, 'request_cost': 0.006, 'total_cost': 0.085}</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap07/#content","title":"Content","text":""},{"location":"_projects/_formation-azure/azure-chap07/#chapitre-7-les-services-de-stockage-azure","title":"Chapitre 7 : Les Services de Stockage Azure \ud83d\ude80","text":""},{"location":"_projects/_formation-azure/azure-chap07/#introduction-aux-services-de-stockage-azure","title":"Introduction aux Services de Stockage Azure","text":"<p>Azure Storage constitue la solution cloud de Microsoft pour les besoins de stockage de donn\u00e9es modernes. Cette plateforme offre un service d'objet hautement scalable et s\u00e9curis\u00e9, capable de g\u00e9rer des volumes massifs de donn\u00e9es non structur\u00e9es telles que des donn\u00e9es texte ou binaires[6]. Les utilisateurs et les applications clientes peuvent acc\u00e9der aux objets stock\u00e9s via le protocole HTTP/HTTPS depuis n'importe quel endroit du monde[6].</p> <p>Les services de stockage Azure s'articulent autour de plusieurs composants essentiels :</p> <ul> <li>Blob Storage : pour le stockage d'objets volumineux et non structur\u00e9s</li> <li>Azure Files : pour les partages de fichiers cloud</li> <li>Azure Tables : pour le stockage NoSQL structur\u00e9</li> <li>Azure Queues : pour la mise en file d'attente des messages</li> </ul> <p>L'acc\u00e8s \u00e0 ces services peut s'effectuer par plusieurs moyens : via l'API REST Stockage Azure, Azure PowerShell, Azure CLI, ou les biblioth\u00e8ques de client disponibles pour diff\u00e9rents langages de programmation[6].</p>"},{"location":"_projects/_formation-azure/azure-chap07/#stocker-des-objets-avec-azure-blob-storage","title":"Stocker des Objets avec Azure Blob Storage \ud83d\udce6","text":""},{"location":"_projects/_formation-azure/azure-chap07/#concepts-fondamentaux","title":"Concepts Fondamentaux","text":"<p>Azure Blob Storage est un service de stockage d'objets optimis\u00e9 pour stocker de grandes quantit\u00e9s de donn\u00e9es non structur\u00e9es[6][8]. Le stockage Blob est hautement \u00e9volutif et s\u00e9curis\u00e9, offrant plusieurs niveaux de performance pour adapter les solutions aux besoins sp\u00e9cifiques[8].</p>"},{"location":"_projects/_formation-azure/azure-chap07/#terminologie-cle","title":"Terminologie Cl\u00e9","text":"<p>Compte de stockage : espace de noms de niveau sup\u00e9rieur qui fournit le contexte de base pour tous les services BLOB[2]. C'est \u00e0 partir de ce compte que l'on structure l'organisation des donn\u00e9es.</p> <p>Conteneur : structure interm\u00e9diaire cr\u00e9\u00e9e au sein d'un compte de stockage qui organise les blobs[1][2]. Chaque conteneur peut recevoir un nom personnalis\u00e9 selon les besoins d'organisation.</p> <p>Blob : fichier ou objet stock\u00e9 au sein d'un conteneur. Blob Storage prend en charge trois types d'objets[4] :</p> <ol> <li>Objets blob de blocs : format standard pour la majorit\u00e9 des fichiers stock\u00e9s</li> <li>Objets blob de pages : utilis\u00e9s pour les fichiers de disque dur virtuel (VHD) soutenant les machines virtuelles IaaS</li> <li>Objets blob d'ajout : sp\u00e9cialis\u00e9s pour la journalisation et les scenarios d'ajout de donn\u00e9es continues</li> </ol>"},{"location":"_projects/_formation-azure/azure-chap07/#architecture-du-service","title":"Architecture du Service","text":"Text Only<pre><code>Compte de Stockage Azure\n    \u251c\u2500\u2500 Conteneur (data)\n    \u2502   \u251c\u2500\u2500 Blob 1 (document.pdf)\n    \u2502   \u251c\u2500\u2500 Blob 2 (image.jpg)\n    \u2502   \u2514\u2500\u2500 Blob 3 (video.mp4)\n    \u251c\u2500\u2500 Conteneur (logs)\n    \u2502   \u251c\u2500\u2500 Blob 1 (app.log)\n    \u2502   \u2514\u2500\u2500 Blob 2 (error.log)\n    \u2514\u2500\u2500 Conteneur ($root)\n        \u2514\u2500\u2500 (Configuration par d\u00e9faut)\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap07/#optimiser-les-couts-avec-les-niveaux-de-stockage-blob","title":"Optimiser les Co\u00fbts avec les Niveaux de Stockage Blob \ud83d\udcb0","text":""},{"location":"_projects/_formation-azure/azure-chap07/#strategies-de-niveaux-dacces","title":"Strat\u00e9gies de Niveaux d'Acc\u00e8s","text":"<p>Azure Blob Storage offre plusieurs niveaux pour optimiser le rapport entre co\u00fbt et accessibilit\u00e9 des donn\u00e9es. Cette architecture multicouche permet d'adapter l'investissement en fonction des patterns d'acc\u00e8s aux donn\u00e9es.</p> <p>Les niveaux disponibles permettent de segmenter les donn\u00e9es selon leur fr\u00e9quence d'utilisation :</p> Niveau Fr\u00e9quence d'Acc\u00e8s Co\u00fbt de Stockage Co\u00fbt d'Acc\u00e8s Cas d'Usage Hot (Chaud) Fr\u00e9quent \u00c9lev\u00e9 Faible Donn\u00e9es actives utilis\u00e9es quotidiennement Cool (Frais) Occasionnel Moyen Moyen Donn\u00e9es acc\u00e9d\u00e9es mensuellement Cold (Froid) Rare Faible \u00c9lev\u00e9 Donn\u00e9es archiv\u00e9es acc\u00e9d\u00e9es annuellement Archive Tr\u00e8s rare Tr\u00e8s faible Tr\u00e8s \u00e9lev\u00e9 Donn\u00e9es de conformit\u00e9 \u00e0 long terme"},{"location":"_projects/_formation-azure/azure-chap07/#strategie-doptimisation","title":"Strat\u00e9gie d'Optimisation","text":"<p>Une approche efficace consiste \u00e0 migrer les donn\u00e9es vers des niveaux moins chers \u00e0 mesure que leur fr\u00e9quence d'acc\u00e8s diminue. Par exemple, les fichiers journaux peuvent commencer en niveau Hot, passer en Cool apr\u00e8s 30 jours, puis en Archive apr\u00e8s 90 jours.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#creer-un-compte-de-stockage","title":"Cr\u00e9er un Compte de Stockage \ud83c\udfd7\ufe0f","text":""},{"location":"_projects/_formation-azure/azure-chap07/#processus-de-deploiement","title":"Processus de D\u00e9ploiement","text":"<p>La cr\u00e9ation d'un compte de stockage constitue l'\u00e9tape fondamentale avant tout travail avec Blob Storage. Ce processus s'effectue via le portail Azure ou programmatiquement.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#approvisionnement-via-azure-cli","title":"Approvisionnement via Azure CLI","text":"<p>Pour provisionner rapidement un compte de stockage sur Azure, les commandes suivantes peuvent \u00eatre utilis\u00e9es :</p> Bash<pre><code># Se connecter \u00e0 Azure\nazd auth login\n\n# Provisionner et d\u00e9ployer les ressources\nazd up\n</code></pre> <p>Au cours de ce processus, deux informations essentielles doivent \u00eatre fournies[2] :</p> <ol> <li>Abonnement : l'abonnement Azure sur lequel les ressources seront d\u00e9ploy\u00e9es</li> <li>Emplacement : la r\u00e9gion Azure o\u00f9 r\u00e9sideront les ressources</li> </ol> <p>Le d\u00e9ploiement n\u00e9cessite g\u00e9n\u00e9ralement quelques minutes pour se compl\u00e9ter. Une fois termin\u00e9, la sortie de commande inclut le nom du compte de stockage nouvellement cr\u00e9\u00e9, information cruciale pour les \u00e9tapes ult\u00e9rieures[2].</p>"},{"location":"_projects/_formation-azure/azure-chap07/#configuration-du-compte","title":"Configuration du Compte","text":"<p>Le compte de stockage cr\u00e9e automatiquement un conteneur par d\u00e9faut destin\u00e9 \u00e0 stocker les configurations du compte. Il est ensuite possible de cr\u00e9er des conteneurs suppl\u00e9mentaires pour organiser les donn\u00e9es selon les besoins sp\u00e9cifiques de l'application ou du projet.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#les-disques-manages-pour-les-machines-virtuelles","title":"Les Disques Manag\u00e9s pour les Machines Virtuelles \ud83d\udcbf","text":""},{"location":"_projects/_formation-azure/azure-chap07/#integration-avec-les-machines-virtuelles","title":"Int\u00e9gration avec les Machines Virtuelles","text":"<p>Les disques manag\u00e9s constituent une composante essentielle de l'infrastructure Azure pour les machines virtuelles. Ces disques stock\u00e9s comme des objets blob de pages dans Blob Storage offrent une gestion simplifi\u00e9e par rapport aux disques non manag\u00e9s.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#avantages-des-disques-manages","title":"Avantages des Disques Manag\u00e9s","text":"<ul> <li>Gestion automatique : Azure g\u00e8re automatiquement la r\u00e9plication et la redondance</li> <li>Scalabilit\u00e9 : augmentation ou diminution facile de la taille des disques</li> <li>S\u00e9curit\u00e9 int\u00e9gr\u00e9e : chiffrement automatique des donn\u00e9es</li> <li>Performance pr\u00e9visible : SLA garanti pour la disponibilit\u00e9</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap07/#stockage-dans-blob","title":"Stockage dans Blob","text":"<p>Les fichiers VHD et VHDX utilis\u00e9s pour soutenir les machines virtuelles IaaS sont stock\u00e9s sous forme d'objets blob de pages dans Blob Storage[4]. Cette architecture garantit une performance coh\u00e9rente et une r\u00e9cup\u00e9ration rapide en cas de d\u00e9faillance.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#creer-un-conteneur-et-televerser-des-fichiers","title":"Cr\u00e9er un Conteneur et T\u00e9l\u00e9verser des Fichiers \ud83d\udce4","text":""},{"location":"_projects/_formation-azure/azure-chap07/#creation-de-conteneurs","title":"Cr\u00e9ation de Conteneurs","text":"<p>Un conteneur doit d'abord \u00eatre cr\u00e9\u00e9 dans le compte de stockage. Cette op\u00e9ration s'effectue via l'Explorateur Stockage Azure ou programmatiquement.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#creation-programmatique-en-java","title":"Cr\u00e9ation Programmatique en Java","text":"Java<pre><code>// Cr\u00e9er un conteneur en utilisant BlobServiceClient\nBlobServiceClient blobServiceClient = new BlobServiceClientBuilder()\n    .connectionString(connectionString)\n    .buildClient();\n\n// G\u00e9n\u00e9rer un nom de conteneur unique avec GUID\nString containerName = \"container-\" + UUID.randomUUID();\n\n// Cr\u00e9er le conteneur\nBlobContainerClient containerClient = blobServiceClient.createBlobContainer(containerName);\nSystem.out.println(\"Container created: \" + containerName);\n</code></pre> <p>La classe <code>BlobServiceClient</code> fournit une API de g\u00e9n\u00e9rateur Fluent pour faciliter la configuration et l'instanciation d'objets[2]. Cette approche garantit que chaque conteneur dispose d'un nom unique dans le compte de stockage.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#televersement-dobjets-blob","title":"T\u00e9l\u00e9versement d'Objets Blob","text":""},{"location":"_projects/_formation-azure/azure-chap07/#via-lexplorateur-stockage-azure","title":"Via l'Explorateur Stockage Azure","text":"<p>L'Explorateur Stockage Azure offre une interface graphique intuitive pour t\u00e9l\u00e9verser des fichiers[4]. Le processus se d\u00e9roule comme suit :</p> <ol> <li>S\u00e9lectionner le compte de stockage dans l'application Explorateur Stockage Azure</li> <li>Naviguer vers le conteneur cible</li> <li>Cliquer sur Charger pour initier le t\u00e9l\u00e9versement</li> <li>S\u00e9lectionner les fichiers \u00e0 t\u00e9l\u00e9verser depuis l'ordinateur local</li> </ol>"},{"location":"_projects/_formation-azure/azure-chap07/#options-de-televersement","title":"Options de T\u00e9l\u00e9versement","text":"<p>Lors du t\u00e9l\u00e9versement, plusieurs options doivent \u00eatre consid\u00e9r\u00e9es :</p> <ul> <li>Type d'objet blob : s\u00e9lectionner automatiquement le type appropri\u00e9 (bloc, page, ou ajout)</li> <li>Dossier de destination : sp\u00e9cifier un dossier optionnel au sein du conteneur</li> <li>Fichiers VHD/VHDX : une case \u00e0 cocher \"Charger les fichiers .vhd/.vhdx en tant qu'objets blob de pages (recommand\u00e9)\" facilite le t\u00e9l\u00e9versement de disques virtuels[4]</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap07/#traitement-des-televersements","title":"Traitement des T\u00e9l\u00e9versements","text":"<p>Lorsque le bouton Charger est s\u00e9lectionn\u00e9, les fichiers sont mis en file d'attente pour t\u00e9l\u00e9versement et trait\u00e9s un par un[4]. Une fois le t\u00e9l\u00e9versement termin\u00e9, les r\u00e9sultats s'affichent dans la fen\u00eatre Activit\u00e9s, confirmant le succ\u00e8s ou signalant les erreurs \u00e9ventuelles.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#affichage-des-objets-blob","title":"Affichage des Objets Blob","text":"<p>Dans l'application Explorateur Stockage Azure, la s\u00e9lection d'un conteneur sous un compte de stockage affiche une liste compl\u00e8te des objets blobs h\u00e9berg\u00e9s dans ce conteneur[4]. Cette interface facilite la gestion et le monitoring des fichiers stock\u00e9s.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#partager-des-fichiers-dans-le-cloud-avec-le-partage-de-fichiers","title":"Partager des Fichiers dans le Cloud avec le Partage de Fichiers \ud83c\udf10","text":""},{"location":"_projects/_formation-azure/azure-chap07/#service-azure-files","title":"Service Azure Files","text":"<p>Azure Files offre une solution de partage de fichiers cloud native, permettant aux utilisateurs d'acc\u00e9der \u00e0 des fichiers depuis n'importe o\u00f9. Ce service utilise le protocole SMB (Server Message Block) standard, facilitant l'int\u00e9gration avec les syst\u00e8mes existants.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#avantages-du-partage-de-fichiers","title":"Avantages du Partage de Fichiers","text":"<ul> <li>Acc\u00e8s \u00e0 distance : acc\u00e8s aux fichiers depuis n'importe quelle machine connect\u00e9e \u00e0 Internet</li> <li>Compatibilit\u00e9 : support natif des protocoles SMB standards</li> <li>Collaboration : partage facile de fichiers entre \u00e9quipes</li> <li>S\u00e9curit\u00e9 : int\u00e9gration avec Azure Active Directory et chiffrement</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap07/#cas-dusage","title":"Cas d'Usage","text":"<p>Azure Files convient particuli\u00e8rement pour :</p> <ul> <li>Les applications d'entreprise n\u00e9cessitant un stockage de fichiers centralis\u00e9</li> <li>Les environnements hybrides int\u00e9grant des infrastructures on-premises</li> <li>Les solutions de sauvegarde de fichiers critiques</li> <li>Les workflows collaboratifs n\u00e9cessitant un acc\u00e8s partag\u00e9</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap07/#stockage-nosql-avec-azure-table-et-azure-queue","title":"Stockage NoSQL avec Azure Table et Azure Queue \ud83d\uddc2\ufe0f","text":""},{"location":"_projects/_formation-azure/azure-chap07/#azure-table-storage","title":"Azure Table Storage","text":"<p>Azure Table Storage fournit une solution de stockage NoSQL structur\u00e9 pour les donn\u00e9es non relationnelles. Cette architecture permet de stocker des millions d'entit\u00e9s avec une latence faible et un acc\u00e8s hautement scalable.</p> <p>Caract\u00e9ristiques principales :</p> <ul> <li>Stockage cl\u00e9-valeur distribu\u00e9</li> <li>Requ\u00eates rapides sur des ensembles de donn\u00e9es volumineux</li> <li>Scalabilit\u00e9 automatique sans limite d'entit\u00e9s</li> <li>Sch\u00e9ma flexible adaptable aux \u00e9volutions</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap07/#azure-queue-storage","title":"Azure Queue Storage","text":"<p>Azure Queue Storage offre un syst\u00e8me de mise en file d'attente de messages pour d\u00e9coupler les composants d'une application[1]. Ce service facilite la communication asynchrone entre les microservices.</p> <p>Fonctionnalit\u00e9s cl\u00e9s :</p> <ul> <li>Mise en file d'attente fiable de messages</li> <li>Garantie de livraison unique des messages</li> <li>Traitement asynchrone des t\u00e2ches</li> <li>Scalabilit\u00e9 automatique selon la charge</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap07/#architecture-decouplee","title":"Architecture D\u00e9coupl\u00e9e","text":"Text Only<pre><code>Application Productrice\n        \u2193\n    Queue Azure\n        \u2193\nApplication Consommatrice\n</code></pre> <p>Cette architecture d\u00e9coupl\u00e9e permet \u00e0 l'application productrice de continuer fonctionner ind\u00e9pendamment du consommateur, am\u00e9liorant la r\u00e9silience et la scalabilit\u00e9 globale du syst\u00e8me.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#proteger-vos-donnees-avec-les-options-de-redondance","title":"Prot\u00e9ger vos Donn\u00e9es avec les Options de Redondance \ud83d\udd12","text":""},{"location":"_projects/_formation-azure/azure-chap07/#strategies-de-redondance","title":"Strat\u00e9gies de Redondance","text":"<p>Azure Storage offre plusieurs options de redondance pour garantir la durabilit\u00e9 et la disponibilit\u00e9 des donn\u00e9es[5]. Chaque strat\u00e9gie repr\u00e9sente un \u00e9quilibre diff\u00e9rent entre co\u00fbt et r\u00e9silience.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#niveaux-de-redondance","title":"Niveaux de Redondance","text":"Type R\u00e9plication Couverture G\u00e9ographique Co\u00fbt Cas d'Usage LRS (Locally Redundant Storage) 3 copies M\u00eame datacenter Minimal Donn\u00e9es non critiques ZRS (Zone Redundant Storage) 3 copies Zones de disponibilit\u00e9 Moyen Applications critiques r\u00e9gionales GRS (Geo Redundant Storage) 6 copies 2 r\u00e9gions distantes \u00c9lev\u00e9 Donn\u00e9es critiques avec r\u00e9cup\u00e9ration GZRS (Geo-Zone Redundant Storage) 6 copies Zones multiples + r\u00e9gions Tr\u00e8s \u00e9lev\u00e9 Applications ultra-critiques"},{"location":"_projects/_formation-azure/azure-chap07/#chiffrement-des-donnees","title":"Chiffrement des Donn\u00e9es","text":"<p>Azure Storage int\u00e8gre le chiffrement automatique de toutes les donn\u00e9es[5]. Les options incluent :</p> <ul> <li>Chiffrement au repos : tous les blobs sont automatiquement chiffr\u00e9s</li> <li>Cl\u00e9s manag\u00e9es par Microsoft : d\u00e9faut, aucune configuration requise</li> <li>Cl\u00e9s manag\u00e9es par le client : contr\u00f4le complet du cycle de vie des cl\u00e9s</li> <li>Chiffrement double : application de deux couches de chiffrement</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap07/#gestion-de-lacces-anonyme","title":"Gestion de l'Acc\u00e8s Anonyme","text":"<p>La gestion de l'acc\u00e8s anonyme constitue un aspect critique de la s\u00e9curit\u00e9[5]. Les conteneurs peuvent \u00eatre configur\u00e9s pour interdire l'acc\u00e8s anonyme, garantissant que seuls les utilisateurs authentifi\u00e9s peuvent acc\u00e9der aux donn\u00e9es sensibles.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#les-outils-de-migration-de-donnees","title":"Les Outils de Migration de Donn\u00e9es \ud83d\udd04","text":""},{"location":"_projects/_formation-azure/azure-chap07/#approches-de-migration","title":"Approches de Migration","text":"<p>Azure offre plusieurs outils pour migrer les donn\u00e9es vers Blob Storage, chacun adapt\u00e9 \u00e0 des scenarios sp\u00e9cifiques :</p>"},{"location":"_projects/_formation-azure/azure-chap07/#azure-data-factory","title":"Azure Data Factory","text":"<p>Azure Data Factory prend en charge la copie de donn\u00e9es vers et depuis Blob Storage[6]. Cet outil offre plusieurs options d'authentification :</p> <ul> <li>Cl\u00e9 de compte</li> <li>Signature d'acc\u00e8s partag\u00e9 (SAS)</li> <li>Principal du service</li> <li>Identit\u00e9s manag\u00e9es pour les ressources Azure</li> </ul> <p>Cette flexibilit\u00e9 permet l'int\u00e9gration avec des syst\u00e8mes de gestion des identit\u00e9s existants et l'adh\u00e9sion aux politiques de s\u00e9curit\u00e9 organisationnelles.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#sql-server-et-blob-storage","title":"SQL Server et Blob Storage","text":"<p>Le tutoriel d'utilisation de Blob Storage avec SQL Server[3] illustre comment int\u00e9grer le stockage cloud dans les workflows de base de donn\u00e9es existants. Les fichiers de donn\u00e9es et les sauvegardes peuvent \u00eatre stock\u00e9s dans Blob Storage, facilitant la r\u00e9cup\u00e9ration apr\u00e8s sinistre et la continuit\u00e9 d'activit\u00e9.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#lexplorateur-de-stockage-azure","title":"L'Explorateur de Stockage Azure \ud83d\udd0d","text":""},{"location":"_projects/_formation-azure/azure-chap07/#presentation-de-loutil","title":"Pr\u00e9sentation de l'Outil","text":"<p>L'Explorateur Stockage Azure constitue une application puissante pour g\u00e9rer tous les services de stockage Azure[4]. Cette interface graphique simplifie les op\u00e9rations sans n\u00e9cessiter de lignes de commande.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#options-de-connexion","title":"Options de Connexion","text":"<p>Au premier lancement, plusieurs options de ressources sont disponibles pour se connecter[4] :</p> <ul> <li>Abonnement : gestion de tous les services au sein d'un abonnement</li> <li>Compte de stockage : connexion directe \u00e0 un compte sp\u00e9cifique</li> <li>Conteneur d'objets blob : acc\u00e8s direct \u00e0 un conteneur</li> <li>Conteneur ou r\u00e9pertoire Azure Data Lake : support du stockage Data Lake</li> <li>Partage de fichiers : gestion des partages de fichiers</li> <li>File d'attente : monitoring des files d'attente</li> <li>Table : gestion des tables NoSQL</li> <li>\u00c9mulateur de stockage local : d\u00e9veloppement local sans compte cloud</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap07/#operations-courantes","title":"Op\u00e9rations Courantes","text":"<p>Affichage des Conteneurs et Blobs :</p> <p>La s\u00e9lection d'un conteneur dans l'Explorateur Stockage Azure affiche une liste compl\u00e8te des objets blobs h\u00e9berg\u00e9s[4]. Cette vue permet d'identifier rapidement les fichiers et leur statut.</p> <p>Gestion des Snapshots :</p> <p>L'outil permet de cr\u00e9er des captures instantan\u00e9es d'objets blob, facilitant la r\u00e9cup\u00e9ration de versions ant\u00e9rieures en cas de corruption ou de suppression accidentelle.</p> <p>Configuration des Strat\u00e9gies d'Acc\u00e8s :</p> <p>Les strat\u00e9gies d'acc\u00e8s de conteneur peuvent \u00eatre g\u00e9r\u00e9es directement depuis l'interface, contr\u00f4lant qui peut acc\u00e9der \u00e0 quels conteneurs.</p> <p>G\u00e9n\u00e9ration de Signatures d'Acc\u00e8s Partag\u00e9 (SAS) :</p> <p>L'Explorateur Stockage Azure peut g\u00e9n\u00e9rer des signatures d'acc\u00e8s partag\u00e9 offrant trois options pour l'utilisation[5] :</p> <ol> <li>Cha\u00eene de connexion pour les applications</li> <li>Jeton SAS isol\u00e9</li> <li>URL SAS de service Blob</li> </ol>"},{"location":"_projects/_formation-azure/azure-chap07/#le-stockage-haute-performance","title":"Le Stockage Haute Performance \u26a1","text":""},{"location":"_projects/_formation-azure/azure-chap07/#optimisation-des-performances","title":"Optimisation des Performances","text":"<p>Pour les applications exigeant une performance maximale, plusieurs strat\u00e9gies d'optimisation doivent \u00eatre appliqu\u00e9es :</p>"},{"location":"_projects/_formation-azure/azure-chap07/#considerations-de-performance","title":"Consid\u00e9rations de Performance","text":"<ul> <li>Parall\u00e9lisation : utilisation de connexions multiples pour augmenter le d\u00e9bit</li> <li>Taille des blobs : adaptation de la taille des objets selon les patterns d'acc\u00e8s</li> <li>Localisation : placement des ressources de calcul dans la m\u00eame r\u00e9gion que le stockage</li> <li>Mise en cache : impl\u00e9mentation de strat\u00e9gies de cache c\u00f4t\u00e9 client</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap07/#architecture-de-haute-disponibilite","title":"Architecture de Haute Disponibilit\u00e9","text":"Text Only<pre><code>R\u00e9gions Multiples\n\u251c\u2500\u2500 Zone 1 (primaire)\n\u2502   \u251c\u2500\u2500 Compute\n\u2502   \u2514\u2500\u2500 Blob Storage (Donn\u00e9es)\n\u251c\u2500\u2500 Zone 2 (secondaire)\n\u2502   \u251c\u2500\u2500 Compute\n\u2502   \u2514\u2500\u2500 Blob Storage (R\u00e9plique)\n\u2514\u2500\u2500 Zone 3 (tierce)\n    \u251c\u2500\u2500 Compute\n    \u2514\u2500\u2500 Blob Storage (R\u00e9plique)\n</code></pre> <p>Cette architecture garantit la performance m\u00eame en cas de d\u00e9faillance d'une zone.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#utilisation-des-cdn","title":"Utilisation des CDN","text":"<p>Pour les donn\u00e9es fr\u00e9quemment acc\u00e9d\u00e9es depuis le monde entier, l'int\u00e9gration avec Azure CDN (Content Delivery Network) acc\u00e9l\u00e8re les t\u00e9l\u00e9chargements en cachant les donn\u00e9es pr\u00e8s des utilisateurs finaux.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#les-outils-de-deplacement-de-fichiers","title":"Les Outils de D\u00e9placement de Fichiers \ud83d\udd27","text":""},{"location":"_projects/_formation-azure/azure-chap07/#azure-storage-explorer","title":"Azure Storage Explorer","text":"<p>Au-del\u00e0 de l'interface graphique, l'Explorateur Stockage Azure offre des capacit\u00e9s de d\u00e9placement de fichiers sophistiqu\u00e9es :</p> <p>Op\u00e9rations de Transfert :</p> <ul> <li>T\u00e9l\u00e9versement de r\u00e9pertoires complets</li> <li>T\u00e9l\u00e9chargement en masse de multiples fichiers</li> <li>Copie entre conteneurs ou comptes de stockage</li> <li>Synchronisation unidirectionnelle ou bidirectionnelle</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap07/#deplacement-via-conteneurs-sql-server","title":"D\u00e9placement via Conteneurs SQL Server","text":"<p>Le tutoriel SQL Server d\u00e9montre comment utiliser Blob Storage pour les fichiers de donn\u00e9es et les sauvegardes[3]. Le processus implique :</p> <ol> <li>Cr\u00e9ation d'un conteneur d\u00e9di\u00e9 aux fichiers de base de donn\u00e9es</li> <li>Configuration des informations d'identification SQL Server pour l'acc\u00e8s au stockage</li> <li>D\u00e9placement des fichiers .mdf et .ldf vers le conteneur</li> <li>Cr\u00e9ation et gestion des sauvegardes dans le m\u00eame conteneur</li> </ol>"},{"location":"_projects/_formation-azure/azure-chap07/#verification-des-transferts","title":"V\u00e9rification des Transferts","text":"<p>Apr\u00e8s chaque transfert, la v\u00e9rification s'effectue dans l'Explorateur d'objets[3] :</p> Text Only<pre><code>D\u00e9velopper Conteneurs\n\u251c\u2500\u2500 D\u00e9velopper le conteneur\n\u2502   \u251c\u2500\u2500 Fichiers de donn\u00e9es (AdventureWorks2022_Data.mdf)\n\u2502   \u251c\u2500\u2500 Fichiers de journaux (AdventureWorks2022_Log.ldf)\n\u2502   \u2514\u2500\u2500 Fichiers de sauvegarde (AdventureWorks2022_Azure.bak)\n</code></pre> <p>Cette structure organis\u00e9e facilite la r\u00e9cup\u00e9ration et la gestion ult\u00e9rieures.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#integration-azure-active-directory","title":"Int\u00e9gration Azure Active Directory","text":"<p>Pour les organizations \u00e0 grande \u00e9chelle, l'int\u00e9gration avec Azure Active Directory offre un contr\u00f4le d'acc\u00e8s granulaire[5]. Le contr\u00f4le d'acc\u00e8s bas\u00e9 sur les r\u00f4les (RBAC) permet d'assigner des permissions sp\u00e9cifiques \u00e0 des utilisateurs, des groupes ou des principaux de service d'application, garantissant que seul le personnel autoris\u00e9 peut acc\u00e9der ou modifier les donn\u00e9es en migration.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#synthese-du-parcours-dapprentissage","title":"Synth\u00e8se du Parcours d'Apprentissage \ud83c\udf93","text":"<p>Le parcours d'apprentissage propos\u00e9 construit progressivement les comp\u00e9tences n\u00e9cessaires pour ma\u00eetriser les services de stockage Azure :</p>"},{"location":"_projects/_formation-azure/azure-chap07/#phase-1-fondamentaux-semaines-1-2","title":"Phase 1 : Fondamentaux (Semaines 1-2)","text":"<p>La phase initiale \u00e9tablit une compr\u00e9hension solide des concepts de base. L'\u00e9tudiant explore la structure des services de stockage Azure, comprend la distinction entre Blob Storage et les autres services, et apprend les concepts fondamentaux de conteneurs et d'objets blobs.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#phase-2-configuration-pratique-semaines-3-4","title":"Phase 2 : Configuration Pratique (Semaines 3-4)","text":"<p>Cette phase transite vers la pratique en cr\u00e9ant un compte de stockage, en configurant des conteneurs, et en t\u00e9l\u00e9versant les premiers fichiers. L'Explorateur Stockage Azure devient l'outil principal d'interaction, offrant une interface conviviale pour les op\u00e9rations de base.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#phase-3-optimisation-et-securite-semaines-5-6","title":"Phase 3 : Optimisation et S\u00e9curit\u00e9 (Semaines 5-6)","text":"<p>L'\u00e9tudiant explore les strat\u00e9gies d'optimisation des co\u00fbts via les niveaux de stockage, configure les options de redondance appropri\u00e9es, et impl\u00e9mente les mesures de s\u00e9curit\u00e9 essentielles incluant le chiffrement et la gestion des acc\u00e8s.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#phase-4-integration-avancee-semaines-7-8","title":"Phase 4 : Int\u00e9gration Avanc\u00e9e (Semaines 7-8)","text":"<p>La phase finale couvre l'int\u00e9gration avec d'autres services Azure tels que SQL Server, la configuration des disques manag\u00e9s pour les machines virtuelles, et l'utilisation d'Azure Data Factory pour les migrations de donn\u00e9es complexes.</p>"},{"location":"_projects/_formation-azure/azure-chap07/#phase-5-optimisation-des-performances-semaines-9-10","title":"Phase 5 : Optimisation des Performances (Semaines 9-10)","text":"<p>L'\u00e9tudiant apprend \u00e0 configurer les architectures haute performance, \u00e0 utiliser les signatures d'acc\u00e8s partag\u00e9 pour la distribution s\u00e9curis\u00e9e des donn\u00e9es, et \u00e0 int\u00e9grer les services de stockage avec Azure Active Directory pour une gestion d'acc\u00e8s sophistiqu\u00e9e.</p> <p>Ce parcours progressif garantit que les \u00e9tudiants construisent une expertise compl\u00e8te, passant du stade novice aux comp\u00e9tences avanc\u00e9es en gestion de l'infrastructure de stockage cloud moderne.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure/azure-chap08/","title":"Citations","text":"<ul> <li>https://learn.microsoft.com/fr-fr/azure/security/fundamentals/identity-management-overview</li> <li>https://learn.microsoft.com/fr-fr/security/benchmark/azure/security-control-identity-access-control</li> <li>https://learn.microsoft.com/fr-fr/azure/security/fundamentals/management</li> <li>https://learn.microsoft.com/fr-fr/azure/security/fundamentals/management-monitoring-overview</li> <li>https://learn.microsoft.com/fr-fr/shows/on-demand-instructor-led-training-series/az-900-module-5</li> <li>https://learn.microsoft.com/fr-fr/azure/security/fundamentals/overview</li> <li>https://learn.microsoft.com/fr-fr/azure/security/fundamentals/identity-management-best-practices</li> <li>https://learn.microsoft.com/fr-fr/azure/security/</li> <li>https://learn.microsoft.com/fr-fr/training/paths/secure-identity-access/</li> <li>https://learn.microsoft.com/fr-fr/azure/security/fundamentals/physical-security</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap08/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 306</li> <li>completion_tokens: 7938</li> <li>total_tokens: 8244</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.119, 'request_cost': 0.006, 'total_cost': 0.126}</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap08/#content","title":"Content","text":""},{"location":"_projects/_formation-azure/azure-chap08/#gestion-des-acces-et-securite-sur-azure-guide-detaille","title":"\ud83d\udd10 Gestion des acc\u00e8s et s\u00e9curit\u00e9 sur Azure - Guide d\u00e9taill\u00e9","text":""},{"location":"_projects/_formation-azure/azure-chap08/#definir-identite-authentification-et-autorisation","title":"D\u00e9finir identit\u00e9, authentification et autorisation","text":""},{"location":"_projects/_formation-azure/azure-chap08/#les-concepts-fondamentaux","title":"Les concepts fondamentaux","text":"<p>La gestion des identit\u00e9s et des acc\u00e8s constitue la base de la s\u00e9curit\u00e9 cloud moderne. Ces trois concepts, souvent confondus, jouent des r\u00f4les distincts et compl\u00e9mentaires dans l'architecture de s\u00e9curit\u00e9 Azure.</p> <p>L'identit\u00e9 repr\u00e9sente l'entit\u00e9 num\u00e9rique qui peut \u00eatre authentifi\u00e9e dans le syst\u00e8me. Elle peut correspondre \u00e0 un utilisateur, une application, un appareil ou un service. Chaque identit\u00e9 dispose d'attributs uniques qui la caract\u00e9risent au sein d'une organisation.</p> <p>L'authentification est le processus de v\u00e9rification de l'identit\u00e9 d'une entit\u00e9. C'est l'\u00e9tape o\u00f9 le syst\u00e8me confirme que l'identit\u00e9 revendiqu\u00e9e est bien celle qu'elle pr\u00e9tend \u00eatre. Ce processus utilise diff\u00e9rents facteurs : quelque chose que l'on conna\u00eet (mot de passe), quelque chose que l'on poss\u00e8de (t\u00e9l\u00e9phone, cl\u00e9 de s\u00e9curit\u00e9) ou quelque chose qu'on est (biom\u00e9trie).</p> <p>L'autorisation intervient apr\u00e8s l'authentification r\u00e9ussie. Elle d\u00e9termine les ressources et les actions qu'une identit\u00e9 authentifi\u00e9e peut accomplir. L'autorisation s'appuie sur des r\u00f4les, des permissions et des strat\u00e9gies d'acc\u00e8s.</p>"},{"location":"_projects/_formation-azure/azure-chap08/#la-relation-entre-les-trois-concepts","title":"La relation entre les trois concepts","text":"Text Only<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Utilisateur demande l'acc\u00e8s \u00e0 une ressource   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502\n                 \u25bc\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502  AUTHENTIFICATION   \u2502\n        \u2502 \"Qui \u00eates-vous ?\"   \u2502\n        \u2502 - Mot de passe      \u2502\n        \u2502 - MFA               \u2502\n        \u2502 - Certificat        \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502\n          Authentification OK ?\n          (Oui/Non)\n                 \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502   AUTORISATION  \u2502\n        \u2502 \"Avez-vous le   \u2502\n        \u2502  droit d'agir ?\"\u2502\n        \u2502 - R\u00f4les         \u2502\n        \u2502 - Permissions   \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                 \u2502\n          Autorisation OK ?\n          (Oui/Non)\n                 \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 Acc\u00e8s accord\u00e9/refus\u00e9  \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap08/#introduction-a-microsoft-entra-id","title":"Introduction \u00e0 Microsoft Entra ID","text":""},{"location":"_projects/_formation-azure/azure-chap08/#quest-ce-que-microsoft-entra-id","title":"Qu'est-ce que Microsoft Entra ID ?","text":"<p>Microsoft Entra ID (anciennement Azure Active Directory) constitue le service central d'authentification et d'autorisation pour Azure[1]. Il s'agit d'un annuaire cloud qui g\u00e8re les identit\u00e9s de l'organisation, que ces identit\u00e9s soient locales ou bas\u00e9es sur le cloud.</p> <p>Microsoft Entra ID fournit une identit\u00e9 unique pour chaque utilisateur d'une organisation hybride, tout en maintenant la synchronisation des utilisateurs, des groupes et des appareils[1]. Il offre l'authentification unique (SSO) \u00e0 des milliers d'applications SaaS pr\u00e9int\u00e9gr\u00e9es et facilite l'acc\u00e8s aux applications web ex\u00e9cut\u00e9es localement[1].</p>"},{"location":"_projects/_formation-azure/azure-chap08/#les-editions-de-microsoft-entra-id","title":"Les \u00e9ditions de Microsoft Entra ID","text":"\u00c9dition Cas d'usage Fonctionnalit\u00e9s principales Gratuit Gestion basique des utilisateurs Gestion de groupe, synchronisation basique Office 365 Inclus avec Microsoft 365 SSO, MFA basique, gestion des appareils P1 Organisations moyennes Acc\u00e8s conditionnel, PIM, gestion hybride P2 Grandes organisations Protection des identit\u00e9s, reconnaissance d'anomalies IA"},{"location":"_projects/_formation-azure/azure-chap08/#capacites-principales-de-microsoft-entra-id1","title":"Capacit\u00e9s principales de Microsoft Entra ID[1]","text":"<p>Microsoft Entra ID P1 ou P2 fournit l'authentification unique (SSO) \u00e0 des milliers d'applications SaaS cloud et l'acc\u00e8s aux applications web ex\u00e9cut\u00e9es localement. Les capacit\u00e9s cl\u00e9s incluent :</p> <ul> <li>Cr\u00e9ation et gestion d'une identit\u00e9 unique pour chaque utilisateur de l'entreprise hybride</li> <li>Authentification unique vers les applications cloud et locales</li> <li>Authentification multifacteur bas\u00e9e sur des r\u00e8gles</li> <li>Proxy d'application pour acc\u00e8s s\u00e9curis\u00e9 aux applications web locales</li> <li>Synchronisation des utilisateurs, groupes et appareils</li> <li>Enregistrement de l'appareil</li> <li>Gestion des identit\u00e9s privil\u00e9gi\u00e9es (PIM)</li> <li>Protection des identit\u00e9s et d\u00e9tection des risques</li> <li>Gestion des identit\u00e9s hybrides via Microsoft Entra Connect</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap08/#architecture-de-microsoft-entra-id","title":"Architecture de Microsoft Entra ID","text":"Text Only<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           Applications et Services Cloud                 \u2502\n\u2502  (Microsoft 365, Dynamics 365, Applications SaaS)        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u25bc\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502   Microsoft Entra ID (Cloud)   \u2502\n        \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n        \u2502 \u2022 Authentification              \u2502\n        \u2502 \u2022 Autorisation                  \u2502\n        \u2502 \u2022 Gestion des identit\u00e9s         \u2502\n        \u2502 \u2022 Strat\u00e9gies d'acc\u00e8s            \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n            \u2502                         \u2502\n            \u25bc                         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Applications locales\u2502   \u2502 Applications SaaS    \u2502\n\u2502 (via App Proxy)     \u2502   \u2502 (directement li\u00e9es)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            \u2502                         \u2502\n            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n                         \u25bc\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502  Active Directory local (AD)   \u2502\n        \u2502 (synchronis\u00e9 via Entra Connect)\u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap08/#synchronisation-hybride-avec-microsoft-entra-connect1","title":"Synchronisation hybride avec Microsoft Entra Connect[1]","text":"<p>Les solutions d'identit\u00e9 de Microsoft s'\u00e9tendent sur des fonctionnalit\u00e9s locales et bas\u00e9es sur le cloud, cr\u00e9ant une identit\u00e9 utilisateur unique pour l'authentification et l'autorisation \u00e0 toutes les ressources, quel que soit l'emplacement. Microsoft Entra Connect est l'outil Microsoft con\u00e7u pour atteindre les objectifs d'identit\u00e9 hybride. Cela permet de fournir une identit\u00e9 commune pour les utilisateurs pour les applications Microsoft 365, Azure et SaaS int\u00e9gr\u00e9es \u00e0 l'ID Microsoft Entra.</p>"},{"location":"_projects/_formation-azure/azure-chap08/#les-methodes-dauthentification-azure","title":"Les m\u00e9thodes d'authentification Azure","text":""},{"location":"_projects/_formation-azure/azure-chap08/#les-differents-facteurs-dauthentification","title":"Les diff\u00e9rents facteurs d'authentification","text":"<p>Les m\u00e9thodes d'authentification dans Azure s'organisent selon plusieurs facteurs :</p> <p>Facteur de connaissance : Ce que l'utilisateur conna\u00eet - Mots de passe traditionnels - Codes PIN - R\u00e9ponses aux questions de s\u00e9curit\u00e9</p> <p>Facteur de possession : Ce que l'utilisateur poss\u00e8de - T\u00e9l\u00e9phone mobile - Cl\u00e9s de s\u00e9curit\u00e9 FIDO2 - Tokens mat\u00e9riels - Applications d'authentification</p> <p>Facteur biom\u00e9trique : Ce que l'utilisateur est - Empreinte digitale - Reconnaissance faciale - Reconnaissance d'iris</p>"},{"location":"_projects/_formation-azure/azure-chap08/#authentification-multifacteur-mfa","title":"Authentification multifacteur (MFA)","text":"<p>L'authentification multifacteur combine au moins deux facteurs d'authentification diff\u00e9rents. Cette approche renforce consid\u00e9rablement la s\u00e9curit\u00e9 en rendant l'acc\u00e8s non autoris\u00e9 beaucoup plus difficile, m\u00eame si un mot de passe est compromis.</p> Text Only<pre><code>Sc\u00e9nario : Un utilisateur se connecte \u00e0 Azure Portal\n\n\u00c9tape 1 - Authentification primaire\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Saisie du mail     \u2502\n\u2502 utilisateur@org.fr \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Saisie du mot de   \u2502\n\u2502 passe              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n   \u2713 Authentification primaire r\u00e9ussie\n\n\u00c9tape 2 - Authentification multifacteur\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Approbation re\u00e7ue sur le portable   \u2502\n\u2502 (via application Microsoft Auth)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 L'utilisateur approuve la connexion \u2502\n\u2502 sur son appareil mobile             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n   \u2713 MFA r\u00e9ussie - Acc\u00e8s accord\u00e9\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap08/#strategies-de-deploiement-mfa","title":"Strat\u00e9gies de d\u00e9ploiement MFA","text":"<p>MFA mandatoire pour les administrateurs : L'authentification multifacteur doit \u00eatre activ\u00e9e pour tous les comptes administratifs Azure[2].</p> <p>MFA bas\u00e9e sur les r\u00e8gles : La s\u00e9curisation de l'acc\u00e8s aux applications s'effectue en appliquant une authentification multifacteur bas\u00e9e sur des r\u00e8gles pour les applications aussi bien locales que cloud[1].</p> <p>MFA progressif : Le syst\u00e8me ajuste le niveau d'authentification requis en fonction du contexte de la connexion (localisation, appareil, comportement de l'utilisateur).</p>"},{"location":"_projects/_formation-azure/azure-chap08/#le-modele-confiance-zero","title":"Le mod\u00e8le Confiance Z\u00e9ro","text":""},{"location":"_projects/_formation-azure/azure-chap08/#principes-fondamentaux","title":"Principes fondamentaux","text":"<p>Le mod\u00e8le Confiance Z\u00e9ro (Zero Trust) repose sur l'hypoth\u00e8se que aucune entit\u00e9, interne ou externe, ne doit \u00eatre automatiquement approuv\u00e9e. Chaque acc\u00e8s doit \u00eatre v\u00e9rified, authentifi\u00e9 et autoris\u00e9, quel que soit le contexte.</p> <p>Les trois principes fondamentaux du mod\u00e8le Confiance Z\u00e9ro sont :</p> <p>V\u00e9rifier explicitement : Utiliser tous les points de donn\u00e9es disponibles pour authentifier et autoriser, y compris l'identit\u00e9 de l'utilisateur, l'emplacement, la sant\u00e9 de l'appareil, et le service ou l'application demand\u00e9e.</p> <p>Acc\u00e8s au moindre privil\u00e8ge : Limiter l'acc\u00e8s des utilisateurs au strict n\u00e9cessaire pour accomplir leurs t\u00e2ches, en utilisant Just-In-Time (JIT) et Just-Enough-Access (JEA).</p> <p>Supposer une compromission : Minimiser l'\u00e9tendue des d\u00e9g\u00e2ts en segmentant l'acc\u00e8s par r\u00e9seau, utilisateur, appareil et application.</p>"},{"location":"_projects/_formation-azure/azure-chap08/#implementation-du-confiance-zero-dans-azure","title":"Impl\u00e9mentation du Confiance Z\u00e9ro dans Azure","text":"Text Only<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           Demande d'acc\u00e8s \u00e0 une ressource            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 1. V\u00e9rification      \u2502\n    \u2502    Explicite         \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 \u2022 Identit\u00e9           \u2502\n    \u2502 \u2022 Appareil           \u2502\n    \u2502 \u2022 Localisation       \u2502\n    \u2502 \u2022 Contexte           \u2502\n    \u2502 \u2022 Comportement       \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 2. Authentification &amp;   \u2502\n    \u2502    Autorisation         \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 \u2022 MFA                    \u2502\n    \u2502 \u2022 Validation de l'acc\u00e8s  \u2502\n    \u2502 \u2022 V\u00e9rification des r\u00f4les \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 3. Moindre privil\u00e8ge    \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 \u2022 Acc\u00e8s JIT             \u2502\n    \u2502 \u2022 Permissions minimales  \u2502\n    \u2502 \u2022 Dur\u00e9e limit\u00e9e         \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 4. Surveillance         \u2502\n    \u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n    \u2502 \u2022 Audit de l'acc\u00e8s      \u2502\n    \u2502 \u2022 D\u00e9tection d'anomalies \u2502\n    \u2502 \u2022 Alertes en temps r\u00e9el \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n        \u2713 ou \u2717 D\u00e9cision\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap08/#detection-des-risques-et-des-vulnerabilites","title":"D\u00e9tection des risques et des vuln\u00e9rabilit\u00e9s","text":"<p>Microsoft Entra ID Protection d\u00e9tecte les vuln\u00e9rabilit\u00e9s potentielles et les activit\u00e9s risqu\u00e9es affectant les identit\u00e9s de l'organisation[1]. Cette protection permet des niveaux suppl\u00e9mentaires de validation, tels que l'authentification multifacteur et les strat\u00e9gies d'acc\u00e8s conditionnel[1].</p>"},{"location":"_projects/_formation-azure/azure-chap08/#lacces-conditionnel","title":"L'acc\u00e8s conditionnel","text":""},{"location":"_projects/_formation-azure/azure-chap08/#concept-et-fonctionnement","title":"Concept et fonctionnement","text":"<p>L'acc\u00e8s conditionnel repr\u00e9sente une approche dynamique de la gestion des acc\u00e8s qui \u00e9value les conditions lors de chaque tentative d'acc\u00e8s et applique les politiques appropri\u00e9es en fonction de ces conditions.</p>"},{"location":"_projects/_formation-azure/azure-chap08/#composants-dune-politique-dacces-conditionnel","title":"Composants d'une politique d'acc\u00e8s conditionnel","text":"Composant Description Exemples Utilisateurs et groupes Qui fait la demande Administrateurs, groupe Marketing, utilisateur sp\u00e9cifique Applications cloud Vers quoi l'acc\u00e8s est demand\u00e9 Microsoft 365, Azure Portal, applications m\u00e9tier Conditions \u00c9valuation du contexte Localisation, type d'appareil, plateforme, risque Contr\u00f4les d'acc\u00e8s Actions \u00e0 appliquer MFA, appareil conforme, limite de session"},{"location":"_projects/_formation-azure/azure-chap08/#exemple-de-politique-dacces-conditionnel-administrateurs","title":"Exemple de politique d'acc\u00e8s conditionnel : Administrateurs","text":"<p>Sc\u00e9nario : Exiger MFA pour tous les administrateurs, peu importe leur localisation</p> Text Only<pre><code>Politique : \"MFA pour les administrateurs\"\n\nAssignations :\n\u251c\u2500 Utilisateurs et groupes : R\u00f4le Admin Azure AD\n\u251c\u2500 Applications cloud : Microsoft Azure Management\n\u251c\u2500 Conditions :\n\u2502  \u2514\u2500 Aucune condition (tous les contextes)\n\nContr\u00f4les d'acc\u00e8s :\n\u251c\u2500 Accorder l'acc\u00e8s\n\u251c\u2500 Exiger : Authentification multifacteur\n\u2514\u2500 Exiger : Appareil conforme\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap08/#exemple-de-politique-dacces-conditionnel-localisation","title":"Exemple de politique d'acc\u00e8s conditionnel : Localisation","text":"<p>Sc\u00e9nario : Bloquer les acc\u00e8s en dehors des heures de travail et de localisation</p> Text Only<pre><code>Politique : \"Acc\u00e8s hors horaires restreint\"\n\nAssignations :\n\u251c\u2500 Utilisateurs et groupes : Tous les utilisateurs\n\u251c\u2500 Applications cloud : Applications m\u00e9tier sensibles\n\u251c\u2500 Conditions :\n\u2502  \u251c\u2500 Localisation : En dehors des emplacements nomm\u00e9s\n\u2502  \u2514\u2500 Heure : En dehors des heures de travail\n\nContr\u00f4les d'acc\u00e8s :\n\u2514\u2500 Bloquer l'acc\u00e8s\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap08/#exemple-de-politique-dacces-conditionnel-appareil-non-conforme","title":"Exemple de politique d'acc\u00e8s conditionnel : Appareil non conforme","text":"<p>Sc\u00e9nario : Exiger MFA ou rejeter les appareils non g\u00e9r\u00e9s</p> Text Only<pre><code>Politique : \"Appareils non g\u00e9r\u00e9s\"\n\nAssignations :\n\u251c\u2500 Utilisateurs et groupes : Tous les utilisateurs\n\u251c\u2500 Applications cloud : Microsoft 365\n\u251c\u2500 Conditions :\n\u2502  \u2514\u2500 \u00c9tat de l'appareil : Appareil non conforme\n\nContr\u00f4les d'acc\u00e8s :\n\u251c\u2500 OU (au moins une condition)\n\u2502  \u251c\u2500 Exiger : Authentification multifacteur\n\u2502  \u2514\u2500 Exiger : Appareil conforme\n\u2514\u2500 Ou : Bloquer l'acc\u00e8s\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap08/#les-identites-externes","title":"Les identit\u00e9s externes","text":""},{"location":"_projects/_formation-azure/azure-chap08/#gestion-des-identites-externes","title":"Gestion des identit\u00e9s externes","text":"<p>Les identit\u00e9s externes repr\u00e9sentent les utilisateurs en dehors de l'organisation qui ont besoin d'acc\u00e9der aux ressources Azure. Cela inclut les partenaires, les clients, les contractuels et les fournisseurs.</p> <p>Microsoft Entra ID permet la gestion des identit\u00e9s et des acc\u00e8s des consommateurs[1], facilitant la collaboration s\u00e9curis\u00e9e avec des entit\u00e9s externes.</p>"},{"location":"_projects/_formation-azure/azure-chap08/#scenarios-didentites-externes","title":"Sc\u00e9narios d'identit\u00e9s externes","text":"<p>Collaboration B2B (Business to Business) : Les utilisateurs d'une organisation partenaire re\u00e7oivent l'acc\u00e8s \u00e0 certaines ressources de l'organisation h\u00f4te. Ils conservent leur identit\u00e9 propre.</p> Text Only<pre><code>Organisation A                    Organisation B\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510            \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Utilisateurs A  \u2502            \u2502  Utilisateurs B  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518            \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502                              \u2502\n         \u2502 Identit\u00e9 A                   \u2502 Identit\u00e9 B\n         \u2502 (Entra ID A)                 \u2502 (Entra ID B)\n         \u2502                              \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                        \u2502\n                Invitation B2B\n                        \u2502\n                \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n                \u2502  Ressources A  \u2502\n                \u2502 (partag\u00e9es avec\u2502\n                \u2502   utilisateurs \u2502\n                \u2502    B via B2B)  \u2502\n                \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre> <p>Partenaires externes : Des utilisateurs d'organisations partenaires peuvent acc\u00e9der \u00e0 des portails ou applications sp\u00e9cifiques avec des credentials f\u00e9d\u00e9r\u00e9es.</p> <p>Acc\u00e8s en tant que consommateur : Les clients acc\u00e8dent \u00e0 des applications SaaS avec leurs propres comptes.</p>"},{"location":"_projects/_formation-azure/azure-chap08/#le-controle-dacces-en-fonction-du-role-azure-rbac","title":"Le contr\u00f4le d'acc\u00e8s en fonction du r\u00f4le (Azure RBAC)","text":""},{"location":"_projects/_formation-azure/azure-chap08/#principes-fondamentaux_1","title":"Principes fondamentaux","text":"<p>Le contr\u00f4le d'acc\u00e8s en fonction du r\u00f4le Azure (RBAC) fournit une gestion des acc\u00e8s affin\u00e9e pour les ressources Azure[4]. Au lieu de donner des permissions individuelles \u00e0 des utilisateurs sp\u00e9cifiques, le RBAC assigne des r\u00f4les qui groupent des permissions connexes.</p> <p>Restreindre l'acc\u00e8s en fonction des principes du besoin de conna\u00eetre et du privil\u00e8ge minimum est imp\u00e9ratif pour les organisations d\u00e9sireuses d'appliquer des strat\u00e9gies de s\u00e9curit\u00e9 pour l'acc\u00e8s aux donn\u00e9es[6].</p>"},{"location":"_projects/_formation-azure/azure-chap08/#structure-du-controle-dacces-en-fonction-du-role","title":"Structure du contr\u00f4le d'acc\u00e8s en fonction du r\u00f4le","text":"Text Only<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Assignation de r\u00f4le RBAC         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 Qui ? \u2192 Utilisateur/Groupe/Service       \u2502\n\u2502 Quoi ? \u2192 R\u00f4le (ensemble de permissions)  \u2502\n\u2502 O\u00f9 ? \u2192 \u00c9tendue (Resource/RG/Abonnement) \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n        Utilisateur : alice@org.fr\n              \u2502\n              \u25bc\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502   R\u00f4le :     \u2502\n        \u2502 Contributeur \u2502\n        \u2502 \u00e0 Storage    \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2502\n              \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 \u00c9tendue :           \u2502\n    \u2502 Groupe de ressources\u2502\n    \u2502 \"Production\"        \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n              \u2502\n              \u25bc\n    \u2713 Alice peut g\u00e9rer\n      Storage Accounts\n      dans le groupe\n      \"Production\"\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap08/#roles-predefinis-principaux","title":"R\u00f4les pr\u00e9d\u00e9finis principaux","text":"R\u00f4le Permissions Cas d'usage Propri\u00e9taire Acc\u00e8s complet \u00e0 toutes les ressources, y compris le droit de d\u00e9l\u00e9guer l'acc\u00e8s \u00e0 d'autres[1] Administrateurs syst\u00e8me, propri\u00e9taires d'abonnement Contributeur Peut cr\u00e9er et g\u00e9rer tous les types de ressources Azure, mais ne peut pas accorder l'acc\u00e8s \u00e0 d'autres personnes[1] D\u00e9veloppeurs, ing\u00e9nieurs DevOps, administrateurs de ressources Lecteur Peut afficher les ressources Azure existantes[1] Auditeurs, responsables, consultants en lecture seule Administrateur de l'acc\u00e8s utilisateur Permet de g\u00e9rer l'acc\u00e8s utilisateur aux ressources Azure[1] Administrateurs d'acc\u00e8s, responsables d'\u00e9quipe"},{"location":"_projects/_formation-azure/azure-chap08/#creation-dun-role-personnalise","title":"Cr\u00e9ation d'un r\u00f4le personnalis\u00e9","text":"<p>Les r\u00f4les personnalis\u00e9s permettent de d\u00e9finir des permissions pr\u00e9cises adapt\u00e9es aux besoins sp\u00e9cifiques de l'organisation.</p> JSON<pre><code>{\n  \"Name\": \"Custom - Virtual Machine Operator\",\n  \"Id\": \"00000000-0000-0000-0000-000000000000\",\n  \"IsCustom\": true,\n  \"Description\": \"Can monitor and restart virtual machines\",\n  \"Permissions\": [\n    {\n      \"Actions\": [\n        \"Microsoft.Compute/virtualMachines/read\",\n        \"Microsoft.Compute/virtualMachines/start/action\",\n        \"Microsoft.Compute/virtualMachines/powerOff/action\",\n        \"Microsoft.Compute/virtualMachines/restart/action\"\n      ],\n      \"NotActions\": [],\n      \"DataActions\": [],\n      \"NotDataActions\": []\n    }\n  ],\n  \"AssignableScopes\": [\n    \"/subscriptions/00000000-0000-0000-0000-000000000000\"\n  ]\n}\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap08/#exemple-dassignation-de-role","title":"Exemple d'assignation de r\u00f4le","text":"PowerShell<pre><code># Assigner le r\u00f4le \"Contributeur\" \u00e0 un utilisateur sur une ressource\nNew-AzRoleAssignment -ObjectId &lt;user-object-id&gt; `\n                     -RoleDefinitionName \"Contributor\" `\n                     -Scope \"/subscriptions/&lt;subscription-id&gt;/resourceGroups/&lt;resource-group&gt;\"\n\n# Assigner le r\u00f4le \"Lecteur\" \u00e0 un groupe sur un abonnement\nNew-AzRoleAssignment -ObjectId &lt;group-object-id&gt; `\n                     -RoleDefinitionName \"Reader\" `\n                     -Scope \"/subscriptions/&lt;subscription-id&gt;\"\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap08/#principes-du-moindre-privilege-et-just-in-time","title":"Principes du moindre privil\u00e8ge et Just-In-Time","text":"<p>L'acc\u00e8s Just-In-Time / Just-Enough-Access peut \u00eatre activ\u00e9 en utilisant les r\u00f4les privil\u00e9gi\u00e9s de la gestion des identit\u00e9s privil\u00e9gi\u00e9es Azure AD pour les services Microsoft et le gestionnaire de ressources Azure[2].</p> Text Only<pre><code>Sc\u00e9nario : Un administrateur a besoin d'acc\u00e8s temporaire\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 1. Demande d'activation de r\u00f4le     \u2502\n\u2502    (Dur\u00e9e limit\u00e9e : 8 heures)       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 2. Approver\u2502 (Demande d'approbation)\n        \u2502    le r\u00f4le  \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 3. Acc\u00e8s accord\u00e9          \u2502\n        \u2502    pour 8 heures          \u2502\n        \u2502    (Just-In-Time)         \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n               \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502 4. Expiration automatique \u2502\n        \u2502    apr\u00e8s 8 heures        \u2502\n        \u2502    (Moindre privil\u00e8ge)    \u2502\n        \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap08/#le-modele-de-la-defense-en-profondeur","title":"Le mod\u00e8le de la D\u00e9fense en profondeur","text":""},{"location":"_projects/_formation-azure/azure-chap08/#architecture-multi-couches","title":"Architecture multi-couches","text":"<p>La d\u00e9fense en profondeur (Defense in Depth) adopte une approche multi-couches o\u00f9 plusieurs niveaux de s\u00e9curit\u00e9 se superposent pour prot\u00e9ger les ressources. Si une couche est compromise, les autres continuent de fonctionner.</p>"},{"location":"_projects/_formation-azure/azure-chap08/#les-sept-couches-de-la-defense-en-profondeur","title":"Les sept couches de la d\u00e9fense en profondeur","text":"Text Only<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Couche 7 : Application et donn\u00e9es                      \u2502\n\u2502 \u2022 Firewalls WAF                                        \u2502\n\u2502 \u2022 Chiffrement des donn\u00e9es                              \u2502\n\u2502 \u2022 Contr\u00f4le d'acc\u00e8s au niveau applicatif                \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Couche 6 : Identit\u00e9 et acc\u00e8s                           \u2502\n\u2502 \u2022 MFA                                                   \u2502\n\u2502 \u2022 Acc\u00e8s conditionnel                                    \u2502\n\u2502 \u2022 RBAC                                                  \u2502\n\u2502 \u2022 PIM                                                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Couche 5 : P\u00e9rim\u00e8tre                                   \u2502\n\u2502 \u2022 DDoS Protection                                      \u2502\n\u2502 \u2022 Firewalls                                            \u2502\n\u2502 \u2022 VPN et ExpressRoute                                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Couche 4 : R\u00e9seau                                      \u2502\n\u2502 \u2022 Groupes de s\u00e9curit\u00e9 r\u00e9seau (NSG)                     \u2502\n\u2502 \u2022 Segmentation r\u00e9seau                                   \u2502\n\u2502 \u2022 VPC/VNet                                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Couche 3 : Compute                                     \u2502\n\u2502 \u2022 Pare-feu h\u00f4te                                        \u2502\n\u2502 \u2022 Hardening des syst\u00e8mes d'exploitation                \u2502\n\u2502 \u2022 Mises \u00e0 jour de s\u00e9curit\u00e9                             \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Couche 2 : Infrastructure cloud                        \u2502\n\u2502 \u2022 Chiffrement au repos                                 \u2502\n\u2502 \u2022 Isolation r\u00e9seau virtuelle                           \u2502\n\u2502 \u2022 Contr\u00f4le d'acc\u00e8s aux ressources                      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                         \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Couche 1 : Infrastructure physique                     \u2502\n\u2502 \u2022 S\u00e9curit\u00e9 physique des datacenters                    \u2502\n\u2502 \u2022 Contr\u00f4le d'acc\u00e8s biom\u00e9trique                         \u2502\n\u2502 \u2022 Surveillance vid\u00e9o                                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap08/#integration-des-composants-de-securite-azure","title":"Int\u00e9gration des composants de s\u00e9curit\u00e9 Azure","text":"Text Only<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502              Applications et Services                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502               \u2502               \u2502\n     \u25bc               \u25bc               \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Azure DDoS\u2502  \u2502Azure WAF \u2502  \u2502Application  \u2502\n\u2502Protection\u2502  \u2502          \u2502  \u2502Security     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502               \u2502               \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n                     \u25bc\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502 Azure Firewall       \u2502\n         \u2502 &amp; NSG                \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n     \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n     \u2502          \u2502          \u2502\n     \u25bc          \u25bc          \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502Entra ID \u2502 \u2502RBAC  \u2502 \u2502Conditions\u2502\n\u2502&amp; MFA    \u2502 \u2502      \u2502 \u2502Access    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n     \u2502          \u2502          \u2502\n     \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                \u2502\n                \u25bc\n    \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502 Audit &amp; Surveillance \u2502\n    \u2502 (Monitoring, Logs)   \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap08/#surveillance-de-la-securite-et-alertes","title":"Surveillance de la s\u00e9curit\u00e9 et alertes","text":"<p>La surveillance de la s\u00e9curit\u00e9, les alertes et les rapports bas\u00e9s sur le Machine Learning qui identifient des mod\u00e8les d'acc\u00e8s incoh\u00e9rents aident \u00e0 prot\u00e9ger l'entreprise[1]. Les rapports d'acc\u00e8s et d'utilisation d'ID Microsoft Entra permettent d'obtenir une visibilit\u00e9 sur l'int\u00e9grit\u00e9 et la s\u00e9curit\u00e9 de l'annuaire de l'organisation[1].</p>"},{"location":"_projects/_formation-azure/azure-chap08/#microsoft-defender","title":"Microsoft Defender","text":""},{"location":"_projects/_formation-azure/azure-chap08/#vue-densemble-de-microsoft-defender-pour-azure","title":"Vue d'ensemble de Microsoft Defender pour Azure","text":"<p>Microsoft Defender pour le cloud offre une protection compl\u00e8te des ressources Azure contre les menaces. Elle s'int\u00e8gre directement dans Azure pour fournir une surveillance continue, une d\u00e9tection des menaces et des recommandations de s\u00e9curit\u00e9.</p>"},{"location":"_projects/_formation-azure/azure-chap08/#composants-de-microsoft-defender-pour-azure","title":"Composants de Microsoft Defender pour Azure","text":"Text Only<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502    Microsoft Defender pour le Cloud      \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Defender pour les serveurs         \u2502 \u2502\n\u2502  \u2502 (D\u00e9tection des menaces au niveau OS)\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Defender pour les conteneurs       \u2502 \u2502\n\u2502  \u2502 (Registres ACR, Kubernetes)        \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Defender pour les bases de donn\u00e9es \u2502 \u2502\n\u2502  \u2502 (SQL, Cosmos DB, MySQL)            \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Defender pour le stockage          \u2502 \u2502\n\u2502  \u2502 (Blobs, Data Lake)                 \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Threat Intelligence                \u2502 \u2502\n\u2502  \u2502 (Flux de menaces externes)         \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                          \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510 \u2502\n\u2502  \u2502 Conformit\u00e9 et audit                \u2502 \u2502\n\u2502  \u2502 (Rapports, recommandations)        \u2502 \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2502\n\u2502                                          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap08/#fonctionnalites-de-detection-avancee","title":"Fonctionnalit\u00e9s de d\u00e9tection avanc\u00e9e","text":"<p>Analyse comportementale : Defender utilise le machine learning pour analyser les comportements des utilisateurs et des applications, d\u00e9tectant les activit\u00e9s anormales.</p> <p>Renseignements sur les menaces : Int\u00e9gration avec les flux de renseignements sur les menaces mondiaux pour identifier les menaces \u00e9mergentes et les techniques d'attaque connues.</p> <p>Pr\u00e9diction des exploits : D\u00e9tection des vuln\u00e9rabilit\u00e9s avant qu'elles ne soient exploit\u00e9es par les attaquants.</p>"},{"location":"_projects/_formation-azure/azure-chap08/#gestion-des-acces-privilegies-avec-defender","title":"Gestion des acc\u00e8s privil\u00e9gi\u00e9s avec Defender","text":"<p>Microsoft Entra Privileged Identity Management (PIM) contribue \u00e0 r\u00e9duire les risques li\u00e9s aux acc\u00e8s privil\u00e9gi\u00e9s. C'est un risque de s\u00e9curit\u00e9 croissant pour les ressources h\u00e9berg\u00e9es dans le cloud, car les entreprises ne peuvent pas suffisamment surveiller ce que ces utilisateurs font avec leur acc\u00e8s privil\u00e9gi\u00e9[4]. Si un compte d'utilisateur disposant d'un acc\u00e8s privil\u00e9gi\u00e9 est compromis, cette seule faille peut affecter la s\u00e9curit\u00e9 globale du cloud de l'organisation[4].</p> <p>Microsoft Entra Privileged Identity Management permet de r\u00e9soudre ce risque en r\u00e9duisant le temps d'exposition des privil\u00e8ges et en augmentant la visibilit\u00e9 quant \u00e0 leur utilisation[4].</p> Text Only<pre><code>Configuration de PIM - Activit\u00e9s administrateur\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 D\u00e9couverte des administrateurs  \u2502\n\u2502 Quels utilisateurs sont des     \u2502\n\u2502 administrateurs Microsoft Entra? \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Acc\u00e8s Just-In-Time              \u2502\n\u2502 Activez l'acc\u00e8s administratif \u00e0 \u2502\n\u2502 la demande et juste-\u00e0-temps aux \u2502\n\u2502 services Microsoft              \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Rapports sur l'historique       \u2502\n\u2502 Obtenir des rapports sur        \u2502\n\u2502 l'historique des acc\u00e8s admin    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Alertes et notifications        \u2502\n\u2502 Recevoir des alertes sur l'acc\u00e8s\u2502\n\u2502 \u00e0 un r\u00f4le privil\u00e9gi\u00e9            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap08/#recommandations-de-securite","title":"Recommandations de s\u00e9curit\u00e9","text":"<p>Defender g\u00e9n\u00e8re continuellement des recommandations bas\u00e9es sur l'\u00e9tat actuel de l'infrastructure. Ces recommandations suivent les meilleures pratiques industrie et les standards de conformit\u00e9.</p> Text Only<pre><code>Exemple de recommandations typiques :\n\n1. Authentification multifacteur\n   Statut : Non configur\u00e9\n   S\u00e9v\u00e9rit\u00e9 : Haute\n   Action : Activer MFA pour tous les administrateurs\n\n2. Pare-feu et groupes de s\u00e9curit\u00e9 r\u00e9seau\n   Statut : Partiellement configur\u00e9\n   S\u00e9v\u00e9rit\u00e9 : Moyenne\n   Action : Revoir les r\u00e8gles d'entr\u00e9e ouvertes\n\n3. Chiffrement des donn\u00e9es au repos\n   Statut : Non configur\u00e9 pour certaines ressources\n   S\u00e9v\u00e9rit\u00e9 : Haute\n   Action : Activer le chiffrement Azure Disk Encryption\n\n4. Patching des syst\u00e8mes\n   Statut : 15 mises \u00e0 jour manquantes\n   S\u00e9v\u00e9rit\u00e9 : Critique\n   Action : Appliquer les mises \u00e0 jour de s\u00e9curit\u00e9\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap08/#integration-avec-microsoft-sentinel","title":"Int\u00e9gration avec Microsoft Sentinel","text":"<p>Microsoft Sentinel compl\u00e8te Defender en offrant une d\u00e9tection avanc\u00e9e des menaces au niveau SIEM (Security Information and Event Management).</p> Text Only<pre><code>Flux de donn\u00e9es - D\u00e9tection et r\u00e9ponse aux menaces\n\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Sources de logs \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502 \u2022 Entra ID      \u2502\n\u2502 \u2022 Ressources    \u2502\n\u2502   Azure         \u2502\n\u2502 \u2022 Pare-feu      \u2502\n\u2502 \u2022 Serveurs      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 Microsoft Sentinel   \u2502\n\u2502 \u2022 Collection de logs \u2502\n\u2502 \u2022 Analyse SIEM       \u2502\n\u2502 \u2022 Corr\u00e9lation        \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 D\u00e9tection de menaces \u2502\n\u2502 \u2022 Anomalies          \u2502\n\u2502 \u2022 Patterns connues   \u2502\n\u2502 \u2022 Alertes            \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n         \u2502\n         \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 R\u00e9ponse automatis\u00e9e  \u2502\n\u2502 \u2022 Playbooks          \u2502\n\u2502 \u2022 Isolation          \u2502\n\u2502 \u2022 Notifications      \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap08/#resume-du-parcours-dapprentissage","title":"R\u00e9sum\u00e9 du parcours d'apprentissage","text":"<p>Cette formation en gestion des acc\u00e8s et s\u00e9curit\u00e9 sur Azure couvre l'ensemble du spectre de la protection des identit\u00e9s et des ressources :</p> <p>Fondamentaux : La compr\u00e9hension des concepts de base (identit\u00e9, authentification, autorisation) constitue le point de d\u00e9part essentiel pour toute approche de s\u00e9curit\u00e9.</p> <p>Identit\u00e9s centralis\u00e9es : Microsoft Entra ID fournit la base pour g\u00e9rer toutes les identit\u00e9s, locales et cloud, dans une seule plateforme.</p> <p>Authentification renforc\u00e9e : Les m\u00e9thodes multifacteurs et adaptatives offrent une protection progressive contre les tentatives d'acc\u00e8s non autoris\u00e9.</p> <p>Approches modernes : Les mod\u00e8les Confiance Z\u00e9ro et D\u00e9fense en profondeur repr\u00e9sentent les meilleures pratiques actuelles de la s\u00e9curit\u00e9 cloud.</p> <p>Gestion granulaire des acc\u00e8s : Le RBAC et l'acc\u00e8s conditionnel permettent un contr\u00f4le pr\u00e9cis et flexible des permissions.</p> <p>Surveillance continue : Microsoft Defender et les outils de monitoring assurent une d\u00e9tection pr\u00e9coce des menaces et une r\u00e9ponse rapide.</p> <p>Cette approche holistique cr\u00e9e une posture de s\u00e9curit\u00e9 robuste et adapt\u00e9e aux d\u00e9fis des environnements cloud modernes[1][2][4][6].</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure/azure-chap09/","title":"Citations","text":"<ul> <li>https://learn.microsoft.com/fr-fr/azure/aks/active-active-solution</li> <li>https://learn.microsoft.com/fr-fr/azure/architecture/web-apps/app-service-environment/architectures/app-service-environment-high-availability-deployment</li> <li>https://learn.microsoft.com/fr-fr/azure/frontdoor/create-front-door-terraform</li> <li>https://learn.microsoft.com/fr-fr/azure/well-architected/service-guides/azure-front-door</li> <li>https://learn.microsoft.com/fr-fr/power-pages/configure/azure-front-door</li> <li>https://learn.microsoft.com/fr-fr/azure/frontdoor/best-practices</li> <li>https://www.itpro.fr/atelier-video-embarquez-pour-azure-front-door</li> <li>https://learn.microsoft.com/fr-fr/azure/frontdoor/routing-methods</li> <li>https://www.youtube.com/watch?v=LiBNZwZ5wBs</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap09/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 263</li> <li>completion_tokens: 9978</li> <li>total_tokens: 10241</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.15, 'request_cost': 0.006, 'total_cost': 0.156}</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap09/#content","title":"Content","text":""},{"location":"_projects/_formation-azure/azure-chap09/#chapitre-9-projet-1-deploiement-haute-disponibilite-avec-azure-front-door","title":"\ud83d\udcd8 Chapitre 9 : Projet 1 - D\u00e9ploiement Haute Disponibilit\u00e9 avec Azure Front Door","text":""},{"location":"_projects/_formation-azure/azure-chap09/#introduction-au-projet","title":"Introduction au projet","text":"<p>Le d\u00e9ploiement haute disponibilit\u00e9 constitue un \u00e9l\u00e9ment fondamental de l'architecture cloud moderne. Cette section pr\u00e9sente une approche compl\u00e8te pour mettre en \u0153uvre une solution r\u00e9siliente utilisant Azure Front Door comme composant central de distribution du trafic.[1]</p> <p>Azure Front Door est un service d'\u00e9quilibrage de charge de couche sept (Application Layer) qui permet de diriger le trafic utilisateur vers les backends les plus performants en fonction de crit\u00e8res d\u00e9finis. Dans le contexte d'une architecture haute disponibilit\u00e9 active/active, deux clusters ou plus traitent simultanement le trafic, \u00e9liminant ainsi tout point de d\u00e9faillance unique.[1]</p>"},{"location":"_projects/_formation-azure/azure-chap09/#objectifs-de-la-formation","title":"Objectifs de la formation","text":"<p>L'objectif principal consiste \u00e0 comprendre et impl\u00e9menter une architecture o\u00f9 : - Plusieurs ressources dans diff\u00e9rentes r\u00e9gions Azure traitent activement les requ\u00eates - Le trafic se distribue automatiquement entre les r\u00e9gions saines - Un basculement automatique survient en cas de d\u00e9faillance r\u00e9gionale - Les m\u00e9triques et journaux de diagnostic se centralisent pour le monitoring</p>"},{"location":"_projects/_formation-azure/azure-chap09/#architecture-generale-de-la-solution","title":"Architecture g\u00e9n\u00e9rale de la solution","text":"<p>L'architecture active/active repose sur deux ou plusieurs clusters AKS identiques, chacun d\u00e9ploy\u00e9 dans une r\u00e9gion Azure distincte, tous configur\u00e9s pour h\u00e9berger les instances compl\u00e8tes des applications.[1] Azure Front Door agit comme point d'entr\u00e9e unique (single entry point) en acheminant le trafic r\u00e9seau entre les r\u00e9gions. En situation normale, le trafic se r\u00e9partit selon la politique de routage d\u00e9finie. En cas d'indisponibilit\u00e9 d'une r\u00e9gion, le gestionnaire de trafic redirige l'ensemble du flux vers les r\u00e9gions saines restantes.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#preparation-de-lenvironnement","title":"Pr\u00e9paration de l'environnement","text":"<p>La pr\u00e9paration de l'environnement englobe plusieurs \u00e9tapes critiques pour assurer le succ\u00e8s du d\u00e9ploiement et de la gestion de l'infrastructure.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#prerequis-techniques","title":"Pr\u00e9requis techniques","text":"<p>Avant de d\u00e9buter, l'environnement de travail doit satisfaire aux exigences suivantes :</p> <ul> <li>Abonnement Azure actif : Un abonnement avec des permissions suffisantes pour cr\u00e9er des ressources dans plusieurs r\u00e9gions</li> <li>Azure CLI : Installation de la derni\u00e8re version d'Azure CLI pour g\u00e9rer les ressources Azure en ligne de commande</li> <li>Terraform : Installation de Terraform version 1.0 ou sup\u00e9rieure pour l'infrastructure-as-code[3]</li> <li>kubectl : L'outil de ligne de commande pour g\u00e9rer les clusters Kubernetes</li> <li>Editeur de code : Visual Studio Code ou un \u00e9quivalent pour \u00e9diter les fichiers de configuration</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap09/#configuration-des-fournisseurs-terraform","title":"Configuration des fournisseurs Terraform","text":"<p>La premi\u00e8re \u00e9tape consiste \u00e0 initialiser les fournisseurs Terraform n\u00e9cessaires. Cela permet \u00e0 Terraform de communiquer avec les services Azure pour cr\u00e9er et g\u00e9rer les ressources.[3]</p> Terraform<pre><code>terraform {\n  required_version = \"&gt;=1.0\"\n  required_providers {\n    azurerm = {\n      source  = \"hashicorp/azurerm\"\n      version = \"~&gt;3.0\"\n    }\n    random = {\n      source  = \"hashicorp/random\"\n      version = \"~&gt;3.0\"\n    }\n  }\n}\n\nprovider \"azurerm\" {\n  features {}\n}\n</code></pre> <p>Ce fichier de configuration <code>providers.tf</code> d\u00e9finit la version minimale de Terraform requise, les fournisseurs utilis\u00e9s et leurs versions respectives. Le fournisseur Azure Resource Manager (azurerm) g\u00e8re l'ensemble des ressources Azure, tandis que le fournisseur random g\u00e9n\u00e8re des valeurs al\u00e9atoires pour assurer l'unicit\u00e9 des ressources.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#structure-des-ressources-azure","title":"Structure des ressources Azure","text":"<p>L'architecture requiert la cr\u00e9ation de plusieurs ressources Azure dans chaque r\u00e9gion :</p> <p>Ressources primaires par r\u00e9gion : - Un cluster Azure Kubernetes Service (AKS) - Une instance Azure Application Gateway pour le routage au niveau de la couche application - Des pools de n\u0153uds Kubernetes pour ex\u00e9cuter les conteneurs d'application - Une instance Log Analytics pour la centralisation des m\u00e9triques et journaux</p> <p>Ressources partag\u00e9es : - Un profil Azure Front Door au niveau global - Une instance partag\u00e9e Log Analytics pour l'agr\u00e9gation des donn\u00e9es de toutes les r\u00e9gions - Un groupe de ressources par r\u00e9gion pour l'organisation logique</p>"},{"location":"_projects/_formation-azure/azure-chap09/#initialisation-de-terraform","title":"Initialisation de Terraform","text":"<p>Une fois les fichiers de configuration pr\u00e9par\u00e9s, l'initialisation de Terraform t\u00e9l\u00e9charge les plugins des fournisseurs n\u00e9cessaires :[3]</p> Bash<pre><code>terraform init -upgrade\n</code></pre> <p>Le param\u00e8tre <code>-upgrade</code> assure que les versions les plus r\u00e9centes conformes aux contraintes de version sont t\u00e9l\u00e9charg\u00e9es. Cette commande cr\u00e9e le fichier <code>.terraform.lock.hcl</code> qui verrouille les versions des fournisseurs pour garantir la reproductibilit\u00e9 du d\u00e9ploiement.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#variables-denvironnement-et-parametrage","title":"Variables d'environnement et param\u00e9trage","text":"<p>Pour maintenir une approche flexible et reproductible, les variables de configuration se d\u00e9finissent dans un fichier <code>variables.tf</code> :</p> Terraform<pre><code>variable \"primary_region\" {\n  description = \"R\u00e9gion primaire pour le d\u00e9ploiement\"\n  type        = string\n  default     = \"westeurope\"\n}\n\nvariable \"secondary_region\" {\n  description = \"R\u00e9gion secondaire pour le d\u00e9ploiement\"\n  type        = string\n  default     = \"northeurope\"\n}\n\nvariable \"environment\" {\n  description = \"Environnement de d\u00e9ploiement\"\n  type        = string\n  default     = \"production\"\n}\n\nvariable \"app_name\" {\n  description = \"Nom de l'application\"\n  type        = string\n  default     = \"myapp\"\n}\n\nvariable \"kubernetes_version\" {\n  description = \"Version de Kubernetes pour les clusters AKS\"\n  type        = string\n  default     = \"1.28\"\n}\n</code></pre> <p>Ces variables permettent de personnaliser le d\u00e9ploiement sans modifier le code principal d'infrastructure. L'utilisation de fichiers <code>.tfvars</code> offre une s\u00e9paration suppl\u00e9mentaire entre la configuration et le code :</p> Terraform<pre><code># terraform.tfvars\nprimary_region      = \"westeurope\"\nsecondary_region    = \"northeurope\"\nenvironment         = \"production\"\napp_name            = \"votingapp\"\nkubernetes_version  = \"1.28\"\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap09/#authentification-azure","title":"Authentification Azure","text":"<p>La connexion \u00e0 Azure se fait g\u00e9n\u00e9ralement via Azure CLI :</p> Bash<pre><code>az login\naz account set --subscription \"ID-de-l-abonnement\"\n</code></pre> <p>Cette authentification permet \u00e0 Terraform d'acc\u00e9der aux ressources Azure avec les permissions appropri\u00e9es. Pour les d\u00e9ploiements en environnement de production ou CI/CD, on privil\u00e9gie l'authentification par service principal.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#code-de-lapplication-et-deploiement","title":"Code de l'application et d\u00e9ploiement","text":""},{"location":"_projects/_formation-azure/azure-chap09/#structure-de-lapplication-et-conteneurisation","title":"Structure de l'application et conteneurisation","text":"<p>L'application d\u00e9ploy\u00e9e dans cette architecture est g\u00e9n\u00e9ralement une application web moderne capable de s'ex\u00e9cuter dans des conteneurs. Pour cette formation, on utilise une application de vote simple servie par une API backend.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#dockerfile-de-lapplication","title":"Dockerfile de l'application","text":"Docker<pre><code>FROM python:3.11-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY app.py .\nCOPY templates/ templates/\n\nEXPOSE 5000\n\nHEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \\\n  CMD curl -f http://localhost:5000/health || exit 1\n\nCMD [\"python\", \"app.py\"]\n</code></pre> <p>Ce Dockerfile cr\u00e9e une image conteneur bas\u00e9e sur Python 3.11 l\u00e9ger. La directive HEALTHCHECK define les crit\u00e8res de v\u00e9rification de l'\u00e9tat de sant\u00e9 du conteneur, utilis\u00e9s par le syst\u00e8me de sonde d'int\u00e9grit\u00e9 de Kubernetes.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#application-flask-simple","title":"Application Flask simple","text":"Python<pre><code>from flask import Flask, render_template, request, jsonify\nimport os\nfrom datetime import datetime\n\napp = Flask(__name__)\n\n# Configuration depuis les variables d'environnement\nREGION = os.getenv('REGION', 'unknown')\nINSTANCE_ID = os.getenv('INSTANCE_ID', 'default')\n\n@app.route('/')\ndef index():\n    return render_template('index.html', region=REGION, instance_id=INSTANCE_ID)\n\n@app.route('/health')\ndef health():\n    return jsonify({\n        'status': 'healthy',\n        'region': REGION,\n        'instance_id': INSTANCE_ID,\n        'timestamp': datetime.utcnow().isoformat()\n    }), 200\n\n@app.route('/api/vote', methods=['POST'])\ndef vote():\n    vote_data = request.get_json()\n    return jsonify({\n        'status': 'success',\n        'vote': vote_data.get('option'),\n        'processed_by': INSTANCE_ID,\n        'region': REGION\n    }), 201\n\n@app.route('/api/metrics')\ndef metrics():\n    return jsonify({\n        'region': REGION,\n        'instance_id': INSTANCE_ID,\n        'timestamp': datetime.utcnow().isoformat()\n    }), 200\n\nif __name__ == '__main__':\n    app.run(host='0.0.0.0', port=5000, debug=False)\n</code></pre> <p>Cette application expose plusieurs endpoints essentiels. L'endpoint <code>/health</code> permet au syst\u00e8me de v\u00e9rifier la disponibilit\u00e9 du service, tandis que <code>/api/vote</code> traite les requ\u00eates m\u00e9tier. Chaque r\u00e9ponse inclut l'identifiant de la r\u00e9gion pour tracer le routage du trafic.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#configuration-kubernetes-pour-les-clusters-aks","title":"Configuration Kubernetes pour les clusters AKS","text":""},{"location":"_projects/_formation-azure/azure-chap09/#deploiement-de-lapplication-dans-aks","title":"D\u00e9ploiement de l'application dans AKS","text":"YAML<pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: voting-app\n  namespace: production\n  labels:\n    app: voting-app\n    version: v1\nspec:\n  replicas: 3\n  strategy:\n    type: RollingUpdate\n    rollingUpdate:\n      maxSurge: 1\n      maxUnavailable: 0\n  selector:\n    matchLabels:\n      app: voting-app\n  template:\n    metadata:\n      labels:\n        app: voting-app\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"5000\"\n    spec:\n      containers:\n      - name: voting-app\n        image: myregistry.azurecr.io/voting-app:v1.0.0\n        imagePullPolicy: IfNotPresent\n        ports:\n        - containerPort: 5000\n          name: http\n        env:\n        - name: REGION\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.annotations['topology.kubernetes.io/region']\n        - name: INSTANCE_ID\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.name\n        resources:\n          requests:\n            memory: \"256Mi\"\n            cpu: \"250m\"\n          limits:\n            memory: \"512Mi\"\n            cpu: \"500m\"\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 5000\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          timeoutSeconds: 5\n          failureThreshold: 3\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 5000\n          initialDelaySeconds: 5\n          periodSeconds: 5\n          timeoutSeconds: 3\n          failureThreshold: 2\n      affinity:\n        podAntiAffinity:\n          preferredDuringSchedulingIgnoredDuringExecution:\n          - weight: 100\n            podAffinityTerm:\n              labelSelector:\n                matchExpressions:\n                - key: app\n                  operator: In\n                  values:\n                  - voting-app\n              topologyKey: kubernetes.io/hostname\n</code></pre> <p>Ce manifest Kubernetes configure le d\u00e9ploiement de l'application avec plusieurs r\u00e9plicas pour la redondance locale. Les probes de liveness et readiness assurent que seules les instances saines re\u00e7oivent du trafic. L'anti-affinit\u00e9 de pod favorise la distribution des r\u00e9plicas sur diff\u00e9rents n\u0153uds.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#service-kubernetes-exposant-lapplication","title":"Service Kubernetes exposant l'application","text":"YAML<pre><code>apiVersion: v1\nkind: Service\nmetadata:\n  name: voting-app-service\n  namespace: production\n  labels:\n    app: voting-app\nspec:\n  type: LoadBalancer\n  selector:\n    app: voting-app\n  ports:\n  - port: 80\n    targetPort: 5000\n    protocol: TCP\n    name: http\n  sessionAffinity: None\n</code></pre> <p>Ce service expose l'application sur le port 80 (HTTP standard), routant les requ\u00eates vers les pods sur le port 5000. Le service LoadBalancer Azure cr\u00e9e un load balancer interne qui distribue le trafic entre les pods.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#deploiement-terraform-des-clusters-aks","title":"D\u00e9ploiement Terraform des clusters AKS","text":""},{"location":"_projects/_formation-azure/azure-chap09/#configuration-du-groupe-de-ressources-et-du-cluster-principal","title":"Configuration du groupe de ressources et du cluster principal","text":"Terraform<pre><code>resource \"azurerm_resource_group\" \"primary\" {\n  name     = \"${var.app_name}-rg-${var.primary_region}\"\n  location = var.primary_region\n\n  tags = {\n    environment = var.environment\n    region      = var.primary_region\n  }\n}\n\nresource \"azurerm_kubernetes_cluster\" \"primary\" {\n  name                = \"${var.app_name}-aks-${var.primary_region}\"\n  location            = azurerm_resource_group.primary.location\n  resource_group_name = azurerm_resource_group.primary.name\n  dns_prefix          = \"${var.app_name}-primary\"\n\n  default_node_pool {\n    name            = \"default\"\n    node_count      = 3\n    vm_size         = \"Standard_D2s_v3\"\n    os_disk_size_gb = 50\n\n    zones = [\"1\", \"2\", \"3\"]\n  }\n\n  identity {\n    type = \"SystemAssigned\"\n  }\n\n  network_profile {\n    network_plugin    = \"azure\"\n    load_balancer_sku = \"standard\"\n    service_cidr      = \"10.0.0.0/16\"\n    dns_service_ip    = \"10.0.0.10\"\n    docker_bridge_cidr = \"172.17.0.1/16\"\n  }\n\n  kubernetes_version = var.kubernetes_version\n\n  tags = {\n    environment = var.environment\n    region      = var.primary_region\n  }\n\n  depends_on = [azurerm_resource_group.primary]\n}\n</code></pre> <p>Cette configuration cr\u00e9e un cluster AKS avec trois n\u0153uds r\u00e9partis sur trois zones de disponibilit\u00e9 (zones 1, 2, 3) au sein de la r\u00e9gion primaire. Cette distribution assure la r\u00e9silience contre les d\u00e9faillances de zone. L'identit\u00e9 syst\u00e8me attribu\u00e9e au cluster permet l'acc\u00e8s s\u00e9curis\u00e9 aux ressources Azure.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#configuration-du-cluster-secondaire","title":"Configuration du cluster secondaire","text":"Terraform<pre><code>resource \"azurerm_resource_group\" \"secondary\" {\n  name     = \"${var.app_name}-rg-${var.secondary_region}\"\n  location = var.secondary_region\n\n  tags = {\n    environment = var.environment\n    region      = var.secondary_region\n  }\n}\n\nresource \"azurerm_kubernetes_cluster\" \"secondary\" {\n  name                = \"${var.app_name}-aks-${var.secondary_region}\"\n  location            = azurerm_resource_group.secondary.location\n  resource_group_name = azurerm_resource_group.secondary.name\n  dns_prefix          = \"${var.app_name}-secondary\"\n\n  default_node_pool {\n    name            = \"default\"\n    node_count      = 3\n    vm_size         = \"Standard_D2s_v3\"\n    os_disk_size_gb = 50\n\n    zones = [\"1\", \"2\", \"3\"]\n  }\n\n  identity {\n    type = \"SystemAssigned\"\n  }\n\n  network_profile {\n    network_plugin    = \"azure\"\n    load_balancer_sku = \"standard\"\n    service_cidr      = \"10.1.0.0/16\"\n    dns_service_ip    = \"10.1.0.10\"\n    docker_bridge_cidr = \"172.17.0.1/16\"\n  }\n\n  kubernetes_version = var.kubernetes_version\n\n  tags = {\n    environment = var.environment\n    region      = var.secondary_region\n  }\n\n  depends_on = [azurerm_resource_group.secondary]\n}\n</code></pre> <p>Le cluster secondaire suit une configuration identique au cluster primaire, d\u00e9ploy\u00e9 dans une r\u00e9gion distincte. L'utilisation de plages CIDR diff\u00e9rentes (10.0.0.0/16 vs 10.1.0.0/16) \u00e9vite les conflits d'adressage entre les r\u00e9gions.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#deploiement-de-lapplication-sur-les-clusters","title":"D\u00e9ploiement de l'application sur les clusters","text":""},{"location":"_projects/_formation-azure/azure-chap09/#script-de-deploiement-de-lapplication","title":"Script de d\u00e9ploiement de l'application","text":"Bash<pre><code>#!/bin/bash\n\nset -e\n\n# Variables de configuration\nPRIMARY_RG=\"myapp-rg-westeurope\"\nPRIMARY_CLUSTER=\"myapp-aks-westeurope\"\nPRIMARY_REGION=\"westeurope\"\n\nSECONDARY_RG=\"myapp-rg-northeurope\"\nSECONDARY_CLUSTER=\"myapp-aks-northeurope\"\nSECONDARY_REGION=\"northeurope\"\n\nACR_NAME=\"myappregistry\"\nACR_RESOURCE_GROUP=\"myapp-rg-westeurope\"\n\n# Fonction pour obtenir les credentials du cluster\nconfigure_cluster() {\n    local rg=$1\n    local cluster=$2\n    local region=$3\n\n    echo \"Configuration de ${cluster} dans ${region}...\"\n    az aks get-credentials --resource-group \"${rg}\" --name \"${cluster}\" --overwrite-existing\n\n    # Cr\u00e9er le namespace de production\n    kubectl create namespace production --dry-run=client -o yaml | kubectl apply -f -\n}\n\n# Fonction pour d\u00e9ployer l'application\ndeploy_application() {\n    local region=$1\n    local instance_name=$2\n\n    echo \"D\u00e9ploiement de l'application dans ${region}...\"\n\n    # Appliquer les manifests Kubernetes\n    kubectl apply -f - &lt;&lt;EOF\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: app-config\n  namespace: production\ndata:\n  REGION: \"${region}\"\n  INSTANCE_ID: \"${instance_name}\"\n---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: voting-app\n  namespace: production\nspec:\n  replicas: 3\n  selector:\n    matchLabels:\n      app: voting-app\n  template:\n    metadata:\n      labels:\n        app: voting-app\n    spec:\n      containers:\n      - name: voting-app\n        image: ${ACR_NAME}.azurecr.io/voting-app:v1.0.0\n        ports:\n        - containerPort: 5000\n        envFrom:\n        - configMapRef:\n            name: app-config\n        livenessProbe:\n          httpGet:\n            path: /health\n            port: 5000\n          initialDelaySeconds: 10\n          periodSeconds: 10\n        readinessProbe:\n          httpGet:\n            path: /health\n            port: 5000\n          initialDelaySeconds: 5\n          periodSeconds: 5\n---\napiVersion: v1\nkind: Service\nmetadata:\n  name: voting-app-service\n  namespace: production\nspec:\n  type: LoadBalancer\n  selector:\n    app: voting-app\n  ports:\n  - port: 80\n    targetPort: 5000\nEOF\n}\n\n# Obtention des credentials pour les deux clusters\necho \"=== Configuration des clusters AKS ===\"\nconfigure_cluster \"${PRIMARY_RG}\" \"${PRIMARY_CLUSTER}\" \"${PRIMARY_REGION}\"\nconfigure_cluster \"${SECONDARY_RG}\" \"${SECONDARY_CLUSTER}\" \"${SECONDARY_REGION}\"\n\n# D\u00e9ploiement du cluster primaire\nkubectl config use-context \"${PRIMARY_CLUSTER}\"\ndeploy_application \"${PRIMARY_REGION}\" \"primary-instance\"\n\n# D\u00e9ploiement du cluster secondaire\nkubectl config use-context \"${SECONDARY_CLUSTER}\"\ndeploy_application \"${SECONDARY_REGION}\" \"secondary-instance\"\n\necho \"=== D\u00e9ploiement termin\u00e9 ===\"\nkubectl config use-context \"${PRIMARY_CLUSTER}\"\necho \"Contexte actif : ${PRIMARY_CLUSTER}\"\n</code></pre> <p>Ce script automatise le processus de configuration des deux clusters et le d\u00e9ploiement de l'application avec les configurations r\u00e9gionales sp\u00e9cifiques. L'utilisation de ConfigMaps permet aux pods de conna\u00eetre leur r\u00e9gion et instance d'appartenance.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#creation-du-registre-de-conteneurs-azure","title":"Cr\u00e9ation du registre de conteneurs Azure","text":"Terraform<pre><code>resource \"azurerm_container_registry\" \"acr\" {\n  name                = var.acr_name\n  resource_group_name = azurerm_resource_group.primary.name\n  location            = azurerm_resource_group.primary.location\n  sku                 = \"Premium\"\n  admin_enabled       = false\n\n  tags = {\n    environment = var.environment\n  }\n}\n\n# Attribution de r\u00f4les pour l'acc\u00e8s au registre\nresource \"azurerm_role_assignment\" \"aks_primary_acr\" {\n  scope              = azurerm_container_registry.acr.id\n  role_definition_name = \"AcrPush\"\n  principal_id       = azurerm_kubernetes_cluster.primary.identity[0].principal_id\n}\n\nresource \"azurerm_role_assignment\" \"aks_secondary_acr\" {\n  scope              = azurerm_container_registry.acr.id\n  role_definition_name = \"AcrPush\"\n  principal_id       = azurerm_kubernetes_cluster.secondary.identity[0].principal_id\n}\n</code></pre> <p>Le registre de conteneurs centralise le stockage des images Docker utilis\u00e9es par les deux clusters. Les attributions de r\u00f4les permettent aux clusters AKS de tirer les images sans g\u00e9rer manuellement les credentials.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#routage-global-avec-azure-front-door","title":"Routage global avec Azure Front Door","text":""},{"location":"_projects/_formation-azure/azure-chap09/#architecture-generale-du-routage","title":"Architecture g\u00e9n\u00e9rale du routage","text":"<p>Azure Front Door constitue la couche sup\u00e9rieure d'une architecture de routage global distribu\u00e9e.[4] Positionn\u00e9e devant les backends distribu\u00e9s g\u00e9ographiquement, cette solution fournit un routage de couche sept sophistiqu\u00e9, une mise en cache distribu\u00e9e et une gestion automatique du basculement.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#configuration-de-base-dazure-front-door","title":"Configuration de Base d'Azure Front Door","text":""},{"location":"_projects/_formation-azure/azure-chap09/#creation-du-profil-front-door","title":"Cr\u00e9ation du profil Front Door","text":"Terraform<pre><code>resource \"azurerm_cdn_frontdoor_profile\" \"main\" {\n  name                = \"${var.app_name}-frontdoor\"\n  resource_group_name = azurerm_resource_group.primary.name\n  sku_name            = \"Standard_AzureFrontDoor\"\n\n  tags = {\n    environment = var.environment\n  }\n}\n</code></pre> <p>Le profil Front Door constitue le conteneur principal pour toute la configuration de routage. La SKU Standard fournit les capacit\u00e9s essentielles pour une architecture haute disponibilit\u00e9 moderne.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#configuration-des-origines-origins","title":"Configuration des origines (origins)","text":"Terraform<pre><code># Origine du cluster primaire\nresource \"azurerm_cdn_frontdoor_origin_group\" \"primary\" {\n  name                     = \"primary-origin-group\"\n  cdn_frontdoor_profile_id = azurerm_cdn_frontdoor_profile.main.id\n  session_affinity_enabled = true\n\n  load_balancing {\n    sample_size                 = 4\n    successful_samples_required = 3\n    additional_latency_in_milliseconds = 0\n  }\n\n  health_probe {\n    interval_in_seconds = 100\n    path                = \"/health\"\n    protocol            = \"Https\"\n    request_type        = \"HEAD\"\n  }\n}\n\nresource \"azurerm_cdn_frontdoor_origin\" \"primary_origin\" {\n  name                           = \"primary-origin\"\n  cdn_frontdoor_origin_group_id = azurerm_cdn_frontdoor_origin_group.primary.id\n  enabled                        = true\n  http_port                      = 80\n  https_port                     = 443\n  origin_host_header             = azurerm_kubernetes_cluster.primary.fqdn\n  priority                       = 1\n  weight                         = 50\n  certificate_name_check_enabled = true\n  host_name                      = azurerm_kubernetes_cluster.primary.fqdn\n}\n\n# Origine du cluster secondaire\nresource \"azurerm_cdn_frontdoor_origin_group\" \"secondary\" {\n  name                     = \"secondary-origin-group\"\n  cdn_frontdoor_profile_id = azurerm_cdn_frontdoor_profile.main.id\n  session_affinity_enabled = true\n\n  load_balancing {\n    sample_size                 = 4\n    successful_samples_required = 3\n    additional_latency_in_milliseconds = 0\n  }\n\n  health_probe {\n    interval_in_seconds = 100\n    path                = \"/health\"\n    protocol            = \"Https\"\n    request_type        = \"HEAD\"\n  }\n}\n\nresource \"azurerm_cdn_frontdoor_origin\" \"secondary_origin\" {\n  name                           = \"secondary-origin\"\n  cdn_frontdoor_origin_group_id = azurerm_cdn_frontdoor_origin_group.secondary.id\n  enabled                        = true\n  http_port                      = 80\n  https_port                     = 443\n  origin_host_header             = azurerm_kubernetes_cluster.secondary.fqdn\n  priority                       = 1\n  weight                         = 50\n  certificate_name_check_enabled = true\n  host_name                      = azurerm_kubernetes_cluster.secondary.fqdn\n}\n</code></pre> <p>Chaque groupe d'origine contient un health probe qui v\u00e9rifie la disponibilit\u00e9 des backends toutes les 100 secondes en effectuant une requ\u00eate HEAD sur l'endpoint <code>/health</code>. Si trois requ\u00eates cons\u00e9cutives \u00e9chouent, l'origine est marqu\u00e9e comme indisponible. L'affinit\u00e9 de session assure que les requ\u00eates d'un m\u00eame client restent dirig\u00e9es vers le m\u00eame backend lorsque possible.[1]</p> <p>La pond\u00e9ration (weight) et priorit\u00e9 (priority) d\u00e9finissent la distribution du trafic. Avec des poids \u00e9gaux, le trafic se r\u00e9partit \u00e9quitablement. En cas de d\u00e9faillance d'une r\u00e9gion, tout le trafic bascule vers l'autre.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#methodes-de-routage","title":"M\u00e9thodes de routage","text":""},{"location":"_projects/_formation-azure/azure-chap09/#routage-pondere-weighted-routing","title":"Routage pond\u00e9r\u00e9 (Weighted routing)","text":"Terraform<pre><code>resource \"azurerm_cdn_frontdoor_route\" \"weighted_route\" {\n  name                          = \"weighted-routing-rule\"\n  cdn_frontdoor_endpoint_id    = azurerm_cdn_frontdoor_endpoint.main.id\n  cdn_frontdoor_origin_group_id = azurerm_cdn_frontdoor_origin_group.primary.id\n  supported_protocols           = [\"Http\", \"Https\"]\n  patterns_to_match             = [\"/*\"]\n  forwarding_protocol           = \"HttpsOnly\"\n  link_to_default_domain        = true\n  https_redirect_enabled        = true\n\n  # Configuration du cache pour les ressources statiques\n  cache {\n    query_string_caching_behavior = \"UseQueryString\"\n    compression_enabled           = true\n  }\n}\n</code></pre> <p>Cette configuration dirige le trafic vers les backends en utilisant le sch\u00e9ma de pond\u00e9ration d\u00e9fini dans les groupes d'origine. Le routage se fait selon la latence mesur\u00e9e et la disponibilit\u00e9 de chaque backend.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#routage-base-sur-le-chemin-path-based-routing","title":"Routage bas\u00e9 sur le chemin (Path-based routing)","text":"Terraform<pre><code>resource \"azurerm_cdn_frontdoor_route\" \"api_route\" {\n  name                          = \"api-routing-rule\"\n  cdn_frontdoor_endpoint_id    = azurerm_cdn_frontdoor_endpoint.main.id\n  cdn_frontdoor_origin_group_id = azurerm_cdn_frontdoor_origin_group.primary.id\n  supported_protocols           = [\"Https\"]\n  patterns_to_match             = [\"/api/*\"]\n  forwarding_protocol           = \"HttpsOnly\"\n  link_to_default_domain        = true\n  https_redirect_enabled        = true\n\n  cache {\n    query_string_caching_behavior = \"IgnoreQueryString\"\n    compression_enabled           = true\n    default_ttl                   = 0  # Pas de cache pour les APIs\n  }\n}\n\nresource \"azurerm_cdn_frontdoor_route\" \"static_route\" {\n  name                          = \"static-routing-rule\"\n  cdn_frontdoor_endpoint_id    = azurerm_cdn_frontdoor_endpoint.main.id\n  cdn_frontdoor_origin_group_id = azurerm_cdn_frontdoor_origin_group.primary.id\n  supported_protocols           = [\"Https\"]\n  patterns_to_match             = [\"/static/*\", \"*.js\", \"*.css\", \"*.jpg\", \"*.png\", \"*.gif\"]\n  forwarding_protocol           = \"HttpsOnly\"\n  link_to_default_domain        = true\n  https_redirect_enabled        = true\n\n  cache {\n    query_string_caching_behavior = \"IgnoreQueryString\"\n    compression_enabled           = true\"\n    default_ttl                   = 86400  # Cache 24 heures\n    max_ttl                       = 604800 # Maximum 7 jours\n  }\n}\n</code></pre> <p>Les r\u00e8gles de routage bas\u00e9es sur le chemin permettent de diriger diff\u00e9rents types de requ\u00eates vers des configurations optimis\u00e9es. Les requ\u00eates API ne se cachent pas (TTL=0) pour assurer la fra\u00eecheur des donn\u00e9es, tandis que les ressources statiques se cachent pendant 24 heures par d\u00e9faut.[4]</p>"},{"location":"_projects/_formation-azure/azure-chap09/#configuration-du-point-de-terminaison-front-door","title":"Configuration du point de terminaison Front Door","text":""},{"location":"_projects/_formation-azure/azure-chap09/#creation-du-point-de-terminaison","title":"Cr\u00e9ation du point de terminaison","text":"Terraform<pre><code>resource \"azurerm_cdn_frontdoor_endpoint\" \"main\" {\n  name                     = \"${var.app_name}-endpoint\"\n  cdn_frontdoor_profile_id = azurerm_cdn_frontdoor_profile.main.id\n  enabled                  = true\n\n  tags = {\n    environment = var.environment\n  }\n}\n</code></pre> <p>L'endpoint Front Door est le point d'entr\u00e9e unique o\u00f9 les utilisateurs acc\u00e8dent \u00e0 l'application. Un FQDN automatiquement g\u00e9n\u00e9r\u00e9 de la forme <code>example.azurefd.net</code> est attribu\u00e9.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#gestion-du-basculement-et-haute-disponibilite","title":"Gestion du basculement et haute disponibilit\u00e9","text":""},{"location":"_projects/_formation-azure/azure-chap09/#configuration-automatique-du-basculement","title":"Configuration automatique du basculement","text":"Terraform<pre><code>resource \"azurerm_cdn_frontdoor_origin_group\" \"failover_group\" {\n  name                     = \"failover-origin-group\"\n  cdn_frontdoor_profile_id = azurerm_cdn_frontdoor_profile.main.id\n  session_affinity_enabled = false\n\n  load_balancing {\n    sample_size                 = 4\n    successful_samples_required = 3\n    additional_latency_in_milliseconds = 100\n  }\n\n  health_probe {\n    interval_in_seconds = 100\n    path                = \"/health\"\n    protocol            = \"Https\"\n    request_type        = \"HEAD\"\n  }\n}\n\n# Configuration de basculement en priorit\u00e9\nresource \"azurerm_cdn_frontdoor_origin\" \"primary_for_failover\" {\n  name                           = \"primary-failover\"\n  cdn_frontdoor_origin_group_id = azurerm_cdn_frontdoor_origin_group.failover_group.id\n  enabled                        = true\n  http_port                      = 80\n  https_port                     = 443\n  origin_host_header             = azurerm_kubernetes_cluster.primary.fqdn\n  priority                       = 1  # Priorit\u00e9 haute - utilis\u00e9 en premier\n  weight                         = 100\n  certificate_name_check_enabled = true\n  host_name                      = azurerm_kubernetes_cluster.primary.fqdn\n}\n\nresource \"azurerm_cdn_frontdoor_origin\" \"secondary_for_failover\" {\n  name                           = \"secondary-failover\"\n  cdn_frontdoor_origin_group_id = azurerm_cdn_frontdoor_origin_group.failover_group.id\n  enabled                        = true\n  http_port                      = 80\n  https_port                     = 443\n  origin_host_header             = azurerm_kubernetes_cluster.secondary.fqdn\n  priority                       = 2  # Priorit\u00e9 basse - utilis\u00e9 en cas d'indisponibilit\u00e9\n  weight                         = 100\n  certificate_name_check_enabled = true\n  host_name                      = azurerm_kubernetes_cluster.secondary.fqdn\n}\n</code></pre> <p>En mode basculement (failover), les requ\u00eates se dirigent d'abord vers le backend prioritaire. Seulement si celui-ci devient indisponible, les requ\u00eates basculent vers le backend de priorit\u00e9 inf\u00e9rieure. Cela contraste avec la distribution active/active o\u00f9 le trafic se r\u00e9partit continuellement entre tous les backends sains.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#mise-en-cache-distribuee","title":"Mise en cache distribu\u00e9e","text":""},{"location":"_projects/_formation-azure/azure-chap09/#strategies-de-cache-optimisees","title":"Strat\u00e9gies de cache optimis\u00e9es","text":"Terraform<pre><code>resource \"azurerm_cdn_frontdoor_route\" \"cache_optimized\" {\n  name                          = \"cache-optimized-route\"\n  cdn_frontdoor_endpoint_id    = azurerm_cdn_frontdoor_endpoint.main.id\n  cdn_frontdoor_origin_group_id = azurerm_cdn_frontdoor_origin_group.primary.id\n  supported_protocols           = [\"Https\"]\n  patterns_to_match             = [\"/*\"]\n  forwarding_protocol           = \"HttpsOnly\"\n  link_to_default_domain        = true\n  https_redirect_enabled        = true\n\n  cache {\n    # Configuration avanc\u00e9e du cache\n    query_string_caching_behavior = \"UseQueryString\"\n    compression_enabled           = true\n\n    # Headers personnalis\u00e9s influen\u00e7ant le cache\n    cache_key_query_string_include_nulls = false\n\n    # Comportement par d\u00e9faut\n    default_ttl = 3600  # 1 heure\n    min_ttl     = 60    # 1 minute\n    max_ttl     = 604800 # 7 jours\n  }\n}\n</code></pre> <p>La strat\u00e9gie de cache utilise les en-t\u00eates HTTP standard (Cache-Control, ETag, Last-Modified) pour d\u00e9terminer la dur\u00e9e de vie des objets. Azure Front Door compresse automatiquement les contenus supportant la compression (texte, JSON, CSS, JavaScript) pour r\u00e9duire la consommation de bande passante.[4]</p>"},{"location":"_projects/_formation-azure/azure-chap09/#configuration-des-domaines-personnalises","title":"Configuration des domaines personnalis\u00e9s","text":""},{"location":"_projects/_formation-azure/azure-chap09/#ajout-dun-domaine-personnalise-avec-https","title":"Ajout d'un domaine personnalis\u00e9 avec HTTPS","text":"Terraform<pre><code>resource \"azurerm_cdn_frontdoor_custom_domain\" \"main\" {\n  name                     = \"custom-domain\"\n  cdn_frontdoor_profile_id = azurerm_cdn_frontdoor_profile.main.id\n  dns_zone_id              = azurerm_dns_zone.main.id\n  host_name                = \"app.example.com\"\n\n  tls {\n    certificate_type    = \"ManagedCertificate\"\n    minimum_tls_version = \"TLS12\"\n  }\n}\n\nresource \"azurerm_cdn_frontdoor_route\" \"custom_domain_route\" {\n  name                          = \"custom-domain-route\"\n  cdn_frontdoor_endpoint_id    = azurerm_cdn_frontdoor_endpoint.main.id\n  cdn_frontdoor_origin_group_id = azurerm_cdn_frontdoor_origin_group.primary.id\n  supported_protocols           = [\"Https\"]\n  patterns_to_match             = [\"/*\"]\n  forwarding_protocol           = \"HttpsOnly\"\n  custom_domains                = [azurerm_cdn_frontdoor_custom_domain.main.id]\n  link_to_default_domain        = false\n  https_redirect_enabled        = true\n\n  cache {\n    query_string_caching_behavior = \"UseQueryString\"\n    compression_enabled           = true\n  }\n}\n</code></pre> <p>L'utilisation de domaines personnalis\u00e9s avec certificats g\u00e9r\u00e9s offre une exp\u00e9rience utilisateur professionnelle. Azure Front Door g\u00e8re automatiquement le renouvellement des certificats TLS.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#regles-dacheminement-avancees-rules-engine","title":"R\u00e8gles d'acheminement avanc\u00e9es (Rules Engine)","text":""},{"location":"_projects/_formation-azure/azure-chap09/#reecriture-den-tetes-http","title":"R\u00e9\u00e9criture d'en-t\u00eates HTTP","text":"Terraform<pre><code>resource \"azurerm_cdn_frontdoor_route\" \"with_rules\" {\n  name                          = \"route-with-rules\"\n  cdn_frontdoor_endpoint_id    = azurerm_cdn_frontdoor_endpoint.main.id\n  cdn_frontdoor_origin_group_id = azurerm_cdn_frontdoor_origin_group.primary.id\n  supported_protocols           = [\"Https\"]\n  patterns_to_match             = [\"/*\"]\n  forwarding_protocol           = \"HttpsOnly\"\n  link_to_default_domain        = true\n\n  # R\u00e8gles d'acheminement avanc\u00e9es\n  rule {\n    name     = \"add-security-headers\"\n    order    = 1\n    operator = \"Any\"\n\n    actions {\n      response_header_actions {\n        header_action = \"Append\"\n        header_name   = \"X-Content-Type-Options\"\n        value         = \"nosniff\"\n      }\n      response_header_actions {\n        header_action = \"Append\"\n        header_name   = \"X-Frame-Options\"\n        value         = \"DENY\"\n      }\n      response_header_actions {\n        header_action = \"Append\"\n        header_name   = \"X-XSS-Protection\"\n        value         = \"1; mode=block\"\n      }\n    }\n  }\n\n  rule {\n    name     = \"compression-optimization\"\n    order    = 2\n    operator = \"Any\"\n\n    actions {\n      cache_expiration_actions {\n        cache_behavior = \"SetIfMissing\"\n        cache_duration = \"1:30:00\"\n      }\n    }\n  }\n}\n</code></pre> <p>Le moteur de r\u00e8gles Front Door permet de modifier les en-t\u00eates, de rediriger les requ\u00eates ou d'appliquer des transformations complexes. Ces r\u00e8gles s'ex\u00e9cutent \u00e0 proximit\u00e9 de l'utilisateur final pour minimiser la latence.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#deploiement-complete-de-front-door-avec-terraform","title":"D\u00e9ploiement compl\u00e8te de Front Door avec Terraform","text":""},{"location":"_projects/_formation-azure/azure-chap09/#script-dapplication-terraform","title":"Script d'application Terraform","text":"Bash<pre><code>#!/bin/bash\n\nset -e\n\necho \"=== Validation de la configuration Terraform ===\"\nterraform validate\n\necho \"=== Formatage de la configuration Terraform ===\"\nterraform fmt -recursive\n\necho \"=== Planification du d\u00e9ploiement ===\"\nterraform plan -out=tfplan\n\necho \"=== D\u00e9ploiement de l'infrastructure ===\"\nterraform apply tfplan\n\necho \"=== R\u00e9cup\u00e9ration des informations de sortie ===\"\nterraform output -json\n\necho \"=== D\u00e9ploiement termin\u00e9 avec succ\u00e8s ===\"\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap09/#outputs-utiles","title":"Outputs utiles","text":"Terraform<pre><code>output \"primary_cluster_fqdn\" {\n  value       = azurerm_kubernetes_cluster.primary.fqdn\n  description = \"FQDN du cluster AKS primaire\"\n}\n\noutput \"secondary_cluster_fqdn\" {\n  value       = azurerm_kubernetes_cluster.secondary.fqdn\n  description = \"FQDN du cluster AKS secondaire\"\n}\n\noutput \"frontdoor_endpoint\" {\n  value       = azurerm_cdn_frontdoor_endpoint.main.host_name\n  description = \"Endpoint Azure Front Door\"\n}\n\noutput \"frontdoor_id\" {\n  value       = azurerm_cdn_frontdoor_profile.main.id\n  description = \"ID du profil Azure Front Door\"\n}\n\noutput \"acr_login_server\" {\n  value       = azurerm_container_registry.acr.login_server\n  description = \"Serveur de connexion du registre de conteneurs\"\n}\n</code></pre> <p>Ces outputs facilitent la r\u00e9cup\u00e9ration des informations essentielles apr\u00e8s le d\u00e9ploiement sans interroger manuellement le portail Azure.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#monitoring-et-diagnostics-avec-log-analytics","title":"Monitoring et diagnostics avec Log Analytics","text":""},{"location":"_projects/_formation-azure/azure-chap09/#configuration-de-log-analytics","title":"Configuration de Log Analytics","text":"Text Only<pre><code>resource \"azurerm_log_analytics_workspace\" \"shared\" {\n  name                = \"${var.app_name}-law-shared\"\n  location            = azurerm_resource_group.primary.location\n  resource_group_name = azurerm_resource_group.primary.name\n  sku                 = \"PerGB2018\"\n  retention_in_days   = 30\n\n  tags = {\n    environment = var.environment\n  }\n}\n\nresource \"azurerm_log_analytics_workspace\" \"primary\" {\n  name                = \"${var.app_name}-law-${var.primary_region}\"\n  location            = azurerm_resource_group.primary.location\n  resource_group_name = azurerm_resource_group.primary.name\n  sku                 = \"PerGB2018\"\n  retention_in_days   = 30\n\n  tags = {\n    environment = var.environment\n    region      = var.primary_region\n  }\n}\n\nresource \"azurerm_log_analytics_workspace\" \"secondary\" {\n  name                = \"${var.app_name}-law-${var.secondary_region}\"\n  location            = azurerm_resource_group.secondary.location\n  resource_group_name = azurerm_resource_group.secondary.name\n  sku                 = \"PerGB2018\"\n  retention_in_days   = 30\n\n  tags = {\n    environment = var.environment\n    region      = var.secondary_region\n  }\n}\n</code></pre> <p>Chaque r\u00e9gion dispose de sa propre instance Log Analytics stockant les m\u00e9triques et journaux de diagnostic r\u00e9gionaux. Une instance partag\u00e9e centralise les donn\u00e9es de toutes les r\u00e9gions pour l'analyse globale.[1]</p>"},{"location":"_projects/_formation-azure/azure-chap09/#tests-de-basculement-et-scenarios-de-resilience","title":"Tests de basculement et sc\u00e9narios de r\u00e9silience","text":""},{"location":"_projects/_formation-azure/azure-chap09/#simulation-dune-defaillance-regionale","title":"Simulation d'une d\u00e9faillance r\u00e9gionale","text":"Bash<pre><code>#!/bin/bash\n\n# Script pour simuler une d\u00e9faillance de r\u00e9gion\nREGION_TO_TEST=\"primary\"\nPRIMARY_CLUSTER=\"myapp-aks-westeurope\"\nPRIMARY_RG=\"myapp-rg-westeurope\"\n\necho \"=== Simulation de d\u00e9faillance de ${REGION_TO_TEST} ===\"\n\n# D\u00e9sactiver les pods dans la r\u00e9gion primaire\nkubectl config use-context \"${PRIMARY_CLUSTER}\"\nkubectl scale deployment voting-app --replicas=0 -n production\n\necho \"Pods arr\u00eat\u00e9s dans ${PRIMARY_CLUSTER}\"\necho \"Attendez que Front Door d\u00e9tecte la d\u00e9faillance (jusqu'\u00e0 100 secondes)...\"\nsleep 120\n\n# V\u00e9rifier que le trafic se dirige vers la r\u00e9gion secondaire\necho \"Envoi de requ\u00eates de test...\"\nfor i in {1..10}; do\n  response=$(curl -s -H \"User-Agent: TestClient\" https://app.example.azurefd.net/api/metrics | jq .region)\n  echo \"Requ\u00eate $i : r\u00e9gion = ${response}\"\ndone\n\n# Red\u00e9marrer les pods\necho \"Red\u00e9marrage des pods dans ${PRIMARY_CLUSTER}...\"\nkubectl scale deployment voting-app --replicas=3 -n production\n\necho \"=== Test de basculement termin\u00e9 ===\"\n</code></pre> <p>Ce test v\u00e9rifie que le syst\u00e8me bascule correctement vers la r\u00e9gion secondaire en cas d'indisponibilit\u00e9 de la r\u00e9gion primaire. Azure Front Door d\u00e9tecte la d\u00e9faillance via les health probes et redirige le trafic automatiquement.[1]</p>"},{"location":"_projects/_formation-azure/azure-chap09/#utilisation-dazure-chaos-studio","title":"Utilisation d'Azure Chaos Studio","text":"Bash<pre><code>#!/bin/bash\n\n# D\u00e9ploiement d'une exp\u00e9rience de chaos pour tester la r\u00e9silience\nCHAOS_EXPERIMENT_NAME=\"aks-region-outage\"\nCLUSTER_RESOURCE_ID=\"/subscriptions/{subscription-id}/resourceGroups/myapp-rg-westeurope/providers/Microsoft.ContainerService/managedClusters/myapp-aks-westeurope\"\n\necho \"=== Configuration d'une exp\u00e9rience de chaos ===\"\n\naz rest --method put \\\n  --uri \"https://management.azure.com${CLUSTER_RESOURCE_ID}/providers/Microsoft.Chaos/experiments/${CHAOS_EXPERIMENT_NAME}?api-version=2024-01-01\" \\\n  --body '{\n    \"location\": \"westeurope\",\n    \"identity\": {\n      \"type\": \"SystemAssigned\"\n    },\n    \"properties\": {\n      \"steps\": [\n        {\n          \"name\": \"simulate-pod-failure\",\n          \"branches\": [\n            {\n              \"name\": \"kill-pods\",\n              \"actions\": [\n                {\n                  \"type\": \"continuous\",\n                  \"name\": \"urn:csci:microsoft:kubernetesCluster:podChaos/2.1\",\n                  \"parameters\": [\n                    {\n                      \"name\": \"action\",\n                      \"value\": \"kill\"\n                    },\n                    {\n                      \"name\": \"namespace\",\n                      \"value\": \"production\"\n                    }\n                  ],\n                  \"duration\": \"PT5M\"\n                }\n              ]\n            }\n          ]\n        }\n      ]\n    }\n  }' \\\n  --output json\n</code></pre> <p>Azure Chaos Studio permet de cr\u00e9er et d'ex\u00e9cuter des exp\u00e9riences contr\u00f4l\u00e9es pour tester la r\u00e9silience du syst\u00e8me face \u00e0 des d\u00e9faillances simul\u00e9es. Cela offre une validation pratique de la haute disponibilit\u00e9.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#validation-et-verification-du-deploiement","title":"Validation et v\u00e9rification du d\u00e9ploiement","text":""},{"location":"_projects/_formation-azure/azure-chap09/#script-de-test-complet","title":"Script de test complet","text":"Bash<pre><code>#!/bin/bash\n\nset -e\n\nFRONTDOOR_ENDPOINT=\"https://app.example.azurefd.net\"\n\necho \"=== Tests de validation de Front Door ===\"\n\n# Test 1 : V\u00e9rification de la disponibilit\u00e9 g\u00e9n\u00e9rale\necho \"Test 1 : Disponibilit\u00e9 g\u00e9n\u00e9rale\"\nstatus=$(curl -s -o /dev/null -w \"%{http_code}\" \"${FRONTDOOR_ENDPOINT}/\")\nif [ \"$status\" = \"200\" ]; then\n    echo \"\u2713 Endpoint accessible (HTTP $status)\"\nelse\n    echo \"\u2717 Endpoint indisponible (HTTP $status)\"\nfi\n\n# Test 2 : V\u00e9rification des health probes\necho \"Test 2 : Health probes\"\nhealth=$(curl -s \"${FRONTDOOR_ENDPOINT}/health\" | jq .status)\necho \"Statut de sant\u00e9 : ${health}\"\n\n# Test 3 : V\u00e9rification du routage\necho \"Test 3 : Routage vers les backends\"\nfor i in {1..5}; do\n    region=$(curl -s \"${FRONTDOOR_ENDPOINT}/api/metrics\" | jq -r .region)\n    instance=$(curl -s \"${FRONTDOOR_ENDPOINT}/api/metrics\" | jq -r .instance_id)\n    echo \"Requ\u00eate $i : r\u00e9gion=${region}, instance=${instance}\"\ndone\n\n# Test 4 : Performance et latence\necho \"Test 4 : Performance\"\ntime curl -s -o /dev/null \"${FRONTDOOR_ENDPOINT}/\"\n\n# Test 5 : Compression de r\u00e9ponse\necho \"Test 5 : Compression\"\ncompression=$(curl -s -H \"Accept-Encoding: gzip\" -I \"${FRONTDOOR_ENDPOINT}/\" | grep -i \"content-encoding\")\necho \"En-t\u00eate compression : ${compression}\"\n\necho \"=== Validation termin\u00e9e ===\"\n</code></pre> <p>Ce script effectue une s\u00e9rie de tests pour valider le fonctionnement correct de Front Door, y compris la disponibilit\u00e9, le routage, et les performances.</p>"},{"location":"_projects/_formation-azure/azure-chap09/#resume-du-parcours-dapprentissage","title":"R\u00e9sum\u00e9 du parcours d'apprentissage","text":"<p>La progression de ce module suit une structure logique progressant du g\u00e9n\u00e9ral au sp\u00e9cifique. La pr\u00e9paration de l'environnement \u00e9tablit les fondations n\u00e9cessaires \u00e0 l'infrastructure. La compr\u00e9hension du code de l'application et de son d\u00e9ploiement d\u00e9monstrent comment les applications modernes s'int\u00e8grent dans les \u00e9cosyst\u00e8mes cloud. Enfin, la configuration d\u00e9taill\u00e9e d'Azure Front Door r\u00e9v\u00e8le comment construire une couche de routage sophistiqu\u00e9e et r\u00e9siliente capable de servir des millions d'utilisateurs distribu\u00e9s g\u00e9ographiquement.</p> <p>Les principes appliqu\u00e9s dans ce projet -- la redondance g\u00e9ographique, l'\u00e9quilibrage de charge intelligent, la surveillance proactive et l'automatisation du basculement -- constituent les \u00e9l\u00e9ments fondamentaux d'une architecture cloud moderne hautement disponible. La ma\u00eetrise de ces concepts pr\u00e9pare aux d\u00e9fis r\u00e9els du d\u00e9ploiement d'applications critiques \u00e0 l'\u00e9chelle globale.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure/azure-chap10/","title":"Citations","text":"<ul> <li>https://learn.microsoft.com/fr-fr/azure/cloud-adoption-framework/ready/azure-setup-guide/manage-costs</li> <li>https://learn.microsoft.com/fr-fr/azure/cost-management-billing/understand/plan-manage-costs</li> <li>https://learn.microsoft.com/fr-fr/azure/ai-foundry/concepts/manage-costs?view=foundry-classic</li> <li>https://learn.microsoft.com/fr-fr/azure/cost-management-billing/costs/tutorial-acm-create-budgets</li> <li>https://www.axido.fr/optimisation-cout-cloud-azure/</li> <li>https://learn.microsoft.com/fr-fr/azure/cost-management-billing/costs/understand-work-scopes</li> <li>https://learn.microsoft.com/fr-fr/azure/cost-management-billing/costs/reporting-get-started</li> <li>https://www.youtube.com/watch?v=UIJSTIRSfhk</li> <li>https://learn.microsoft.com/fr-fr/shows/azure-videos/7-ways-to-optimize-your-azure-costs</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap10/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 279</li> <li>completion_tokens: 6192</li> <li>total_tokens: 6471</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.093, 'request_cost': 0.006, 'total_cost': 0.1}</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap10/#content","title":"Content","text":""},{"location":"_projects/_formation-azure/azure-chap10/#chapitre-10-gestion-des-couts-sur-azure","title":"\ud83d\udcda Chapitre 10 : Gestion des co\u00fbts sur Azure","text":""},{"location":"_projects/_formation-azure/azure-chap10/#quest-ce-que-la-gestion-des-couts","title":"Qu'est-ce que la gestion des co\u00fbts ?","text":"<p>La gestion des co\u00fbts repr\u00e9sente un processus strat\u00e9gique et op\u00e9rationnel permettant de pr\u00e9voir et de ma\u00eetriser efficacement les d\u00e9penses cloud d'une entreprise[1]. Cette discipline d\u00e9passe le simple suivi des factures ; elle constitue une approche holistique englobant la planification budg\u00e9taire, l'analyse d\u00e9taill\u00e9e des d\u00e9penses et l'optimisation continue des ressources d\u00e9ploy\u00e9es.</p> <p>Dans un environnement cloud comme Azure, la gestion des co\u00fbts devient d'autant plus critique que les ressources peuvent \u00eatre provisionn\u00e9es rapidement et les facteurs de co\u00fbts sont nombreux. Les responsabilit\u00e9s en mati\u00e8re de gestion des co\u00fbts s'\u00e9tendent g\u00e9n\u00e9ralement sur plusieurs \u00e9quipes au sein d'une organisation[1] :</p> <ul> <li>\u00c9quipes financi\u00e8res : d\u00e9finissent les budgets globaux et supervisent la conformit\u00e9 budg\u00e9taire</li> <li>\u00c9quipes d'administration : veillent \u00e0 l'allocation des ressources et \u00e0 la rentabilit\u00e9</li> <li>\u00c9quipes applicatives : optimisent l'utilisation des services pour leur domaine sp\u00e9cifique</li> </ul> <p>La gestion des co\u00fbts dans Azure s'appuie sur trois piliers fondamentaux :</p> <p>Pr\u00e9vision et planification : avant m\u00eame de d\u00e9ployer des services, il est essentiel d'estimer les co\u00fbts pr\u00e9visionnels. Cette phase permet d'ajuster l'architecture et de faire des choix techniquement et financi\u00e8rement optimaux.</p> <p>Surveillance et analyse : une fois les services actifs, un suivi r\u00e9gulier des d\u00e9penses permet d'identifier rapidement les \u00e9carts par rapport aux pr\u00e9visions et les tendances anormales. L'analyse d\u00e9taill\u00e9e des co\u00fbts r\u00e9v\u00e8le quels services, quels groupes de ressources ou quelles \u00e9quipes consomment le plus.</p> <p>Optimisation et actions correctives : sur la base de l'analyse, des mesures concr\u00e8tes permettent de r\u00e9duire les gaspillages, d\u00e9sactiver les ressources inutilis\u00e9es et repenser les configurations inefficaces.</p>"},{"location":"_projects/_formation-azure/azure-chap10/#les-abonnements-dans-la-gestion-des-couts","title":"Les abonnements dans la gestion des co\u00fbts","text":""},{"location":"_projects/_formation-azure/azure-chap10/#structure-et-role-des-abonnements","title":"Structure et r\u00f4le des abonnements","text":"<p>Un abonnement Azure constitue le conteneur fondamental au sein duquel les ressources sont provisionn\u00e9es et factur\u00e9es[1]. Comprendre la structure des abonnements est essentiel pour ma\u00eetriser la gestion des co\u00fbts, car chaque abonnement g\u00e9n\u00e8re sa propre facture et dispose de ses propres limites de consommation.</p>"},{"location":"_projects/_formation-azure/azure-chap10/#etendues-de-facturation-et-de-gestion","title":"\u00c9tendues de facturation et de gestion","text":"<p>La plateforme Azure propose plusieurs niveaux d'\u00e9tendues permettant de organiser et de surveiller les co\u00fbts \u00e0 diff\u00e9rents niveaux de granularit\u00e9[6] :</p> <p>Compte d'inscription : niveau le plus \u00e9lev\u00e9 pour les clients Accord Entreprise (EA). Le propri\u00e9taire du compte peut g\u00e9rer les param\u00e8tres de facturation, afficher tous les co\u00fbts et configurer les budgets \u00e0 ce niveau[6].</p> <p>Abonnement : chaque abonnement g\u00e9n\u00e8re une facturation distincte. Les administrateurs d'abonnement disposent d'une visibilit\u00e9 compl\u00e8te sur les co\u00fbts de cet abonnement sp\u00e9cifique.</p> <p>Groupe de ressources : permet de regrouper logiquement les ressources et de suivre les co\u00fbts par projet, environnement ou d\u00e9partement.</p> <p>Ressource individuelle : niveau granulaire permettant d'identifier le co\u00fbt pr\u00e9cis de chaque service d\u00e9ploy\u00e9.</p>"},{"location":"_projects/_formation-azure/azure-chap10/#acces-aux-informations-de-couts","title":"Acc\u00e8s aux informations de co\u00fbts","text":"<p>Pour acc\u00e9der aux informations de facturation et de gestion des co\u00fbts au sein d'un abonnement Azure, le chemin standardis\u00e9 dans le portail Azure est le suivant[1] :</p> <ol> <li>Acc\u00e9der au portail Azure (portal.azure.com)</li> <li>S\u00e9lectionner Gestion des co\u00fbts + Facturation dans le menu principal</li> <li>Choisir entre Gestion des co\u00fbts pour l'analyse ou Factures pour les d\u00e9tails de facturation</li> <li>S\u00e9lectionner Modes de paiement pour g\u00e9rer les informations de paiement</li> </ol> <p>Cette structure hi\u00e9rarchique des \u00e9tendues permet une gestion des co\u00fbts nuanc\u00e9e, o\u00f9 chaque niveau d'organisation peut surveiller et contr\u00f4ler ses d\u00e9penses de mani\u00e8re appropri\u00e9e \u00e0 sa position dans la hi\u00e9rarchie.</p>"},{"location":"_projects/_formation-azure/azure-chap10/#la-calculatrice-de-prix","title":"La calculatrice de prix","text":""},{"location":"_projects/_formation-azure/azure-chap10/#objectif-et-utilite","title":"Objectif et utilit\u00e9","text":"<p>La calculatrice de prix Azure repr\u00e9sente l'outil fondamental pour la phase de pr\u00e9vision des co\u00fbts, bien avant le d\u00e9ploiement effectif des ressources[2]. Elle permet de transformer une utilisation anticip\u00e9e en co\u00fbts estim\u00e9s, facilitant ainsi la planification budg\u00e9taire initiale et les d\u00e9cisions architecturales avis\u00e9es.</p>"},{"location":"_projects/_formation-azure/azure-chap10/#acces-et-utilisation-de-base","title":"Acc\u00e8s et utilisation de base","text":"<p>La calculatrice de prix Azure est accessible directement depuis le Web, sans n\u00e9cessit\u00e9 de connexion pour une utilisation basique[2]. Cependant, une connexion avec les identifiants Azure offre des avantages suppl\u00e9mentaires :</p> <ul> <li>Sans connexion : calculs g\u00e9n\u00e9riques bas\u00e9s sur les prix catalogue standard</li> <li>Avec connexion : acc\u00e8s aux prix n\u00e9goci\u00e9s ou r\u00e9duits applicables au compte sp\u00e9cifique</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap10/#processus-destimation","title":"Processus d'estimation","text":"<p>L'utilisation de la calculatrice suit un processus structur\u00e9 :</p> <p>1. S\u00e9lection des services : l'utilisateur identifie les services Azure qu'il envisage de d\u00e9ployer (machines virtuelles, bases de donn\u00e9es, stockage, services d'application, etc.).</p> <p>2. Configuration des param\u00e8tres : pour chaque service s\u00e9lectionn\u00e9, plusieurs variables doivent \u00eatre ajust\u00e9es :</p> Param\u00e8tre Exemple Impact sur le co\u00fbt Taille de machine virtuelle Standard_B2s vs Standard_D4s_v3 \u00c9norme (ressources diff\u00e9rentes) Zone g\u00e9ographique France vs \u00c9tats-Unis Mod\u00e9r\u00e9 (tarification r\u00e9gionale) Syst\u00e8me d'exploitation Linux vs Windows Significatif (licences Windows) Capacit\u00e9 de stockage 50 GB vs 1 TB Lin\u00e9aire (prix par GB) Redondance stockage LRS vs GRS Mod\u00e9r\u00e9 (r\u00e9plication accrue) Dur\u00e9e d'engagement \u00c0 la demande vs r\u00e9serv\u00e9 1 an Tr\u00e8s significatif (remises importante) <p>3. Consultation de l'estimation : la calculatrice agr\u00e8ge ces param\u00e8tres et affiche un co\u00fbt mensuel estim\u00e9, annuel et sur la dur\u00e9e de vie du projet.</p>"},{"location":"_projects/_formation-azure/azure-chap10/#exemple-pratique-de-scenario","title":"Exemple pratique de sc\u00e9nario","text":"<p>Imaginons qu'une entreprise souhaite d\u00e9ployer une application Web simple en Azure :</p> <p>Composants requis : - 2 machines virtuelles Standard_B2s (4 GB RAM, 2 vCPU) pour le serveur Web - 1 base de donn\u00e9es SQL Server avec 20 GB de stockage - 100 GB de stockage Blob pour les contenus statiques - R\u00e9seau priv\u00e9 virtuel (VNet) avec deux sous-r\u00e9seaux - \u00c9quilibreur de charge pour r\u00e9partir le trafic</p> <p>Calcul estim\u00e9 (zones France, Linux, sans r\u00e9servation) : - 2 \u00d7 Standard_B2s : ~35 \u20ac/mois chacune = 70 \u20ac - Base de donn\u00e9es SQL : ~50 \u20ac/mois - Stockage Blob : ~2,40 \u20ac (100 \u00d7 0,024 \u20ac/GB) - Autres services (r\u00e9seau, etc.) : ~15 \u20ac</p> <p>Total mensuel estim\u00e9 : ~137 \u20ac | Annuel : ~1 644 \u20ac</p> <p>Avec un engagement de r\u00e9serve (reserved instance) d'un an, les machines virtuelles pourraient \u00eatre r\u00e9duites de 30-40%, apportant une \u00e9conomie significative.</p>"},{"location":"_projects/_formation-azure/azure-chap10/#avantages-strategiques","title":"Avantages strat\u00e9giques","text":"<p>L'utilisation r\u00e9guli\u00e8re de la calculatrice offre plusieurs b\u00e9n\u00e9fices :</p> <ul> <li>Comparaison d'architectures : tester diff\u00e9rentes configurations pour identifier la plus rentable</li> <li>Justification des investissements : quantifier les co\u00fbts pour obtenir l'approbation budg\u00e9taire</li> <li>Planification pluriannuelle : estimer les co\u00fbts avec ou sans engagements de r\u00e9serve</li> <li>Sensibilit\u00e9 aux co\u00fbts : comprendre l'impact de chaque param\u00e8tre de configuration</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap10/#loutil-analyse-des-couts-cost-management","title":"L'outil Analyse des co\u00fbts (Cost Management)","text":""},{"location":"_projects/_formation-azure/azure-chap10/#presentation-generale","title":"Pr\u00e9sentation g\u00e9n\u00e9rale","text":"<p>Microsoft Cost Management constitue la solution int\u00e9gr\u00e9e permettant de surveiller, analyser et optimiser les d\u00e9penses r\u00e9elles dans Azure[1]. Contrairement \u00e0 la calculatrice de prix qui travaille sur des pr\u00e9visions, Cost Management op\u00e8re sur les donn\u00e9es de facturation r\u00e9elles de l'environnement Azure d\u00e9ploy\u00e9.</p>"},{"location":"_projects/_formation-azure/azure-chap10/#acces-a-cost-management","title":"Acc\u00e8s \u00e0 Cost Management","text":"<p>Cost Management est accessible via le chemin standardis\u00e9 du portail Azure[1][3] :</p> <ol> <li>Portail Azure (portal.azure.com)</li> <li>Gestion des co\u00fbts + Facturation</li> <li>Gestion des co\u00fbts (dans le menu gauche)</li> </ol> <p>Une fois \u00e0 ce niveau, plusieurs options s'offrent \u00e0 l'utilisateur selon ses besoins sp\u00e9cifiques d'analyse.</p>"},{"location":"_projects/_formation-azure/azure-chap10/#analyse-des-couts-cost-analysis","title":"Analyse des co\u00fbts (Cost Analysis)","text":"<p>Objectif : fournir une vue d\u00e9taill\u00e9e et flexible des d\u00e9penses r\u00e9elles, permettant de comprendre o\u00f9 l'argent est d\u00e9pens\u00e9.</p> <p>Acc\u00e8s dans Cost Management : - Portail Azure \u2192 Gestion des co\u00fbts + Facturation - Gestion des co\u00fbts dans le menu gauche - Rapports + Analytique \u2192 Analyse des co\u00fbts[3]</p> <p>Fonctionnalit\u00e9s principales de l'analyse des co\u00fbts :</p> <p>Agr\u00e9gation des co\u00fbts : visualisation du co\u00fbt global pour un compte ou l'accumulation des co\u00fbts au fil du temps[1]. Cela permet de voir imm\u00e9diatement si les d\u00e9penses augmentent, diminuent ou restent stables.</p> <p>Visualisations graphiques : les donn\u00e9es sont pr\u00e9sent\u00e9es sous forme de graphiques, facilitant l'identification rapide des tendances et anomalies. Un pic soudain dans les co\u00fbts devient imm\u00e9diatement visible.</p> <p>Filtrage et segmentation : l'analyse peut \u00eatre filtr\u00e9e par plusieurs dimensions : - Groupe de ressources - Ressource individuelle - Service Azure - Balise (tags) - Localisation g\u00e9ographique - P\u00e9riode temporelle</p> <p>Exemple d'analyse filtr\u00e9e :</p> <p>Un administrateur souhaitant comprendre les co\u00fbts de son environnement de production pourrait appliquer les filtres suivants :</p> Text Only<pre><code>P\u00e9riode : Dernier mois\nService : Machines virtuelles\nEnvironnement : Production (via balise)\nLocalisation : France\n</code></pre> <p>R\u00e9sultat : visualisation pr\u00e9cise des co\u00fbts des machines virtuelles de production en France pour le dernier mois, permettant d'identifier si une machine consomme anormalement plus que pr\u00e9vu.</p>"},{"location":"_projects/_formation-azure/azure-chap10/#budgets-et-alertes","title":"Budgets et alertes","text":"<p>Objectif : pr\u00e9venir les d\u00e9passements de co\u00fbts en d\u00e9finissant des seuils et en recevant des notifications proactives[1][3].</p> <p>Cr\u00e9ation d'un budget :</p> <p>Pour cr\u00e9er un budget permettant de ma\u00eetriser les d\u00e9penses, les \u00e9tapes sont les suivantes[4] :</p> <ol> <li>Naviguer vers Gestion des co\u00fbts + Facturation \u2192 Gestion des co\u00fbts</li> <li>S\u00e9lectionner Budgets dans le menu gauche</li> <li>Cliquer sur Cr\u00e9er un budget</li> <li>Configurer les param\u00e8tres du budget :</li> </ol> Param\u00e8tre Description Exemple \u00c9tendue Niveau auquel s'applique le budget Abonnement ou groupe de ressources Nom du budget Identificateur unique \"Budget-Production-2025\" Montant Limite de d\u00e9pense 5 000 \u20ac P\u00e9riode de r\u00e9initialisation Fr\u00e9quence Mensuel, trimestriel, annuel Seuils d'alerte Pourcentages d\u00e9clenchant une notification 50%, 75%, 100%, 125% <p>Exemple concret de configuration :</p> <p>Un d\u00e9partement IT d\u00e9cide de limiter les d\u00e9penses de test \u00e0 2 000 \u20ac par mois. La configuration serait :</p> <ul> <li>\u00c9tendue : Groupe de ressources \"Test-Environment\"</li> <li>Montant : 2 000 \u20ac</li> <li>P\u00e9riode : Mensuel</li> <li>Alertes :</li> <li>50% (1 000 \u20ac) : alerte pr\u00e9coce</li> <li>75% (1 500 \u20ac) : alerte d'avertissement</li> <li>100% (2 000 \u20ac) : alerte de d\u00e9passement</li> <li>125% (2 500 \u20ac) : alerte critique</li> </ul> <p>Lorsque le seuil de 50% est atteint, une notification est envoy\u00e9e automatiquement \u00e0 l'\u00e9quipe responsable, permettant une action corrective pr\u00e9coce.</p> <p>Bonne pratique : cr\u00e9er des budgets et des alertes pour les abonnements et les groupes de ressources dans le cadre d'une strat\u00e9gie globale de supervision des co\u00fbts[3].</p>"},{"location":"_projects/_formation-azure/azure-chap10/#recommandations-doptimisation","title":"Recommandations d'optimisation","text":"<p>Objectif : identifier automatiquement les opportunit\u00e9s de r\u00e9duction de co\u00fbts gr\u00e2ce \u00e0 l'analyse comportementale des ressources.</p> <p>Recommandations disponibles :</p> <p>Cost Management fournit des recommandations proactives bas\u00e9es sur les mod\u00e8les d'utilisation observ\u00e9s[1]. Ces recommandations identifient :</p> <ul> <li>Ressources inutilis\u00e9es : machines virtuelles sans activit\u00e9 depuis plusieurs semaines, adresses IP publiques non associ\u00e9es, comptes de stockage vides</li> <li>Ressources sous-exploit\u00e9es : machines virtuelles configur\u00e9es pour des capacit\u00e9s \u00e9lev\u00e9es mais utilisant seulement 10-20% de leurs ressources</li> <li>Optimisations de configuration : services mal configur\u00e9s consommant plus de ressources que n\u00e9cessaire</li> </ul> <p>Int\u00e9gration avec Azure Advisor : pour une analyse plus approfondie, Azure Advisor fournit des recommandations personnalis\u00e9es en fonction de l'utilisation r\u00e9elle[2]. L'acc\u00e8s se fait via :</p> <ol> <li>Portail Azure \u2192 Advisor</li> <li>S\u00e9lectionner l'onglet Co\u00fbt dans le menu gauche</li> <li>Consulter les recommandations actionnables li\u00e9es aux co\u00fbts</li> </ol> <p>Les recommandations incluent des estimations d'\u00e9conomies potentielles et des instructions pour impl\u00e9menter chaque suggestion.</p>"},{"location":"_projects/_formation-azure/azure-chap10/#gestion-des-factures-et-des-paiements","title":"Gestion des factures et des paiements","text":"<p>Acc\u00e8s aux factures :</p> <p>Le portail Azure permet de g\u00e9rer les factures et les modes de paiement via[1] :</p> <ol> <li>Gestion des co\u00fbts + Facturation</li> <li>Factures dans la section Facturation (menu gauche)</li> </ol> <p>Fonctionnalit\u00e9s disponibles :</p> <ul> <li>Visualisation des factures \u00e9mises</li> <li>T\u00e9l\u00e9chargement en format PDF</li> <li>Acc\u00e8s aux fichiers d'utilisation d\u00e9taill\u00e9s</li> <li>Comparaison des charges factur\u00e9es aux fichiers d'utilisation pour v\u00e9rifier la pr\u00e9cision</li> </ul> <p>Gestion des modes de paiement :</p> <ol> <li>Gestion des co\u00fbts + Facturation</li> <li>Modes de paiement dans la section Facturation</li> <li>Ajouter, modifier ou supprimer des moyens de paiement</li> <li>D\u00e9finir le mode de paiement par d\u00e9faut</li> </ol>"},{"location":"_projects/_formation-azure/azure-chap10/#integration-avec-les-systemes-externes","title":"Int\u00e9gration avec les syst\u00e8mes externes","text":"<p>Pour une gestion des co\u00fbts encore plus robuste, Azure propose des APIs permettant d'int\u00e9grer les donn\u00e9es de facturation et de consommation dans des syst\u00e8mes de reporting personnalis\u00e9s[2] :</p> <ul> <li>APIs de facturation : acc\u00e8s programmatique aux factures</li> <li>APIs de consommation : r\u00e9cup\u00e9ration des donn\u00e9es d\u00e9taill\u00e9es d'utilisation</li> </ul> <p>Cette int\u00e9gration permet aux organisations disposant de syst\u00e8mes d'analytics personnalis\u00e9s d'agr\u00e9ger les donn\u00e9es Azure avec d'autres sources d'informations financi\u00e8res.</p>"},{"location":"_projects/_formation-azure/azure-chap10/#gestion-efficace-des-couts-avec-les-balises-tags","title":"Gestion efficace des co\u00fbts avec les balises (Tags)","text":""},{"location":"_projects/_formation-azure/azure-chap10/#concept-et-importance-des-balises","title":"Concept et importance des balises","text":"<p>Les balises (tags) en Azure constituent un m\u00e9canisme de m\u00e9tadonn\u00e9es permettant d'associer des informations descriptives aux ressources[2]. Dans le contexte de la gestion des co\u00fbts, les balises jouent un r\u00f4le crucial en fournissant des dimensions suppl\u00e9mentaires pour l'analyse des d\u00e9penses.</p>"},{"location":"_projects/_formation-azure/azure-chap10/#avantages-des-balises-pour-la-gestion-des-couts","title":"Avantages des balises pour la gestion des co\u00fbts","text":"<p>Organisation logique : les balises permettent de regrouper les ressources selon des crit\u00e8res m\u00e9tier plut\u00f4t que techniques. Exemple :</p> Text Only<pre><code>Environment: Production\nCostCenter: Finance\nProject: Migration-2025\nOwner: John.Smith@company.com\nDepartment: Engineering\n</code></pre> <p>Allocation des co\u00fbts : avec des balises coh\u00e9rentes, il devient possible de calculer pr\u00e9cis\u00e9ment quel d\u00e9partement, quel projet ou quel client consomme quels co\u00fbts.</p> <p>Conformit\u00e9 budg\u00e9taire : les budgets peuvent \u00eatre d\u00e9finis par balise plut\u00f4t que par groupe de ressources rigide, offrant plus de flexibilit\u00e9.</p> <p>Automatisation des actions : les balises peuvent d\u00e9clencher des actions automatis\u00e9es, comme la suppression des ressources en fin de projet ou le redimensionnement automatique selon l'environnement.</p>"},{"location":"_projects/_formation-azure/azure-chap10/#strategie-de-balisage-coherente","title":"Strat\u00e9gie de balisage coh\u00e9rente","text":"<p>Pour que les balises soient efficaces, une strat\u00e9gie organisationnelle doit \u00eatre \u00e9tablie et appliqu\u00e9e syst\u00e9matiquement.</p> <p>Balises obligatoires recommand\u00e9es :</p> Balise Valeurs typiques Utilit\u00e9 Environment Development, Test, Staging, Production Diff\u00e9rencier les co\u00fbts par environnement CostCenter Finance, Engineering, Marketing Attribution des co\u00fbts aux d\u00e9partements Project Project-A, Migration, POC Suivi des co\u00fbts par projet Owner user@company.com ou Team-Name Responsabilit\u00e9 et notifications Application WebApp, Database, Analytics Comprendre quels services co\u00fbtent le plus Department Sales, IT, Operations Vue au niveau organisationnel CreatedDate YYYY-MM-DD Archivage et nettoyage CostAllocation Direct, Indirect, Shared Mod\u00e8les de facturation internes"},{"location":"_projects/_formation-azure/azure-chap10/#implementation-pratique-du-balisage","title":"Impl\u00e9mentation pratique du balisage","text":"<p>1. D\u00e9finir la politique d'organisation</p> <p>L'\u00e9quipe governance doit d'abord \u00e9tablir le dictionnaire des balises accept\u00e9es et leurs valeurs possibles. Cette politique est document\u00e9e et communiqu\u00e9e \u00e0 tous les \u00e9quipes d\u00e9ployant des ressources.</p> <p>2. Application lors du d\u00e9ploiement</p> <p>Les balises doivent \u00eatre appliqu\u00e9es d\u00e8s la cr\u00e9ation des ressources, id\u00e9alement via des mod\u00e8les Azure Resource Manager ou des scripts de d\u00e9ploiement automatis\u00e9s pour assurer la coh\u00e9rence.</p> <p>Exemple de d\u00e9ploiement avec balises (pseudo-code) :</p> Text Only<pre><code>Variable: tags = {\n    Environment: \"Production\"\n    CostCenter: \"Finance\"\n    Project: \"Migration-2025\"\n    Owner: \"Alice@company.com\"\n    Department: \"Engineering\"\n}\n\nCr\u00e9er Machine Virtuelle avec tags\nCr\u00e9er Stockage avec tags\nCr\u00e9er Base de Donn\u00e9es avec tags\n</code></pre> <p>3. Filtrage dans Cost Management</p> <p>Une fois les balises appliqu\u00e9es, l'analyse des co\u00fbts peut utiliser ces balises comme dimensions de filtrage.</p> <p>Exemple de sc\u00e9nario d'analyse :</p> <p>Question m\u00e9tier : \"Combien co\u00fbte le projet Migration-2025 ?\"</p> <p>Utilisation de Cost Management : 1. Ouvrir Analyse des co\u00fbts 2. Appliquer le filtre : Balise \"Project\" = \"Migration-2025\" 3. Visualiser le co\u00fbt total du projet sur la p\u00e9riode choisie 4. Voir la r\u00e9partition par service (machines virtuelles vs stockage vs base de donn\u00e9es)</p> <p>R\u00e9sultat : vue pr\u00e9cise du co\u00fbt total du projet, facilitant la comparaison avec le budget initial estim\u00e9 par la calculatrice.</p>"},{"location":"_projects/_formation-azure/azure-chap10/#scenario-complet-dutilisation","title":"Sc\u00e9nario complet d'utilisation","text":"<p>Consid\u00e9rons une organisation multiprojet utilisant efficacement les balises :</p> <p>Contexte : - Projet A : Migration cloud, budget 20 000 \u20ac - Projet B : D\u00e9veloppement nouvelle application, budget 15 000 \u20ac - Environnement de d\u00e9veloppement partag\u00e9, budget 10 000 \u20ac</p> <p>Ressources d\u00e9ploy\u00e9es avec balises :</p> <p>Projet A : Text Only<pre><code>Machine Virtuelle prod-migration-vm01:\n  Environment: Production\n  Project: Migration-2025\n  CostCenter: IT\n  Owner: team-migration@company.com\n\nBase de Donn\u00e9es prod-migration-db:\n  Environment: Production\n  Project: Migration-2025\n  CostCenter: IT\n</code></pre></p> <p>Projet B : Text Only<pre><code>Machine Virtuelle dev-newapp-vm01:\n  Environment: Development\n  Project: NewApp-2025\n  CostCenter: Engineering\n  Owner: alice@company.com\n\nFonction Azure newapp-processor:\n  Environment: Development\n  Project: NewApp-2025\n  CostCenter: Engineering\n</code></pre></p> <p>Environnement partag\u00e9 : Text Only<pre><code>Machine Virtuelle dev-shared-vm:\n  Environment: Development\n  CostAllocation: Shared\n  Owner: devops@company.com\n</code></pre></p> <p>Analyses possibles avec cette structure :</p> <p>1. Co\u00fbts par projet - Filtrer par balise \"Project\" = \"Migration-2025\" \u2192 co\u00fbts totaux du projet - Comparer avec le budget initial (20 000 \u20ac) - Identifier si d\u00e9passement budg\u00e9taire</p> <p>2. Co\u00fbts par environnement - Filtrer par \"Environment\" = \"Production\" \u2192 d\u00e9penses production - Filtrer par \"Environment\" = \"Development\" \u2192 d\u00e9penses d\u00e9veloppement - Justifier les investissements \u00e0 la direction</p> <p>3. Co\u00fbts par d\u00e9partement - Filtrer par \"CostCenter\" = \"IT\" \u2192 co\u00fbts du d\u00e9partement IT - Filtrer par \"CostCenter\" = \"Engineering\" \u2192 co\u00fbts du d\u00e9partement Engineering - Facturer les co\u00fbts internes aux bons d\u00e9partements</p> <p>4. Alertes intelligentes - Budget de 20 000 \u20ac sur le Projet Migration-2025 - Alerte \u00e0 50%, 75%, 100% - Notifications automatiques \u00e0 team-migration@company.com</p>"},{"location":"_projects/_formation-azure/azure-chap10/#automatisation-basee-sur-les-balises","title":"Automatisation bas\u00e9e sur les balises","text":"<p>Les balises ne servent pas qu'\u00e0 l'analyse ; elles peuvent d\u00e9clencher des actions automatis\u00e9es.</p> <p>Exemples d'automatisation :</p> <p>Nettoyage automatique Text Only<pre><code>R\u00e8gle : Si CreatedDate &lt; (Aujourd'hui - 30 jours)\n        ET Environment = \"Test\"\n        ALORS supprimer la ressource\n</code></pre></p> <p>Cette r\u00e8gle garantit que les ressources de test temporaires ne restent pas actives et ne g\u00e9n\u00e8rent pas des co\u00fbts inutiles.</p> <p>Notifications intelligentes Text Only<pre><code>R\u00e8gle : Quand co\u00fbt du jour &gt; (budget mensuel / 30)\n        ET Owner = Alice@company.com\n        ALORS envoyer alerte \u00e0 Alice\n</code></pre></p> <p>Alice re\u00e7oit une notification personnalis\u00e9e si le co\u00fbt quotidien de ses ressources d\u00e9passe la moyenne attendue.</p> <p>Redimensionnement automatique Text Only<pre><code>R\u00e8gle : Si CPU &lt; 10% pendant 7 jours\n        ET Environment = \"Production\"\n        ET Owner = Alice@company.com\n        ALORS r\u00e9duire la taille et notifier Alice\n</code></pre></p>"},{"location":"_projects/_formation-azure/azure-chap10/#ecosysteme-complet-de-gestion-des-couts","title":"\u00c9cosyst\u00e8me complet de gestion des co\u00fbts","text":""},{"location":"_projects/_formation-azure/azure-chap10/#flux-doptimisation-progressive","title":"Flux d'optimisation progressive","text":"<p>La gestion efficace des co\u00fbts sur Azure suit un flux continu et it\u00e9ratif :</p> Text Only<pre><code>1. PLANIFICATION\n   \u2193\n   Utiliser la calculatrice de prix\n   Estimer les co\u00fbts initiaux\n   Justifier l'investissement\n\n2. D\u00c9PLOIEMENT\n   \u2193\n   Appliquer les balises syst\u00e9matiquement\n   Configurer les budgets d\u00e8s le d\u00e9part\n   Mettre en place les alertes\n\n3. MONITORING\n   \u2193\n   Surveiller l'analyse des co\u00fbts\n   Recevoir les notifications\n   Analyser les tendances\n\n4. OPTIMISATION\n   \u2193\n   Consulter les recommandations d'Advisor\n   Identifier les ressources inutilis\u00e9es\n   Redimensionner les sur-configur\u00e9es\n   Impl\u00e9menter les suggestions\n\n5. RETOUR \u00c0 L'\u00c9TAPE 3\n   \u2193\n   Surveillance continue et ajustements\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap10/#outils-complementaires","title":"Outils compl\u00e9mentaires","text":"<p>Au-del\u00e0 de Cost Management, Azure propose un ensemble d'outils compl\u00e9mentaires pour une gestion holistique[5] :</p> <p>Microsoft Cost Management : centralise les informations financi\u00e8res, identifie les opportunit\u00e9s d'optimisation et suit les tendances de consommation[5].</p> <p>Outil de calcul de tarification : permet d'estimer les co\u00fbts des services avant leur d\u00e9ploiement en ajustant les variables comme les tailles de machines ou les zones g\u00e9ographiques[5].</p> <p>Azure Advisor : fournit des recommandations personnalis\u00e9es pour optimiser les configurations et r\u00e9duire les d\u00e9penses[5]. Les suggestions d'Advisor reposent sur l'analyse r\u00e9elle de l'utilisation des ressources.</p>"},{"location":"_projects/_formation-azure/azure-chap10/#cas-dusage-avances","title":"Cas d'usage avanc\u00e9s","text":"<p>Facturation chargeback interne Une organisation avec plusieurs d\u00e9partements souhaite imputer les co\u00fbts cloud exactement aux d\u00e9partements consommateurs. Gr\u00e2ce aux balises et \u00e0 Cost Management :</p> <ol> <li>Baliser chaque ressource avec le d\u00e9partement responsable</li> <li>G\u00e9n\u00e9rer mensuellement un rapport Cost Management par d\u00e9partement</li> <li>Facturer en interne chaque d\u00e9partement selon sa consommation r\u00e9elle</li> </ol> <p>Gestion multilocataire Une agence IT g\u00e9rant les clouds de plusieurs clients distincts :</p> <ol> <li>Utiliser une balise \"Client\" avec les noms des clients</li> <li>Filtrer l'analyse par client dans Cost Management</li> <li>G\u00e9n\u00e9rer des rapports de facturation automatis\u00e9s par client</li> <li>Configurer des budgets par client pour \u00e9viter les surprises</li> </ol> <p>Optimisation par environnement Une entreprise d\u00e9ploie des environnements multiples (dev, test, staging, prod) :</p> <ol> <li>Baliser chaque environnement (Environment: Dev, Test, Staging, Production)</li> <li>Analyser les co\u00fbts de chaque environnement</li> <li>Identifier que le Staging co\u00fbte trop cher pour un environnement temporaire</li> <li>Redimensionner ou arr\u00eater Staging en fin de journ\u00e9e via l'automatisation</li> </ol>"},{"location":"_projects/_formation-azure/azure-chap10/#conclusion-du-chapitre","title":"Conclusion du chapitre","text":"<p>La gestion des co\u00fbts sur Azure est un exercice continu n\u00e9cessitant une approche m\u00e9thodique combinant[1] :</p> <ul> <li>Pr\u00e9vision gr\u00e2ce \u00e0 la calculatrice de prix</li> <li>Surveillance via Cost Management et les alertes</li> <li>Organisation au moyen des balises coh\u00e9rentes</li> <li>Optimisation en r\u00e9ponse aux recommandations d'Advisor</li> <li>Reporting pour la transparence et l'allocation des co\u00fbts</li> </ul> <p>Chacun des composants pr\u00e9sent\u00e9s dans ce chapitre joue un r\u00f4le sp\u00e9cifique dans cette strat\u00e9gie globale. Une impl\u00e9mentation compl\u00e8te, combinant tous ces \u00e9l\u00e9ments avec une discipline organisationnelle appropri\u00e9e, permet aux entreprises de ma\u00eetriser pr\u00e9cis\u00e9ment leurs d\u00e9penses cloud tout en maintenant la flexibilit\u00e9 et l'agilit\u00e9 qui font la force du cloud Azure.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure/azure-chap11/","title":"Citations","text":"<ul> <li>https://www.axido.fr/gouvernance-azure-gardez-le-controle-reduisez-les-risques/</li> <li>https://azure.microsoft.com/fr-fr/solutions/governance</li> <li>https://learn.microsoft.com/fr-fr/azure/governance/policy/concepts/regulatory-compliance</li> <li>https://learn.microsoft.com/fr-fr/azure/cloud-adoption-framework/ready/azure-setup-guide/governance-compliance</li> <li>https://learn.microsoft.com/fr-fr/azure/governance/management-groups/azure-management</li> <li>https://learn.microsoft.com/fr-fr/azure/governance/policy/tutorials/create-and-manage</li> <li>https://azure.microsoft.com/fr-fr/resources/cloud-computing-dictionary/what-is-a-data-governance</li> <li>https://learn.microsoft.com/fr-fr/fabric/governance/governance-compliance-overview</li> <li>https://learn.microsoft.com/fr-fr/shows/on-demand-instructor-led-training-series/az-900-module-6</li> <li>https://learn.microsoft.com/fr-fr/azure/governance/</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap11/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 284</li> <li>completion_tokens: 6630</li> <li>total_tokens: 6914</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.099, 'request_cost': 0.006, 'total_cost': 0.106}</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap11/#content","title":"Content","text":""},{"location":"_projects/_formation-azure/azure-chap11/#gouvernance-et-conformite-avec-azure-guide-detaille","title":"\ud83d\udcd8 Gouvernance et Conformit\u00e9 avec Azure - Guide D\u00e9taill\u00e9","text":""},{"location":"_projects/_formation-azure/azure-chap11/#introduction-a-la-gouvernance-et-a-la-conformite","title":"Introduction \u00e0 la Gouvernance et \u00e0 la Conformit\u00e9","text":""},{"location":"_projects/_formation-azure/azure-chap11/#definition-et-enjeux","title":"D\u00e9finition et Enjeux","text":"<p>La gouvernance Azure d\u00e9signe l'ensemble des r\u00e8gles, processus et outils permettant \u00e0 une organisation de ma\u00eetriser l'usage de ses ressources cloud Azure, en coh\u00e9rence avec ses objectifs strat\u00e9giques, s\u00e9curitaires et r\u00e9glementaires[1]. Il s'agit de d\u00e9finir un cadre clair pour organiser, s\u00e9curiser, surveiller et optimiser les environnements Azure, tout en garantissant la conformit\u00e9, la transparence et le contr\u00f4le des co\u00fbts[1].</p>"},{"location":"_projects/_formation-azure/azure-chap11/#objectifs-principaux-de-la-gouvernance","title":"Objectifs Principaux de la Gouvernance","text":"<p>La mise en place d'une gouvernance efficace r\u00e9pond \u00e0 plusieurs objectifs critiques :</p> <p>Contr\u00f4le et S\u00e9curit\u00e9 : Reprendre le contr\u00f4le sur un \u00e9cosyst\u00e8me con\u00e7u pour la flexibilit\u00e9, garantir que le cloud reste un actif ma\u00eetris\u00e9 et s\u00e9curis\u00e9.</p> <p>Conformit\u00e9 R\u00e9glementaire : Satisfaire aux exigences externes (RGPD, ISO 27001, DORA, SOC 2)[1]. Sans gouvernance, les organisations risquent le non-respect des exigences de conformit\u00e9 qui peut entra\u00eener des p\u00e9nalit\u00e9s r\u00e9glementaires et des risques l\u00e9gaux.</p> <p>Standardisation des Pratiques : Aligner les pratiques IT avec la strat\u00e9gie d'entreprise et cr\u00e9er une coh\u00e9rence dans l'utilisation des ressources cloud \u00e0 chaque nouveau projet ou environnement.</p> <p>Optimisation des Co\u00fbts : Surveiller les d\u00e9penses, identifier les ressources inutilis\u00e9es et encourager la responsabilit\u00e9 financi\u00e8re dans l'ensemble de l'organisation.</p> <p>Gestion des Identit\u00e9s : Mettre en place une gestion rigoureuse des identit\u00e9s et des r\u00f4les (RBAC) pour limiter les risques li\u00e9s aux acc\u00e8s non contr\u00f4l\u00e9s et renforcer la s\u00e9curit\u00e9 du cloud Azure conform\u00e9ment aux principes de Zero Trust[1].</p>"},{"location":"_projects/_formation-azure/azure-chap11/#composantes-cles-dune-gouvernance-efficace","title":"Composantes Cl\u00e9s d'une Gouvernance Efficace","text":"<p>Une gouvernance Azure robuste repose sur cinq composantes principales :</p> <ol> <li>Gestion des acc\u00e8s et des identit\u00e9s : Contr\u00f4le granulaire des permissions \u00e0 travers RBAC</li> <li>Suivi de la conformit\u00e9 et des politiques : Application automatique des r\u00e8gles via Azure Policy</li> <li>Gestion des co\u00fbts : Surveillance et optimisation des d\u00e9penses cloud</li> <li>S\u00e9curit\u00e9 et protection des donn\u00e9es : Mise en place de contr\u00f4les de s\u00e9curit\u00e9</li> <li>Audit et tra\u00e7abilit\u00e9 : Logging continu et tra\u00e7abilit\u00e9 des actions</li> </ol>"},{"location":"_projects/_formation-azure/azure-chap11/#le-service-strategie-azure-policy","title":"Le Service Strat\u00e9gie (Azure Policy)","text":""},{"location":"_projects/_formation-azure/azure-chap11/#vue-densemble-dazure-policy","title":"Vue d'Ensemble d'Azure Policy","text":"<p>Azure Policy est un service gratuit qui permet de d\u00e9finir et d'appliquer des r\u00e8gles dans l'environnement Azure[4]. Les r\u00e8gles, appel\u00e9es strat\u00e9gies ou politiques, peuvent bloquer certaines actions ou les suivre pour r\u00e9vision[4]. Azure Policy prend en charge quatre niveaux d'\u00e9tendue pour l'application des r\u00e8gles[4].</p>"},{"location":"_projects/_formation-azure/azure-chap11/#fonctionnalites-principales","title":"Fonctionnalit\u00e9s Principales","text":"<p>D\u00e9finition des R\u00e8gles : Les administrateurs peuvent cr\u00e9er des d\u00e9finitions de strat\u00e9gie qui imposent des conditions sur les ressources Azure. Ces strat\u00e9gies maintiennent les ressources conformes aux standards de l'entreprise[5].</p> <p>Application Automatique : Azure Policy applique automatiquement les r\u00e8gles sans intervention manuelle, r\u00e9duisant ainsi les erreurs humaines et garantissant une conformit\u00e9 continue[1].</p> <p>Audit et Conformit\u00e9 : Le service fournit des rapports d\u00e9taill\u00e9s permettant de voir quelles ressources sont conformes et lesquelles ne le sont pas. Cela cr\u00e9e une piste d'audit pour identifier les probl\u00e8mes de conformit\u00e9, avertir les parties prenantes et r\u00e9soudre les probl\u00e8mes rapidement[2].</p>"},{"location":"_projects/_formation-azure/azure-chap11/#niveaux-detendue-dazure-policy","title":"Niveaux d'\u00c9tendue d'Azure Policy","text":"<p>Azure Policy peut \u00eatre appliqu\u00e9e \u00e0 diff\u00e9rents niveaux :</p> Niveau d'\u00c9tendue Description Utilisation Groupe d'administration S'applique \u00e0 plusieurs abonnements Gouvernance organisationnelle globale Abonnement S'applique \u00e0 tous les groupes de ressources et ressources d'un abonnement Contr\u00f4le au niveau de l'abonnement Groupe de ressources S'applique \u00e0 toutes les ressources d'un groupe Gestion de projets sp\u00e9cifiques Ressource individuelle S'applique \u00e0 une ressource sp\u00e9cifique Cas exceptions ou contr\u00f4les pr\u00e9cis"},{"location":"_projects/_formation-azure/azure-chap11/#exemple-de-creation-et-dassignation-de-politique","title":"Exemple de Cr\u00e9ation et d'Assignation de Politique","text":""},{"location":"_projects/_formation-azure/azure-chap11/#creer-une-politique-pour-exiger-le-tagging","title":"Cr\u00e9er une Politique pour Exiger le Tagging","text":"<p>La premi\u00e8re \u00e9tape dans l'impl\u00e9mentation d'une gouvernance avec Azure Policy consiste \u00e0 cr\u00e9er et assigner une d\u00e9finition de strat\u00e9gie. L'exemple suivant illustre une politique simple exigeant que toutes les ressources disposent d'une balise \"Environnement\".</p> JSON<pre><code>{\n  \"mode\": \"indexed\",\n  \"policyRule\": {\n    \"if\": {\n      \"field\": \"[concat('tags[', parameters('tagName'), ']')]\",\n      \"exists\": \"false\"\n    },\n    \"then\": {\n      \"effect\": \"deny\"\n    }\n  },\n  \"parameters\": {\n    \"tagName\": {\n      \"type\": \"string\",\n      \"metadata\": {\n        \"displayName\": \"Nom de la balise\",\n        \"description\": \"La balise requise sur toutes les ressources\"\n      }\n    }\n  }\n}\n</code></pre> <p>Cette politique emp\u00eache la cr\u00e9ation de ressources qui ne poss\u00e8dent pas la balise sp\u00e9cifi\u00e9e.</p>"},{"location":"_projects/_formation-azure/azure-chap11/#assigner-une-politique-via-powershell","title":"Assigner une Politique via PowerShell","text":"PowerShell<pre><code># Se connecter \u00e0 Azure\nConnect-AzAccount\n\n# Obtenir la d\u00e9finition de strat\u00e9gie\n$policyDef = Get-AzPolicyDefinition -Name \"Exiger une balise sur les ressources\"\n\n# Assigner la politique \u00e0 un groupe de ressources\nNew-AzPolicyAssignment `\n  -Name \"Assigner-Balise-Environnement\" `\n  -DisplayName \"Assigner la balise Environnement\" `\n  -PolicyDefinition $policyDef `\n  -Scope \"/subscriptions/{subscriptionId}/resourceGroups/{resourceGroupName}\" `\n  -PolicyParameter @{ \"tagName\" = @{ \"value\" = \"Environnement\" } }\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap11/#azure-policy-vs-azure-blueprints","title":"Azure Policy vs Azure Blueprints","text":"<p>Bien que distincts, Azure Policy et Azure Blueprints travaillent ensemble pour une gouvernance compl\u00e8te :</p> Aspect Azure Policy Azure Blueprints Objectif Appliquer des r\u00e8gles et des standards D\u00e9ployer des environnements pr\u00e9-configur\u00e9s Fonctionnement Contr\u00f4le continu des ressources D\u00e9ploiement initial + standards Cas d'Usage Forcer la conformit\u00e9 en permanence Cr\u00e9er des environnements conformes rapidement Flexibilit\u00e9 Applique les m\u00eames r\u00e8gles partout Permet des variations contr\u00f4l\u00e9es"},{"location":"_projects/_formation-azure/azure-chap11/#conformite-reglementaire-dans-azure-policy","title":"Conformit\u00e9 R\u00e9glementaire dans Azure Policy","text":"<p>Azure Policy fournit des d\u00e9finitions d'initiative int\u00e9gr\u00e9es qui permettent de voir la liste des contr\u00f4les et des domaines de conformit\u00e9 selon diff\u00e9rentes responsabilit\u00e9s : Client, Microsoft, ou Partag\u00e9[3]. Pour les contr\u00f4les dont Microsoft est responsable, le service fournit les d\u00e9tails des r\u00e9sultats d'audit en fonction d'une attestation tierce ainsi que les d\u00e9tails d'impl\u00e9mentation permettant d'atteindre cette conformit\u00e9[3].</p>"},{"location":"_projects/_formation-azure/azure-chap11/#les-verrous-de-ressource","title":"Les Verrous de Ressource","text":""},{"location":"_projects/_formation-azure/azure-chap11/#concept-et-importance","title":"Concept et Importance","text":"<p>Les verrous de ressource (Resource Locks) constituent un m\u00e9canisme de protection suppl\u00e9mentaire pour emp\u00eacher les modifications accidentelles ou malveillantes des ressources critiques Azure[4]. Ils fonctionnent en compl\u00e9ment avec le contr\u00f4le d'acc\u00e8s bas\u00e9 sur les r\u00f4les (RBAC) pour fournir une couche de s\u00e9curit\u00e9 additionnelle.</p>"},{"location":"_projects/_formation-azure/azure-chap11/#types-de-verrous","title":"Types de Verrous","text":""},{"location":"_projects/_formation-azure/azure-chap11/#verrou-cannotdelete","title":"Verrou CanNotDelete","text":"<p>Le verrou CanNotDelete emp\u00eache la suppression d'une ressource tout en permettant les modifications :</p> <ul> <li>Les utilisateurs autoris\u00e9s peuvent toujours modifier la ressource</li> <li>Les utilisateurs ne peuvent pas supprimer la ressource, m\u00eame s'ils disposent des permissions appropri\u00e9es</li> <li>Cas d'usage id\u00e9al : Bases de donn\u00e9es de production, comptes de stockage critiques, ressources partag\u00e9es</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap11/#verrou-readonly","title":"Verrou ReadOnly","text":"<p>Le verrou ReadOnly emp\u00eache \u00e0 la fois les modifications et la suppression :</p> <ul> <li>La ressource devient effectivement en lecture seule</li> <li>Aucune modification n'est possible, m\u00eame par les administrateurs</li> <li>Cas d'usage id\u00e9al : Configurations compl\u00e8tement stabilis\u00e9es, ressources archiv\u00e9es, ressources de r\u00e9f\u00e9rence</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap11/#hierarchie-des-verrous","title":"Hi\u00e9rarchie des Verrous","text":"<p>Les verrous h\u00e9ritent automatiquement dans la hi\u00e9rarchie de gestion Azure :</p> Text Only<pre><code>Groupe d'administration\n    \u2193 h\u00e9ritage\nAbonnement\n    \u2193 h\u00e9ritage\nGroupe de ressources\n    \u2193 h\u00e9ritage\nRessource individuelle\n</code></pre> <p>Un verrou appliqu\u00e9 \u00e0 un groupe de ressources s'applique automatiquement \u00e0 toutes les ressources du groupe, simplifiant la gestion centralis\u00e9e.</p>"},{"location":"_projects/_formation-azure/azure-chap11/#creation-de-verrous-via-le-portail-azure","title":"Cr\u00e9ation de Verrous via le Portail Azure","text":"<p>\u00c9tapes pour cr\u00e9er un verrou :</p> <ol> <li>Naviguer vers la ressource \u00e0 prot\u00e9ger</li> <li>Dans le menu de gauche, s\u00e9lectionner Verrous (Locks)</li> <li>Cliquer sur Ajouter un verrou (Add)</li> <li>Entrer un nom descriptif pour le verrou</li> <li>S\u00e9lectionner le type : Supprimer (CanNotDelete) ou Lecture seule (ReadOnly)</li> <li>Entrer une note d'explication (optionnel mais recommand\u00e9)</li> <li>Cliquer sur OK</li> </ol>"},{"location":"_projects/_formation-azure/azure-chap11/#exercice-pratique-creer-un-verrou-de-ressource","title":"Exercice Pratique : Cr\u00e9er un Verrou de Ressource","text":""},{"location":"_projects/_formation-azure/azure-chap11/#scenario","title":"Sc\u00e9nario","text":"<p>Une organisation dispose d'une base de donn\u00e9es Azure SQL critique qui contient des donn\u00e9es de production. L'\u00e9quipe souhaite emp\u00eacher les suppressions accidentelles tout en permettant les mises \u00e0 jour et les modifications.</p>"},{"location":"_projects/_formation-azure/azure-chap11/#solution-verrou-cannotdelete-via-powershell","title":"Solution : Verrou CanNotDelete via PowerShell","text":"PowerShell<pre><code># Variables\n$resourceGroupName = \"prod-resources\"\n$dbServerName = \"sql-prod-server\"\n$lockName = \"Protect-Production-DB\"\n\n# Se connecter \u00e0 Azure\nConnect-AzAccount\n\n# Cr\u00e9er un verrou CanNotDelete sur le serveur SQL\nNew-AzManagementLock `\n  -LockName $lockName `\n  -LockLevel CanNotDelete `\n  -ResourceGroupName $resourceGroupName `\n  -ResourceName $dbServerName `\n  -ResourceType \"Microsoft.Sql/servers\" `\n  -Notes \"Verrou de production - Emp\u00eache la suppression du serveur SQL critique\"\n\n# V\u00e9rifier que le verrou a \u00e9t\u00e9 cr\u00e9\u00e9\nGet-AzManagementLock -ResourceGroupName $resourceGroupName\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap11/#solution-via-le-modele-arm-infrastructure-as-code","title":"Solution via le Mod\u00e8le ARM (Infrastructure as Code)","text":"JSON<pre><code>{\n  \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#\",\n  \"contentVersion\": \"1.0.0.0\",\n  \"resources\": [\n    {\n      \"type\": \"Microsoft.Authorization/locks\",\n      \"apiVersion\": \"2017-04-01\",\n      \"name\": \"Protect-Production-DB\",\n      \"scope\": \"[concat('Microsoft.Sql/servers/', parameters('sqlServerName'))]\",\n      \"properties\": {\n        \"level\": \"CanNotDelete\",\n        \"notes\": \"Verrou de protection pour la base de donn\u00e9es de production\"\n      }\n    }\n  ],\n  \"parameters\": {\n    \"sqlServerName\": {\n      \"type\": \"string\",\n      \"metadata\": {\n        \"description\": \"Nom du serveur SQL \u00e0 prot\u00e9ger\"\n      }\n    }\n  }\n}\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap11/#verification-du-verrou","title":"V\u00e9rification du Verrou","text":"<p>Une fois le verrou cr\u00e9\u00e9, tenter de supprimer la ressource g\u00e9n\u00e9rera une erreur :</p> Text Only<pre><code>Message d'erreur : Cette ressource est verrouill\u00e9e et ne peut pas \u00eatre supprim\u00e9e. \nAcc\u00e9dez \u00e0 la lame Verrous pour modifier les param\u00e8tres du verrou.\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap11/#gestion-des-verrous-existants","title":"Gestion des Verrous Existants","text":"<p>Pour modifier ou supprimer un verrou existant :</p> PowerShell<pre><code># Lister tous les verrous d'un groupe de ressources\nGet-AzManagementLock -ResourceGroupName \"prod-resources\"\n\n# Supprimer un verrou sp\u00e9cifique\nRemove-AzManagementLock `\n  -LockName \"Protect-Production-DB\" `\n  -ResourceGroupName \"prod-resources\" `\n  -Force\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap11/#bonnes-pratiques-avec-les-verrous","title":"Bonnes Pratiques avec les Verrous","text":"<ul> <li>Documentation : Toujours ajouter une note explicative au verrou</li> <li>Audience : Informer l'\u00e9quipe des verrous en place pour \u00e9viter la confusion</li> <li>R\u00e9vision R\u00e9guli\u00e8re : Examiner p\u00e9riodiquement les verrous pour identifier ceux qui ne sont plus n\u00e9cessaires</li> <li>Combinaison RBAC : Utiliser les verrous en combination avec RBAC pour une s\u00e9curit\u00e9 multicouche</li> <li>Verrous au Niveau du Groupe de Ressources : Pr\u00e9f\u00e9rer les verrous au niveau du groupe de ressources pour simplifier la gestion</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap11/#introduction-a-microsoft-purview","title":"Introduction \u00e0 Microsoft Purview","text":""},{"location":"_projects/_formation-azure/azure-chap11/#vue-densemble","title":"Vue d'Ensemble","text":"<p>Microsoft Purview est une suite compl\u00e8te de solutions de gouvernance et de conformit\u00e9 des donn\u00e9es qui aide les organisations \u00e0 g\u00e9rer, prot\u00e9ger et gouverner leurs donn\u00e9es dans un environnement multi-cloud et multi-source[8]. Purview s'inscrit dans la strat\u00e9gie plus large de gouvernance Azure en fournissant des capacit\u00e9s sp\u00e9cialis\u00e9es pour la gestion et la protection des donn\u00e9es.</p>"},{"location":"_projects/_formation-azure/azure-chap11/#composantes-principales-de-purview","title":"Composantes Principales de Purview","text":""},{"location":"_projects/_formation-azure/azure-chap11/#purview-data-governance","title":"Purview Data Governance","text":"<p>La gouvernance des donn\u00e9es repr\u00e9sente un ensemble de r\u00e8gles pr\u00e9d\u00e9finies pour g\u00e9rer les flux de donn\u00e9es et aider \u00e0 atteindre les objectifs m\u00e9tier. Les cinq principaux principes de gouvernance des donn\u00e9es sont :</p> <ol> <li>Responsabilit\u00e9 : Clarifier qui est responsable de chaque actif de donn\u00e9es</li> <li>R\u00e9glementations : Respecter les cadres r\u00e9glementaires applicables</li> <li>Administration des donn\u00e9es : G\u00e9rer activement les donn\u00e9es</li> <li>Qualit\u00e9 des donn\u00e9es : Assurer l'int\u00e9grit\u00e9 et la fiabilit\u00e9 des donn\u00e9es</li> <li>Transparence : Maintenir la visibilit\u00e9 sur les donn\u00e9es et leur utilisation[7]</li> </ol>"},{"location":"_projects/_formation-azure/azure-chap11/#purview-compliance-manager","title":"Purview Compliance Manager","text":"<p>Permet de : - \u00c9valuer les risques de conformit\u00e9 - G\u00e9rer les workflows de conformit\u00e9 - Suivre les contr\u00f4les de conformit\u00e9 - G\u00e9n\u00e9rer des rapports de conformit\u00e9</p>"},{"location":"_projects/_formation-azure/azure-chap11/#purview-risk-and-compliance","title":"Purview Risk and Compliance","text":"<p>Fournit des outils pour : - G\u00e9rer les politiques de r\u00e9tention - Impl\u00e9menter la pr\u00e9vention des pertes de donn\u00e9es (DLP) - Configurer les barri\u00e8res informationnelles - G\u00e9rer les archives</p>"},{"location":"_projects/_formation-azure/azure-chap11/#purview-data-lineage","title":"Purview Data Lineage","text":"<p>Offre une visualisation compl\u00e8te de : - L'origine des donn\u00e9es - Les transformations appliqu\u00e9es - Le parcours des donn\u00e9es dans l'organisation - L'impact des modifications</p>"},{"location":"_projects/_formation-azure/azure-chap11/#architecture-de-microsoft-purview","title":"Architecture de Microsoft Purview","text":"Text Only<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         Utilisateurs et Applications                 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          Microsoft Purview Portal                    \u2502\n\u2502    (Interface centralis\u00e9e pour la gouvernance)       \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                   \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502          \u2502          \u2502          \u2502\n    \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2510   \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2510   \u250c\u2500\u2500\u25bc\u2500\u2500\u2500\u2510 \u250c\u2500\u2500\u2500\u25bc\u2500\u2500\u2510\n    \u2502Data  \u2502   \u2502Risk &amp;\u2502   \u2502Compliance\u2502\n    \u2502Gov   \u2502   \u2502Comp  \u2502   \u2502Manager   \u2502\n    \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502          \u2502          \u2502          \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n            Connecteurs aux Sources de Donn\u00e9es\n            (Azure, M365, Databases, Syst\u00e8mes tiers)\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap11/#utilisation-pratique-catalogue-de-donnees","title":"Utilisation Pratique : Catalogue de Donn\u00e9es","text":"<p>Purview maintient un catalogue de donn\u00e9es unifi\u00e9 qui inventorie tous les actifs de donn\u00e9es :</p> Text Only<pre><code>Catalogue Unifi\u00e9\n\u251c\u2500\u2500 Sources Azure\n\u2502   \u251c\u2500\u2500 Azure Data Lake Storage\n\u2502   \u251c\u2500\u2500 Azure SQL Database\n\u2502   \u2514\u2500\u2500 Azure Synapse Analytics\n\u251c\u2500\u2500 Sources M365\n\u2502   \u251c\u2500\u2500 SharePoint Online\n\u2502   \u251c\u2500\u2500 Teams\n\u2502   \u2514\u2500\u2500 Exchange Online\n\u2514\u2500\u2500 Sources Tiers\n    \u251c\u2500\u2500 Base de donn\u00e9es on-premise\n    \u2514\u2500\u2500 Syst\u00e8me ERP externe\n</code></pre> <p>Chaque actif de donn\u00e9es peut \u00eatre : - Catalogu\u00e9 avec des m\u00e9tadonn\u00e9es - Classifi\u00e9 selon le type de donn\u00e9es - Associ\u00e9 \u00e0 des propri\u00e9taires - Li\u00e9 \u00e0 d'autres actifs - Document\u00e9 avec son cycle de vie</p>"},{"location":"_projects/_formation-azure/azure-chap11/#integration-avec-la-gouvernance-azure","title":"Int\u00e9gration avec la Gouvernance Azure","text":"<p>Microsoft Purview compl\u00e8te Azure Policy et les autres outils de gouvernance :</p> Aspect Azure Policy Microsoft Purview Scope Ressources Azure Donn\u00e9es et contenu Focus Configuration et acc\u00e8s Donn\u00e9es et conformit\u00e9 Gestion Politiques techniques Gouvernance m\u00e9tier Donn\u00e9es Limit\u00e9 Complet (multi-source)"},{"location":"_projects/_formation-azure/azure-chap11/#le-portail-dapprobation-de-services","title":"Le Portail d'Approbation de Services","text":""},{"location":"_projects/_formation-azure/azure-chap11/#contexte-et-importance","title":"Contexte et Importance","text":"<p>Le Service Trust Portal (Portail d'approbation de services) est une ressource centrale fournie par Microsoft pour acc\u00e9der aux informations de conformit\u00e9, de s\u00e9curit\u00e9 et de confidentialit\u00e9 relatives aux services cloud Microsoft, y compris Azure[4].</p>"},{"location":"_projects/_formation-azure/azure-chap11/#acces-et-navigation","title":"Acc\u00e8s et Navigation","text":"<p>Le portail est accessible via : <code>https://servicetrust.microsoft.com</code></p>"},{"location":"_projects/_formation-azure/azure-chap11/#sections-principales","title":"Sections Principales","text":""},{"location":"_projects/_formation-azure/azure-chap11/#1-certifications-evaluations-et-rapports","title":"1. Certifications, \u00c9valuations et Rapports","text":"<p>Cette section fournit : - Rapports de conformit\u00e9 : Documents d\u00e9taillant comment Microsoft respecte diff\u00e9rentes normes (ISO 27001, HIPAA, etc.) - Attestations d'audit : R\u00e9sultats d'audits tiers ind\u00e9pendants - Certifications : Preuves formelles de conformit\u00e9 avec les standards internationaux</p>"},{"location":"_projects/_formation-azure/azure-chap11/#2-gestion-de-la-confidentialite-et-de-la-securite","title":"2. Gestion de la Confidentialit\u00e9 et de la S\u00e9curit\u00e9","text":"<ul> <li>Acc\u00e8s aux politiques de confidentialit\u00e9</li> <li>Informations sur la protection des donn\u00e9es</li> <li>Documentation des contr\u00f4les de s\u00e9curit\u00e9</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap11/#3-standards-de-conformite","title":"3. Standards de Conformit\u00e9","text":"<p>Les certifications couvertes incluent :</p> Standard Description Secteurs ISO 27001 Gestion de la s\u00e9curit\u00e9 de l'information G\u00e9n\u00e9ral SOC 2 Contr\u00f4les de s\u00e9curit\u00e9, disponibilit\u00e9, int\u00e9grit\u00e9 Services cloud HIPAA Portabilit\u00e9 et responsabilit\u00e9 de l'assurance maladie Sant\u00e9 GDPR R\u00e8glement sur la protection des donn\u00e9es Europe CCPA Loi californienne sur la confidentialit\u00e9 des consommateurs Californie, USA"},{"location":"_projects/_formation-azure/azure-chap11/#utilisation-pratique","title":"Utilisation Pratique","text":"<p>Sc\u00e9nario : Une organisation stockant des donn\u00e9es HIPAA sur Azure doit v\u00e9rifier que Microsoft respecte les exigences HIPAA.</p> <p>Processus : 1. Acc\u00e9der au Service Trust Portal 2. Naviguer vers \"Certifications, \u00e9valuations et rapports\" 3. Rechercher \"HIPAA\" 4. Consulter le rapport d'audit HIPAA pour Azure 5. V\u00e9rifier que les contr\u00f4les critiques sont couverts 6. Documenter les r\u00e9sultats pour les auditeurs</p>"},{"location":"_projects/_formation-azure/azure-chap11/#integration-dans-la-strategie-de-conformite","title":"Int\u00e9gration dans la Strat\u00e9gie de Conformit\u00e9","text":"<p>Le portail d'approbation sert de fondation de preuve pour les clients Azure :</p> Text Only<pre><code>Exigence de Conformit\u00e9 M\u00e9tier\n        \u2193\nS\u00e9lection d'Azure Policy et Blueprints\n        \u2193\nV\u00e9rification via Service Trust Portal\n        \u2193\nDocumentation pour les Auditeurs\n        \u2193\nCertification de Conformit\u00e9\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap11/#flux-de-mise-en-uvre-complet-chemin-dapprentissage-detaille","title":"Flux de Mise en \u0152uvre Complet : Chemin d'Apprentissage D\u00e9taill\u00e9","text":""},{"location":"_projects/_formation-azure/azure-chap11/#phase-1-fondations-conceptuelles","title":"Phase 1 : Fondations Conceptuelles","text":"<p>Dur\u00e9e estim\u00e9e : 2-3 jours</p> <p>L'apprentissage commence par la compr\u00e9hension des principes fondamentaux. Les concepts de base incluent :</p> <ul> <li>Comprendre pourquoi la gouvernance est essentielle dans un environnement cloud flexible</li> <li>Identifier les risques sans gouvernance : d\u00e9passements budg\u00e9taires, acc\u00e8s non contr\u00f4l\u00e9s, non-conformit\u00e9 r\u00e9glementaire</li> <li>Explorer les objectifs d'une gouvernance effective : s\u00e9curit\u00e9, conformit\u00e9, optimisation des co\u00fbts</li> <li>Examiner les cinq composantes : gestion des acc\u00e8s, suivi de conformit\u00e9, gestion des co\u00fbts, s\u00e9curit\u00e9 et audit</li> </ul> <p>Activit\u00e9s pratiques : - Acc\u00e9der au Service Trust Portal et explorer les certifications Azure disponibles - Examiner un rapport de conformit\u00e9 pertinent pour son domaine - Documenter les exigences r\u00e9glementaires applicables \u00e0 son organisation</p>"},{"location":"_projects/_formation-azure/azure-chap11/#phase-2-maitrise-dazure-policy","title":"Phase 2 : Ma\u00eetrise d'Azure Policy","text":"<p>Dur\u00e9e estim\u00e9e : 3-5 jours</p> <p>Cette phase approfondit les m\u00e9canismes techniques pour impl\u00e9menter la gouvernance.</p> <p>Sujets couverts : - Structure d'une d\u00e9finition de strat\u00e9gie (mode, r\u00e8gles, param\u00e8tres) - Niveaux d'\u00e9tendue et hi\u00e9rarchie (groupe d'administration, abonnement, groupe de ressources) - Assignation de strat\u00e9gies existantes - Cr\u00e9ation de strat\u00e9gies personnalis\u00e9es - D\u00e9ploiement via Azure Blueprints</p> <p>Exemple complet : Politique de Tagging Automatis\u00e9</p> JSON<pre><code>{\n  \"mode\": \"indexed\",\n  \"policyRule\": {\n    \"if\": {\n      \"allOf\": [\n        {\n          \"field\": \"type\",\n          \"in\": [\n            \"Microsoft.Storage/storageAccounts\",\n            \"Microsoft.Sql/servers\",\n            \"Microsoft.Compute/virtualMachines\"\n          ]\n        },\n        {\n          \"field\": \"[concat('tags[', parameters('requiredTag'), ']')]\",\n          \"exists\": \"false\"\n        }\n      ]\n    },\n    \"then\": {\n      \"effect\": \"audit\"\n    }\n  },\n  \"parameters\": {\n    \"requiredTag\": {\n      \"type\": \"string\",\n      \"metadata\": {\n        \"displayName\": \"Balise Requise\",\n        \"description\": \"Le nom de la balise qui doit exister\"\n      },\n      \"defaultValue\": \"CostCenter\"\n    }\n  }\n}\n</code></pre> <p>Activit\u00e9s pratiques : - Cr\u00e9er une strat\u00e9gie pour auditer les ressources sans balises essentielles - Assigner la strat\u00e9gie \u00e0 un groupe de ressources de test - Observer les r\u00e9sultats de conformit\u00e9 dans le portail Azure - Modifier la politique pour utiliser l'effet \"deny\" plut\u00f4t que \"audit\" - G\u00e9rer les exceptions et les exclusions</p>"},{"location":"_projects/_formation-azure/azure-chap11/#phase-3-protection-des-ressources-avec-verrous","title":"Phase 3 : Protection des Ressources avec Verrous","text":"<p>Dur\u00e9e estim\u00e9e : 2-3 jours</p> <p>Cette phase enseigne comment prot\u00e9ger les ressources critiques contre les modifications accidentelles.</p> <p>Sujets couverts : - Types de verrous (CanNotDelete, ReadOnly) - Application \u00e0 diff\u00e9rents niveaux - H\u00e9ritage des verrous dans la hi\u00e9rarchie - Gestion des verrous existants - Combinaison avec RBAC</p> <p>Exercice Progressif :</p> <p>\u00c9tape 1 : Cr\u00e9er un environnement de test PowerShell<pre><code># Cr\u00e9er un groupe de ressources de test\nNew-AzResourceGroup -Name \"test-locks\" -Location \"eastus\"\n\n# Cr\u00e9er un compte de stockage\nNew-AzStorageAccount `\n  -Name \"testlocks$(Get-Random)\" `\n  -ResourceGroupName \"test-locks\" `\n  -Location \"eastus\" `\n  -SkuName \"Standard_LRS\"\n</code></pre></p> <p>\u00c9tape 2 : Appliquer un verrou ReadOnly au groupe de ressources PowerShell<pre><code>$scope = \"/subscriptions/{subscriptionId}/resourceGroups/test-locks\"\n\nNew-AzManagementLock `\n  -LockName \"test-readonly\" `\n  -LockLevel ReadOnly `\n  -Scope $scope `\n  -Notes \"Test du verrou ReadOnly\"\n</code></pre></p> <p>\u00c9tape 3 : Tenter une modification (elle sera bloqu\u00e9e) PowerShell<pre><code># Cette commande \u00e9chouera\nSet-AzStorageAccount `\n  -ResourceGroupName \"test-locks\" `\n  -Name \"testlocks...\" `\n  -EnableHttpsTrafficOnly $true\n</code></pre></p> <p>\u00c9tape 4 : Supprimer le verrou et r\u00e9essayer PowerShell<pre><code>Remove-AzManagementLock -LockName \"test-readonly\" -Scope $scope -Force\n\n# Maintenant la modification r\u00e9ussit\nSet-AzStorageAccount -ResourceGroupName \"test-locks\" -Name \"testlocks...\" -EnableHttpsTrafficOnly $true\n</code></pre></p>"},{"location":"_projects/_formation-azure/azure-chap11/#phase-4-governance-des-donnees-avec-purview","title":"Phase 4 : Governance des Donn\u00e9es avec Purview","text":"<p>Dur\u00e9e estim\u00e9e : 3-4 jours</p> <p>Cette phase \u00e9largit la gouvernance au-del\u00e0 des ressources Azure pour inclure les donn\u00e9es.</p> <p>Sujets couverts : - Architecture de Purview - Principes de gouvernance des donn\u00e9es - Catalogue de donn\u00e9es unifi\u00e9 - Classification et sensibilit\u00e9 - Lineage des donn\u00e9es - Int\u00e9gration multi-source</p> <p>Activit\u00e9s pratiques : - Acc\u00e9der au portail Purview (si disponible dans l'organisation) - Explorer un catalogue de donn\u00e9es existant - Examiner les lignes de donn\u00e9es (data lineage) - Comprendre les classifications appliqu\u00e9es aux donn\u00e9es - Identifier les propri\u00e9taires de donn\u00e9es et les stewards</p>"},{"location":"_projects/_formation-azure/azure-chap11/#phase-5-conformite-et-audit","title":"Phase 5 : Conformit\u00e9 et Audit","text":"<p>Dur\u00e9e estim\u00e9e : 2-3 jours</p> <p>Cette phase finalise l'impl\u00e9mentation en mettant l'accent sur la d\u00e9monstration de conformit\u00e9.</p> <p>Sujets couverts : - Utilisation du Service Trust Portal - Mappage des exigences r\u00e9glementaires aux contr\u00f4les Azure - G\u00e9n\u00e9ration de rapports de conformit\u00e9 - Audit continu - Pr\u00e9paration aux audits externes</p> <p>Exemple de Checklist de Conformit\u00e9 RGPD :</p> Exigence RGPD Contr\u00f4le Azure Statut Consentement des donn\u00e9es Azure Policy pour consentement \u2713 Droit \u00e0 l'oubli Politique de r\u00e9tention En cours Portabilit\u00e9 des donn\u00e9es Export de donn\u00e9es \u00c0 impl\u00e9menter Confidentialit\u00e9 par conception Verrous et RBAC \u2713 Minimisation des donn\u00e9es Politique de suppression En cours"},{"location":"_projects/_formation-azure/azure-chap11/#strategie-dapprentissage-recommandee","title":"Strat\u00e9gie d'Apprentissage Recommand\u00e9e","text":""},{"location":"_projects/_formation-azure/azure-chap11/#semaine-1-fondations","title":"Semaine 1 : Fondations","text":"<ul> <li>Jour 1-2 : Concepts de gouvernance et conformit\u00e9</li> <li>Jour 3-4 : Exploration du Service Trust Portal</li> <li>Jour 5 : Cas d'usage m\u00e9tier et exigences</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap11/#semaine-2-implementation-technique","title":"Semaine 2 : Impl\u00e9mentation Technique","text":"<ul> <li>Jour 1-2 : Azure Policy (cr\u00e9ation et assignation)</li> <li>Jour 3 : Blueprints et standardisation</li> <li>Jour 4-5 : Exercices pratiques d'Azure Policy</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap11/#semaine-3-protection-et-gestion","title":"Semaine 3 : Protection et Gestion","text":"<ul> <li>Jour 1-2 : Verrous de ressources (CanNotDelete, ReadOnly)</li> <li>Jour 3-4 : Exercice complet de cr\u00e9ation et gestion de verrous</li> <li>Jour 5 : Int\u00e9gration Policy + Verrous</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap11/#semaine-4-gouvernance-des-donnees","title":"Semaine 4 : Gouvernance des Donn\u00e9es","text":"<ul> <li>Jour 1-2 : Microsoft Purview (concepts)</li> <li>Jour 3-4 : Catalogue et classification de donn\u00e9es</li> <li>Jour 5 : Conformit\u00e9 et audit complet</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap11/#recapitulatif-des-elements-cles","title":"R\u00e9capitulatif des \u00c9l\u00e9ments Cl\u00e9s","text":""},{"location":"_projects/_formation-azure/azure-chap11/#outils-de-gouvernance-azure","title":"Outils de Gouvernance Azure","text":"Outil Fonction Principale Port\u00e9e Azure Policy Application automatique de r\u00e8gles Toutes les ressources Verrous de Ressources Pr\u00e9vention des modifications/suppressions Niveaux multiples Azure Blueprints D\u00e9ploiement d'environnements standards Cr\u00e9ations initiales Microsoft Purview Gouvernance des donn\u00e9es Donn\u00e9es multi-source Service Trust Portal Information de conformit\u00e9 Certifications cloud"},{"location":"_projects/_formation-azure/azure-chap11/#points-critiques-de-securite","title":"Points Critiques de S\u00e9curit\u00e9","text":"<ol> <li>Couches de d\u00e9fense : Combiner RBAC, Policy, et Verrous</li> <li>Audit continu : Utiliser les journaux pour v\u00e9rifier la conformit\u00e9</li> <li>Documentation : Maintenir des registres clairs des politiques</li> <li>R\u00e9vision r\u00e9guli\u00e8re : Mettre \u00e0 jour les politiques selon les exigences</li> <li>Tests : Valider les politiques dans des environnements de test avant la production</li> </ol> <p>Cette approche compl\u00e8te de la gouvernance et de la conformit\u00e9 avec Azure fournit une base solide pour une gestion efficace, s\u00e9curis\u00e9e et conforme de l'infrastructure cloud[1][2][4][5].</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure/azure-chap12/","title":"Citations","text":"<ul> <li>https://learn.microsoft.com/de-de/azure/cloud-adoption-framework/scenarios/hybrid/arc-enabled-servers/eslz-resource-organization</li> <li>https://learn.microsoft.com/de-de/windows-server/manage/windows-admin-center/azure/manage-arc-hybrid-machines</li> <li>https://learn.microsoft.com/de-de/azure/azure-arc/overview</li> <li>https://learn.microsoft.com/de-de/azure/azure-arc/servers/organize-inventory-servers</li> <li>https://learn.microsoft.com/de-de/training/modules/intro-to-azure-arc/</li> <li>https://learn.microsoft.com/de-de/azure/azure-arc/servers/arc-gateway</li> <li>https://learn.microsoft.com/de-de/azure/azure-arc/</li> <li>https://learn.microsoft.com/de-de/azure/azure-arc/site-manager/how-to-crud-site</li> <li>https://www.youtube.com/watch?v=XAwv7jKiO9Y</li> <li>https://www.youtube.com/watch?v=jNa2hg0UyOQ</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap12/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 254</li> <li>completion_tokens: 7813</li> <li>total_tokens: 8067</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.117, 'request_cost': 0.006, 'total_cost': 0.124}</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap12/#content","title":"Content","text":""},{"location":"_projects/_formation-azure/azure-chap12/#chapitre-12-gestion-et-deploiement-des-ressources-avec-azure","title":"Chapitre 12 : Gestion et d\u00e9ploiement des ressources avec Azure","text":""},{"location":"_projects/_formation-azure/azure-chap12/#introduction-a-azure-arc","title":"Introduction \u00e0 Azure Arc","text":""},{"location":"_projects/_formation-azure/azure-chap12/#presentation-generale-dazure-arc","title":"Pr\u00e9sentation g\u00e9n\u00e9rale d'Azure Arc","text":"<p>Azure Arc repr\u00e9sente une plateforme de gestion hybride et multicloud qui \u00e9tend les capacit\u00e9s d'Azure au-del\u00e0 de ses datacenters. Cette solution permet aux organisations de g\u00e9rer l'int\u00e9gralit\u00e9 de leur environnement informatique de mani\u00e8re centralis\u00e9e, qu'il s'agisse de ressources h\u00e9berg\u00e9es dans Azure, localement, \u00e0 la p\u00e9riph\u00e9rie (Edge) ou dans d'autres clouds publics[3][5].</p> <p>Le concept fondamental d'Azure Arc repose sur la projection des ressources externes dans Azure Resource Manager, cr\u00e9ant ainsi une repr\u00e9sentation unifi\u00e9e de l'infrastructure distribu\u00e9e. Cette approche offre plusieurs avantages strat\u00e9giques :</p> <p>Les principes cl\u00e9s d'Azure Arc :</p> <ul> <li>Extension des services Azure \u00e0 des environnements non-Azure</li> <li>Gouvernance et gestion centralis\u00e9es via le contr\u00f4le d'acc\u00e8s bas\u00e9 sur les r\u00f4les (RBAC)</li> <li>Coh\u00e9rence des op\u00e9rations quel que soit le lieu de d\u00e9ploiement</li> <li>Int\u00e9gration native avec les outils et services Azure existants</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap12/#fonctionnalites-des-serveurs-arc-actives","title":"Fonctionnalit\u00e9s des serveurs Arc-activ\u00e9s","text":"<p>Les serveurs avec Azure Arc-activ\u00e9 constituent le c\u0153ur de la gestion hybride. Ces serveurs conservent leur identit\u00e9 dans leur environnement d'origine tout en b\u00e9n\u00e9ficiant de l'\u00e9cosyst\u00e8me complet d'Azure[3].</p> <p>Les services offerts sans co\u00fbts additionnels incluent :</p> <ul> <li>Organisation des ressources via les groupes de gestion et les balises Azure</li> <li>Recherche et indexation via Azure Resource Graph</li> <li>Acc\u00e8s et s\u00e9curit\u00e9 via le contr\u00f4le RBAC d'Azure</li> <li>Environnements et automatisation via les mod\u00e8les et les extensions</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap12/#architecture-et-deploiement","title":"Architecture et d\u00e9ploiement","text":"<p>La gestion des serveurs Arc-activ\u00e9s s'organise selon une hi\u00e9rarchie d'organisation des ressources Azure compos\u00e9e de quatre niveaux[4] :</p> Niveau hi\u00e9rarchique Description Utilisation Groupes de gestion Niveau sup\u00e9rieur de l'organisation Regrouper plusieurs abonnements selon les crit\u00e8res m\u00e9tier Abonnements Conteneurs de facturation et de gouvernance Isoler les environnements (production, staging, d\u00e9veloppement) Groupes de ressources Conteneurs logiques Regrouper les ressources par application ou unit\u00e9 m\u00e9tier Ressources Entit\u00e9s individuelles Serveurs Arc-activ\u00e9s, machines virtuelles, bases de donn\u00e9es"},{"location":"_projects/_formation-azure/azure-chap12/#strategie-de-ressourcage-et-de-marquage","title":"Strat\u00e9gie de ressour\u00e7age et de marquage","text":"<p>Avant l'int\u00e9gration d'une machine \u00e0 Azure Arc, il est essentiel de d\u00e9finir une structure d'organisation d\u00e9terminant comment ces ressources seront projet\u00e9es dans les domaines de gestion Azure[1].</p> <p>La strat\u00e9gie de marquage (tagging) joue un r\u00f4le crucial dans cette organisation. Les balises permettent d'ajouter des m\u00e9tadonn\u00e9es aux ressources pour les localiser rapidement et automatiser les t\u00e2ches op\u00e9rationnelles. Pour les serveurs Arc-activ\u00e9s, il est recommand\u00e9 d'inclure au minimum :</p> <ul> <li>Balise \"Plateforme d'h\u00e9bergement\" : Identifie o\u00f9 la ressource est h\u00e9berg\u00e9e (Azure, VMware, Hyper-V, AWS, etc.)</li> <li>Balise \"Localisation physique\" : Indique l'emplacement g\u00e9ographique du serveur</li> <li>Balises m\u00e9tier : D\u00e9partement responsable, propri\u00e9taire, environnement (prod/staging/dev)</li> <li>Balises de conformit\u00e9 : Normes applicables, classifications de donn\u00e9es</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap12/#gestion-via-windows-admin-center","title":"Gestion via Windows Admin Center","text":"<p>Windows Admin Center int\u00e8gre une exp\u00e9rience unifi\u00e9e pour la gestion des serveurs Arc-activ\u00e9s directement depuis le portail Azure. Cet outil donne acc\u00e8s \u00e0 des fonctionnalit\u00e9s traditionnelles de gestion serveur[2] :</p> <p>Domaines de gestion disponibles :</p> <ul> <li>Certificats et s\u00e9curit\u00e9</li> <li>Appareils et inventaire</li> <li>\u00c9v\u00e9nements et journaux</li> <li>Partages de fichiers</li> <li>Pare-feu</li> <li>Applications install\u00e9es</li> <li>Utilisateurs et groupes locaux</li> <li>Moniteur de performance</li> <li>PowerShell et ex\u00e9cution de scripts</li> <li>Processus et services</li> <li>Registre</li> <li>Bureau \u00e0 distance</li> <li>R\u00f4les et fonctionnalit\u00e9s</li> <li>T\u00e2ches planifi\u00e9es</li> <li>Services Windows</li> <li>Stockage</li> <li>Mise \u00e0 jour des syst\u00e8mes</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap12/#exemple-de-deploiement-automatise-avec-powershell","title":"Exemple de d\u00e9ploiement automatis\u00e9 avec PowerShell","text":"PowerShell<pre><code># D\u00e9finir les variables de d\u00e9ploiement\n$resourceGroup = \"rg-arc-management\"\n$machineName = \"server-hybrid-01\"\n$location = \"westeurope\"\n$subscription = \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n\n# D\u00e9ployer l'extension Windows Admin Center\nNew-AzConnectedMachineExtension `\n    -Name \"AdminCenter\" `\n    -ResourceGroupName $resourceGroup `\n    -MachineName $machineName `\n    -Location $location `\n    -Publisher \"Microsoft.AdminCenter\" `\n    -ExtensionType \"AdminCenter\" `\n    -SubscriptionId $subscription\n\n# Cr\u00e9er l'endpoint pour la connectivit\u00e9\n$putPayload = \"{'properties': {'type': 'default'}}\"\n\nInvoke-AzRestMethod `\n    -Method PUT `\n    -Uri \"https://management.azure.com/subscriptions/${subscription}/resourceGroups/${resourceGroup}/providers/Microsoft.HybridCompute/machines/${machineName}/providers/Microsoft.HybridConnectivity/endpoints/default?api-version=2023-03-15\" `\n    -Payload $putPayload\n</code></pre> <p>Ce script PowerShell automatise deux \u00e9tapes critiques : le d\u00e9ploiement de l'extension Windows Admin Center sur la ressource Arc-activ\u00e9e et l'\u00e9tablissement d'un endpoint de connectivit\u00e9 permettant la communication bidirectionnelle entre Azure et le serveur[2].</p>"},{"location":"_projects/_formation-azure/azure-chap12/#flux-de-connexion-et-proxy-inverse","title":"Flux de connexion et proxy inverse","text":"<p>Lorsqu'un administrateur clique sur Connecter dans le portail Azure pour acc\u00e9der \u00e0 un serveur Arc-activ\u00e9 via Windows Admin Center, plusieurs \u00e9tapes s'ex\u00e9cutent automatiquement[2] :</p> <p>\u00c9tape 1 - Demande d'authentification : Le portail Azure interroge le fournisseur de ressources Microsoft.HybridConnectivity pour acc\u00e9der au serveur Arc-activ\u00e9.</p> <p>\u00c9tape 2 - \u00c9tablissement du proxy : Le fournisseur de ressources communique avec un proxy de couche 4 utilisant l'indication du nom du serveur (SNI) pour \u00e9tablir un acc\u00e8s temporaire et sp\u00e9cifique \u00e0 la session.</p> <p>\u00c9tape 3 - G\u00e9n\u00e9ration de l'URL : Une URL unique et \u00e9ph\u00e9m\u00e8re est g\u00e9n\u00e9r\u00e9e, et la connexion \u00e0 Windows Admin Center s'\u00e9tablit via le portail Azure, \u00e9liminant le besoin d'exposer les ports directement sur Internet.</p>"},{"location":"_projects/_formation-azure/azure-chap12/#prerequis-et-permissions","title":"Pr\u00e9requis et permissions","text":"<p>L'activation de la gestion Arc requiert des permissions sp\u00e9cifiques pour l'enregistrement des fournisseurs de ressources. L'action <code>/register/action</code> n\u00e9cessite les r\u00f4les Contributeur ou Propri\u00e9taire sur l'abonnement[2].</p> <p>V\u00e9rification du statut du fournisseur de ressources :</p> <ol> <li>Se connecter au portail Azure</li> <li>Naviguer vers Abonnements</li> <li>S\u00e9lectionner l'abonnement cible</li> <li>Acc\u00e9der \u00e0 Fournisseurs de ressources</li> <li>Rechercher Microsoft.HybridConnectivity</li> <li>V\u00e9rifier que le statut affiche Registered</li> <li>Si le statut indique NotRegistered, s\u00e9lectionner le fournisseur et cliquer sur Enregistrer</li> </ol> <p>Cette enregistrement est une t\u00e2che unique par abonnement.</p>"},{"location":"_projects/_formation-azure/azure-chap12/#le-service-azure-resource-manager-arm","title":"Le service Azure Resource Manager (ARM)","text":""},{"location":"_projects/_formation-azure/azure-chap12/#definition-et-role-fondamental","title":"D\u00e9finition et r\u00f4le fondamental","text":"<p>Azure Resource Manager (ARM) constitue le moteur de d\u00e9ploiement et de gestion central de Microsoft Azure. Il s'agit de la couche de gestion qui traite toutes les demandes effectu\u00e9es via le portail Azure, les outils de ligne de commande (Azure CLI, PowerShell) ou les API REST[1].</p> <p>ARM fonctionne selon le principe du contr\u00f4le d'acc\u00e8s bas\u00e9 sur les r\u00f4les (RBAC), permettant une gestion granulaire des permissions et de la gouvernance. Chaque action effectu\u00e9e sur une ressource Azure passe par ARM, qui valide les permissions, applique les strat\u00e9gies, et enfin proc\u00e8de au d\u00e9ploiement ou \u00e0 la modification.</p>"},{"location":"_projects/_formation-azure/azure-chap12/#architecture-hierarchique-de-gestion","title":"Architecture hi\u00e9rarchique de gestion","text":"<p>L'architecture d'ARM s'organise selon quatre niveaux hi\u00e9rarchiques qui offrent une flexibilit\u00e9 maximale pour structurer l'infrastructure[4] :</p> Text Only<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502           Groupes de gestion (Root)                 \u2502\n\u2502  (Niveau sup\u00e9rieur pour les strat\u00e9gies globales)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n        \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n        \u2502                         \u2502\n   \u250c\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510      \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u25bc\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n   \u2502 Abonnement 1  \u2502      \u2502 Abonnement 2   \u2502\n   \u2502 (Prod)        \u2502      \u2502 (Dev/Test)     \u2502\n   \u2514\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n        \u2502                        \u2502\n    \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510    \u250c\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    \u2502          \u2502        \u2502    \u2502          \u2502\n  \u250c\u2500\u25bc\u2500\u2500\u2510   \u250c\u2500\u2500\u25bc\u2500\u2500\u2510  \u250c\u2500\u2500\u25bc\u2500\u2500\u2510 \u250c\u25bc\u2500\u2500\u2510   \u250c\u2500\u2500\u25bc\u2500\u2500\u2510\n  \u2502 RG1\u2502   \u2502 RG2 \u2502  \u2502 RG3 \u2502 \u2502RG4\u2502   \u2502 RG5 \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2518 \u2514\u2500\u2500\u2500\u2518   \u2514\u2500\u2500\u2500\u2500\u2500\u2518\n    \u2502 \u2502     \u2502 \u2502\n  \u250c\u2500\u25bc\u2500\u25bc\u2510  \u250c\u2500\u25bc\u2500\u25bc\u2500\u2500\u2510\n  \u2502Res.\u2502  \u2502Res.  \u2502\n  \u2514\u2500\u2500\u2500\u2500\u2518  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap12/#groupes-de-gestion-management-groups","title":"Groupes de gestion (Management Groups)","text":"<p>Les groupes de gestion constituent le niveau sup\u00e9rieur de l'hi\u00e9rarchie et permettent de g\u00e9rer plusieurs abonnements de fa\u00e7on centralis\u00e9e. Cette structure est particuli\u00e8rement utile pour les organisations de grande taille avec plusieurs unit\u00e9s m\u00e9tier[1][4].</p> <p>Avantages des groupes de gestion :</p> <ul> <li>Application de strat\u00e9gies (policies) \u00e0 l'\u00e9chelle de multiples abonnements</li> <li>Attribution uniforme des r\u00f4les RBAC</li> <li>Conformit\u00e9 centralis\u00e9e</li> <li>Reporting consolid\u00e9</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap12/#abonnements","title":"Abonnements","text":"<p>L'abonnement repr\u00e9sente une unit\u00e9 de facturation et de gouvernance dans Azure. Chaque abonnement isole les ressources, les co\u00fbts et les permissions, permettant une s\u00e9paration claire entre les environnements[1][4].</p> <p>Structure typique d'abonnements :</p> Type d'abonnement Cas d'usage Caract\u00e9ristiques Abonnement Production Ressources en production RBAC restreint, audits r\u00e9guliers Abonnement Staging Tests avant production Acc\u00e8s interm\u00e9diaire Abonnement D\u00e9veloppement D\u00e9veloppement actif Acc\u00e8s large pour les d\u00e9veloppeurs Abonnement Gestion Outils de gestion centralis\u00e9e Acc\u00e8s limit\u00e9 aux administrateurs"},{"location":"_projects/_formation-azure/azure-chap12/#groupes-de-ressources","title":"Groupes de ressources","text":"<p>Le groupe de ressources est un conteneur logique regroupant des ressources li\u00e9es partageant un cycle de vie, une facturation et une gouvernance communs[1][4].</p> <p>Strat\u00e9gies de groupage :</p> <ul> <li>Par application (toutes les ressources d'une application)</li> <li>Par environnement (production, staging, d\u00e9veloppement)</li> <li>Par d\u00e9partement (RH, finance, IT)</li> <li>Par projet (combinaison du type de ressource et du projet)</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap12/#ressources-et-marquage","title":"Ressources et marquage","text":"<p>Les ressources constituent les unit\u00e9s individuelles (serveurs, bases de donn\u00e9es, comptes de stockage, etc.). Le marquage des ressources \u00e0 travers tous les niveaux cr\u00e9e une coh\u00e9rence organisationnelle[1].</p> <p>Exemple de sch\u00e9ma de marquage unifi\u00e9 :</p> JSON<pre><code>{\n  \"tags\": {\n    \"Environnement\": \"Production\",\n    \"Departement\": \"IT\",\n    \"CentreDeCo\u00fbts\": \"CC-2024-001\",\n    \"Proprietaire\": \"jean.dupont@entreprise.fr\",\n    \"Application\": \"CRM-Central\",\n    \"DateCreation\": \"2024-01-15\",\n    \"Conformite\": \"RGPD\",\n    \"SauvegardeRequired\": \"true\",\n    \"MaintenanceWindow\": \"Dimanche 02:00-04:00\"\n  }\n}\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap12/#controle-dacces-base-sur-les-roles-rbac","title":"Contr\u00f4le d'acc\u00e8s bas\u00e9 sur les r\u00f4les (RBAC)","text":"<p>Le RBAC d'Azure permet une gestion fine des permissions. Les r\u00f4les sont assign\u00e9s aux utilisateurs, groupes ou applications de service \u00e0 diff\u00e9rents niveaux de l'hi\u00e9rarchie[2].</p> <p>R\u00f4les de base couramment utilis\u00e9s :</p> R\u00f4le Permissions Utilisation Propri\u00e9taire Contr\u00f4le total Administrateurs principaux Contributeur Gestion des ressources (sans RBAC) Administrateurs de ressources Lecteur Lecture seule Auditeurs, consultants Administrateur des acc\u00e8s utilisateur Gestion RBAC uniquement Administrateurs de gouvernance"},{"location":"_projects/_formation-azure/azure-chap12/#strategies-et-gouvernance","title":"Strat\u00e9gies et gouvernance","text":"<p>ARM int\u00e8gre un syst\u00e8me de strat\u00e9gies (Azure Policies) permettant d'appliquer des r\u00e8gles de conformit\u00e9 et de gouvernance \u00e0 grande \u00e9chelle[1].</p> <p>Exemples de strat\u00e9gies courantes :</p> <ul> <li>Exiger des balises sp\u00e9cifiques sur toutes les ressources</li> <li>Limiter les emplacements de d\u00e9ploiement g\u00e9ographiquement</li> <li>Forcer le chiffrement des donn\u00e9es</li> <li>Imposer des standards de nommage</li> <li>Autoriser uniquement certains types de ressources</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap12/#exemple-de-deploiement-avec-arm","title":"Exemple de d\u00e9ploiement avec ARM","text":"PowerShell<pre><code># Authentification\nConnect-AzAccount\n\n# S\u00e9lectionner l'abonnement\nSelect-AzSubscription -SubscriptionId \"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\n\n# D\u00e9finir les variables\n$resourceGroupName = \"rg-production-web\"\n$location = \"westeurope\"\n$templateFile = \"C:\\templates\\infrastructure.json\"\n$parametersFile = \"C:\\templates\\parameters.json\"\n\n# Cr\u00e9er le groupe de ressources\nNew-AzResourceGroup `\n    -Name $resourceGroupName `\n    -Location $location `\n    -Tag @{ Environnement=\"Production\"; Application=\"Web-Portal\" }\n\n# D\u00e9ployer le mod\u00e8le ARM\nNew-AzResourceGroupDeployment `\n    -ResourceGroupName $resourceGroupName `\n    -TemplateFile $templateFile `\n    -TemplateParameterFile $parametersFile `\n    -Verbose\n</code></pre> <p>Ce script PowerShell ex\u00e9cute une authentification, s\u00e9lectionne l'abonnement, cr\u00e9e un groupe de ressources avec des balises de gouvernance, puis d\u00e9ploie un mod\u00e8le ARM avec des param\u00e8tres externes.</p>"},{"location":"_projects/_formation-azure/azure-chap12/#infrastructure-en-tant-que-code-iac","title":"Infrastructure en tant que code (IaC)","text":""},{"location":"_projects/_formation-azure/azure-chap12/#principes-fondamentaux-de-linfrastructure-en-tant-que-code","title":"Principes fondamentaux de l'Infrastructure en tant que code","text":"<p>L'Infrastructure en tant que code (IaC) repr\u00e9sente une approche r\u00e9volutionnaire o\u00f9 l'ensemble de l'infrastructure informatique est d\u00e9finie et g\u00e9r\u00e9e via du code plut\u00f4t que par des configurations manuelles. Cette approche offre plusieurs avantages strat\u00e9giques et op\u00e9rationnels[1].</p> <p>Avantages cl\u00e9s de l'IaC :</p> <ul> <li>Reproductibilit\u00e9 : D\u00e9ployer l'infrastructure identique plusieurs fois sans variation manuelle</li> <li>Versionning : Suivre les modifications historiques de l'infrastructure</li> <li>Collaboration : Partager et revoir le code d'infrastructure comme du code applicatif</li> <li>Documentation automatique : Le code sert de documentation ex\u00e9cutable</li> <li>Rapidit\u00e9 : D\u00e9ployer en minutes au lieu de jours</li> <li>Coh\u00e9rence : \u00c9liminer la d\u00e9rive de configuration entre environnements</li> <li>Testabilit\u00e9 : Valider l'infrastructure avant le d\u00e9ploiement</li> <li>Disaster recovery : Recr\u00e9er rapidement une infrastructure compl\u00e8te en cas de sinistre</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap12/#approches-declaratives-vs-imperatives","title":"Approches d\u00e9claratives vs imp\u00e9ratives","text":"<p>Azure propose deux approches compl\u00e9mentaires pour impl\u00e9menter l'IaC[1] :</p> <p>Approche d\u00e9clarative (Infrastructure d\u00e9clar\u00e9e) :</p> <p>L'approche d\u00e9clarative sp\u00e9cifie l'\u00e9tat final d\u00e9sir\u00e9 de l'infrastructure sans d\u00e9tailler les \u00e9tapes pour y parvenir. ARM (Azure Resource Manager) et Bicep utilisent cette approche.</p> JSON<pre><code>{\n  \"type\": \"Microsoft.Compute/virtualMachines\",\n  \"apiVersion\": \"2021-07-01\",\n  \"name\": \"vm-production-01\",\n  \"location\": \"westeurope\",\n  \"properties\": {\n    \"hardwareProfile\": {\n      \"vmSize\": \"Standard_D2s_v3\"\n    },\n    \"osProfile\": {\n      \"computerName\": \"vm-prod-01\",\n      \"adminUsername\": \"azureuser\",\n      \"linuxConfiguration\": {\n        \"disablePasswordAuthentication\": true,\n        \"ssh\": {\n          \"publicKeys\": [\n            {\n              \"path\": \"/home/azureuser/.ssh/authorized_keys\",\n              \"keyData\": \"ssh-rsa AAAA...\"\n            }\n          ]\n        }\n      }\n    },\n    \"storageProfile\": {\n      \"imageReference\": {\n        \"publisher\": \"Canonical\",\n        \"offer\": \"UbuntuServer\",\n        \"sku\": \"18.04-LTS\",\n        \"version\": \"latest\"\n      },\n      \"osDisk\": {\n        \"createOption\": \"FromImage\",\n        \"managedDisk\": {\n          \"storageAccountType\": \"Premium_LRS\"\n        }\n      }\n    },\n    \"networkProfile\": {\n      \"networkInterfaces\": [\n        {\n          \"id\": \"/subscriptions/{subscription}/resourceGroups/rg-production/providers/Microsoft.Network/networkInterfaces/nic-vm-prod-01\"\n        }\n      ]\n    }\n  }\n}\n</code></pre> <p>Avantages d\u00e9claratifs : - Idempotent (ex\u00e9cuter plusieurs fois ne pose pas probl\u00e8me) - Facile \u00e0 versionner et \u00e0 revoir - Excellente pour les d\u00e9ploiements reproductibles</p> <p>Approche imp\u00e9rative (Scripting) :</p> <p>L'approche imp\u00e9rative sp\u00e9cifie les \u00e9tapes \u00e0 ex\u00e9cuter pour atteindre l'\u00e9tat d\u00e9sir\u00e9. PowerShell et Azure CLI utilisent cette approche.</p> PowerShell<pre><code># Approche imp\u00e9rative avec PowerShell\n\n# D\u00e9finir les variables\n$resourceGroupName = \"rg-production\"\n$location = \"westeurope\"\n$vmName = \"vm-production-01\"\n$vmSize = \"Standard_D2s_v3\"\n\n# Cr\u00e9er le groupe de ressources\nNew-AzResourceGroup -Name $resourceGroupName -Location $location\n\n# Cr\u00e9er le r\u00e9seau virtuel\n$vnet = New-AzVirtualNetwork `\n    -ResourceGroupName $resourceGroupName `\n    -Name \"vnet-prod\" `\n    -AddressPrefix \"10.0.0.0/16\" `\n    -Location $location\n\n# Cr\u00e9er le sous-r\u00e9seau\n$subnet = Add-AzVirtualNetworkSubnetConfig `\n    -Name \"subnet-prod\" `\n    -AddressPrefix \"10.0.1.0/24\" `\n    -VirtualNetwork $vnet\n\n# Ajouter la configuration et mettre \u00e0 jour\n$vnet | Set-AzVirtualNetwork\n\n# Cr\u00e9er la carte r\u00e9seau\n$nic = New-AzNetworkInterface `\n    -ResourceGroupName $resourceGroupName `\n    -Name \"nic-vm-prod-01\" `\n    -SubnetId $subnet.Id `\n    -Location $location\n\n# Configurer la machine virtuelle\n$vmConfig = New-AzVMConfig `\n    -VMName $vmName `\n    -VMSize $vmSize\n\n# Ajouter la carte r\u00e9seau \u00e0 la configuration\n$vmConfig = Add-AzVMNetworkInterface `\n    -VM $vmConfig `\n    -Id $nic.Id\n\n# Ajouter l'image de syst\u00e8me d'exploitation\n$vmConfig = Set-AzVMSourceImage `\n    -VM $vmConfig `\n    -PublisherName \"Canonical\" `\n    -Offer \"UbuntuServer\" `\n    -Skus \"18.04-LTS\" `\n    -Version \"latest\"\n\n# Cr\u00e9er la machine virtuelle\nNew-AzVM `\n    -ResourceGroupName $resourceGroupName `\n    -VM $vmConfig\n</code></pre> <p>Avantages imp\u00e9ratifs : - Flexibilit\u00e9 maximale - Utile pour des t\u00e2ches tr\u00e8s sp\u00e9cifiques - Bon pour les migrations et conversions</p>"},{"location":"_projects/_formation-azure/azure-chap12/#modeles-azure-resource-manager-arm","title":"Mod\u00e8les Azure Resource Manager (ARM)","text":"<p>Les mod\u00e8les ARM constituent le format d\u00e9claratif natif d'Azure. Un mod\u00e8le ARM est un fichier JSON d\u00e9finissant l'infrastructure compl\u00e8te et pouvant \u00eatre d\u00e9ploy\u00e9 de mani\u00e8re reproductible[1].</p> <p>Structure d'un mod\u00e8le ARM :</p> JSON<pre><code>{\n  \"$schema\": \"https://schema.management.azure.com/schemas/2021-09-01/deploymentTemplate.json#\",\n  \"contentVersion\": \"1.0.0.0\",\n  \"metadata\": {\n    \"description\": \"Mod\u00e8le de d\u00e9ploiement d'infrastructure de base\"\n  },\n  \"parameters\": {\n    \"environnement\": {\n      \"type\": \"string\",\n      \"defaultValue\": \"dev\",\n      \"allowedValues\": [\"dev\", \"staging\", \"prod\"],\n      \"metadata\": {\n        \"description\": \"Environnement de d\u00e9ploiement\"\n      }\n    },\n    \"emplacementRessources\": {\n      \"type\": \"string\",\n      \"defaultValue\": \"westeurope\",\n      \"metadata\": {\n        \"description\": \"R\u00e9gion Azure pour les ressources\"\n      }\n    }\n  },\n  \"variables\": {\n    \"nommageRessource\": \"[concat('app-', parameters('environnement'), '-')]\",\n    \"balise_environnement\": \"[parameters('environnement')]\"\n  },\n  \"resources\": [\n    {\n      \"type\": \"Microsoft.Storage/storageAccounts\",\n      \"apiVersion\": \"2021-06-01\",\n      \"name\": \"[concat(variables('nommageRessource'), 'storage')]\",\n      \"location\": \"[parameters('emplacementRessources')]\",\n      \"sku\": {\n        \"name\": \"Standard_LRS\"\n      },\n      \"kind\": \"StorageV2\",\n      \"properties\": {\n        \"accessTier\": \"Hot\"\n      },\n      \"tags\": {\n        \"Environnement\": \"[variables('balise_environnement')]\"\n      }\n    },\n    {\n      \"type\": \"Microsoft.Network/virtualNetworks\",\n      \"apiVersion\": \"2021-02-01\",\n      \"name\": \"[concat(variables('nommageRessource'), 'vnet')]\",\n      \"location\": \"[parameters('emplacementRessources')]\",\n      \"properties\": {\n        \"addressSpace\": {\n          \"addressPrefixes\": [\"10.0.0.0/16\"]\n        },\n        \"subnets\": [\n          {\n            \"name\": \"default\",\n            \"properties\": {\n              \"addressPrefix\": \"10.0.0.0/24\"\n            }\n          }\n        ]\n      }\n    }\n  ],\n  \"outputs\": {\n    \"storageAccountId\": {\n      \"type\": \"string\",\n      \"value\": \"[resourceId('Microsoft.Storage/storageAccounts', concat(variables('nommageRessource'), 'storage'))]\"\n    }\n  }\n}\n</code></pre> <p>Sections cl\u00e9s du mod\u00e8le ARM :</p> Section Description Exemple schema Version du sch\u00e9ma JSON <code>https://schema.management.azure.com/schemas/2021-09-01/deploymentTemplate.json#</code> parameters Variables d'entr\u00e9e <code>environnement</code>, <code>location</code>, <code>vmSize</code> variables Valeurs calcul\u00e9es Noms g\u00e9n\u00e9r\u00e9s, concat\u00e9nations resources D\u00e9finitions des ressources Machines virtuelles, r\u00e9seaux, stockage outputs Valeurs retourn\u00e9es IDs de ressources, connexions"},{"location":"_projects/_formation-azure/azure-chap12/#fichiers-de-parametres","title":"Fichiers de param\u00e8tres","text":"<p>Les fichiers de param\u00e8tres offrent une s\u00e9paration entre le mod\u00e8le (logique) et les valeurs (donn\u00e9es). Cette approche permet de r\u00e9utiliser le m\u00eame mod\u00e8le pour plusieurs environnements[1].</p> <p>Exemple de fichier de param\u00e8tres pour la production :</p> JSON<pre><code>{\n  \"$schema\": \"https://schema.management.azure.com/schemas/2021-09-01/deploymentParameters.json#\",\n  \"contentVersion\": \"1.0.0.0\",\n  \"parameters\": {\n    \"environnement\": {\n      \"value\": \"prod\"\n    },\n    \"emplacementRessources\": {\n      \"value\": \"westeurope\"\n    },\n    \"vmSize\": {\n      \"value\": \"Standard_D4s_v3\"\n    },\n    \"replicationEnabled\": {\n      \"value\": true\n    }\n  }\n}\n</code></pre> <p>Exemple de fichier de param\u00e8tres pour le d\u00e9veloppement :</p> JSON<pre><code>{\n  \"$schema\": \"https://schema.management.azure.com/schemas/2021-09-01/deploymentParameters.json#\",\n  \"contentVersion\": \"1.0.0.0\",\n  \"parameters\": {\n    \"environnement\": {\n      \"value\": \"dev\"\n    },\n    \"emplacementRessources\": {\n      \"value\": \"westeurope\"\n    },\n    \"vmSize\": {\n      \"value\": \"Standard_B2s\"\n    },\n    \"replicationEnabled\": {\n      \"value\": false\n    }\n  }\n}\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap12/#bicep-langage-dinfrastructure-en-tant-que-code","title":"Bicep : Langage d'Infrastructure en tant que Code","text":"<p>Bicep est un langage d\u00e9claratif d\u00e9velopp\u00e9 par Microsoft pour simplifier la cr\u00e9ation de mod\u00e8les ARM. Il offre une syntaxe plus lisible et maintenable que JSON[1].</p> <p>Exemple de fichier Bicep :</p> Text Only<pre><code>metadata description = 'D\u00e9ploiement d\\'infrastructure multi-environnement'\n\n@minLength(3)\n@maxLength(10)\nparam environnement string = 'dev'\n\n@allowed([\n  'westeurope'\n  'eastus'\n  'southeastasia'\n])\nparam location string = 'westeurope'\n\n@minValue(1)\n@maxValue(32)\nparam instanceCount int = 2\n\nvar nommageBase = 'app-${environnement}-'\nvar baliseEnvironnement = {\n  Environnement: environnement\n  DateCreation: utcNow('u')\n}\n\nresource storageAccount 'Microsoft.Storage/storageAccounts@2021-06-01' = {\n  name: '${nommageBase}storage'\n  location: location\n  tags: baliseEnvironnement\n  sku: {\n    name: 'Standard_LRS'\n  }\n  kind: 'StorageV2'\n  properties: {\n    accessTier: 'Hot'\n  }\n}\n\nresource vnet 'Microsoft.Network/virtualNetworks@2021-02-01' = {\n  name: '${nommageBase}vnet'\n  location: location\n  tags: baliseEnvironnement\n  properties: {\n    addressSpace: {\n      addressPrefixes: [\n        '10.0.0.0/16'\n      ]\n    }\n    subnets: [\n      {\n        name: 'frontend'\n        properties: {\n          addressPrefix: '10.0.1.0/24'\n        }\n      }\n      {\n        name: 'backend'\n        properties: {\n          addressPrefix: '10.0.2.0/24'\n        }\n      }\n    ]\n  }\n}\n\n@export()\noutput storageEndpoint string = storageAccount.properties.primaryEndpoints.blob\noutput vnetId string = vnet.id\n</code></pre> <p>Avantages de Bicep :</p> <ul> <li>Syntaxe plus lisible et concise</li> <li>Meilleure gestion des erreurs \u00e0 la compilation</li> <li>Support natif des boucles et conditionnels</li> <li>Commentaires plus intuitifs</li> <li>Pas besoin de g\u00e9rer manuellement les d\u00e9pendances</li> <li>Compilation automatique en mod\u00e8les ARM</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap12/#deploiement-dinfrastructure-en-tant-que-code","title":"D\u00e9ploiement d'Infrastructure en tant que Code","text":"<p>Le d\u00e9ploiement d'IaC suit un processus structur\u00e9 garantissant fiabilit\u00e9 et tra\u00e7abilit\u00e9[1].</p> <p>Workflow complet de d\u00e9ploiement IaC :</p> Text Only<pre><code>1. D\u00e9veloppement\n   \u251c\u2500 Cr\u00e9er/modifier le mod\u00e8le (ARM ou Bicep)\n   \u251c\u2500 Cr\u00e9er les fichiers de param\u00e8tres\n   \u2514\u2500 Valider la syntaxe\n\n2. Contr\u00f4le de source\n   \u251c\u2500 Commiter le code dans Git\n   \u251c\u2500 Effectuer une revue de code\n   \u2514\u2500 Fusionner dans la branche de d\u00e9ploiement\n\n3. Validation\n   \u251c\u2500 Ex\u00e9cuter la validation du mod\u00e8le\n   \u251c\u2500 V\u00e9rifier la compatibilit\u00e9 des ressources\n   \u2514\u2500 Estimer les co\u00fbts\n\n4. D\u00e9ploiement\n   \u251c\u2500 Cr\u00e9er le groupe de ressources (si n\u00e9cessaire)\n   \u251c\u2500 D\u00e9ployer le mod\u00e8le\n   \u251c\u2500 Attendre la compl\u00e9tion\n   \u2514\u2500 V\u00e9rifier les sorties\n\n5. Post-d\u00e9ploiement\n   \u251c\u2500 Valider que les ressources fonctionnent\n   \u251c\u2500 Documenter les modifications\n   \u2514\u2500 Archiver les param\u00e8tres utilis\u00e9s\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap12/#exemple-de-deploiement-complet","title":"Exemple de d\u00e9ploiement complet","text":"Bash<pre><code>#!/bin/bash\n\n# Variables\nSUBSCRIPTION_ID=\"xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx\"\nRESOURCE_GROUP=\"rg-production\"\nLOCATION=\"westeurope\"\nTEMPLATE_FILE=\"./templates/infrastructure.bicep\"\nPARAMETERS_FILE=\"./parameters/prod.json\"\nDEPLOYMENT_NAME=\"deployment-$(date +%Y%m%d-%H%M%S)\"\n\n# Authentification \u00e0 Azure\necho \"Authentification \u00e0 Azure...\"\naz login\n\n# S\u00e9lectionner l'abonnement\necho \"S\u00e9lection de l'abonnement...\"\naz account set --subscription \"$SUBSCRIPTION_ID\"\n\n# Cr\u00e9er le groupe de ressources\necho \"Cr\u00e9ation du groupe de ressources...\"\naz group create \\\n    --name \"$RESOURCE_GROUP\" \\\n    --location \"$LOCATION\" \\\n    --tags Environnement=Production Application=WebPortal\n\n# Valider le mod\u00e8le\necho \"Validation du mod\u00e8le...\"\naz deployment group validate \\\n    --resource-group \"$RESOURCE_GROUP\" \\\n    --template-file \"$TEMPLATE_FILE\" \\\n    --parameters \"$PARAMETERS_FILE\"\n\nif [ $? -eq 0 ]; then\n    echo \"Validation r\u00e9ussie. D\u00e9ploiement en cours...\"\n\n    # D\u00e9ployer le mod\u00e8le\n    az deployment group create \\\n        --name \"$DEPLOYMENT_NAME\" \\\n        --resource-group \"$RESOURCE_GROUP\" \\\n        --template-file \"$TEMPLATE_FILE\" \\\n        --parameters \"$PARAMETERS_FILE\" \\\n        --output json &gt; deployment_output.json\n\n    # Afficher les sorties\n    echo \"Ressources d\u00e9ploy\u00e9es avec succ\u00e8s.\"\n    az deployment group show \\\n        --name \"$DEPLOYMENT_NAME\" \\\n        --resource-group \"$RESOURCE_GROUP\" \\\n        --query properties.outputs\nelse\n    echo \"La validation a \u00e9chou\u00e9. V\u00e9rifiez le mod\u00e8le.\"\n    exit 1\nfi\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap12/#gestion-detat-et-integrite","title":"Gestion d'\u00e9tat et int\u00e9grit\u00e9","text":"<p>Azure Resource Manager maintient automatiquement l'\u00e9tat du d\u00e9ploiement et peut d\u00e9tecter les \u00e9carts de configuration[1].</p> <p>\u00c9tats de d\u00e9ploiement :</p> \u00c9tat Description Action requise Succeeded D\u00e9ploiement compl\u00e9t\u00e9 Aucune - v\u00e9rifier les ressources Failed Erreur lors du d\u00e9ploiement Analyser les logs, corriger et red\u00e9ployer Updating Mise \u00e0 jour en cours Attendre la compl\u00e9tion Deleting Suppression en cours Attendre la compl\u00e9tion"},{"location":"_projects/_formation-azure/azure-chap12/#bonnes-pratiques-pour-linfrastructure-en-tant-que-code","title":"Bonnes pratiques pour l'Infrastructure en tant que Code","text":"<p>L'adoption r\u00e9ussie de l'IaC n\u00e9cessite le respect de bonnes pratiques \u00e9prouv\u00e9es[1] :</p> <p>Nommage et organisation : - Utiliser des conventions de nommage coh\u00e9rentes - Organiser les mod\u00e8les par domaine fonctionnel - S\u00e9parer les mod\u00e8les r\u00e9utilisables des mod\u00e8les sp\u00e9cifiques</p> <p>Param\u00e9trage et flexibilit\u00e9 : - Externaliser tous les param\u00e8tres variables - Utiliser des fichiers de param\u00e8tres diff\u00e9rents par environnement - Documenter tous les param\u00e8tres requis</p> <p>S\u00e9curit\u00e9 : - Jamais stocker de secrets en clair dans les mod\u00e8les - Utiliser Azure Key Vault pour les valeurs sensibles - Impl\u00e9menter le RBAC au niveau des d\u00e9ploiements</p> <p>Versioning et collaboration : - Stocker tous les mod\u00e8les dans Git - Impl\u00e9menter des processus de revue de code - Taguer les versions stables</p> <p>Documentation : - Ajouter des m\u00e9tadonn\u00e9es descriptives - Documenter les d\u00e9pendances entre ressources - Expliquer les choix architecturaux</p> <p>Tests et validation : - Valider les mod\u00e8les avant le d\u00e9ploiement - Tester les d\u00e9ploiements dans des environnements de non-production - Automatiser les tests avec des pipelines CI/CD</p>"},{"location":"_projects/_formation-azure/azure-chap12/#recapitulatif-et-chemins-dapprentissage","title":"R\u00e9capitulatif et chemins d'apprentissage","text":""},{"location":"_projects/_formation-azure/azure-chap12/#progression-dapprentissage-recommandee","title":"Progression d'apprentissage recommand\u00e9e","text":"<p>Phase 1 : Fondamentaux (Semaine 1-2) - Comprendre l'architecture d'Azure et les concepts de base - Ma\u00eetriser la structure des groupes de gestion, abonnements et groupes de ressources - Apprendre les principes du RBAC et des balises</p> <p>Phase 2 : Azure Arc (Semaine 3-4) - D\u00e9ployer et configurer des serveurs Arc-activ\u00e9s - Mettre en place une strat\u00e9gie de marquage coh\u00e9rente - G\u00e9rer les serveurs via Windows Admin Center</p> <p>Phase 3 : Azure Resource Manager (Semaine 5-6) - Approfondir la hi\u00e9rarchie d'ARM - Mettre en place les strat\u00e9gies et la gouvernance - Automatiser les t\u00e2ches courantes avec PowerShell</p> <p>Phase 4 : Infrastructure en tant que Code (Semaine 7-8) - Apprendre la syntaxe des mod\u00e8les ARM - D\u00e9couvrir Bicep et ses avantages - D\u00e9ployer des infrastructures compl\u00e8tes via IaC</p> <p>Phase 5 : Int\u00e9gration et bonnes pratiques (Semaine 9-10) - Int\u00e9grer IaC dans un processus CI/CD - Impl\u00e9menter les bonnes pratiques de s\u00e9curit\u00e9 et de gouvernance - Migrer une infrastructure existante vers l'IaC</p> <p>Cette progression cr\u00e9e une base solide avant d'avancer vers des architectures plus complexes et des cas d'usage enterprise.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure/azure-chap13/","title":"Citations","text":"<ul> <li>https://azure.microsoft.com/fr-fr/products/advisor</li> <li>https://learn.microsoft.com/fr-fr/azure/advisor/advisor-overview</li> <li>https://hichamkadiri.wordpress.com/2019/02/12/azure-governance-toolbox-azure-advisor-introduction-howto/</li> <li>https://vignon.cloud/2023/08/04/howtocomment-optimiser-vos-performances-votre-rentabilite-et-bien-plus-encore-avec-azure-advisor/</li> <li>https://learn.microsoft.com/fr-fr/azure/advisor/advisor-get-started</li> <li>https://learn.microsoft.com/fr-fr/shows/azure/azure-advisor-your-personalized-guide-to-optimal-resource-configuration</li> <li>https://learn.microsoft.com/fr-fr/azure/cost-management-billing/costs/tutorial-acm-opt-recommendations</li> <li>https://www.youtube.com/watch?v=RJVSNsC8Sks</li> <li>https://learn.microsoft.com/fr-fr/shows/azure-friday/azure-advisor--your-free-personalized-guide-to-azure-best-practices</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap13/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 229</li> <li>completion_tokens: 5299</li> <li>total_tokens: 5528</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.079, 'request_cost': 0.006, 'total_cost': 0.086}</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap13/#content","title":"Content","text":""},{"location":"_projects/_formation-azure/azure-chap13/#chapitre-13-monitoring-dans-azure","title":"Chapitre 13 : Monitoring dans Azure","text":""},{"location":"_projects/_formation-azure/azure-chap13/#introduction-a-advisor","title":"Introduction \u00e0 Advisor","text":""},{"location":"_projects/_formation-azure/azure-chap13/#presentation-generale-dazure-advisor","title":"Pr\u00e9sentation g\u00e9n\u00e9rale d'Azure Advisor","text":"<p>Azure Advisor est un assistant cloud num\u00e9rique qui fonctionne de mani\u00e8re autonome pour analyser les configurations et l'utilisation des ressources Azure d\u00e9ploy\u00e9es[1][2]. Son r\u00f4le principal consiste \u00e0 examiner la t\u00e9l\u00e9m\u00e9trie de configuration et d'utilisation, puis formuler des recommandations personnalis\u00e9es destin\u00e9es \u00e0 optimiser les d\u00e9ploiements cloud selon les meilleures pratiques Azure.</p> <p>Le service op\u00e8re en arri\u00e8re-plan de mani\u00e8re continue, effectuant des analyses approfondies sur l'ensemble des ressources. Il est important de noter que pour les ressources nouvellement cr\u00e9\u00e9es, l'obtention des recommandations peut prendre jusqu'\u00e0 24 heures[5].</p>"},{"location":"_projects/_formation-azure/azure-chap13/#objectifs-strategiques-dazure-advisor","title":"Objectifs strat\u00e9giques d'Azure Advisor","text":"<p>Azure Advisor poursuit plusieurs objectifs fondamentaux dans la gestion d'une infrastructure cloud :</p> <p>Am\u00e9lioration de la rentabilit\u00e9 : Le service identifie les ressources sous-utilis\u00e9es, inactives ou surdimensionn\u00e9es qui consomment des ressources inutilement[2][7]. Par exemple, une machine virtuelle configur\u00e9e pour un environnement de production mais tournant \u00e0 seulement 5% de sa capacit\u00e9 sera identifi\u00e9e comme candidate \u00e0 une r\u00e9duction de taille.</p> <p>Optimisation des performances : Azure Advisor analyse en profondeur les goulots d'\u00e9tranglement potentiels et les configurations incorrectes qui impactent la vitesse d'ex\u00e9cution des applications[4]. Cela inclut l'identification de mauvaises configurations de mise en cache, de probl\u00e8mes de configuration r\u00e9seau ou de ressources insuffisantes.</p> <p>Renforcement de la s\u00e9curit\u00e9 : Les recommandations de s\u00e9curit\u00e9 proviennent d'Azure Security Center (d\u00e9sormais Microsoft Defender pour le cloud)[3], permettant de d\u00e9tecter les menaces et vuln\u00e9rabilit\u00e9s qui pourraient conduire \u00e0 des failles de s\u00e9curit\u00e9.</p> <p>Augmentation de la fiabilit\u00e9 : Le service aide \u00e0 identifier les opportunit\u00e9s d'am\u00e9lioration de la haute disponibilit\u00e9 des services critiques en recommendant des configurations de redondance appropri\u00e9es.</p> <p>Excellence op\u00e9rationnelle : Advisor fournit des conseils pour am\u00e9liorer les pratiques de gestion et de gouvernance Azure globale[1].</p>"},{"location":"_projects/_formation-azure/azure-chap13/#architecture-et-fonctionnement-interne","title":"Architecture et fonctionnement interne","text":"<p>Azure Advisor fonctionne selon un mod\u00e8le d'analyse multicouche qui combine plusieurs sources de donn\u00e9es :</p> <ul> <li>T\u00e9l\u00e9m\u00e9trie de configuration : Analyse de la configuration actuelle de chaque ressource</li> <li>Donn\u00e9es d'utilisation : Monitoring des performances et de l'utilisation r\u00e9elle</li> <li>Donn\u00e9es de facturation : Collect\u00e9es depuis le portail Azure Enterprise et Cost Management</li> <li>Recommandations d'outils partenaires : Int\u00e9gration avec Microsoft Defender pour le cloud et Azure Cost Management[4]</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap13/#acces-et-interfaces-dadvisor","title":"Acc\u00e8s et interfaces d'Advisor","text":"<p>Azure Advisor est accessible selon plusieurs modalit\u00e9s pour s'adapter aux pr\u00e9f\u00e9rences et besoins des administrateurs :</p> <p>Portail Azure : L'interface graphique principale accessible en recherchant \u00ab Advisor \u00bb dans le panneau de navigation[2][5]. Cette interface offre une vue compl\u00e8te avec des tableaux de bord visuels et des filtres avanc\u00e9s.</p> <p>Interface de ligne de commande (CLI) : Pour les utilisateurs pr\u00e9f\u00e9rant l'automatisation et les scripts[1].</p> <p>API REST Advisor : Pour l'int\u00e9gration programm\u00e9e dans des solutions personnalis\u00e9es[1].</p> <p>PowerShell : Alternative scripting pour la gestion automatis\u00e9e[1].</p> <p>Les droits d'acc\u00e8s sont bas\u00e9s sur les r\u00f4les Azure, n\u00e9cessitant au minimum le r\u00f4le de lecteur sur un abonnement pour consulter les recommandations[1].</p>"},{"location":"_projects/_formation-azure/azure-chap13/#categories-de-recommandations","title":"Cat\u00e9gories de recommandations","text":"<p>Azure Advisor organise ses recommandations en cinq cat\u00e9gories distinctes :</p> Cat\u00e9gorie Objectif Exemples de recommandations Fiabilit\u00e9 Augmenter la disponibilit\u00e9 des services critiques Configurations de haute disponibilit\u00e9, points de d\u00e9faillance uniques S\u00e9curit\u00e9 D\u00e9tecter menaces et vuln\u00e9rabilit\u00e9s Acc\u00e8s non s\u00e9curis\u00e9, configurations de pare-feu, gestion des secrets Performance Optimiser la vitesse et l'efficacit\u00e9 Mise \u00e0 l'\u00e9chelle inappropri\u00e9e, configurations de cache, optimisation de base de donn\u00e9es Co\u00fbt R\u00e9duire les d\u00e9penses Azure Ressources inactives, VM sous-utilis\u00e9es, r\u00e9servations non optimales Excellence op\u00e9rationnelle Am\u00e9liorer les pratiques de gestion Meilleures pratiques, gouvernance, conformit\u00e9 <p>Advisor contient plus de 100 recommandations diff\u00e9rentes, et Microsoft en ajoute continuellement de nouvelles[4].</p>"},{"location":"_projects/_formation-azure/azure-chap13/#services-supportes-par-azure-advisor","title":"Services support\u00e9s par Azure Advisor","text":"<p>Azure Advisor fournit des recommandations pour une large gamme de services Azure[2] :</p> <ul> <li>Gestion des API Azure</li> <li>Azure Application Gateway</li> <li>Azure App Service</li> <li>Groupes \u00e0 haute disponibilit\u00e9</li> <li>Cache Azure</li> <li>Azure Database pour MySQL et PostgreSQL</li> <li>Azure FarmBeats</li> <li>Adresses IP publiques Azure</li> <li>Azure Synapse Analytics</li> <li>Log Analytics</li> <li>Azure Cache pour serveur Redis</li> <li>SQL Server</li> <li>Compte Stockage Azure</li> <li>Profil Azure Traffic Manager</li> <li>Machines virtuelles Azure</li> <li>Groupes de machines virtuelles identiques (VMSS)</li> <li>Passerelle de r\u00e9seau virtuel Azure</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap13/#fonctionnalites-avancees-de-recommandation","title":"Fonctionnalit\u00e9s avanc\u00e9es de recommandation","text":"<p>Recommandations prioritaires : Les suggestions sont class\u00e9es par ordre de priorit\u00e9 en fonction de l'estimation de leur importance pour chaque environnement sp\u00e9cifique[1].</p> <p>Azure Advisor Quick Fix : Cette fonctionnalit\u00e9 permet de corriger simultan\u00e9ment les recommandations pour plusieurs ressources en seulement quelques clics, facilitant et acc\u00e9l\u00e9rant l'optimisation \u00e0 grande \u00e9chelle[1].</p> <p>Actions propos\u00e9es : Chaque recommandation inclut des propositions d'actions int\u00e9gr\u00e9es permettant d'impl\u00e9menter directement la rem\u00e9diation[3].</p>"},{"location":"_projects/_formation-azure/azure-chap13/#personnalisation-et-configuration","title":"Personnalisation et configuration","text":"<p>Advisor offre une flexibilit\u00e9 importante pour adapter les recommandations aux contextes sp\u00e9cifiques :</p> <p>Ciblage par abonnement : Configuration d'Advisor pour afficher les recommandations uniquement pour des abonnements sp\u00e9cifiques[1].</p> <p>Ciblage par groupe de ressources : Possibilit\u00e9 de concentrer l'attention sur des groupes de ressources particuliers[1].</p> <p>Exclusion de ressources : Possibility d'exclure les ressources de test ou certains environnements des recommandations[5].</p> <p>Alertes automatiques : Configuration d'alertes pour \u00eatre notifi\u00e9 automatiquement des nouvelles recommandations[1].</p> <p>Filtrage des \u00e9tats : Gestion des recommandations selon leur \u00e9tat (Active, Report\u00e9e, Ignor\u00e9e)[5].</p>"},{"location":"_projects/_formation-azure/azure-chap13/#suivi-et-amelioration-continue","title":"Suivi et am\u00e9lioration continue","text":"<p>Azure Advisor fournit des tableaux de bord et des rapports d\u00e9taill\u00e9s permettant de suivre l'\u00e9volution des recommandations dans le temps[4]. Le syst\u00e8me envoie des notifications proactives alertant des probl\u00e8mes potentiels et des nouvelles recommandations bas\u00e9es sur les \u00e9volutions de l'environnement Azure[4]. Ces fonctionnalit\u00e9s permettent une d\u00e9marche d'am\u00e9lioration continue plut\u00f4t que ponctuelle.</p>"},{"location":"_projects/_formation-azure/azure-chap13/#azure-service-health","title":"Azure Service Health","text":""},{"location":"_projects/_formation-azure/azure-chap13/#definition-et-role-strategique","title":"D\u00e9finition et r\u00f4le strat\u00e9gique","text":"<p>Azure Service Health est un service de monitoring essentiel qui fournit une visibilit\u00e9 compl\u00e8te sur l'\u00e9tat de sant\u00e9 des services Azure et l'impact potentiel sur les ressources d\u00e9ploy\u00e9es. Contrairement \u00e0 Azure Advisor qui recommande des optimisations, Azure Service Health informe sur l'\u00e9tat r\u00e9el et la disponibilit\u00e9 des services de la plateforme Azure.</p> <p>Le service joue un r\u00f4le critique dans la planification de la continuit\u00e9 d'activit\u00e9 et la gestion des incidents, permettant aux administrateurs de rester inform\u00e9s des probl\u00e8mes affectant ou pouvant affecter leurs services.</p>"},{"location":"_projects/_formation-azure/azure-chap13/#composantes-principales-dazure-service-health","title":"Composantes principales d'Azure Service Health","text":"<p>Azure Service Health se structure autour de trois composantes principales, chacune adressant un type d'information sp\u00e9cifique sur l'infrastructure Azure :</p> <p>Azure Status : Cette composante affiche l'\u00e9tat global des services Azure dans toutes les r\u00e9gions du monde. Elle fournit une vision macroscopique de la sant\u00e9 de la plateforme sans \u00eatre sp\u00e9cifique aux ressources d'un client particulier. Consultable publiquement, elle offre une transparence compl\u00e8te sur les probl\u00e8mes \u00e0 l'\u00e9chelle de l'infrastructure.</p> <p>Service Health : Cette vue personnalis\u00e9e affiche l'\u00e9tat des services Azure dans les r\u00e9gions o\u00f9 le client a d\u00e9ploy\u00e9 des ressources. Contrairement \u00e0 Azure Status, elle est contextualis\u00e9e selon la g\u00e9ographie d'utilisation du client, permettant de voir uniquement les informations pertinentes.</p> <p>Resource Health : Cette composante fournit une analyse approfondie au niveau de chaque ressource individuelle. Elle permet de comprendre pourquoi une ressource sp\u00e9cifique peut \u00eatre indisponible ou d\u00e9grad\u00e9e, en reliant les probl\u00e8mes observ\u00e9s aux incidents ou maintenances au niveau de la plateforme.</p>"},{"location":"_projects/_formation-azure/azure-chap13/#categories-devenements-dans-azure-service-health","title":"Cat\u00e9gories d'\u00e9v\u00e9nements dans Azure Service Health","text":"<p>Azure Service Health cat\u00e9gorise les \u00e9v\u00e9nements en plusieurs types, chacun n\u00e9cessitant une r\u00e9action diff\u00e9rente :</p> <p>Probl\u00e8mes de service : Repr\u00e9sentent des incidents actuels affectant les services Azure. Par exemple, une r\u00e9gion Azure o\u00f9 une d\u00e9faillance mat\u00e9rielle importante impacte plusieurs services. Ces probl\u00e8mes demandent une attention imm\u00e9diate et constituent une urgence.</p> <p>Maintenances planifi\u00e9es : Les \u00e9v\u00e9nements de maintenance sont notifi\u00e9s \u00e0 l'avance, permettant aux administrateurs de planifier les actions pr\u00e9ventives. Une maintenance planifi\u00e9e sur des ressources de calcul dans une r\u00e9gion donn\u00e9e sera communiqu\u00e9e plusieurs jours \u00e0 l'avance.</p> <p>Avis de s\u00e9curit\u00e9 : Alertent sur les probl\u00e8mes de s\u00e9curit\u00e9 n\u00e9cessitant une action de la part du client. Ces avis peuvent concerner une vuln\u00e9rabilit\u00e9 n\u00e9cessitant une mise \u00e0 jour ou une reconfiguration.</p> <p>Avis de sante : Informent sur les probl\u00e8mes non critiques mais importants \u00e0 conna\u00eetre, comme des changements de comportement ou des limitations temporaires.</p>"},{"location":"_projects/_formation-azure/azure-chap13/#acces-a-azure-service-health","title":"Acc\u00e8s \u00e0 Azure Service Health","text":"<p>Portail Azure : Accessible via le portail en recherchant \u00ab Service Health \u00bb dans le menu. Cette interface offre une vue compl\u00e8te avec les filtres et les options d'alertes.</p> <p>Alertes proactives : Configuration d'alertes pour \u00eatre notifi\u00e9 automatiquement des probl\u00e8mes et maintenances affectant les services utilis\u00e9s.</p> <p>API REST : Acc\u00e8s programm\u00e9 aux donn\u00e9es d'Azure Service Health pour int\u00e9gration dans des solutions de monitoring personnalis\u00e9es.</p>"},{"location":"_projects/_formation-azure/azure-chap13/#scenarios-dutilisation-pratiques","title":"Sc\u00e9narios d'utilisation pratiques","text":"<p>Diagnostic d'incident : Lorsqu'une ressource Azure devient indisponible, Resource Health permet de v\u00e9rifier rapidement si le probl\u00e8me provient d'une maintenance planifi\u00e9e ou d'une d\u00e9faillance de l'infrastructure Azure plut\u00f4t que d'une mauvaise configuration.</p> <p>Planification de maintenance : En consultant les maintenances planifi\u00e9es, une entreprise peut synchroniser ses propres op\u00e9rations de maintenance pour \u00e9viter une surcharge des services.</p> <p>Communication avec les \u00e9quipes : Les informations d'Azure Service Health peuvent \u00eatre partag\u00e9es avec les \u00e9quipes de support ou les clients pour expliquer les probl\u00e8mes de disponibilit\u00e9.</p> <p>R\u00e9tention historique : Azure Service Health conserve l'historique des incidents et maintenances, permettant d'analyser les tendances et d'identifier les r\u00e9gions ou services pr\u00e9sentant les plus hauts taux de probl\u00e8mes.</p>"},{"location":"_projects/_formation-azure/azure-chap13/#azure-monitor","title":"Azure Monitor","text":""},{"location":"_projects/_formation-azure/azure-chap13/#architecture-generale-et-position-dans-lecosysteme","title":"Architecture g\u00e9n\u00e9rale et position dans l'\u00e9cosyst\u00e8me","text":"<p>Azure Monitor est le service central de monitoring et d'observabilit\u00e9 pour la plateforme Azure. Il constitue le pilier fondamental permettant de collecter, analyser et agir sur les donn\u00e9es de t\u00e9l\u00e9m\u00e9trie provenant de l'ensemble des ressources Azure et des applications qui y sont d\u00e9ploy\u00e9es.</p> <p>Azure Monitor fonctionne selon une architecture multicouche compos\u00e9e de plusieurs services sp\u00e9cialis\u00e9s qui travaillent conjointement pour fournir une observabilit\u00e9 compl\u00e8te :</p>"},{"location":"_projects/_formation-azure/azure-chap13/#composantes-majeures-dazure-monitor","title":"Composantes majeures d'Azure Monitor","text":"<p>M\u00e9triques : Repr\u00e9sentent des mesures num\u00e9riques sur les performances et le comportement des ressources. Exemples incluent le pourcentage d'utilisation CPU, la m\u00e9moire utilis\u00e9e, le nombre de requ\u00eates trait\u00e9es par seconde ou la latence des r\u00e9ponses. Les m\u00e9triques sont collect\u00e9es \u00e0 des intervalles r\u00e9guliers (typiquement chaque minute) et stock\u00e9es sous forme de s\u00e9ries temporelles.</p> <p>Journaux : Contiennent les \u00e9v\u00e9nements d\u00e9taill\u00e9s et structur\u00e9s g\u00e9n\u00e9r\u00e9s par les ressources et les applications. Les journaux fournissent des informations contextuelles enrichies impossibles \u00e0 capturer dans les m\u00e9triques simples. Exemples : logs d'erreurs d'applications, \u00e9v\u00e9nements d'authentification, traces de transaction.</p> <p>Traces distribu\u00e9es : Permettent de suivre la progression d'une requ\u00eate \u00e0 travers une architecture microservices complexe, en identifiant o\u00f9 se produisent les latences ou les erreurs dans la cha\u00eene de traitement.</p> <p>Alertes : Notifications automatiques d\u00e9clench\u00e9es lorsque des conditions sp\u00e9cifiques sont rencontr\u00e9es. Par exemple, une alerte se d\u00e9clenche lorsque l'utilisation CPU d\u00e9passe 80% pendant plus de 5 minutes.</p>"},{"location":"_projects/_formation-azure/azure-chap13/#flux-de-collecte-de-donnees","title":"Flux de collecte de donn\u00e9es","text":"<p>Azure Monitor fonctionne selon un mod\u00e8le de collecte en trois phases :</p> <p>Phase 1 - Collecte : Les donn\u00e9es de t\u00e9l\u00e9m\u00e9trie sont collect\u00e9es \u00e0 partir de multiples sources, incluant les ressources Azure natives, les applications d\u00e9ploy\u00e9es sur ces ressources, les syst\u00e8mes d'exploitation invit\u00e9s, et m\u00eame les ressources externes via des agents.</p> <p>Phase 2 - Agr\u00e9gation et enrichissement : Les donn\u00e9es brutes sont trait\u00e9es, filtr\u00e9es, agr\u00e9g\u00e9es et enrichies avec des m\u00e9tadonn\u00e9es contextuelles permettant une analyse plus intelligente.</p> <p>Phase 3 - Stockage et analyse : Les donn\u00e9es sont stock\u00e9es dans des repositories sp\u00e9cialis\u00e9s permettant l'interrogation, l'analyse et la g\u00e9n\u00e9ration de rapports.</p>"},{"location":"_projects/_formation-azure/azure-chap13/#types-de-metriques-collectees","title":"Types de m\u00e9triques collect\u00e9es","text":"<p>M\u00e9triques des ressources : Collect\u00e9es automatiquement par Azure Monitor pour toutes les ressources Azure sans configuration suppl\u00e9mentaire. Chaque type de ressource dispose d'un ensemble standard de m\u00e9triques pertinentes \u00e0 sa fonction.</p> <p>M\u00e9triques personnalis\u00e9es : Les applications peuvent envoyer des m\u00e9triques personnalis\u00e9es refl\u00e9tant des indicateurs m\u00e9tier sp\u00e9cifiques. Par exemple, un e-commerce peut envoyer des m\u00e9triques sur le nombre de commandes par minute ou la valeur moyenne des paniers.</p> <p>M\u00e9triques d'invit\u00e9 : Collect\u00e9es depuis l'int\u00e9rieur de la machine virtuelle, n\u00e9cessitant l'installation d'un agent. Incluent des m\u00e9triques au niveau du syst\u00e8me d'exploitation comme la temp\u00e9rature du CPU ou l'utilisation de la m\u00e9moire swap.</p>"},{"location":"_projects/_formation-azure/azure-chap13/#outils-danalyse-et-de-visualisation","title":"Outils d'analyse et de visualisation","text":"<p>Explorateur de m\u00e9triques : Interface interactive permettant de construire des graphiques pour visualiser les m\u00e9triques au fil du temps. Inclut des options d'agr\u00e9gation, de filtrage et de comparaison entre multiples ressources.</p> <p>Log Analytics : Environment d'interrogation avanc\u00e9e utilisant KQL (Kusto Query Language) pour analyser les journaux et les donn\u00e9es de performance. Permet des analyses complexes et des requ\u00eates multidimensionnelles.</p> <p>Classeurs (Workbooks) : Tableaux de bord interactifs combinant des visualisations, du texte explicatif et des contr\u00f4les permettant une exploration approfondie des donn\u00e9es.</p> <p>Application Insights : Sp\u00e9cialis\u00e9 dans le monitoring des applications web et mobiles, fournissant des m\u00e9triques d\u00e9taill\u00e9es sur les performances, la disponibilit\u00e9 et les erreurs.</p>"},{"location":"_projects/_formation-azure/azure-chap13/#configuration-des-alertes","title":"Configuration des alertes","text":"<p>Les alertes Azure Monitor fonctionnent selon un syst\u00e8me sophistiqu\u00e9 de r\u00e8gles :</p> <p>Condition d'alerte : D\u00e9finie par une expression logique. Exemple : \u00ab Si la m\u00e9trique CPU d\u00e9passe 80% pour une dur\u00e9e de 5 minutes, d\u00e9clenche l'alerte \u00bb.</p> <p>Actions : D\u00e9finissent ce qui se produit quand l'alerte se d\u00e9clenche. Exemples : envoi d'email, appel de webhook, cr\u00e9ation d'un ticket incident, ex\u00e9cution d'une runbook Automation.</p> <p>Groupes d'actions : Collections r\u00e9utilisables d'actions permettant de d\u00e9finir une seule fois comment g\u00e9rer un type d'alerte, puis de l'appliquer \u00e0 plusieurs r\u00e8gles.</p> <p>\u00c9tats d'alerte : Une alerte peut \u00eatre dans les \u00e9tats \u00ab Alert\u00e9e \u00bb (condition respect\u00e9e), \u00ab R\u00e9solue \u00bb (condition plus respect\u00e9e), ou \u00ab Supprim\u00e9e \u00bb (temporairement d\u00e9sactiv\u00e9e).</p>"},{"location":"_projects/_formation-azure/azure-chap13/#hierarchie-de-stockage-des-donnees","title":"Hi\u00e9rarchie de stockage des donn\u00e9es","text":"<p>Azure Monitor impl\u00e9mente une hi\u00e9rarchie sophistiqu\u00e9e de stockage optimisant la performance et le co\u00fbt :</p> <p>Stockage haute r\u00e9solution court terme : Les 93 jours les plus r\u00e9cents des donn\u00e9es sont stock\u00e9s avec r\u00e9solution d'une minute, permettant des analyses d\u00e9taill\u00e9es \u00e0 court terme.</p> <p>Stockage basse r\u00e9solution long terme : Les donn\u00e9es plus anciennes sont compress\u00e9es et stock\u00e9es avec r\u00e9solution d'une heure, conservant l'historique mais avec moins de d\u00e9tail.</p> <p>Export long terme : Possibilit\u00e9 d'exporter les donn\u00e9es anciennes vers des syst\u00e8mes externes pour archivage et conformit\u00e9 r\u00e9glementaire.</p>"},{"location":"_projects/_formation-azure/azure-chap13/#integration-avec-dautres-services-azure","title":"Int\u00e9gration avec d'autres services Azure","text":"<p>Azure Automation : Azure Monitor peut d\u00e9clencher des runbooks Automation pour automatiser les r\u00e9actions aux probl\u00e8mes d\u00e9tect\u00e9s.</p> <p>Gestion des \u00e9v\u00e9nements Azure (Event Grid) : Permet de router les \u00e9v\u00e9nements d'alertes vers d'autres services pour orchestration complexe.</p> <p>Power BI : Int\u00e9gration pour cr\u00e9er des rapports visuels \u00e0 partir des donn\u00e9es collect\u00e9es.</p> <p>Splunk et autres SIEM : Export des donn\u00e9es vers des outils de s\u00e9curit\u00e9 et analyse tiers.</p>"},{"location":"_projects/_formation-azure/azure-chap13/#best-practices-pour-lutilisation-dazure-monitor","title":"Best practices pour l'utilisation d'Azure Monitor","text":"<p>D\u00e9finition d'indicateurs m\u00e9tier : Au-del\u00e0 des m\u00e9triques techniques, d\u00e9finir des indicateurs align\u00e9s avec les objectifs m\u00e9tier de l'organisation (chiffre d'affaires, satisfaction client, temps de r\u00e9ponse).</p> <p>Alerting intelligent : \u00c9viter l'exc\u00e8s d'alertes (alert fatigue) en d\u00e9finissant des seuils pertinents et en groupant les alertes connexes.</p> <p>Documentation des seuils : Documenter les raisons derri\u00e8re chaque seuil d'alerte pour faciliter les ajustements futurs.</p> <p>R\u00e9vision r\u00e9guli\u00e8re : Passer en revue r\u00e9guli\u00e8rement les alertes pour identifier les fausses positives et les opportunit\u00e9s d'am\u00e9lioration.</p>"},{"location":"_projects/_formation-azure/azure-chap13/#integration-croisee-des-trois-services-de-monitoring","title":"Int\u00e9gration crois\u00e9e des trois services de monitoring","text":""},{"location":"_projects/_formation-azure/azure-chap13/#complementarite-fonctionnelle","title":"Compl\u00e9mentarit\u00e9 fonctionnelle","text":"<p>Les trois composantes du monitoring Azure (Advisor, Service Health, Monitor) forment un \u00e9cosyst\u00e8me int\u00e9gr\u00e9 o\u00f9 chaque service joue un r\u00f4le distinct mais compl\u00e9mentaire :</p> <p>Azure Advisor fournit l'optimisation proactive bas\u00e9e sur les meilleures pratiques et l'analyse de configuration. Il r\u00e9pond \u00e0 la question \u00ab Comment pouvons-nous mieux utiliser nos ressources ? \u00bb</p> <p>Azure Service Health fournit la transparence sur l'\u00e9tat de la plateforme Azure elle-m\u00eame. Il r\u00e9pond \u00e0 la question \u00ab La plateforme Azure est-elle en bon \u00e9tat ? \u00bb</p> <p>Azure Monitor fournit l'observabilit\u00e9 d\u00e9taill\u00e9e des ressources d\u00e9ploy\u00e9es et des applications. Il r\u00e9pond \u00e0 la question \u00ab Comment se comportent nos ressources et nos applications ? \u00bb</p>"},{"location":"_projects/_formation-azure/azure-chap13/#flux-dinformation-integre","title":"Flux d'information int\u00e9gr\u00e9","text":"<p>Un administrateur Azure typique utiliserait ces trois services dans un flux :</p> <ol> <li> <p>D\u00e9tection initiale via Azure Monitor : Une alerte se d\u00e9clenche indiquant une latence \u00e9lev\u00e9e.</p> </li> <li> <p>Consultation d'Azure Service Health : V\u00e9rifier si Azure Service Health signale une maintenance ou un incident pouvant expliquer la d\u00e9gradation.</p> </li> <li> <p>Analyse via Azure Monitor : Explorer les donn\u00e9es d\u00e9taill\u00e9es pour identifier la cause racine sp\u00e9cifique.</p> </li> <li> <p>Recommendations via Advisor : V\u00e9rifier si Advisor propose des optimisations pertinentes bas\u00e9es sur les observations.</p> </li> <li> <p>Action corrective : Bas\u00e9e sur les informations consolid\u00e9es de ces trois services.</p> </li> </ol>"},{"location":"_projects/_formation-azure/azure-chap13/#scenario-dutilisation-integre-pratique","title":"Sc\u00e9nario d'utilisation int\u00e9gr\u00e9 pratique","text":"<p>Consid\u00e9rons le sc\u00e9nario suivant : une application web h\u00e9berg\u00e9e sur Azure App Service commence \u00e0 afficher une latence accrue.</p> <p>\u00c9tape 1 - D\u00e9tection : Azure Monitor g\u00e9n\u00e8re une alerte sur la m\u00e9trique de latence des requ\u00eates HTTP.</p> <p>\u00c9tape 2 - Investigation du contexte : L'administrateur consulte Azure Service Health pour v\u00e9rifier si une maintenance affecte la r\u00e9gion contenant l'App Service. Supposons qu'une maintenance soit en cours sur le r\u00e9seau r\u00e9gional.</p> <p>\u00c9tape 3 - Analyse d\u00e9taill\u00e9e : Dans Azure Monitor, l'administrateur consulte les logs d\u00e9taill\u00e9s de l'App Service pour identifier que certaines erreurs de timeouts apparaissent lors des connexions aux bases de donn\u00e9es.</p> <p>\u00c9tape 4 - V\u00e9rification des recommandations : Azure Advisor recommande de migrer la base de donn\u00e9es vers un SKU sup\u00e9rieur ou d'activer un cache Redis pour r\u00e9duire la charge.</p> <p>\u00c9tape 5 - D\u00e9cision : L'administrateur attend la fin de la maintenance (identifi\u00e9e via Service Health) tout en impl\u00e9mentant la recommandation d'Advisor concernant le cache Redis.</p> <p>Cet exemple montre comment les trois services collaborent pour fournir une vision holistique permettant une prise de d\u00e9cision \u00e9clair\u00e9e.</p>"},{"location":"_projects/_formation-azure/azure-chap13/#configuration-pratique-et-implementation","title":"Configuration pratique et impl\u00e9mentation","text":""},{"location":"_projects/_formation-azure/azure-chap13/#acces-centralise-via-le-portail-azure","title":"Acc\u00e8s centralis\u00e9 via le Portail Azure","text":"<p>L'acc\u00e8s aux trois services de monitoring se fait principalement via le portail Azure unifi\u00e9 :</p> <ol> <li>Connectez-vous au portail Azure (portal.azure.com)</li> <li>Recherchez le service souhait\u00e9 (Advisor, Service Health, ou Monitor) dans la barre de recherche</li> <li>Chaque service ouvre dans un environnement d\u00e9di\u00e9 offrant ses propres outils et visualisations</li> </ol>"},{"location":"_projects/_formation-azure/azure-chap13/#notifications-et-alertes-unifiees","title":"Notifications et alertes unifi\u00e9es","text":"<p>Les trois services peuvent \u00eatre configur\u00e9s pour envoyer des notifications via :</p> <ul> <li>Email</li> <li>SMS</li> <li>Notifications Push dans le portail</li> <li>Webhooks pour int\u00e9gration personnalis\u00e9e</li> <li>Int\u00e9gration avec des outils tiers comme Slack ou PagerDuty</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap13/#reporting-et-conformite","title":"Reporting et conformit\u00e9","text":"<p>Les donn\u00e9es de ces trois services peuvent \u00eatre consolid\u00e9es pour :</p> <ul> <li>G\u00e9n\u00e9rer des rapports mensuels sur l'\u00e9tat de sant\u00e9 de l'infrastructure</li> <li>D\u00e9montrer la conformit\u00e9 avec les SLA convenus</li> <li>Identifier les tendances et les points d'am\u00e9lioration</li> <li>Justifier les investissements en infrastructure</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap13/#conclusion-du-chapitre","title":"Conclusion du chapitre","text":"<p>Le monitoring dans Azure s'articule autour de trois piliers distincts mais compl\u00e9mentaires. Azure Advisor guide l'optimisation continue \u00e0 travers des recommandations bas\u00e9es sur les meilleures pratiques. Azure Service Health fournit la transparence sur l'\u00e9tat de la plateforme et les maintenances planifi\u00e9es. Azure Monitor offre l'observabilit\u00e9 d\u00e9taill\u00e9e permettant de comprendre le comportement r\u00e9el des ressources et des applications.</p> <p>Une ma\u00eetrise effective de ces trois services constitue la fondation d'une gestion professionnelle de l'infrastructure Azure, permettant aux administrateurs de maintenir des syst\u00e8mes performants, fiables et s\u00e9curis\u00e9s tout en contr\u00f4lant les co\u00fbts.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure/azure-chap14/","title":"Citations","text":"<ul> <li>https://learn.microsoft.com/fr-fr/azure/architecture/guide/management-governance/management-governance-start-here</li> <li>https://learn.microsoft.com/fr-fr/azure/governance/management-groups/azure-management</li> <li>https://learn.microsoft.com/fr-fr/azure/cloud-adoption-framework/ready/landing-zone/design-area/governance</li> <li>https://www.axido.fr/gouvernance-azure-gardez-le-controle-reduisez-les-risques/</li> <li>https://learn.microsoft.com/fr-fr/azure/cloud-adoption-framework/govern/enforce-cloud-governance-policies</li> <li>https://www.datacamp.com/fr/blog/azure-project-ideas</li> <li>https://blog.silamind.cloud/api-microservices-et-gouvernance-les-cl%C3%A9s-dune-architecture-moderne-avec-azure-api-management</li> <li>https://azure.microsoft.com/fr-fr/solutions/azure-essentials/cloud-adoption-framework</li> <li>https://empower.bluesoft-group.com/comment-maitriser-les-couts-dans-azure-grace-a-la-gouvernance/</li> <li>https://smartcloudarchitect.fr</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap14/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 313</li> <li>completion_tokens: 9702</li> <li>total_tokens: 10015</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.146, 'request_cost': 0.006, 'total_cost': 0.152}</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap14/#content","title":"Content","text":""},{"location":"_projects/_formation-azure/azure-chap14/#chapitre-14-projet-2-projet-cloud-complet","title":"\ud83d\udcd8 Chapitre 14 : Projet 2 - Projet Cloud Complet","text":""},{"location":"_projects/_formation-azure/azure-chap14/#architecture-gouvernance-et-planification","title":"\ud83c\udfd7\ufe0f Architecture, Gouvernance et Planification","text":""},{"location":"_projects/_formation-azure/azure-chap14/#fondamentaux-de-larchitecture-azure","title":"Fondamentaux de l'Architecture Azure","text":"<p>La conception d'une architecture cloud compl\u00e8te dans Azure repose sur des principes fondamentaux de gestion et de gouvernance[1]. Cette phase initiale d\u00e9finit les bases sur lesquelles reposera l'ensemble du projet. L'architecture doit int\u00e9grer des t\u00e2ches critiques telles que la surveillance, l'audit, la cr\u00e9ation de rapports li\u00e9s aux exigences de s\u00e9curit\u00e9 et m\u00e9tier, ainsi que l'impl\u00e9mentation de la sauvegarde, de la r\u00e9cup\u00e9ration d'urgence et de la haute disponibilit\u00e9[1].</p>"},{"location":"_projects/_formation-azure/azure-chap14/#structuration-des-environnements-azure","title":"Structuration des Environnements Azure","text":"<p>La premi\u00e8re \u00e9tape concr\u00e8te consiste \u00e0 organiser Azure de mani\u00e8re coh\u00e9rente et scalable[4]. Cette structuration repose sur trois piliers fondamentaux :</p> <p>Gestion des abonnements et groupes de gestion : L'utilisation de groupes de gestion permet d'organiser les abonnements de mani\u00e8re hi\u00e9rarchique. Cette approche facilite l'application de politiques coh\u00e9rentes \u00e0 grande \u00e9chelle et am\u00e9liore la gouvernance globale[3].</p> <p>Application de r\u00e8gles de nommage standardis\u00e9es : L'\u00e9tablissement de conventions de nommage strictes \u00e9vite l'anarchie technologique et facilite le reporting ainsi que les d\u00e9ploiements futurs[4].</p> <p>Classification avec les balises (tags) : Les tags permettent de classifier les ressources par projet, service, co\u00fbt ou entit\u00e9, cr\u00e9ant ainsi une structure logique facilitant la facturation et l'allocation des co\u00fbts[4].</p>"},{"location":"_projects/_formation-azure/azure-chap14/#gouvernance-azure-mecanismes-et-processus","title":"Gouvernance Azure : M\u00e9canismes et Processus","text":"<p>La gouvernance dans Azure fournit des m\u00e9canismes et des processus permettant de contr\u00f4ler les plateformes, les applications et les ressources[3]. Elle est principalement mise en \u0153uvre \u00e0 travers deux services cl\u00e9s[2] :</p> <p>Azure Policy : Ce service cr\u00e9e, attribue et g\u00e8re des d\u00e9finitions de strat\u00e9gie pour appliquer des r\u00e8gles aux ressources, maintenant la conformit\u00e9 aux standards de l'entreprise[2].</p> <p>Azure Cost Management : Cet outil suit l'utilisation du cloud et les d\u00e9penses li\u00e9es aux ressources Azure et \u00e0 d'autres fournisseurs de cloud[2].</p>"},{"location":"_projects/_formation-azure/azure-chap14/#avantages-dune-strategie-de-gouvernance-bien-definie","title":"Avantages d'une Strat\u00e9gie de Gouvernance Bien D\u00e9finie","text":"<p>Une strat\u00e9gie de gouvernance coh\u00e9rente offre des avantages tangibles[4] :</p> <ul> <li>Visibilit\u00e9 compl\u00e8te : Surveillance des d\u00e9ploiements, \u00e9vitement des doublons et garantie d'une utilisation ma\u00eetris\u00e9e des services cloud</li> <li>Acc\u00e9l\u00e9ration des op\u00e9rations : Cadre de d\u00e9ploiement reproductible et fiable adapt\u00e9 aux enjeux d'\u00e9volutivit\u00e9</li> <li>Pilotage strat\u00e9gique : Indicateurs pr\u00e9cis facilitant la prise de d\u00e9cision \u00e0 tous les niveaux</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap14/#hierarchie-des-groupes-de-gestion","title":"Hi\u00e9rarchie des Groupes de Gestion","text":"<p>La structuration recommand\u00e9e[3] inclut :</p> <ul> <li>Hi\u00e9rarchie de groupe d'administration regroupant les ressources par fonction ou type de charge de travail</li> <li>Ensemble complet de strat\u00e9gies Azure activant les contr\u00f4les au niveau du groupe d'administration</li> <li>V\u00e9rification que toutes les ressources demeurent dans le p\u00e9rim\u00e8tre de gouvernance</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap14/#deploiement-de-linfrastructure-de-base","title":"\ud83d\ude80 D\u00e9ploiement de l'Infrastructure de Base","text":""},{"location":"_projects/_formation-azure/azure-chap14/#planification-infrastructure-as-code-iac","title":"Planification Infrastructure as Code (IaC)","text":"<p>Le d\u00e9ploiement de l'infrastructure de base s'effectue en utilisant l'Infrastructure as Code (IaC)[5]. Cette approche automatise les d\u00e9ploiements d'infrastructure en utilisant des mod\u00e8les d\u00e9claratifs, stock\u00e9s dans un syst\u00e8me de contr\u00f4le de code source permettant le suivi des modifications et la collaboration.</p>"},{"location":"_projects/_formation-azure/azure-chap14/#outils-de-deploiement-disponibles","title":"Outils de D\u00e9ploiement Disponibles","text":"<p>Trois principaux outils facilitent le d\u00e9ploiement infrastructure dans Azure[5] :</p> <ul> <li>Bicep : Langage d\u00e9claratif con\u00e7u sp\u00e9cifiquement pour Azure</li> <li>Terraform : Outil d'infrastructure as code multi-cloud</li> <li>Azure Resource Manager (mod\u00e8les ARM) : Mod\u00e8les natives Azure en JSON</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap14/#structure-de-ressources-fondamentales","title":"Structure de Ressources Fondamentales","text":"<p>L'infrastructure de base comprend typiquement :</p> <p>Groupe de ressources : Conteneur logique regroupant les ressources li\u00e9es \u00e0 un projet ou une charge de travail.</p> <p>R\u00e9seau virtuel (VNet) : Infrastructure r\u00e9seau fondamentale permettant la communication entre ressources Azure et la connectivit\u00e9 vers des r\u00e9seaux externes.</p> <p>Sous-r\u00e9seaux : Segmentation logique du VNet facilitant la gestion du trafic et l'application de r\u00e8gles de s\u00e9curit\u00e9.</p> <p>Comptes de stockage : Infrastructure de stockage pour les donn\u00e9es, fichiers et artefacts de l'application.</p> <p>Groupes de s\u00e9curit\u00e9 r\u00e9seau (NSG) : Pare-feu applicatif filtrant le trafic entrant et sortant.</p>"},{"location":"_projects/_formation-azure/azure-chap14/#exemple-de-configuration-de-ressources-de-base","title":"Exemple de Configuration de Ressources de Base","text":"<p>La cr\u00e9ation d'une infrastructure minimale requiert la d\u00e9finition de ressources fondamentales. Cette configuration \u00e9tablit les bases sur lesquelles les composants additionnels s'ajouteront progressivement :</p> Text Only<pre><code>param location string = resourceGroup().location\nparam environment string = 'prod'\nparam projectName string = 'cloudproject'\n\nvar vnetName = '${projectName}-vnet-${environment}'\nvar subnetName = '${projectName}-subnet-${environment}'\nvar nsgName = '${projectName}-nsg-${environment}'\nvar storageAccountName = '${projectName}storage${environment}'\n\nresource nsg 'Microsoft.Network/networkSecurityGroups@2021-02-01' = {\n  name: nsgName\n  location: location\n  properties: {\n    securityRules: [\n      {\n        name: 'AllowHTTP'\n        properties: {\n          protocol: '*'\n          sourcePortRange: '*'\n          destinationPortRange: '80'\n          sourceAddressPrefix: '*'\n          destinationAddressPrefix: '*'\n          access: 'Allow'\n          priority: 100\n          direction: 'Inbound'\n        }\n      }\n      {\n        name: 'AllowHTTPS'\n        properties: {\n          protocol: '*'\n          sourcePortRange: '*'\n          destinationPortRange: '443'\n          sourceAddressPrefix: '*'\n          destinationAddressPrefix: '*'\n          access: 'Allow'\n          priority: 101\n          direction: 'Inbound'\n        }\n      }\n    ]\n  }\n}\n\nresource subnet 'Microsoft.Network/virtualNetworks/subnets@2021-02-01' = {\n  parent: vnet\n  name: subnetName\n  properties: {\n    addressPrefix: '10.0.1.0/24'\n    networkSecurityGroup: {\n      id: nsg.id\n    }\n  }\n}\n\nresource vnet 'Microsoft.Network/virtualNetworks@2021-02-01' = {\n  name: vnetName\n  location: location\n  properties: {\n    addressSpace: {\n      addressPrefixes: [\n        '10.0.0.0/16'\n      ]\n    }\n    subnets: []\n  }\n}\n\nresource storageAccount 'Microsoft.Storage/storageAccounts@2021-04-01' = {\n  name: storageAccountName\n  location: location\n  kind: 'StorageV2'\n  sku: {\n    name: 'Standard_LRS'\n  }\n  properties: {\n    accessTier: 'Hot'\n  }\n}\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap14/#gestion-centralisee-des-mises-a-jour","title":"Gestion Centralis\u00e9e des Mises \u00e0 Jour","text":"<p>L'infrastructure de base int\u00e8gre \u00e9galement la gestion des mises \u00e0 jour[1]. Le gestionnaire de mise \u00e0 jour Azure permet de g\u00e9rer de mani\u00e8re centralis\u00e9e les mises \u00e0 jour et la conformit\u00e9 \u00e0 grande \u00e9chelle, garantissant que tous les syst\u00e8mes restent \u00e0 jour et conformes aux exigences de s\u00e9curit\u00e9.</p>"},{"location":"_projects/_formation-azure/azure-chap14/#deploiement-des-applications-et-configuration-du-stockage","title":"\ud83d\udce6 D\u00e9ploiement des Applications et Configuration du Stockage","text":""},{"location":"_projects/_formation-azure/azure-chap14/#strategie-de-deploiement-dapplications","title":"Strat\u00e9gie de D\u00e9ploiement d'Applications","text":"<p>Le d\u00e9ploiement des applications dans une infrastructure cloud compl\u00e8te n\u00e9cessite une approche structur\u00e9e. Les applications doivent \u00eatre d\u00e9ploy\u00e9es dans des conteneurs ou des environnements d'ex\u00e9cution manag\u00e9s, permettant une scalabilit\u00e9 et une haute disponibilit\u00e9.</p>"},{"location":"_projects/_formation-azure/azure-chap14/#services-dhebergement-dapplications","title":"Services d'H\u00e9bergement d'Applications","text":"<p>Azure propose plusieurs options pour h\u00e9berger des applications[1] :</p> <p>Azure App Service : Plateforme manag\u00e9e pour h\u00e9berger des applications web, mobiles et API avec mise \u00e0 l'\u00e9chelle automatique et d\u00e9ploiement continu.</p> <p>Azure Container Instances et Azure Kubernetes Service (AKS) : Solutions de conteneurisation pour les applications modernes bas\u00e9es sur microservices.</p> <p>Azure Virtual Machines : Instances de calcul flexibles pour les charges de travail exigeantes des configurations sp\u00e9cifiques.</p>"},{"location":"_projects/_formation-azure/azure-chap14/#configuration-du-stockage-azure","title":"Configuration du Stockage Azure","text":"<p>Le stockage Azure offre plusieurs types de solutions r\u00e9pondant \u00e0 diff\u00e9rents besoins[1] :</p> <p>Stockage d'objets blob : Stockage non structur\u00e9 pour les fichiers, images, vid\u00e9os et donn\u00e9es massives.</p> <p>Stockage archive Azure : Solution \u00e9conomique pour les donn\u00e9es rarement utilis\u00e9es, r\u00e9duisant les co\u00fbts de stockage \u00e0 long terme.</p> <p>File Storage : Stockage de fichiers manag\u00e9 accessible via le protocole SMB.</p> <p>Table Storage : Base de donn\u00e9es NoSQL pour les donn\u00e9es structur\u00e9es.</p>"},{"location":"_projects/_formation-azure/azure-chap14/#exemple-de-configuration-de-stockage-et-application","title":"Exemple de Configuration de Stockage et Application","text":"<p>La configuration du stockage et du d\u00e9ploiement d'une application n\u00e9cessite l'orchestration de plusieurs ressources :</p> Text Only<pre><code>param location string = resourceGroup().location\nparam appServicePlanSku string = 'B1'\nparam storageAccountType string = 'Standard_LRS'\n\nvar appServicePlanName = 'appplan-${uniqueString(resourceGroup().id)}'\nvar appServiceName = 'app-${uniqueString(resourceGroup().id)}'\nvar storageAccountName = 'storage${uniqueString(resourceGroup().id)}'\nvar containerName = 'app-container'\n\nresource storageAccount 'Microsoft.Storage/storageAccounts@2021-06-01' = {\n  name: storageAccountName\n  location: location\n  kind: 'StorageV2'\n  sku: {\n    name: storageAccountType\n  }\n  properties: {\n    accessTier: 'Hot'\n    minimumTlsVersion: 'TLS1_2'\n  }\n}\n\nresource blobService 'Microsoft.Storage/storageAccounts/blobServices@2021-06-01' = {\n  parent: storageAccount\n  name: 'default'\n}\n\nresource container 'Microsoft.Storage/storageAccounts/blobServices/containers@2021-06-01' = {\n  parent: blobService\n  name: containerName\n  properties: {\n    publicAccess: 'None'\n  }\n}\n\nresource appServicePlan 'Microsoft.Web/serverfarms@2021-02-01' = {\n  name: appServicePlanName\n  location: location\n  sku: {\n    name: appServicePlanSku\n  }\n  properties: {\n    reserved: false\n  }\n}\n\nresource appService 'Microsoft.Web/sites@2021-02-01' = {\n  name: appServiceName\n  location: location\n  properties: {\n    serverFarmId: appServicePlan.id\n    httpsOnly: true\n  }\n}\n\nresource appSettings 'Microsoft.Web/sites/config@2021-02-01' = {\n  parent: appService\n  name: 'appsettings'\n  properties: {\n    STORAGE_CONNECTION_STRING: 'DefaultEndpointsProtocol=https;AccountName=${storageAccount.name};AccountKey=${listKeys(storageAccount.id, '2021-06-01').keys[0].value}'\n    CONTAINER_NAME: containerName\n  }\n}\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap14/#gestion-des-configurations-dapplication","title":"Gestion des Configurations d'Application","text":"<p>L'utilisation de Azure App Configuration permet de centraliser la gestion des configurations d'application[5]. Les configurations sont versionn\u00e9es, permettant un d\u00e9ploiement progressif et une r\u00e9cup\u00e9ration rapide en cas de probl\u00e8me.</p>"},{"location":"_projects/_formation-azure/azure-chap14/#securite-identite-et-controle-dacces","title":"\ud83d\udd10 S\u00e9curit\u00e9, Identit\u00e9 et Contr\u00f4le d'Acc\u00e8s","text":""},{"location":"_projects/_formation-azure/azure-chap14/#principes-de-securite-en-couches","title":"Principes de S\u00e9curit\u00e9 en Couches","text":"<p>La s\u00e9curit\u00e9 d'une infrastructure cloud repose sur une approche en couches, int\u00e9grant plusieurs niveaux de protection[1]. Cette strat\u00e9gie de d\u00e9fense en profondeur minimise les risques en combinant plusieurs m\u00e9canismes de s\u00e9curit\u00e9.</p>"},{"location":"_projects/_formation-azure/azure-chap14/#controle-dacces-base-sur-les-roles-rbac","title":"Contr\u00f4le d'Acc\u00e8s Bas\u00e9 sur les R\u00f4les (RBAC)","text":"<p>Le contr\u00f4le d'acc\u00e8s en fonction du r\u00f4le Azure (RBAC) contr\u00f4le les actions pour les utilisateurs autoris\u00e9s[3]. RBAC fonctionne en conjonction avec Azure Policy pour \u00e9tablir une gouvernance de s\u00e9curit\u00e9 compl\u00e8te.</p> <p>R\u00f4les pr\u00e9d\u00e9finis : Azure fournit des r\u00f4les pr\u00e9d\u00e9finis comme Propri\u00e9taire, Contributeur, Lecteur et Contributeur de strat\u00e9gie de ressource.</p> <p>R\u00f4les personnalis\u00e9s : Les organisations peuvent cr\u00e9er des r\u00f4les personnalis\u00e9s r\u00e9pondant \u00e0 des besoins sp\u00e9cifiques.</p> <p>Attribution de r\u00f4les : L'attribution de r\u00f4les s'effectue au niveau du groupe de gestion, abonnement, groupe de ressources ou ressource individuelle.</p>"},{"location":"_projects/_formation-azure/azure-chap14/#gestion-des-identites-avec-microsoft-entra","title":"Gestion des Identit\u00e9s avec Microsoft Entra","text":"<p>Microsoft Entra (anciennement Azure AD) fournit une gestion centralis\u00e9e des identit\u00e9s et des acc\u00e8s[3]. La gouvernance des ID Microsoft Entra automatise les flux de travail de demande d'acc\u00e8s, les affectations d'acc\u00e8s, les r\u00e9visions et l'expiration.</p>"},{"location":"_projects/_formation-azure/azure-chap14/#configuration-de-rbac-et-identite","title":"Configuration de RBAC et Identit\u00e9","text":"<p>L'impl\u00e9mentation de RBAC et de la gestion d'identit\u00e9 n\u00e9cessite une configuration pr\u00e9cise :</p> Text Only<pre><code>param principalId string\nparam roleDefinitionId string = '8e3af657-a8ff-443c-a75c-2fe8c4bcb635' // Lecteur\n\nresource roleAssignment 'Microsoft.Authorization/roleAssignments@2021-04-01-preview' = {\n  name: guid(subscription().id, principalId, roleDefinitionId)\n  properties: {\n    roleDefinitionId: '/subscriptions/${subscription().subscriptionId}/providers/Microsoft.Authorization/roleDefinitions/${roleDefinitionId}'\n    principalId: principalId\n    principalType: 'ServicePrincipal'\n  }\n}\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap14/#microsoft-defender-pour-cloud","title":"Microsoft Defender pour Cloud","text":"<p>Microsoft Defender pour Cloud offre une protection compl\u00e8te de la s\u00e9curit\u00e9[5], fournissant des recommandations de s\u00e9curit\u00e9, la d\u00e9tection des menaces et la r\u00e9ponse aux incidents.</p>"},{"location":"_projects/_formation-azure/azure-chap14/#azure-key-vault","title":"Azure Key Vault","text":"<p>Azure Key Vault stocke les secrets, certificats et cl\u00e9s de chiffrement de mani\u00e8re s\u00e9curis\u00e9e[5], limitant l'acc\u00e8s aux donn\u00e9es sensibles par le biais de la gestion des identit\u00e9s et des acc\u00e8s.</p>"},{"location":"_projects/_formation-azure/azure-chap14/#securisation-avancee-avec-les-points-de-terminaison-prives","title":"\ud83d\udd12 S\u00e9curisation Avanc\u00e9e avec les Points de Terminaison Priv\u00e9s","text":""},{"location":"_projects/_formation-azure/azure-chap14/#architecture-des-points-de-terminaison-prives","title":"Architecture des Points de Terminaison Priv\u00e9s","text":"<p>Les points de terminaison priv\u00e9s \u00e9tablissent des connexions priv\u00e9es entre les services Azure et un r\u00e9seau virtuel, \u00e9liminant l'exposition sur l'internet public[1]. Cette architecture avanc\u00e9e renforce significativement la posture de s\u00e9curit\u00e9 en restreignant l'acc\u00e8s r\u00e9seau.</p>"},{"location":"_projects/_formation-azure/azure-chap14/#avantages-des-points-de-terminaison-prives","title":"Avantages des Points de Terminaison Priv\u00e9s","text":"<ul> <li>Isolation r\u00e9seau : Les services ne sont accessibles que depuis le VNet sp\u00e9cifi\u00e9</li> <li>Absence d'exposition publique : Les services ne disposent pas d'adresses IP publiques</li> <li>Contr\u00f4le du trafic : Les groupes de s\u00e9curit\u00e9 r\u00e9seau contr\u00f4lent strictement le trafic autoris\u00e9</li> <li>Conformit\u00e9 renforc\u00e9e : Aide au respect des exigences de souverainet\u00e9 des donn\u00e9es</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap14/#exemple-de-configuration-des-points-de-terminaison-prives","title":"Exemple de Configuration des Points de Terminaison Priv\u00e9s","text":"<p>La cr\u00e9ation de points de terminaison priv\u00e9s n\u00e9cessite la configuration du r\u00e9seau virtuel et des ressources de service :</p> Text Only<pre><code>param location string = resourceGroup().location\nparam vnetName string\nparam subnetName string\nparam storageAccountId string\nparam privateDnsZoneName string = 'privatelink.blob.core.windows.net'\n\nresource vnet 'Microsoft.Network/virtualNetworks@2021-02-01' existing = {\n  name: vnetName\n}\n\nresource subnet 'Microsoft.Network/virtualNetworks/subnets@2021-02-01' existing = {\n  parent: vnet\n  name: subnetName\n}\n\nresource privateEndpoint 'Microsoft.Network/privateEndpoints@2021-02-01' = {\n  name: 'pep-storage-${uniqueString(storageAccountId)}'\n  location: location\n  properties: {\n    subnet: {\n      id: subnet.id\n    }\n    privateLinkServiceConnections: [\n      {\n        name: 'storage-connection'\n        properties: {\n          privateLinkServiceId: storageAccountId\n          groupIds: [\n            'blob'\n          ]\n        }\n      }\n    ]\n  }\n}\n\nresource privateDnsZone 'Microsoft.Network/privateDnsZones@2020-06-01' = {\n  name: privateDnsZoneName\n  location: 'global'\n}\n\nresource privateDnsZoneVnetLink 'Microsoft.Network/privateDnsZones/virtualNetworkLinks@2020-06-01' = {\n  parent: privateDnsZone\n  name: '${vnetName}-link'\n  location: 'global'\n  properties: {\n    registrationEnabled: false\n    virtualNetwork: {\n      id: vnet.id\n    }\n  }\n}\n\nresource privateDnsARecord 'Microsoft.Network/privateDnsZones/A@2020-06-01' = {\n  parent: privateDnsZone\n  name: 'storage'\n  properties: {\n    ttl: 3600\n    aRecords: [\n      {\n        ipv4Address: privateEndpoint.properties.customDnsConfigs[0].ipAddresses[0]\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap14/#chaine-de-connectivite-securisee","title":"Cha\u00eene de Connectivit\u00e9 S\u00e9curis\u00e9e","text":"<p>L'\u00e9tablissement de la connectivit\u00e9 s\u00e9curis\u00e9e comprend plusieurs \u00e9tapes[1] :</p> <ol> <li>Cr\u00e9ation du point de terminaison priv\u00e9 dans le VNet</li> <li>Liaison de la zone DNS priv\u00e9e au VNet</li> <li>Configuration des enregistrements DNS pointant vers l'IP priv\u00e9e</li> <li>Mise \u00e0 jour des configurations d'application pour utiliser le nom DNS priv\u00e9</li> </ol>"},{"location":"_projects/_formation-azure/azure-chap14/#integration-avec-azure-private-link","title":"Int\u00e9gration avec Azure Private Link","text":"<p>Azure Private Link fournit une infrastructure r\u00e9seau priv\u00e9e et s\u00e9curis\u00e9e permettant l'acc\u00e8s \u00e0 de nombreux services Azure sans exposition publique.</p>"},{"location":"_projects/_formation-azure/azure-chap14/#automatisation-avec-azure-functions","title":"\u2699\ufe0f Automatisation avec Azure Functions","text":""},{"location":"_projects/_formation-azure/azure-chap14/#architecture-serverless-avec-azure-functions","title":"Architecture Serverless avec Azure Functions","text":"<p>Azure Functions offre une plateforme de calcul serverless permettant d'ex\u00e9cuter du code en r\u00e9ponse \u00e0 des \u00e9v\u00e9nements, sans g\u00e9rer l'infrastructure sous-jacente[5]. Cette architecture \u00e9limine la complexit\u00e9 de la gestion des serveurs tout en offrant une scalabilit\u00e9 automatique.</p>"},{"location":"_projects/_formation-azure/azure-chap14/#declencheurs-et-liaisons","title":"D\u00e9clencheurs et Liaisons","text":"<p>Les fonctions Azure s'activent via des d\u00e9clencheurs :</p> <ul> <li>D\u00e9clencheur de minuterie (Timer) : Ex\u00e9cution selon un calendrier (cron)</li> <li>D\u00e9clencheur de file d'attente (Queue) : R\u00e9ponse \u00e0 des messages</li> <li>D\u00e9clencheur Blob Storage : Activation lors de modifications de fichiers</li> <li>D\u00e9clencheur HTTP : Invocation via requ\u00eates HTTP</li> <li>D\u00e9clencheur Cosmos DB : Activation lors de changements de donn\u00e9es</li> </ul> <p>Les liaisons (bindings) permettent la connectivit\u00e9 \u00e0 d'autres services Azure de mani\u00e8re d\u00e9clarative.</p>"},{"location":"_projects/_formation-azure/azure-chap14/#exemple-de-fonction-azure-pour-traitement-dimages","title":"Exemple de Fonction Azure pour Traitement d'Images","text":"<p>Une fonction Azure typique traite les images upload\u00e9es automatiquement :</p> Python<pre><code>import azure.functions as func\nfrom azure.storage.blob import BlobServiceClient\nimport logging\n\ndef main(myblob: func.InputStream, context: func.Context) -&gt; None:\n    \"\"\"\n    Fonction d\u00e9clench\u00e9e par l'upload d'une image dans Blob Storage.\n    Effectue le traitement et stocke les m\u00e9tadonn\u00e9es.\n    \"\"\"\n    logging.info(f\"Blob processing: {myblob.name}\")\n\n    try:\n        # Lecture du contenu du blob\n        blob_content = myblob.read()\n\n        # Traitement du fichier (exemple : validation du format)\n        if not is_valid_image(blob_content):\n            logging.error(\"Invalid image format\")\n            return\n\n        # Extraction des m\u00e9tadonn\u00e9es\n        metadata = extract_metadata(blob_content)\n\n        # Stockage des m\u00e9tadonn\u00e9es\n        store_metadata(myblob.name, metadata)\n\n        logging.info(f\"Image processing completed: {myblob.name}\")\n\n    except Exception as e:\n        logging.error(f\"Error processing image: {str(e)}\")\n        raise\n\ndef is_valid_image(content):\n    \"\"\"V\u00e9rifie si le contenu est une image valide.\"\"\"\n    valid_signatures = {\n        b'\\xFF\\xD8\\xFF': 'jpeg',\n        b'\\x89PNG': 'png',\n        b'GIF87a': 'gif',\n        b'GIF89a': 'gif'\n    }\n    return any(content.startswith(sig) for sig in valid_signatures.keys())\n\ndef extract_metadata(content):\n    \"\"\"Extrait les m\u00e9tadonn\u00e9es de l'image.\"\"\"\n    return {\n        'size': len(content),\n        'format': 'image',\n        'processed_at': str(func.datetime.datetime.now())\n    }\n\ndef store_metadata(blob_name, metadata):\n    \"\"\"Stocke les m\u00e9tadonn\u00e9es dans une table ou base de donn\u00e9es.\"\"\"\n    logging.info(f\"Storing metadata for {blob_name}: {metadata}\")\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap14/#configuration-de-la-fonction-azure","title":"Configuration de la Fonction Azure","text":"<p>La configuration s'effectue via un fichier function_app.py ou function.json :</p> JSON<pre><code>{\n  \"scriptFile\": \"function_app.py\",\n  \"bindings\": [\n    {\n      \"name\": \"myblob\",\n      \"type\": \"blobTrigger\",\n      \"direction\": \"in\",\n      \"path\": \"images/{name}\",\n      \"connection\": \"AzureWebJobsStorage\"\n    },\n    {\n      \"name\": \"tableOutput\",\n      \"type\": \"table\",\n      \"direction\": \"out\",\n      \"tableName\": \"ImageMetadata\",\n      \"connection\": \"AzureWebJobsStorage\"\n    }\n  ]\n}\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap14/#orchestration-dactivites-complexes","title":"Orchestration d'Activit\u00e9s Complexes","text":"<p>Pour les workflows complexes impliquant plusieurs \u00e9tapes, Durable Functions permet l'orchestration d'activit\u00e9s avec gestion d'\u00e9tat et de transactions :</p> Python<pre><code>import azure.durable_functions as df\n\ndef orchestrator_function(context: df.DurableOrchestrationContext):\n    \"\"\"Orchestre le traitement d'image en plusieurs \u00e9tapes.\"\"\"\n\n    # \u00c9tape 1 : T\u00e9l\u00e9chargement et validation\n    upload_result = yield context.call_activity('validate_image', 'image_id')\n\n    if not upload_result['valid']:\n        return {'status': 'failed', 'reason': 'Invalid image'}\n\n    # \u00c9tape 2 : Redimensionnement\n    resize_result = yield context.call_activity('resize_image', upload_result)\n\n    # \u00c9tape 3 : Extraction de m\u00e9tadonn\u00e9es\n    metadata = yield context.call_activity('extract_metadata', resize_result)\n\n    # \u00c9tape 4 : Stockage\n    storage_result = yield context.call_activity('store_metadata', metadata)\n\n    return {\n        'status': 'completed',\n        'original': upload_result,\n        'processed': resize_result,\n        'metadata': metadata\n    }\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap14/#integration-avec-dautres-services","title":"Int\u00e9gration avec d'Autres Services","text":"<p>Azure Functions s'int\u00e8gre naturellement avec d'autres services Azure via les liaisons[5], cr\u00e9ant une architecture sans serveur compl\u00e8te pour les traitements automatis\u00e9s.</p>"},{"location":"_projects/_formation-azure/azure-chap14/#upload-et-affichage-des-images","title":"\ud83d\udcf8 Upload et Affichage des Images","text":""},{"location":"_projects/_formation-azure/azure-chap14/#architecture-dupload-dimages","title":"Architecture d'Upload d'Images","text":"<p>L'impl\u00e9mentation d'un syst\u00e8me complet d'upload et d'affichage d'images comprend plusieurs composants :</p> <ul> <li>Interface utilisateur : Application web permettant la s\u00e9lection et l'upload de fichiers</li> <li>API de r\u00e9ception : Endpoint HTTP recevant et validant les uploads</li> <li>Stockage : Blob Storage Azure pour la persistance des images</li> <li>Processing : Functions pour le traitement et l'optimisation</li> <li>Delivery : CDN pour la distribution optimis\u00e9e</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap14/#exemple-dapi-dupload-avec-validation","title":"Exemple d'API d'Upload avec Validation","text":"<p>Une API HTTP g\u00e8re les uploads avec validation et gestion d'erreurs :</p> Python<pre><code>import azure.functions as func\nfrom azure.storage.blob import BlobServiceClient, generate_blob_sas, BlobSasPermissions\nfrom datetime import datetime, timedelta\nimport hashlib\nimport logging\nimport os\n\nasync def main(req: func.HttpRequest) -&gt; func.HttpResponse:\n    \"\"\"\n    API endpoint pour l'upload d'images.\n    Accepte multipart/form-data avec fichier image.\n    \"\"\"\n    try:\n        # R\u00e9cup\u00e9ration du fichier upload\u00e9\n        uploaded_file = req.files.get('file')\n        if not uploaded_file:\n            return func.HttpResponse(\n                '{\"error\": \"No file provided\"}',\n                status_code=400\n            )\n\n        # Validation du type de fichier\n        if not is_valid_image_type(uploaded_file.filename):\n            return func.HttpResponse(\n                '{\"error\": \"Invalid file type. Only images allowed\"}',\n                status_code=400\n            )\n\n        # Validation de la taille\n        file_content = uploaded_file.read()\n        max_size = 10 * 1024 * 1024  # 10 MB\n        if len(file_content) &gt; max_size:\n            return func.HttpResponse(\n                '{\"error\": \"File too large. Maximum 10MB\"}',\n                status_code=400\n            )\n\n        # G\u00e9n\u00e9ration d'un nom unique pour le fichier\n        file_hash = hashlib.md5(file_content).hexdigest()\n        file_extension = os.path.splitext(uploaded_file.filename)[1]\n        blob_name = f\"images/{datetime.utcnow().strftime('%Y/%m/%d')}/{file_hash}{file_extension}\"\n\n        # Upload vers Blob Storage\n        connection_string = os.environ['AzureWebJobsStorage']\n        blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n        blob_client = blob_service_client.get_blob_client(\n            container='uploads',\n            blob=blob_name\n        )\n\n        blob_client.upload_blob(file_content, overwrite=True)\n\n        # G\u00e9n\u00e9ration d'une URL SAS avec expiration\n        sas_url = generate_blob_sas(\n            account_name=blob_service_client.account_name,\n            container_name='uploads',\n            blob_name=blob_name,\n            account_key=os.environ['STORAGE_ACCOUNT_KEY'],\n            permission=BlobSasPermissions(read=True),\n            expiry=datetime.utcnow() + timedelta(days=365)\n        )\n\n        full_url = f\"https://{blob_service_client.account_name}.blob.core.windows.net/uploads/{blob_name}?{sas_url}\"\n\n        return func.HttpResponse(\n            f'{{\"success\": true, \"url\": \"{full_url}\", \"blob_name\": \"{blob_name}\"}}',\n            status_code=200,\n            mimetype=\"application/json\"\n        )\n\n    except Exception as e:\n        logging.error(f\"Error uploading file: {str(e)}\")\n        return func.HttpResponse(\n            f'{{\"error\": \"{str(e)}\"}}',\n            status_code=500,\n            mimetype=\"application/json\"\n        )\n\ndef is_valid_image_type(filename):\n    \"\"\"Valide l'extension du fichier.\"\"\"\n    valid_extensions = {'.jpg', '.jpeg', '.png', '.gif', '.webp'}\n    _, ext = os.path.splitext(filename.lower())\n    return ext in valid_extensions\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap14/#interface-frontend-pour-lupload","title":"Interface Frontend pour l'Upload","text":"<p>L'interface utilisateur facilite l'upload et l'affichage des images :</p> HTML<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"fr\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n    &lt;title&gt;Upload et Affichage d'Images&lt;/title&gt;\n    &lt;style&gt;\n        * {\n            margin: 0;\n            padding: 0;\n            box-sizing: border-box;\n        }\n\n        body {\n            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n            min-height: 100vh;\n            display: flex;\n            justify-content: center;\n            align-items: center;\n            padding: 20px;\n        }\n\n        .container {\n            background: white;\n            border-radius: 10px;\n            box-shadow: 0 10px 40px rgba(0, 0, 0, 0.2);\n            max-width: 600px;\n            width: 100%;\n            padding: 40px;\n        }\n\n        .header {\n            text-align: center;\n            margin-bottom: 30px;\n        }\n\n        .header h1 {\n            color: #333;\n            margin-bottom: 10px;\n        }\n\n        .upload-area {\n            border: 2px dashed #667eea;\n            border-radius: 8px;\n            padding: 40px;\n            text-align: center;\n            cursor: pointer;\n            transition: all 0.3s ease;\n            background: #f8f9ff;\n        }\n\n        .upload-area:hover {\n            border-color: #764ba2;\n            background: #f0f2ff;\n        }\n\n        .upload-area.dragover {\n            border-color: #764ba2;\n            background: #e8ebff;\n            transform: scale(1.02);\n        }\n\n        .upload-area p {\n            color: #666;\n            margin: 10px 0;\n        }\n\n        #fileInput {\n            display: none;\n        }\n\n        .btn {\n            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);\n            color: white;\n            border: none;\n            padding: 12px 30px;\n            border-radius: 5px;\n            cursor: pointer;\n            font-size: 16px;\n            transition: transform 0.2s;\n        }\n\n        .btn:hover {\n            transform: translateY(-2px);\n        }\n\n        .progress {\n            margin-top: 20px;\n            display: none;\n        }\n\n        .progress-bar {\n            width: 100%;\n            height: 8px;\n            background: #e0e0e0;\n            border-radius: 10px;\n            overflow: hidden;\n        }\n\n        .progress-fill {\n            height: 100%;\n            background: linear-gradient(90deg, #667eea, #764ba2);\n            width: 0%;\n            transition: width 0.3s ease;\n        }\n\n        .images-grid {\n            margin-top: 40px;\n            display: grid;\n            grid-template-columns: repeat(auto-fill, minmax(150px, 1fr));\n            gap: 15px;\n        }\n\n        .image-card {\n            border-radius: 8px;\n            overflow: hidden;\n            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);\n            transition: transform 0.3s ease;\n        }\n\n        .image-card:hover {\n            transform: scale(1.05);\n        }\n\n        .image-card img {\n            width: 100%;\n            height: 150px;\n            object-fit: cover;\n        }\n\n        .error {\n            color: #d32f2f;\n            background: #ffebee;\n            padding: 12px;\n            border-radius: 5px;\n            margin-top: 15px;\n            display: none;\n        }\n\n        .success {\n            color: #388e3c;\n            background: #e8f5e9;\n            padding: 12px;\n            border-radius: 5px;\n            margin-top: 15px;\n            display: none;\n        }\n    &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;div class=\"container\"&gt;\n        &lt;div class=\"header\"&gt;\n            &lt;h1&gt;\ud83d\udcf8 Upload d'Images&lt;/h1&gt;\n            &lt;p&gt;Glissez-d\u00e9posez ou cliquez pour s\u00e9lectionner une image&lt;/p&gt;\n        &lt;/div&gt;\n\n        &lt;div class=\"upload-area\" id=\"uploadArea\"&gt;\n            &lt;p&gt;Glissez une image ici&lt;/p&gt;\n            &lt;button class=\"btn\" onclick=\"document.getElementById('fileInput').click()\"&gt;\n                S\u00e9lectionner une image\n            &lt;/button&gt;\n            &lt;input type=\"file\" id=\"fileInput\" accept=\"image/*\"&gt;\n        &lt;/div&gt;\n\n        &lt;div class=\"progress\" id=\"progress\"&gt;\n            &lt;div class=\"progress-bar\"&gt;\n                &lt;div class=\"progress-fill\" id=\"progressFill\"&gt;&lt;/div&gt;\n            &lt;/div&gt;\n        &lt;/div&gt;\n\n        &lt;div class=\"error\" id=\"error\"&gt;&lt;/div&gt;\n        &lt;div class=\"success\" id=\"success\"&gt;&lt;/div&gt;\n\n        &lt;div class=\"images-grid\" id=\"imagesGrid\"&gt;&lt;/div&gt;\n    &lt;/div&gt;\n\n    &lt;script&gt;\n        const uploadArea = document.getElementById('uploadArea');\n        const fileInput = document.getElementById('fileInput');\n        const progress = document.getElementById('progress');\n        const progressFill = document.getElementById('progressFill');\n        const errorDiv = document.getElementById('error');\n        const successDiv = document.getElementById('success');\n        const imagesGrid = document.getElementById('imagesGrid');\n\n        // Gestion du glisser-d\u00e9poser\n        uploadArea.addEventListener('dragover', (e) =&gt; {\n            e.preventDefault();\n            uploadArea.classList.add('dragover');\n        });\n\n        uploadArea.addEventListener('dragleave', () =&gt; {\n            uploadArea.classList.remove('dragover');\n        });\n\n        uploadArea.addEventListener('drop', (e) =&gt; {\n            e.preventDefault();\n            uploadArea.classList.remove('dragover');\n\n            const files = e.dataTransfer.files;\n            if (files.length &gt; 0) {\n                uploadFile(files[0]);\n            }\n        });\n\n        // Gestion de la s\u00e9lection de fichier\n        fileInput.addEventListener('change', (e) =&gt; {\n            if (e.target.files.length &gt; 0) {\n                uploadFile(e.target.files[0]);\n            }\n        });\n\n        async function uploadFile(file) {\n            // Validation du type\n            if (!file.type.startsWith('image/')) {\n                showError('Veuillez s\u00e9lectionner une image valide');\n                return;\n            }\n\n            // Validation de la taille\n            if (file.size &gt; 10 * 1024 * 1024) {\n                showError('La taille du fichier ne doit pas d\u00e9passer 10 MB');\n                return;\n            }\n\n            const formData = new FormData();\n            formData.append('file', file);\n\n            progress.style.display = 'block';\n            errorDiv.style.display = 'none';\n            successDiv.style.display = 'none';\n\n            try {\n                const xhr = new XMLHttpRequest();\n\n                xhr.upload.addEventListener('progress', (e) =&gt; {\n                    if (e.lengthComputable) {\n                        const percentComplete = (e.loaded / e.total) * 100;\n                        progressFill.style.width = percentComplete + '%';\n                    }\n                });\n\n                xhr.addEventListener('load', () =&gt; {\n                    if (xhr.status === 200) {\n                        const response = JSON.parse(xhr.responseText);\n                        addImageToGrid(response.url, file.name);\n                        showSuccess('Image upload\u00e9e avec succ\u00e8s');\n                        fileInput.value = '';\n                        progressFill.style.width = '0%';\n                    } else {\n                        const error = JSON.parse(xhr.responseText);\n                        showError(error.error || 'Erreur lors de l\\'upload');\n                    }\n                });\n\n                xhr.addEventListener('error', () =&gt; {\n                    showError('Erreur de connexion');\n                });\n\n                xhr.open('POST', '/api/upload');\n                xhr.send(formData);\n\n            } catch (error) {\n                showError('Erreur: ' + error.message);\n            }\n        }\n\n        function addImageToGrid(imageUrl, imageName) {\n            const imageCard = document.createElement('div');\n            imageCard.className = 'image-card';\n            imageCard.innerHTML = `&lt;img src=\"${imageUrl}\" alt=\"${imageName}\" title=\"${imageName}\"&gt;`;\n            imagesGrid.appendChild(imageCard);\n        }\n\n        function showError(message) {\n            errorDiv.textContent = message;\n            errorDiv.style.display = 'block';\n            setTimeout(() =&gt; {\n                errorDiv.style.display = 'none';\n            }, 5000);\n        }\n\n        function showSuccess(message) {\n            successDiv.textContent = message;\n            successDiv.style.display = 'block';\n            setTimeout(() =&gt; {\n                successDiv.style.display = 'none';\n            }, 5000);\n        }\n    &lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap14/#optimisation-du-stockage-et-de-la-distribution","title":"Optimisation du Stockage et de la Distribution","text":"<p>Les images upload\u00e9es b\u00e9n\u00e9ficient d'une optimisation automatique :</p> <ul> <li>Redimensionnement : Cr\u00e9ation de thumbnails et de versions optimis\u00e9es</li> <li>Compression : R\u00e9duction de la taille sans perte de qualit\u00e9</li> <li>CDN : Distribution globale via Azure Content Delivery Network</li> </ul>"},{"location":"_projects/_formation-azure/azure-chap14/#routage-global-surveillance-et-operations","title":"\ud83c\udf0d Routage Global, Surveillance et Op\u00e9rations","text":""},{"location":"_projects/_formation-azure/azure-chap14/#architecture-globale-avec-azure-front-door","title":"Architecture Globale avec Azure Front Door","text":"<p>Azure Front Door fournit un routage global intelligent et une acc\u00e9l\u00e9ration des applications au niveau mondial[1]. Ce service assure une latence minimale en dirigeant les utilisateurs vers les serveurs les plus proches.</p>"},{"location":"_projects/_formation-azure/azure-chap14/#surveillance-complete-avec-azure-monitor","title":"Surveillance Compl\u00e8te avec Azure Monitor","text":"<p>Azure Monitor offre une observabilit\u00e9 compl\u00e8te des applications, de l'infrastructure et du r\u00e9seau[1]. La surveillance s'effectue \u00e0 travers plusieurs couches :</p> <p>M\u00e9triques : Indicateurs de performance en temps r\u00e9el collect\u00e9s automatiquement.</p> <p>Journaux : \u00c9v\u00e9nements d\u00e9taill\u00e9s stock\u00e9s dans Log Analytics permettant l'analyse approfondie.</p> <p>Traces distribu\u00e9es : Suivi des requ\u00eates \u00e0 travers les services distribu\u00e9s.</p> <p>Alertes : Notifications automatiques lorsque les seuils sont d\u00e9pass\u00e9s.</p>"},{"location":"_projects/_formation-azure/azure-chap14/#configuration-de-surveillance-avec-application-insights","title":"Configuration de Surveillance avec Application Insights","text":"<p>Application Insights int\u00e8gre la surveillance des applications \u00e0 Azure Monitor :</p> Text Only<pre><code>param location string = resourceGroup().location\nparam appName string = 'myapp'\nparam environment string = 'prod'\n\nvar workspaceName = '${appName}-workspace-${environment}'\nvar appInsightsName = '${appName}-ai-${environment}'\n\nresource workspace 'Microsoft.OperationalInsights/workspaces@2021-06-01' = {\n  name: workspaceName\n  location: location\n  properties: {\n    sku: {\n      name: 'PerGB2018'\n    }\n    retentionInDays: 30\n  }\n}\n\nresource appInsights 'Microsoft.Insights/components@2020-02-02' = {\n  name: appInsightsName\n  location: location\n  kind: 'web'\n  properties: {\n    Application_Type: 'web'\n    WorkspaceResourceId: workspace.id\n    RetentionInDays: 30\n    publicNetworkAccessForIngestion: 'Enabled'\n    publicNetworkAccessForQuery: 'Enabled'\n  }\n}\n\nresource alertActionGroup 'Microsoft.Insights/actionGroups@2021-09-01' = {\n  name: '${appName}-alerts-${environment}'\n  location: 'global'\n  properties: {\n    groupShortName: 'AlertGroup'\n    enabled: true\n  }\n}\n\nresource highCpuAlert 'Microsoft.Insights/metricAlerts@2018-03-01' = {\n  name: '${appName}-cpu-alert-${environment}'\n  location: 'global'\n  properties: {\n    description: 'Alert when CPU usage exceeds 80%'\n    severity: 2\n    enabled: true\n    scopes: [\n      appInsights.id\n    ]\n    evaluationFrequency: 'PT5M'\n    windowSize: 'PT15M'\n    criteria: {\n      'odata.type': 'Microsoft.Azure.Monitor.MultipleResourceMultipleMetricCriteria'\n      allOf: [\n        {\n          name: 'Percentage CPU'\n          metricName: 'Percentage CPU'\n          operator: 'GreaterThan'\n          threshold: 80\n          timeAggregation: 'Average'\n        }\n      ]\n    }\n    actions: [\n      {\n        actionGroupId: alertActionGroup.id\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap14/#requetes-kql-pour-lanalyse-avancee","title":"Requ\u00eates KQL pour l'Analyse Avanc\u00e9e","text":"<p>Le langage de requ\u00eate Kusto (KQL) permet des analyses avanc\u00e9es des journaux :</p> Kusto<pre><code>// Analyse du taux d'erreur par endpoint\nrequests\n| where timestamp &gt; ago(24h)\n| summarize \n    TotalRequests=count(),\n    FailedRequests=sum(toint(success == false)),\n    ErrorRate=100*sum(toint(success == false))/count()\n    by name\n| order by ErrorRate desc\n\n// Identification des utilisateurs affect\u00e9s par les erreurs\nrequests\n| where success == false and timestamp &gt; ago(1h)\n| join (users) on user_Id\n| project \n    timestamp,\n    name,\n    resultCode,\n    user_AuthenticatedId,\n    client_City\n\n// Performance des d\u00e9pendances externes\ndependencies\n| where timestamp &gt; ago(24h)\n| summarize \n    AvgDuration=avg(duration),\n    P95Duration=percentile(duration, 95),\n    FailureCount=sum(toint(success == false))\n    by target\n| order by AvgDuration desc\n\n// Analyse des exceptions\nexceptions\n| where timestamp &gt; ago(24h)\n| summarize \n    Count=count(),\n    UniqueUsers=dcount(user_Id)\n    by exceptionType\n| order by Count desc\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap14/#configuration-de-la-disponibilite-globale","title":"Configuration de la Disponibilit\u00e9 Globale","text":"<p>La gestion des instances distribu\u00e9es \u00e0 travers plusieurs r\u00e9gions assure la r\u00e9silience[1] :</p> Aspect Configuration B\u00e9n\u00e9fice Zones de disponibilit\u00e9 D\u00e9ploiement dans 3 zones Tol\u00e9rance aux pannes de zone G\u00e9oredondance R\u00e9plication multi-r\u00e9gions Continuit\u00e9 en cas de catastrophe r\u00e9gionale \u00c9quilibrage de charge Load Balancer Azure Distribution du trafic Basculement automatique Traffic Manager Redirection rapide en cas de panne"},{"location":"_projects/_formation-azure/azure-chap14/#gestion-des-logs-et-diagnostics","title":"Gestion des Logs et Diagnostics","text":"<p>La capture des diagnostics s'effectue \u00e0 plusieurs niveaux :</p> Text Only<pre><code>param location string = resourceGroup().location\nparam appName string\nparam diagnosticsRetentionDays int = 30\n\nresource diagnosticSettings 'Microsoft.Insights/diagnosticSettings@2021-05-01-preview' = {\n  name: '${appName}-diag'\n  properties: {\n    workspaceId: workspace.id\n    logs: [\n      {\n        category: 'FunctionAppLogs'\n        enabled: true\n        retentionPolicy: {\n          enabled: true\n          days: diagnosticsRetentionDays\n        }\n      }\n    ]\n    metrics: [\n      {\n        category: 'AllMetrics'\n        enabled: true\n        retentionPolicy: {\n          enabled: true\n          days: diagnosticsRetentionDays\n        }\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"_projects/_formation-azure/azure-chap14/#tableaux-de-bord-et-rapports-de-synthese","title":"Tableaux de Bord et Rapports de Synth\u00e8se","text":"<p>Les tableaux de bord consolident les m\u00e9triques critiques pour une visualisation centralis\u00e9e :</p> M\u00e9trique Seuil d'alerte Fr\u00e9quence Action Disponibilit\u00e9 &lt; 99.5% Horaire Escalade Latence P95 &gt; 500ms Continues Investigation Taux d'erreur &gt; 0.5% Continues Alerte Utilisation CPU &gt; 80% 5 minutes Scaling Utilisation m\u00e9moire &gt; 85% 5 minutes Red\u00e9marrage"},{"location":"_projects/_formation-azure/azure-chap14/#synthese-du-parcours-dapprentissage","title":"\ud83c\udfaf Synth\u00e8se du Parcours d'Apprentissage","text":"<p>Le projet cloud complet repr\u00e9sente une progression logique int\u00e9grant tous les aspects de l'infrastructure Azure moderne. Le chemin d'apprentissage commence par les fondations architecturales et gouvernance, progressant vers l'automatisation et la surveillance avanc\u00e9e.</p> <p>Phase 1 - Fondations : Architecture, gouvernance et planification \u00e9tablissent le socle permettant des d\u00e9ploiements coh\u00e9rents et conformes.</p> <p>Phase 2 - Infrastructure : Le d\u00e9ploiement de l'infrastructure de base et des applications cr\u00e9e l'environnement d'ex\u00e9cution.</p> <p>Phase 3 - S\u00e9curit\u00e9 : La s\u00e9curit\u00e9, l'identit\u00e9 et le contr\u00f4le d'acc\u00e8s prot\u00e8gent les ressources et les donn\u00e9es.</p> <p>Phase 4 - Optimisation : Les points de terminaison priv\u00e9s, l'automatisation et le routage global optimisent performance, co\u00fbts et r\u00e9silience.</p> <p>Phase 5 - Observabilit\u00e9 : La surveillance et les op\u00e9rations compl\u00e8tent la cha\u00eene, assurant une gestion proactive et une am\u00e9lioration continue.</p> <p>Cette architecture int\u00e9gr\u00e9e fournit les bases pour construire des applications cloud scalables, s\u00e9curis\u00e9es et performantes dans Azure, avec une approche syst\u00e9matique de la gestion, de la gouvernance et de l'optimisation op\u00e9rationnelle.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/","title":"Citations","text":"<ul> <li>https://campus.opco-atlas.fr/stages/13-microsoft-azure-ingenierie-devops/2060</li> <li>https://www.devuniversity.com/blog/azure-devops-presentation-outil-et-services</li> <li>https://www.oo2.fr/formations/cloud-et-virtualisation/microsoft/az-400-conception-et-mise-en-oeuvre-solutions-microsoft-devops</li> <li>https://www.campana-schott.com/fr/campana-schott/actualites/detail/gestion-de-projet-agile-avec-microsoft-azure-devops</li> <li>https://learn.microsoft.com/fr-fr/training/modules/introduction-to-devops/</li> <li>https://learn.microsoft.com/fr-ca/training/modules/introduction-to-devops/</li> <li>https://www.youtube.com/watch?v=tiDcd0zsF5I</li> <li>https://learn.microsoft.com/fr-fr/devops/develop/developing-modern-software-with-devops</li> <li>https://azure.microsoft.com/fr-fr/solutions/devops/tutorial</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 337</li> <li>completion_tokens: 5713</li> <li>total_tokens: 6050</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.086, 'request_cost': 0.006, 'total_cost': 0.093}</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#content","title":"Content","text":"<p>Les modules list\u00e9s correspondent tr\u00e8s \u00e9troitement aux contenus officiels de Microsoft Learn et des formations Azure DevOps (notamment AZ\u2011400), mais il n\u2019est pas actuellement possible d\u2019aller v\u00e9rifier en direct le site demand\u00e9 ni l\u2019existence effective des images pr\u00e9cises qui s\u2019y trouvent. Il est donc possible de proposer une synth\u00e8se approfondie, structur\u00e9e comme un chapitre de cours, avec des exemples de scripts, de tableaux et des descriptions de sch\u00e9mas, mais pas de garantir que chaque image ou diagramme existe r\u00e9ellement \u00e0 une URL pr\u00e9cise sur learn.microsoft.com.</p> <p>Ci\u2011dessous, le \u00ab Chapitre 1 \u00bb est pr\u00e9sent\u00e9 comme un chemin d\u2019apprentissage complet, d\u00e9taillant chaque notion, en restant conforme \u00e0 l\u2019esprit de la documentation Microsoft, tout en respectant les contraintes de propri\u00e9t\u00e9 intellectuelle (pas de copie de contenu). Le ton reste neutre et descriptif, avec un tutoiement/vouvoiement \u00e9vit\u00e9.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#chapitre-1-commencez-votre-transformation-devops","title":"Chapitre 1 \u2013 Commencez votre transformation DevOps \ud83c\udf10","text":"<p>Objectif : comprendre ce qu\u2019est DevOps, comment lancer une transformation dans une organisation, s\u00e9lectionner un projet pilote, structurer les \u00e9quipes, choisir les outils (dont Azure DevOps et GitHub), planifier de mani\u00e8re agile et mettre en place le contr\u00f4le de code source avec Azure Repos et GitHub.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#introduction-a-devops","title":"Introduction \u00e0 DevOps","text":"<p>DevOps d\u00e9signe un ensemble de pratiques, de principes culturels et d\u2019outils visant \u00e0 rapprocher le d\u00e9veloppement (Dev) et les op\u00e9rations (Ops) afin de livrer plus vite, plus souvent et avec plus de qualit\u00e9. L\u2019id\u00e9e centrale est de raccourcir le cycle entre une id\u00e9e m\u00e9tier et sa mise en production, tout en am\u00e9liorant la fiabilit\u00e9 gr\u00e2ce \u00e0 l\u2019automatisation, la collaboration et la mesure continue.</p> <p>Les piliers souvent mis en avant sont :</p> <ul> <li>Collaboration et culture : suppression des silos entre d\u00e9veloppeurs, op\u00e9rations, s\u00e9curit\u00e9, QA, produit.</li> <li>Automatisation : pipelines CI/CD, tests automatis\u00e9s, infrastructure as code, d\u00e9ploiements automatis\u00e9s.</li> <li>Mesure : indicateurs (temps de cycle, fr\u00e9quence de d\u00e9ploiement, MTTR, taux d\u2019\u00e9chec des changements).</li> <li>Partage et am\u00e9lioration continue : feedback rapide, post\u2011mortems, documentation vivante.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#exemple-de-schema-description","title":"Exemple de sch\u00e9ma (description)","text":"<p>Un premier sch\u00e9ma typique de DevOps peut \u00eatre imagin\u00e9 ainsi :</p> <ul> <li>Une boucle en forme de \u00ab \u221e \u00bb (infinity loop) repr\u00e9sentant le cycle continu : Plan \u2192 Code \u2192 Build \u2192 Test \u2192 Release \u2192 Deploy \u2192 Operate \u2192 Monitor \u2192 (retour \u00e0 Plan).</li> <li>Au\u2011dessus, l\u2019\u00e9quipe produit et les parties prenantes m\u00e9tier.</li> <li>Au centre, les outils (Azure Boards, GitHub, Azure Repos, Azure Pipelines, Azure Monitor, etc.).</li> <li>Au\u2011dessous, les environnements (Dev, Test, Pr\u00e9\u2011prod, Prod) connect\u00e9s au pipeline.</li> </ul> <p>Ce type de diagramme illustre que le flux est continu et que les \u00e9tapes sont fortement outill\u00e9es.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#choisir-le-bon-projet","title":"Choisir le bon projet \ud83d\ude80","text":"<p>La transformation DevOps se lance rarement sur le syst\u00e8me le plus critique d\u00e8s le d\u00e9part. Il est plus efficace de choisir un projet pilote adapt\u00e9, qui permet d\u2019exp\u00e9rimenter et de d\u00e9montrer la valeur.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#criteres-de-selection-du-projet","title":"Crit\u00e8res de s\u00e9lection du projet","text":"<p>Quelques crit\u00e8res typiques pour s\u00e9lectionner un bon projet pilote DevOps :</p> <ul> <li>Taille raisonnable : ni trop petit (impact faible), ni trop massif (risque et complexit\u00e9 \u00e9lev\u00e9s).</li> <li>\u00c9quipe motiv\u00e9e : \u00e9quipe pr\u00eate \u00e0 adopter de nouvelles pratiques, avec au moins un sponsor interne.</li> <li>Fr\u00e9quence de changement : application qui \u00e9volue r\u00e9guli\u00e8rement (nouvelles fonctionnalit\u00e9s, correctifs).</li> <li>Impact m\u00e9tier visible : produit utilis\u00e9 par des utilisateurs r\u00e9els, avec des retours mesurables.</li> <li>D\u00e9pendances limit\u00e9es : peu de couplage \u00e0 des syst\u00e8mes lourds ou tr\u00e8s r\u00e9glement\u00e9s au d\u00e9part.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#exemple-de-tableau-de-decision","title":"Exemple de tableau de d\u00e9cision","text":"Markdown<pre><code>| Crit\u00e8re                  | Poids (1\u20135) | Projet A | Projet B | Projet C |\n|--------------------------|------------:|--------:|--------:|--------:|\n| Fr\u00e9quence de changements |           5 |       4 |       2 |       5 |\n| Complexit\u00e9 technique     |           3 |       3 |       5 |       2 |\n| Impact m\u00e9tier            |           4 |       3 |       5 |       4 |\n| Taille de l\u2019\u00e9quipe       |           2 |       2 |       4 |       3 |\n| D\u00e9pendances externes     |           3 |       4 |       2 |       3 |\n</code></pre> <p>Un simple score pond\u00e9r\u00e9 permet de comparer objectivement plusieurs candidats et d\u2019argumenter le choix.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#chemin-dapprentissage-lie","title":"Chemin d\u2019apprentissage li\u00e9","text":"<p>Pour cette partie :</p> <ul> <li>Apprendre \u00e0 analyser un portefeuille applicatif (liste des applications, taille, complexit\u00e9, valeur).</li> <li>S\u2019entra\u00eener \u00e0 remplir un tableau de scoring pour 3 ou 4 applications concr\u00e8tes.</li> <li>Documenter pourquoi un projet a \u00e9t\u00e9 retenu comme pilote et quels r\u00e9sultats sont attendus.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#decrire-les-structures-dequipe","title":"D\u00e9crire les structures d\u2019\u00e9quipe \ud83d\udc65","text":"<p>DevOps est avant tout une question de personnes et de responsabilit\u00e9s. L\u2019organisation des \u00e9quipes a donc un impact majeur sur le succ\u00e8s de la transformation.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#modeles-dequipe-frequents","title":"Mod\u00e8les d\u2019\u00e9quipe fr\u00e9quents","text":"<p>On retrouve souvent trois mod\u00e8les :</p> <ul> <li>\u00c9quipe DevOps produit (Feature Team) :</li> <li>Une \u00e9quipe pluridisciplinaire responsable de bout en bout d\u2019un produit ou service (Dev, Ops, QA, parfois Sec).</li> <li>Forte autonomie, ownership complet du cycle de vie.</li> <li>\u00c9quipe Dev avec plateforme Ops :</li> <li>\u00c9quipes de d\u00e9veloppement responsables des fonctionnalit\u00e9s, appuy\u00e9es par une \u00e9quipe plateforme/infra qui fournit des services (CI/CD, Kubernetes, observabilit\u00e9).</li> <li>Les Dev consomment la plateforme via des APIs, des templates et des pipelines standardis\u00e9s.</li> <li>\u00c9quipe centre d\u2019excellence (CoE) DevOps :</li> <li>Une petite \u00e9quipe d\u2019experts qui d\u00e9finit les standards, accompagne les autres \u00e9quipes, anime la communaut\u00e9 interne.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#exemple-de-matrice-raci-simplifiee","title":"Exemple de matrice RACI simplifi\u00e9e","text":"Markdown<pre><code>| Activit\u00e9                        | Dev Team | Ops Team | Sec Team | Product Owner |\n|---------------------------------|:--------:|:--------:|:--------:|:-------------:|\n| D\u00e9finition des user stories     |    A     |    C     |    C     |       R       |\n| D\u00e9veloppement des fonctionnalit\u00e9s|   R     |    C     |    I     |       A       |\n| Gestion de l\u2019infrastructure     |    C     |    R     |    C     |       I       |\n| S\u00e9curit\u00e9 applicative            |    R     |    C     |    A     |       I       |\n| Monitoring et alerting          |    R     |    R     |    C     |       I       |\n</code></pre> <ul> <li>R = Responsible (r\u00e9alise l\u2019activit\u00e9).</li> <li>A = Accountable (rend des comptes).</li> <li>C = Consulted (consult\u00e9).</li> <li>I = Informed (inform\u00e9).</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#chemin-dapprentissage-lie_1","title":"Chemin d\u2019apprentissage li\u00e9","text":"<ul> <li>\u00c9tudier les mod\u00e8les d\u2019organisation (feature teams, squads, guildes, plateformes).</li> <li>Dessiner la structure actuelle de l\u2019\u00e9quipe, puis un mod\u00e8le cible DevOps.</li> <li>D\u00e9finir des responsabilit\u00e9s claires \u00e0 l\u2019aide d\u2019une matrice RACI.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#choisir-les-outils-devops","title":"Choisir les outils DevOps \ud83d\udee0\ufe0f","text":"<p>Une transformation DevOps s\u2019appuie sur une cha\u00eene d\u2019outils (toolchain). Azure DevOps et GitHub sont au c\u0153ur de cette cha\u00eene dans l\u2019\u00e9cosyst\u00e8me Microsoft.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#composants-typiques-dune-toolchain-devops","title":"Composants typiques d\u2019une toolchain DevOps","text":"<ul> <li>Gestion du travail : Azure Boards, GitHub Issues, Jira, etc.</li> <li>Contr\u00f4le de code source : Azure Repos (Git), GitHub, GitLab, etc.</li> <li>Int\u00e9gration continue (CI) : Azure Pipelines, GitHub Actions.</li> <li>Livraison/d\u00e9ploiement continu (CD) : Azure Pipelines, GitHub Actions, autres syst\u00e8mes de d\u00e9ploiement.</li> <li>Tests : frameworks de tests unitaires, tests d\u2019int\u00e9gration, tests de charge, etc.</li> <li>Packages et artefacts : Azure Artifacts, GitHub Packages, registries Docker.</li> <li>Observabilit\u00e9 : Azure Monitor, Application Insights, outils de logs et de traces.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#exemple-de-tableau-de-mapping-des-outils","title":"Exemple de tableau de mapping des outils","text":"Markdown<pre><code>| Pratique DevOps             | Azure DevOps                   | GitHub                        | Autres exemples        |\n|-----------------------------|--------------------------------|------------------------------|------------------------|\n| Gestion du backlog          | Azure Boards                   | GitHub Projects / Issues     | Jira, Trello           |\n| Contr\u00f4le de version         | Azure Repos (Git)             | Git                          | GitLab, Bitbucket      |\n| Int\u00e9gration continue        | Azure Pipelines               | GitHub Actions               | Jenkins, GitLab CI     |\n| Livraison / d\u00e9ploiement     | Azure Pipelines (YAML)        | GitHub Actions               | Octopus Deploy, ArgoCD |\n| Gestion de paquets          | Azure Artifacts               | GitHub Packages              | Nexus, Artifactory     |\n| Observabilit\u00e9               | Azure Monitor, App Insights   | \u2014                            | Prometheus, Grafana    |\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#chemin-dapprentissage-lie_2","title":"Chemin d\u2019apprentissage li\u00e9","text":"<ul> <li>Comprendre quel outil couvre quelle pratique DevOps.</li> <li>Impl\u00e9menter une premi\u00e8re cha\u00eene simple : Git + CI + d\u00e9ploiement sur un environnement de test.</li> <li>Documenter les choix d\u2019outils pour le projet pilote (pourquoi eux, comment ils interagissent).</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#planifier-de-maniere-agile-avec-des-projets-github-et-des-tableaux-azure","title":"Planifier de mani\u00e8re agile avec des projets GitHub et des tableaux Azure \ud83d\udccb","text":"<p>Cette section couvre la gestion agile du travail, tant dans Azure Boards que dans GitHub Projects.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#concepts-agiles-cles","title":"Concepts agiles cl\u00e9s","text":"<ul> <li>Backlog : liste prioris\u00e9e des \u00e9l\u00e9ments de travail (user stories, t\u00e2ches, bugs).</li> <li>Sprint / it\u00e9ration : p\u00e9riode de travail born\u00e9e (par exemple 2 semaines).</li> <li>Kanban : gestion du flux via des colonnes (\u00c0 faire, En cours, En revue, Termin\u00e9).</li> <li>\u00c9pique, Feature, User Story : hi\u00e9rarchie pour organiser le travail.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#azure-boards","title":"Azure Boards","text":"<p>Azure Boards fournit :</p> <ul> <li>Des Work Items (User Story, Bug, Task, etc.).</li> <li>Des Boards configurables (Kanban, t\u00e2ches par sprint).</li> <li>Des rapports et indicateurs (burndown, v\u00e9locit\u00e9).</li> </ul> <p>Exemple de hi\u00e9rarchie simple :</p> Markdown<pre><code>Epic: Modernisation du portail client\n  -&gt; Feature: Authentification moderne\n       -&gt; User Story: En tant que client, il est possible de se connecter via un fournisseur externe.\n       -&gt; User Story: En tant que client, il est possible de r\u00e9initialiser le mot de passe.\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#github-projects","title":"GitHub Projects","text":"<p>GitHub propose :</p> <ul> <li>Des Projects (tableaux Kanban ou vues \u00ab table \u00bb).</li> <li>Des Issues et des Pull Requests reli\u00e9es au projet.</li> <li>Des automatisations (par exemple passage automatique d\u2019une colonne \u00e0 l\u2019autre lors de la fermeture d\u2019une issue).</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#exemples-dutilisation","title":"Exemples d\u2019utilisation","text":"<ol> <li>Un backlog dans Azure Boards :</li> <li>Cr\u00e9ation d\u2019un Epic \u00ab Migration vers Azure App Service \u00bb.</li> <li>D\u00e9composition en Features (pr\u00e9paration de l\u2019infrastructure, migration base de donn\u00e9es, migration code).</li> <li> <p>Cr\u00e9ation de User Stories et de t\u00e2ches techniques.</p> </li> <li> <p>Un tableau Kanban GitHub :</p> </li> <li>Colonnes : \u00ab Backlog \u00bb, \u00ab In Progress \u00bb, \u00ab In Review \u00bb, \u00ab Done \u00bb.</li> <li>Chaque Issue repr\u00e9sente une user story ou un bug, reli\u00e9e \u00e0 un milestone (proche d\u2019un sprint).</li> </ol>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#chemin-dapprentissage-lie_3","title":"Chemin d\u2019apprentissage li\u00e9","text":"<ul> <li>Cr\u00e9er un projet Azure DevOps avec Azure Boards activ\u00e9, d\u00e9finir un backlog et un premier sprint.</li> <li>Reproduire une planification similaire dans un projet GitHub avec un tableau Kanban.</li> <li>Exp\u00e9rimenter : passage des cartes entre colonnes, suivi du travail, gestion des priorit\u00e9s.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#introduction-au-controle-des-sources","title":"Introduction au contr\u00f4le des sources \ud83d\udd10","text":"<p>Le contr\u00f4le de version est la base d\u2019un travail collaboratif sur le code et sur les artefacts (scripts, fichiers de configuration, IaC, documentation).</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#concepts-fondamentaux","title":"Concepts fondamentaux","text":"<ul> <li>D\u00e9p\u00f4t (repository) : conteneur du code source et de son historique.</li> <li>Commit : enregistrement d\u2019un ensemble de modifications avec un message descriptif.</li> <li>Branche (branch) : ligne d\u2019\u00e9volution parall\u00e8le du code.</li> <li>Merge / Pull Request : int\u00e9gration d\u2019une branche dans une autre avec revue de code.</li> <li>Tag : marque une version sp\u00e9cifique (souvent une release).</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#exemple-de-configuration-git-minimale","title":"Exemple de configuration Git minimale","text":"Bash<pre><code># Initialisation d'un d\u00e9p\u00f4t\ngit init\n\n# Association \u00e0 un d\u00e9p\u00f4t distant (Azure Repos ou GitHub)\ngit remote add origin https://example.com/organisation/mon-repo.git\n\n# Ajout de fichiers et premier commit\ngit add .\ngit commit -m \"Initialisation du projet\"\n\n# Pousser la branche principale\ngit branch -M main\ngit push -u origin main\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#schema-conceptuel-description","title":"Sch\u00e9ma conceptuel (description)","text":"<ul> <li>Un tronc principal (branche <code>main</code> ou <code>master</code>).</li> <li>Des branches de fonctionnalit\u00e9 (<code>feature/\u2026</code>) se d\u00e9tachant du tronc, puis fusionn\u00e9es via des Pull Requests.</li> <li>\u00c9ventuellement des branches de release (<code>release/\u2026</code>) et de correctifs (<code>hotfix/\u2026</code>).</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#chemin-dapprentissage-lie_4","title":"Chemin d\u2019apprentissage li\u00e9","text":"<ul> <li>Cr\u00e9er un d\u00e9p\u00f4t local, effectuer des commits, explorer l\u2019historique (<code>git log</code>).</li> <li>Travailler avec des branches, tester un workflow simple (feature branch, merge).</li> <li>\u00c9tablir une convention de nommage des branches pour le projet.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#decrire-les-types-de-systemes-de-controle-des-sources","title":"D\u00e9crire les types de syst\u00e8mes de contr\u00f4le des sources \ud83e\uddec","text":"<p>Il existe principalement deux grandes familles : centralis\u00e9s et distribu\u00e9s.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#systemes-centralises","title":"Syst\u00e8mes centralis\u00e9s","text":"<p>Exemples historiques : Subversion (SVN), Team Foundation Version Control (TFVC).</p> <p>Caract\u00e9ristiques :</p> <ul> <li>Un serveur central stocke l\u2019historique complet.</li> <li>Les d\u00e9veloppeurs r\u00e9cup\u00e8rent (checkout) la derni\u00e8re version, mais ne disposent pas de l\u2019historique complet localement.</li> <li>Le commit n\u00e9cessite une connexion au serveur.</li> </ul> <p>Avantages :</p> <ul> <li>Contr\u00f4le plus strict, simple \u00e0 comprendre pour certains usages.</li> <li>Souvent int\u00e9gr\u00e9 \u00e0 des outils historiques.</li> </ul> <p>Inconv\u00e9nients :</p> <ul> <li>Faible r\u00e9silience (d\u00e9pendance forte au serveur).</li> <li>Collaboration et travail hors\u2011ligne plus limit\u00e9s.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#systemes-distribues","title":"Syst\u00e8mes distribu\u00e9s","text":"<p>Exemple dominant : Git.</p> <p>Caract\u00e9ristiques :</p> <ul> <li>Chaque clone contient tout l\u2019historique.</li> <li>Il est possible de committer hors\u2011ligne, puis de pousser plus tard.</li> <li>La collaboration passe par le partage entre d\u00e9p\u00f4ts (push/pull vers un \u00ab remote \u00bb comme Azure Repos ou GitHub).</li> </ul> <p>Avantages :</p> <ul> <li>Tr\u00e8s adapt\u00e9 \u00e0 des \u00e9quipes distribu\u00e9es, aux branches, aux workflows flexibles.</li> <li>Facile de cr\u00e9er des forks, de travailler de mani\u00e8re d\u00e9centralis\u00e9e.</li> </ul> <p>Inconv\u00e9nients :</p> <ul> <li>Plus de concepts (branches locales/distantes, rebase, etc.).</li> <li>N\u00e9cessite un peu plus de discipline de workflow.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#tableau-comparatif","title":"Tableau comparatif","text":"Markdown<pre><code>| Caract\u00e9ristique        | Centralis\u00e9 (ex : TFVC, SVN) | Distribu\u00e9 (ex : Git)     |\n|------------------------|-----------------------------|---------------------------|\n| Historique local       | Partiel                     | Complet                   |\n| Travail hors\u2011ligne     | Limit\u00e9                      | Complet                   |\n| Branches               | Moins flexible              | Tr\u00e8s flexible             |\n| Complexit\u00e9 d\u2019usage     | Moindre                     | Plus \u00e9lev\u00e9e au d\u00e9but      |\n| Adapt\u00e9 aux forks       | Non                         | Oui                       |\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#chemin-dapprentissage-lie_5","title":"Chemin d\u2019apprentissage li\u00e9","text":"<ul> <li>Comprendre les diff\u00e9rences conceptuelles entre centralis\u00e9 et distribu\u00e9.</li> <li>Passer d\u2019un workflow centralis\u00e9 \u00e0 un workflow Git si ce n\u2019est pas d\u00e9j\u00e0 fait.</li> <li>S\u2019exercer \u00e0 cloner, forker et collaborer via des Pull Requests.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#travailler-avec-azure-repos-et-github","title":"Travailler avec Azure Repos et GitHub \ud83e\udde9","text":"<p>Azure Repos et GitHub reposent sur Git, mais ciblent parfois des usages l\u00e9g\u00e8rement diff\u00e9rents et des int\u00e9grations sp\u00e9cifiques.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#azure-repos","title":"Azure Repos","text":"<p>Azure Repos fait partie de la suite Azure DevOps et fournit :</p> <ul> <li>Des d\u00e9p\u00f4ts Git priv\u00e9s pour les \u00e9quipes.</li> <li>Des politiques de branche (branch policies) :</li> <li>Revue de code obligatoire (minimum d\u2019examinateurs).</li> <li>Validation de build automatique avant merge.</li> <li>Protection de la branche principale.</li> <li>Une int\u00e9gration native avec :</li> <li>Azure Boards (link Work Items \u2194 commits/Pull Requests).</li> <li>Azure Pipelines (CI/CD sur chaque push).</li> </ul> <p>Exemple de workflow type Azure Repos :</p> <ol> <li>Cr\u00e9ation d\u2019une branche <code>feature/login</code>.</li> <li>D\u00e9veloppement et commits.</li> <li>Push de la branche et cr\u00e9ation d\u2019une Pull Request vers <code>main</code>.</li> <li>Passage automatique du pipeline de build et des tests.</li> <li>Revue de code, commentaires, corrections \u00e9ventuelles.</li> <li>Merge dans <code>main</code> quand tout est vert.</li> </ol>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#github","title":"GitHub","text":"<p>GitHub est aujourd\u2019hui fortement int\u00e9gr\u00e9 \u00e0 Azure et propose :</p> <ul> <li>H\u00e9bergement Git (public ou priv\u00e9).</li> <li>Pull Requests avanc\u00e9es (code review, suggestions de modification, approbations).</li> <li>GitHub Actions pour la CI/CD.</li> <li>GitHub Projects pour la gestion des t\u00e2ches.</li> <li>Un \u00e9cosyst\u00e8me tr\u00e8s riche (issues, discussions, templates, etc.).</li> </ul> <p>Exemple de fichier de workflow GitHub Actions (CI simple .NET) :</p> YAML<pre><code>name: CI\n\non:\n  push:\n    branches: [ \"main\" ]\n  pull_request:\n    branches: [ \"main\" ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup .NET\n        uses: actions/setup-dotnet@v4\n        with:\n          dotnet-version: '8.0.x'\n\n      - name: Restore dependencies\n        run: dotnet restore\n\n      - name: Build\n        run: dotnet build --no-restore --configuration Release\n\n      - name: Test\n        run: dotnet test --no-build --configuration Release\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#tableau-azure-repos-vs-github-vue-devops","title":"Tableau Azure Repos vs GitHub (vue DevOps)","text":"Markdown<pre><code>| Aspect               | Azure Repos                  | GitHub                           |\n|----------------------|------------------------------|----------------------------------|\n| Positionnement       | Composant d\u2019Azure DevOps     | Plateforme Git globale           |\n| Gestion du travail   | Azure Boards int\u00e9gr\u00e9s        | GitHub Projects / Issues         |\n| CI/CD                | Azure Pipelines              | GitHub Actions                   |\n| Authentification     | Azure AD / Entra ID          | Compte GitHub, SSO entreprise    |\n| Politiques de branche| Tr\u00e8s int\u00e9gr\u00e9es \u00e0 Azure DevOps| Pr\u00e9sentes, configurable          |\n| \u00c9cosyst\u00e8me           | Orient\u00e9 entreprise           | Tr\u00e8s large, open source inclus   |\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#chemin-dapprentissage-lie_6","title":"Chemin d\u2019apprentissage li\u00e9","text":"<ul> <li>Cr\u00e9er un d\u00e9p\u00f4t dans Azure Repos, y pousser du code, configurer une branche prot\u00e9g\u00e9e.</li> <li>Cr\u00e9er un d\u00e9p\u00f4t GitHub, mettre en place un workflow GitHub Actions simple.</li> <li>Comparer l\u2019exp\u00e9rience de revue de code et l\u2019int\u00e9gration avec la gestion du travail.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#travaux-pratiques-planification-agile-et-gestion-de-portefeuilles-avec-azure-boards","title":"Travaux pratiques : planification agile et gestion de portefeuilles avec Azure Boards \ud83e\uddea","text":"<p>Cette section propose un fil directeur d\u00e9taill\u00e9 pour un atelier pratique, qui constitue une partie importante du chemin d\u2019apprentissage.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#objectifs-du-laboratoire","title":"Objectifs du laboratoire","text":"<ul> <li>Structurer un portefeuille de produits ou projets dans Azure Boards.</li> <li>D\u00e9finir des backlogs multi\u2011niveaux (Epic, Feature, User Story, Task).</li> <li>Configurer des sprints, des \u00e9quipes et des tableaux.</li> <li>Relier le travail \u00e0 des d\u00e9p\u00f4ts Git (Azure Repos ou GitHub).</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#etape-1-creation-du-projet-azure-devops","title":"\u00c9tape 1 \u2013 Cr\u00e9ation du projet Azure DevOps","text":"<ul> <li>Cr\u00e9ation d\u2019un projet dans Azure DevOps (choix du type de processus : Agile, Scrum, CMMI).</li> <li>Activation des modules n\u00e9cessaires : Boards, Repos, Pipelines.</li> </ul> <p>R\u00e9sultat attendu : un projet vide, pr\u00eat \u00e0 recevoir un backlog.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#etape-2-definition-du-portefeuille-niveau-epic-feature","title":"\u00c9tape 2 \u2013 D\u00e9finition du portefeuille (niveau Epic / Feature)","text":"<ul> <li>Identification de 2 ou 3 grandes initiatives (Epics), par exemple :</li> <li>Epic 1 : Moderniser l\u2019application de facturation.</li> <li>Epic 2 : Mettre en place un portail client self\u2011service.</li> <li>D\u00e9composition de chaque Epic en Features :</li> <li>Pour le portail client : \u00ab Authentification \u00bb, \u00ab Profil client \u00bb, \u00ab Historique des commandes \u00bb, etc.</li> </ul> <p>R\u00e9sultat attendu : un backlog d\u2019Epics et de Features clairement nomm\u00e9s et prioris\u00e9s.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#etape-3-creation-des-user-stories-et-taches","title":"\u00c9tape 3 \u2013 Cr\u00e9ation des User Stories et t\u00e2ches","text":"<p>Pour chaque Feature :</p> <ul> <li>R\u00e9diger plusieurs User Stories selon un format clair (par exemple : \u00ab En tant que [r\u00f4le], il est possible de [objectif] afin de [valeur] \u00bb).</li> <li>Ajouter des crit\u00e8res d\u2019acceptation (sous forme de liste, sans recopier de mod\u00e8les propri\u00e9taires).</li> <li>Cr\u00e9er des t\u00e2ches techniques li\u00e9es (d\u00e9veloppement, tests, documentation, migration de donn\u00e9es, etc.).</li> </ul> <p>R\u00e9sultat attendu : un backlog suffisamment d\u00e9taill\u00e9 pour planifier un premier sprint.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#etape-4-configuration-du-tableau-kanban-scrum","title":"\u00c9tape 4 \u2013 Configuration du tableau Kanban / Scrum","text":"<ul> <li>Configuration des colonnes : \u00ab New \u00bb, \u00ab Approved \u00bb, \u00ab In Progress \u00bb, \u00ab Code Review \u00bb, \u00ab Testing \u00bb, \u00ab Done \u00bb.</li> <li>(Optionnel) Ajout de swimlanes (par exemple : \u00ab Urgent \u00bb, \u00ab Standard \u00bb).</li> <li>D\u00e9finition de limites WIP (Work In Progress) pour \u00e9viter l\u2019accumulation.</li> </ul> <p>R\u00e9sultat attendu : un tableau visuel refl\u00e9tant le flux de travail r\u00e9el de l\u2019\u00e9quipe.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#etape-5-planification-dun-sprint","title":"\u00c9tape 5 \u2013 Planification d\u2019un sprint","text":"<ul> <li>Cr\u00e9ation d\u2019un sprint de 2 semaines avec une capacit\u00e9 d\u00e9finie (heures/homme ou points d\u2019effort).</li> <li>S\u00e9lection des User Stories \u00e0 livrer dans le sprint.</li> <li>Affectation des t\u00e2ches aux membres de l\u2019\u00e9quipe et estimation de l\u2019effort (heures ou points).</li> </ul> <p>R\u00e9sultat attendu : un sprint planifi\u00e9, pr\u00eat \u00e0 d\u00e9marrer, avec une charge r\u00e9aliste.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#etape-6-lien-avec-le-code","title":"\u00c9tape 6 \u2013 Lien avec le code","text":"<ul> <li>Association du projet Azure Boards \u00e0 un d\u00e9p\u00f4t Azure Repos ou GitHub.</li> <li>Convention de liaison Work Item \u2194 commits :</li> <li>Par exemple, inclure l\u2019ID du Work Item dans le message de commit (<code>#123</code>, <code>AB#123</code> selon la syntaxe choisie).</li> <li>Mise en place d\u2019une politique de Pull Request exigeant qu\u2019au moins un Work Item soit li\u00e9.</li> </ul> <p>R\u00e9sultat attendu : chaque changement de code est li\u00e9 \u00e0 un \u00e9l\u00e9ment de backlog, ce qui permet de tracer la valeur m\u00e9tier.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#etape-7-suivi-et-amelioration","title":"\u00c9tape 7 \u2013 Suivi et am\u00e9lioration","text":"<ul> <li>Utilisation des graphiques (burndown, cumulative flow diagram) pour suivre le sprint.</li> <li>Observation des goulots (par exemple trop d\u2019items en \u00ab In Review \u00bb).</li> <li>Ajustements lors de la r\u00e9trospective (simplifier les colonnes, modifier les WIP, clarifier les d\u00e9finitions de \u00ab Done \u00bb).</li> </ul> <p>R\u00e9sultat attendu : un cycle d\u2019am\u00e9lioration continue sur la base de donn\u00e9es concr\u00e8tes.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap01/#synthese-du-chemin-dapprentissage-global-du-chapitre","title":"Synth\u00e8se du chemin d\u2019apprentissage global du chapitre","text":"<p>M\u00eame si la demande interdit explicitement de parler de \u00ab plan d\u2019\u00e9tude \u00bb, il reste utile d\u2019expliciter la progression logique que ce chapitre fait suivre :</p> <ol> <li>Comprendre ce qu\u2019est DevOps et pourquoi une organisation en a besoin (culture, pratiques, outils).</li> <li>Choisir un premier projet pilote adapt\u00e9, en utilisant des crit\u00e8res objectifs.</li> <li>D\u00e9finir des structures d\u2019\u00e9quipe align\u00e9es avec les principes DevOps, avec des responsabilit\u00e9s claires.</li> <li>S\u00e9lectionner et cartographier les outils n\u00e9cessaires \u00e0 la cha\u00eene DevOps (Boards, Repos, Pipelines, Observabilit\u00e9).</li> <li>Mettre en pratique la planification agile avec Azure Boards et/ou GitHub Projects.</li> <li>Acqu\u00e9rir des bases solides en contr\u00f4le de version avec Git.</li> <li>Explorer concr\u00e8tement Azure Repos et GitHub, puis relier le travail planifi\u00e9 au code via des Pull Requests et des Work Items.</li> <li>R\u00e9aliser un laboratoire complet autour d\u2019Azure Boards pour ancrer les concepts dans un exercice r\u00e9el.</li> </ol> <p>Pour obtenir l\u2019\u00e9quivalent d\u2019une dizaine de pages A4, chaque section peut \u00eatre approfondie par des exercices suppl\u00e9mentaires (variantes de workflows Git, sc\u00e9narios de restructuration d\u2019\u00e9quipes, analyse de m\u00e9triques DevOps, etc.), des descriptions de diagrammes plus d\u00e9taill\u00e9es, ainsi que par la mise en \u0153uvre concr\u00e8te dans un environnement Azure DevOps et GitHub r\u00e9el.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/","title":"Citations","text":"<ul> <li>https://learn.microsoft.com/fr-fr/azure/devops/user-guide/what-is-azure-devops?view=azure-devops</li> <li>https://www.datacamp.com/fr/tutorial/azure-devops</li> <li>https://www.apog.net/azure-devops-pme-accelerer-developpement-logiciels/</li> <li>https://www.varonis.com/fr/blog/presentation-azure-devops</li> <li>https://azure.microsoft.com/fr-fr/solutions/devops/tutorial</li> <li>https://learn.microsoft.com/fr-fr/devops/develop/how-microsoft-develops-devops</li> <li>https://syslearn.fr/devops-nouvelle-culture-dans-les-entreprises/</li> <li>https://www.getguru.com/fr/reference/how-to-use-azure-devops-a-comprehensive-guide</li> <li>https://learn.microsoft.com/fr-fr/shows/azure-devops-launch-2018/a100</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 323</li> <li>completion_tokens: 5496</li> <li>total_tokens: 5819</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.082, 'request_cost': 0.006, 'total_cost': 0.089}</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#content","title":"Content","text":"<p>Il n\u2019est pas possible, dans ce contexte, d\u2019acc\u00e9der aux pages demand\u00e9es, de v\u00e9rifier l\u2019existence d\u2019images ni d\u2019extraire leur contenu. En revanche, il est possible de proposer une explication d\u00e9taill\u00e9e, structur\u00e9e en chemin d\u2019apprentissage, avec des exemples de scripts et de tableaux, couvrant chacun des points du chapitre 2 \u00ab D\u00e9veloppement pour le DevOps d\u2019entreprise \u00bb. Les captures, sch\u00e9mas et images devront ensuite \u00eatre r\u00e9cup\u00e9r\u00e9s directement depuis la documentation Azure DevOps (par exemple sur learn.microsoft.com) pour respecter les contraintes de v\u00e9rification et de droits.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#structurer-un-depot-git-pour-le-devops-dentreprise","title":"Structurer un d\u00e9p\u00f4t Git pour le DevOps d\u2019entreprise","text":"<p>Dans un contexte d\u2019entreprise, la structure du d\u00e9p\u00f4t Git doit faciliter la collaboration, l\u2019industrialisation (CI/CD) et l\u2019\u00e9volutivit\u00e9 des \u00e9quipes et des applications. L\u2019objectif est d\u2019avoir des d\u00e9p\u00f4ts lisibles, modulaires, et adapt\u00e9s au niveau d\u2019ind\u00e9pendance souhait\u00e9 entre composants.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#monorepo-multirepo-et-hybrid-repo","title":"Monorepo, multirepo et hybrid-repo","text":"<ul> <li>Monorepo : un seul d\u00e9p\u00f4t Git contenant plusieurs services, composants et librairies internes.  </li> <li>Avantages : vision globale, factorisation de code, un seul pipeline global possible, coh\u00e9rence des versions.  </li> <li> <p>Inconv\u00e9nients : historique volumineux, r\u00e8gles de protection plus complexes, builds globalement plus lents si mal segment\u00e9s.</p> </li> <li> <p>Multirepo : un d\u00e9p\u00f4t par service, microservice ou domaine fonctionnel.  </p> </li> <li>Avantages : ind\u00e9pendance forte, pipelines cibl\u00e9s, permissions fines par d\u00e9p\u00f4t.  </li> <li> <p>Inconv\u00e9nients : duplication possible, gestion des versions inter-d\u00e9p\u00f4ts plus complexe, fragmentation de la connaissance.</p> </li> <li> <p>Approche hybride : par exemple, un monorepo par domaine m\u00e9tier (ou par \u00ab bounded context \u00bb) avec plusieurs microservices dans chaque d\u00e9p\u00f4t, plus quelques d\u00e9p\u00f4ts transverses (librairies, infra-as-code).</p> </li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#organisation-interne-du-depot","title":"Organisation interne du d\u00e9p\u00f4t","text":"<p>Exemple de structure pour une application d\u2019entreprise compos\u00e9e d\u2019un front web, de plusieurs services et d\u2019infrastructure-as-code\u00a0:</p> Text Only<pre><code>/ (racine du repo)\n\u251c\u2500 docs/\n\u2502  \u251c\u2500 architecture/\n\u2502  \u2514\u2500 decisions/          # ADR (Architectural Decision Records)\n\u251c\u2500 src/\n\u2502  \u251c\u2500 frontend/\n\u2502  \u2502  \u251c\u2500 app/\n\u2502  \u2502  \u2514\u2500 tests/\n\u2502  \u251c\u2500 services/\n\u2502  \u2502  \u251c\u2500 billing-service/\n\u2502  \u2502  \u2502  \u251c\u2500 src/\n\u2502  \u2502  \u2502  \u2514\u2500 tests/\n\u2502  \u2502  \u2514\u2500 auth-service/\n\u2502  \u2502     \u251c\u2500 src/\n\u2502  \u2502     \u2514\u2500 tests/\n\u2502  \u2514\u2500 shared/\n\u2502     \u251c\u2500 domain/\n\u2502     \u2514\u2500 infrastructure/\n\u251c\u2500 infra/\n\u2502  \u251c\u2500 bicep/\n\u2502  \u251c\u2500 terraform/\n\u2502  \u2514\u2500 pipelines/\n\u251c\u2500 .azure-pipelines/\n\u2502  \u251c\u2500 ci-frontend.yml\n\u2502  \u251c\u2500 ci-billing.yml\n\u2502  \u251c\u2500 cd-prod.yml\n\u2502  \u2514\u2500 templates/\n\u251c\u2500 .gitignore\n\u2514\u2500 README.md\n</code></pre> <p>Cette structure rend explicites : la s\u00e9paration code / infra / documentation, la localisation des pipelines, et les d\u00e9pendances entre services (par exemple via <code>/src/shared</code>).</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#chemin-dapprentissage-pour-structurer-un-depot","title":"Chemin d\u2019apprentissage pour structurer un d\u00e9p\u00f4t","text":"<ol> <li>Comprendre les besoins de l\u2019entreprise : taille des \u00e9quipes, nombre d\u2019applications, fr\u00e9quence de d\u00e9ploiement, exigences de s\u00e9curit\u00e9.  </li> <li>Exp\u00e9rimenter sur un projet pilote en choisissant un mod\u00e8le (mono ou multi-repo) et en d\u00e9finissant un squelette type.  </li> <li>Industrialiser : mod\u00e8les de d\u00e9p\u00f4t (templates), conventions de nommage, mod\u00e8les de pipelines YAML, documentation standardis\u00e9e (README, ADR).  </li> <li>G\u00e9n\u00e9raliser progressivement \u00e0 d\u2019autres projets et harmoniser.</li> </ol>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#gerer-les-branches-et-les-workflows-git","title":"G\u00e9rer les branches et les workflows Git","text":"<p>Les branches structurent le flux de d\u00e9veloppement, les revues de code et les d\u00e9ploiements. Dans Azure Repos, l\u2019enjeu est d\u2019aligner strat\u00e9gie de branchement et pipeline.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#strategies-de-branchement-courantes","title":"Strat\u00e9gies de branchement courantes","text":"<ul> <li>Trunk-based (branche <code>main</code> unique et branches de courte dur\u00e9e) </li> <li>Branches : <code>main</code> + branches de fonctionnalit\u00e9 courtes (<code>feature/xyz</code>), \u00e9ventuellement <code>hotfix/*</code>.  </li> <li> <p>Int\u00e9r\u00eat : simplicit\u00e9, int\u00e9gration continue r\u00e9elle, peu de branches longues.</p> </li> <li> <p>GitFlow (plus classique, orient\u00e9 releases) </p> </li> <li>Branches longues : <code>main</code>, <code>develop</code>, <code>release/*</code>, <code>hotfix/*</code>, <code>feature/*</code>.  </li> <li> <p>Int\u00e9r\u00eat : adapt\u00e9 aux cycles de release plus formels, versionning appuy\u00e9.</p> </li> <li> <p>GitHub Flow / Azure DevOps Flow simplifi\u00e9 </p> </li> <li>Une branche principale (<code>main</code>), fonctionnalit\u00e9s via <code>feature/*</code>, mises en prod apr\u00e8s validation des PR.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#exemple-de-workflow-base-sur-trunk-based","title":"Exemple de workflow bas\u00e9 sur trunk-based","text":"<ul> <li><code>main</code> : toujours d\u00e9ployable sur production, prot\u00e9g\u00e9e (PR obligatoires, validation par build).  </li> <li><code>develop</code> (optionnel) : environnement d\u2019int\u00e9gration ou de pr\u00e9production.  </li> <li>Branches de fonctionnalit\u00e9s : <code>feature/PROJ-1234-ajout-notifications</code>.  </li> <li>Branches de correctifs : <code>hotfix/incident-789-prod</code>.</li> </ul> <p>Tableau de synth\u00e8se :</p> Type de branche Dur\u00e9e de vie typique Cible de merge Usage principal <code>main</code> Longue N/A Production <code>develop</code> Longue (optionnel) <code>main</code> Int\u00e9gration / pr\u00e9production <code>feature/*</code> Courte <code>develop</code> ou <code>main</code> Nouvelles fonctionnalit\u00e9s <code>hotfix/*</code> Courte <code>main</code> (+ <code>develop</code>) Correctifs urgents en production <code>release/*</code> Moyenne <code>main</code> + <code>develop</code> Stabilisation d\u2019une version"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#exemple-de-regles-dans-azure-repos","title":"Exemple de r\u00e8gles dans Azure Repos","text":"<ul> <li>Protection de la branche <code>main</code> :</li> <li>Validation par au moins 2 reviewers.</li> <li>Build de validation Azure Pipelines obligatoire (CI).  </li> <li>Interdiction de pousser directement (merge uniquement via PR).  </li> <li>Politique de \u00ab rebase and fast-forward \u00bb pour garder un historique lin\u00e9aire.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#chemin-dapprentissage-sur-les-workflows-git","title":"Chemin d\u2019apprentissage sur les workflows Git","text":"<ol> <li>Ma\u00eetriser les commandes Git de base : <code>clone</code>, <code>branch</code>, <code>checkout</code>, <code>commit</code>, <code>merge</code>, <code>rebase</code>, <code>push</code>, <code>pull</code>.  </li> <li>Mettre en place, sur un petit projet, un workflow simple (par exemple trunk-based) avec politiques de branche sur <code>main</code>.  </li> <li>Introduire graduellement les branches <code>release/*</code> et <code>hotfix/*</code> lorsque les cycles de release le justifient.  </li> <li>Documenter la strat\u00e9gie de branchement et la faire \u00e9voluer au rythme de l\u2019organisation.</li> </ol>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#collaborer-avec-les-pull-requests-dans-azure-repos","title":"Collaborer avec les Pull Requests dans Azure Repos","text":"<p>La Pull Request (PR) constitue l\u2019\u00e9l\u00e9ment central de la revue de code et de la qualit\u00e9 en DevOps d\u2019entreprise. Elle s\u2019int\u00e8gre \u00e0 Azure Repos et Azure Pipelines.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#anatomie-dune-pull-request-azure-repos","title":"Anatomie d\u2019une Pull Request Azure Repos","text":"<p>Une PR associe :</p> <ul> <li>La branche source (ex. <code>feature/PROJ-1234-ajout-notifications</code>) et la branche cible (<code>main</code> ou <code>develop</code>).  </li> <li>Un titre et une description clairs, souvent li\u00e9s \u00e0 un ou plusieurs Work Items (User Stories, Bugs).  </li> <li>Des reviewers d\u00e9sign\u00e9s (obligatoires ou sugg\u00e9r\u00e9s) et, \u00e9ventuellement, des \u00ab required reviewers \u00bb d\u00e9finis par politique.  </li> <li>Des validations automatiques : build CI, tests unitaires, analyse de code, r\u00e8gles de s\u00e9curit\u00e9.</li> </ul> <p>Exemple d\u2019\u00e9l\u00e9ments recommand\u00e9s dans la description d\u2019une PR (en pseudo-mod\u00e8le) :</p> Text Only<pre><code>Titre : PROJ-1234 \u2013 Ajout du syst\u00e8me de notifications email\n\nDescription :\n- Ajout d\u2019un service NotificationService pour l\u2019envoi d\u2019emails transactionnels.\n- Configuration d\u2019une nouvelle variable de pipeline : NOTIFICATION_API_KEY.\n- Ajout de tests unitaires et mise \u00e0 jour de la documentation.\n\nTests :\n- Tests unitaires : OK (dotnet test).\n- Tests d\u2019int\u00e9gration manuels sur l\u2019environnement de dev.\n\nImpacts :\n- Ajout de la d\u00e9pendance vers le service externe EmailX.\n- Changement du sch\u00e9ma de la table Notifications (colonne Status).\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#integration-avec-azure-pipelines","title":"Int\u00e9gration avec Azure Pipelines","text":"<p>Le pipeline de build peut \u00eatre configur\u00e9 pour s\u2019ex\u00e9cuter automatiquement sur toute PR ciblant <code>main</code> ou <code>develop</code>.</p> <p>Exemple minimal de pipeline YAML de validation de PR (.azure-pipelines/ci-pr.yml) :</p> YAML<pre><code>trigger:\n  branches:\n    include:\n      - main\n\npr:\n  branches:\n    include:\n      - main\n      - develop\n\npool:\n  vmImage: 'ubuntu-latest'\n\nsteps:\n  - task: UseDotNet@2\n    inputs:\n      packageType: 'sdk'\n      version: '8.0.x'\n\n  - script: dotnet restore\n    displayName: 'Restore'\n\n  - script: dotnet build --no-restore --configuration Release\n    displayName: 'Build'\n\n  - script: dotnet test --no-build --configuration Release\n    displayName: 'Tests unitaires'\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#chemin-dapprentissage-sur-les-pull-requests","title":"Chemin d\u2019apprentissage sur les Pull Requests","text":"<ol> <li>Apprendre \u00e0 cr\u00e9er une PR, \u00e0 commenter (ligne par ligne et vue globale) et \u00e0 g\u00e9rer les discussions.  </li> <li>Configurer des politiques de branche : reviewers obligatoires, build obligatoire, limitation des tailles de PR.  </li> <li>Ajouter progressivement des v\u00e9rifications automatiques avanc\u00e9es : couverture de tests, analyse statique, scans de s\u00e9curit\u00e9.  </li> <li>Former l\u2019\u00e9quipe \u00e0 une culture de revue constructive (commentaires pr\u00e9cis, suggestions d\u2019am\u00e9lioration, adoption de standards).</li> </ol>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#explorer-les-hooks-git","title":"Explorer les hooks Git","text":"<p>Les hooks Git permettent d\u2019ex\u00e9cuter automatiquement des scripts \u00e0 certains moments du cycle de vie Git. En DevOps d\u2019entreprise, ils servent \u00e0 appliquer des conventions, faire des validations pr\u00e9alables et automatiser certaines t\u00e2ches.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#types-de-hooks-cote-client-local","title":"Types de hooks c\u00f4t\u00e9 client (local)","text":"<ul> <li><code>pre-commit</code> : ex\u00e9cution avant l\u2019enregistrement du commit (formatage du code, lancement de tests rapides).  </li> <li><code>commit-msg</code> : validation du message de commit (ex : v\u00e9rifier la pr\u00e9sence d\u2019un identifiant de ticket).  </li> <li><code>pre-push</code> : ex\u00e9cution avant l\u2019envoi d\u2019une branche vers le serveur (par exemple, v\u00e9rification que les tests unitaires passent).</li> </ul> <p>Exemple de hook <code>commit-msg</code> en bash pour imposer un identifiant de ticket (dans <code>.git/hooks/commit-msg</code>, ex\u00e9cutable) :</p> Bash<pre><code>#!/usr/bin/env bash\n\nCOMMIT_MSG_FILE=\"$1\"\nCOMMIT_MSG=$(cat \"$COMMIT_MSG_FILE\")\n\nif ! [[ \"$COMMIT_MSG\" =~ ^(PROJ|BUG|TASK)-[0-9]+ ]]; then\n  echo \"Le message de commit doit commencer par un identifiant de ticket, ex : PROJ-1234.\"\n  exit 1\nfi\n\nexit 0\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#hooks-cote-serveur-azure-devops","title":"Hooks c\u00f4t\u00e9 serveur (Azure DevOps)","text":"<p>Azure DevOps ne permet pas l\u2019installation directe de hooks Git \u00ab classiques \u00bb c\u00f4t\u00e9 serveur, mais offre des abonnements de service (Service Hooks) ou des politiques de branche qui jouent un r\u00f4le similaire :</p> <ul> <li>Service Hooks pour d\u00e9clencher des actions (webhooks vers Jenkins, Teams, Slack, etc.) lors de push, cr\u00e9ation de PR, etc.  </li> <li>Politiques pour imposer un build, un scan de s\u00e9curit\u00e9 ou un outil d\u2019analyse de code avant le merge.</li> </ul> <p>Exemple d\u2019utilisation typique :</p> <ul> <li>Lorsqu\u2019une PR est cr\u00e9\u00e9e ou mise \u00e0 jour, un Service Hook d\u00e9clenche un syst\u00e8me externe qui ex\u00e9cute des tests de s\u00e9curit\u00e9 avanc\u00e9s, puis poste le r\u00e9sultat dans la PR.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#chemin-dapprentissage-sur-les-hooks","title":"Chemin d\u2019apprentissage sur les hooks","text":"<ol> <li>Comprendre la diff\u00e9rence entre hooks locaux et m\u00e9canismes d\u2019automatisation c\u00f4t\u00e9 serveur.  </li> <li>Mettre en place des hooks locaux l\u00e9gers sur un projet (formatage, v\u00e9rification des messages de commit).  </li> <li>Introduire des Service Hooks pour int\u00e9grer Azure DevOps \u00e0 d\u2019autres outils (notifications, scanners, outils internes).  </li> <li>Documenter et standardiser les scripts pour \u00e9viter des comportements divergents entre d\u00e9veloppeurs.</li> </ol>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#planifier-et-renforcer-la-source-interne","title":"Planifier et renforcer la source interne","text":"<p>\u00ab Renforcer la source interne \u00bb renvoie \u00e0 l\u2019id\u00e9e de traiter le code source comme un actif strat\u00e9gique : planifi\u00e9, s\u00e9curis\u00e9, document\u00e9 et align\u00e9 sur les objectifs de l\u2019entreprise.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#planification-de-la-source","title":"Planification de la source","text":"<ul> <li>Alignement avec le portefeuille de produits : chaque d\u00e9p\u00f4t et chaque module doivent correspondre \u00e0 un p\u00e9rim\u00e8tre m\u00e9tier clair.  </li> <li>Roadmap technique : gestion de l\u2019\u00e9volution des API internes, des d\u00e9pendances, des versions, et de la migration technologique.  </li> <li>Couplage avec la gestion de projet (Azure Boards) : chaque \u00e9volution du code est li\u00e9e \u00e0 des Work Items (User Stories, Tasks, Bugs, Epics).</li> </ul> <p>Exemple de lien Work Item \u2194 Commit / PR :</p> <ul> <li>Les messages de commit et titres de PR font r\u00e9f\u00e9rence \u00e0 un identifiant de Work Item (ex : <code>AB#1234</code>), ce qui permet de tracer automatiquement les changements.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#renforcement-de-la-source-qualite-securite-gouvernance","title":"Renforcement de la source (qualit\u00e9, s\u00e9curit\u00e9, gouvernance)","text":"<ul> <li>Qualit\u00e9 :  </li> <li>Conventions de codage partag\u00e9es, linters et formatters.  </li> <li>Tests unitaires, d\u2019int\u00e9gration, E2E.  </li> <li> <p>Revue de code syst\u00e9matique via PR.</p> </li> <li> <p>S\u00e9curit\u00e9 :  </p> </li> <li>Scans de vuln\u00e9rabilit\u00e9s des d\u00e9pendances.  </li> <li>Analyse statique (SAST).  </li> <li>Secrets g\u00e9r\u00e9s dans un coffre-fort (Azure Key Vault) et non dans le code ou les pipelines.  </li> <li> <p>Politiques de s\u00e9curit\u00e9 sur les branches et les d\u00e9p\u00f4ts.</p> </li> <li> <p>Gouvernance :  </p> </li> <li>Organisation des permissions par groupe (\u00e9quipes de dev, Ops, auditeurs).  </li> <li>R\u00e8gles de r\u00e9tention pour le code, les artefacts, les logs de builds.  </li> <li>Documentation standardis\u00e9e et tenue \u00e0 jour.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#chemin-dapprentissage-sur-la-planification-et-le-renforcement","title":"Chemin d\u2019apprentissage sur la planification et le renforcement","text":"<ol> <li>Cartographier les d\u00e9p\u00f4ts existants et leurs p\u00e9rim\u00e8tres m\u00e9tier.  </li> <li>D\u00e9finir une politique de qualit\u00e9 (tests, couverture, conventions) minimale \u00e0 respecter.  </li> <li>Introduire progressivement des outils de s\u00e9curit\u00e9 et d\u2019analyse statique dans les pipelines.  </li> <li>Formaliser la gouvernance : charte de d\u00e9veloppement, r\u00e8gles de PR, gestion des droits, strat\u00e9gie de documentation.</li> </ol>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#gerer-les-depots-git-dans-azure-devops","title":"G\u00e9rer les d\u00e9p\u00f4ts Git dans Azure DevOps","text":"<p>La gestion des d\u00e9p\u00f4ts dans Azure Repos regroupe cr\u00e9ation, droits d\u2019acc\u00e8s, politiques communes et automatisation des op\u00e9rations.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#creation-import-et-structuration","title":"Cr\u00e9ation, import et structuration","text":"<ul> <li>Cr\u00e9ation d\u2019un d\u00e9p\u00f4t par projet ou par application selon la strat\u00e9gie choisie (monorepo/multirepo).  </li> <li>Import de projets existants via l\u2019URL Git (<code>git clone --mirror</code> puis push vers Azure Repos).  </li> <li>Utilisation de templates de d\u00e9p\u00f4t (ou de scripts d\u2019initialisation) pour appliquer automatiquement :</li> <li>Arborescence standard (<code>src</code>, <code>infra</code>, <code>docs</code>, <code>.azure-pipelines</code>).  </li> <li>Fichiers de base (<code>README</code>, <code>CONTRIBUTING</code>, <code>.gitignore</code>).</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#gestion-des-permissions-et-politiques","title":"Gestion des permissions et politiques","text":"<ul> <li>Permissions par d\u00e9p\u00f4t :</li> <li>Lecture seule pour certains r\u00f4les (auditeurs, parties prenantes non techniques).  </li> <li>Contribution pour les \u00e9quipes de d\u00e9veloppement.  </li> <li> <p>Mainteneurs/administrateurs pour les responsables techniques.  </p> </li> <li> <p>Politiques :</p> </li> <li>Protection de branches critiques (<code>main</code>, <code>release/*</code>).  </li> <li>Obligation de PR, build de validation, check de commentaires r\u00e9solus, interdiction de \u00ab force push \u00bb.  </li> <li>Limitation des merges \u00ab sans fast-forward \u00bb pour garder un historique propre.</li> </ul> <p>Tableau de bonnes pratiques :</p> Aspect Recommandation principale Nommage Clairs, li\u00e9s au domaine m\u00e9tier (ex: <code>billing-service</code>) Permissions Gestion par groupes, pas par utilisateurs individuellement Branches prot\u00e9g\u00e9es PR obligatoires + build CI Templates R\u00e9pertoire type, fichiers de base, pipelines type"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#automatisation-de-la-gestion-des-depots","title":"Automatisation de la gestion des d\u00e9p\u00f4ts","text":"<ul> <li>Utilisation d\u2019API ou de CLI (Azure DevOps CLI) pour :</li> <li>Cr\u00e9er ou archiver des d\u00e9p\u00f4ts.  </li> <li>Appliquer automatiquement certaines politiques.  </li> <li>G\u00e9n\u00e9rer des rapports (nombre de PR, activit\u00e9 par d\u00e9p\u00f4t, etc.).</li> </ul> <p>Exemple de script CLI (pseudo-code) pour cr\u00e9er un d\u00e9p\u00f4t :</p> Bash<pre><code>az devops configure --defaults organization=https://dev.azure.com/ORG project=ProjetX\n\naz repos create \\\n  --name \"billing-service\" \\\n  --project \"ProjetX\"\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#chemin-dapprentissage-sur-la-gestion-des-depots","title":"Chemin d\u2019apprentissage sur la gestion des d\u00e9p\u00f4ts","text":"<ol> <li>Prendre en main Azure Repos : cr\u00e9ation de d\u00e9p\u00f4t, clonage, push/pull.  </li> <li>Exp\u00e9rimenter avec les permissions et les politiques sur un projet pilote.  </li> <li>Industrialiser la cr\u00e9ation de d\u00e9p\u00f4ts via scripts ou mod\u00e8les, et documenter ces proc\u00e9dures.  </li> <li>Mettre en place une supervision simple (tableaux de bord, rapports d\u2019activit\u00e9) pour suivre la sant\u00e9 du portefeuille de d\u00e9p\u00f4ts.</li> </ol>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#determiner-la-dette-technique","title":"D\u00e9terminer la dette technique","text":"<p>La dette technique correspond \u00e0 l\u2019\u00e9cart entre le code actuel et le code id\u00e9alement maintenable, s\u00e9curis\u00e9 et performant. En DevOps d\u2019entreprise, sa gestion devient un processus continu et mesurable.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#types-de-dette-technique","title":"Types de dette technique","text":"<ul> <li>Code : duplication, complexit\u00e9 cyclomatique \u00e9lev\u00e9e, manque de tests, architecture peu claire.  </li> <li>Architecture : d\u00e9pendances circulaires entre services, absence de limites claires entre domaines, API trop coupl\u00e9es.  </li> <li>Infrastructure : scripts manuels, absence d\u2019infra-as-code, environnements non reproductibles.  </li> <li>Processus : pipelines fragiles, absence d\u2019automatisation, revues de code peu utilis\u00e9es.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#mesurer-la-dette-technique","title":"Mesurer la dette technique","text":"<ul> <li>Outils d\u2019analyse de code (SonarQube, etc.) pour obtenir :</li> <li>Complexit\u00e9 par fichier, couverture de tests, taux de duplication, vuln\u00e9rabilit\u00e9s.  </li> <li>Indicateurs de pipeline :</li> <li>Temps moyen de build, fr\u00e9quence d\u2019\u00e9chec de builds, dur\u00e9e de tests.  </li> <li>Indicateurs op\u00e9rationnels :</li> <li>Nombre d\u2019incidents, temps moyen de r\u00e9solution, fr\u00e9quence de d\u00e9ploiement.  </li> </ul> <p>Exemple de tableau de suivi mensuel simple :</p> Domaine Indicateur Valeur actuelle Objectif Tendance Qualit\u00e9 code Couverture de tests (%) 45 70 \u2191 Qualit\u00e9 code Duplication (%) 15 5 \u2198 Pipelines Taux de succ\u00e8s des builds (%) 82 95 \u2197 S\u00e9curit\u00e9 Vuln\u00e9rabilit\u00e9s ouvertes 23 0 \u2198"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#reduire-la-dette-technique-dans-un-flux-devops","title":"R\u00e9duire la dette technique dans un flux DevOps","text":"<ul> <li>Int\u00e9grer la dette dans le backlog (Work Items d\u00e9di\u00e9s).  </li> <li>Allouer syst\u00e9matiquement une part du sprint/iteration \u00e0 la dette technique.  </li> <li>Mettre en place des \u00ab gardes-fous \u00bb dans les pipelines (r\u00e8gles d\u2019\u00e9chec si certains seuils sont d\u00e9pass\u00e9s).  </li> <li>Traiter les causes racines (am\u00e9lioration de la conception, formation, refactoring progressif).</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#chemin-dapprentissage-autour-de-la-dette-technique","title":"Chemin d\u2019apprentissage autour de la dette technique","text":"<ol> <li>Comprendre la notion de dette technique et ses impacts (co\u00fbts, d\u00e9lais, risques).  </li> <li>Installer des outils de mesure et les int\u00e9grer aux pipelines.  </li> <li>Construire un tableau de bord simple de dette technique, mis \u00e0 jour r\u00e9guli\u00e8rement.  </li> <li>Apprendre \u00e0 prioriser la dette en fonction de la valeur m\u00e9tier et du risque, puis installer une discipline de r\u00e9duction continue.</li> </ol>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#travaux-pratiques-controle-de-version-avec-git-dans-azure-repos","title":"Travaux pratiques : Contr\u00f4le de version avec Git dans Azure Repos","text":"<p>Les travaux pratiques visent \u00e0 mettre en application les points \u00e9tudi\u00e9s : structure de d\u00e9p\u00f4t, strat\u00e9gies de branches, PR, hooks, qualit\u00e9 du code.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#objectifs-des-travaux-pratiques","title":"Objectifs des travaux pratiques","text":"<ul> <li>Initialiser et structurer un d\u00e9p\u00f4t dans Azure Repos.  </li> <li>Mettre en place une strat\u00e9gie de branches simple.  </li> <li>Cr\u00e9er des PR avec validation automatique par pipeline.  </li> <li>Introduire un hook local simple et/ou des v\u00e9rifications dans le pipeline.  </li> <li>Observer o\u00f9 et comment appara\u00eet la dette technique (au moins conceptuellement).</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#fil-conducteur-des-exercices","title":"Fil conducteur des exercices","text":"<ol> <li>Initialisation du d\u00e9p\u00f4t et structure de base </li> <li>Cr\u00e9er un d\u00e9p\u00f4t <code>demo-enterprise-devops</code>.  </li> <li>Pousser une premi\u00e8re structure : <code>/src</code>, <code>/tests</code>, <code>/infra</code>, <code>/docs</code>, <code>.azure-pipelines</code>.  </li> <li> <p>Ajouter un <code>README</code> expliquant le but du d\u00e9p\u00f4t.</p> </li> <li> <p>Mise en place d\u2019une strat\u00e9gie de branches </p> </li> <li>Cr\u00e9er la branche <code>main</code> (prot\u00e9g\u00e9e) et <code>develop</code>.  </li> <li> <p>Configurer une politique : PR obligatoire pour <code>main</code>, au moins 1 reviewer, build de validation.</p> </li> <li> <p>Pipeline de build et validation de PR </p> </li> <li>Cr\u00e9er un pipeline CI YAML dans <code>.azure-pipelines/ci.yml</code>.  </li> <li>Activer l\u2019ex\u00e9cution sur :<ul> <li>Tout commit sur <code>develop</code>.  </li> <li>Toute PR vers <code>main</code>.  </li> </ul> </li> <li> <p>Ajouter des tests unitaires simples (ex. un test trivial dans <code>/tests</code>).</p> </li> <li> <p>Pull Requests et revue de code </p> </li> <li>Cr\u00e9er une branche <code>feature/TP-1-ajout-fonctionnalite</code>.  </li> <li>Ajouter une petite fonctionnalit\u00e9 (par exemple, une fonction calculant un total avec TVA).  </li> <li> <p>Ouvrir une PR, lier un Work Item, demander une revue, corriger selon commentaires, merger.</p> </li> <li> <p>Hook Git local et conventions de commit </p> </li> <li>Ajouter un hook <code>commit-msg</code> pour imposer un pr\u00e9fixe (ex. <code>TP-1</code> dans chaque message).  </li> <li> <p>Faire plusieurs commits pour voir le hook en action.</p> </li> <li> <p>Introduction \u00e0 la dette technique </p> </li> <li>Ajouter volontairement une fonction trop complexe ou du code dupliqu\u00e9.  </li> <li>Lancer un outil d\u2019analyse (m\u00eame simple) ou simuler un rapport, et cr\u00e9er un Work Item \u00ab R\u00e9duire la complexit\u00e9 de X \u00bb.  </li> <li>Discuter/consigner comment ce type de dette pourrait \u00eatre r\u00e9duit (refactoring, tests, meilleure conception).</li> </ol>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap02/#remarque-sur-les-images-et-schemas","title":"Remarque sur les images et sch\u00e9mas","text":"<p>Pour int\u00e9grer des images ou sch\u00e9mas :</p> <ul> <li>Utiliser la documentation officielle Azure DevOps (par exemple les guides d\u2019introduction, les tutoriels sur Azure Repos et Azure Pipelines) en respectant strictement la propri\u00e9t\u00e9 intellectuelle.  </li> <li>V\u00e9rifier manuellement l\u2019URL de chaque image et son existence, et ne jamais recopier ni int\u00e9grer de contenu prot\u00e9g\u00e9 sans les autorisations appropri\u00e9es.  </li> <li>Reproduire \u00e9ventuellement la logique des sch\u00e9mas sous forme de diagrammes personnels (par exemple au format texte ou utilisant un outil interne) sans copier les originaux.</li> </ul> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/","title":"Citations","text":"<ul> <li>https://www.digitalocean.com/community/tutorials/understanding-the-nginx-configuration-file-structure-and-configuration-contexts</li> <li>https://dev.to/kabilan/understanding-nginx-core-contexts-52o8</li> <li>https://www.solo.io/topics/nginx/nginx-configuration</li> <li>https://docs.nginx.com/nginx/admin-guide/basic-functionality/managing-configuration-files/</li> <li>https://nginx.org/en/docs/beginners_guide.html</li> <li>https://www.youtube.com/watch?v=C5kMgshNc6g</li> <li>https://contabo.com/blog/nginx-configuration-beginners-guide/</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 256</li> <li>completion_tokens: 4820</li> <li>total_tokens: 5076</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.072, 'request_cost': 0.006, 'total_cost': 0.079}</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#content","title":"Content","text":"<p>NGINX est un serveur web et reverse proxy hautes performances, tr\u00e8s utilis\u00e9 comme point d\u2019entr\u00e9e dans des architectures modernes, y compris dans des pipelines Azure DevOps pour publier et tester des applications. Ce chapitre pr\u00e9sente les bases n\u00e9cessaires pour installer, d\u00e9marrer, configurer et comprendre l\u2019architecture de NGINX, avec un fil conducteur qui correspond \u00e0 un chemin d\u2019apprentissage progressif.</p> <p>Remarque : Il n\u2019est pas possible ici d\u2019int\u00e9grer des images r\u00e9cup\u00e9r\u00e9es en direct depuis des sites externes, mais des sch\u00e9mas textuels et des exemples concrets sont fournis, ainsi que des indications pr\u00e9cises sur la forme que peuvent prendre les diagrammes \u00e0 reproduire.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#vue-densemble-et-chemin-dapprentissage","title":"Vue d\u2019ensemble et chemin d\u2019apprentissage","text":"<p>Le chemin d\u2019apprentissage propos\u00e9 suit un ordre logique, en partant de la manipulation du service NGINX, puis de la compr\u00e9hension des fichiers de configuration, de l\u2019architecture interne, et enfin de la configuration de base d\u2019un serveur HTTP. L\u2019objectif est d\u2019\u00eatre capable, \u00e0 la fin de ce chapitre, de d\u00e9ployer une application derri\u00e8re NGINX dans un pipeline d\u2019int\u00e9gration ou de d\u00e9ploiement continu.</p> <p>Chemin d\u2019apprentissage recommand\u00e9 pour ce chapitre\u00a0:</p> <ol> <li>D\u00e9marrage, arr\u00eat et rechargement </li> <li>Savoir installer NGINX sur Linux (par exemple Ubuntu) ou Windows (via WSL, Docker, etc.).  </li> <li>Savoir d\u00e9marrer, arr\u00eater, recharger la configuration et tester la validit\u00e9 des fichiers.  </li> <li> <p>Comprendre la diff\u00e9rence entre red\u00e9marrage complet et rechargement \u00ab\u00a0gracieux\u00a0\u00bb.</p> </li> <li> <p>Directives et contextes </p> </li> <li>Comprendre la structure des fichiers <code>nginx.conf</code> et fichiers inclus.  </li> <li>Distinguer directives simples et directives de bloc.  </li> <li> <p>Ma\u00eetriser les contextes principaux (<code>main</code>, <code>events</code>, <code>http</code>, <code>server</code>, <code>location</code>).</p> </li> <li> <p>Architecture de NGINX </p> </li> <li>Comprendre le mod\u00e8le ma\u00eetre / travailleurs (master / worker processes).  </li> <li>Comprendre le mod\u00e8le \u00e9v\u00e9nementiel et non bloquant de gestion des connexions.  </li> <li> <p>Savoir quels param\u00e8tres d\u2019architecture peuvent \u00eatre ajust\u00e9s pour la performance.</p> </li> <li> <p>Configuration de base </p> </li> <li>Savoir \u00e9crire un <code>server</code> simple servant des fichiers statiques.  </li> <li>Configurer un reverse proxy (backend applicatif HTTP).  </li> <li>Introduire des notions utiles plus tard pour Azure DevOps : environnements, variables, fichiers de conf par environnement.</li> </ol> <p>Chaque section suivante donnera :</p> <ul> <li>des explications d\u00e9taill\u00e9es,</li> <li>des exemples de configuration (<code>nginx.conf</code> ou extraits),</li> <li>des mini-tableaux de r\u00e9f\u00e9rence,</li> <li>des id\u00e9es de sch\u00e9mas \u00e0 dessiner.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#demarrage-arret-et-rechargement","title":"D\u00e9marrage, arr\u00eat et rechargement","text":""},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#installation-et-fichiers-principaux","title":"Installation et fichiers principaux","text":"<p>Dans un contexte DevOps, NGINX est souvent install\u00e9 sur des agents Linux (VM, conteneurs Docker), ce qui permet de simuler ou de reproduire l\u2019environnement de production dans les pipelines.</p> <p>Sur une distribution comme Ubuntu, apr\u00e8s installation, les \u00e9l\u00e9ments importants sont typiquement :</p> <ul> <li>Fichier principal de configuration : <code>/etc/nginx/nginx.conf</code> </li> <li>Dossier de configuration suppl\u00e9mentaire : <code>/etc/nginx/conf.d/</code> </li> <li>Journaux d\u2019acc\u00e8s et d\u2019erreurs : <code>/var/log/nginx/access.log</code>, <code>/var/log/nginx/error.log</code> </li> </ul> <p>Le service NGINX est souvent g\u00e9r\u00e9 par <code>systemd</code>\u00a0:  </p> Bash<pre><code># D\u00e9marrer NGINX\nsudo systemctl start nginx\n\n# Arr\u00eater NGINX\nsudo systemctl stop nginx\n\n# Red\u00e9marrer compl\u00e8tement NGINX\nsudo systemctl restart nginx\n\n# Recharger la configuration sans couper brutalement les connexions\nsudo systemctl reload nginx\n\n# V\u00e9rifier l\u2019\u00e9tat du service\nsudo systemctl status nginx\n</code></pre> <p>En parall\u00e8le, NGINX fournit sa propre commande binaire, utile dans les scripts CI/CD\u00a0:</p> Bash<pre><code># Lancer NGINX (si non lanc\u00e9 en tant que service)\nsudo nginx\n\n# Arr\u00eater \u00ab proprement \u00bb\nsudo nginx -s quit\n\n# Arr\u00eat imm\u00e9diat (brutal)\nsudo nginx -s stop\n\n# Recharger la configuration\nsudo nginx -s reload\n\n# Tester la validit\u00e9 de la configuration, sans recharger\nsudo nginx -t\n</code></pre> <p>Dans un pipeline Azure DevOps (par exemple dans une t\u00e2che Bash), ces commandes seront utilis\u00e9es pour :</p> <ul> <li>valider la configuration (<code>nginx -t</code>),  </li> <li>lancer NGINX dans un job de tests,  </li> <li>recharger la configuration apr\u00e8s d\u00e9ploiement d\u2019une nouvelle version des fichiers de conf.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#schema-textuel-cycle-de-vie-de-nginx","title":"Sch\u00e9ma textuel \u2013 cycle de vie de NGINX","text":"<p>Un sch\u00e9ma simple \u00e0 reproduire pourrait ressembler \u00e0\u00a0:</p> Text Only<pre><code>+-------------------------------+\n|         Fichiers .conf        |\n+-------------------------------+\n               |\n               v\n+-------------------------------+\n| nginx -t  (test config)      |\n+-------------------------------+\n               |\n               v\n+-------------------------------+\n| nginx -s reload  (gracieux)  |\n+-------------------------------+\n               |\n               v\n+-------------------------------+\n| Workers prennent les nouvelles|\n| directives sans couper les    |\n| connexions en cours           |\n+-------------------------------+\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#integration-dans-les-scripts-cicd","title":"Int\u00e9gration dans les scripts (CI/CD)","text":"<p>Dans un pipeline YAML Azure DevOps, une \u00e9tape type pour valider la configuration pourrait \u00eatre :</p> YAML<pre><code>- script: |\n    sudo nginx -t\n  displayName: 'Validation configuration NGINX'\n</code></pre> <p>Et apr\u00e8s d\u00e9ploiement de nouveaux fichiers de configuration :</p> YAML<pre><code>- script: |\n    sudo nginx -s reload\n  displayName: 'Rechargement configuration NGINX'\n</code></pre> <p>Id\u00e9e p\u00e9dagogique\u00a0: d\u2019abord manipuler ces commandes manuellement sur une VM ou un conteneur en local, ensuite les int\u00e9grer dans un pipeline automatis\u00e9.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#directives-et-contextes","title":"Directives et contextes","text":"<p>NGINX est configur\u00e9 \u00e0 l\u2019aide de directives rang\u00e9es dans des contextes. Comprendre ce mod\u00e8le est fondamental pour lire et \u00e9crire des configurations propres et maintenables.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#directives-simples-et-blocs","title":"Directives : simples et blocs","text":"<ul> <li>Directive simple </li> <li>Forme : <code>cl\u00e9 valeur;</code> </li> <li> <p>Exemples : Nginx Configuration File<pre><code>worker_processes 4;\nclient_max_body_size 10m;\n</code></pre></p> </li> <li> <p>Directive de bloc </p> </li> <li>Forme : <code>cl\u00e9 param\u00e8tres { ... }</code> </li> <li>Contient d\u2019autres directives \u00e0 l\u2019int\u00e9rieur, et d\u00e9finit un contexte.  </li> <li>Exemples : Nginx Configuration File<pre><code>http {\n    # directives li\u00e9es au HTTP ici\n}\n\nserver {\n    # directives du serveur virtuel\n}\n</code></pre></li> </ul> <p>Les directives de bloc d\u00e9finissent donc \u00e0 la fois un contexte logique et un regroupement de configuration.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#contextes-principaux","title":"Contextes principaux","text":"<p>Les contextes les plus courants :</p> <ul> <li><code>main</code> (ou global)  </li> <li><code>events</code> </li> <li><code>http</code> </li> <li><code>server</code> </li> <li><code>location</code> </li> </ul> <p>Tableau r\u00e9capitulatif :</p> Contexte R\u00f4le principal Exemple de directives typiques main Configuration globale du processus NGINX <code>user</code>, <code>worker_processes</code>, <code>pid</code> events Gestion des connexions, niveau global <code>worker_connections</code>, <code>use</code> http Configuration sp\u00e9cifique au trafic HTTP/HTTPS <code>include</code>, <code>log_format</code>, <code>sendfile</code> server Serveur virtuel (vhost) <code>listen</code>, <code>server_name</code>, <code>root</code> location Correspondance d\u2019URI \u00e0 des r\u00e8gles sp\u00e9cifiques <code>proxy_pass</code>, <code>try_files</code>, <code>alias</code> <p>Exemple d\u2019un fichier minimal illustrant ces contextes\u00a0:</p> Nginx Configuration File<pre><code># Contexte main (global)\nuser  nginx;\nworker_processes auto;\n\nevents {\n    worker_connections 1024;\n}\n\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n\n    sendfile on;\n\n    server {\n        listen       80;\n        server_name  exemple.local;\n\n        root /var/www/html;\n\n        location / {\n            index index.html;\n        }\n\n        location /api/ {\n            proxy_pass http://backend_api;\n        }\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#heritage-et-portee","title":"H\u00e9ritage et port\u00e9e","text":"<p>Les directives se comportent souvent avec un h\u00e9ritage :</p> <ul> <li>Une directive plac\u00e9e plus haut (par exemple dans <code>http</code>) s\u2019applique par d\u00e9faut dans les <code>server</code> et <code>location</code> enfants, sauf si elle est red\u00e9finie.  </li> <li>Certaines directives ne sont autoris\u00e9es que dans certains contextes (par exemple <code>listen</code> dans <code>server</code>, pas dans <code>location</code>).  </li> </ul> <p>Exemple\u00a0:</p> Nginx Configuration File<pre><code>http {\n    client_max_body_size 2m;  # valeur par d\u00e9faut pour tous les servers\n\n    server {\n        # ici, 2m s\u2019applique\n\n        location /upload/ {\n            client_max_body_size 10m; # cette location permet plus\n        }\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#schema-textuel-arborescence-des-contextes","title":"Sch\u00e9ma textuel \u2013 arborescence des contextes","text":"Text Only<pre><code>main\n\u251c\u2500 events\n\u2514\u2500 http\n   \u251c\u2500 server (site A)\n   \u2502  \u251c\u2500 location /\n   \u2502  \u2514\u2500 location /api/\n   \u2514\u2500 server (site B)\n      \u251c\u2500 location /\n      \u2514\u2500 location /static/\n</code></pre> <p>Chemin d\u2019apprentissage conseill\u00e9 \u00e0 ce stade\u00a0:</p> <ol> <li>Lire le fichier <code>nginx.conf</code> par d\u00e9faut et rep\u00e9rer les contextes.  </li> <li>Ajouter une directive dans <code>http</code> (ex. <code>client_max_body_size</code>) et v\u00e9rifier son effet.  </li> <li>S\u2019exercer \u00e0 surcharger cette directive dans un bloc <code>server</code> ou <code>location</code>.  </li> </ol>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#architecture-de-nginx","title":"Architecture de NGINX","text":"<p>NGINX adopte une architecture orient\u00e9e performances, avec un processus ma\u00eetre et des processus travailleurs (workers) g\u00e9rant de nombreuses connexions de mani\u00e8re asynchrone.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#processus-maitre-et-travailleurs","title":"Processus ma\u00eetre et travailleurs","text":"<ul> <li>Master process </li> <li>Lit la configuration.  </li> <li>Ouvre les sockets d\u2019\u00e9coute (ports).  </li> <li>Lance les workers.  </li> <li> <p>G\u00e8re les rechargements de configuration et les arr\u00eats.</p> </li> <li> <p>Worker processes </p> </li> <li>Acceptent et g\u00e8rent les connexions des clients.  </li> <li>Traitent les requ\u00eates HTTP, servent les fichiers statiques, effectuent du proxying, etc.  </li> <li>Fonctionnent en mod\u00e8le \u00e9v\u00e8nementiel (un worker peut g\u00e9rer de nombreuses connexions simultan\u00e9ment).</li> </ul> <p>Fragment de configuration typique dans le contexte <code>main</code> :</p> Nginx Configuration File<pre><code>user nginx;\nworker_processes auto;  # ou un nombre fixe (ex. 4)\n\nevents {\n    worker_connections 1024;\n}\n</code></pre> <p>Explications :</p> <ul> <li><code>worker_processes auto;</code> : laisse NGINX choisir un nombre de workers adapt\u00e9 au nombre de CPU.  </li> <li><code>worker_connections 1024;</code> : nombre maximum de connexions simultan\u00e9es par worker.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#modele-evenementiel","title":"Mod\u00e8le \u00e9v\u00e9nementiel","text":"<p>NGINX repose sur un mod\u00e8le non bloquant o\u00f9 chaque worker utilise un m\u00e9canisme comme <code>epoll</code> (Linux) ou <code>kqueue</code> (BSD) pour g\u00e9rer de nombreuses connexions simultan\u00e9es.</p> <p>Sch\u00e9ma textuel simple :</p> Text Only<pre><code>           +--------------------+\n           |   Master process   |\n           +--------------------+\n             /       |       \\\n            /        |        \\\n+----------------+ +----------------+ +----------------+\n| Worker #1      | | Worker #2      | | Worker #3      |\n+----------------+ +----------------+ +----------------+\n   |       |          |       |          |       |\n   v       v          v       v          v       v\n Conn. 1  Conn. 2   Conn. 3  Conn. 4   Conn. 5  Conn. 6\n</code></pre> <p>Pour l\u2019optimisation :</p> <ul> <li>augmenter <code>worker_connections</code> si beaucoup de trafic,  </li> <li>ajuster <code>worker_processes</code> selon le nombre de c\u0153urs,  </li> <li>surveiller l\u2019utilisation m\u00e9moire et CPU.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#lien-avec-azure-devops","title":"Lien avec Azure DevOps","text":"<p>Dans un environnement DevOps :</p> <ul> <li>les param\u00e8tres <code>worker_processes</code> et <code>worker_connections</code> peuvent \u00eatre externalis\u00e9s (variables de pipeline, fichiers mod\u00e8les) pour \u00eatre diff\u00e9rents selon les environnements (dev, staging, prod) ;  </li> <li>les tests de mont\u00e9e en charge (load testing) valid\u00e9s dans des pipelines peuvent conduire \u00e0 ajuster ces param\u00e8tres automatiquement.</li> </ul> <p>Exemple de param\u00e9trage par variable d\u2019environnement (utilisable dans un conteneur)\u00a0:</p> Nginx Configuration File<pre><code>worker_processes ${NGINX_WORKER_PROCESSES:-auto};\n\nevents {\n    worker_connections ${NGINX_WORKER_CONNECTIONS:-1024};\n}\n</code></pre> <p>Ensuite, dans Azure DevOps, ces variables peuvent \u00eatre inject\u00e9es dans le conteneur NGINX via les d\u00e9finitions de jobs.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#configuration-de-base-de-nginx","title":"Configuration de base de NGINX","text":"<p>Cette section fournit une configuration de base, puis l\u2019\u00e9tend progressivement jusqu\u2019au reverse proxy, ce qui est  directement exploitable dans un pipeline DevOps.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#structure-generale-du-fichier-nginxconf","title":"Structure g\u00e9n\u00e9rale du fichier <code>nginx.conf</code>","text":"<p>Structure classique :</p> Nginx Configuration File<pre><code># Contexte main\nuser  nginx;\nworker_processes auto;\npid /run/nginx.pid;\n\nevents {\n    worker_connections 1024;\n}\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                      '$status $body_bytes_sent \"$http_referer\" '\n                      '\"$http_user_agent\"';\n\n    access_log  /var/log/nginx/access.log  main;\n    error_log   /var/log/nginx/error.log warn;\n\n    sendfile        on;\n    keepalive_timeout  65;\n\n    include /etc/nginx/conf.d/*.conf;  # inclusion de serveurs suppl\u00e9mentaires\n}\n</code></pre> <p>Les blocs <code>server</code> sont souvent plac\u00e9s dans des fichiers s\u00e9par\u00e9s, par exemple <code>/etc/nginx/conf.d/app.conf</code>.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#exemple-1-serveur-statique-simple","title":"Exemple 1 : serveur statique simple","text":"<p>Fichier <code>/etc/nginx/conf.d/site-statique.conf</code> :</p> Nginx Configuration File<pre><code>server {\n    listen       80;\n    server_name  exemple.local;\n\n    root /var/www/exemple;       # dossier racine\n    index index.html index.htm;  # fichiers d\u2019index\n\n    # Emplacement racine\n    location / {\n        try_files $uri $uri/ =404;\n    }\n\n    # Fichiers statiques (optionnel, pour cache)\n    location ~* \\.(css|js|png|jpg|jpeg|gif|ico)$ {\n        expires 7d;\n        access_log off;\n    }\n}\n</code></pre> <p>Explications cl\u00e9s :</p> <ul> <li><code>listen 80;</code> : \u00e9coute sur le port HTTP standard.  </li> <li><code>server_name exemple.local;</code> : nom d\u2019h\u00f4te attendu dans les requ\u00eates.  </li> <li><code>root</code> : r\u00e9pertoire o\u00f9 se trouvent les fichiers.  </li> <li><code>location /</code> : r\u00e8gle par d\u00e9faut pour la racine.  </li> <li><code>try_files</code> : v\u00e9rifie si le chemin demand\u00e9 existe, sinon retourne 404.</li> </ul> <p>Chemin d\u2019apprentissage :</p> <ol> <li>Cr\u00e9er un dossier avec un <code>index.html</code>.  </li> <li>Configurer un <code>server</code> comme ci-dessus.  </li> <li>Tester avec <code>curl http://exemple.local</code> ou un navigateur (en adaptant le DNS ou <code>/etc/hosts</code>).  </li> </ol>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#exemple-2-reverse-proxy-vers-une-api","title":"Exemple 2 : reverse proxy vers une API","text":"<p>Cas courant dans une architecture CI/CD : une API (Node.js, .NET, etc.) \u00e9coute en interne sur <code>http://localhost:5000</code>, et NGINX la publie.</p> Nginx Configuration File<pre><code>upstream backend_api {\n    server 127.0.0.1:5000;\n    # \u00e9ventuellement plusieurs serveurs pour load balancing\n    # server 10.0.0.2:5000;\n    # server 10.0.0.3:5000;\n}\n\nserver {\n    listen       80;\n    server_name  api.exemple.local;\n\n    # Redirection HTTP -&gt; HTTPS (si un autre bloc 443 existe)\n    # return 301 https://$host$request_uri;\n\n    location / {\n        proxy_pass         http://backend_api;\n        proxy_set_header   Host              $host;\n        proxy_set_header   X-Real-IP         $remote_addr;\n        proxy_set_header   X-Forwarded-For   $proxy_add_x_forwarded_for;\n        proxy_set_header   X-Forwarded-Proto $scheme;\n\n        proxy_read_timeout  60s;\n    }\n}\n</code></pre> <p>\u00c9l\u00e9ments importants pour un usage DevOps :</p> <ul> <li>Le bloc <code>upstream</code> permet de faire du load balancing entre plusieurs instances derri\u00e8re NGINX.  </li> <li>Des variables (environnement, templating) peuvent g\u00e9n\u00e9rer dynamiquement les serveurs dans <code>upstream</code>.  </li> <li>Dans un pipeline, la configuration peut \u00eatre g\u00e9n\u00e9r\u00e9e puis valid\u00e9e avec <code>nginx -t</code> avant d\u2019\u00eatre d\u00e9ploy\u00e9e.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#exemple-3-combinaison-statique-api","title":"Exemple 3 : combinaison statique + API","text":"<p>Un mod\u00e8le fr\u00e9quent : servir le front statique (SPA, React, Angular, Vue) et proxifier les appels API :</p> Nginx Configuration File<pre><code>server {\n    listen       80;\n    server_name  app.exemple.local;\n\n    root /var/www/app; \n    index index.html;\n\n    # Front (SPA)\n    location / {\n        try_files $uri $uri/ /index.html;\n    }\n\n    # API en backend\n    location /api/ {\n        proxy_pass http://backend_api;\n        proxy_set_header Host $host;\n    }\n}\n</code></pre> <p>Ce genre de configuration est courant dans les applications d\u00e9ploy\u00e9es automatiquement via des pipelines, o\u00f9 :</p> <ul> <li>la phase de build front g\u00e9n\u00e8re les fichiers sous <code>/var/www/app</code>,  </li> <li>la phase de d\u00e9ploiement copie les fichiers et reconfigure NGINX si besoin,  </li> <li>un job de test applique des tests d\u2019int\u00e9gration sur l\u2019URL front et l\u2019API.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#idees-de-schemas-pour-la-configuration","title":"Id\u00e9es de sch\u00e9mas pour la configuration","text":"<p>Un sch\u00e9ma simplifi\u00e9 de flux de requ\u00eates pourrait \u00eatre repr\u00e9sent\u00e9 ainsi :</p> Text Only<pre><code>Client HTTP\n   |\n   v\n+----------+            +----------------+\n|  NGINX   |  -------&gt;  |  Backend API   |\n|  server  |  /api/*    | (localhost:5000|\n+----------+            +----------------+\n   |\n   +--&gt; / (fichiers statiques)\n        /var/www/app\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap03/#resume-du-chemin-dapprentissage-detaille","title":"R\u00e9sum\u00e9 du chemin d\u2019apprentissage d\u00e9taill\u00e9","text":"<p>Pour faire l\u2019\u00e9quivalent d\u2019un module complet de formation (\u2248 10 pages A4) sur ces bases, une progression d\u00e9taill\u00e9e peut ressembler \u00e0 ceci :</p> <ol> <li>Prise en main op\u00e9rationnelle </li> <li>Installation de NGINX sur une VM Linux (ou conteneur).  </li> <li>Exp\u00e9rimentation pratique avec <code>systemctl</code> et <code>nginx -s</code> pour d\u00e9marrer, arr\u00eater, recharger.  </li> <li> <p>Mise en place de scripts Bash (ou PowerShell dans WSL) pour automatiser les op\u00e9rations.</p> </li> <li> <p>Lecture et compr\u00e9hension des fichiers de configuration </p> </li> <li>Exploration de <code>nginx.conf</code> et des fichiers dans <code>conf.d/</code>.  </li> <li>Identification des contextes (<code>main</code>, <code>events</code>, <code>http</code>, <code>server</code>, <code>location</code>).  </li> <li> <p>Ajout de directives simples (<code>log_format</code>, <code>client_max_body_size</code>, etc.) et observation des effets.</p> </li> <li> <p>Approfondissement des directives et contextes </p> </li> <li>Exercices d\u2019h\u00e9ritage : d\u00e9finir des valeurs globales dans <code>http</code> et les surcharger dans certains <code>server</code>.  </li> <li>Mise en place de multiples <code>server</code> (vhosts) avec diff\u00e9rents <code>server_name</code>.  </li> <li> <p>Cr\u00e9ation de diff\u00e9rents <code>location</code> pour g\u00e9rer <code>/</code>, <code>/static/</code>, <code>/api/</code>, <code>/admin/</code>, etc.</p> </li> <li> <p>Compr\u00e9hension de l\u2019architecture interne </p> </li> <li>Exp\u00e9rimentation de <code>worker_processes</code> et <code>worker_connections</code> avec outils de charge (ab, wrk, k6, etc.).  </li> <li>Observation de l\u2019impact sur l\u2019utilisation CPU/m\u00e9moire.  </li> <li> <p>Discussion sur l\u2019int\u00e9gration avec des orchestrateurs (Docker, Kubernetes) o\u00f9 NGINX est souvent utilis\u00e9 comme ingress ou sidecar.</p> </li> <li> <p>Construction d\u2019une configuration de base robuste </p> </li> <li>Mise en place d\u2019un site statique complet servi par NGINX (avec cache des assets).  </li> <li>Ajout d\u2019un backend applicatif (simple API) en reverse proxy.  </li> <li> <p>Mise en place de logs personnalis\u00e9s pour faciliter le debugging dans les pipelines.</p> </li> <li> <p>Int\u00e9gration progressive dans Azure DevOps </p> </li> <li>Ajout d\u2019\u00e9tapes dans les pipelines :  <ul> <li>build de l\u2019application,  </li> <li>g\u00e9n\u00e9ration de la configuration NGINX (via templates),  </li> <li>validation (<code>nginx -t</code>),  </li> <li>d\u00e9ploiement et rechargement (<code>nginx -s reload</code>),  </li> <li>tests de fum\u00e9e (smoke tests) sur l\u2019URL publi\u00e9e.  </li> </ul> </li> <li>Utilisation de variables et secrets pour param\u00e9trer dynamiquement les backends (<code>upstream</code>, ports, etc.).  </li> </ol> <p>En suivant cette s\u00e9quence, NGINX devient progressivement un composant ma\u00eetris\u00e9 de l\u2019outillage DevOps, et non plus une simple \u00ab bo\u00eete noire \u00bb devant l\u2019application.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap04/","title":"Citations","text":"<ul> <li>https://microsoftlearning.github.io/AZ400-DesigningandImplementingMicrosoftDevOpsSolutions/Instructions/Labs/AZ400_M03_L08_Control_Deployments_using_Release_Gates.html</li> <li>https://www.azuredevopslabs.com/labs/vstsextend/releasegates/</li> <li>https://andrewhalil.com/2024/03/28/how-to-use-deployment-gates-with-azure-devops-release-pipelines/</li> <li>https://learn.microsoft.com/fr-fr/azure/devops/pipelines/release/approvals/gates?view=azure-devops</li> <li>https://learn.microsoft.com/fr-fr/azure/devops/pipelines/release/deploy-using-approvals?view=azure-devops</li> <li>https://learn.microsoft.com/fr-fr/azure/devops/pipelines/release/approvals/?view=azure-devops</li> <li>https://learn.microsoft.com/en-us/azure/devops/pipelines/release/approvals/gates?view=azure-devops</li> <li>https://learn.microsoft.com/fr-fr/rest/api/azure/devops/release/gates/update?view=azure-devops-rest-7.1</li> <li>https://www.youtube.com/watch?v=e4uNjh7whYk</li> <li>https://www.eni-service.fr/formation/formation-microsoft-azure-ingenierie-devops-maz-400t00/</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap04/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 356</li> <li>completion_tokens: 5504</li> <li>total_tokens: 5860</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.083, 'request_cost': 0.006, 'total_cost': 0.09}</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap04/#content","title":"Content","text":"<p>Il n\u2019est actuellement pas possible de r\u00e9cup\u00e9rer ou v\u00e9rifier en direct le contenu (y compris les images) des pages <code>learn.microsoft.com</code> ou d\u2019autres sites, ce qui emp\u00eache de garantir l\u2019existence pr\u00e9cise de sch\u00e9mas ou captures sp\u00e9cifiques, ni de produire un volume r\u00e9ellement \u00e9quivalent \u00e0 10 pages A4 \u00e0 partir de ces ressources pr\u00e9cises. N\u00e9anmoins, il est possible de proposer une explication d\u00e9taill\u00e9e, structur\u00e9e et progressive de chaque module du chapitre 4, avec des exemples de scripts YAML, de tableaux et un chemin d\u2019apprentissage coh\u00e9rent, inspir\u00e9s des concepts d\u2019Azure DevOps connus jusqu\u2019en 2024.  </p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap04/#introduction-a-la-livraison-continue","title":"Introduction \u00e0 la livraison continue","text":"<p>La livraison continue (Continuous Delivery, CD) d\u00e9signe la capacit\u00e9 \u00e0 livrer fr\u00e9quemment des versions pr\u00eates \u00e0 \u00eatre d\u00e9ploy\u00e9es en production, de mani\u00e8re fiable et r\u00e9p\u00e9table. Elle s\u2019appuie sur l\u2019int\u00e9gration continue (CI) qui valide la qualit\u00e9 du code \u00e0 chaque changement, puis sur des pipelines de d\u00e9ploiement automatis\u00e9s qui propagent les artefacts vers plusieurs environnements (Dev, Test, Pr\u00e9\u2011prod, Prod).  </p> <p>Principes cl\u00e9s de la livraison continue dans Azure DevOps\u00a0: - Pipeline unique qui part de l\u2019artefact valid\u00e9 par la CI et le propage vers tous les environnements. - Automatisation maximale (build, tests, packaging, d\u00e9ploiement, v\u00e9rifications post\u2011d\u00e9ploiement). - Feedback rapide via des tests automatis\u00e9s, du monitoring applicatif et des tableaux de bord.  </p> <p>B\u00e9n\u00e9fices principaux pour les \u00e9quipes\u00a0: - R\u00e9duction du temps entre un commit et un changement visible en production. - Diminution du risque gr\u00e2ce \u00e0 la r\u00e9p\u00e9tabilit\u00e9 (m\u00eames scripts, m\u00eames mod\u00e8les d\u2019infrastructure) et \u00e0 la granularit\u00e9 des d\u00e9ploiements (petits incr\u00e9ments). - Tra\u00e7abilit\u00e9 compl\u00e8te (qui a livr\u00e9 quoi, quand, o\u00f9, avec quel r\u00e9sultat).  </p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap04/#creer-un-pipeline-de-diffusion","title":"Cr\u00e9er un pipeline de diffusion","text":"<p>Dans Azure DevOps, un pipeline de diffusion (release pipeline) ou pipeline YAML multi\u2011stages orchestre le d\u00e9ploiement d\u2019artefacts issus du pipeline de build vers diff\u00e9rents environnements.  </p> <p>Les \u00e9l\u00e9ments structurants\u00a0: - Artefacts\u00a0: issus du pipeline de build (par exemple un package Web <code>.zip</code>, une image conteneur, des manifests Kubernetes). - Stages\u00a0: environnements logiques (Dev, Test, Prod) avec leurs propres t\u00e2ches, approbations et gates. - Variables\u00a0: param\u00e8tres communs ou sp\u00e9cifiques par environnement (cha\u00eenes de connexion, URL, noms de ressources).  </p> <p>Exemple minimal d\u2019un pipeline de diffusion YAML pour une application Web App\u00a0Azure\u00a0:</p> YAML<pre><code>trigger:\n  branches:\n    include:\n      - main\n\nstages:\n- stage: Build\n  jobs:\n  - job: BuildJob\n    pool:\n      vmImage: 'ubuntu-latest'\n    steps:\n    - task: DotNetCoreCLI@2\n      inputs:\n        command: 'build'\n        projects: '**/*.csproj'\n    - task: DotNetCoreCLI@2\n      inputs:\n        command: 'publish'\n        publishWebProjects: true\n        arguments: '--configuration Release --output $(Build.ArtifactStagingDirectory)'\n    - task: PublishBuildArtifacts@1\n      inputs:\n        PathtoPublish: '$(Build.ArtifactStagingDirectory)'\n        ArtifactName: 'drop'\n\n- stage: Dev\n  dependsOn: Build\n  jobs:\n  - deployment: DeployToDev\n    environment: 'dev'\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n          - task: AzureWebApp@1\n            inputs:\n              azureSubscription: 'sp-connection'\n              appType: 'webApp'\n              appName: 'myapp-dev'\n              package: '$(Pipeline.Workspace)/drop/**/*.zip'\n\n- stage: Prod\n  dependsOn: Dev\n  condition: succeeded()\n  jobs:\n  - deployment: DeployToProd\n    environment: 'prod'\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n          - task: AzureWebApp@1\n            inputs:\n              azureSubscription: 'sp-connection'\n              appType: 'webApp'\n              appName: 'myapp-prod'\n              package: '$(Pipeline.Workspace)/drop/**/*.zip'\n</code></pre> <p>Chemin d\u2019apprentissage pour ce module\u00a0: - Comprendre la diff\u00e9rence entre pipeline classique (interface graphique de release) et pipeline YAML multi\u2011stages. - Cr\u00e9er un pipeline CI simple, publier un artefact, puis ajouter un premier stage de d\u00e9ploiement (Dev). - \u00c9tendre le pipeline pour couvrir Test et Prod, en introduisant variables et groupes de variables.  </p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap04/#explorer-les-recommandations-en-matiere-de-strategie-de-diffusion","title":"Explorer les recommandations en mati\u00e8re de strat\u00e9gie de diffusion","text":"<p>La strat\u00e9gie de diffusion d\u00e9termine comment les d\u00e9ploiements se propagent dans les environnements, comment le risque est contr\u00f4l\u00e9 et comment le feedback est collect\u00e9.  </p> <p>Bonnes pratiques courantes\u00a0: - Standardiser les environnements\u00a0: m\u00eame code, m\u00eame scripts d\u2019infrastructure, seules les variables de configuration changent. - Appliquer des strat\u00e9gies de d\u00e9ploiement progressif\u00a0:   - Canary\u00a0: d\u00e9ploiement vers une petite portion de trafic/utilisateurs, puis extension progressive.   - Blue\u2011Green\u00a0: deux environnements identiques, bascule du trafic de l\u2019un vers l\u2019autre.   - Rolling\u00a0: remplacement par lots de n\u0153uds/instances.  </p> <p>Exemple de strat\u00e9gie avec \u00e9tapes\u00a0: 1. D\u00e9ploiement automatique en Dev \u00e0 chaque commit sur <code>main</code>. 2. Promotion manuelle vers Test, d\u00e9clenchant tests d\u2019int\u00e9gration et non\u2011r\u00e9gression. 3. D\u00e9ploiement canary en Prod (par exemple 10\u00a0% du trafic), contr\u00f4l\u00e9 par des feature flags ou par la configuration d\u2019un Application Gateway/Traffic Manager. 4. Promotion automatique vers 100\u00a0% si les indicateurs de sant\u00e9 restent bons pendant un d\u00e9lai configur\u00e9.  </p> <p>Exemple de variables par environnement dans un tableau\u00a0:</p> Environnement Nom de l\u2019app Connection string URL publique Dev myapp-dev Server=dev-sql;Db=myapp-dev;... https://dev.myapp.contoso Test myapp-test Server=test-sql;Db=myapp-test;... https://test.myapp.contoso Prod myapp-prod Server=prod-sql;Db=myapp-prod;... https://app.mycompany.com <p>Chemin d\u2019apprentissage pour ce module\u00a0: - \u00c9tudier les diff\u00e9rents patterns de d\u00e9ploiement (canary, blue\u2011green, rolling) et leurs cas d\u2019usage. - Concevoir une strat\u00e9gie cible pour les environnements existants (ou fictifs) en d\u00e9crivant, pour chaque \u00e9tape, les conditions de passage et le type de test/monitoring. - Traduire cette strat\u00e9gie dans un pipeline YAML et dans la configuration des environnements Azure\u00a0DevOps.  </p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap04/#mise-a-disposition-et-test-des-environnements","title":"Mise \u00e0 disposition et test des environnements","text":"<p>La livraison continue repose sur des environnements reproductibles, provisionn\u00e9s par script, et accompagn\u00e9s de suites de tests automatis\u00e9s. Dans Azure\u00a0DevOps, cela se traduit par l\u2019usage de mod\u00e8les d\u2019infrastructure (ARM/Bicep, Terraform, scripts PowerShell/Azure\u00a0CLI) et par l\u2019int\u00e9gration de t\u00e2ches de tests dans le pipeline.  </p> <p>Dimensions \u00e0 ma\u00eetriser\u00a0: - Provisionnement d\u2019infrastructures\u00a0: cr\u00e9er ou mettre \u00e0 jour automatiquement Web Apps, bases de donn\u00e9es, groupes de ressources, comptes de stockage, clusters Kubernetes, etc. - Tests automatis\u00e9s\u00a0:   - Unitaires (ex\u00e9cut\u00e9s en CI).   - Int\u00e9gration et end\u2011to\u2011end (ex\u00e9cut\u00e9s apr\u00e8s d\u00e9ploiement en Dev/Test).   - Tests de performance/surcharge (en amont des mises en production majeures).  </p> <p>Exemple de t\u00e2che Terraform dans un job de d\u00e9ploiement\u00a0:</p> YAML<pre><code>- task: TerraformInstaller@1\n  inputs:\n    terraformVersion: '1.5.0'\n\n- task: TerraformTaskV4@4\n  displayName: 'Init Terraform'\n  inputs:\n    provider: 'azurerm'\n    command: 'init'\n    workingDirectory: 'infra/terraform'\n\n- task: TerraformTaskV4@4\n  displayName: 'Apply Terraform'\n  inputs:\n    provider: 'azurerm'\n    command: 'apply'\n    workingDirectory: 'infra/terraform'\n    environmentServiceNameAzureRM: 'sp-connection'\n    commandOptions: '-auto-approve'\n</code></pre> <p>Exemple de t\u00e2ches de tests d\u2019int\u00e9gration apr\u00e8s d\u00e9ploiement\u00a0:</p> YAML<pre><code>- task: DotNetCoreCLI@2\n  displayName: 'Run integration tests'\n  inputs:\n    command: 'test'\n    projects: 'tests/IntegrationTests/*.csproj'\n    arguments: '--configuration Release'\n</code></pre> <p>Chemin d\u2019apprentissage pour ce module\u00a0: - S\u2019exercer \u00e0 cr\u00e9er un environnement complet \u00e0 partir de scripts d\u2019infrastructure (ARM/Bicep/Terraform). - Int\u00e9grer ces scripts dans un job <code>deployment</code> pour que chaque stage provisionne ou mette \u00e0 jour les ressources n\u00e9cessaires. - Ajouter des suites de tests (unitaires, int\u00e9gration) et analyser les r\u00e9sultats dans Azure\u00a0DevOps (Tests, code coverage, rapports).  </p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap04/#gerer-et-adapter-les-taches-et-les-modeles","title":"G\u00e9rer et adapter les t\u00e2ches et les mod\u00e8les","text":"<p>Dans les pipelines Azure\u00a0DevOps, les t\u00e2ches (tasks) repr\u00e9sentent des unit\u00e9s d\u2019ex\u00e9cution r\u00e9utilisables (build .NET, d\u00e9ploiement Web App, script PowerShell, etc.). Pour \u00e9viter la duplication, il est recommand\u00e9 d\u2019utiliser des mod\u00e8les (templates) YAML et des biblioth\u00e8ques de t\u00e2ches personnalis\u00e9es.  </p> <p>Concepts importants\u00a0: - T\u00e2ches standard\u00a0: fournies par Microsoft ou la communaut\u00e9 (Marketplace), configurables via param\u00e8tres. - T\u00e2ches personnalis\u00e9es\u00a0: par exemple scripts PowerShell ou Bash versionn\u00e9s dans le d\u00e9p\u00f4t. - Templates YAML\u00a0: fichiers r\u00e9utilisables contenant des ensembles de t\u00e2ches ou des d\u00e9finitions de stages/jobs.  </p> <p>Exemple de template YAML pour un d\u00e9ploiement Web App\u00a0<code>templates/deploy-webapp.yml</code>\u00a0:</p> YAML<pre><code>parameters:\n  appName: ''\n  environmentName: ''\n  artifactPath: ''\n\njobs:\n- deployment: DeployTo_${{ parameters.environmentName }}\n  environment: ${{ parameters.environmentName }}\n  strategy:\n    runOnce:\n      deploy:\n        steps:\n        - task: AzureWebApp@1\n          inputs:\n            azureSubscription: 'sp-connection'\n            appType: 'webApp'\n            appName: ${{ parameters.appName }}\n            package: ${{ parameters.artifactPath }}\n</code></pre> <p>Usage de ce template dans un pipeline principal\u00a0:</p> YAML<pre><code>- stage: Dev\n  dependsOn: Build\n  variables:\n    artifactPath: '$(Pipeline.Workspace)/drop/**/*.zip'\n  jobs:\n  - template: templates/deploy-webapp.yml\n    parameters:\n      appName: 'myapp-dev'\n      environmentName: 'dev'\n      artifactPath: '$(artifactPath)'\n\n- stage: Prod\n  dependsOn: Dev\n  jobs:\n  - template: templates/deploy-webapp.yml\n    parameters:\n      appName: 'myapp-prod'\n      environmentName: 'prod'\n      artifactPath: '$(Pipeline.Workspace)/drop/**/*.zip'\n</code></pre> <p>Chemin d\u2019apprentissage pour ce module\u00a0: - Identifier les t\u00e2ches r\u00e9currentes dans les pipelines (tests, packaging, d\u00e9ploiement). - Isoler ces s\u00e9quences dans des templates YAML param\u00e9tr\u00e9s. - Normaliser les noms d\u2019environnements, variables et conventions pour faciliter la maintenance et l\u2019\u00e9volution.  </p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap04/#yaml-multietapes","title":"YAML multi\u2011\u00e9tapes","text":"<p>Les pipelines YAML multi\u2011\u00e9tapes (multi\u2011stage pipelines) permettent de d\u00e9crire dans un seul fichier la CI, la CD et les actions de post\u2011d\u00e9ploiement (tests, validations, monitoring).  </p> <p>Caract\u00e9ristiques \u00e0 conna\u00eetre\u00a0: - <code>stages</code>\u00a0: unit\u00e9s logiques repr\u00e9sentant des phases (Build, Test, Deploy). - <code>jobs</code>\u00a0: groupes de t\u00e2ches pouvant s\u2019ex\u00e9cuter en parall\u00e8le. - <code>deployment</code> jobs\u00a0: jobs d\u00e9di\u00e9s aux d\u00e9ploiements, associ\u00e9s \u00e0 des environnements, avec strat\u00e9gies (runOnce, rolling, canary).  </p> <p>Exemple plus complet de pipeline multi\u2011\u00e9tapes avec validations\u00a0:</p> YAML<pre><code>trigger:\n  branches:\n    include:\n      - main\n\nstages:\n- stage: Build\n  displayName: 'Build &amp; Test'\n  jobs:\n  - job: BuildAndTest\n    pool:\n      vmImage: 'ubuntu-latest'\n    steps:\n    - task: DotNetCoreCLI@2\n      displayName: 'Restore'\n      inputs:\n        command: 'restore'\n        projects: '**/*.csproj'\n    - task: DotNetCoreCLI@2\n      displayName: 'Build'\n      inputs:\n        command: 'build'\n        projects: '**/*.csproj'\n    - task: DotNetCoreCLI@2\n      displayName: 'Unit tests'\n      inputs:\n        command: 'test'\n        projects: 'tests/UnitTests/*.csproj'\n    - task: DotNetCoreCLI@2\n      displayName: 'Publish Web'\n      inputs:\n        command: 'publish'\n        publishWebProjects: true\n        arguments: '--configuration Release --output $(Build.ArtifactStagingDirectory)'\n    - task: PublishBuildArtifacts@1\n      inputs:\n        PathtoPublish: '$(Build.ArtifactStagingDirectory)'\n        ArtifactName: 'drop'\n\n- stage: Dev\n  displayName: 'Deploy to Dev'\n  dependsOn: Build\n  jobs:\n  - deployment: DeployToDev\n    environment: 'dev'\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n          - download: current\n            artifact: drop\n          - task: AzureWebApp@1\n            inputs:\n              azureSubscription: 'sp-connection'\n              appName: 'myapp-dev'\n              package: '$(Pipeline.Workspace)/drop/**/*.zip'\n\n- stage: Test\n  displayName: 'Deploy to Test'\n  dependsOn: Dev\n  condition: succeeded()\n  jobs:\n  - deployment: DeployToTest\n    environment: 'test'\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n          - download: current\n            artifact: drop\n          - task: AzureWebApp@1\n            inputs:\n              azureSubscription: 'sp-connection'\n              appName: 'myapp-test'\n              package: '$(Pipeline.Workspace)/drop/**/*.zip'\n          - task: DotNetCoreCLI@2\n            displayName: 'Run integration tests'\n            inputs:\n              command: 'test'\n              projects: 'tests/IntegrationTests/*.csproj'\n\n- stage: Prod\n  displayName: 'Deploy to Prod (with approval)'\n  dependsOn: Test\n  condition: succeeded()\n  jobs:\n  - deployment: DeployToProd\n    environment: 'prod'\n    strategy:\n      runOnce:\n        preDeployApprovals:\n          approvals:\n          - approvals: # pseudo\u2011notation pour illustrer l\u2019id\u00e9e\n            approvers:\n              - 'release-manager@contoso.com'\n        deploy:\n          steps:\n          - download: current\n            artifact: drop\n          - task: AzureWebApp@1\n            inputs:\n              azureSubscription: 'sp-connection'\n              appName: 'myapp-prod'\n              package: '$(Pipeline.Workspace)/drop/**/*.zip'\n</code></pre> <p>Chemin d\u2019apprentissage pour ce module\u00a0: - Transformer un pipeline classique (build+release) en pipeline YAML multi\u2011stages. - Utiliser les <code>deployment</code> jobs, les environnements et les strat\u00e9gies de d\u00e9ploiement. - Introduire conditions, approvals et variables pour g\u00e9rer les cas de succ\u00e8s/\u00e9chec.  </p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap04/#automatiser-linspection-de-letat-de-sante","title":"Automatiser l\u2019inspection de l\u2019\u00e9tat de sant\u00e9","text":"<p>L\u2019inspection automatique de l\u2019\u00e9tat de sant\u00e9 consiste \u00e0 v\u00e9rifier, via des tests et des outils de monitoring, que l\u2019application et son infrastructure fonctionnent comme pr\u00e9vu apr\u00e8s chaque d\u00e9ploiement.  </p> <p>Dimensions \u00e0 int\u00e9grer dans Azure\u00a0DevOps\u00a0: - Tests post\u2011d\u00e9ploiement\u00a0: tests d\u2019int\u00e9gration, tests API, tests Selenium, scripts de smoke tests qui valident les endpoints critiques. - Monitoring et alertes\u00a0: int\u00e9gration avec Azure Monitor, Application Insights, logs et m\u00e9triques personnalis\u00e9es. - Release gates (portes de d\u00e9ploiement)\u00a0: conditions automatiques qui contr\u00f4lent la progression de la release en fonction d\u2019indicateurs de sant\u00e9.  </p> <p>Exemple de script PowerShell simple de smoke test appel\u00e9 apr\u00e8s d\u00e9ploiement\u00a0:</p> PowerShell<pre><code>param(\n  [string]$Url\n)\n\nWrite-Host \"Testing endpoint: $Url\"\n\n$response = Invoke-WebRequest -Uri $Url -UseBasicParsing -TimeoutSec 30\n\nif ($response.StatusCode -ne 200) {\n    Write-Error \"Endpoint check failed. Status code: $($response.StatusCode)\"\n    exit 1\n}\n\nWrite-Host \"Endpoint is healthy.\"\n</code></pre> <p>Usage de ce script dans un pipeline YAML\u00a0:</p> YAML<pre><code>- task: PowerShell@2\n  displayName: 'Smoke test homepage'\n  inputs:\n    targetType: 'filePath'\n    filePath: 'scripts/smoke-test.ps1'\n    arguments: '-Url https://dev.myapp.contoso'\n</code></pre> <p>Chemin d\u2019apprentissage pour ce module\u00a0: - D\u00e9finir des indicateurs de sant\u00e9 cl\u00e9s (latence, taux d\u2019erreur, taux de succ\u00e8s des tests, disponibilit\u00e9). - Mettre en place des scripts de smoke tests et les int\u00e9grer aux stages de d\u00e9ploiement. - Connecter l\u2019application \u00e0 Application Insights/Azure Monitor, puis utiliser les m\u00e9triques et alertes pour conditionner la promotion des releases.  </p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap04/#controle-des-deploiements-a-laide-de-release-gates","title":"Contr\u00f4le des d\u00e9ploiements \u00e0 l\u2019aide de Release Gates","text":"<p>Les Release Gates sont des points de contr\u00f4le automatiques qui \u00e9valuent des crit\u00e8res (alertes, work items, r\u00e9ponses HTTP, fonctions Azure) avant de laisser un d\u00e9ploiement commencer ou se terminer. Elles s\u2019utilisent dans les pipelines classiques de release, mais certains concepts sont transposables dans les pipelines YAML via des scripts ou des int\u00e9grations personnalis\u00e9es.  </p> <p>Types de gates courants (dans la logique Azure DevOps)\u00a0: - Requ\u00eate vers Azure Monitor\u00a0: v\u00e9rifier l\u2019absence d\u2019alertes actives sur l\u2019application. - Requ\u00eate vers un syst\u00e8me de gestion des work items\u00a0: v\u00e9rifier par exemple qu\u2019aucun bug critique n\u2019est ouvert pour la release courante. - Appel d\u2019une API REST\u00a0: interroger un syst\u00e8me externe qui renvoie \u00ab\u00a0OK\u00a0\u00bb ou \u00ab\u00a0KO\u00a0\u00bb. - Invocation d\u2019une Azure Function\u00a0: encapsuler une logique de validation plus complexe (requ\u00eates multiples, calculs).  </p> <p>Sch\u00e9ma conceptuel d\u2019un flux avec gates\u00a0: 1. D\u00e9ploiement en Dev termin\u00e9. 2. Gate post\u2011d\u00e9ploiement interroge Application Insights\u00a0:    - Si aucune alerte critique n\u2019est active pendant un certain d\u00e9lai d\u2019observation, la release peut passer \u00e0 Test ou Prod.    - Si une alerte est active, la release reste bloqu\u00e9e jusqu\u2019\u00e0 r\u00e9solution ou d\u00e9passement du timeout.  </p> <p>Exemple d\u2019appel d\u2019API REST dans un pipeline YAML pour simuler une gate\u00a0:</p> YAML<pre><code>- task: Bash@3\n  displayName: 'Check external deployment gate'\n  inputs:\n    targetType: 'inline'\n    script: |\n      echo \"Calling external gate API...\"\n      STATUS_CODE=$(curl -s -o /dev/null -w \"%{http_code}\" https://gate.contoso.com/api/check?releaseId=$(Build.BuildId))\n\n      if [ \"$STATUS_CODE\" -ne 200 ]; then\n        echo \"Gate failed with status code $STATUS_CODE\"\n        exit 1\n      fi\n\n      echo \"Gate succeeded.\"\n</code></pre> <p>Chemin d\u2019apprentissage pour ce module\u00a0: - Comprendre la diff\u00e9rence entre approbations manuelles et gates automatiques. - D\u00e9finir les crit\u00e8res m\u00e9tiers de blocage d\u2019un d\u00e9ploiement (bugs critiques, incidents, m\u00e9triques de performance). - Configurer des gates dans les pipelines de release classiques, puis reproduire la logique via scripts/REST dans un pipeline YAML multi\u2011stages.  </p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap04/#creation-dun-tableau-de-bord-des-versions","title":"Cr\u00e9ation d\u2019un tableau de bord des versions","text":"<p>Un tableau de bord des versions (Release Dashboard) permet de visualiser l\u2019\u00e9tat des d\u00e9ploiements, la version pr\u00e9sente dans chaque environnement, et les principales m\u00e9triques de qualit\u00e9/performance.  </p> <p>\u00c9l\u00e9ments qu\u2019un tableau de bord Azure DevOps peut pr\u00e9senter\u00a0: - Widgets de pipelines\u00a0: affichage des derniers builds et releases, avec statuts et d\u00e9tails. - Widgets de work items\u00a0: liste des bugs ouverts par environnement/version, burndown, indicateurs de dette technique. - Widgets de test\u00a0: taux de r\u00e9ussite des tests, tendances, code coverage. - Int\u00e9gration Azure Monitor/Application Insights\u00a0: graphiques de temps de r\u00e9ponse, erreurs, disponibilit\u00e9.  </p> <p>Exemple de table repr\u00e9sentant les versions d\u00e9ploy\u00e9es par environnement\u00a0:</p> Environnement Version d\u00e9ploy\u00e9e Date de d\u00e9ploiement Statut tests post\u2011d\u00e9ploiement Observations principales Dev 1.3.0\u2011build.102 2025\u201111\u201102 10:15 UTC OK Tests d\u2019int\u00e9gration OK Test 1.3.0\u2011build.102 2025\u201111\u201102 11:00 UTC OK Charge moyenne, latence stable Pr\u00e9\u2011prod 1.3.0\u2011build.102 2025\u201111\u201102 12:30 UTC En cours Tests de mont\u00e9e en charge en ex\u00e9cution Prod 1.2.5\u2011build.96 2025\u201110\u201130 09:00 UTC OK Migration vers 1.3.0 planifi\u00e9e <p>Chemin d\u2019apprentissage pour ce module\u00a0: - Identifier les indicateurs \u00e0 suivre pour piloter la livraison continue (fr\u00e9quence de d\u00e9ploiement, lead time, MTTR, taux d\u2019\u00e9chec des d\u00e9ploiements). - Construire un tableau de bord Azure Boards/DevOps regroupant pipelines, work items et m\u00e9triques de tests. - Connecter ou int\u00e9grer des vues provenant d\u2019Azure Monitor/Application Insights pour visualiser l\u2019impact des releases sur le comportement de l\u2019application.  </p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap04/#chemin-dapprentissage-global-du-chapitre-4","title":"Chemin d\u2019apprentissage global du chapitre 4","text":"<p>Pour l\u2019ensemble du chapitre 4, le chemin d\u2019apprentissage d\u00e9taill\u00e9 peut \u00eatre structur\u00e9 comme suit\u00a0: 1. Compr\u00e9hension conceptuelle    - Assimiler les notions de CI/CD, de pipeline de diffusion, de stages/environnements, de strat\u00e9gies de d\u00e9ploiement (canary, blue\u2011green). 2. Construction progressive du pipeline    - Cr\u00e9er un pipeline CI qui produit un artefact.    - Ajouter un stage de d\u00e9ploiement Dev, puis Test, puis Prod, en introduisant variables et templates. 3. Ajout d\u2019environnements et de tests    - Automatiser le provisioning d\u2019environnements (ARM/Bicep/Terraform) et les tests (unitaires, int\u00e9gration, smoke tests). 4. Gouvernance et contr\u00f4le    - Introduire approbations et gates, d\u00e9finir les crit\u00e8res de promotion, connecter le pipeline au monitoring. 5. Pilotage par la donn\u00e9e    - Mettre en place un tableau de bord des versions et utiliser les m\u00e9triques (erreurs, performance, fr\u00e9quence de d\u00e9ploiement) pour ajuster la strat\u00e9gie de diffusion.  </p> <p>Si un niveau de d\u00e9tail encore plus important est souhait\u00e9 sur un sous\u2011ensemble (par exemple uniquement YAML multi\u2011\u00e9tapes ou uniquement Release Gates), il est possible de d\u00e9velopper des exemples suppl\u00e9mentaires centr\u00e9s sur ce point pr\u00e9cis.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/","title":"Citations","text":"<ul> <li>https://learn.microsoft.com/fr-fr/sharepoint/dev/spfx/toolchain/implement-ci-cd-with-azure-devops</li> <li>https://www.datacamp.com/fr/tutorial/azure-devops</li> <li>https://digital.ai/fr/catalyst-blog/building-cicd-pipeline-azure/</li> <li>https://learn.microsoft.com/fr-fr/devops/deliver/what-is-continuous-delivery</li> <li>https://azure.microsoft.com/fr-fr/solutions/devops/tutorial</li> <li>https://learn.microsoft.com/fr-fr/training/paths/az-400-implement-secure-continuous-deployment/</li> <li>https://www.varonis.com/fr/blog/presentation-azure-devops</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 409</li> <li>completion_tokens: 4987</li> <li>total_tokens: 5396</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.075, 'request_cost': 0.006, 'total_cost': 0.082}</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#content","title":"Content","text":"<p>Il n\u2019est pas possible, dans ce contexte, d\u2019aller v\u00e9rifier en direct les ressources (textes et images) sur learn.microsoft.com ou d\u2019autres sites ni de produire l\u2019\u00e9quivalent fiable de 10 pages A4 directement fond\u00e9 sur ces contenus pr\u00e9cis. En revanche, il est possible de proposer un cours structur\u00e9 et d\u00e9taill\u00e9 sur chaque point du chapitre, avec YAML, scripts, tableaux et un chemin d\u2019apprentissage progressif, en restant original et sans copier la documentation officielle.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#introduction-aux-modeles-de-deploiement","title":"Introduction aux mod\u00e8les de d\u00e9ploiement","text":"<p>Les mod\u00e8les de d\u00e9ploiement d\u00e9crivent la mani\u00e8re dont les nouvelles versions d\u2019une application sont mises en production, tout en limitant le risque et l\u2019interruption de service.</p> <p>Principaux mod\u00e8les utiles avec Azure Pipelines\u00a0:</p> <ul> <li>D\u00e9ploiement blue\u2011green\u00a0: deux environnements quasi identiques (\u00ab\u00a0blue\u00a0\u00bb et \u00ab\u00a0green\u00a0\u00bb), l\u2019un sert le trafic, l\u2019autre re\u00e7oit la nouvelle version, puis un basculement du routage est r\u00e9alis\u00e9.</li> <li>Canary release\u00a0: une petite fraction des utilisateurs re\u00e7oit la nouvelle version en premier, pour observer le comportement r\u00e9el avant une g\u00e9n\u00e9ralisation.</li> <li>Dark launching\u00a0: la fonctionnalit\u00e9 est d\u00e9ploy\u00e9e c\u00f4t\u00e9 back\u2011end, mais non visible pour les utilisateurs tant qu\u2019un flag ou une configuration ne l\u2019active pas.</li> <li>A/B testing\u00a0: deux variantes (ou plus) sont d\u00e9ploy\u00e9es simultan\u00e9ment, avec mesure de m\u00e9triques (conversion, latence, erreurs, etc.).</li> <li>Diffusion graduelle (progressive rollout / ring deployment)\u00a0: mise en production par anneaux successifs (d\u00e9veloppeurs internes, b\u00eata, production globale, r\u00e9gions, etc.).</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#exemple-de-logique-de-strategie-dans-azure-pipelines","title":"Exemple de logique de strat\u00e9gie dans Azure Pipelines","text":"<p>Dans Azure Pipelines, ces mod\u00e8les se traduisent par\u00a0:</p> <ul> <li>Des environnements (staging, pr\u00e9\u2011prod, prod).</li> <li>Des strat\u00e9gies de d\u00e9ploiement (par exemple <code>runOnce</code>, <code>rolling</code>, <code>canary</code> dans les d\u00e9ploiements vers Kubernetes).</li> <li>Des approbations manuelles, des gates (contr\u00f4les automatiques) et des variables de configuration par environnement.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#deploiement-bluegreen-et-permutation-des-fonctionnalites","title":"D\u00e9ploiement blue\u2011green et permutation des fonctionnalit\u00e9s","text":"<p>Le d\u00e9ploiement blue\u2011green vise \u00e0 r\u00e9duire au maximum les interruptions et \u00e0 permettre un rollback rapide.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#principe-bluegreen","title":"Principe blue\u2011green","text":"<ul> <li>Environnement \u00ab\u00a0Blue\u00a0\u00bb\u00a0: version actuelle en production.</li> <li>Environnement \u00ab\u00a0Green\u00a0\u00bb\u00a0: nouvelle version.</li> <li>Pipeline\u00a0:</li> <li>Build et tests.</li> <li>D\u00e9ploiement en \u00ab\u00a0Green\u00a0\u00bb.</li> <li>Tests fonctionnels / smoke tests sur \u00ab\u00a0Green\u00a0\u00bb.</li> <li>Basculement du trafic (DNS, load balancer, slot swap, etc.).</li> <li>Option de rollback vers \u00ab\u00a0Blue\u00a0\u00bb si incident.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#exemple-yaml-pour-deux-environnements-simplifie","title":"Exemple YAML pour deux environnements (simplifi\u00e9)","text":"YAML<pre><code>trigger:\n  branches:\n    include:\n      - main\n\nstages:\n- stage: Build\n  jobs:\n  - job: BuildApp\n    pool:\n      vmImage: 'ubuntu-latest'\n    steps:\n    - task: DotNetCoreCLI@2\n      inputs:\n        command: 'build'\n        projects: '**/*.csproj'\n\n- stage: Deploy_Green\n  dependsOn: Build\n  jobs:\n  - deployment: DeployToGreen\n    environment: 'prod-green'\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n          - script: echo \"D\u00e9ploiement de la nouvelle version sur Green\"\n            displayName: 'Deploy on Green'\n\n- stage: Swap_Traffic\n  dependsOn: Deploy_Green\n  jobs:\n  - job: Swap\n    steps:\n    - script: echo \"Basculement du trafic de Blue vers Green\"\n      displayName: 'Swap Blue-&gt;Green'\n</code></pre> <p>Ce pipeline illustre l\u2019id\u00e9e\u00a0: d\u2019abord construire, ensuite d\u00e9ployer sur un environnement \u00ab\u00a0Green\u00a0\u00bb, puis op\u00e9rer un basculement logique (par exemple un slot swap App Service ou une mise \u00e0 jour du routage).</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#permutation-des-fonctionnalites-feature-toggles","title":"Permutation des fonctionnalit\u00e9s (feature toggles)","text":"<p>La permutation des fonctionnalit\u00e9s consiste \u00e0 contr\u00f4ler finement quelles fonctionnalit\u00e9s sont visibles ou actives via des feature flags.</p> <p>B\u00e9n\u00e9fices\u00a0:</p> <ul> <li>Activation progressive sans nouveau d\u00e9ploiement.</li> <li>Possibilit\u00e9 de d\u00e9sactiver une fonctionnalit\u00e9 d\u00e9faillante en production.</li> <li>Exp\u00e9rimentation (A/B, dark launch) via configuration.</li> </ul> <p>Exemple de code (C# pseudo\u2011code) utilisant un flag issu d\u2019une configuration (App Configuration, Key Vault, config file)\u00a0:</p> C#<pre><code>public class CheckoutController\n{\n    private readonly IFeatureManager _featureManager;\n\n    public CheckoutController(IFeatureManager featureManager)\n    {\n        _featureManager = featureManager;\n    }\n\n    public async Task&lt;IActionResult&gt; Index()\n    {\n        if (await _featureManager.IsEnabledAsync(\"NewCheckoutFlow\"))\n        {\n            return View(\"NewCheckout\");\n        }\n\n        return View(\"LegacyCheckout\");\n    }\n}\n</code></pre> <p>Le pipeline ne fait alors que d\u00e9ployer le code ; l\u2019activation de <code>NewCheckoutFlow</code> se g\u00e8re par configuration.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#canary-release-et-dark-launching","title":"Canary release et dark launching","text":""},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#canary-release","title":"Canary release","text":"<p>Objectif\u00a0: limiter l\u2019impact d\u2019un bug en exposant d\u2019abord la nouvelle version \u00e0 un petit pourcentage d\u2019utilisateurs (ou de pods).</p> <p>Sc\u00e9narios typiques\u00a0:</p> <ul> <li>D\u00e9ploiement sur un petit sous\u2011ensemble d\u2019instances (par exemple quelques pods Kubernetes \u00e9tiquet\u00e9s \u00ab\u00a0canary\u00a0\u00bb).</li> <li>Routage de 5\u00a0% du trafic vers la version canary via le load balancer ou le gateway.</li> <li>Surveillance de m\u00e9triques (erreurs, latence, taux de conversion).</li> <li>\u00c9largissement progressif (25\u00a0%, 50\u00a0%, 100\u00a0%) si tout reste stable.</li> </ul> <p>Exemple YAML (d\u00e9ploiement canary simplifi\u00e9 vers Kubernetes)\u00a0:</p> YAML<pre><code>stages:\n- stage: Deploy_Canary\n  jobs:\n  - deployment: DeployCanary\n    environment: 'prod-canary'\n    strategy:\n      canary:\n        increments: [10, 50, 100]\n        preDeploy:\n          steps:\n          - script: echo \"D\u00e9ploiement canary - pr\u00e9paration\"\n        deploy:\n          steps:\n          - task: KubernetesManifest@1\n            inputs:\n              action: deploy\n              manifests: 'manifests/canary.yaml'\n        routeTraffic:\n          steps:\n          - script: echo \"Mise \u00e0 jour du routage trafic\"\n        postRouteTraffic:\n          steps:\n          - script: echo \"Surveiller les m\u00e9triques avant \u00e9tape suivante\"\n</code></pre> <p>Ici, l\u2019id\u00e9e est de monter progressivement le pourcentage de trafic (increments).</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#dark-launching","title":"Dark launching","text":"<p>Le dark launching permet de d\u00e9ployer une fonctionnalit\u00e9 compl\u00e8te c\u00f4t\u00e9 serveur, mais sans la rendre visible aux utilisateurs finaux.</p> <p>M\u00e9canismes\u00a0:</p> <ul> <li>Flags internes (non expos\u00e9s au produit) activ\u00e9s seulement pour des comptes internes ou des requ\u00eates sp\u00e9cifiques.</li> <li>Endpoints API accessibles uniquement via un header ou un token.</li> <li>Configuration dynamique (App Configuration, Key Vault, etc.) pour piloter cette visibilit\u00e9.</li> </ul> <p>Exemple simple\u00a0: une nouvelle version du moteur de recommandation est disponible, mais elle est utilis\u00e9e uniquement pour logger des r\u00e9sultats comparatifs sans impacter r\u00e9ellement les recommandations servies aux utilisateurs.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#tests-ab-et-diffusion-graduelle","title":"Tests A/B et diffusion graduelle","text":""},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#tests-ab","title":"Tests A/B","text":"<p>Les tests A/B visent \u00e0 comparer deux variantes (A et B) en production, en mesurant des indicateurs m\u00e9tier ou techniques.</p> <p>\u00c9tapes typiques\u00a0:</p> <ol> <li>D\u00e9ployer les deux variantes (A &amp; B) dans l\u2019environnement de production.</li> <li>Configurer un r\u00e9partiteur de trafic (front\u2011door, gateway, feature flag avec pourcentage)\u00a0:</li> <li>50\u00a0% des utilisateurs \u2192 A</li> <li>50\u00a0% des utilisateurs \u2192 B</li> <li>Collecter les m\u00e9triques dans Application Insights, Log Analytics ou une solution d\u2019analytics m\u00e9tier.</li> <li>D\u00e9cider de la variante gagnante et basculer tout le trafic dessus.</li> </ol> <p>Exemple de pseudo\u2011configuration de feature flags (JSON)\u00a0:</p> JSON<pre><code>{\n  \"Features\": {\n    \"NewLandingPage\": {\n      \"enabled\": true,\n      \"variants\": [\n        { \"name\": \"A\", \"percentage\": 50 },\n        { \"name\": \"B\", \"percentage\": 50 }\n      ]\n    }\n  }\n}\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#diffusion-graduelle-ring-deployment","title":"Diffusion graduelle (ring deployment)","text":"<p>La diffusion graduelle consiste \u00e0 d\u00e9ployer progressivement par \u00ab\u00a0anneaux\u00a0\u00bb (rings)\u00a0:</p> <ul> <li>Ring 0\u00a0: \u00e9quipe interne (dogfooding).</li> <li>Ring 1\u00a0: petit groupe d\u2019utilisateurs externes.</li> <li>Ring 2\u00a0: r\u00e9gion ou segment plus large.</li> <li>Ring N\u00a0: l\u2019ensemble des utilisateurs.</li> </ul> <p>Exemple de structure de pipeline avec plusieurs stages\u00a0:</p> YAML<pre><code>stages:\n- stage: Deploy_Ring0\n  jobs:\n  - deployment: Ring0\n    environment: 'prod-ring0'\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n          - script: echo \"D\u00e9ploiement Ring 0 (interne)\"\n\n- stage: Deploy_Ring1\n  dependsOn: Deploy_Ring0\n  condition: succeeded('Deploy_Ring0')\n  jobs:\n  - deployment: Ring1\n    environment: 'prod-ring1'\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n          - script: echo \"D\u00e9ploiement Ring 1 (b\u00eata)\"\n\n- stage: Deploy_Ring2\n  dependsOn: Deploy_Ring1\n  condition: succeeded('Deploy_Ring1')\n  jobs:\n  - deployment: Ring2\n    environment: 'prod-ring2'\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n          - script: echo \"D\u00e9ploiement Ring 2 (g\u00e9n\u00e9ral)\"\n</code></pre> <p>Chaque ring peut int\u00e9grer des gates\u00a0: seuil d\u2019erreurs, qualit\u00e9, m\u00e9triques.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#integration-aux-systemes-de-gestion-de-lidentite","title":"Int\u00e9gration aux syst\u00e8mes de gestion de l\u2019identit\u00e9","text":"<p>Un d\u00e9ploiement continu s\u00e9curis\u00e9 implique une int\u00e9gration forte avec les syst\u00e8mes de gestion d\u2019identit\u00e9 (Azure AD / Entra ID, identit\u00e9s manag\u00e9es, etc.) et le contr\u00f4le d\u2019acc\u00e8s.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#concepts-essentiels","title":"Concepts essentiels","text":"<ul> <li>Service connections dans Azure DevOps\u00a0: objets repr\u00e9sentant des identit\u00e9s techniques pour se connecter \u00e0 Azure, GitHub, Docker registries, etc.</li> <li>Principe du moindre privil\u00e8ge\u00a0: le service connection doit n\u2019avoir que les droits n\u00e9cessaires (par exemple, \u00ab\u00a0Contributor\u00a0\u00bb sur un groupe de ressources sp\u00e9cifique, pas sur l\u2019abonnement entier).</li> <li>Identit\u00e9s manag\u00e9es (Managed Identities)\u00a0: identit\u00e9s g\u00e9r\u00e9es par Azure pour les ressources (App Service, VM, Functions), \u00e0 utiliser pour acc\u00e9der aux secrets ou \u00e0 d\u2019autres services sans g\u00e9rer de secrets dans le pipeline.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#exemple-de-tache-azure-cli-avec-service-principal","title":"Exemple de t\u00e2che Azure CLI avec service principal","text":"YAML<pre><code>- task: AzureCLI@2\n  inputs:\n    azureSubscription: 'svc-connection-to-azure'\n    scriptType: 'bash'\n    scriptLocation: 'inlineScript'\n    inlineScript: |\n      az webapp deployment slot swap \\\n        --name myapp \\\n        --resource-group my-rg \\\n        --slot green \\\n        --target-slot production\n</code></pre> <p><code>azureSubscription</code> fait r\u00e9f\u00e9rence \u00e0 une connexion de service configur\u00e9e dans le projet Azure DevOps.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#rbac-et-permissions","title":"RBAC et permissions","text":"<p>Points d\u2019attention\u00a0:</p> <ul> <li>Isoler les environnements par resource groups ou par abonnements.</li> <li>Utiliser des r\u00f4les int\u00e9gr\u00e9s adapt\u00e9s (Reader, Contributor, Web Deploy, etc.).</li> <li>Limiter les permissions des comptes utilisateurs qui modifient les pipelines (s\u00e9paration des r\u00f4les\u00a0: dev, ops, s\u00e9curit\u00e9).</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#gestion-des-donnees-de-configuration-des-applications","title":"Gestion des donn\u00e9es de configuration des applications","text":"<p>Une architecture de d\u00e9ploiement moderne distingue clairement code, configuration et secrets.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#types-de-donnees-de-configuration","title":"Types de donn\u00e9es de configuration","text":"<ul> <li>Param\u00e8tres fonctionnels (feature flags, tailles de cache, URLs de services).</li> <li>Param\u00e8tres d\u2019infrastructure (sku de base de donn\u00e9es, type d\u2019instance).</li> <li>Cha\u00eenes de connexion, cl\u00e9s API, certificats.</li> </ul> <p>Pratiques recommand\u00e9es\u00a0:</p> <ul> <li>Centraliser la configuration applicative dans un service d\u00e9di\u00e9 (par exemple, un service de configuration g\u00e9r\u00e9).</li> <li>Externaliser les secrets dans un coffre\u2011fort.</li> <li>Versionner des valeurs par environnement (dev, test, prod).</li> <li>Charger dynamiquement la configuration (sans red\u00e9ploiement) si possible.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#exemple-de-variables-par-environnement-dans-un-pipeline","title":"Exemple de variables par environnement dans un pipeline","text":"YAML<pre><code>variables:\n- template: vars/common.yml\n- template: vars/vars-dev.yml  # pour un stage dev\n</code></pre> <p>Fichier <code>vars/vars-dev.yml</code>\u00a0:</p> YAML<pre><code>variables:\n  APP_ENV: 'dev'\n  API_BASE_URL: 'https://api-dev.contoso.com'\n  FEATURE_NEW_CHECKOUT: 'false'\n</code></pre> <p>L\u2019application consomme ensuite ces variables via des m\u00e9caniques de substitution (<code>fileTransform</code>, <code>variable substitution</code>, etc.).</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#travaux-pratiques-pipelines-as-code-avec-yaml","title":"Travaux pratiques\u00a0: pipelines as code avec YAML","text":"<p>Ce module vise la ma\u00eetrise de la description des pipelines en YAML, ce qui apporte tra\u00e7abilit\u00e9, revue de code et r\u00e9utilisation.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#etape-1-pipeline-ci-de-base","title":"\u00c9tape 1\u00a0: pipeline CI de base","text":"<p>Exemple pour une application .NET\u00a0:</p> YAML<pre><code>trigger:\n  branches:\n    include:\n      - main\n\npool:\n  vmImage: 'ubuntu-latest'\n\nsteps:\n- task: UseDotNet@2\n  inputs:\n    packageType: 'sdk'\n    version: '8.0.x'\n\n- script: dotnet restore\n  displayName: 'Restore'\n\n- script: dotnet build --configuration Release\n  displayName: 'Build'\n\n- script: dotnet test --configuration Release --logger trx\n  displayName: 'Tests unitaires'\n</code></pre> <p>Objectifs p\u00e9dagogiques\u00a0:</p> <ul> <li>Comprendre <code>trigger</code>, <code>pool</code>, <code>steps</code>.</li> <li>Apprendre \u00e0 utiliser des tasks (UseDotNet, DotNetCoreCLI, etc.).</li> <li>Introduire les tests automatis\u00e9s.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#etape-2-separation-ci-cd-avec-stages","title":"\u00c9tape 2\u00a0: s\u00e9paration CI / CD avec stages","text":"YAML<pre><code>stages:\n- stage: Build\n  jobs:\n  - job: BuildAndTest\n    steps:\n    - script: dotnet build\n    - script: dotnet test\n\n- stage: Deploy_Dev\n  dependsOn: Build\n  jobs:\n  - deployment: DeployToDev\n    environment: 'dev'\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n          - script: echo \"D\u00e9ploiement en Dev\"\n\n- stage: Deploy_Prod\n  dependsOn: Deploy_Dev\n  condition: succeeded('Deploy_Dev')\n  jobs:\n  - deployment: DeployToProd\n    environment: 'prod'\n    strategy:\n      runOnce:\n        deploy:\n          steps:\n          - script: echo \"D\u00e9ploiement en Prod\"\n</code></pre> <p>Ce pipeline illustre la progression\u00a0: CI \u2192 Dev \u2192 Prod, avec des environnements distincts et une cha\u00eene de d\u00e9pendances.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#travaux-pratiques-mise-en-place-et-execution-de-tests-fonctionnels","title":"Travaux pratiques\u00a0: mise en place et ex\u00e9cution de tests fonctionnels","text":"<p>Les tests fonctionnels ou end\u2011to\u2011end (E2E) valident une fonctionnalit\u00e9 du point de vue de l\u2019utilisateur.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#organisation-des-tests","title":"Organisation des tests","text":"<ul> <li>Dossier d\u00e9di\u00e9 dans le repo (<code>tests/e2e</code>).</li> <li>Outil adapt\u00e9\u00a0: Selenium, Playwright, Cypress, Postman/Newman, etc.</li> <li>Donn\u00e9es de test g\u00e9r\u00e9es par environnement (URLs, utilisateurs de test, etc.).</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#exemple-dintegration-de-tests-postmannewman","title":"Exemple d\u2019int\u00e9gration de tests Postman/Newman","text":"YAML<pre><code>- task: NodeTool@0\n  inputs:\n    versionSpec: '18.x'\n\n- script: |\n    npm install -g newman\n    newman run tests/e2e/collection.json \\\n      --environment tests/e2e/env-dev.json \\\n      --reporters cli,junit \\\n      --reporter-junit-export $(System.DefaultWorkingDirectory)/test-results/e2e.xml\n  displayName: 'Tests E2E Newman'\n\n- task: PublishTestResults@2\n  inputs:\n    testResultsFiles: '**/e2e.xml'\n    testResultsFormat: 'JUnit'\n    testRunTitle: 'Tests E2E'\n</code></pre> <p>L\u2019objectif p\u00e9dagogique\u00a0: relier la r\u00e9ussite du d\u00e9ploiement \u00e0 la r\u00e9ussite des tests de bout en bout.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#travaux-pratiques-integration-dazure-key-vault-a-azure-devops","title":"Travaux pratiques\u00a0: int\u00e9gration d\u2019Azure Key Vault \u00e0 Azure DevOps","text":"<p>Ce module porte sur la s\u00e9curisation des secrets utilis\u00e9s par les pipelines et par les applications d\u00e9ploy\u00e9es.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#etapes-conceptuelles","title":"\u00c9tapes conceptuelles","text":"<ol> <li>Cr\u00e9er un coffre\u2011fort de cl\u00e9s (Key Vault).</li> <li>D\u00e9finir les secrets (par exemple <code>DbConnectionString</code>, <code>ApiKeyPayment</code>).</li> <li>Autoriser le service principal / l\u2019identit\u00e9 manag\u00e9e du pipeline \u00e0 <code>get</code> ces secrets.</li> <li>Ajouter une t\u00e2che ou une liaison dans Azure Pipelines pour consommer ces secrets.</li> </ol>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#exemple-dutilisation-de-secrets-dans-un-pipeline","title":"Exemple d\u2019utilisation de secrets dans un pipeline","text":"YAML<pre><code>variables:\n  - group: kv-secrets  # variable group li\u00e9 au coffre-fort\n\nsteps:\n- script: |\n    echo \"Db connection: $(DbConnectionString)\"\n  displayName: 'Utilisation du secret'\n</code></pre> <p>Lors de la configuration, le variable group <code>kv-secrets</code> est connect\u00e9 au coffre\u2011fort et les noms de variables correspondent aux noms de secrets.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#acces-direct-via-une-tache-dediee","title":"Acc\u00e8s direct via une t\u00e2che d\u00e9di\u00e9e","text":"YAML<pre><code>- task: AzureKeyVault@2\n  inputs:\n    azureSubscription: 'svc-connection-to-azure'\n    KeyVaultName: 'my-kv'\n    SecretsFilter: 'DbConnectionString,ApiKeyPayment'\n    RunAsPreJob: true\n</code></pre> <p>Les secrets deviennent alors accessibles via <code>$(DbConnectionString)</code> et <code>$(ApiKeyPayment)</code> dans les steps suivants.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#travaux-pratiques-configuration-dynamique-et-flags-de-fonctionnalites","title":"Travaux pratiques\u00a0: configuration dynamique et flags de fonctionnalit\u00e9s","text":"<p>Ce module assemble les notions de configuration externe et de feature flags pour un d\u00e9ploiement vraiment flexible.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#objectifs","title":"Objectifs","text":"<ul> <li>D\u00e9coupler le cycle de vie du code de celui des fonctionnalit\u00e9s.</li> <li>Permettre l\u2019activation/d\u00e9sactivation de fonctionnalit\u00e9s sans red\u00e9ploiement.</li> <li>Supporter les sc\u00e9narios canary, dark launch et A/B tests.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#etapes-pedagogiques","title":"\u00c9tapes p\u00e9dagogiques","text":"<ol> <li>Ajouter un package de gestion des flags dans l\u2019application (SDK appropri\u00e9).</li> <li>Cr\u00e9er un magasin de configuration (fichier, service externe, base de donn\u00e9es).</li> <li>Brancher l\u2019application sur cette source de configuration.</li> <li>Configurer le pipeline pour d\u00e9ployer la configuration ou mettre \u00e0 jour le service de configuration \u00e0 chaque release.</li> </ol>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#exemple-feature-flag-pilote-par-variable-de-pipeline","title":"Exemple\u00a0: feature flag pilot\u00e9 par variable de pipeline","text":"<p>Pipeline\u00a0:</p> YAML<pre><code>variables:\n  Feature_NewCheckout: 'false'\n\nsteps:\n- script: echo \"FEATURE_NEW_CHECKOUT=$(Feature_NewCheckout)\" &gt;&gt; .env\n  displayName: 'G\u00e9n\u00e9ration des variables de fonctionnalit\u00e9'\n</code></pre> <p>Code applicatif (pseudo\u2011code)\u00a0:</p> Python<pre><code>import os\n\nif os.getenv(\"FEATURE_NEW_CHECKOUT\", \"false\").lower() == \"true\":\n    # Nouveau parcours\n    ...\nelse:\n    # Ancien parcours\n    ...\n</code></pre> <p>Pour un canary, la valeur de <code>Feature_NewCheckout</code> peut \u00eatre progressive\u00a0: <code>10%</code>, <code>50%</code>, <code>100%</code> et l\u2019application applique alors une strat\u00e9gie de routage interne par pourcentage d\u2019utilisateurs.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap05/#chemin-dapprentissage-detaille-pour-ce-chapitre","title":"Chemin d\u2019apprentissage d\u00e9taill\u00e9 pour ce chapitre","text":"<p>Pour assimiler le chapitre 5 de mani\u00e8re progressive et approfondie, un chemin possible est le suivant\u00a0:</p> <ol> <li>Concepts g\u00e9n\u00e9raux (1\u20132 jours) </li> <li>\u00c9tudier les notions de CI/CD, d\u2019environnements (dev/test/staging/prod).  </li> <li> <p>Comprendre les mod\u00e8les de d\u00e9ploiement blue\u2011green, canary, dark launch, A/B, rings, ainsi que leurs avantages/inconv\u00e9nients.</p> </li> <li> <p>Pipelines YAML de base (1\u20133 jours) </p> </li> <li>Cr\u00e9er un pipeline CI simple \u00e0 partir d\u2019un repo existant.  </li> <li> <p>Ajouter des tests unitaires, des artefacts de build, et s\u00e9parer les stages Build / Deploy.</p> </li> <li> <p>D\u00e9ploiement s\u00e9curis\u00e9 multi\u2011environnements (3\u20135 jours) </p> </li> <li>Ajouter des environnements (dev, test, prod), avec approbations manuelles et gates.  </li> <li>Mettre en \u0153uvre un flux blue\u2011green ou slots pour les d\u00e9ploiements web.  </li> <li> <p>Int\u00e9grer les syst\u00e8mes de gestion de l\u2019identit\u00e9 via des connexions de service et un RBAC strict.</p> </li> <li> <p>Strat\u00e9gies avanc\u00e9es et tests (3\u20135 jours) </p> </li> <li>Mettre en place un canary release et une diffusion graduelle par rings.  </li> <li> <p>Ajouter des tests fonctionnels/E2E dans le pipeline et lier la r\u00e9ussite du d\u00e9ploiement \u00e0 leur ex\u00e9cution.</p> </li> <li> <p>S\u00e9curit\u00e9 et configuration (3\u20135 jours) </p> </li> <li>Centraliser les secrets dans un coffre\u2011fort et les consommer depuis les pipelines.  </li> <li>Introduire un syst\u00e8me de configuration externe et des feature flags.  </li> <li> <p>Pratiquer le dark launching et des sc\u00e9narios simples d\u2019A/B testing.</p> </li> <li> <p>Industrialisation (continu) </p> </li> <li>Factoriser les pipelines avec des templates YAML.  </li> <li>Mettre en place des conventions (naming, structure de repo, gestion des environnements).  </li> <li>Int\u00e9grer la surveillance (logs, m\u00e9triques, traces) dans les strat\u00e9gies de d\u00e9ploiement (gates automatiques).</li> </ol> <p>Si un approfondissement sur un point pr\u00e9cis (par exemple \u00ab\u00a0canary sur AKS\u00a0\u00bb, \u00ab\u00a0Azure App Configuration + feature flags\u00a0\u00bb ou \u00ab\u00a0Key Vault + identit\u00e9s manag\u00e9es\u00a0\u00bb) est souhait\u00e9, un focus d\u00e9taill\u00e9 avec plus de code et de sc\u00e9narios concrets peut \u00eatre propos\u00e9.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/","title":"Citations","text":"<ul> <li>https://blog.atawiz.fr/iac-azure-devops-terraform/</li> <li>https://www.inow-formation.fr/telecharger/formation-azure-devops-infrasstructure-as-code-bicep-arm-terraform/AZOI</li> <li>https://www.varonis.com/fr/blog/presentation-azure-devops</li> <li>https://www.datacamp.com/fr/tutorial/azure-pipelines</li> <li>https://learn.microsoft.com/fr-fr/devops/deliver/what-is-infrastructure-as-code</li> <li>https://azure.microsoft.com/fr-fr/solutions/devops/tutorial</li> <li>https://learn.microsoft.com/fr-fr/azure/cloud-adoption-framework/ready/considerations/infrastructure-as-code</li> <li>https://www.youtube.com/watch?v=2euUIyNpbqI</li> <li>https://openclassrooms.com/fr/courses/2035736-mettez-en-place-l-integration-et-la-livraison-continues-avec-la-demarche-devops</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 341</li> <li>completion_tokens: 4226</li> <li>total_tokens: 4567</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.063, 'request_cost': 0.006, 'total_cost': 0.07}</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#content","title":"Content","text":"<p>Il n\u2019est pas possible, dans ce contexte, d\u2019acc\u00e9der aux ressources externes (y compris learn.microsoft.com) ni de v\u00e9rifier l\u2019existence effective des images demand\u00e9es, ce qui emp\u00eache de proposer un contenu vraiment exhaustif de l\u2019ordre de 10 pages A4 ou d\u2019ins\u00e9rer des sch\u00e9mas issus de ces sites. En revanche, il est possible de d\u00e9tailler chaque point du chapitre, d\u2019expliquer le chemin d\u2019apprentissage et de proposer des exemples concrets (scripts, structures de fichiers, tableaux) enti\u00e8rement r\u00e9dig\u00e9s pour l\u2019occasion.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#introduction-generale-a-linfrastructure-as-code","title":"Introduction g\u00e9n\u00e9rale \u00e0 l\u2019Infrastructure as Code","text":"<p>L\u2019infrastructure as code (IaC) consiste \u00e0 d\u00e9finir et g\u00e9rer l\u2019infrastructure (r\u00e9seaux, machines, services PaaS, r\u00e8gles de s\u00e9curit\u00e9, etc.) gr\u00e2ce \u00e0 du code versionn\u00e9, r\u00e9utilisable et automatis\u00e9, plut\u00f4t que par des clics manuels dans un portail. Cette approche rapproche l\u2019infrastructure des bonnes pratiques de d\u00e9veloppement logiciel\u202f: contr\u00f4le de version, revues de code, tests, int\u00e9gration et d\u00e9ploiement continus.</p> <p>Dans un environnement Azure + Azure DevOps, l\u2019IaC se d\u00e9cline typiquement autour de plusieurs briques\u202f: mod\u00e8les ARM, Bicep, scripts Azure CLI/PowerShell, Azure Automation et Desired State Configuration (DSC). Chacun de ces outils adresse un niveau diff\u00e9rent\u202f: provisionnement de ressources, configuration de syst\u00e8mes, orchestration et gestion continue.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#explorer-linfra-as-code-et-la-gestion-des-configurations","title":"Explorer l\u2019Infra as Code et la gestion des configurations","text":"<p>L\u2019Infra as Code se d\u00e9coupe en deux grands volets compl\u00e9mentaires\u202f: le provisioning (cr\u00e9ation et modification des ressources cloud) et la configuration (\u00e9tat interne des machines, services ou applications). Le provisioning, dans Azure, repose couramment sur ARM, Bicep ou des scripts Azure CLI/PowerShell, tandis que la configuration continue implique DSC, Azure Automation ou d\u2019autres agents de configuration.</p> <p>Un chemin d\u2019apprentissage pragmatique consiste \u00e0\u202f: - Comprendre les concepts (d\u00e9claratif vs imp\u00e9ratif, idempotence, immutabilit\u00e9). - Prendre en main un langage d\u00e9claratif (ARM ou Bicep) pour d\u00e9ployer de la ressource. - Ajouter progressivement la configuration syst\u00e8me via DSC ou des scripts g\u00e9r\u00e9s par Azure Automation. - Enfin, int\u00e9grer le tout dans des pipelines Azure DevOps pour automatiser et s\u00e9curiser les d\u00e9ploiements.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#modele-declaratif-vs-imperatif","title":"Mod\u00e8le d\u00e9claratif vs imp\u00e9ratif","text":"<ul> <li>D\u00e9claratif\u202f: le code d\u00e9crit l\u2019\u00e9tat final souhait\u00e9 (par exemple\u202f: un groupe de ressources contenant un compte de stockage avec tel SKU). Le moteur d\u2019ex\u00e9cution calcule les op\u00e9rations n\u00e9cessaires.</li> <li>Imp\u00e9ratif\u202f: le code d\u00e9crit la s\u00e9quence d\u2019actions \u00e0 ex\u00e9cuter (cr\u00e9er un groupe de ressources, puis un compte de stockage, puis configurer les acc\u00e8s, etc.).</li> </ul> <p>ARM, Bicep et DSC sont des langages d\u00e9claratifs, alors qu\u2019Azure CLI ou PowerShell sont traditionnellement imp\u00e9ratifs, m\u00eame si l\u2019on peut les utiliser pour piloter des d\u00e9ploiements d\u00e9claratifs.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#creer-des-ressources-azure-a-laide-de-modeles-arm","title":"Cr\u00e9er des ressources Azure \u00e0 l\u2019aide de mod\u00e8les ARM","text":"<p>Les mod\u00e8les ARM (Azure Resource Manager) sont des fichiers JSON d\u00e9crivant l\u2019ensemble des ressources et de leurs d\u00e9pendances. Ils sont soumis \u00e0 Azure Resource Manager, qui se charge de cr\u00e9er, mettre \u00e0 jour ou supprimer les ressources pour atteindre l\u2019\u00e9tat d\u00e9sir\u00e9.</p> <p>Les principaux \u00e9l\u00e9ments d\u2019un template ARM sont\u202f: - <code>parameters</code>\u202f: ce qui varie entre environnements (noms, tailles, emplacements). - <code>variables</code>\u202f: valeurs construites \u00e0 partir de param\u00e8tres ou constantes. - <code>resources</code>\u202f: la liste des ressources \u00e0 d\u00e9ployer (type, nom, API version, propri\u00e9t\u00e9s). - <code>outputs</code>\u202f: valeurs retourn\u00e9es par le d\u00e9ploiement (par exemple un FQDN ou un ID de ressource).</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#exemple-de-template-arm-minimal","title":"Exemple de template ARM minimal","text":"<p>Ci-dessous un exemple simplifi\u00e9 d\u2019un template ARM d\u00e9ployant un compte de stockage\u202f:</p> JSON<pre><code>{\n  \"$schema\": \"https://schema.management.azure.com/schemas/2019-04-01/deploymentTemplate.json#\",\n  \"contentVersion\": \"1.0.0.0\",\n  \"parameters\": {\n    \"storageAccountName\": {\n      \"type\": \"string\"\n    },\n    \"location\": {\n      \"type\": \"string\",\n      \"defaultValue\": \"westeurope\"\n    }\n  },\n  \"resources\": [\n    {\n      \"type\": \"Microsoft.Storage/storageAccounts\",\n      \"apiVersion\": \"2023-01-01\",\n      \"name\": \"[parameters('storageAccountName')]\",\n      \"location\": \"[parameters('location')]\",\n      \"sku\": {\n        \"name\": \"Standard_LRS\"\n      },\n      \"kind\": \"StorageV2\",\n      \"properties\": {}\n    }\n  ],\n  \"outputs\": {\n    \"storageAccountId\": {\n      \"type\": \"string\",\n      \"value\": \"[resourceId('Microsoft.Storage/storageAccounts', parameters('storageAccountName'))]\"\n    }\n  }\n}\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#deploiement-dun-template-arm","title":"D\u00e9ploiement d\u2019un template ARM","text":"<p>Un template ARM peut se d\u00e9ployer via\u202f: - Azure CLI (<code>az deployment group create</code>). - PowerShell (<code>New-AzResourceGroupDeployment</code>). - Azure DevOps (t\u00e2ches \u00ab\u202fARM template deployment\u202f\u00bb dans un pipeline). - Le portail Azure (d\u00e9ploiement personnalis\u00e9).</p> <p>Exemple avec Azure CLI\u202f:</p> Bash<pre><code>az group create \\\n  --name rg-iac-demo \\\n  --location westeurope\n\naz deployment group create \\\n  --name deploy-storage-demo \\\n  --resource-group rg-iac-demo \\\n  --template-file ./storage-account-template.json \\\n  --parameters storageAccountName=stiacdemotest\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#mettre-en-uvre-bicep","title":"Mettre en \u0153uvre Bicep","text":"<p>Bicep est un langage d\u00e9claratif de haut niveau qui simplifie l\u2019\u00e9criture des templates ARM. Il compile vers JSON ARM standard, ce qui permet de b\u00e9n\u00e9ficier du m\u00eame moteur de d\u00e9ploiement tout en \u00e9crivant un code plus concis, plus lisible et modulable.</p> <p>Les avantages cl\u00e9s de Bicep\u202f: - Syntaxe proche d\u2019un langage de programmation (types, modules, boucles, conditions). - Possibilit\u00e9 de factoriser du code gr\u00e2ce aux modules. - Outils de d\u00e9veloppement adapt\u00e9s (extension VS Code, IntelliSense, validation).</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#exemple-bicep-equivalent-au-template-arm-precedent","title":"Exemple Bicep \u00e9quivalent au template ARM pr\u00e9c\u00e9dent","text":"Text Only<pre><code>param storageAccountName string\nparam location string = 'westeurope'\n\nresource storageAccount 'Microsoft.Storage/storageAccounts@2023-01-01' = {\n  name: storageAccountName\n  location: location\n  sku: {\n    name: 'Standard_LRS'\n  }\n  kind: 'StorageV2'\n}\n\noutput storageAccountId string = storageAccount.id\n</code></pre> <p>Compilation vers ARM\u202f:</p> Bash<pre><code>bicep build ./storage-account.bicep\n# Produit ./storage-account.json\n</code></pre> <p>D\u00e9ploiement via Azure CLI\u202f:</p> Bash<pre><code>az deployment group create \\\n  --name deploy-storage-bicep \\\n  --resource-group rg-iac-demo \\\n  --template-file ./storage-account.bicep \\\n  --parameters storageAccountName=stbicepdemotest\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#modules-bicep-et-structuration-du-code","title":"Modules Bicep et structuration du code","text":"<p>Un chemin d\u2019apprentissage naturel consiste \u00e0\u202f: 1. \u00c9crire un premier fichier Bicep monolithique. 2. Identifier des ressources qui se r\u00e9p\u00e8tent (par exemple VNet, sous-r\u00e9seaux, diagnostics). 3. En faire des modules r\u00e9utilisables.</p> <p>Exemple d\u2019appel de module\u202f:</p> Text Only<pre><code>param env string\nparam location string = 'westeurope'\n\nmodule network './modules/vnet.bicep' = {\n  name: 'vnet-${env}'\n  params: {\n    env: env\n    location: location\n  }\n}\n\noutput vnetId string = network.outputs.vnetId\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#creer-des-ressources-azure-en-utilisant-azure-cli","title":"Cr\u00e9er des ressources Azure en utilisant Azure CLI","text":"<p>Azure CLI est un outil en ligne de commande multiplateforme (Windows, macOS, Linux, Cloud Shell) permettant de g\u00e9rer Azure via des commandes imp\u00e9ratives. Il est particuli\u00e8rement adapt\u00e9 pour\u202f: - Des scripts rapides. - La cr\u00e9ation de ressources simples ou ponctuelles. - Le pilotage de d\u00e9ploiements ARM/Bicep. - L\u2019int\u00e9gration dans des jobs de pipeline.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#exemple-de-script-azure-cli-pour-creer-une-vm","title":"Exemple de script Azure CLI pour cr\u00e9er une VM","text":"Bash<pre><code>#!/usr/bin/env bash\n\nset -e\n\nRESOURCE_GROUP=\"rg-iac-cli-demo\"\nLOCATION=\"westeurope\"\nVM_NAME=\"vm-iac-demo\"\n\n# Connexion interactive (ou via service principal dans un pipeline)\naz login\n\n# Cr\u00e9ation du groupe de ressources\naz group create \\\n  --name \"$RESOURCE_GROUP\" \\\n  --location \"$LOCATION\"\n\n# Cr\u00e9ation d'une machine virtuelle\naz vm create \\\n  --resource-group \"$RESOURCE_GROUP\" \\\n  --name \"$VM_NAME\" \\\n  --image \"Ubuntu2204\" \\\n  --admin-username \"azureuser\" \\\n  --generate-ssh-keys \\\n  --size \"Standard_B1s\"\n\n# Ouverture du port 22\naz vm open-port \\\n  --resource-group \"$RESOURCE_GROUP\" \\\n  --name \"$VM_NAME\" \\\n  --port 22\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#structurer-un-projet-base-sur-azure-cli","title":"Structurer un projet bas\u00e9 sur Azure CLI","text":"<p>Pour garder une approche IaC avec CLI, il est utile de\u202f: - Stocker les scripts dans un d\u00e9p\u00f4t Git. - Passer les valeurs via des variables d\u2019environnement ou des fichiers de param\u00e8tres. - Introduire des fonctions ou scripts modulaires (<code>create-network.sh</code>, <code>create-vm.sh</code>, etc.). - Utiliser des pipelines pour ex\u00e9cuter ces scripts dans un workflow contr\u00f4l\u00e9.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#explorer-azure-automation-avec-devops","title":"Explorer Azure Automation avec DevOps","text":"<p>Azure Automation fournit un environnement manag\u00e9 pour ex\u00e9cuter des runbooks (scripts PowerShell, PowerShell Workflow, Python) et g\u00e9rer des configurations DSC. Associ\u00e9 \u00e0 Azure DevOps, il constitue une plateforme pour orchestrer des t\u00e2ches r\u00e9currentes, post-d\u00e9ploiement ou de maintenance.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#composants-principaux-dazure-automation","title":"Composants principaux d\u2019Azure Automation","text":"<ul> <li>Comptes Automation\u202f: contiennent les runbooks, modules PowerShell, identit\u00e9s manag\u00e9es, assets (variables, credentials, certificats).</li> <li>Runbooks\u202f: scripts d\u2019automatisation ex\u00e9cutables manuellement, planifi\u00e9s ou d\u00e9clench\u00e9s par webhook.</li> <li>Hybrid Runbook Workers\u202f: permettent d\u2019ex\u00e9cuter des runbooks dans un environnement on-premises ou dans d\u2019autres clouds.</li> <li>State Configuration (DSC)\u202f: gestion du Desired State Configuration en mode pull (agent Windows ou Linux).</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#integration-avec-azure-devops","title":"Int\u00e9gration avec Azure DevOps","text":"<p>Un chemin d\u2019int\u00e9gration typique\u202f: 1. Stocker les scripts PowerShell et runbooks sous forme de fichiers <code>.ps1</code> dans un repo Git. 2. Cr\u00e9er un pipeline de build qui valide la qualit\u00e9 des scripts (tests Pester, linting, etc.). 3. Cr\u00e9er un pipeline de release ou un stage d\u00e9di\u00e9 pour publier les runbooks dans Azure Automation. 4. Optionnel\u202f: d\u00e9clencher des runbooks depuis un pipeline (par exemple pour un d\u00e9ploiement de configuration, un correctif, un nettoyage d\u2019environnement).</p> <p>Exemple de t\u00e2che YAML (conceptuel) pour publier un runbook\u202f:</p> YAML<pre><code>- task: AzurePowerShell@5\n  displayName: 'Publier runbook dans Azure Automation'\n  inputs:\n    azureSubscription: 'ServiceConnection-Azure'\n    ScriptType: 'FilePath'\n    ScriptPath: './scripts/Publish-Runbook.ps1'\n    azurePowerShellVersion: 'LatestVersion'\n</code></pre> <p>Le script <code>Publish-Runbook.ps1</code> pourrait\u202f: - V\u00e9rifier si le runbook existe d\u00e9j\u00e0. - Mettre \u00e0 jour le contenu \u00e0 partir du repo. - D\u00e9finir les param\u00e8tres, les identit\u00e9s, etc.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#mettre-en-uvre-desired-state-configuration-dsc","title":"Mettre en \u0153uvre Desired State Configuration (DSC)","text":"<p>Desired State Configuration est une fonctionnalit\u00e9 de PowerShell permettant de d\u00e9finir l\u2019\u00e9tat souhait\u00e9 d\u2019un syst\u00e8me (modules install\u00e9s, fichiers, services, registres, etc.) sous forme de configuration d\u00e9clarative. Une fois la configuration appliqu\u00e9e, l\u2019agent DSC surveille et corrige les d\u00e9rives pour maintenir cet \u00e9tat.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#concepts-cles-de-dsc","title":"Concepts cl\u00e9s de DSC","text":"<ul> <li>Configuration\u202f: bloc PowerShell d\u00e9claratif d\u00e9crivant l\u2019\u00e9tat souhait\u00e9.</li> <li>Ressources DSC\u202f: briques de configuration (ex\u202f: <code>File</code>, <code>Service</code>, <code>WindowsFeature</code> ou modules tiers).</li> <li>MOF (Managed Object Format)\u202f: fichier g\u00e9n\u00e9r\u00e9 \u00e0 partir d\u2019une configuration.</li> <li>Mode push vs pull\u202f:</li> <li>Push\u202f: la configuration est envoy\u00e9e directement \u00e0 la machine cible.</li> <li>Pull\u202f: la machine se connecte \u00e0 un serveur de pull DSC (ou Azure Automation) pour r\u00e9cup\u00e9rer sa configuration.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#exemple-de-configuration-dsc-simple","title":"Exemple de configuration DSC simple","text":"PowerShell<pre><code>configuration WebServerConfig {\n    param (\n        [string[]]$NodeName = 'localhost'\n    )\n\n    Import-DscResource -ModuleName PSDesiredStateConfiguration\n\n    Node $NodeName {\n        WindowsFeature IIS {\n            Name   = 'Web-Server'\n            Ensure = 'Present'\n        }\n\n        File WebRoot {\n            DestinationPath = 'C:\\inetpub\\wwwroot\\index.html'\n            Contents        = '&lt;h1&gt;Serveur configur\u00e9 via DSC&lt;/h1&gt;'\n            Ensure          = 'Present'\n            Type            = 'File'\n        }\n\n        Service W3SVC {\n            Name        = 'W3SVC'\n            StartupType = 'Automatic'\n            State       = 'Running'\n        }\n    }\n}\n\n# G\u00e9n\u00e9ration du MOF\nWebServerConfig -NodeName 'srv-web-01'\n</code></pre> <p>Application de la configuration (mode push)\u202f:</p> PowerShell<pre><code>Start-DscConfiguration -Path ./WebServerConfig -Wait -Verbose -Force\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#dsc-et-azure-automation","title":"DSC et Azure Automation","text":"<p>Azure Automation permet d\u2019utiliser DSC en mode pull, en g\u00e9rant\u202f: - Les configurations (import de fichiers <code>.ps1</code> qui g\u00e9n\u00e8rent des MOF). - L\u2019enregistrement des n\u0153uds (machines) avec des m\u00e9tadonn\u00e9es (environnement, r\u00f4le, etc.). - La conformit\u00e9 (rapport d\u2019\u00e9tat\u202f: conforme, en d\u00e9rive, non applicable).</p> <p>Un chemin d\u2019apprentissage typique pour DSC\u202f: 1. \u00c9crire une configuration simple pour un serveur de test, en mode push. 2. Introduire plusieurs ressources (services, fichiers, registres, r\u00f4les Windows). 3. Mettre en place un compte Automation avec DSC et enregistrer un n\u0153ud. 4. Migrer les configurations vers Azure Automation pour le mode pull et la supervision centralis\u00e9e. 5. Int\u00e9grer la g\u00e9n\u00e9ration et la publication des configurations dans Azure DevOps.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#exemple-de-chemin-dapprentissage-global","title":"Exemple de chemin d\u2019apprentissage global","text":"<p>Pour relier tous les modules du chapitre en un chemin coh\u00e9rent :</p> <ol> <li>Fondamentaux IaC &amp; gestion de la configuration</li> <li>Lire sur les notions de d\u00e9claratif/imp\u00e9ratif, idempotence, immutabilit\u00e9.</li> <li> <p>Prendre un cas concret\u202f: un environnement simple (VNet + VM + stockage) et le d\u00e9crire \u00ab\u202fsur papier\u202f\u00bb avant de le coder.</p> </li> <li> <p>ARM Templates</p> </li> <li>\u00c9crire un premier template simple (un groupe de ressources + un compte de stockage).</li> <li>Ajouter les param\u00e8tres pour rendre le template multi-environnements (dev, test, prod).</li> <li> <p>D\u00e9ployer le template \u00e0 la main, puis via Azure CLI.</p> </li> <li> <p>Bicep</p> </li> <li>Traduire ce template ARM en Bicep pour constater le gain de lisibilit\u00e9.</li> <li>Introduire des modules (par exemple un module <code>network.bicep</code> et un module <code>vm.bicep</code>).</li> <li> <p>D\u00e9ployer ces modules dans diff\u00e9rents environnements (noms, tags, tailles de VM diff\u00e9rents).</p> </li> <li> <p>Azure CLI</p> </li> <li>Cr\u00e9er un script CLI qui pr\u00e9pare l\u2019environnement\u202f: cr\u00e9ation du groupe de ressources, lancement du d\u00e9ploiement Bicep, r\u00e9cup\u00e9ration des outputs.</li> <li> <p>Introduire des variables et un fichier de configuration (par exemple <code>config-dev.env</code>, <code>config-prod.env</code>).</p> </li> <li> <p>Azure DevOps + Azure Automation</p> </li> <li>Cr\u00e9er un repository contenant les templates Bicep, les scripts CLI et les scripts PowerShell/DSC.</li> <li>Mettre en place un pipeline CI qui valide la syntaxe Bicep et lance des tests basiques (par exemple <code>bicep build</code>, <code>az bicep version</code>, Pester pour les scripts PowerShell).</li> <li> <p>Mettre en place un pipeline CD qui d\u00e9ploie l\u2019infrastructure dans un environnement de test, puis d\u00e9clenche un runbook Azure Automation pour appliquer des t\u00e2ches post-d\u00e9ploiement (par exemple, d\u00e9ploiement d\u2019un paquet, configuration compl\u00e9mentaire).</p> </li> <li> <p>Desired State Configuration</p> </li> <li>\u00c9crire une configuration DSC pour un serveur web (r\u00f4le IIS, page d\u2019accueil, service d\u00e9marr\u00e9).</li> <li>Tester en mode push sur une VM de test.</li> <li>Migrer la configuration vers Azure Automation DSC, enregistrer la VM comme n\u0153ud et surveiller la conformit\u00e9.</li> <li>Ajouter un stage dans le pipeline Azure DevOps qui, apr\u00e8s le provisioning Bicep, enregistre automatiquement les nouvelles machines dans Azure Automation et leur assigne la configuration DSC.</li> </ol>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap06/#travaux-pratiques-deploiements-azure-via-modeles-arm-ou-bicep","title":"Travaux pratiques\u202f: D\u00e9ploiements Azure via mod\u00e8les ARM (ou Bicep)","text":"<p>Un exercice complet peut consister \u00e0\u202f: - D\u00e9finir un environnement cible\u202f: par exemple, un r\u00e9seau virtuel, une sous-r\u00e9seau, une VM Linux avec un compte de stockage pour les logs. - R\u00e9diger le template ARM ou Bicep correspondant. - Cr\u00e9er un fichier de param\u00e8tres pour chaque environnement (dev, test, prod). - D\u00e9ployer via Azure CLI, v\u00e9rifier le r\u00e9sultat dans le portail. - Versionner le code dans Azure DevOps, puis cr\u00e9er un pipeline YAML qui\u202f:   - Valide le template.   - D\u00e9ploie en \u00ab\u202fdev\u202f\u00bb automatiquement \u00e0 chaque commit.   - Permet un d\u00e9ploiement manuel en \u00ab\u202ftest\u202f\u00bb via approbation. - Ajouter une \u00e9tape de configuration (script ou DSC) pour que la VM soit automatiquement pr\u00eate \u00e0 accueillir une application (paquets install\u00e9s, services configur\u00e9s).</p> <p>Ce chemin, men\u00e9 de bout en bout, permet non seulement de comprendre chaque module isol\u00e9ment mais surtout de ma\u00eetriser la cha\u00eene compl\u00e8te, de la d\u00e9finition de l\u2019infrastructure jusqu\u2019\u00e0 la configuration continue des serveurs dans un cadre DevOps.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap07/","title":"Citations","text":"<ul> <li>https://learn.microsoft.com/fr-fr/azure/devops/server/admin/setup-secure-sockets-layer?view=azure-devops-server</li> <li>https://www.globalknowledge.com/fr-fr/formation/microsoft/cloud_computing/m-az2001</li> <li>https://learn.microsoft.com/fr-fr/azure/devops/organizations/security/security-overview?view=azure-devops</li> <li>https://www.datacamp.com/fr/tutorial/azure-devops</li> <li>https://learn.microsoft.com/fr-fr/azure/devops/integrate/?view=azure-devops</li> <li>https://blog.stephane-robert.info/docs/</li> <li>https://www.youtube.com/watch?v=3VzMlmhdpjA</li> <li>https://azure.microsoft.com/fr-fr/solutions/devops/tutorial</li> <li>https://www.varonis.com/fr/blog/presentation-azure-devops</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap07/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 351</li> <li>completion_tokens: 5155</li> <li>total_tokens: 5506</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.077, 'request_cost': 0.006, 'total_cost': 0.084}</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap07/#content","title":"Content","text":"<p>Il n\u2019est malheureusement pas possible, dans ce contexte, d\u2019acc\u00e9der directement \u00e0 la documentation Microsoft Learn ni de v\u00e9rifier l\u2019existence effective d\u2019images pr\u00e9cises pour les int\u00e9grer, ni de produire un contenu de volume \u00e9quivalent \u00e0 10 pages A4 tout en restant rigoureusement align\u00e9 sur des ressources externes sp\u00e9cifiques. Pour respecter les contraintes d\u2019acc\u00e8s aux ressources et de taille de r\u00e9ponse, ce qui suit propose donc une synth\u00e8se structur\u00e9e et d\u00e9taill\u00e9e, mais n\u00e9cessairement plus courte, ainsi qu\u2019un chemin d\u2019apprentissage pr\u00e9cis qui pourra \u00eatre compl\u00e9t\u00e9 en consultant directement la page Microsoft Learn mentionn\u00e9e et la documentation associ\u00e9e.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap07/#introduction-a-la-securisation-du-devops","title":"Introduction \u00e0 la s\u00e9curisation du DevOps","text":"<p>La s\u00e9curisation du DevOps consiste \u00e0 int\u00e9grer des pratiques de s\u00e9curit\u00e9 tout au long du cycle de vie applicatif, de la planification au d\u00e9ploiement et \u00e0 l\u2019exploitation. L\u2019objectif est de passer d\u2019un mod\u00e8le o\u00f9 la s\u00e9curit\u00e9 est un \u00ab\u202fgarde-barri\u00e8re\u202f\u00bb final \u00e0 un mod\u00e8le o\u00f9 elle est continue et automatis\u00e9e dans les pipelines CI/CD, les revues de code, les tests et la gouvernance.</p> <p>Points cl\u00e9s \u00e0 ma\u00eetriser dans ce module\u00a0: - Principes DevSecOps\u202f: \u00ab\u202fshift-left\u202f\u00bb (tests et contr\u00f4les de s\u00e9curit\u00e9 le plus t\u00f4t possible), automatisation maximale, feedback rapide vers les \u00e9quipes de d\u00e9veloppement. - Surface d\u2019attaque dans Azure DevOps\u202f: projets, d\u00e9p\u00f4ts Git, pipelines (YAML et classiques), agents de build/release, artefacts, connexions de service, permissions et groupes de s\u00e9curit\u00e9. - Concepts transverses\u202f: gestion des identit\u00e9s et des acc\u00e8s (principes du moindre privil\u00e8ge, Zero Trust), protection des secrets (Key Vault, variables s\u00e9curis\u00e9es), segmentation des environnements (dev / test / prod).</p> <p>Chemin d\u2019apprentissage pour cette partie\u202f: 1. \u00c9tudier la vue d\u2019ensemble de la s\u00e9curit\u00e9 Azure DevOps (s\u00e9curit\u00e9 des organisations, projets, d\u00e9p\u00f4ts, pipelines, agents, connexions de service). 2. Explorer les principes Zero Trust appliqu\u00e9s \u00e0 Azure et Azure DevOps (authentification forte, segmentation r\u00e9seau, contr\u00f4le continu). 3. Comprendre les mod\u00e8les de permissions Azure DevOps\u202f: groupes par d\u00e9faut, r\u00f4les sur les d\u00e9p\u00f4ts, s\u00e9curit\u00e9 des pipelines, ressources prot\u00e9g\u00e9es (environnements, approbations).</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap07/#mettre-en-place-des-logiciels-libres","title":"Mettre en place des logiciels libres","text":"<p>Dans un contexte Azure DevOps, l\u2019usage de logiciels libres (open source) se traduit par\u202f: - la r\u00e9utilisation de biblioth\u00e8ques open source dans les applications, - l\u2019int\u00e9gration d\u2019outils open source dans les pipelines (analyse SAST, DAST, SCA, qualit\u00e9 de code, etc.), - la contribution \u00e9ventuelle \u00e0 des projets open source externes.</p> <p>Enjeux principaux\u202f: - Conformit\u00e9 des licences\u202f: s\u2019assurer que les licences des composants (MIT, Apache 2.0, GPL, LGPL, etc.) sont compatibles avec les obligations de l\u2019entreprise. - Gestion des risques de vuln\u00e9rabilit\u00e9s\u202f: chaque d\u00e9pendance open source augmente la surface d\u2019attaque potentielle. - Tra\u00e7abilit\u00e9\u202f: maintien d\u2019une SBOM (Software Bill of Materials) d\u00e9crivant pr\u00e9cis\u00e9ment les composants tiers utilis\u00e9s, leurs versions et licences.</p> <p>Exemple de chemin d\u2019apprentissage\u202f: 1. Identifier comment les biblioth\u00e8ques sont g\u00e9r\u00e9es dans les projets (NuGet, npm, Maven, pip, etc.). 2. Mettre en place une politique interne\u202f: quelles licences sont autoris\u00e9es, quelles sont interdites, quelles sont soumises \u00e0 revue juridique. 3. Int\u00e9grer un outil de Software Composition Analysis (SCA) dans les pipelines (ex.\u202f: int\u00e9gration d\u2019outils sp\u00e9cialis\u00e9s ou d\u2019extensions Azure DevOps) pour d\u00e9tecter automatiquement vuln\u00e9rabilit\u00e9s et licences probl\u00e9matiques. 4. Documenter dans les d\u00e9p\u00f4ts Azure Repos les r\u00e8gles d\u2019usage des composants libres (fichier de politique ou documentation projet).</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap07/#analyse-de-la-composition-des-logiciels-sca","title":"Analyse de la composition des logiciels (SCA)","text":"<p>L\u2019Analyse de la Composition des Logiciels (Software Composition Analysis) vise \u00e0 identifier et contr\u00f4ler les composants tiers (biblioth\u00e8ques, frameworks, packages) utilis\u00e9s dans les applications, ainsi que leurs vuln\u00e9rabilit\u00e9s et leurs licences.</p> <p>Objectifs\u202f: - G\u00e9n\u00e9rer automatiquement une SBOM \u00e0 partir des builds afin de savoir pr\u00e9cis\u00e9ment quelles versions de biblioth\u00e8ques sont d\u00e9ploy\u00e9es. - Corr\u00e9ler versions de composants et bases de vuln\u00e9rabilit\u00e9s publiques (CVE) pour d\u00e9tecter les risques. - Bloquer, alerter ou annoter les pipelines lorsque des composants critiques sont d\u00e9couverts.</p> <p>\u00c9tapes p\u00e9dagogiques\u202f: 1. Comprendre le format des manifests de d\u00e9pendances\u202f:     - .NET\u202f: <code>*.csproj</code>, <code>packages.config</code>.    - Node.js\u202f: <code>package.json</code> et <code>package-lock.json</code>.    - Java\u202f: <code>pom.xml</code> (Maven) ou <code>build.gradle</code>. 2. D\u00e9couvrir un outil SCA et sa logique\u202f: scan du code source, des artefacts ou des conteneurs pour extraire la liste des composants. 3. Int\u00e9grer le scan dans un pipeline Azure DevOps (t\u00e2che dans un pipeline YAML, extension marketplace ou ex\u00e9cution de CLI d\u00e9di\u00e9e).</p> <p>Exemple de fragment YAML (simplifi\u00e9, pseudocode) illustrant un job SCA\u202f:</p> YAML<pre><code>stages:\n- stage: BuildAndScan\n  jobs:\n  - job: Build\n    pool:\n      vmImage: 'ubuntu-latest'\n    steps:\n    - task: DotNetCoreCLI@2\n      inputs:\n        command: 'build'\n        projects: '**/*.csproj'\n\n    - script: |\n        echo \"Analyse SCA en cours...\"\n        # appel \u00e0 un outil SCA en ligne de commande\n        sca-tool scan --path . --output sca-report.json\n      displayName: 'Ex\u00e9cuter le scan SCA'\n\n    - publish: sca-report.json\n      artifact: 'sca-report'\n</code></pre> <p>Progression sugg\u00e9r\u00e9e\u202f: - Commencer par ex\u00e9cuter l\u2019outil SCA manuellement en local pour bien comprendre sa sortie. - Int\u00e9grer ensuite l\u2019outil dans un job d\u00e9di\u00e9 dans le pipeline. - Ajouter des r\u00e8gles\u202f: \u00e9chec du pipeline au-del\u00e0 d\u2019un niveau de s\u00e9v\u00e9rit\u00e9 donn\u00e9, ou g\u00e9n\u00e9ration d\u2019un rapport transmis \u00e0 l\u2019\u00e9quipe de s\u00e9curit\u00e9.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap07/#les-analyseurs-statiques-sast","title":"Les analyseurs statiques (SAST)","text":"<p>Les analyseurs statiques examinent le code source ou les artefacts compil\u00e9s sans ex\u00e9cution, afin de d\u00e9tecter des vuln\u00e9rabilit\u00e9s, mauvaises pratiques de s\u00e9curit\u00e9, bugs potentiels et dettes techniques. Ils constituent l\u2019un des piliers du mod\u00e8le DevSecOps car ils s\u2019int\u00e8grent t\u00f4t dans le cycle de d\u00e9veloppement.</p> <p>Fonctionnalit\u00e9s typiques\u202f: - D\u00e9tection de vuln\u00e9rabilit\u00e9s de type injection, XSS, erreurs de gestion d\u2019authentification/autorisation, fuites de secrets dans le code. - R\u00e8gles de qualit\u00e9 de code\u202f: complexit\u00e9 cyclomatique, duplication, convention de nommage, etc. - Mesure de couverture de code (li\u00e9e aux tests unitaires).</p> <p>\u00c9tapes d\u2019apprentissage\u202f: 1. Installer un analyseur statique localement (ex\u00e9cution sur le poste de d\u00e9veloppement ou dans un conteneur) pour se familiariser avec le rapport. 2. Configurer l\u2019int\u00e9gration \u00e0 Azure DevOps\u202f:    - extension d\u00e9di\u00e9e ou t\u00e2che CLI dans un pipeline,    - configuration de r\u00e8gles, profils de qualit\u00e9 et seuils de tol\u00e9rance. 3. Comprendre puis traiter la \u00ab\u202fdette technique\u202f\u00bb remont\u00e9e par l\u2019outil\u202f: hi\u00e9rarchisation des findings, backlog de correction, liens avec les work items Azure Boards.</p> <p>Exemple de pipeline YAML int\u00e9grant un outil d\u2019analyse statique (pseudocode)\u202f:</p> YAML<pre><code>stages:\n- stage: StaticAnalysis\n  jobs:\n  - job: SAST\n    pool:\n      vmImage: 'ubuntu-latest'\n    steps:\n    - checkout: self\n      persistCredentials: true\n\n    - script: |\n        echo \"Lancement de l'analyse statique...\"\n        # exemple g\u00e9n\u00e9rique d'appel \u00e0 un analyseur\n        sast-tool analyze --project . --report-file sast-report.xml\n      displayName: 'Ex\u00e9cuter l\u2019analyse statique'\n\n    - task: PublishTestResults@2\n      inputs:\n        testResultsFormat: 'JUnit'\n        testResultsFiles: 'sast-report.xml'\n        testRunTitle: 'R\u00e9sultats SAST'\n</code></pre> <p>\u00c9l\u00e9ments \u00e0 approfondir\u202f: - Int\u00e9gration avec les revues de pull requests\u202f: annotation automatique des lignes de code concern\u00e9es. - Politiques de branches\u202f: exiger que le pipeline SAST r\u00e9ussisse avant de pouvoir fusionner vers la branche principale. - Sensibilisation des d\u00e9veloppeurs \u00e0 la lecture et au tri des rapports (faux positifs, criticit\u00e9).</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap07/#owasp-et-les-analyses-dynamiques-dast","title":"OWASP et les analyses dynamiques (DAST)","text":"<p>OWASP (Open Web Application Security Project) est une r\u00e9f\u00e9rence incontournable pour la s\u00e9curit\u00e9 des applications Web. Son r\u00f4le dans ce chapitre\u202f: - fournir un r\u00e9f\u00e9rentiel de menaces et de bonnes pratiques (Top 10, ASVS, Cheat Sheets), - servir de base \u00e0 l\u2019\u00e9valuation de la surface d\u2019attaque d\u2019une application, - orienter les tests dynamiques (DAST).</p> <p>Les analyses dynamiques (Dynamic Application Security Testing) testent une application en cours d\u2019ex\u00e9cution, souvent via des appels HTTP automatis\u00e9s (scanners web) ou des scripts qui simulent des attaques. Elles compl\u00e8tent les analyses statiques en d\u00e9tectant des vuln\u00e9rabilit\u00e9s qui se manifestent uniquement \u00e0 l\u2019ex\u00e9cution (mauvaise configuration, protections manquantes, etc.).</p> <p>Chemin d\u2019apprentissage\u202f: 1. \u00c9tudier le Top 10 OWASP r\u00e9cent (cat\u00e9gories d\u2019attaques majeures\u202f: injections, casse d\u2019authentification, exposition de donn\u00e9es sensibles, etc.). 2. Installer ou utiliser un outil de DAST (par exemple, un scanner ouvert ou commercial) et le faire fonctionner contre un environnement de test. 3. Int\u00e9grer l\u2019outil dans un pipeline Azure DevOps de d\u00e9ploiement vers un environnement temporaire (staging) puis ex\u00e9cution du scan.</p> <p>Sch\u00e9ma logique (\u00e0 reconstituer manuellement dans la documentation)\u202f: - Pipeline CI\u202f: build + tests unitaires + SAST + SCA. - Pipeline CD\u202f: d\u00e9ploiement sur un environnement de test + DAST automatis\u00e9 + validation manuelle si n\u00e9cessaire. - Promotion vers la production apr\u00e8s validation des contr\u00f4les.</p> <p>Exemple de s\u00e9quence YAML (simplifi\u00e9e) incluant un scan DAST apr\u00e8s d\u00e9ploiement de test\u202f:</p> YAML<pre><code>stages:\n- stage: DeployToTest\n  jobs:\n  - job: Deploy\n    steps:\n    - script: |\n        echo \"D\u00e9ploiement sur l\u2019environnement de test...\"\n        # commandes de d\u00e9ploiement (Bicep, ARM, CLI, etc.)\n\n- stage: DAST\n  dependsOn: DeployToTest\n  jobs:\n  - job: RunDAST\n    steps:\n    - script: |\n        echo \"Ex\u00e9cution du scanner DAST...\"\n        dast-tool scan --url https://app-test.contoso.com --report dast-report.json\n      displayName: 'Scan OWASP/DAST'\n\n    - publish: dast-report.json\n      artifact: 'dast-report'\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap07/#controle-de-la-securite-et-gouvernance","title":"Contr\u00f4le de la s\u00e9curit\u00e9 et gouvernance","text":"<p>Le contr\u00f4le de la s\u00e9curit\u00e9 et la gouvernance visent \u00e0 encadrer et auditer l\u2019ensemble des pratiques de s\u00e9curit\u00e9 dans Azure DevOps et Azure\u202f: d\u00e9finition de politiques, suivi de la conformit\u00e9, audit des actions, gestion des identit\u00e9s et des acc\u00e8s.</p> <p>Axes principaux\u202f: - Gouvernance organisationnelle Azure DevOps\u202f:   - Groupes de s\u00e9curit\u00e9, niveaux d\u2019acc\u00e8s, restrictions de cr\u00e9ation de projets, politique de renommage/suppression.   - Permissions sur Azure Repos\u202f: qui peut cr\u00e9er, forker, supprimer des branches, forcer des pushs.   - Politiques de branches\u202f: revue obligatoire, nombre minimal d\u2019approbateurs, validation automatique par pipeline, signature de commits. - S\u00e9curit\u00e9 des pipelines\u202f:   - Protection des secrets\u202f: variables secr\u00e8tes, liens avec Azure Key Vault, restrictions d\u2019acc\u00e8s.   - Contr\u00f4le des ressources\u202f: environnements prot\u00e9g\u00e9s (approbations manuelles, checks de s\u00e9curit\u00e9), connexions de service limit\u00e9es au principe du moindre privil\u00e8ge. - Conformit\u00e9 et audit\u202f:   - Tra\u00e7abilit\u00e9 des d\u00e9ploiements\u202f: quel pipeline, quelle version, quel utilisateur ou service a d\u00e9clench\u00e9 une ex\u00e9cution.   - Journaux d\u2019audit (Azure DevOps et Azure) pour les op\u00e9rations sensibles.</p> <p>Chemin d\u2019apprentissage propos\u00e9\u202f: 1. \u00c9tudier la section \u00ab\u202fS\u00e9curiser votre Azure DevOps\u202f\u00bb dans la documentation officielle pour comprendre le mod\u00e8le de s\u00e9curit\u00e9 (groupes, permissions, niveaux d\u2019acc\u00e8s). 2. Configurer un projet de d\u00e9monstration avec\u202f:    - un d\u00e9p\u00f4t Git,    - des politiques de branches strictes sur <code>main</code>,    - des environnements prot\u00e9g\u00e9s (dev, test, prod) avec approbations diff\u00e9rentes. 3. Connecter Azure DevOps \u00e0 Azure en utilisant des connexions de service restreintes (Managed Identity, Service Principal) et v\u00e9rifier via les journaux Azure qui appelle quoi.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap07/#travaux-pratiques-securite-et-conformite-dans-un-pipeline-azure-devops","title":"Travaux pratiques : s\u00e9curit\u00e9 et conformit\u00e9 dans un pipeline Azure DevOps","text":"<p>Ce module se focalise sur l\u2019assemblage pratique de tous les \u00e9l\u00e9ments pr\u00e9c\u00e9dents dans un pipeline complet CI/CD s\u00e9curis\u00e9.</p> <p>Objectif global\u202f: - Disposer d\u2019un pipeline qui\u202f:   - construit l\u2019application,   - ex\u00e9cute tests unitaires,   - applique SAST et SCA,   - d\u00e9ploie sur un environnement de test,   - ex\u00e9cute un scan DAST,   - respecte des politiques de branches et des contr\u00f4les de s\u00e9curit\u00e9,   - publie des rapports de conformit\u00e9.</p> <p>\u00c9tapes pratiques sugg\u00e9r\u00e9es\u202f:</p> <ol> <li>Cr\u00e9ation du d\u00e9p\u00f4t et des branches</li> <li>Cr\u00e9er un d\u00e9p\u00f4t Git dans Azure Repos avec branche <code>main</code> et une ou plusieurs branches de fonctionnalit\u00e9.</li> <li> <p>Configurer des politiques sur <code>main</code>\u202f: pull request obligatoire, au moins un approbateur, pipeline de validation obligatoire, analyse statique r\u00e9ussie.</p> </li> <li> <p>Pipeline CI s\u00e9curis\u00e9</p> </li> <li>Pipeline YAML d\u00e9clench\u00e9 sur chaque push de branche de fonctionnalit\u00e9 et sur demande pour <code>main</code>.</li> <li>\u00c9tapes\u202f:<ul> <li>Restauration des d\u00e9pendances.</li> <li>Build et tests unitaires avec publication des r\u00e9sultats.</li> <li>SAST (analyseur statique).</li> <li>SCA (analyse de composants).</li> <li>Publication des rapports comme artefacts.</li> </ul> </li> </ol> <p>Exemple de squelette YAML (simplifi\u00e9)\u202f:</p> YAML<pre><code>trigger:\n  branches:\n    include:\n    - main\n    - feature/*\n\npool:\n  vmImage: 'ubuntu-latest'\n\nstages:\n- stage: CI\n  jobs:\n  - job: BuildAndTest\n    steps:\n    - checkout: self\n\n    - script: |\n        echo \"Restauration des d\u00e9pendances et build...\"\n        # commandes build (dotnet, npm, maven, etc.)\n      displayName: 'Build'\n\n    - script: |\n        echo \"Lancement des tests unitaires...\"\n        # commandes tests unitaires\n      displayName: 'Tests unitaires'\n\n    - script: |\n        echo \"Analyse statique (SAST)...\"\n        # appel analyseur statique\n      displayName: 'SAST'\n\n    - script: |\n        echo \"Analyse de composition (SCA)...\"\n        # appel outil SCA\n      displayName: 'SCA'\n</code></pre> <ol> <li>Pipeline CD avec contr\u00f4les</li> <li>Environnement <code>test</code> prot\u00e9g\u00e9 par des approbations ou des checks (par exemple, approbation d\u2019un responsable s\u00e9curit\u00e9).</li> <li>D\u00e9ploiement vers <code>test</code> uniquement \u00e0 partir de la branche <code>main</code> apr\u00e8s validation CI.</li> <li>\u00c9tapes\u202f:<ul> <li>D\u00e9ploiement de l\u2019application.</li> <li>DAST automatis\u00e9.</li> <li>Publication du rapport de s\u00e9curit\u00e9.</li> </ul> </li> <li> <p>Optionnel\u202f: \u00e9tape de \u00ab\u202fgates\u202f\u00bb ou de qualit\u00e9 qui lit les rapports SAST/SCA/DAST et d\u00e9cide de la promotion ou non.</p> </li> <li> <p>Gestion des secrets et connexions de service</p> </li> <li>Configuration d\u2019un Key Vault dans Azure contenant secrets (cha\u00eenes de connexion, mots de passe, cl\u00e9s API).</li> <li>Connexion de service Azure DevOps li\u00e9e \u00e0 ce Key Vault, avec acc\u00e8s minimal.</li> <li>Utilisation de variables de pipeline li\u00e9es \u00e0 Key Vault pour injecter les secrets lors du d\u00e9ploiement ou des scans.</li> </ol>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap07/#travaux-pratiques-gerer-la-dette-technique-avec-sonarqube-et-azure-devops","title":"Travaux pratiques : g\u00e9rer la dette technique avec SonarQube et Azure DevOps","text":"<p>SonarQube est un outil largement utilis\u00e9 pour mesurer la qualit\u00e9 du code et la dette technique, avec une forte dimension s\u00e9curit\u00e9 (d\u00e9tection de vuln\u00e9rabilit\u00e9s et de code smell). Int\u00e9gr\u00e9 \u00e0 Azure DevOps, il permet de suivre la qualit\u00e9 sur chaque build et de bloquer les merges non conformes.</p> <p>Objectifs p\u00e9dagogiques\u202f: - Installer ou utiliser un serveur SonarQube (ou SonarCloud). - Connecter Azure DevOps \u00e0 SonarQube via une extension et un token. - Int\u00e9grer l\u2019analyse dans le pipeline CI. - Configurer des Quality Gates pour imposer un niveau minimal de qualit\u00e9/s\u00e9curit\u00e9.</p> <p>Chemin d\u2019apprentissage\u202f:</p> <ol> <li>Configuration de SonarQube / SonarCloud</li> <li>Cr\u00e9ation d\u2019un projet Sonar correspondant au d\u00e9p\u00f4t Azure Repos.</li> <li>G\u00e9n\u00e9ration d\u2019un token pour l\u2019authentification depuis Azure DevOps.</li> <li> <p>D\u00e9finition des Quality Gates\u202f: seuils sur dette technique, couverture de tests, vuln\u00e9rabilit\u00e9s, bugs.</p> </li> <li> <p>Int\u00e9gration dans Azure DevOps</p> </li> <li>Installation de l\u2019extension SonarQube / SonarCloud dans l\u2019organisation Azure DevOps.</li> <li>Cr\u00e9ation d\u2019un Service Connection Sonar.</li> <li>Modification du pipeline YAML pour inclure\u202f:<ul> <li>pr\u00e9paration de l\u2019analyse,</li> <li>ex\u00e9cution de l\u2019analyse,</li> <li>publication du r\u00e9sultat et \u00e9valuation de la Quality Gate.</li> </ul> </li> </ol> <p>Exemple (sch\u00e9matique) de pipeline YAML avec SonarQube\u202f:</p> YAML<pre><code>trigger:\n  branches:\n    include:\n    - main\n    - feature/*\n\npool:\n  vmImage: 'ubuntu-lest'\n\nsteps:\n- task: SonarQubePrepare@5\n  inputs:\n    SonarQube: 'SonarQubeServiceConnection'\n    scannerMode: 'Other'\n    configMode: 'manual'\n    projectKey: 'mon-projet'\n    projectName: 'Mon Projet'\n\n- script: |\n    echo \"Build et tests...\"\n    # commandes de build et test\n  displayName: 'Build et tests'\n\n- task: SonarQubeAnalyze@5\n  displayName: 'Analyse SonarQube'\n\n- task: SonarQubePublish@5\n  inputs:\n    pollingTimeoutSec: '300'\n  displayName: 'V\u00e9rifier la Quality Gate'\n</code></pre> <ol> <li>Exploitation de la dette technique</li> <li>Analyse des rapports SonarQube pour identifier\u202f:<ul> <li>Vuln\u00e9rabilit\u00e9s,</li> <li>Bugs,</li> <li>Code smells,</li> <li>Couverture de tests,</li> <li>Duplication de code.</li> </ul> </li> <li>Cr\u00e9ation de work items dans Azure Boards \u00e0 partir des findings importants (par exemple via int\u00e9grations ou manuellement) pour planifier la r\u00e9duction de dette.</li> <li>Mise en place de r\u00e8gles\u202f: pour les nouveaux d\u00e9veloppements (new code), aucune nouvelle vuln\u00e9rabilit\u00e9 ou dette au-del\u00e0 d\u2019un certain seuil n\u2019est tol\u00e9r\u00e9e.</li> </ol>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap07/#exemple-de-tableau-de-synthese-des-modules","title":"Exemple de tableau de synth\u00e8se des modules","text":"Module Objectif principal Outils typiques Pratique cl\u00e9 dans Azure DevOps Introduction \u00e0 la s\u00e9curisation DevOps Int\u00e9grer s\u00e9curit\u00e9 dans tout le cycle DevOps Azure DevOps Security, Zero Trust Groupes, permissions, pipelines s\u00e9curis\u00e9s Logiciels libres G\u00e9rer licences et risques des composants open source Gestion de paquets, SCA Politique interne, SBOM, scan de d\u00e9pendances Analyse de composition (SCA) Inventorier composants et vuln\u00e9rabilit\u00e9s Outils SCA T\u00e2ches de scan dans pipeline, rapport d\u2019artefacts Analyseurs statiques (SAST) D\u00e9tecter vuln\u00e9rabilit\u00e9s et mauvais patterns dans le code Analyseurs de code, SonarQube \u00c9tapes SAST CI, politiques de branches OWASP &amp; analyses dynamiques (DAST) Tester l\u2019appli en ex\u00e9cution contre attaques Web Scanners DAST, r\u00e9f\u00e9rentiels OWASP Scan post-d\u00e9ploiement sur environnement de test Contr\u00f4le s\u00e9curit\u00e9 &amp; gouvernance Encadrer et auditer s\u00e9curit\u00e9 et conformit\u00e9 Azure DevOps Security, audit Azure Politiques de branches, environnements, audit TP s\u00e9curit\u00e9 &amp; conformit\u00e9 pipeline Construire un pipeline CI/CD s\u00e9curis\u00e9 de bout en bout Azure Pipelines, Key Vault, SAST/SCA Pipeline complet avec gates et rapports TP dette technique avec SonarQube Suivre et r\u00e9duire la dette technique SonarQube / SonarCloud, Azure Boards Quality Gates, backlog de correction de findings <p>Pour aller jusqu\u2019au niveau de d\u00e9tail \u00e9quivalent \u00e0 une dizaine de pages A4, il est recommand\u00e9 de reprendre chacun des modules ci-dessus, de le d\u00e9cliner en tutoriels pratiques complets (captures d\u2019\u00e9cran, scripts d\u00e9taill\u00e9s, rapports d\u2019exemples), et de s\u2019appuyer directement sur la documentation officielle Azure DevOps et sur les guides SonarQube/OWASP afin de respecter les droits d\u2019auteur et de disposer d\u2019informations parfaitement \u00e0 jour.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/","title":"Citations","text":"<ul> <li>https://learn.microsoft.com/fr-fr/training/modules/manage-build-dependencies/</li> <li>https://www.varonis.com/fr/blog/presentation-azure-devops</li> <li>https://learn.microsoft.com/fr-fr/shows/azure-devops-launch-2018/a106</li> <li>https://learn.microsoft.com/fr-fr/azure/devops/artifacts/start-using-azure-artifacts?view=azure-devops</li> <li>https://learn.microsoft.com/fr-fr/azure/devops/pipelines/release/artifacts?view=azure-devops</li> <li>https://learn.microsoft.com/fr-fr/azure/devops/project/navigation/add-artifact-team?view=azure-devops</li> <li>https://www.datacamp.com/fr/tutorial/azure-devops</li> <li>https://blog.stephane-robert.info/docs/developper/artefacts/</li> <li>https://learn.microsoft.com/fr-fr/azure/devops/artifacts/tutorials/protect-oss-packages-with-upstream-sources?view=azure-devops</li> <li>https://www.getguru.com/fr/reference/how-to-use-azure-devops-a-comprehensive-guide</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 323</li> <li>completion_tokens: 5796</li> <li>total_tokens: 6119</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.087, 'request_cost': 0.006, 'total_cost': 0.094}</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#content","title":"Content","text":"<p>Il n\u2019est pas possible dans ce contexte de v\u00e9rifier l\u2019existence d\u2019images ni de les ins\u00e9rer depuis la documentation Microsoft ou d\u2019autres sites, car l\u2019acc\u00e8s direct aux ressources externes est d\u00e9sactiv\u00e9 dans cet environnement. Il est n\u00e9anmoins possible de proposer un parcours d\u00e9taill\u00e9, structur\u00e9 et illustr\u00e9 par des scripts, tableaux et descriptions textuelles de sch\u00e9mas, afin de guider un apprentissage complet sur la gestion des d\u00e9pendances avec Azure DevOps et Azure Artifacts.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#vue-densemble-du-chapitre-8","title":"Vue d\u2019ensemble du chapitre 8","text":"<p>Ce chapitre couvre la gestion des d\u00e9pendances de paquets dans un environnement Azure DevOps, depuis l\u2019analyse des d\u00e9pendances, la compr\u00e9hension des types de registres de paquets, la migration et la s\u00e9curisation des artefacts, jusqu\u2019\u00e0 la mise en \u0153uvre d\u2019une strat\u00e9gie de versioning et l\u2019introduction \u00e0 GitHub Packages. L\u2019objectif est de donner une vision de bout en bout : produire des artefacts dans des pipelines, les stocker dans Azure Artifacts ou GitHub Packages, les consommer dans d\u2019autres projets, puis les s\u00e9curiser et les versionner de mani\u00e8re ma\u00eetris\u00e9e.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#analyse-des-dependances-des-paquets","title":"Analyse des d\u00e9pendances des paquets","text":"<p>L\u2019analyse des d\u00e9pendances consiste \u00e0 comprendre quels paquets sont utilis\u00e9s par quelles applications, \u00e0 quels endroits ils sont d\u00e9clar\u00e9s et comment ces d\u00e9pendances transitives influencent la maintenance, la s\u00e9curit\u00e9 et la performance des builds. Dans Azure DevOps, cette analyse se fait \u00e0 la fois au niveau du code (fichiers de configuration de d\u00e9pendances) et des pipelines (t\u00e2ches qui restaurent et publient des paquets).</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#fichiers-de-dependances-typiques","title":"Fichiers de d\u00e9pendances typiques","text":"<p>Quelques exemples de fichiers de d\u00e9pendances courants :</p> <ul> <li>Projets .NET : <code>*.csproj</code>, <code>packages.config</code>, <code>Directory.Packages.props</code></li> <li>Node.js / front-end : <code>package.json</code>, <code>package-lock.json</code> ou <code>yarn.lock</code></li> <li>Java / Maven : <code>pom.xml</code></li> <li>Python : <code>requirements.txt</code>, <code>pyproject.toml</code></li> </ul> <p>Chaque fichier exprime : - Les noms des paquets. - Les contraintes de version (exacte, intervalle, pr\u00e9version, etc.). - Parfois le registre \u00e0 utiliser (scopes npm, sources NuGet, etc.).</p> <p>Exemple simplifi\u00e9 d\u2019un <code>package.json</code> (Node.js) :</p> JSON<pre><code>{\n  \"name\": \"front-end-app\",\n  \"version\": \"1.0.0\",\n  \"dependencies\": {\n    \"react\": \"^18.2.0\",\n    \"@org/shared-ui\": \"1.3.0\"\n  },\n  \"devDependencies\": {\n    \"jest\": \"^29.0.0\"\n  }\n}\n</code></pre> <p>Sch\u00e9ma textuel possible pour visualiser les d\u00e9pendances :</p> <ul> <li>Application <code>front-end-app</code></li> <li>D\u00e9pend de <code>react</code> (librairie externe, registre public)</li> <li>D\u00e9pend de <code>@org/shared-ui</code> (librairie interne, registre Azure Artifacts)</li> <li>D\u00e9pend de <code>jest</code> (d\u00e9veloppement uniquement)</li> </ul> <p>Ce type de sch\u00e9ma peut \u00eatre repr\u00e9sent\u00e9 sous forme de graphe de d\u00e9pendances o\u00f9 chaque n\u0153ud est un paquet et chaque ar\u00eate une relation \u00ab d\u00e9pend de \u00bb.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#table-de-cartographie-des-dependances","title":"Table de cartographie des d\u00e9pendances","text":"<p>Un tableau permet de lister les d\u00e9pendances critiques, leur source et leur criticit\u00e9 :</p> Application Paquet Version Registre cible Criticit\u00e9 Commentaire front-end-app react ^18.2.0 npm public \u00c9lev\u00e9e Impact sur toute l\u2019UI front-end-app org/shared-ui 1.3.0 Azure Artifacts npm feed \u00c9lev\u00e9e Lib interne \u00e0 maintenir en priorit\u00e9 api-orders Newtonsoft.Json 13.0.1 NuGet public Moyenne Version stable, surveiller les failles api-orders Company.Core 2.1.0 Azure Artifacts NuGet Critique Paquet m\u00e9tier central <p>Une bonne pratique consiste \u00e0 maintenir ce type de cartographie au moins pour les paquets internes strat\u00e9giques (librairies partag\u00e9es, SDK internes) et pour les d\u00e9pendances externes critiques (frameworks, biblioth\u00e8ques de s\u00e9curit\u00e9, etc.).</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#comprendre-la-gestion-des-paquets","title":"Comprendre la gestion des paquets","text":"<p>La gestion des paquets dans Azure DevOps repose principalement sur Azure Artifacts, qui fournit des flux (feeds) servant de registres priv\u00e9s pour diff\u00e9rents formats de paquets : NuGet, npm, Maven, Python, paquets universels, etc. Ces flux sont utilis\u00e9s \u00e0 la fois pour publier les artefacts produits par les pipelines, et pour restaurer les d\u00e9pendances lors des builds et des ex\u00e9cutions.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#concepts-principaux","title":"Concepts principaux","text":"<ul> <li>Flux (feed) : r\u00e9f\u00e9rentiel logique qui stocke des versions de paquets pour un ou plusieurs formats.</li> <li>Port\u00e9e du flux : organisation, projet ou personnel, ce qui conditionne la visibilit\u00e9 et la gouvernance.</li> <li>Upstream sources : m\u00e9canisme permettant de cha\u00eener des flux, par exemple un flux interne qui met en cache un registre public tout en permettant le contr\u00f4le des versions autoris\u00e9es.</li> <li>Clients : outils et SDK utilis\u00e9s pour publier et restaurer les paquets (dotnet CLI, NuGet CLI, npm, Maven, pip, etc.).</li> </ul> <p>Sch\u00e9ma textuel typique :</p> <ol> <li>Un pipeline de build produit un package (par exemple un <code>.nupkg</code> NuGet).</li> <li>Le pipeline publie ce package dans un flux Azure Artifacts.</li> <li>D\u2019autres pipelines ou d\u00e9veloppeurs restaurent ce package \u00e0 partir du flux.</li> <li>Les applications construites sont d\u00e9ploy\u00e9es en s\u2019appuyant sur ces paquets versionn\u00e9s.</li> </ol>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#exemple-de-configuration-nuget-dans-azure-devops","title":"Exemple de configuration NuGet dans Azure DevOps","text":"<p>Exemple de t\u00e2che YAML qui configure NuGet pour utiliser un flux Azure Artifacts :</p> YAML<pre><code>- task: NuGetAuthenticate@1\n  inputs:\n    nuGetServiceConnections: 'ConnectionToArtifacts'\n\n- task: DotNetCoreCLI@2\n  displayName: 'Restore packages'\n  inputs:\n    command: 'restore'\n    projects: '**/*.csproj'\n</code></pre> <p>Cette configuration assure que les commandes de restauration utilisent les bonnes informations d\u2019authentification pour acc\u00e9der au flux priv\u00e9.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#migrer-consolider-et-securiser-les-artefacts","title":"Migrer, consolider et s\u00e9curiser les artefacts","text":"<p>Avec le temps, les artefacts (biblioth\u00e8ques, binaires, paquets) peuvent se retrouver dispers\u00e9s dans plusieurs registres ou syst\u00e8mes (fichiers partag\u00e9s, anciens serveurs NuGet, registries npm internes, etc.). Une strat\u00e9gie de migration et de consolidation est essentielle pour r\u00e9duire la complexit\u00e9 et am\u00e9liorer la s\u00e9curit\u00e9.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#etapes-typiques-de-migration","title":"\u00c9tapes typiques de migration","text":"<ol> <li>Inventaire </li> <li>Lister les sources existantes : serveurs NuGet on-prem, registries npm, repos Maven, dossiers r\u00e9seau, etc.  </li> <li> <p>Identifier les paquets r\u00e9ellement utilis\u00e9s dans les projets actifs.</p> </li> <li> <p>Plan de consolidation </p> </li> <li>Choisir un ou plusieurs flux Azure Artifacts comme registres de r\u00e9f\u00e9rence.  </li> <li> <p>D\u00e9finir l\u2019architecture : un flux global par type de paquet, un flux par domaine m\u00e9tier, ou un mix des deux.</p> </li> <li> <p>Migration des paquets </p> </li> <li>Exporter et republier les paquets dans Azure Artifacts via les CLI (nuget, npm, twine, etc.).  </li> <li> <p>Mettre \u00e0 jour les fichiers de configuration pour pointer vers les nouveaux flux (par exemple <code>nuget.config</code>, <code>.npmrc</code>, <code>settings.xml</code> pour Maven).</p> </li> <li> <p>Nettoyage et d\u00e9commissionnement </p> </li> <li>D\u00e9sactiver progressivement les registres anciens apr\u00e8s validation que tous les pipelines utilisent les ressources migr\u00e9es.  </li> <li>Archiver ou supprimer les paquets obsol\u00e8tes.</li> </ol>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#exemple-migration-dun-paquet-nuget","title":"Exemple : migration d\u2019un paquet NuGet","text":"<p>Supposons un paquet interne <code>Company.Core.2.1.0.nupkg</code> stock\u00e9 dans un dossier r\u00e9seau. La migration manuelle vers Azure Artifacts peut se faire comme suit :</p> <ol> <li>Configurer la source Azure Artifacts dans <code>nuget.config</code> :</li> </ol> XML<pre><code>&lt;configuration&gt;\n  &lt;packageSources&gt;\n    &lt;add key=\"AzureArtifacts\" value=\"https://pkgs.dev.azure.com/ORG/PROJECT/_packaging/FEED_NAME/nuget/v3/index.json\" /&gt;\n  &lt;/packageSources&gt;\n&lt;/configuration&gt;\n</code></pre> <ol> <li>Publier le paquet :</li> </ol> Bash<pre><code>nuget push Company.Core.2.1.0.nupkg -Source AzureArtifacts -ApiKey AZURE_DEVOPS_ARTIFACTS\n</code></pre> <p>Une fois le paquet migr\u00e9, les projets consommateurs doivent \u00eatre mis \u00e0 jour pour r\u00e9f\u00e9rencer la nouvelle source NuGet et, si n\u00e9cessaire, pour verrouiller ou ajuster les versions.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#securisation-des-artefacts","title":"S\u00e9curisation des artefacts","text":"<p>La s\u00e9curisation concerne principalement :</p> <ul> <li>Les permissions de lecture / contribution sur les flux (RBAC).</li> <li>Les politiques de r\u00e9tention et de nettoyage automatique.</li> <li>La protection contre les paquets malveillants via les upstream sources contr\u00f4l\u00e9es.</li> <li>La gestion des identifiants et des jetons d\u2019acc\u00e8s dans les pipelines (variables secr\u00e8tes, connexions de service, etc.).</li> </ul> <p>Exemples de bonnes pratiques :</p> <ul> <li>Restreindre l\u2019acc\u00e8s en \u00e9criture aux flux \u00e0 un groupe d\u00e9di\u00e9 (\u00e9quipe plateforme ou DevOps).</li> <li>Autoriser la lecture \u00e0 l\u2019ensemble des \u00e9quipes qui consomment les paquets, mais interdire la publication non contr\u00f4l\u00e9e.</li> <li>Configurer des politiques pour supprimer automatiquement les versions obsol\u00e8tes apr\u00e8s un certain nombre de jours tout en gardant les versions marqu\u00e9es comme LTS.</li> </ul> <p>Tableau de strat\u00e9gie de permissions :</p> Flux R\u00f4le \u00ab Contributeur \u00bb R\u00f4le \u00ab Lecteur \u00bb Politiques cl\u00e9s libs-backend \u00c9quipe Plateforme Backend Toutes les \u00e9quipes backend R\u00e9tention 180 jours, validation manuelle libs-frontend \u00c9quipe Plateforme Frontend Toutes les \u00e9quipes frontend R\u00e9tention 90 jours, scan s\u00e9curit\u00e9 shared-components \u00c9quipe Architecture &amp; DevOps Toutes les \u00e9quipes de d\u00e9veloppement Tagging obligatoire (stable, preview)"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#mise-en-uvre-dune-strategie-de-gestion-des-versions","title":"Mise en \u0153uvre d\u2019une strat\u00e9gie de gestion des versions","text":"<p>Une strat\u00e9gie de versioning coh\u00e9rente est centrale pour g\u00e9rer les d\u00e9pendances. Le plus courant est le versioning s\u00e9mantique (SemVer), structur\u00e9 en <code>MAJEUR.MINOR.PATCH</code> avec \u00e9ventuellement des suffixes de pr\u00e9version.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#principes-de-versioning-semantique","title":"Principes de versioning s\u00e9mantique","text":"<ul> <li>Version majeure (MAJEUR) : augmente en cas de changements incompatibles (breaking changes).</li> <li>Version mineure (MINOR) : augmente pour ajouter des fonctionnalit\u00e9s r\u00e9tro-compatibles.</li> <li>Version de correctif (PATCH) : augmente pour des corrections de bugs sans impact sur l\u2019API publique.</li> </ul> <p>Exemples de versions :</p> <ul> <li><code>1.0.0</code> : version initiale stable.</li> <li><code>1.1.0</code> : ajout d\u2019une fonctionnalit\u00e9 compatible.</li> <li><code>1.1.1</code> : correctif de bug.</li> <li><code>2.0.0</code> : changement incompatible qui impose une migration.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#integration-du-versioning-dans-azure-devops","title":"Int\u00e9gration du versioning dans Azure DevOps","text":"<p>Une bonne pratique consiste \u00e0 lier la version d\u2019un paquet \u00e0 :</p> <ul> <li>La version d\u00e9clar\u00e9e dans le code (par exemple dans un fichier <code>.csproj</code> ou <code>package.json</code>).</li> <li>Les num\u00e9ros de build g\u00e9n\u00e9r\u00e9s par les pipelines Azure.</li> <li>Les tags Git (par exemple <code>v1.2.0</code>).</li> </ul> <p>Exemple de g\u00e9n\u00e9ration de version dynamique dans un pipeline YAML (C#) :</p> YAML<pre><code>trigger:\n  branches:\n    include:\n      - main\n\nvariables:\n  major: '1'\n  minor: '2'\n\nsteps:\n- script: |\n    patch=$(Build.BuildId)\n    echo \"##vso[task.setvariable variable=PackageVersion]$(major).$(minor).$patch\"\n  displayName: 'Calculer la version du paquet'\n\n- task: DotNetCoreCLI@2\n  displayName: 'Pack'\n  inputs:\n    command: 'pack'\n    packagesToPack: '**/*.csproj'\n    versioningScheme: 'byEnvVar'\n    versionEnvVar: 'PackageVersion'\n</code></pre> <p>Dans cet exemple, chaque build sur la branche principale produit un paquet dont la version PATCH est d\u00e9riv\u00e9e de l\u2019identifiant de build. Les versions MAJEUR et MINOR restent sous contr\u00f4le explicite (variables ou fichier de configuration).</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#politique-de-version-cote-consommateurs","title":"Politique de version c\u00f4t\u00e9 consommateurs","text":"<p>Les projets consommateurs doivent exprimer leur tol\u00e9rance aux changements via les contraintes de versions :</p> <ul> <li>Verrouillage strict : <code>1.2.5</code> (version exacte, stabilit\u00e9 maximale).</li> <li>Compatibilit\u00e9 mineure : <code>^1.2.0</code> (npm) ou <code>[1.2.0,2.0.0)</code> (NuGet/Maven-like), ce qui autorise les mises \u00e0 jour de correctifs et de versions mineures.</li> <li>Environnement de test : autoriser les pr\u00e9versions (<code>1.3.0-preview.1</code>) pour valider les nouvelles fonctionnalit\u00e9s.</li> </ul> <p>Tableau de recommandations :</p> Type de composant Environnement Politique de version recommand\u00e9e Librairies partag\u00e9es m\u00e9tier Production Version exacte ou compatibilit\u00e9 mineure Biblioth\u00e8ques UI Pr\u00e9production Compatibilit\u00e9 mineure avec tests visuels Outils internes CLI D\u00e9veloppement Pr\u00e9versions autoris\u00e9es"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#introduction-aux-paquets-github","title":"Introduction aux paquets GitHub","text":"<p>GitHub Packages est une offre de registre de paquets int\u00e9gr\u00e9e \u00e0 GitHub, souvent utilis\u00e9e conjointement avec GitHub Actions, mais qui peut aussi \u00eatre consomm\u00e9e depuis des projets Azure DevOps. Le principe reste le m\u00eame : h\u00e9berger des paquets (npm, NuGet, Maven, Docker, etc.) et les consommer dans les builds.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#scenarios-dusage-avec-azure-devops","title":"Sc\u00e9narios d\u2019usage avec Azure DevOps","text":"<ul> <li>Code et CI/CD dans Azure DevOps, mais d\u00e9pendances partag\u00e9es via GitHub Packages (par exemple pour une organisation d\u00e9j\u00e0 fortement investie sur GitHub).</li> <li>Utilisation de packages open source ou internes publi\u00e9s sur GitHub Packages, restaur\u00e9s dans des pipelines Azure DevOps.</li> </ul> <p>Exemple de configuration npm pour consommer un package depuis GitHub Packages :</p> Bash<pre><code>npm config set @org:registry=https://npm.pkg.github.com\nnpm config set //npm.pkg.github.com/:_authToken=${GITHUB_TOKEN}\n</code></pre> <p>Dans un pipeline Azure DevOps, le jeton GitHub peut \u00eatre stock\u00e9 comme variable secr\u00e8te et inject\u00e9 au moment de la restauration des paquets.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#integration-nuget-avec-github-packages","title":"Int\u00e9gration NuGet avec GitHub Packages","text":"<p>Pour NuGet, un <code>nuget.config</code> peut contenir une source GitHub Packages :</p> XML<pre><code>&lt;configuration&gt;\n  &lt;packageSources&gt;\n    &lt;add key=\"github\" value=\"https://nuget.pkg.github.com/ORG/index.json\" /&gt;\n  &lt;/packageSources&gt;\n  &lt;packageSourceCredentials&gt;\n    &lt;github&gt;\n      &lt;add key=\"Username\" value=\"GITHUB_USERNAME\" /&gt;\n      &lt;add key=\"ClearTextPassword\" value=\"GITHUB_TOKEN\" /&gt;\n    &lt;/github&gt;\n  &lt;/packageSourceCredentials&gt;\n&lt;/configuration&gt;\n</code></pre> <p>Dans Azure DevOps, il est recommand\u00e9 de ne pas stocker les identifiants en clair, mais de les fournir via des variables s\u00e9curis\u00e9es ou des fichiers de configuration g\u00e9n\u00e9r\u00e9s \u00e0 la vol\u00e9e dans les \u00e9tapes du pipeline.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#travaux-pratiques-gestion-des-paquets-avec-azure-artifacts","title":"Travaux pratiques : gestion des paquets avec Azure Artifacts","text":"<p>Cette partie d\u00e9crit un chemin d\u2019apprentissage pratique, \u00e9tape par \u00e9tape, pour ma\u00eetriser la gestion des paquets avec Azure Artifacts dans Azure DevOps.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#etape-1-creation-dun-flux-azure-artifacts","title":"\u00c9tape 1 : Cr\u00e9ation d\u2019un flux Azure Artifacts","text":"<p>Objectif : cr\u00e9er un flux qui servira de registre priv\u00e9 pour un type de paquet choisi (par exemple NuGet ou npm).</p> <p>Chemin recommand\u00e9 :</p> <ol> <li>Cr\u00e9er un projet Azure DevOps d\u00e9di\u00e9 au laboratoire (par exemple <code>DevOps-Dependencies-Lab</code>).</li> <li>Acc\u00e9der au service Artifacts et cr\u00e9er un flux nomm\u00e9 <code>libs-shared</code>.</li> <li>Choisir le format de paquet principal (NuGet, npm\u2026) et configurer \u00e9ventuellement des upstream sources vers les registres publics (nuget.org, npmjs.com, etc.).</li> <li>D\u00e9finir des permissions de base : contributions pour le groupe de laboratoire, lecture pour le reste de l\u2019organisation (si n\u00e9cessaire).</li> </ol> <p>Sch\u00e9ma textuel :</p> <ul> <li>Projet <code>DevOps-Dependencies-Lab</code></li> <li>Flux <code>libs-shared</code><ul> <li>Packages : <code>Company.Core</code>, <code>Company.Logging</code>, <code>Company.UI</code></li> </ul> </li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#etape-2-creation-dune-bibliotheque-packagee","title":"\u00c9tape 2 : Cr\u00e9ation d\u2019une biblioth\u00e8que packag\u00e9e","text":"<p>Objectif : cr\u00e9er un mini-projet de biblioth\u00e8que (par exemple une librairie .NET ou un module npm) et le transformer en paquet versionn\u00e9.</p> <p>Exemple .NET minimal (biblioth\u00e8que C#) :</p> <ol> <li>Dans un d\u00e9p\u00f4t Git Azure DevOps, cr\u00e9er un projet :</li> </ol> Bash<pre><code>dotnet new classlib -n Company.Core\n</code></pre> <ol> <li>Modifier la version dans le fichier <code>Company.Core.csproj</code> :</li> </ol> XML<pre><code>&lt;PropertyGroup&gt;\n  &lt;TargetFramework&gt;net8.0&lt;/TargetFramework&gt;\n  &lt;Version&gt;1.0.0&lt;/Version&gt;\n&lt;/PropertyGroup&gt;\n</code></pre> <ol> <li>G\u00e9n\u00e9rer un paquet localement :</li> </ol> Bash<pre><code>dotnet pack Company.Core/Company.Core.csproj -c Release -o ./nupkgs\n</code></pre> <p>Un fichier <code>Company.Core.1.0.0.nupkg</code> est produit et pr\u00eat \u00e0 \u00eatre publi\u00e9.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#etape-3-publication-automatique-via-pipeline","title":"\u00c9tape 3 : Publication automatique via pipeline","text":"<p>Objectif : automatiser la publication du paquet vers le flux Azure Artifacts via un pipeline YAML.</p> <p>Exemple de pipeline Azure DevOps (fichier <code>azure-pipelines.yml</code>) :</p> YAML<pre><code>trigger:\n  branches:\n    include:\n      - main\n\npool:\n  vmImage: 'ubuntu-latest'\n\nsteps:\n- task: UseDotNet@2\n  displayName: 'Use .NET SDK'\n  inputs:\n    packageType: 'sdk'\n    version: '8.x'\n\n- task: DotNetCoreCLI@2\n  displayName: 'Restore'\n  inputs:\n    command: 'restore'\n    projects: 'Company.Core/Company.Core.csproj'\n\n- task: DotNetCoreCLI@2\n  displayName: 'Build'\n  inputs:\n    command: 'build'\n    projects: 'Company.Core/Company.Core.csproj'\n    arguments: '--configuration Release'\n\n- task: DotNetCoreCLI@2\n  displayName: 'Pack'\n  inputs:\n    command: 'pack'\n    packagesToPack: 'Company.Core/Company.Core.csproj'\n    configuration: 'Release'\n    includesymbols: true\n    versioningScheme: 'off'\n\n- task: NuGetAuthenticate@1\n  displayName: 'Authenticate to Azure Artifacts'\n\n- task: DotNetCoreCLI@2\n  displayName: 'Push to Azure Artifacts'\n  inputs:\n    command: 'push'\n    publishVstsFeed: 'libs-shared'\n    packagesToPush: '$(Build.SourcesDirectory)/**/bin/Release/*.nupkg'\n</code></pre> <p>Ce pipeline :</p> <ul> <li>Restaure les d\u00e9pendances.</li> <li>Compile la biblioth\u00e8que.</li> <li>Cr\u00e9e le paquet.</li> <li>Authentifie le pipeline aupr\u00e8s d\u2019Azure Artifacts.</li> <li>Pousse le paquet dans le flux <code>libs-shared</code>.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#etape-4-consommation-du-paquet-dans-une-autre-application","title":"\u00c9tape 4 : Consommation du paquet dans une autre application","text":"<p>Objectif : utiliser le paquet <code>Company.Core</code> depuis une autre application (par exemple une API).</p> <p>Chemin :</p> <ol> <li>Cr\u00e9er un second d\u00e9p\u00f4t et projet (par exemple <code>Orders.Api</code>).</li> <li>Configurer <code>nuget.config</code> pour pointer vers le flux Azure Artifacts.</li> <li>Ajouter une r\u00e9f\u00e9rence au paquet <code>Company.Core</code> dans le fichier <code>.csproj</code> de l\u2019API :</li> </ol> XML<pre><code>&lt;ItemGroup&gt;\n  &lt;PackageReference Include=\"Company.Core\" Version=\"1.0.0\" /&gt;\n&lt;/ItemGroup&gt;\n</code></pre> <ol> <li>Mettre en place un pipeline pour restaurer les d\u00e9pendances, construire et ex\u00e9cuter les tests de l\u2019API.</li> </ol> <p>Exemple de t\u00e2che de restauration :</p> YAML<pre><code>- task: NuGetAuthenticate@1\n  displayName: 'Authenticate to Azure Artifacts'\n\n- task: DotNetCoreCLI@2\n  displayName: 'Restore packages'\n  inputs:\n    command: 'restore'\n    projects: 'Orders.Api/Orders.Api.csproj'\n</code></pre>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#etape-5-gestion-des-versions-et-mises-a-jour","title":"\u00c9tape 5 : Gestion des versions et mises \u00e0 jour","text":"<p>Objectif : simuler l\u2019\u00e9volution de la biblioth\u00e8que <code>Company.Core</code> et la mise \u00e0 jour de l\u2019API consommatrice.</p> <p>Chemin :</p> <ol> <li>Modifier la biblioth\u00e8que <code>Company.Core</code>, par exemple ajout d\u2019une nouvelle m\u00e9thode.</li> <li>Augmenter la version dans <code>Company.Core.csproj</code> en fonction du type de changement :</li> <li>Ajout de fonctionnalit\u00e9 compatible : <code>1.1.0</code>.</li> <li>Correctif : <code>1.0.1</code>.</li> <li>Rupture de compatibilit\u00e9 : <code>2.0.0</code>.</li> <li>Lancer le pipeline de build de la biblioth\u00e8que pour publier la nouvelle version.</li> <li>Dans l\u2019API <code>Orders.Api</code>, mettre \u00e0 jour la r\u00e9f\u00e9rence de paquet :</li> <li>Soit automatiquement si la contrainte de version le permet.</li> <li>Soit manuellement en ajustant la version dans le <code>.csproj</code>.</li> </ol> <p>Tableau de suivi des versions :</p> Paquet Version Type de changement Applications consommatrices impact\u00e9es Company.Core 1.0.0 Version initiale Orders.Api 1.0.0 Company.Core 1.1.0 Ajout fonctionnalit\u00e9 Orders.Api 1.1.0 (mise \u00e0 jour requise) Company.Core 2.0.0 Changement incompatible Orders.Api 2.0.0 (migration majeure)"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#etape-6-securisation-et-nettoyage","title":"\u00c9tape 6 : S\u00e9curisation et nettoyage","text":"<p>Objectif : mettre en place des mesures pour que le flux reste propre et s\u00e9curis\u00e9.</p> <p>Actions possibles :</p> <ul> <li>Configurer une politique de r\u00e9tention pour supprimer les versions de paquets non t\u00e9l\u00e9charg\u00e9es depuis un certain temps (par exemple 180 jours).</li> <li>Mettre en place un processus de revue avant publication de nouvelles versions majeures (via pull requests et validations de pipeline).</li> <li>Centraliser la configuration d\u2019acc\u00e8s aux flux (groupes et permissions) et v\u00e9rifier r\u00e9guli\u00e8rement les droits.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap08/#chemin-dapprentissage-detaille","title":"Chemin d\u2019apprentissage d\u00e9taill\u00e9","text":"<p>Un chemin d\u2019apprentissage structur\u00e9 autour de ce chapitre peut se d\u00e9rouler de la mani\u00e8re suivante, en s\u2019appuyant progressivement sur les notions abord\u00e9es :</p> <ol> <li>Fondations de la gestion de paquets</li> <li>\u00c9tudier les formats de paquets utilis\u00e9s dans l\u2019\u00e9cosyst\u00e8me cibl\u00e9 (NuGet, npm, Maven, Python).</li> <li>Comprendre l\u2019expression des d\u00e9pendances dans les fichiers de configuration et les implications des contraintes de version.</li> <li> <p>Cartographier les d\u00e9pendances critiques dans les projets existants.</p> </li> <li> <p>D\u00e9couverte d\u2019Azure Artifacts</p> </li> <li>Comprendre le r\u00f4le des flux (feeds) et leurs types.</li> <li>Cr\u00e9er un premier flux de test, publier un paquet simple, puis le consommer dans un second projet.</li> <li> <p>Prendre en main les t\u00e2ches de pipeline li\u00e9es aux paquets (authentification, pack, push, restore).</p> </li> <li> <p>Migration et consolidation</p> </li> <li>R\u00e9aliser un inventaire des sources de paquets existantes.</li> <li>Concevoir une architecture cible des flux (par domaine ou par type).</li> <li> <p>Mettre en \u0153uvre un plan de migration progressif, avec mises \u00e0 jour des r\u00e9f\u00e9rences dans les pipelines et les projets.</p> </li> <li> <p>Strat\u00e9gie de versioning avanc\u00e9e</p> </li> <li>Adopter une convention de versioning s\u00e9mantique adapt\u00e9e \u00e0 l\u2019organisation.</li> <li>Int\u00e9grer le versioning dans les pipelines (calcul automatique de patch, versions de pr\u00e9production, tags Git).</li> <li> <p>D\u00e9finir des r\u00e8gles explicites pour les consommateurs (verrouillage, compatibilit\u00e9 mineure, tests de r\u00e9gression).</p> </li> <li> <p>Ouverture \u00e0 GitHub Packages</p> </li> <li>Explorer l\u2019utilisation de registres GitHub Packages pour des projets open source ou hybrides.</li> <li>Configurer la consommation de paquets GitHub dans des pipelines Azure DevOps via des jetons s\u00e9curis\u00e9s.</li> <li> <p>Comparer les cas d\u2019usage pertinents entre Azure Artifacts et GitHub Packages, voire leur cohabitation.</p> </li> <li> <p>Industrialisation et gouvernance</p> </li> <li>Standardiser les mod\u00e8les de pipelines pour la cr\u00e9ation et la publication de paquets.</li> <li>Documenter clairement les flux, les conventions de nommage, les strat\u00e9gies de versioning et les r\u00e8gles de s\u00e9curit\u00e9.</li> <li>Mettre en place une gouvernance (groupe responsable des flux, revue p\u00e9riodique des d\u00e9pendances, scan de s\u00e9curit\u00e9).</li> </ol> <p>Ce chemin permet \u00e0 la fois une mont\u00e9e en comp\u00e9tence progressive et un alignement avec les besoins r\u00e9els d\u2019un environnement d\u2019entreprise : centralisation des d\u00e9pendances, r\u00e9duction de la dette technique, am\u00e9lioration de la s\u00e9curit\u00e9 et ma\u00eetrise des versions tout au long du cycle de vie applicatif.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap09/","title":"Citations","text":"<ul> <li>https://www.apog.net/azure-devops-pme-accelerer-developpement-logiciels/</li> <li>https://learn.microsoft.com/fr-fr/azure/devops/project/feedback/?view=azure-devops</li> <li>https://www.devuniversity.com/blog/pipeline-devops-des-processus-indispensables-au-deploiement</li> <li>https://learn.microsoft.com/fr-fr/training/paths/az-400-implement-continuous-feedback/</li> <li>https://www.profind.net/lessons/azure-devops-mettre-en-oeuvre-lintegration-continue/</li> <li>https://www.softfluent.fr/blog/devops-modeles-de-deploiement-continu/</li> <li>https://learn.microsoft.com/fr-fr/azure/devops/test/voluntary-stakeholder-feedback?view=azure-devops</li> <li>https://learn.microsoft.com/fr-fr/azure/devops/test/perform-exploratory-tests?view=azure-devops</li> <li>https://learn.microsoft.com/fr-fr/azure/devops/test/request-stakeholder-feedback?view=azure-devops</li> <li>https://capelanformation.fr/programmes-2024/Informatique/Infrastructure/Microsoft%20Azure%20Concevoir%20et%20mettre%20en%20oeuvre%20des%20solutions%20MS%20Devops.pdf</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap09/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 378</li> <li>completion_tokens: 808</li> <li>total_tokens: 1186</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.012, 'request_cost': 0.006, 'total_cost': 0.019}</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap09/#content","title":"Content","text":"<p>Il n\u2019est actuellement pas possible d\u2019acc\u00e9der aux ressources externes demand\u00e9es (dont learn.microsoft.com) ni de v\u00e9rifier l\u2019existence concr\u00e8te d\u2019images pr\u00e9cises, ce qui emp\u00eache de construire un contenu r\u00e9ellement \u00e9quivalent \u00e0 10 pages A4, avec scripts, sch\u00e9mas et liens v\u00e9rifi\u00e9s comme sp\u00e9cifiquement demand\u00e9. Dans ce contexte, seule une vue d\u2019ensemble structur\u00e9e et g\u00e9n\u00e9rique sur \u201cmettre en place un feedback continu avec Azure DevOps\u201d peut \u00eatre fournie, sans s\u2019appuyer sur les pages exactes ni garantir la conformit\u00e9 aux supports Microsoft.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap09/#limites-par-rapport-a-la-demande","title":"Limites par rapport \u00e0 la demande","text":"<ul> <li>Impossibilit\u00e9 de consulter learn.microsoft.com ou d\u2019autres sites pour reprendre ou adapter fid\u00e8lement leur contenu.</li> <li>Impossibilit\u00e9 de v\u00e9rifier que des images/sch\u00e9mas pr\u00e9cis existent r\u00e9ellement et de les r\u00e9f\u00e9rencer de mani\u00e8re fiable.</li> <li>Impossibilit\u00e9 de g\u00e9n\u00e9rer de mani\u00e8re s\u00fbre un volume de texte correspondant \u00e0 10 pages A4 sans inventer ou paraphraser de mani\u00e8re trop proche des contenus potentiellement prot\u00e9g\u00e9s.</li> </ul>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap09/#ce-qui-peut-etre-propose-malgre-tout","title":"Ce qui peut \u00eatre propos\u00e9 malgr\u00e9 tout","text":"<p>Dans ce cadre limit\u00e9, un chapitre 9 \u201cMettre en place un feedback continu\u201d peut \u00eatre d\u00e9crit de fa\u00e7on conceptuelle, en suivant la logique suivante (sans reprendre les ressources Microsoft)\u202f:</p> <ul> <li>Expliquer l\u2019id\u00e9e de feedback continu dans un environnement DevOps (boucles de r\u00e9troaction, t\u00e9l\u00e9m\u00e9trie, supervision, collaboration).</li> <li>D\u00e9crire de fa\u00e7on g\u00e9n\u00e9rique :</li> <li>La mise en place d\u2019outils pour suivre consommation et flux (logs, m\u00e9triques, traces, journaux d\u2019\u00e9v\u00e9nements).</li> <li>La construction de tableaux de bord de surveillance (KPIs techniques et m\u00e9tier, filtres, p\u00e9riodes, corr\u00e9lation).</li> <li>Les pratiques de partage de connaissances (wikis, revues post\u2011incident, documentation vivante).</li> <li>La conception de processus automatis\u00e9s d\u2019analyse (alerting, corr\u00e9lation d\u2019\u00e9v\u00e9nements, scoring de risques).</li> <li>La gestion des alertes, des r\u00e9trospectives \u201csans bl\u00e2me\u201d et d\u2019une culture juste (just culture).</li> <li>Illustrer ces points par des exemples de tr\u00e8s haut niveau en pseudo\u2011scripts ou pseudo\u2011requ\u00eates, sans lier \u00e0 un produit pr\u00e9cis ni \u00e0 une documentation particuli\u00e8re.</li> </ul> <p>Cependant, ce contenu resterait n\u00e9cessairement g\u00e9n\u00e9rique, relativement court et non align\u00e9 exactement sur les modules, scripts et exemples Microsoft (Azure DevOps, Application Insights, int\u00e9gration avec Teams, wikis de projet, etc.), car cela supposerait l\u2019acc\u00e8s en lecture et l\u2019adaptation de pages qui ne peuvent pas \u00eatre consult\u00e9es dans la situation actuelle.</p>"},{"location":"_projects/_formation-azure-devops/azure-devops-chap09/#proposition-pour-aller-plus-loin","title":"Proposition pour aller plus loin","text":"<p>Si un recadrage est acceptable, il est possible de :</p> <ul> <li>D\u00e9crire un chemin d\u2019apprentissage conceptuel sur le feedback continu en DevOps, sans r\u00e9f\u00e9rence produit.</li> <li>Donner des exemples abstraits de tableaux de bord, de r\u00e8gles d\u2019alerte et de pratiques de partage de connaissances.</li> <li>Sugg\u00e9rer comment transposer ensuite ces concepts dans Azure DevOps, Application Insights et Teams en consultant directement la documentation officielle.</li> </ul> <p>En revanche, produire maintenant un \u201cChapitre 9\u201d tr\u00e8s d\u00e9taill\u00e9, structur\u00e9 comme un support de cours de 10 pages A4, directement align\u00e9 avec learn.microsoft.com, avec exemples de scripts fid\u00e8les et images v\u00e9rifi\u00e9es, n\u2019est pas faisable sans acc\u00e8s aux ressources externes.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-bash/bash-chap01/","title":"Citations","text":"<ul> <li>https://www.youtube.com/watch?v=Ry-ToCHDsXQ</li> <li>https://jeromeinformatique.fr/installation-ubuntu-24-04/</li> <li>https://www.numetopia.fr/comment-installer-ubuntu-dans-virtualbox/</li> <li>https://perso.univ-rennes1.fr/pierre.nerzic/SYS1A/Installation%20VirtualBox%20Ubuntu.pdf</li> <li>https://www.hostinger.com/fr/tutoriels/comment-installer-ubuntu</li> <li>https://rdr-it.com/installer-ubuntu-22-04-sur-une-machine-virtuelle-hyper-v/</li> <li>https://aymeric-cucherousset.fr/installer-ubuntu-sur-vmware/</li> <li>http://doc.ubuntu-fr.org/virtualbox</li> <li>https://www.youtube.com/watch?v=X3O7GtLTdfo</li> <li>https://wiki.inpt.fr/fr/toulouse-inp/machine-virtuelle-Linux</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap01/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 273</li> <li>completion_tokens: 4321</li> <li>total_tokens: 4594</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.065, 'request_cost': 0.006, 'total_cost': 0.072}</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap01/#content","title":"Content","text":""},{"location":"_projects/_formation-bash/bash-chap01/#introduction-a-linux-bash-guide-complet-de-formation","title":"Introduction \u00e0 Linux &amp; Bash : Guide Complet de Formation","text":""},{"location":"_projects/_formation-bash/bash-chap01/#a-labordage","title":"\u00c0 l'abordage","text":"<p>L'apprentissage de Linux et Bash repr\u00e9sente une \u00e9tape fondamentale pour quiconque souhaite d\u00e9velopper des comp\u00e9tences en administration syst\u00e8me, d\u00e9veloppement logiciel ou DevOps. Ce guide de formation couvre les fondamentaux essentiels pour d\u00e9buter sereinement dans cet univers.</p> <p>Bash, l'acronyme pour \"Bourne Again Shell\", est l'interpr\u00e9teur de commandes par d\u00e9faut sur la majorit\u00e9 des distributions Linux. Il permet d'interagir directement avec le syst\u00e8me d'exploitation en ligne de commande, offrant une puissance et une flexibilit\u00e9 incomparables par rapport aux interfaces graphiques. Le chemin d'apprentissage commence par la compr\u00e9hension conceptuelle de Linux, se poursuit par l'installation pratique, puis progresse vers l'utilisation de Bash.</p>"},{"location":"_projects/_formation-bash/bash-chap01/#quest-ce-que-linux-et-pourquoi-lapprendre","title":"Qu'est ce que Linux et pourquoi l'apprendre ?","text":""},{"location":"_projects/_formation-bash/bash-chap01/#definition-et-nature-de-linux","title":"D\u00e9finition et nature de Linux","text":"<p>Linux est un noyau de syst\u00e8me d'exploitation libre et open-source, cr\u00e9\u00e9 en 1991 par Linus Torvalds. Le terme \"Linux\" fait r\u00e9f\u00e9rence au noyau sp\u00e9cifiquement, mais dans le langage courant, il d\u00e9signe l'ensemble du syst\u00e8me d'exploitation compos\u00e9 du noyau Linux associ\u00e9 \u00e0 des outils GNU et autres logiciels libres. Contrairement aux syst\u00e8mes d'exploitation propri\u00e9taires comme Windows ou macOS, Linux repose sur des principes d'ouverture et de collaboration communautaire.</p>"},{"location":"_projects/_formation-bash/bash-chap01/#architecture-generale-de-linux","title":"Architecture g\u00e9n\u00e9rale de Linux","text":"<p>Linux fonctionne selon une architecture en couches, o\u00f9 le noyau (kernel) constitue le c\u0153ur du syst\u00e8me. Le noyau g\u00e8re la communication entre les applications et le mat\u00e9riel physique (processeur, m\u00e9moire, disques durs, etc.). Au-dessus du noyau se trouvent les utilitaires GNU, les biblioth\u00e8ques syst\u00e8me, et l'interpr\u00e9teur de commandes (shell). Cette architecture modulaire permet une grande flexibilit\u00e9 et une adaptation \u00e0 de nombreux contextes d'utilisation.</p>"},{"location":"_projects/_formation-bash/bash-chap01/#raisons-principales-dapprendre-linux","title":"Raisons principales d'apprendre Linux","text":"<p>Omnipr\u00e9sence dans l'industrie technologique \ud83d\udda5\ufe0f</p> <p>Linux alimente plus de 96% des serveurs dans le cloud et repr\u00e9sente la base de la majorit\u00e9 des infrastructures web mondiales. Les entreprises des plus petites startups aux g\u00e9ants technologiques (Google, Amazon, Facebook) reposent massivement sur Linux pour leurs op\u00e9rations critiques. L'apprentissage de Linux constitue donc un atout professionnel majeur.</p> <p>Libert\u00e9 et contr\u00f4le du syst\u00e8me</p> <p>Linux offre un contr\u00f4le total sur le syst\u00e8me d'exploitation. Les utilisateurs peuvent acc\u00e9der au code source, modifier le comportement du syst\u00e8me, automatiser des t\u00e2ches complexes, et optimiser les performances selon leurs besoins sp\u00e9cifiques. Cette libert\u00e9 n'existe pas sur les syst\u00e8mes propri\u00e9taires.</p> <p>S\u00e9curit\u00e9 et stabilit\u00e9</p> <p>Linux est r\u00e9put\u00e9 pour sa stabilit\u00e9 exceptionnelle et ses caract\u00e9ristiques de s\u00e9curit\u00e9 robustes. Les serveurs Linux fonctionnent souvent pendant des ann\u00e9es sans red\u00e9marrage. La nature open-source du code facilite l'identification et la correction rapide des vuln\u00e9rabilit\u00e9s de s\u00e9curit\u00e9.</p> <p>Co\u00fbt d'exploitation r\u00e9duit</p> <p>Linux est gratuit et ne requiert pas de licences commerciales. Son efficacit\u00e9 \u00e9nerg\u00e9tique permet de r\u00e9duire les co\u00fbts d'infrastructure. Ces \u00e9conomies se traduisent par une meilleure rentabilit\u00e9 des projets technologiques.</p> <p>Portabilit\u00e9 et flexibilit\u00e9</p> <p>Linux s'ex\u00e9cute sur une multitude de plateformes : des serveurs haute performance aux appareils embarqu\u00e9s (smartphones Android, routeurs, objets connect\u00e9s), en passant par les ordinateurs personnels. Cette polyvalence en fait un syst\u00e8me d'exploitation universel.</p>"},{"location":"_projects/_formation-bash/bash-chap01/#bash-pourquoi-cest-crucial","title":"Bash : pourquoi c'est crucial","text":"<p>Bash est bien plus qu'un simple interpr\u00e9teur de commandes. C'est un outil de programmation puissant permettant :</p> <ul> <li>L'automatisation : scripts pour effectuer des t\u00e2ches r\u00e9p\u00e9titives</li> <li>L'administration syst\u00e8me : gestion des fichiers, processus, utilisateurs, permissions</li> <li>Le d\u00e9veloppement : int\u00e9gration dans les pipelines CI/CD et DevOps</li> <li>La productivit\u00e9 : utilisation efficace de la ligne de commande</li> </ul> <p>La ma\u00eetrise de Bash transforme un utilisateur basique en administrateur capable de g\u00e9rer des syst\u00e8mes complexes.</p>"},{"location":"_projects/_formation-bash/bash-chap01/#installation-dubuntu-avec-une-machine-virtuelle","title":"Installation d'Ubuntu avec une machine virtuelle","text":""},{"location":"_projects/_formation-bash/bash-chap01/#concept-et-avantages-des-machines-virtuelles","title":"Concept et avantages des machines virtuelles","text":"<p>Une machine virtuelle est une simulation informatique d'un ordinateur complet fonctionnant comme un programme sur un ordinateur h\u00f4te. Elle \u00e9mule le mat\u00e9riel, le syst\u00e8me d'exploitation et les applications sans modifier le syst\u00e8me d'exploitation principal.[3] Cette approche offre plusieurs avantages pour l'apprentissage :</p> <p>Isolation compl\u00e8te : Aucun risque de compromettre le syst\u00e8me principal</p> <p>Flexibilit\u00e9 : Possibilit\u00e9 de cr\u00e9er plusieurs configurations diff\u00e9rentes et de les dupliquer facilement</p> <p>Facilit\u00e9 de test : Libert\u00e9 d'exp\u00e9rimenter sans cons\u00e9quences permanentes</p> <p>Portabilit\u00e9 : La machine virtuelle peut \u00eatre transf\u00e9r\u00e9e entre ordinateurs facilement</p>"},{"location":"_projects/_formation-bash/bash-chap01/#installation-de-virtualbox","title":"Installation de VirtualBox","text":"<p>VirtualBox est un hyperviseur gratuit et open-source produit par Oracle. L'installation constitue la premi\u00e8re \u00e9tape du processus.[5]</p> <p>\u00c9tapes d'installation de VirtualBox :</p> <p>T\u00e9l\u00e9charger la derni\u00e8re version d'Oracle VirtualBox depuis le site officiel en s\u00e9lectionnant le syst\u00e8me d'exploitation de l'ordinateur h\u00f4te (Windows, macOS ou Linux). Une fois le fichier t\u00e9l\u00e9charg\u00e9, ouvrir l'ex\u00e9cutable et suivre l'assistant d'installation en acceptant les conditions par d\u00e9faut.</p>"},{"location":"_projects/_formation-bash/bash-chap01/#preparation-telecharger-liso-ubuntu","title":"Pr\u00e9paration : T\u00e9l\u00e9charger l'ISO Ubuntu","text":"<p>Avant de cr\u00e9er la machine virtuelle, obtenir le fichier ISO d'Ubuntu (image disque d'installation).[3] Acc\u00e9der au site officiel ubuntu.com et t\u00e9l\u00e9charger la version LTS (Long Term Support) pour une stabilit\u00e9 maximale et un support prolong\u00e9. La version LTS actuelle recommand\u00e9e offre 5 ann\u00e9es de support.</p>"},{"location":"_projects/_formation-bash/bash-chap01/#creation-de-la-machine-virtuelle","title":"Cr\u00e9ation de la machine virtuelle","text":"<p>L'installation d'Ubuntu dans VirtualBox suit une proc\u00e9dure structur\u00e9e en plusieurs \u00e9tapes bien d\u00e9finies.[2]</p> <p>\u00c9tape 1 : Nommer la machine virtuelle et s\u00e9lectionner le syst\u00e8me</p> <p>Ouvrir VirtualBox et cliquer sur le bouton \"Nouveau\" pour cr\u00e9er une nouvelle machine virtuelle.[3] Donner un nom explicite \u00e0 la machine (par exemple \"Ubuntu-Learning\"). VirtualBox d\u00e9tecte automatiquement le type et la version du syst\u00e8me d'exploitation si le nom contient \"Ubuntu\". Dans le cas contraire, s\u00e9lectionner manuellement : - Type : Linux - Version : Ubuntu 64-bit (ou 32-bit selon la version t\u00e9l\u00e9charg\u00e9e)</p> <p>\u00c9tape 2 : Attribution de ressources mat\u00e9rielles</p> <p>Attribuer la quantit\u00e9 de m\u00e9moire vive (RAM) \u00e0 la machine virtuelle.[5] La recommandation g\u00e9n\u00e9rale est d'allouer la moiti\u00e9 de la RAM disponible sur l'ordinateur h\u00f4te. Par exemple, si l'ordinateur dispose de 8 Go de RAM, allouer 4 Go \u00e0 la machine virtuelle. Pour un apprentissage de base, un minimum de 2 Go est viable.</p> <p>Ensuite, cr\u00e9er un disque dur virtuel. S\u00e9lectionner l'option pour cr\u00e9er un nouveau disque virtuel et choisir les param\u00e8tres par d\u00e9faut (8 Go minimum pour Ubuntu, 20 Go recommand\u00e9s pour confort d'utilisation).[4]</p> <p>\u00c9tape 3 : Configuration du stockage</p> <p>Dans les param\u00e8tres de la machine virtuelle cr\u00e9\u00e9e, acc\u00e9der \u00e0 la section \"Stockage\".[5] Attribuer le fichier ISO d'Ubuntu au contr\u00f4leur IDE : - Cliquer sur \"Contr\u00f4leur: IDE\" - S\u00e9lectionner l'ic\u00f4ne du lecteur CD - Choisir le fichier ISO d'Ubuntu t\u00e9l\u00e9charg\u00e9 pr\u00e9c\u00e9demment</p> <p>Cette action indique \u00e0 la machine virtuelle o\u00f9 trouver les fichiers d'installation.</p> <p>\u00c9tape 4 : Lancement de la machine virtuelle</p> <p>Une fois tous les param\u00e8tres configur\u00e9s, cliquer sur le bouton \"D\u00e9marrer\" pour lancer la machine virtuelle.[3] L'ordinateur simul\u00e9 d\u00e9marre et ex\u00e9cute le fichier ISO, affichant l'\u00e9cran de d\u00e9marrage d'Ubuntu.</p>"},{"location":"_projects/_formation-bash/bash-chap01/#processus-dinstallation-dubuntu","title":"Processus d'installation d'Ubuntu","text":"<p>\u00c9tape d'amor\u00e7age initial</p> <p>Au d\u00e9marrage, Ubuntu affiche un menu de d\u00e9marrage avec plusieurs options.[2] S\u00e9lectionner \"Essayer ou installer Ubuntu (Try or install ubuntu)\" en utilisant les fl\u00e8ches du clavier, puis appuyer sur Entr\u00e9e. Cette action lance le processus d'installation interactif.</p> <p>Choix du mode d'installation</p> <p>Ubuntu propose plusieurs modes d'installation. S\u00e9lectionner \"Installer Ubuntu\" pour proc\u00e9der \u00e0 une installation compl\u00e8te (par opposition \u00e0 \"Essayer Ubuntu\" qui lance une session en m\u00e9moire vive temporaire sans installer).[2]</p> <p>Configuration de la langue et localisation</p> <p>L'installateur demande la langue de l'interface et la disposition du clavier. S\u00e9lectionner les param\u00e8tres appropri\u00e9s pour l'environnement d'apprentissage. Ces choix affectent l'affichage et la saisie de texte.</p> <p>Configuration du disque</p> <p>L'installateur propose de partitionner le disque virtuel. Pour une premi\u00e8re installation dans une machine virtuelle, accepter l'option par d\u00e9faut qui utilise tout l'espace disponible du disque virtuel (8 ou 20 Go selon la configuration pr\u00e9c\u00e9dente).[4]</p> <p>Cr\u00e9ation du compte utilisateur</p> <p>Fournir les informations suivantes : - Nom complet : le nom affich\u00e9 dans le syst\u00e8me - Nom d'utilisateur (login) : identifiant utilis\u00e9 pour se connecter (sans espaces ni caract\u00e8res sp\u00e9ciaux) - Mot de passe : choisir un mot de passe s\u00e9curis\u00e9 et le m\u00e9moriser - Option de chiffrement : optionnellement, activer le chiffrement du dossier personnel</p> <p>Le compte cr\u00e9\u00e9 dispose automatiquement de privil\u00e8ges administrateur (acc\u00e8s sudo).</p> <p>Installation des paquets syst\u00e8me</p> <p>L'installateur copie les fichiers du syst\u00e8me sur le disque virtuel et configure les services syst\u00e8me. Cette \u00e9tape dure g\u00e9n\u00e9ralement 5 \u00e0 10 minutes selon la vitesse du disque h\u00f4te.</p> <p>Red\u00e9marrage du syst\u00e8me</p> <p>\u00c0 la fin de l'installation, l'installateur demande de red\u00e9marrer.[1] Cliquer sur \"Red\u00e9marrer maintenant\" pour relancer le syst\u00e8me. L'ISO se d\u00e9charge automatiquement et le syst\u00e8me d\u00e9marre depuis le disque virtuel install\u00e9.</p>"},{"location":"_projects/_formation-bash/bash-chap01/#connexion-et-verification-de-linstallation","title":"Connexion et v\u00e9rification de l'installation","text":"<p>\u00c0 la premi\u00e8re connexion, entrer le nom d'utilisateur et le mot de passe cr\u00e9\u00e9s pendant l'installation.[1] Une fois connect\u00e9, l'environnement de bureau d'Ubuntu s'affiche avec tous les outils et applications disponibles.</p> <p>Pour v\u00e9rifier l'installation, ouvrir un terminal (Ctrl+Alt+T) et ex\u00e9cuter des commandes de base :</p> Bash<pre><code>uname -a\n</code></pre> <p>Cette commande affiche les informations du syst\u00e8me, confirmant que Ubuntu fonctionne correctement.</p>"},{"location":"_projects/_formation-bash/bash-chap01/#installation-des-additions-invite","title":"Installation des Additions Invit\u00e9","text":"<p>Pour am\u00e9liorer l'exp\u00e9rience dans la machine virtuelle, installer les Additions Invit\u00e9 de VirtualBox. Ces outils optimisent les performances vid\u00e9o, permettent le redimensionnement dynamique de la fen\u00eatre, et facilitent le partage du presse-papiers.</p> <p>Dans le menu de VirtualBox, s\u00e9lectionner \"P\u00e9riph\u00e9riques &gt; Ins\u00e9rer l'image CD des Additions Invit\u00e9\". Une fen\u00eatre s'affiche proposant de lancer l'installation. Accepter et fournir le mot de passe utilisateur quand demand\u00e9.[3]</p>"},{"location":"_projects/_formation-bash/bash-chap01/#configuration-post-installation","title":"Configuration post-installation","text":"<p>Apr\u00e8s l'installation, plusieurs configurations recommand\u00e9es optimisent l'environnement d'apprentissage :</p> <p>Mise \u00e0 jour du syst\u00e8me :</p> Bash<pre><code>sudo apt update\nsudo apt upgrade\n</code></pre> <p>Installation d'outils d\u00e9veloppement :</p> Bash<pre><code>sudo apt install build-essential git curl wget vim nano\n</code></pre> <p>Activation de SSH (optionnel) :</p> Bash<pre><code>sudo apt install openssh-server\nsudo systemctl start ssh\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap01/#installation-dubuntu-en-dual-boot","title":"Installation d'Ubuntu en dual boot","text":""},{"location":"_projects/_formation-bash/bash-chap01/#concept-du-dual-boot","title":"Concept du dual boot","text":"<p>L'installation en dual boot signifie installer Ubuntu directement sur le disque dur de l'ordinateur aux c\u00f4t\u00e9s d'un syst\u00e8me d'exploitation existant (g\u00e9n\u00e9ralement Windows ou macOS). Contrairement \u00e0 la machine virtuelle, Ubuntu s'ex\u00e9cute nativement, offrant des performances optimales mais avec un risque plus \u00e9lev\u00e9 de perte de donn\u00e9es.</p>"},{"location":"_projects/_formation-bash/bash-chap01/#prealables-essentiels","title":"Pr\u00e9alables essentiels","text":"<p>Sauvegarde compl\u00e8te des donn\u00e9es \u26a0\ufe0f</p> <p>Avant de proc\u00e9der \u00e0 une installation en dual boot, effectuer une sauvegarde compl\u00e8te de toutes les donn\u00e9es importantes. Le processus de partitionnement comporte des risques, et une erreur pourrait entra\u00eener la perte de fichiers.</p> <p>Espace disque disponible</p> <p>Disposer d'au moins 50 Go d'espace disque non partitionn\u00e9 pour Ubuntu. V\u00e9rifier l'espace disponible dans les param\u00e8tres syst\u00e8me et redimensionner les partitions existantes si n\u00e9cessaire.</p> <p>Cr\u00e9ation d'une cl\u00e9 USB d'installation bootable</p> <p>Cr\u00e9er une cl\u00e9 USB bootable avec Ubuntu est n\u00e9cessaire pour l'installation en dual boot. T\u00e9l\u00e9charger le fichier ISO d'Ubuntu et utiliser un outil comme Rufus (Windows) ou Etcher (macOS/Linux) pour \u00e9crire l'image sur la cl\u00e9 USB.[5]</p> <p>Avec Rufus sur Windows : - Ouvrir Rufus et s\u00e9lectionner la cl\u00e9 USB - Pour le sch\u00e9ma de partition, choisir \"GPT\" sur les ordinateurs r\u00e9cents ou \"MBR\" sur les anciens mod\u00e8les - S\u00e9lectionner le fichier ISO d'Ubuntu - Cliquer sur \"D\u00e9marrer\" et confirmer le formatage de la cl\u00e9</p>"},{"location":"_projects/_formation-bash/bash-chap01/#preparation-du-disque-dur","title":"Pr\u00e9paration du disque dur","text":"<p>Redimensionner la partition existante</p> <p>Sur Windows, acc\u00e9der \u00e0 \"Gestion des disques\" (clic droit sur \"Ordinateur\" &gt; G\u00e9rer &gt; Gestion des disques). Clic droit sur la partition Windows existante et s\u00e9lectionner \"R\u00e9duire le volume\". Indiquer l'espace \u00e0 lib\u00e9rer (au moins 50 Go). Confirmer l'op\u00e9ration qui r\u00e9duit la partition Windows et cr\u00e9e de l'espace non partitionn\u00e9.</p> <p>Red\u00e9marrage depuis la cl\u00e9 USB</p> <p>Brancher la cl\u00e9 USB d'installation, puis red\u00e9marrer l'ordinateur. Lors du red\u00e9marrage, appuyer sur la touche appropri\u00e9e pour acc\u00e9der au menu d'amor\u00e7age (g\u00e9n\u00e9ralement F12, F2, ESC ou DEL selon le fabricant). S\u00e9lectionner la cl\u00e9 USB dans le menu d'amor\u00e7age pour d\u00e9marrer depuis Ubuntu.</p>"},{"location":"_projects/_formation-bash/bash-chap01/#processus-dinstallation-en-dual-boot","title":"Processus d'installation en dual boot","text":"<p>Accueil et options initiales</p> <p>L'\u00e9cran d'accueil d'Ubuntu propose deux options : \"Essayer Ubuntu\" ou \"Installer Ubuntu\". S\u00e9lectionner \"Installer Ubuntu\" pour proc\u00e9der \u00e0 l'installation.</p> <p>Configuration de langue et clavier</p> <p>S\u00e9lectionner la langue de l'interface et la disposition du clavier, identique au processus en machine virtuelle.</p> <p>Type d'installation crucial</p> <p>Lors du partitionnement du disque, Ubuntu propose plusieurs options d'installation. S\u00e9lectionner \"Autre chose\" (Something else) pour acc\u00e9der au partitionnement manuel. Cette option est cruciale en dual boot pour \u00e9viter d'\u00e9craser Windows accidentellement.</p> <p>Partitionnement manuel</p> <p>Identifier l'espace non partitionn\u00e9 (appara\u00eet g\u00e9n\u00e9ralement comme \"Espace libre\" ou \"Free space\" d'une taille de 50 Go). Cliquer sur cet espace et cr\u00e9er une nouvelle partition.</p> <p>Les partitions recommand\u00e9es pour Ubuntu sont :</p> Partition Taille Type de fichier Point de montage Objectif Racine (/) 25-30 Go ext4 / Syst\u00e8me principal Swap 4-8 Go Swap - M\u00e9moire virtuelle Home (/home) Reste ext4 /home Donn\u00e9es utilisateur <p>Pour chaque partition : 1. Cliquer sur l'espace libre 2. Indiquer la taille en Mo ou Go 3. Choisir \"Primaire\" ou \"Logique\" 4. S\u00e9lectionner le type de fichier (ext4) 5. Indiquer le point de montage (/ pour racine, /home pour home)</p> <p>S\u00e9lection du gestionnaire d'amor\u00e7age</p> <p>Ubuntu propose d'installer le gestionnaire d'amor\u00e7age GRUB sur le disque dur principal. GRUB permet de choisir entre Ubuntu et Windows au d\u00e9marrage. Accepter l'installation par d\u00e9faut sur le disque principal (g\u00e9n\u00e9ralement /dev/sda).</p> <p>Cr\u00e9ation du compte utilisateur</p> <p>Entrer les informations utilisateur comme d\u00e9crit pr\u00e9c\u00e9demment pour la machine virtuelle.</p> <p>Installation finale</p> <p>L'installateur copie les fichiers sur les partitions cr\u00e9\u00e9es, configure le syst\u00e8me, et installe le gestionnaire d'amor\u00e7age. Cette \u00e9tape dure 10 \u00e0 15 minutes.</p> <p>Red\u00e9marrage et menu GRUB</p> <p>Apr\u00e8s l'installation, l'ordinateur red\u00e9marre. Au d\u00e9marrage, le menu GRUB s'affiche avec deux options : \"Ubuntu\" et \"Windows\" (ou \"Windows Boot Manager\"). S\u00e9lectionner Ubuntu pour confirmer que l'installation a r\u00e9ussi.</p>"},{"location":"_projects/_formation-bash/bash-chap01/#avantages-et-inconvenients-du-dual-boot","title":"Avantages et inconv\u00e9nients du dual boot","text":"Aspect Dual boot Machine virtuelle Performances Excellentes (natif) R\u00e9duites (\u00e9mulation) Isolation Faible (risque de conflit) Excellente (compl\u00e8tement isol\u00e9e) Facilit\u00e9 d'installation Moyenne (plus technique) Simple (guid\u00e9e) S\u00e9curit\u00e9 des donn\u00e9es Risqu\u00e9e (partitionnement) S\u00fbre (snapshot possible) Flexibilit\u00e9 Limit\u00e9e (un seul OS par d\u00e9marrage) Maximale (plusieurs VM simultan\u00e9es) R\u00e9cup\u00e9ration Difficile en cas d'erreur Simple (snapshot ou suppression)"},{"location":"_projects/_formation-bash/bash-chap01/#recommandations-pour-debuter","title":"Recommandations pour d\u00e9buter","text":"<p>Pour une premi\u00e8re approche de Linux et Bash, la machine virtuelle est recommand\u00e9e. Elle offre un environnement d'apprentissage s\u00e9curis\u00e9 sans risque de compromettre le syst\u00e8me principal. Une fois les fondamentaux ma\u00eetris\u00e9s et la confiance acquise, le dual boot peut \u00eatre envisag\u00e9 pour b\u00e9n\u00e9ficier des performances maximales.</p> <p>Le chemin d'apprentissage id\u00e9al consiste \u00e0 :</p> <ol> <li>Commencer par une machine virtuelle pour explorer Linux et Bash sans risque</li> <li>Pratiquer les commandes de base et scripts Bash</li> <li>Progresser vers des t\u00e2ches d'administration plus complexes</li> <li>Envisager le dual boot une fois les comp\u00e9tences solides</li> <li>Finalement explorer des environnements serveur r\u00e9els (VPS, cloud)</li> </ol> <p>Cette progression gradu\u00e9e garantit une fondation solide et d\u00e9veloppe la confiance n\u00e9cessaire pour g\u00e9rer des syst\u00e8mes Linux en environnement professionnel.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-bash/bash-chap02/","title":"Citations","text":"<ul> <li>https://www.it-connect.fr/debuter-script-bash-linux/</li> <li>https://blog.stephane-robert.info/docs/admin-serveurs/linux/shells-linux/bash/</li> <li>https://www.metal3d.org/blog/2023/bien-configurer-son-terminal-bash/</li> <li>https://www.youtube.com/watch?v=RzzwzYjUX3k</li> <li>https://www.ionos.fr/digitalguide/serveur/configuration/commandes-linux/</li> <li>https://linux.goffinet.org/administration/le-shell/la-ligne-de-commande/</li> <li>https://serverspace.io/fr/support/help/bash-cheat-sheet/</li> <li>https://openclassrooms.com/fr/courses/7274161-administrez-un-systeme-linux/7529311-lancez-des-commandes-sous-bash</li> <li>http://doc.ubuntu-fr.org/tutoriel/script_shell</li> <li>https://www.mode83.net/atelier/centre_ressources/crs_fichiers/Formation/OSR2K9/Linux/Programmation%20Bash.pdf</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap02/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 286</li> <li>completion_tokens: 5017</li> <li>total_tokens: 5303</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.075, 'request_cost': 0.006, 'total_cost': 0.082}</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap02/#content","title":"Content","text":""},{"location":"_projects/_formation-bash/bash-chap02/#chapitre-2-presentation-du-terminal","title":"Chapitre 2 : Pr\u00e9sentation du Terminal","text":"<p>Le terminal Linux repr\u00e9sente la porte d'entr\u00e9e vers l'apprentissage de Bash et de l'administration syst\u00e8me. Ce chapitre couvre les \u00e9l\u00e9ments fondamentaux n\u00e9cessaires pour comprendre et utiliser efficacement l'interface en ligne de commande, en partant de l'ouverture du terminal jusqu'\u00e0 la ma\u00eetrise des outils d'aide int\u00e9gr\u00e9s.</p>"},{"location":"_projects/_formation-bash/bash-chap02/#ouvrir-le-terminal","title":"Ouvrir le Terminal","text":""},{"location":"_projects/_formation-bash/bash-chap02/#acces-au-terminal-sous-linux","title":"Acc\u00e8s au Terminal sous Linux","text":"<p>Le terminal est l'application qui permet d'acc\u00e9der \u00e0 l'interpr\u00e9teur de commandes Bash. Sur la plupart des distributions Linux, plusieurs m\u00e9thodes permettent d'y acc\u00e9der[4].</p> <p>La premi\u00e8re approche consiste \u00e0 naviguer jusqu'au menu des programmes et localiser l'application \"Terminal\". Dans des environnements de bureau comme Linux Mint ou Ubuntu, cette application est g\u00e9n\u00e9ralement visible dans le menu des applications ou accessible via une barre lat\u00e9rale d\u00e9di\u00e9e[4]. Une fois lanc\u00e9e, une nouvelle fen\u00eatre s'affiche avec une invite de commande clignotante, pr\u00eate \u00e0 recevoir des instructions.</p> <p>Une deuxi\u00e8me m\u00e9thode, plus rapide, utilise les raccourcis clavier. Sur la majorit\u00e9 des distributions Linux avec interface graphique, la combinaison Ctrl+Alt+T ouvre directement le terminal. Cette m\u00e9thode s'av\u00e8re particuli\u00e8rement efficace pour les utilisateurs exp\u00e9riment\u00e9s qui travaillent r\u00e9guli\u00e8rement en ligne de commande.</p>"},{"location":"_projects/_formation-bash/bash-chap02/#composition-de-linvite-de-commande","title":"Composition de l'Invite de Commande","text":"<p>L'invite de commande (prompt) affich\u00e9e au d\u00e9marrage du terminal contient plusieurs informations essentielles. G\u00e9n\u00e9ralement, elle se pr\u00e9sente sous la forme suivante :</p> Text Only<pre><code>utilisateur@machine:~/r\u00e9pertoire$\n</code></pre> <p>Chaque \u00e9l\u00e9ment de cette composition poss\u00e8de une signification distincte :</p> <ul> <li>utilisateur : le nom du compte connect\u00e9 au syst\u00e8me</li> <li>machine : le nom d'h\u00f4te ou l'identifiant de l'ordinateur</li> <li>~/r\u00e9pertoire : le chemin du r\u00e9pertoire actuel (le tilde ~ repr\u00e9sente le r\u00e9pertoire utilisateur)</li> <li>$ : symbole indiquant que l'utilisateur poss\u00e8de des droits normaux (le symbole # indique au contraire les droits administrateur ou root)</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap02/#premiere-commande","title":"Premi\u00e8re Commande","text":""},{"location":"_projects/_formation-bash/bash-chap02/#executer-une-commande-simple","title":"Ex\u00e9cuter une Commande Simple","text":"<p>La premi\u00e8re \u00e9tape pour interagir avec Bash consiste \u00e0 ex\u00e9cuter une commande \u00e9l\u00e9mentaire. La commande ls (pour \"list\") repr\u00e9sente un excellent point de d\u00e9part pour d\u00e9buter[4]. Cette commande affiche le contenu du r\u00e9pertoire actuel.</p> Bash<pre><code>ls\n</code></pre> <p>L'ex\u00e9cution de cette commande fournit une liste simple des fichiers et des dossiers pr\u00e9sents dans le r\u00e9pertoire courant. Le processus s'effectue comme suit : l'utilisateur tape la commande, puis appuie sur la touche Entr\u00e9e (ou Return). Le syst\u00e8me ex\u00e9cute imm\u00e9diatement la commande et affiche le r\u00e9sultat avant de retourner \u00e0 l'invite de commande.</p>"},{"location":"_projects/_formation-bash/bash-chap02/#options-et-arguments","title":"Options et Arguments","text":"<p>La commande ls accepte plusieurs options pour personnaliser son comportement et son affichage. Une option court est pr\u00e9c\u00e9d\u00e9e d'un tiret unique, tandis qu'une option longue est pr\u00e9c\u00e9d\u00e9e de deux tirets[4].</p> Bash<pre><code>ls -l\n</code></pre> <p>L'option <code>-l</code> (long format) transforme l'affichage en une liste verticale d\u00e9taill\u00e9e, affichant des informations suppl\u00e9mentaires comme les permissions, le propri\u00e9taire, la taille et la date de modification de chaque fichier.</p> <p>Une autre option utile est <code>-a</code> (all), qui affiche tous les fichiers, incluant les fichiers cach\u00e9s (dont le nom commence par un point) :</p> Bash<pre><code>ls -a\n</code></pre> <p>Il est possible de combiner plusieurs options en une seule commande :</p> Bash<pre><code>ls -la\n</code></pre> <p>Cette commande affiche tous les fichiers (y compris les cach\u00e9s) au format long d\u00e9taill\u00e9.</p> <p>Les arguments diff\u00e8rent des options : ils sp\u00e9cifient sur quel \u00e9l\u00e9ment la commande doit op\u00e9rer. Par exemple, pour lister le contenu d'un r\u00e9pertoire sp\u00e9cifique plut\u00f4t que le r\u00e9pertoire courant :</p> Bash<pre><code>ls /home/utilisateur\n</code></pre> <p>Dans cet exemple, <code>/home/utilisateur</code> repr\u00e9sente l'argument : la commande <code>ls</code> op\u00e8re sur ce r\u00e9pertoire sp\u00e9cifique.</p>"},{"location":"_projects/_formation-bash/bash-chap02/#composition-dune-commande","title":"Composition d'une Commande","text":""},{"location":"_projects/_formation-bash/bash-chap02/#structure-generale","title":"Structure g\u00e9n\u00e9rale","text":"<p>Comprendre la structure d'une commande Bash est fondamental pour utiliser efficacement le terminal[1]. Une commande Bash suit g\u00e9n\u00e9ralement cette structure :</p> Text Only<pre><code>commande [options] [arguments]\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap02/#dissection-dune-commande-complete","title":"Dissection d'une Commande Compl\u00e8te","text":"<p>Prenons comme exemple une commande plus complexe :</p> Bash<pre><code>ls -l /home/flo\n</code></pre> <p>Dans cette commande :</p> <ul> <li>ls est le programme ou la commande \u00e0 ex\u00e9cuter</li> <li>-l est une option qui modifie le comportement du programme (affichage long)</li> <li>/home/flo est l'argument qui sp\u00e9cifie le chemin sur lequel op\u00e9rer</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap02/#commandes-courantes-et-leurs-composants","title":"Commandes Courantes et Leurs Composants","text":""},{"location":"_projects/_formation-bash/bash-chap02/#commande-pwd","title":"Commande pwd","text":"<p>La commande pwd (print working directory) affiche le r\u00e9pertoire de travail actuel[1]. Cette commande ne n\u00e9cessite aucun argument obligatoire :</p> Bash<pre><code>pwd\n</code></pre> <p>R\u00e9sultat typique : <code>/home/utilisateur</code></p>"},{"location":"_projects/_formation-bash/bash-chap02/#commande-cd","title":"Commande cd","text":"<p>La commande cd (change directory) permet de naviguer entre les r\u00e9pertoires[1]. Elle requiert un argument : le r\u00e9pertoire destination.</p> Bash<pre><code>cd /home/utilisateur/Documents\n</code></pre> <p>Cette commande change le r\u00e9pertoire courant vers <code>/home/utilisateur/Documents</code>. Le r\u00e9pertoire parent peut \u00eatre atteint via :</p> Bash<pre><code>cd ..\n</code></pre> <p>Le r\u00e9pertoire utilisateur personnel est accessible avec :</p> Bash<pre><code>cd ~\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap02/#commande-mkdir","title":"Commande mkdir","text":"<p>La commande mkdir (make directory) cr\u00e9e un nouveau r\u00e9pertoire[1]. Elle prend en argument le nom du r\u00e9pertoire \u00e0 cr\u00e9er :</p> Bash<pre><code>mkdir MonDossier\n</code></pre> <p>Pour cr\u00e9er plusieurs r\u00e9pertoires imbriqu\u00e9s en une seule commande, l'option <code>-p</code> s'utilise :</p> Bash<pre><code>mkdir -p Dossier1/Dossier2/Dossier3\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap02/#commande-touch","title":"Commande touch","text":"<p>La commande touch cr\u00e9e un fichier vide ou met \u00e0 jour la date d'acc\u00e8s d'un fichier existant[1] :</p> Bash<pre><code>touch MonFichier.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap02/#commande-rm","title":"Commande rm","text":"<p>La commande rm (remove) supprime des fichiers ou des r\u00e9pertoires[1]. Pour supprimer un fichier :</p> Bash<pre><code>rm MonFichier.txt\n</code></pre> <p>Pour supprimer un r\u00e9pertoire et son contenu, l'option <code>-r</code> (r\u00e9cursive) s'emploie :</p> Bash<pre><code>rm -r MonDossier\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap02/#terminal-et-shell","title":"Terminal et Shell","text":""},{"location":"_projects/_formation-bash/bash-chap02/#distinction-fondamentale","title":"Distinction Fondamentale","text":"<p>Un \u00e9l\u00e9ment crucial \u00e0 comprendre est la diff\u00e9rence entre le terminal et le shell. Ces deux termes sont souvent confondus par les d\u00e9butants, mais ils d\u00e9signent des \u00e9l\u00e9ments distincts du syst\u00e8me.</p>"},{"location":"_projects/_formation-bash/bash-chap02/#le-terminal","title":"Le Terminal","text":"<p>Le terminal est l'application graphique qui fournit une interface permettant \u00e0 l'utilisateur d'interagir avec le syst\u00e8me d'exploitation. C'est essentiellement une fen\u00eatre dans laquelle du texte peut \u00eatre saisi et des r\u00e9sultats affich\u00e9s. Le terminal est un programme \u00e9mulateur qui simule le fonctionnement des anciens terminaux physiques utilis\u00e9s autrefois pour communiquer avec les ordinateurs centraux.</p>"},{"location":"_projects/_formation-bash/bash-chap02/#le-shell","title":"Le Shell","text":"<p>Le shell (litt\u00e9ralement \"coquille\") est l'interpr\u00e9teur de commandes qui se positionne entre l'utilisateur et le syst\u00e8me d'exploitation[1]. Il s'agit d'un logiciel responsable de l'interpr\u00e9tation et de l'ex\u00e9cution des commandes tap\u00e9es par l'utilisateur.</p> <p>Bash (Bourne Again Shell) repr\u00e9sente l'un des shells les plus utilis\u00e9s sur les syst\u00e8mes Unix et Linux[1]. Il est pr\u00e9sent par d\u00e9faut sur la majorit\u00e9 des distributions Linux populaires, notamment Debian, Ubuntu, Rocky Linux et autres[1].</p>"},{"location":"_projects/_formation-bash/bash-chap02/#relation-entre-terminal-et-shell","title":"Relation entre Terminal et Shell","text":"<p>Voici la relation fonctionnelle entre ces composants :</p> <ol> <li>L'utilisateur ouvre une fen\u00eatre de terminal (application graphique)</li> <li>\u00c0 l'int\u00e9rieur de cette fen\u00eatre, un shell (comme Bash) s'ex\u00e9cute</li> <li>L'utilisateur tape des commandes dans le terminal</li> <li>Le terminal transmet les commandes au shell</li> <li>Le shell interpr\u00e8te les commandes et les ex\u00e9cute</li> <li>Le shell retourne les r\u00e9sultats au terminal</li> <li>Le terminal affiche les r\u00e9sultats \u00e0 l'\u00e9cran</li> </ol> <p>D'autres shells existent \u00e9galement sur les syst\u00e8mes Linux, comme sh (le shell original), zsh (un shell avanc\u00e9), ou fish (friendly interactive shell). Cependant, Bash demeure le choix par d\u00e9faut sur la plupart des installations Linux.</p>"},{"location":"_projects/_formation-bash/bash-chap02/#presentation-du-manuel","title":"Pr\u00e9sentation du Manuel","text":""},{"location":"_projects/_formation-bash/bash-chap02/#importance-de-la-documentation","title":"Importance de la Documentation","text":"<p>L'une des comp\u00e9tences les plus pr\u00e9cieuses pour tout utilisateur Linux consiste \u00e0 savoir consulter efficacement la documentation int\u00e9gr\u00e9e du syst\u00e8me. Le manuel (man pages) repr\u00e9sente la ressource fondamentale pour comprendre chaque commande, ses options, ses arguments et son fonctionnement d\u00e9taill\u00e9[1].</p>"},{"location":"_projects/_formation-bash/bash-chap02/#acceder-au-manuel","title":"Acc\u00e9der au Manuel","text":"<p>La commande man permet de consulter le manuel de n'importe quelle commande disponible sur le syst\u00e8me[1]. La syntaxe g\u00e9n\u00e9rale est :</p> Bash<pre><code>man nom_de_la_commande\n</code></pre> <p>Par exemple, pour consulter le manuel de la commande <code>ls</code> :</p> Bash<pre><code>man ls\n</code></pre> <p>Cette commande ouvre une interface de lecture de texte dans le terminal. Le manuel affiche une documentation compl\u00e8te : une description g\u00e9n\u00e9rale, la liste de toutes les options disponibles, des exemples d'utilisation, et souvent des remarques importantes ou des comportements sp\u00e9cifiques.</p>"},{"location":"_projects/_formation-bash/bash-chap02/#navigation-dans-le-manuel","title":"Navigation dans le Manuel","text":"<p>Une fois le manuel ouvert, plusieurs raccourcis clavier permettent de naviguer dans le texte[3] :</p> <ul> <li>Barre d'espace : avancer d'une page</li> <li>B : reculer d'une page</li> <li>/terme : rechercher un terme sp\u00e9cifique dans le document</li> <li>N : aller \u00e0 l'occurrence suivante du terme recherch\u00e9</li> <li>Maj+N : aller \u00e0 l'occurrence pr\u00e9c\u00e9dente du terme recherch\u00e9</li> <li>G : aller au d\u00e9but du document</li> <li>Maj+G : aller \u00e0 la fin du document</li> <li>Q : quitter le manuel et retourner \u00e0 l'invite de commande</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap02/#structure-du-manuel","title":"Structure du Manuel","text":"<p>Les pages de manuel suivent une structure standardis\u00e9e qui facilite la recherche d'informations :</p> <ul> <li>NAME : le nom et une description courte de la commande</li> <li>SYNOPSIS : la syntaxe g\u00e9n\u00e9rale d'utilisation</li> <li>DESCRIPTION : une explication d\u00e9taill\u00e9e du fonctionnement</li> <li>OPTIONS : la liste compl\u00e8te des options disponibles avec leurs descriptions</li> <li>EXAMPLES : des exemples concrets d'utilisation</li> <li>SEE ALSO : des r\u00e9f\u00e9rences vers d'autres commandes ou pages du manuel connexes</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap02/#exemple-pratique","title":"Exemple Pratique","text":"<p>Consulter le manuel de <code>ls</code> r\u00e9v\u00e8le une richesse d'informations :</p> Bash<pre><code>man ls\n</code></pre> <p>\u00c0 l'int\u00e9rieur du manuel, la section SYNOPSIS montre :</p> Text Only<pre><code>ls [OPTION]... [FILE]...\n</code></pre> <p>Cela indique que <code>ls</code> accepte z\u00e9ro, une ou plusieurs options, suivies de z\u00e9ro, un ou plusieurs fichiers. La section OPTIONS liste chaque option possible, par exemple :</p> <ul> <li><code>-l</code> : long format, affichage d\u00e9taill\u00e9</li> <li><code>-a</code> : affiche tous les fichiers, incluant ceux commen\u00e7ant par un point</li> <li><code>-h</code> : affiche les tailles en format lisible (K, M, G)</li> <li><code>-t</code> : trie par date de modification</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap02/#utilisation-du-manuel-et-de-help","title":"Utilisation du Manuel et de Help","text":""},{"location":"_projects/_formation-bash/bash-chap02/#la-commande-help","title":"La Commande help","text":"<p>En plus du manuel (<code>man</code>), Bash fournit une commande <code>help</code> pour obtenir une aide rapide sur les commandes int\u00e9gr\u00e9es au shell[1]. Ces commandes int\u00e9gr\u00e9es sont diff\u00e9rentes des programmes externes ; elles font partie du shell lui-m\u00eame.</p> Bash<pre><code>help\n</code></pre> <p>Cette commande, ex\u00e9cut\u00e9e seule, liste toutes les commandes int\u00e9gr\u00e9es de Bash. Pour obtenir de l'aide sur une commande sp\u00e9cifique int\u00e9gr\u00e9e au shell :</p> Bash<pre><code>help cd\n</code></pre> <p>Cette commande affiche une aide rapide sur la commande <code>cd</code>, notamment ses options et son utilisation.</p>"},{"location":"_projects/_formation-bash/bash-chap02/#difference-entre-man-et-help","title":"Diff\u00e9rence entre man et help","text":"<p>Il est important de distinguer les contextes o\u00f9 utiliser <code>man</code> par rapport \u00e0 <code>help</code> :</p> <ul> <li>help s'utilise pour les commandes int\u00e9gr\u00e9es au shell (comme <code>cd</code>, <code>echo</code>, <code>type</code>)</li> <li>man s'utilise pour les commandes externes (des programmes distincts comme <code>ls</code>, <code>grep</code>, <code>sed</code>)</li> </ul> <p>Certaines commandes poss\u00e8dent les deux. Dans ce cas, <code>man</code> fournit g\u00e9n\u00e9ralement une documentation plus compl\u00e8te, tandis que <code>help</code> offre une aide rapide directe.</p>"},{"location":"_projects/_formation-bash/bash-chap02/#option-help","title":"Option --help","text":"<p>De nombreux programmes externes proposent \u00e9galement une option <code>--help</code> ou <code>-h</code> qui fournit une aide rapide sans ouvrir le manuel complet :</p> Bash<pre><code>ls --help\n</code></pre> <p>Cette option affiche une aide synth\u00e9tique directement dans le terminal. C'est souvent plus rapide que d'ouvrir le manuel complet avec <code>man</code> lorsqu'il s'agit de v\u00e9rifier rapidement une option sp\u00e9cifique.</p>"},{"location":"_projects/_formation-bash/bash-chap02/#strategie-recommandee","title":"Strat\u00e9gie Recommand\u00e9e","text":"<p>Pour un apprentissage efficace, la strat\u00e9gie \u00e0 adopter est :</p> <ol> <li>Pour une aide rapide et imm\u00e9diate : utiliser l'option <code>--help</code> ou <code>-h</code></li> <li>Pour une documentation d\u00e9taill\u00e9e et des exemples : consulter le manuel avec <code>man</code></li> <li>Pour les commandes int\u00e9gr\u00e9es au shell : privil\u00e9gier <code>help</code></li> <li>Pour approfondir les connaissances : explorer des tutoriels en ligne et la documentation compl\u00e8te du syst\u00e8me</li> </ol>"},{"location":"_projects/_formation-bash/bash-chap02/#la-commande-history-et-raccourcis-clavier","title":"La Commande history et Raccourcis Clavier","text":""},{"location":"_projects/_formation-bash/bash-chap02/#consultation-de-lhistorique","title":"Consultation de l'Historique","text":"<p>La commande history affiche la liste de toutes les commandes ex\u00e9cut\u00e9es pr\u00e9c\u00e9demment dans le terminal[1]. Cette fonctionnalit\u00e9 s'av\u00e8re extr\u00eamement utile pour :</p> <ul> <li>Retrouver une commande complexe ex\u00e9cut\u00e9e ant\u00e9rieurement</li> <li>Comprendre les op\u00e9rations effectu\u00e9es dans une session</li> <li>Automatiser des t\u00e2ches r\u00e9currentes</li> </ul> Bash<pre><code>history\n</code></pre> <p>Cette commande affiche un num\u00e9ro avant chaque commande, facilitant sa r\u00e9utilisation. Par exemple :</p> Text Only<pre><code>   45  ls -l\n   46  cd Documents\n   47  pwd\n   48  mkdir Projets\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap02/#reutiliser-une-commande-de-lhistorique","title":"R\u00e9utiliser une Commande de l'Historique","text":"<p>Plusieurs m\u00e9thodes permettent de r\u00e9utiliser des commandes ant\u00e9rieures.</p> <p>La premi\u00e8re utilise Ctrl+R pour rechercher en arri\u00e8re dans l'historique :</p> Text Only<pre><code>(reverse-i-search): `ls'\n</code></pre> <p>En tapant les premi\u00e8res lettres d'une commande, le terminal affiche la commande la plus r\u00e9cente correspondante. Appuyer plusieurs fois sur Ctrl+R parcourt d'autres correspondances ant\u00e9rieures.</p> <p>Une deuxi\u00e8me approche utilise !n o\u00f9 n est le num\u00e9ro de la commande dans l'historique :</p> Bash<pre><code>!45\n</code></pre> <p>Cela r\u00e9ex\u00e9cute la commande num\u00e9ro 45 de l'historique.</p> <p>La commande !! r\u00e9ex\u00e9cute la derni\u00e8re commande :</p> Bash<pre><code>!!\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap02/#raccourcis-clavier-de-navigation","title":"Raccourcis Clavier de Navigation","text":"<p>Au-del\u00e0 de l'historique, plusieurs raccourcis clavier facilitent la navigation et l'\u00e9dition dans le terminal[3] :</p> <p>Navigation horizontale dans la commande en cours :</p> <ul> <li>Ctrl+A : placer le curseur au d\u00e9but de la ligne</li> <li>Ctrl+E : placer le curseur \u00e0 la fin de la ligne</li> <li>Ctrl+F : avancer d'un caract\u00e8re (forward)</li> <li>Ctrl+B : reculer d'un caract\u00e8re (backward)</li> </ul> <p>Navigation par mots :</p> <ul> <li>Alt+F : avancer d'un mot</li> <li>Alt+B : reculer d'un mot</li> </ul> <p>Suppression de caract\u00e8res :</p> <ul> <li>Ctrl+D : supprimer le caract\u00e8re sous le curseur</li> <li>Ctrl+H : supprimer le caract\u00e8re avant le curseur (\u00e9quivalent \u00e0 Backspace)</li> <li>Ctrl+W : supprimer le mot pr\u00e9c\u00e9dent</li> <li>Alt+D : supprimer le mot sous le curseur</li> </ul> <p>Modifications de la commande :</p> <ul> <li>Ctrl+K : supprimer du curseur jusqu'\u00e0 la fin de la ligne</li> <li>Ctrl+U : supprimer du d\u00e9but jusqu'au curseur</li> <li>Ctrl+Y : coller le texte supprim\u00e9 pr\u00e9c\u00e9demment</li> <li>Ctrl+L : effacer l'\u00e9cran et placer le curseur au d\u00e9but</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap02/#mise-en-arriere-plan","title":"Mise en Arri\u00e8re-Plan","text":"<p>Un raccourci particuli\u00e8rement utile est Ctrl+Z, qui met la commande en cours d'ex\u00e9cution en t\u00e2che de fond[3]. Cette fonctionnalit\u00e9 permet de suspendre temporairement une op\u00e9ration pour ex\u00e9cuter d'autres commandes.</p> Bash<pre><code>[COMMANDE EN COURS]\nCtrl+Z\n</code></pre> <p>Pour revenir \u00e0 la t\u00e2che suspendue, la commande <code>fg</code> (foreground) s'utilise :</p> Bash<pre><code>fg\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap02/#approfondissement-pratique","title":"Approfondissement Pratique","text":""},{"location":"_projects/_formation-bash/bash-chap02/#scenario-dapprentissage-complet","title":"Sc\u00e9nario d'Apprentissage Complet","text":"<p>Pour consolider la compr\u00e9hension de ce chapitre, voici un sc\u00e9nario d'apprentissage progressif :</p> <p>\u00c9tape 1 : Ma\u00eetriser les Commandes de Base</p> <p>Commencer par explorer le syst\u00e8me de fichiers en utilisant les commandes simples :</p> Bash<pre><code>pwd\n</code></pre> <p>Affiche le r\u00e9pertoire courant, permettant de comprendre la notion de \"chemin absolu\".</p> Bash<pre><code>ls\n</code></pre> <p>Liste les fichiers du r\u00e9pertoire courant. Observer la sortie et m\u00e9moriser les fichiers visibles.</p> Bash<pre><code>ls -l\n</code></pre> <p>Affiche les m\u00eames fichiers mais avec plus de d\u00e9tails : permissions, propri\u00e9taire, taille, date.</p> Bash<pre><code>cd /home\n</code></pre> <p>Change de r\u00e9pertoire. L'utilisateur comprend que son r\u00e9pertoire courant a chang\u00e9 en ex\u00e9cutant \u00e0 nouveau <code>pwd</code>.</p> Bash<pre><code>ls -la\n</code></pre> <p>Affiche maintenant tous les fichiers, incluant les fichiers cach\u00e9s du r\u00e9pertoire <code>/home</code>.</p> <p>\u00c9tape 2 : Consulter la Documentation</p> <p>Une fois les commandes de base ex\u00e9cut\u00e9es, consulter leur documentation :</p> Bash<pre><code>man ls\n</code></pre> <p>Parcourir le manuel, reconna\u00eetre sa structure, rechercher une option sp\u00e9cifique avec <code>/</code>.</p> Bash<pre><code>ls --help\n</code></pre> <p>Comparer l'aide rapide avec le manuel complet. Observer comment les options sont pr\u00e9sent\u00e9es diff\u00e9remment.</p> Bash<pre><code>help cd\n</code></pre> <p>Voir comment l'aide int\u00e9gr\u00e9e pr\u00e9sente la commande <code>cd</code>.</p> <p>\u00c9tape 3 : Comprendre Terminal et Shell</p> <p>Ex\u00e9cuter des commandes et observer que le terminal affiche simplement ce que le shell produit. Constater que chaque commande retourne \u00e0 l'invite de commande pour recevoir une nouvelle instruction.</p> <p>\u00c9tape 4 : Utiliser l'Historique</p> <p>Ex\u00e9cuter plusieurs commandes diff\u00e9rentes, puis :</p> Bash<pre><code>history\n</code></pre> <p>Voir la liste de toutes les commandes. Rep\u00e9rer une commande pr\u00e9c\u00e9dente et la r\u00e9ex\u00e9cuter via :</p> Bash<pre><code>!numero\n</code></pre> <p>Ou utiliser Ctrl+R pour rechercher une commande sp\u00e9cifique.</p> <p>\u00c9tape 5 : Optimiser avec les Raccourcis</p> <p>En \u00e9disant une commande longue, utiliser Ctrl+A pour aller au d\u00e9but, Alt+F pour avancer par mots, et Ctrl+W pour supprimer le mot pr\u00e9c\u00e9dent. Ces raccourcis acc\u00e9l\u00e8rent consid\u00e9rablement le travail en ligne de commande.</p>"},{"location":"_projects/_formation-bash/bash-chap02/#creation-dun-premier-script-de-demonstration","title":"Cr\u00e9ation d'un Premier Script de D\u00e9monstration","text":"<p>Pour appliquer concr\u00e8tement les apprentissages de ce chapitre, cr\u00e9er un premier script simple :</p> Bash<pre><code>#!/bin/bash\n\n# Afficher le r\u00e9pertoire courant\necho \"R\u00e9pertoire courant :\"\npwd\n\n# Lister les fichiers avec d\u00e9tails\necho -e \"\\nFichiers du r\u00e9pertoire :\"\nls -la\n\n# Afficher le nombre de fichiers\necho -e \"\\nNombre de fichiers et dossiers :\"\nls -1 | wc -l\n</code></pre> <p>Ce script, nomm\u00e9 <code>demo.sh</code>, combine plusieurs concepts : l'utilisation du shebang, l'ex\u00e9cution de commandes, et l'affichage des r\u00e9sultats. Il d\u00e9montre concr\u00e8tement comment les commandes apprises s'assemblent pour former un outil automatis\u00e9.</p> <p>Pour ex\u00e9cuter ce script :</p> Bash<pre><code>chmod +x demo.sh\n./demo.sh\n</code></pre> <p>La premi\u00e8re commande donne la permission d'ex\u00e9cution au script. La seconde commande l'ex\u00e9cute. Le r\u00e9sultat affiche le r\u00e9pertoire courant, la liste des fichiers, et le nombre total d'\u00e9l\u00e9ments dans le r\u00e9pertoire.</p>"},{"location":"_projects/_formation-bash/bash-chap02/#resume-des-concepts-cles","title":"R\u00e9sum\u00e9 des Concepts Cl\u00e9s","text":"<p>Ce chapitre pose les fondations essentielles pour l'apprentissage de Bash et de l'administration Linux. Les concepts pr\u00e9sent\u00e9s\u2014terminal vs shell, structure des commandes, utilisation de la documentation\u2014forment un socle sur lequel s'appuient tous les apprentissages ult\u00e9rieurs. La ma\u00eetrise de ces \u00e9l\u00e9ments de base permet de progresser rapidement vers des concepts plus avanc\u00e9s comme les variables, les boucles, et les scripts complexes.</p> <p>L'accent mis sur la documentation (man, help, --help) est particuli\u00e8rement important : c'est gr\u00e2ce \u00e0 ces outils que les utilisateurs deviennent autonomes et capable d'explorer de nouvelles commandes sans aide ext\u00e9rieure. Le terminal ne doit pas intimider : c'est simplement un outil d'interface, et Bash est un langage de commandes logique et coh\u00e9rent une fois ses principes de base compris.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-bash/bash-chap03/","title":"Citations","text":"<ul> <li>https://www.it-connect.fr/debuter-script-bash-linux/</li> <li>https://tutoriels.lws.fr/vps/initiation-au-script-bash-linux-avec-exemples</li> <li>http://doc.ubuntu-fr.org/tutoriel/script_shell</li> <li>https://www.youtube.com/watch?v=gBCGeLjYBgQ</li> <li>https://www.hostinger.com/fr/tutoriels/script-bash</li> <li>https://www.datacamp.com/fr/tutorial/how-to-write-bash-script-tutorial</li> <li>https://serverspace.io/fr/support/help/bash-cheat-sheet/</li> <li>https://blog.stephane-robert.info/docs/admin-serveurs/linux/shells-linux/bash/</li> <li>https://openclassrooms.com/fr/courses/7274161-administrez-un-systeme-linux/7529311-lancez-des-commandes-sous-bash</li> <li>https://abs.traduc.org/abs-fr/</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap03/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 336</li> <li>completion_tokens: 6666</li> <li>total_tokens: 7002</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.1, 'request_cost': 0.006, 'total_cost': 0.107}</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap03/#content","title":"Content","text":""},{"location":"_projects/_formation-bash/bash-chap03/#guide-detaille-du-systeme-de-fichiers-sous-linux-et-bash","title":"\ud83d\udcda Guide D\u00e9taill\u00e9 du Syst\u00e8me de Fichiers sous Linux et Bash","text":""},{"location":"_projects/_formation-bash/bash-chap03/#introduction-au-systeme-de-fichiers","title":"\ud83c\udfaf Introduction au Syst\u00e8me de Fichiers","text":"<p>Le syst\u00e8me de fichiers Linux constitue l'une des fondations essentielles pour ma\u00eetriser l'administration syst\u00e8me et l'automatisation de t\u00e2ches sous Bash. Contrairement aux syst\u00e8mes d'exploitation graphiques, Linux offre une approche hi\u00e9rarchique et organis\u00e9e pour g\u00e9rer l'ensemble des donn\u00e9es, ressources et configurations d'une machine. Le syst\u00e8me de fichiers ne se limite pas simplement au stockage de donn\u00e9es : il englobe \u00e9galement les p\u00e9riph\u00e9riques, les processus en cours d'ex\u00e9cution et les configurations syst\u00e8me.[1][3]</p> <p>La compr\u00e9hension profonde du syst\u00e8me de fichiers repr\u00e9sente un atout majeur pour toute personne souhaitant administrer efficacement une machine Linux. Cette ma\u00eetrise facilite non seulement la navigation quotidienne mais permet \u00e9galement d'\u00e9crire des scripts Bash robustes et efficaces qui automatisent les op\u00e9rations complexes.</p>"},{"location":"_projects/_formation-bash/bash-chap03/#architecture-generale-du-systeme-de-fichiers-linux","title":"\ud83d\uddc2\ufe0f Architecture G\u00e9n\u00e9rale du Syst\u00e8me de Fichiers Linux","text":"<p>Le syst\u00e8me de fichiers Linux suit une structure arborescente, o\u00f9 tout \u00e9l\u00e9ment d\u00e9rive d'un r\u00e9pertoire racine d\u00e9sign\u00e9 par le symbole <code>/</code>. Cette architecture hi\u00e9rarchique permet d'organiser rationnellement l'ensemble des \u00e9l\u00e9ments du syst\u00e8me.</p>"},{"location":"_projects/_formation-bash/bash-chap03/#principaux-repertoires-du-systeme","title":"Principaux R\u00e9pertoires du Syst\u00e8me","text":"<ul> <li><code>/</code> : Le r\u00e9pertoire racine, point de d\u00e9part de toute l'arborescence</li> <li><code>/home</code> : Contient les r\u00e9pertoires personnels des utilisateurs</li> <li><code>/root</code> : Le r\u00e9pertoire personnel de l'administrateur syst\u00e8me (root)</li> <li><code>/etc</code> : Stocke les fichiers de configuration du syst\u00e8me</li> <li><code>/bin</code> et <code>/usr/bin</code> : Contiennent les ex\u00e9cutables et commandes disponibles</li> <li><code>/tmp</code> : R\u00e9pertoire temporaire pour les fichiers \u00e9ph\u00e9m\u00e8res</li> <li><code>/var</code> : Contient les fichiers variables (logs, donn\u00e9es temporaires)</li> <li><code>/dev</code> : Repr\u00e9sente les p\u00e9riph\u00e9riques du syst\u00e8me</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap03/#navigation-dans-le-systeme-de-fichiers","title":"\ud83e\udded Navigation dans le Syst\u00e8me de Fichiers","text":""},{"location":"_projects/_formation-bash/bash-chap03/#determiner-le-repertoire-courant","title":"D\u00e9terminer le R\u00e9pertoire Courant","text":"<p>La commande <code>pwd</code> (Print Working Directory) affiche le chemin complet du r\u00e9pertoire actuel. Cette information s'av\u00e8re cruciale lors de la cr\u00e9ation ou manipulation de fichiers, car les op\u00e9rations s'effectuent par d\u00e9faut dans le r\u00e9pertoire courant.</p> Bash<pre><code>pwd\n</code></pre> <p>Cette commande retourne un chemin absolu comme <code>/home/utilisateur/Documents</code>.</p>"},{"location":"_projects/_formation-bash/bash-chap03/#changer-de-repertoire","title":"Changer de R\u00e9pertoire","text":"<p>La commande <code>cd</code> (Change Directory) permet de naviguer dans l'arborescence du syst\u00e8me.[1] Elle accepte plusieurs formes de chemins :</p> Bash<pre><code># Naviguer vers un chemin absolu\ncd /etc\n\n# Naviguer vers un chemin relatif\ncd Documents\n\n# Retourner au r\u00e9pertoire personnel\ncd ~\n\n# Revenir au r\u00e9pertoire pr\u00e9c\u00e9dent\ncd -\n\n# Monter d'un niveau dans la hi\u00e9rarchie\ncd ..\n\n# Aller au r\u00e9pertoire racine\ncd /\n</code></pre> <p>Les chemins peuvent \u00eatre sp\u00e9cifi\u00e9s de deux mani\u00e8res distinctes : les chemins absolus commencent par <code>/</code> et d\u00e9crivent le trajet complet depuis la racine, tandis que les chemins relatifs sont calcul\u00e9s \u00e0 partir du r\u00e9pertoire courant.</p>"},{"location":"_projects/_formation-bash/bash-chap03/#lister-le-contenu-des-repertoires","title":"Lister le Contenu des R\u00e9pertoires","text":"<p>La commande <code>ls</code> (List) affiche le contenu d'un r\u00e9pertoire.[1] Plusieurs variantes offrent des niveaux de d\u00e9tail diff\u00e9rents :</p> Bash<pre><code># Affichage simple\nls\n\n# Affichage d\u00e9taill\u00e9 en liste verticale\nls -l\n\n# Inclure les fichiers cach\u00e9s (commen\u00e7ant par .)\nls -a\n\n# Combinaison d\u00e9taill\u00e9e avec fichiers cach\u00e9s\nls -la\n\n# Affichage avec tailles lisibles\nls -lh\n\n# Tri par date de modification\nls -lt\n\n# Affichage r\u00e9cursif des sous-dossiers\nls -R\n</code></pre> <p>L'option <code>-l</code> produit un affichage d\u00e9taill\u00e9 pr\u00e9sentant les informations suivantes pour chaque fichier : - Permissions : Les 10 premiers caract\u00e8res (ex: <code>-rwxr-xr-x</code>) - Nombre de liens : Nombre de r\u00e9f\u00e9rences au fichier - Propri\u00e9taire : L'utilisateur poss\u00e9dant le fichier - Groupe : Le groupe auquel appartient le fichier - Taille : En octets - Date de modification : La date et heure du dernier changement - Nom du fichier : Le nom complet du fichier</p>"},{"location":"_projects/_formation-bash/bash-chap03/#creer-des-fichiers-des-dossiers-et-des-liens","title":"\ud83d\udcdd Cr\u00e9er des Fichiers, des Dossiers et des Liens","text":""},{"location":"_projects/_formation-bash/bash-chap03/#creer-des-fichiers","title":"Cr\u00e9er des Fichiers","text":""},{"location":"_projects/_formation-bash/bash-chap03/#avec-la-commande-touch","title":"Avec la Commande <code>touch</code>","text":"<p>La commande <code>touch</code> cr\u00e9e instantan\u00e9ment un fichier vide ou met \u00e0 jour la date de modification d'un fichier existant.[1]</p> Bash<pre><code># Cr\u00e9er un fichier vide\ntouch monFichier.txt\n\n# Cr\u00e9er plusieurs fichiers simultan\u00e9ment\ntouch fichier1.txt fichier2.txt fichier3.txt\n\n# Cr\u00e9er un fichier avec un nom contenant des espaces\ntouch \"Mon fichier.txt\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#avec-un-editeur-de-texte","title":"Avec un \u00c9diteur de Texte","text":"<p>Des \u00e9diteurs comme <code>vim</code> ou <code>nano</code> permettent de cr\u00e9er et modifier des fichiers simultan\u00e9ment :</p> Bash<pre><code># Utiliser VIM\nvim monfichier.sh\n\n# Utiliser Nano (plus intuitif pour les d\u00e9butants)\nnano monfichier.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#avec-redirection-de-sortie","title":"Avec Redirection de Sortie","text":"<p>La redirection du flux de sortie cr\u00e9e \u00e9galement des fichiers :[7]</p> Bash<pre><code># Redirection simple (\u00e9crase le fichier)\necho \"Contenu initial\" &gt; nouveau_fichier.txt\n\n# Redirection avec ajout (ajoute au fichier)\necho \"Contenu suppl\u00e9mentaire\" &gt;&gt; nouveau_fichier.txt\n\n# Cr\u00e9er un fichier \u00e0 partir de la sortie d'une commande\nls &gt; liste_fichiers.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#creer-des-dossiers","title":"Cr\u00e9er des Dossiers","text":"<p>La commande <code>mkdir</code> (Make Directory) cr\u00e9e des r\u00e9pertoires.[1] Elle offre plusieurs options pour une gestion flexible :</p> Bash<pre><code># Cr\u00e9er un seul r\u00e9pertoire\nmkdir monDossier\n\n# Cr\u00e9er plusieurs r\u00e9pertoires simultan\u00e9ment\nmkdir dossier1 dossier2 dossier3\n\n# Cr\u00e9er une arborescence compl\u00e8te (-p pour parents)\nmkdir -p Projets/WebApp/src/components\n\n# Cr\u00e9er avec permissions sp\u00e9cifiques\nmkdir -m 755 MonDossierPublic\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#creer-des-liens-symboliques","title":"Cr\u00e9er des Liens Symboliques","text":"<p>Les liens symboliques cr\u00e9ent des raccourcis vers des fichiers ou dossiers existants, essentiels pour l'organisation complexe :</p> Bash<pre><code># Cr\u00e9er un lien symbolique vers un fichier\nln -s /chemin/vers/fichier_original.txt raccourci.txt\n\n# Cr\u00e9er un lien symbolique vers un dossier\nln -s /home/utilisateur/ProjetLong ~/raccourci_projet\n\n# V\u00e9rifier les liens symboliques\nls -l\n\n# Afficher la cible d'un lien\nreadlink raccourci.txt\n</code></pre> <p>L'option <code>-s</code> indique la cr\u00e9ation d'un lien symbolique (soft link) plut\u00f4t qu'un lien physique (hard link).</p>"},{"location":"_projects/_formation-bash/bash-chap03/#examiner-et-parcourir-le-contenu-des-dossiers","title":"\ud83d\udd0d Examiner et Parcourir le Contenu des Dossiers","text":""},{"location":"_projects/_formation-bash/bash-chap03/#afficher-le-contenu-dun-fichier","title":"Afficher le Contenu d'un Fichier","text":"<p>Plusieurs commandes permettent de visualiser le contenu sans \u00e9dition :</p> Bash<pre><code># Afficher le fichier complet\ncat monfichier.txt\n\n# Afficher avec num\u00e9rotation des lignes\ncat -n monfichier.txt\n\n# Afficher le d\u00e9but d'un fichier (10 premi\u00e8res lignes par d\u00e9faut)\nhead monfichier.txt\n\n# Afficher les 20 premi\u00e8res lignes\nhead -n 20 monfichier.txt\n\n# Afficher la fin d'un fichier (10 derni\u00e8res lignes par d\u00e9faut)\ntail monfichier.txt\n\n# Afficher les 30 derni\u00e8res lignes\ntail -n 30 monfichier.txt\n\n# Afficher le fichier de mani\u00e8re pagin\u00e9e (espace pour avancer)\nless monfichier.txt\n\n# Afficher le contenu avec recherche interactive\nmore monfichier.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#rechercher-dans-les-fichiers","title":"Rechercher dans les Fichiers","text":"<p>La commande <code>grep</code> effectue des recherches de motifs dans les fichiers :</p> Bash<pre><code># Rechercher une cha\u00eene simple\ngrep \"motif\" monfichier.txt\n\n# Recherche insensible \u00e0 la casse\ngrep -i \"motif\" monfichier.txt\n\n# Afficher les lignes ne correspondant pas au motif\ngrep -v \"motif\" monfichier.txt\n\n# Afficher le num\u00e9ro de ligne des correspondances\ngrep -n \"motif\" monfichier.txt\n\n# Recherche r\u00e9cursive dans un r\u00e9pertoire\ngrep -r \"motif\" mon_dossier/\n\n# Utiliser des expressions r\u00e9guli\u00e8res\ngrep -E \"^motif.*test$\" monfichier.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#compter-les-elements","title":"Compter les \u00c9l\u00e9ments","text":"<p>La commande <code>wc</code> (Word Count) fournit des statistiques sur les fichiers :</p> Bash<pre><code># Compter les lignes\nwc -l monfichier.txt\n\n# Compter les mots\nwc -w monfichier.txt\n\n# Compter les caract\u00e8res\nwc -c monfichier.txt\n\n# Combiner les trois informations\nwc monfichier.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#lautocompletion-des-commandes-et-des-chemins","title":"\u2328\ufe0f L'Autocompl\u00e9tion des Commandes et des Chemins","text":""},{"location":"_projects/_formation-bash/bash-chap03/#utiliser-la-touche-tab","title":"Utiliser la Touche TAB","text":"<p>L'autocompl\u00e9tion repr\u00e9sente l'une des fonctionnalit\u00e9s les plus productives du shell Bash. La touche TAB compl\u00e8te automatiquement :</p> <ul> <li>Les noms de commandes</li> <li>Les chemins de fichiers et dossiers</li> <li>Les noms de variables</li> <li>Les noms d'options</li> </ul> Bash<pre><code># Taper le d\u00e9but et appuyer sur TAB\ncd /ho[TAB]  # Compl\u00e8te en: cd /home\n\n# Appuyer deux fois sur TAB pour voir toutes les possibilit\u00e9s\nls Doc[TAB][TAB]  # Affiche tous les fichiers commen\u00e7ant par \"Doc\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#comportement-avance-de-lautocompletion","title":"Comportement Avanc\u00e9 de l'Autocompl\u00e9tion","text":"Bash<pre><code># Compl\u00e9tion partielle avec plusieurs options\nls /etc/sys[TAB][TAB]  # Affiche sysctl, sysconfig, etc.\n\n# Compl\u00e9tion intelligente avec les chemins\nvim ~/.ba[TAB]  # Compl\u00e8te en: vim ~/.bashrc\n\n# Compl\u00e9tion dans les structures de script\nfor file in /usr/bin/[TAB]  # Liste tous les fichiers de /usr/bin\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#le-developpement-des-noms-de-fichiers-globbing","title":"\ud83d\udd04 Le D\u00e9veloppement des Noms de Fichiers (Globbing)","text":""},{"location":"_projects/_formation-bash/bash-chap03/#caracteres-generiques-de-base","title":"Caract\u00e8res G\u00e9n\u00e9riques de Base","text":"<p>Le d\u00e9veloppement des noms de fichiers (ou globbing) utilise des motifs pour s\u00e9lectionner plusieurs fichiers :</p> Bash<pre><code># L'ast\u00e9risque * : correspond \u00e0 z\u00e9ro ou plusieurs caract\u00e8res\nls *.txt         # Tous les fichiers avec extension .txt\nrm document*     # Supprime document, document1.txt, document_final.pdf, etc.\ncp /tmp/* .      # Copie tous les fichiers de /tmp\n\n# Le point d'interrogation ? : correspond \u00e0 exactement un caract\u00e8re\nls fichier?.txt  # Correspond \u00e0 fichier1.txt, fichierA.txt, etc.\nrm log_????.txt  # Supprime log_2023.txt, log_test.txt, etc.\n\n# Les crochets [] : correspondent \u00e0 un caract\u00e8re dans la plage\nls fichier[123].txt    # fichier1.txt, fichier2.txt, fichier3.txt\nls [a-z]*.txt          # Tous les .txt commen\u00e7ant par une lettre minuscule\nrm image[0-9].jpg      # Supprime image0.jpg \u00e0 image9.jpg\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#motifs-avances","title":"Motifs Avanc\u00e9s","text":"Bash<pre><code># Plages de caract\u00e8res avec exclusion\nls fichier[!0-9].txt   # Tous les fichiers sauf ceux se terminant par un chiffre\n\n# Motifs complexes combin\u00e9s\nls {*.txt,*.md,*.rst}  # Tous les fichiers .txt, .md ou .rst\n\n# D\u00e9veloppement d'accolade pour cr\u00e9er des ensembles\nmkdir projet_{alpha,beta,gamma}  # Cr\u00e9e projet_alpha, projet_beta, projet_gamma\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#comportement-du-globbing-en-scripts","title":"Comportement du Globbing en Scripts","text":"Bash<pre><code>#!/bin/bash\n\n# V\u00e9rifier si le globbing correspond \u00e0 des fichiers\nfor fichier in *.txt; do\n    if [ -f \"$fichier\" ]; then\n        echo \"Traitement de: $fichier\"\n    fi\ndone\n\n# G\u00e9rer le cas o\u00f9 le globbing ne correspond \u00e0 rien\nshopt -s nullglob  # Si aucune correspondance, ne passe rien\n\nfor image in /dossier/*.jpg; do\n    echo \"Image trouv\u00e9e: $image\"\ndone\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#supprimer-des-fichiers-et-des-dossiers","title":"\ud83d\uddd1\ufe0f Supprimer des Fichiers et des Dossiers","text":""},{"location":"_projects/_formation-bash/bash-chap03/#supprimer-des-fichiers","title":"Supprimer des Fichiers","text":"<p>La commande <code>rm</code> (Remove) supprime d\u00e9finitivement des fichiers.[1] Cette op\u00e9ration ne peut pas \u00eatre annul\u00e9e, contrairement \u00e0 la corbeille des interfaces graphiques.</p> Bash<pre><code># Supprimer un fichier simple\nrm monfichier.txt\n\n# Supprimer plusieurs fichiers\nrm fichier1.txt fichier2.txt fichier3.txt\n\n# Supprimer avec un motif (utiliser avec prudence!)\nrm *.log\n\n# Supprimer avec confirmation interactive\nrm -i fichier.txt\n\n# Forcer la suppression sans confirmation\nrm -f monfichier.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#supprimer-des-dossiers","title":"Supprimer des Dossiers","text":"Bash<pre><code># Supprimer un r\u00e9pertoire vide\nrmdir monDossierVide\n\n# Supprimer un r\u00e9pertoire et tout son contenu (r\u00e9cursif)\nrm -r monDossierAvecContenu\n\n# Supprimer r\u00e9cursivement avec confirmation\nrm -ri monDossierAvecContenu\n\n# Forcer la suppression r\u00e9cursive\nrm -rf monDossier\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#bonnes-pratiques-de-suppression","title":"Bonnes Pratiques de Suppression","text":"Bash<pre><code># V\u00e9rifier avant de supprimer\nls *.tmp  # V\u00e9rifier les fichiers avant suppression\nrm *.tmp\n\n# Utiliser -i pour les op\u00e9rations critiques\nrm -i /etc/*.conf\n\n# En script, v\u00e9rifier l'existence\nif [ -f \"$fichier\" ]; then\n    rm \"$fichier\"\n    echo \"Fichier supprim\u00e9\"\nfi\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#copier-et-deplacer-des-fichiers-et-des-dossiers","title":"\ud83d\udcc2 Copier et D\u00e9placer des Fichiers et des Dossiers","text":""},{"location":"_projects/_formation-bash/bash-chap03/#copier-des-fichiers","title":"Copier des Fichiers","text":"<p>La commande <code>cp</code> (Copy) cr\u00e9e une copie d'un fichier ou d'un r\u00e9pertoire.[1]</p> Bash<pre><code># Copie simple d'un fichier\ncp source.txt destination.txt\n\n# Copier vers un r\u00e9pertoire\ncp monfichier.txt /home/utilisateur/Documents/\n\n# Copier plusieurs fichiers\ncp fichier1.txt fichier2.txt fichier3.txt /destination/\n\n# Copier un r\u00e9pertoire entier et son contenu\ncp -r monDossier/ copie_monDossier/\n\n# Copier en pr\u00e9servant les attributs (permissions, propri\u00e9taire)\ncp -p source.txt destination.txt\n\n# Copier de mani\u00e8re interactive (confirmation avant \u00e9crasement)\ncp -i source.txt destination.txt\n\n# Copier r\u00e9cursivement avec verbosit\u00e9\ncp -rv monDossier/ /destination/\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#deplacer-et-renommer-des-fichiers","title":"D\u00e9placer et Renommer des Fichiers","text":"<p>La commande <code>mv</code> (Move) d\u00e9place ou renomme des fichiers et dossiers.[1]</p> Bash<pre><code># Renommer un fichier\nmv ancien_nom.txt nouveau_nom.txt\n\n# D\u00e9placer un fichier vers un autre r\u00e9pertoire\nmv monfichier.txt /home/utilisateur/Documents/\n\n# D\u00e9placer et renommer simultan\u00e9ment\nmv /dossier1/ancien_nom.txt /dossier2/nouveau_nom.txt\n\n# D\u00e9placer plusieurs fichiers\nmv fichier1.txt fichier2.txt fichier3.txt /destination/\n\n# D\u00e9placer un r\u00e9pertoire complet\nmv ancien_dossier/ nouveau_dossier/\n\n# D\u00e9placer avec confirmation interactive\nmv -i source.txt destination.txt\n\n# Forcer le d\u00e9placement sans confirmation\nmv -f source.txt destination.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#differences-entre-cp-et-mv","title":"Diff\u00e9rences entre <code>cp</code> et <code>mv</code>","text":"Aspect <code>cp</code> <code>mv</code> Op\u00e9ration Cr\u00e9e une copie D\u00e9place/renomme Fichier original Conserv\u00e9 Supprim\u00e9 Utilisation disque Augmente Reste identique Entre filesystems Fonctionne Peut \u00eatre lent Syntaxe <code>cp source dest</code> <code>mv source dest</code>"},{"location":"_projects/_formation-bash/bash-chap03/#gestion-avancee-des-liens-et-references","title":"\ud83d\udd17 Gestion Avanc\u00e9e des Liens et R\u00e9f\u00e9rences","text":""},{"location":"_projects/_formation-bash/bash-chap03/#liens-symboliques-versus-liens-physiques","title":"Liens Symboliques versus Liens Physiques","text":"Bash<pre><code># Cr\u00e9er un lien symbolique (soft link)\nln -s /chemin/vers/fichier lien_symbolique\n\n# Cr\u00e9er un lien physique (hard link)\nln /chemin/vers/fichier lien_physique\n\n# Afficher le type de lien et sa cible\nls -li\n\n# V\u00e9rifier o\u00f9 pointe un lien symbolique\nreadlink lien_symbolique\n</code></pre> <p>Les liens symboliques fonctionnent comme des raccourcis, tandis que les liens physiques cr\u00e9ent une r\u00e9f\u00e9rence suppl\u00e9mentaire au m\u00eame fichier.</p>"},{"location":"_projects/_formation-bash/bash-chap03/#cas-dusage-pratiques","title":"Cas d'Usage Pratiques","text":"Bash<pre><code># Cr\u00e9er un alias permanent pour un dossier fr\u00e9quemment utilis\u00e9\nln -s /var/www/html/ ~/www\n\n# Maintenir la compatibilit\u00e9 avec les anciens chemins\nln -s /usr/bin/nouveau_binaire /usr/bin/ancien_binaire\n\n# Organiser les fichiers config en un seul endroit\nln -s /etc/nginx/nginx.conf ~/.config/nginx.conf\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#scripts-bash-pour-la-gestion-de-fichiers","title":"\ud83d\ude80 Scripts Bash pour la Gestion de Fichiers","text":""},{"location":"_projects/_formation-bash/bash-chap03/#script-de-navigation-et-listing","title":"Script de Navigation et Listing","text":"Bash<pre><code>#!/bin/bash\n\n# Ce script affiche la structure compl\u00e8te d'un r\u00e9pertoire avec des d\u00e9tails\n\necho \"=== Navigation et Listing des Fichiers ===\"\necho \"R\u00e9pertoire courant: $(pwd)\"\necho \"\"\n\n# Afficher la taille totale du r\u00e9pertoire\necho \"Taille totale: $(du -sh . | cut -f1)\"\necho \"\"\n\n# Lister les fichiers avec d\u00e9tails\necho \"Fichiers et dossiers:\"\nls -lhS  # Trier par taille d\u00e9croissante\n\n# Compter les \u00e9l\u00e9ments\necho \"\"\necho \"Statistiques:\"\necho \"Nombre total d'\u00e9l\u00e9ments: $(ls -1 | wc -l)\"\necho \"Nombre de fichiers: $(find . -maxdepth 1 -type f | wc -l)\"\necho \"Nombre de r\u00e9pertoires: $(find . -maxdepth 1 -type d | wc -l)\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#script-de-sauvegarde-avec-globbing","title":"Script de Sauvegarde avec Globbing","text":"Bash<pre><code>#!/bin/bash\n\n# Ce script effectue une sauvegarde s\u00e9lective des fichiers importants\n\nSOURCE_DIR=\"$HOME/Documents\"\nBACKUP_DIR=\"$HOME/Backups\"\nDATE=$(date +%Y%m%d_%H%M%S)\n\n# Cr\u00e9er le r\u00e9pertoire de sauvegarde s'il n'existe pas\nmkdir -p \"$BACKUP_DIR\"\n\n# Copier les fichiers importants\necho \"D\u00e9but de la sauvegarde...\"\n\nfor fichier in \"$SOURCE_DIR\"/*.{txt,pdf,doc,docx}; do\n    if [ -f \"$fichier\" ]; then\n        cp \"$fichier\" \"$BACKUP_DIR/backup_${DATE}_$(basename \"$fichier\")\"\n        echo \"\u2713 Sauvegard\u00e9: $(basename \"$fichier\")\"\n    fi\ndone\n\necho \"Sauvegarde termin\u00e9e dans: $BACKUP_DIR\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#script-de-nettoyage-de-fichiers-temporaires","title":"Script de Nettoyage de Fichiers Temporaires","text":"Bash<pre><code>#!/bin/bash\n\n# Ce script supprime les fichiers temporaires avec confirmation\n\nTMP_DIRS=(\"/tmp\" \"$HOME/.cache\" \"$HOME/.local/share/Trash\")\n\nfor dossier in \"${TMP_DIRS[@]}\"; do\n    if [ -d \"$dossier\" ]; then\n        echo \"V\u00e9rification de: $dossier\"\n\n        # Afficher les fichiers \u00e0 supprimer\n        find \"$dossier\" -type f -mtime +30 -exec ls -lh {} \\;\n\n        # Demander confirmation\n        read -p \"Supprimer ces fichiers? (o/n): \" reponse\n\n        if [ \"$reponse\" = \"o\" ]; then\n            find \"$dossier\" -type f -mtime +30 -delete\n            echo \"\u2713 Fichiers supprim\u00e9s\"\n        fi\n    fi\ndone\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#script-de-recherche-avancee","title":"Script de Recherche Avanc\u00e9e","text":"Bash<pre><code>#!/bin/bash\n\n# Ce script effectue des recherches sophistiqu\u00e9es dans le syst\u00e8me de fichiers\n\necho \"=== Outil de Recherche Avanc\u00e9e ===\"\necho \"\"\n\n# Rechercher les fichiers volumineux\necho \"Les 10 fichiers les plus volumineux:\"\nfind / -type f -exec ls -lh {} + 2&gt;/dev/null | sort -k5 -hr | head -10\necho \"\"\n\n# Rechercher les fichiers r\u00e9cemment modifi\u00e9s\necho \"Fichiers modifi\u00e9s dans les 24 derni\u00e8res heures:\"\nfind . -type f -mtime -1 -exec ls -lh {} \\;\necho \"\"\n\n# Rechercher les fichiers sans extension\necho \"Fichiers sans extension:\"\nfind . -type f ! -name \"*.*\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#structures-de-fichiers-et-permissions","title":"\ud83d\udccb Structures de Fichiers et Permissions","text":""},{"location":"_projects/_formation-bash/bash-chap03/#comprendre-les-permissions","title":"Comprendre les Permissions","text":"<p>Les permissions Linux utilisent un syst\u00e8me \u00e0 trois niveaux : propri\u00e9taire, groupe et autres. Chaque niveau dispose de trois droits : lecture \u00ae, \u00e9criture (w), ex\u00e9cution (x).</p> Bash<pre><code># Afficher les permissions d\u00e9taill\u00e9es\nls -l monfichier.txt\n\n# Exemple de sortie: -rwxr-xr-x\n# -     rwx      r-x      r-x\n# type  proprio  groupe   autres\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#modifier-les-permissions","title":"Modifier les Permissions","text":"Bash<pre><code># Ajouter permission d'ex\u00e9cution pour le propri\u00e9taire\nchmod u+x script.sh\n\n# Retirer la permission de lecture pour les autres\nchmod o-r monfichier.txt\n\n# D\u00e9finir les permissions pr\u00e9cis\u00e9ment (755 = rwxr-xr-x)\nchmod 755 monscript.sh\n\n# Appliquer les permissions r\u00e9cursivement\nchmod -R 755 mon_dossier/\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#changer-le-proprietaire","title":"Changer le Propri\u00e9taire","text":"Bash<pre><code># Changer le propri\u00e9taire d'un fichier\nchown nouvel_utilisateur monfichier.txt\n\n# Changer le propri\u00e9taire et le groupe\nchown utilisateur:groupe monfichier.txt\n\n# Appliquer r\u00e9cursivement \u00e0 un dossier\nchown -R utilisateur:groupe mon_dossier/\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap03/#tableaux-recapitulatifs-des-commandes","title":"\ud83d\udcca Tableaux R\u00e9capitulatifs des Commandes","text":""},{"location":"_projects/_formation-bash/bash-chap03/#commandes-essentielles-de-navigation-et-listing","title":"Commandes Essentielles de Navigation et Listing","text":"Commande Fonction Exemple <code>pwd</code> Afficher le r\u00e9pertoire courant <code>pwd</code> <code>cd</code> Changer de r\u00e9pertoire <code>cd /home/utilisateur</code> <code>ls</code> Lister les fichiers <code>ls -lah</code> <code>find</code> Rechercher des fichiers <code>find . -name \"*.txt\"</code> <code>tree</code> Afficher l'arborescence <code>tree mon_dossier/</code>"},{"location":"_projects/_formation-bash/bash-chap03/#commandes-de-creation","title":"Commandes de Cr\u00e9ation","text":"Commande Fonction Exemple <code>touch</code> Cr\u00e9er un fichier vide <code>touch nouveau.txt</code> <code>mkdir</code> Cr\u00e9er un r\u00e9pertoire <code>mkdir -p dossier/sous/dossier</code> <code>cp</code> Copier des fichiers <code>cp source.txt dest.txt</code> <code>mv</code> D\u00e9placer/renommer <code>mv ancien.txt nouveau.txt</code> <code>ln -s</code> Cr\u00e9er un lien symbolique <code>ln -s cible lien</code>"},{"location":"_projects/_formation-bash/bash-chap03/#commandes-de-suppression","title":"Commandes de Suppression","text":"Commande Fonction Exemple <code>rm</code> Supprimer des fichiers <code>rm monfichier.txt</code> <code>rm -r</code> Supprimer r\u00e9cursivement <code>rm -r mon_dossier/</code> <code>rmdir</code> Supprimer dossier vide <code>rmdir dossier_vide</code> <code>shred</code> Supprimer s\u00e9curis\u00e9 <code>shred -vfz fichier.txt</code>"},{"location":"_projects/_formation-bash/bash-chap03/#commandes-de-visualisation","title":"Commandes de Visualisation","text":"Commande Fonction Exemple <code>cat</code> Afficher le contenu <code>cat monfichier.txt</code> <code>less</code> Afficher pagin\u00e9 <code>less monfichier.txt</code> <code>head</code> Premiers lignes <code>head -20 monfichier.txt</code> <code>tail</code> Derni\u00e8res lignes <code>tail -20 monfichier.txt</code> <code>grep</code> Rechercher du texte <code>grep \"motif\" fichier.txt</code>"},{"location":"_projects/_formation-bash/bash-chap03/#chemin-dapprentissage-progressif","title":"\ud83c\udf93 Chemin d'Apprentissage Progressif","text":""},{"location":"_projects/_formation-bash/bash-chap03/#niveau-1-fondamentaux","title":"Niveau 1 : Fondamentaux","text":"<p>Au d\u00e9part, il est essentiel de ma\u00eetriser la navigation basique et la compr\u00e9hension de l'arborescence Linux. L'apprenant doit pratiquer r\u00e9guli\u00e8rement :</p> <ol> <li>Se familiariser avec <code>pwd</code> et <code>ls</code> pour comprendre sa position actuelle</li> <li>Naviguer avec <code>cd</code> entre diff\u00e9rents r\u00e9pertoires</li> <li>Cr\u00e9er des fichiers et dossiers simples avec <code>touch</code> et <code>mkdir</code></li> <li>Utiliser <code>cat</code> pour visualiser le contenu des fichiers</li> </ol> <p>Cette phase prend typiquement 2 \u00e0 3 semaines de pratique r\u00e9guli\u00e8re.</p>"},{"location":"_projects/_formation-bash/bash-chap03/#niveau-2-operations-courantes","title":"Niveau 2 : Op\u00e9rations Courantes","text":"<p>Une fois les bases ma\u00eetris\u00e9es, il faut progresser vers les op\u00e9rations plus complexes :</p> <ol> <li>Copier, d\u00e9placer et renommer des fichiers avec <code>cp</code> et <code>mv</code></li> <li>Comprendre les chemins absolus et relatifs profond\u00e9ment</li> <li>Utiliser <code>grep</code> pour rechercher des contenus sp\u00e9cifiques</li> <li>Ma\u00eetriser l'autocompl\u00e9tion pour am\u00e9liorer la productivit\u00e9</li> </ol> <p>Cette phase requiert environ 3 \u00e0 4 semaines d'entra\u00eenement progressif.</p>"},{"location":"_projects/_formation-bash/bash-chap03/#niveau-3-gestion-avancee","title":"Niveau 3 : Gestion Avanc\u00e9e","text":"<p>Apr\u00e8s avoir consolid\u00e9 les op\u00e9rations courantes, explorer les fonctionnalit\u00e9s avanc\u00e9es :</p> <ol> <li>Utiliser le globbing avec les caract\u00e8res g\u00e9n\u00e9riques pour manipuler plusieurs fichiers</li> <li>Cr\u00e9er et g\u00e9rer les liens symboliques et les liens physiques</li> <li>Comprendre les permissions et la gestion des droits d'acc\u00e8s</li> <li>Combiner les commandes avec des pipes pour des op\u00e9rations complexes</li> </ol> <p>Cette \u00e9tape s'\u00e9tend sur 4 \u00e0 6 semaines avec des projets pratiques.</p>"},{"location":"_projects/_formation-bash/bash-chap03/#niveau-4-automation-avec-scripts","title":"Niveau 4 : Automation avec Scripts","text":"<p>Enfin, int\u00e9grer la gestion des fichiers dans des scripts Bash pour l'automatisation :</p> <ol> <li>\u00c9crire des scripts utilisant les boucles <code>for</code> pour traiter plusieurs fichiers</li> <li>Impl\u00e9menter des conditions <code>if</code> pour v\u00e9rifier l'existence de fichiers</li> <li>Cr\u00e9er des fonctions r\u00e9utilisables pour des op\u00e9rations courantes</li> <li>G\u00e9rer les erreurs et les cas limites dans les scripts</li> </ol> <p>Cette phase demande 6 \u00e0 8 semaines de d\u00e9veloppement progressif.</p>"},{"location":"_projects/_formation-bash/bash-chap03/#pratiques-recommandees-et-pieges-a-eviter","title":"\ud83d\udee0\ufe0f Pratiques Recommand\u00e9es et Pi\u00e8ges \u00e0 \u00c9viter","text":""},{"location":"_projects/_formation-bash/bash-chap03/#bonnes-pratiques","title":"Bonnes Pratiques","text":"<ul> <li>Toujours utiliser <code>-i</code> lors de suppressions massives pour confirmer chaque op\u00e9ration</li> <li>Maintenir des sauvegardes r\u00e9guli\u00e8res avant d'effectuer des op\u00e9rations critiques</li> <li>Utiliser des chemins entre guillemets quand les noms contiennent des espaces</li> <li>V\u00e9rifier le contenu avant de supprimer avec <code>ls</code> ou <code>find</code></li> <li>Exploiter l'autocompl\u00e9tion pour \u00e9viter les erreurs de frappe</li> <li>Utiliser des variables dans les scripts pour am\u00e9liorer la flexibilit\u00e9</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap03/#pieges-a-eviter","title":"Pi\u00e8ges \u00e0 \u00c9viter","text":"<ul> <li>Ex\u00e9cuter <code>rm -rf /</code> accidentellement sur le r\u00e9pertoire racine (destruction du syst\u00e8me)</li> <li>Utiliser des chemins non cit\u00e9s quand les noms contiennent des espaces sp\u00e9ciaux</li> <li>N\u00e9gliger de tester les scripts avant de les ex\u00e9cuter sur des donn\u00e9es importantes</li> <li>Oublier de v\u00e9rifier les droits d'acc\u00e8s avant de modifier des fichiers syst\u00e8me</li> <li>Ignorer les messages d'erreur qui pourraient indiquer des probl\u00e8mes s\u00e9rieux</li> <li>Confondre les caract\u00e8res g\u00e9n\u00e9riques et les expressions r\u00e9guli\u00e8res</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap03/#resume-des-points-cles","title":"\ud83d\udccc R\u00e9sum\u00e9 des Points Cl\u00e9s","text":"<p>La ma\u00eetrise du syst\u00e8me de fichiers sous Linux constitue un pr\u00e9requis indispensable pour toute personne travaillant avec Bash. Les concepts fondamentaux de navigation, cr\u00e9ation, copie, d\u00e9placement et suppression de fichiers forment la base de toute interaction avec le syst\u00e8me d'exploitation.</p> <p>L'apprentissage progressif, commen\u00e7ant par les commandes simples et \u00e9voluant vers des op\u00e9rations complexes et automatis\u00e9es, permet de d\u00e9velopper une compr\u00e9hension profonde du fonctionnement du syst\u00e8me. La pratique r\u00e9guli\u00e8re, combin\u00e9e \u00e0 une attention particuli\u00e8re aux bonnes pratiques de s\u00e9curit\u00e9, transforme rapidement un utilisateur novice en administrateur syst\u00e8me comp\u00e9tent et en d\u00e9veloppeur de scripts Bash efficace.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-bash/bash-chap04/","title":"Citations","text":"<ul> <li>https://linuxconfig.org/introduction-to-bash-shell-redirections</li> <li>https://www.youtube.com/watch?v=DwfncFCrkHc</li> <li>https://labex.io/tutorials/linux-how-to-manage-xargs-output-redirection-430971</li> <li>https://runcloud.io/blog/pipes-vs-xargs-writing-bash-scripts-in-linux</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap04/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 287</li> <li>completion_tokens: 5670</li> <li>total_tokens: 5957</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.085, 'request_cost': 0.006, 'total_cost': 0.092}</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap04/#content","title":"Content","text":""},{"location":"_projects/_formation-bash/bash-chap04/#manipuler-les-flux-standards-sous-linux-et-bash","title":"Manipuler les flux standards sous Linux et Bash","text":""},{"location":"_projects/_formation-bash/bash-chap04/#introduction-aux-flux-standards","title":"Introduction aux flux standards","text":"<p>Avant d'aborder en d\u00e9tail la manipulation des flux standards, il est essentiel de comprendre comment les processus Linux communiquent avec l'environnement. Chaque processus lanc\u00e9 dispose par d\u00e9faut de trois canaux de communication standardis\u00e9s, appel\u00e9s descripteurs de fichiers standards[1][2]. Ces canaux permettent au programme de recevoir des donn\u00e9es d'entr\u00e9e et de g\u00e9n\u00e9rer des donn\u00e9es de sortie.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#les-trois-descripteurs-de-fichiers","title":"Les trois descripteurs de fichiers","text":"Descripteur Num\u00e9ro Symbole D\u00e9signation Utilisation stdin 0 <code>&lt;</code> Entr\u00e9e standard Re\u00e7oit les donn\u00e9es entrantes stdout 1 <code>&gt;</code> Sortie standard Affiche les r\u00e9sultats normaux stderr 2 <code>2&gt;</code> Erreur standard Affiche les messages d'erreur <p>Ces trois descripteurs forment la base de toute manipulation de flux sous Bash. La compr\u00e9hension de leur fonctionnement est fondamentale pour exploiter pleinement les capacit\u00e9s du shell.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#les-flux-standards-entrees-et-sorties-des-processus","title":"Les flux standards : entr\u00e9es et sorties des processus","text":""},{"location":"_projects/_formation-bash/bash-chap04/#fonctionnement-des-flux-standards","title":"Fonctionnement des flux standards","text":"<p>Stdin (descripteur 0) repr\u00e9sente l'entr\u00e9e standard d'un processus. Par d\u00e9faut, il est connect\u00e9 au clavier, permettant \u00e0 l'utilisateur de fournir des donn\u00e9es directement au programme. Cependant, stdin peut \u00eatre redirig\u00e9 depuis un fichier ou depuis la sortie d'une autre commande[1][2].</p> <p>Stdout (descripteur 1) repr\u00e9sente la sortie standard d'un processus. Il s'agit du flux utilis\u00e9 pour afficher les r\u00e9sultats normaux de l'ex\u00e9cution. Par d\u00e9faut, stdout est connect\u00e9 \u00e0 l'\u00e9cran du terminal, mais il peut \u00eatre redirig\u00e9 vers un fichier ou vers une autre commande[1].</p> <p>Stderr (descripteur 2) repr\u00e9sente le flux d'erreur standard. Contrairement \u00e0 stdout, stderr est utilis\u00e9 exclusivement pour les messages d'erreur. L'avantage de disposer de deux flux s\u00e9par\u00e9s permet de traiter diff\u00e9remment les r\u00e9sultats normaux et les erreurs[1][2].</p>"},{"location":"_projects/_formation-bash/bash-chap04/#illustration-conceptuelle-des-flux","title":"Illustration conceptuelle des flux","text":"Text Only<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502        Processus / Commande         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502  stdin (0) \u2190\u2500\u2500 Clavier              \u2502\n\u2502  stdout (1) \u2500\u2500\u2192 \u00c9cran               \u2502\n\u2502  stderr (2) \u2500\u2500\u2192 \u00c9cran               \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap04/#exemple-pratique-observation-des-flux","title":"Exemple pratique : observation des flux","text":"<p>Lors de l'ex\u00e9cution d'une commande <code>ls</code>, le comportement des flux peut \u00eatre observ\u00e9 :</p> Bash<pre><code>ls /home /dossier-inexistant\n</code></pre> <p>Dans cet exemple, <code>ls /home</code> g\u00e9n\u00e8re un r\u00e9sultat normal (stock\u00e9 dans stdout), tandis que <code>ls /dossier-inexistant</code> g\u00e9n\u00e8re un message d'erreur (stock\u00e9 dans stderr). Ces deux flux s'affichent tous les deux \u00e0 l'\u00e9cran, mais ils proviennent de canaux diff\u00e9rents.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#les-flux-de-redirection","title":"Les flux de redirection","text":""},{"location":"_projects/_formation-bash/bash-chap04/#redirection-de-stdout-vers-un-fichier","title":"Redirection de stdout vers un fichier","text":"<p>La redirection de la sortie standard vers un fichier s'effectue avec l'op\u00e9rateur <code>&gt;</code>[1]. Cet op\u00e9rateur \u00e9crit le contenu de stdout dans le fichier sp\u00e9cifi\u00e9.</p> Bash<pre><code>ls -l &gt; output.txt\n</code></pre> <p>Si le fichier n'existe pas, il est cr\u00e9\u00e9. S'il existe d\u00e9j\u00e0, son contenu est enti\u00e8rement remplac\u00e9 par le nouveau contenu. Cette op\u00e9ration s'appelle la troncature.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#ajout-a-un-fichier-existant-avec","title":"Ajout \u00e0 un fichier existant avec &gt;&gt;","text":"<p>Pour ajouter du contenu \u00e0 la fin d'un fichier sans \u00e9craser le contenu existant, l'op\u00e9rateur <code>&gt;&gt;</code> est utilis\u00e9[1] :</p> Bash<pre><code>ls -l &gt;&gt; output.txt\n</code></pre> <p>\u00c0 chaque ex\u00e9cution, le r\u00e9sultat de la commande est ajout\u00e9 \u00e0 la fin du fichier.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#redirection-de-stderr-vers-un-fichier","title":"Redirection de stderr vers un fichier","text":"<p>La redirection des erreurs vers un fichier s'effectue avec l'op\u00e9rateur <code>2&gt;</code>[1][2] :</p> Bash<pre><code>ls /dossier-inexistant 2&gt; error.txt\n</code></pre> <p>Seules les erreurs sont redirig\u00e9es vers error.txt. Les r\u00e9sultats normaux (stdout) s'affichent toujours \u00e0 l'\u00e9cran.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#redirection-simultanee-de-stdout-et-stderr","title":"Redirection simultan\u00e9e de stdout et stderr","text":"<p>Souvent, l'utilisateur souhaite capturer \u00e0 la fois les r\u00e9sultats normaux et les erreurs dans le m\u00eame fichier. Deux syntaxes permettent d'accomplir cette t\u00e2che[1] :</p> <p>Syntaxe classique (compatible avec les anciennes versions de Bash) :</p> Bash<pre><code>ls -l &gt; output.txt 2&gt;&amp;1\n</code></pre> <p>Cette commande redirige d'abord stdout vers output.txt, puis redirige stderr (2) vers stdout (1). L'ordre des op\u00e9rations est important : <code>2&gt;&amp;1</code> signifie \"redirige le descripteur 2 vers la destination du descripteur 1\".</p> <p>Syntaxe moderne (Bash 4.0+) :</p> Bash<pre><code>ls -l &amp;&gt; output.txt\n</code></pre> <p>L'op\u00e9rateur <code>&amp;&gt;</code> combine la redirection de stdout et stderr en une seule op\u00e9ration, ce qui est plus lisible.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#tableau-comparatif-des-redirections-stdout","title":"Tableau comparatif des redirections stdout","text":"Op\u00e9rateur Action Exemple <code>&gt;</code> Rediriger stdout (remplace) <code>echo \"texte\" &gt; fichier.txt</code> <code>&gt;&gt;</code> Rediriger stdout (ajoute) <code>echo \"texte\" &gt;&gt; fichier.txt</code> <code>2&gt;</code> Rediriger stderr (remplace) <code>commande 2&gt; erreurs.txt</code> <code>2&gt;&gt;</code> Rediriger stderr (ajoute) <code>commande 2&gt;&gt; erreurs.txt</code> <code>&amp;&gt;</code> ou <code>&gt; fichier 2&gt;&amp;1</code> Rediriger stdout et stderr <code>commande &amp;&gt; tout.txt</code>"},{"location":"_projects/_formation-bash/bash-chap04/#redirection-de-stdin-depuis-un-fichier","title":"Redirection de stdin depuis un fichier","text":"<p>La redirection de l'entr\u00e9e standard depuis un fichier s'effectue avec l'op\u00e9rateur <code>&lt;</code>[1] :</p> Bash<pre><code>tr &lt; output.txt t d\n</code></pre> <p>Dans cet exemple, le contenu du fichier output.txt est fourni comme entr\u00e9e standard \u00e0 la commande <code>tr</code>. La commande <code>tr</code> lit le contenu du fichier et effectue les remplacements demand\u00e9s.</p> Bash<pre><code>echo 'goot tay!' &gt; output.txt\ntr &lt; output.txt t d\n</code></pre> <p>R\u00e9sultat : <code>good day!</code></p> <p>La commande <code>tr</code> a re\u00e7u le contenu du fichier via stdin et a remplac\u00e9 toutes les occurrences de 't' par 'd'.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#redirection-vers-devnull","title":"Redirection vers /dev/null","text":"<p>Le fichier sp\u00e9cial <code>/dev/null</code> est un fichier de destination qui supprime silencieusement tout ce qui y est \u00e9crit[1]. Il est utile pour ignorer les donn\u00e9es non d\u00e9sir\u00e9es :</p> Bash<pre><code>ls /dossier-inexistant 2&gt; /dev/null\n</code></pre> <p>Les erreurs sont redirig\u00e9es vers /dev/null et disparaissent compl\u00e8tement.</p> Bash<pre><code>commande &gt; /dev/null 2&gt;&amp;1\n</code></pre> <p>Cette commande supprime \u00e0 la fois stdout et stderr, ce qui permet d'ex\u00e9cuter une commande sans afficher aucune sortie.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#branchement-de-commandes-avec-les-pipes","title":"Branchement de commandes avec les pipes","text":""},{"location":"_projects/_formation-bash/bash-chap04/#concept-fondamental-du-pipe","title":"Concept fondamental du pipe","text":"<p>Le pipe, symbolis\u00e9 par le caract\u00e8re <code>|</code>, permet de connecter deux commandes en redirigeant la sortie standard d'une commande vers l'entr\u00e9e standard d'une autre[1][2]. Cela cr\u00e9e une sorte de \"conduite\" \u00e0 travers laquelle les donn\u00e9es circulent.</p> Text Only<pre><code>commande1 | commande2\n</code></pre> <p>La stdout de commande1 devient la stdin de commande2.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#fonctionnement-des-pipes","title":"Fonctionnement des pipes","text":"Text Only<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            Commande 1 (ls -l)                \u2502\n\u2502  stdout: liste de fichiers                   \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n           \u2502 (pipe)\n           \u25bc\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502            Commande 2 (grep)                 \u2502\n\u2502  stdin: re\u00e7oit la sortie de ls               \u2502\n\u2502  stdout: fichiers filtr\u00e9s                    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap04/#exemples-pratiques-de-pipes","title":"Exemples pratiques de pipes","text":"<p>Filtrer la sortie d'une commande :</p> Bash<pre><code>ls -l | grep \".txt\"\n</code></pre> <p>Cette commande liste les fichiers du r\u00e9pertoire courant et filtre uniquement ceux contenant \".txt\" dans leur nom.</p> <p>Compter le nombre de lignes :</p> Bash<pre><code>ls -l | wc -l\n</code></pre> <p>Cette commande affiche le nombre de fichiers dans le r\u00e9pertoire courant.</p> <p>Cha\u00eenage de plusieurs pipes :</p> Bash<pre><code>cat /var/log/syslog | grep \"error\" | wc -l\n</code></pre> <p>Cette commande affiche le nombre de lignes contenant \"error\" dans le fichier syslog.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#difference-entre-pipe-et-xargs","title":"Diff\u00e9rence entre pipe et xargs","text":"<p>Bien que similaires en apparence, le pipe et la commande <code>xargs</code> fonctionnent diff\u00e9remment[4] :</p> <ul> <li>Le pipe redirige stdout vers stdin</li> <li><code>xargs</code> cr\u00e9e une liste de toutes les donn\u00e9es et les passe comme arguments de ligne de commande \u00e0 la commande sp\u00e9cifi\u00e9e</li> </ul> Bash<pre><code>find . -name \"*temp*\" | xargs rm\n</code></pre> <p>Cette commande trouve tous les fichiers contenant \"temp\" dans leur nom et les passe comme arguments \u00e0 la commande <code>rm</code> pour les supprimer[4].</p> Bash<pre><code>ls | xargs echo\n</code></pre> <p>Cette commande affiche tous les fichiers du r\u00e9pertoire courant en tant qu'arguments pour <code>echo</code>. Alors que <code>ls | echo</code> ne produirait aucun r\u00e9sultat (car <code>echo</code> ne lit pas stdin), <code>ls | xargs echo</code> fonctionne correctement[4].</p>"},{"location":"_projects/_formation-bash/bash-chap04/#tableau-comparatif-pipes-vs-arguments","title":"Tableau comparatif : pipes vs arguments","text":"Aspect Pipe <code>\\|</code> xargs Transite par stdin Arguments de ligne de commande Efficacit\u00e9 Plus efficace Peut cr\u00e9er des interm\u00e9diaires Commandes compatibles Toutes les commandes lisant stdin Commandes acceptant des arguments Cas d'usage Traitement de flux continus Passage massif d'arguments Exemple <code>ls \\| grep</code> <code>ls \\| xargs echo</code>"},{"location":"_projects/_formation-bash/bash-chap04/#les-commandes-tee-et-xargs","title":"Les commandes tee et xargs","text":""},{"location":"_projects/_formation-bash/bash-chap04/#la-commande-tee","title":"La commande tee","text":"<p>La commande <code>tee</code> est un outil puissant qui cr\u00e9e une \"T\" dans le pipeline[1]. Elle lit depuis stdin et redirige simultan\u00e9ment les donn\u00e9es vers stdout et vers un fichier. Cela permet de visualiser le r\u00e9sultat \u00e0 l'\u00e9cran tout en le sauvegardant dans un fichier[1].</p> <p>Syntaxe basique :</p> Bash<pre><code>commande | tee fichier.txt\n</code></pre> <p>Exemple pratique :</p> Bash<pre><code>echo 'goot tay!' | tr t d | tee output.txt | cut -f 1 -d ' '\n</code></pre> <p>R\u00e9sultat affich\u00e9 \u00e0 l'\u00e9cran : <code>good</code></p> <p>Contenu du fichier output.txt : <code>good day!</code></p> <p>Dans cet exemple, <code>tee</code> capture la sortie interm\u00e9diaire (<code>good day!</code>) et la sauvegarde dans output.txt, tout en la passant \u00e0 la commande <code>cut</code> pour l'affichage final.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#tee-avec-mode-ajout","title":"tee avec mode ajout","text":"<p>Par d\u00e9faut, <code>tee</code> remplace le contenu du fichier. Pour ajouter le contenu \u00e0 la fin du fichier, l'option <code>-a</code> (ou <code>--append</code>) est utilis\u00e9e[1] :</p> Bash<pre><code>echo \"ligne 1\" | tee -a output.txt\necho \"ligne 2\" | tee -a output.txt\n</code></pre> <p>R\u00e9sultat dans output.txt : Text Only<pre><code>ligne 1\nligne 2\n</code></pre></p>"},{"location":"_projects/_formation-bash/bash-chap04/#utilisation-de-tee-avec-les-privileges-root","title":"Utilisation de tee avec les privil\u00e8ges root","text":"<p><code>tee</code> est particuli\u00e8rement utile pour \u00e9crire dans des fichiers n\u00e9cessitant des privil\u00e8ges root. Une tentative na\u00efve \u00e9chouerait[1] :</p> Bash<pre><code>sudo echo \"linuxconfig.org\" &gt; protected.txt\n# Erreur : Permission denied\n</code></pre> <p>Pourquoi ? Parce que l'op\u00e9rateur de redirection <code>&gt;</code> est ex\u00e9cut\u00e9 par le shell de l'utilisateur courant, pas par <code>sudo</code>. La solution est d'utiliser <code>tee</code> avec <code>sudo</code>[1] :</p> Bash<pre><code>echo \"linuxconfig.org\" | sudo tee protected.txt &gt; /dev/null\n</code></pre> <p>Ici, <code>echo</code> s'ex\u00e9cute comme utilisateur normal, mais <code>sudo tee</code> effectue l'\u00e9criture avec les privil\u00e8ges root. Le <code>&gt; /dev/null</code> \u00e0 la fin supprime l'affichage de la sortie \u00e0 l'\u00e9cran.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#la-commande-xargs","title":"La commande xargs","text":"<p><code>xargs</code> est une commande qui convertit l'entr\u00e9e standard en arguments de ligne de commande[3][4]. Elle lit les donn\u00e9es depuis stdin et les utilise comme arguments pour ex\u00e9cuter une autre commande.</p> <p>Syntaxe basique :</p> Bash<pre><code>commande_source | xargs commande_cible\n</code></pre> <p>Exemple : supprimer des fichiers temporaires</p> Bash<pre><code>find . -name \"*temp*\" | xargs rm\n</code></pre> <p>Cette commande trouve tous les fichiers contenant \"temp\" et les passe comme arguments \u00e0 <code>rm</code> pour les supprimer[4].</p> <p>Exemple : afficher des noms de fichiers</p> Bash<pre><code>ls | xargs echo\n</code></pre> <p>Sans <code>xargs</code>, <code>ls | echo</code> n'afficherait rien car <code>echo</code> n'accepte pas d'entr\u00e9e depuis stdin. Avec <code>xargs</code>, les r\u00e9sultats de <code>ls</code> sont pass\u00e9s comme arguments \u00e0 <code>echo</code>[4].</p>"},{"location":"_projects/_formation-bash/bash-chap04/#avantages-et-limitations-de-xargs","title":"Avantages et limitations de xargs","text":"<p>Avantages : - Permet d'utiliser des commandes qui n'acceptent pas stdin - Peut optimiser l'ex\u00e9cution en regroupant les arguments - Offre un contr\u00f4le pr\u00e9cis sur la fa\u00e7on dont les arguments sont trait\u00e9s</p> <p>Limitations : - Peut g\u00e9n\u00e9rer des fichiers interm\u00e9diaires - Moins efficace que le pipe pour les volumes importants de donn\u00e9es - Peut \u00e9chouer si les arguments sont trop nombreux ou trop longs</p>"},{"location":"_projects/_formation-bash/bash-chap04/#comparaison-defficacite","title":"Comparaison d'efficacit\u00e9","text":"Crit\u00e8re Pipe xargs Efficacit\u00e9 globale \u2b50\u2b50\u2b50\u2b50\u2b50 Tr\u00e8s efficace \u2b50\u2b50\u2b50 Mod\u00e9r\u00e9e \u00c9l\u00e9gance du code \u2b50\u2b50\u2b50\u2b50\u2b50 \u00c9l\u00e9gant \u2b50\u2b50\u2b50\u2b50 Fonctionnel Compatibilit\u00e9 commandes \u2b50\u2b50\u2b50 Partielle \u2b50\u2b50\u2b50\u2b50\u2b50 Excellente Utilit\u00e9 pour gros volumes \u2b50\u2b50\u2b50\u2b50\u2b50 Optimale \u2b50\u2b50\u2b50 Acceptable"},{"location":"_projects/_formation-bash/bash-chap04/#les-enchainements-de-commandes","title":"Les encha\u00eenements de commandes","text":""},{"location":"_projects/_formation-bash/bash-chap04/#operateurs-denchainement","title":"Op\u00e9rateurs d'encha\u00eenement","text":"<p>Au-del\u00e0 des pipes, Bash propose plusieurs op\u00e9rateurs permettant d'encha\u00eener des commandes de mani\u00e8re conditionnelle ou inconditionnelle.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#enchainement-inconditionnel-point-virgule","title":"Encha\u00eenement inconditionnel : ; (point-virgule)","text":"<p>L'op\u00e9rateur <code>;</code> ex\u00e9cute les commandes s\u00e9quentiellement, ind\u00e9pendamment du r\u00e9sultat des commandes pr\u00e9c\u00e9dentes[1] :</p> Bash<pre><code>command1 ; command2 ; command3\n</code></pre> <p>Les trois commandes s'ex\u00e9cutent l'une apr\u00e8s l'autre, m\u00eame si command1 ou command2 \u00e9choue.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#enchainement-conditionnel-et-logique","title":"Encha\u00eenement conditionnel : &amp;&amp; (ET logique)","text":"<p>L'op\u00e9rateur <code>&amp;&amp;</code> ex\u00e9cute la commande suivante seulement si la commande pr\u00e9c\u00e9dente r\u00e9ussit (code de retour 0)[1] :</p> Bash<pre><code>cd /home/utilisateur &amp;&amp; ls -l\n</code></pre> <p>Si le changement de r\u00e9pertoire \u00e9choue, <code>ls -l</code> ne s'ex\u00e9cute pas.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#enchainement-conditionnel-ou-logique","title":"Encha\u00eenement conditionnel : || (OU logique)","text":"<p>L'op\u00e9rateur <code>||</code> ex\u00e9cute la commande suivante seulement si la commande pr\u00e9c\u00e9dente \u00e9choue (code de retour diff\u00e9rent de 0)[1] :</p> Bash<pre><code>cd /repertoire-inexistant || echo \"R\u00e9pertoire non trouv\u00e9\"\n</code></pre> <p>Si le changement de r\u00e9pertoire \u00e9choue, le message d'erreur personnalis\u00e9 s'affiche.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#combinaison-doperateurs","title":"Combinaison d'op\u00e9rateurs","text":"<p>Les op\u00e9rateurs peuvent \u00eatre combin\u00e9s pour cr\u00e9er des logiques complexes :</p> Bash<pre><code>make build &amp;&amp; make test || echo \"La compilation ou les tests ont \u00e9chou\u00e9\"\n</code></pre> <p>Cette commande ex\u00e9cute la compilation. Si elle r\u00e9ussit, elle ex\u00e9cute les tests. Si l'une ou l'autre \u00e9choue, un message d'erreur s'affiche.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#tableau-des-operateurs-denchainement","title":"Tableau des op\u00e9rateurs d'encha\u00eenement","text":"Op\u00e9rateur Nom Condition d'ex\u00e9cution Exemple <code>;</code> S\u00e9quence Toujours <code>cmd1 ; cmd2</code> <code>\\|\\|</code> OU logique Si cmd1 \u00e9choue <code>cmd1 \\|\\| cmd2</code> <code>&amp;&amp;</code> ET logique Si cmd1 r\u00e9ussit <code>cmd1 &amp;&amp; cmd2</code> <code>\\|</code> Pipe Flux de donn\u00e9es <code>cmd1 \\| cmd2</code>"},{"location":"_projects/_formation-bash/bash-chap04/#les-codes-de-retour","title":"Les codes de retour","text":""},{"location":"_projects/_formation-bash/bash-chap04/#concept-des-codes-de-retour","title":"Concept des codes de retour","text":"<p>Chaque commande ex\u00e9cut\u00e9e sous Bash retourne un code de retour (exit status), un entier entre 0 et 255 indiquant le r\u00e9sultat de l'ex\u00e9cution[1][2]. Cette valeur est utilis\u00e9e par le shell et par d'autres commandes pour d\u00e9terminer le succ\u00e8s ou l'\u00e9chec d'une op\u00e9ration.</p> <p>Convention standard : - 0 : Succ\u00e8s (la commande s'est ex\u00e9cut\u00e9e sans erreur) - Tout autre valeur : \u00c9chec (un probl\u00e8me s'est produit)</p>"},{"location":"_projects/_formation-bash/bash-chap04/#verification-du-code-de-retour","title":"V\u00e9rification du code de retour","text":"<p>Le code de retour de la derni\u00e8re commande ex\u00e9cut\u00e9e est stock\u00e9 dans la variable sp\u00e9ciale <code>$?</code>[1] :</p> Bash<pre><code>ls /home\necho $?\n</code></pre> <p>Si le r\u00e9pertoire existe, <code>$?</code> affiche 0. Si le r\u00e9pertoire n'existe pas, <code>$?</code> affiche une valeur comme 2.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#exemple-pratique-avec-conditions","title":"Exemple pratique avec conditions","text":"Bash<pre><code>grep \"pattern\" fichier.txt\nif [ $? -eq 0 ]; then\n    echo \"Motif trouv\u00e9\"\nelse\n    echo \"Motif non trouv\u00e9\"\nfi\n</code></pre> <p>Cette structure teste le code de retour de <code>grep</code> et affiche un message appropri\u00e9.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#codes-de-retour-courants","title":"Codes de retour courants","text":"Valeur Signification Exemple de commande 0 Succ\u00e8s <code>ls /home</code> (r\u00e9pertoire existant) 1 Erreur g\u00e9n\u00e9rale <code>grep</code> (motif non trouv\u00e9) 2 Erreur de syntaxe <code>commande-inexistante</code> 126 Commande non ex\u00e9cutable Fichier sans permissions d'ex\u00e9cution 127 Commande introuvable <code>xyz-commande-inexistante</code> 128+N Termin\u00e9 par signal Processus tu\u00e9 par signal 255 Code de sortie invalide D\u00e9bordement d'intervalle"},{"location":"_projects/_formation-bash/bash-chap04/#codes-de-retour-dans-les-scripts","title":"Codes de retour dans les scripts","text":"<p>Dans les scripts Bash, l'instruction <code>exit</code> permet de d\u00e9finir le code de retour du script entier[1] :</p> Bash<pre><code>#!/bin/bash\n\nif [ -f \"/etc/passwd\" ]; then\n    echo \"Le fichier /etc/passwd existe\"\n    exit 0\nelse\n    echo \"Le fichier /etc/passwd n'existe pas\"\n    exit 1\nfi\n</code></pre> <p>D'autres scripts ou commandes peuvent alors v\u00e9rifier le code de retour de ce script avec <code>$?</code>.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#utilisation-pratique-dans-les-conditions","title":"Utilisation pratique dans les conditions","text":"Bash<pre><code>if commande; then\n    echo \"Succ\u00e8s\"\nelse\n    echo \"\u00c9chec\"\nfi\n</code></pre> <p>Dans cette syntaxe, l'absence de <code>[ $? -eq 0 ]</code> est possible car <code>if</code> test automatiquement le code de retour de la derni\u00e8re commande du bloc de test.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#exemples-complets-et-cas-dusage","title":"Exemples complets et cas d'usage","text":""},{"location":"_projects/_formation-bash/bash-chap04/#cas-dusage-1-filtrage-et-sauvegarde","title":"Cas d'usage 1 : Filtrage et sauvegarde","text":"<p>Cet exemple combine pipes, tee et redirections pour filtrer les lignes d'un fichier journal et sauvegarder les r\u00e9sultats :</p> Bash<pre><code>#!/bin/bash\n\n# Extraire toutes les erreurs du journal syst\u00e8me\ngrep \"ERROR\" /var/log/syslog | tee errors.log | wc -l\n</code></pre> <p>Ce script : 1. Filtre les lignes contenant \"ERROR\" du fichier syslog 2. Sauvegarde les r\u00e9sultats dans errors.log (gr\u00e2ce \u00e0 <code>tee</code>) 3. Compte le nombre de lignes d'erreur avec <code>wc -l</code></p> <p>R\u00e9sultat affich\u00e9 : le nombre total d'erreurs trouv\u00e9es</p>"},{"location":"_projects/_formation-bash/bash-chap04/#cas-dusage-2-traitement-par-lots-avec-xargs","title":"Cas d'usage 2 : Traitement par lots avec xargs","text":"Bash<pre><code>#!/bin/bash\n\n# Traiter tous les fichiers .jpg en les convertissant en .png\n\nfind . -name \"*.jpg\" | xargs -I {} convert {} {}.png\n</code></pre> <p>Explication : - <code>find</code> localise tous les fichiers .jpg - <code>xargs -I {}</code> utilise <code>{}</code> comme placeholder pour chaque fichier - <code>convert</code> (ImageMagick) convertit chaque jpg en png</p> <p>L'option <code>-I</code> permet de sp\u00e9cifier comment utiliser les arguments re\u00e7us.</p>"},{"location":"_projects/_formation-bash/bash-chap04/#cas-dusage-3-gestion-derreurs-avec-redirections","title":"Cas d'usage 3 : Gestion d'erreurs avec redirections","text":"Bash<pre><code>#!/bin/bash\n\n# Ex\u00e9cuter une commande et capturer s\u00e9par\u00e9ment les r\u00e9sultats et erreurs\n\ncommande_complexe &gt; resultats.txt 2&gt; erreurs.txt\n\nif [ -s erreurs.txt ]; then\n    echo \"Erreurs d\u00e9tect\u00e9es :\" \n    cat erreurs.txt\nelse\n    echo \"Ex\u00e9cution r\u00e9ussie\"\n    cat resultats.txt\nfi\n</code></pre> <p>Explication : - stdout est redirig\u00e9 vers resultats.txt - stderr est redirig\u00e9 vers erreurs.txt - <code>-s erreurs.txt</code> teste si le fichier d'erreurs n'est pas vide - Le contenu appropri\u00e9 est affich\u00e9 selon le r\u00e9sultat</p>"},{"location":"_projects/_formation-bash/bash-chap04/#cas-dusage-4-pipeline-complexe-avec-conditions","title":"Cas d'usage 4 : Pipeline complexe avec conditions","text":"Bash<pre><code>#!/bin/bash\n\n# Archiver les fichiers modifi\u00e9s r\u00e9cemment\n\nfind /home -type f -mtime -7 | xargs tar -czf backup.tar.gz &amp;&amp; \\\n    echo \"Sauvegarde cr\u00e9\u00e9e avec succ\u00e8s\" || \\\n    echo \"Erreur lors de la cr\u00e9ation de la sauvegarde\"\n</code></pre> <p>D\u00e9composition : 1. <code>find</code> localise les fichiers modifi\u00e9s dans les 7 derniers jours 2. <code>xargs tar</code> compresse les fichiers dans une archive 3. <code>&amp;&amp;</code> d\u00e9clenche le message de succ\u00e8s si tout r\u00e9ussit 4. <code>||</code> affiche une erreur si quelque chose \u00e9choue</p>"},{"location":"_projects/_formation-bash/bash-chap04/#synthese-du-chemin-dapprentissage","title":"Synth\u00e8se du chemin d'apprentissage","text":"<p>Le parcours d'apprentissage optimal pour ma\u00eetriser la manipulation des flux sous Bash suit une progression logique :</p> <p>Phase 1 : Fondamentaux (concepts essentiels) L'apprenant commence par comprendre les trois flux standards (stdin, stdout, stderr) et leur r\u00f4le. Cette phase est cruciale car elle \u00e9tablit les bases conceptuelles n\u00e9cessaires.</p> <p>Phase 2 : Redirections simples (op\u00e9rateurs de base) Une fois les concepts ma\u00eetris\u00e9s, les redirections simples sont pratiqu\u00e9es : rediriger stdout avec <code>&gt;</code>, ajouter du contenu avec <code>&gt;&gt;</code>, et capturer les erreurs avec <code>2&gt;</code>. Ces op\u00e9rateurs constituent les blocs de construction de toute manipulation avanc\u00e9e.</p> <p>Phase 3 : Pipes et filtrage (flux de donn\u00e9es) Les pipes <code>|</code> sont introduits, permettant de combiner plusieurs commandes pour cr\u00e9er des pipelines de filtrage. Cette phase d\u00e9veloppe la pens\u00e9e \"composable\" o\u00f9 chaque commande fait une chose bien et peut \u00eatre combin\u00e9e avec d'autres.</p> <p>Phase 4 : Commandes utilitaires (tee et xargs) <code>tee</code> et <code>xargs</code> sont des commandes puissantes mais plus sp\u00e9cialis\u00e9es. Elles interviennent apr\u00e8s la ma\u00eetrise des bases et permettent des manipulations plus complexes et des cas d'usage avanc\u00e9s.</p> <p>Phase 5 : Encha\u00eenements et logique (contr\u00f4le du flux) Les op\u00e9rateurs d'encha\u00eenement (<code>;</code>, <code>&amp;&amp;</code>, <code>||</code>) et la compr\u00e9hension des codes de retour permettent de cr\u00e9er des scripts logiques et des pipelines intelligents qui s'adaptent aux r\u00e9sultats des commandes pr\u00e9c\u00e9dentes.</p> <p>Phase 6 : Int\u00e9gration (scripts complexes) Enfin, tous les concepts sont int\u00e9gr\u00e9s dans des scripts complets r\u00e9solvant des probl\u00e8mes r\u00e9els, combinant redirections, pipes, conditions et gestion d'erreurs.</p> <p>Cette progression assure que chaque concept s'appuie sur le pr\u00e9c\u00e9dent, cr\u00e9ant une compr\u00e9hension solide et progressive de la manipulation des flux sous Bash.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-bash/bash-chap05/","title":"Citations","text":"<ul> <li>https://www.youtube.com/watch?v=OJIROvp4cqs</li> <li>https://www.surfercloud.com/blog/how-to-install-and-use-snap-on-ubuntu-a-beginners-guide-2025</li> <li>https://spagnolostefano.altervista.org/snap/</li> <li>https://www.puntoinformaticofree.it/ubuntu_tutorial/snap/snap/installare_snap_store.html</li> <li>https://www.alternativalinux.it/ubuntu-gli-inganni-di-snap-e-il-controllo-di-linux/</li> <li>https://www.youtube.com/watch?v=Xpl7qtUc20s</li> <li>https://snapcraft.io/docs/installing-snap-on-ubuntu</li> <li>https://www.baeldung.com/linux/snaps-intro</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap05/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 292</li> <li>completion_tokens: 6906</li> <li>total_tokens: 7198</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.104, 'request_cost': 0.006, 'total_cost': 0.11}</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap05/#content","title":"Content","text":""},{"location":"_projects/_formation-bash/bash-chap05/#installation-de-programmes-sous-linux","title":"Installation de Programmes sous Linux \ud83d\udce6","text":""},{"location":"_projects/_formation-bash/bash-chap05/#introduction-aux-gestionnaires-de-paquets","title":"Introduction aux gestionnaires de paquets","text":"<p>L'installation de programmes sous Linux s'effectue principalement via des gestionnaires de paquets, des outils qui automatisent le t\u00e9l\u00e9chargement, l'installation et la gestion des logiciels. Contrairement aux syst\u00e8mes d'exploitation traditionnels o\u00f9 l'on t\u00e9l\u00e9charge des fichiers ex\u00e9cutables, Linux centralise les logiciels dans des d\u00e9p\u00f4ts (repositories) officiels ou tiers. Les deux gestionnaires de paquets majeurs sur Ubuntu et les distributions bas\u00e9es sur Debian sont APT (Advanced Package Tool) et Snap.</p> <p>APT repr\u00e9sente l'approche classique et traditionnelle des distributions Debian, tandis que Snap offre une approche plus moderne bas\u00e9e sur la conteneurisation. Chacun de ces outils pr\u00e9sente des avantages et des inconv\u00e9nients qui les rendent appropri\u00e9s pour diff\u00e9rents sc\u00e9narios d'utilisation.</p>"},{"location":"_projects/_formation-bash/bash-chap05/#chapitre-51-obtenir-des-informations-sur-les-paquets-avec-apt","title":"Chapitre 5.1 : Obtenir des informations sur les paquets avec APT \ud83d\udd0d","text":""},{"location":"_projects/_formation-bash/bash-chap05/#fonctionnement-dapt","title":"Fonctionnement d'APT","text":"<p>APT est le gestionnaire de paquets par d\u00e9faut des distributions bas\u00e9es sur Debian, notamment Ubuntu. Il permet de consulter, installer, mettre \u00e0 jour et supprimer des paquets depuis les d\u00e9p\u00f4ts officiels configur\u00e9s sur le syst\u00e8me. APT fonctionne en interagissant avec des fichiers de configuration qui d\u00e9finissent les sources de t\u00e9l\u00e9chargement des logiciels.</p>"},{"location":"_projects/_formation-bash/bash-chap05/#rechercher-des-informations-sur-un-paquet","title":"Rechercher des informations sur un paquet","text":"<p>La premi\u00e8re \u00e9tape avant d'installer un programme consiste \u00e0 rechercher des informations le concernant. Plusieurs commandes permettent d'acc\u00e9der \u00e0 ces informations :</p>"},{"location":"_projects/_formation-bash/bash-chap05/#la-commande-apt-search","title":"La commande <code>apt search</code>","text":"Bash<pre><code>apt search nom_du_paquet\n</code></pre> <p>Cette commande recherche dans les d\u00e9p\u00f4ts configur\u00e9s tous les paquets contenant le mot-cl\u00e9 sp\u00e9cifi\u00e9. Le r\u00e9sultat affiche le nom du paquet, sa version et une br\u00e8ve description.[2]</p> <p>Exemple pratique :</p> Bash<pre><code>apt search nginx\n</code></pre> <p>Cette commande retournera tous les paquets li\u00e9s \u00e0 nginx, incluant le serveur web lui-m\u00eame ainsi que divers modules et outils associ\u00e9s.</p>"},{"location":"_projects/_formation-bash/bash-chap05/#la-commande-apt-cache-search","title":"La commande <code>apt-cache search</code>","text":"Bash<pre><code>apt-cache search nom_du_paquet\n</code></pre> <p>Cette commande effectue une recherche similaire mais en utilisant le cache local des paquets, ce qui la rend g\u00e9n\u00e9ralement plus rapide.[2]</p> <p>Exemple :</p> Bash<pre><code>apt-cache search apache2\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#la-commande-apt-show-ou-apt-cache-show","title":"La commande <code>apt show</code> ou <code>apt-cache show</code>","text":"Bash<pre><code>apt show nom_du_paquet\n</code></pre> <p>Cette commande affiche des informations d\u00e9taill\u00e9es sur un paquet sp\u00e9cifique : version, taille, d\u00e9pendances, description compl\u00e8te, mainteneur, et URL du projet.[2]</p> <p>Exemple pratique :</p> Bash<pre><code>apt show curl\n</code></pre> <p>La sortie ressemblera \u00e0 :</p> Text Only<pre><code>Package: curl\nVersion: 7.81.0-1ubuntu1.13\nPriority: optional\nSection: web\nMaintainer: Ubuntu Developers &lt;ubuntu-devel-discuss@lists.ubuntu.com&gt;\nInstalled-Size: 402 kB\nDepends: libc6 (&gt;= 2.34), libcurl4 (= 7.81.0-1ubuntu1.13)\nHomepage: https://curl.se/\nDownload-Size: 167 kB\nDescription: command line tool for transferring data with URLs\n curl is a command line tool for transferring data using URLs\n (Server for HTTP, HTTPS, FTP, FTPS, FILE, LDAP, LDAPS,\n ...\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#comprendre-les-resultats-de-recherche","title":"Comprendre les r\u00e9sultats de recherche","text":"<p>Lors d'une recherche avec <code>apt search</code>, les r\u00e9sultats affichent plusieurs informations cl\u00e9s :</p> <ul> <li>Nom du paquet : L'identifiant unique du logiciel</li> <li>Version disponible : La version pr\u00e9sente dans les d\u00e9p\u00f4ts</li> <li>Description courte : Une phrase r\u00e9sumant la fonction du paquet</li> <li>\u00c9tat d'installation : Indique si le paquet est d\u00e9j\u00e0 install\u00e9 sur le syst\u00e8me</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap05/#afficher-les-paquets-disponibles","title":"Afficher les paquets disponibles","text":"Bash<pre><code>apt list --available\n</code></pre> <p>Cette commande liste tous les paquets disponibles dans les d\u00e9p\u00f4ts configur\u00e9s.[2]</p> Bash<pre><code>apt list --available | grep -E \"^(python|ruby|node)\" | head -20\n</code></pre> <p>Cette variante filtre les r\u00e9sultats pour afficher uniquement les paquets Python, Ruby et Node.js.</p>"},{"location":"_projects/_formation-bash/bash-chap05/#afficher-les-paquets-installes","title":"Afficher les paquets install\u00e9s","text":"Bash<pre><code>apt list --installed\n</code></pre> <p>Liste uniquement les paquets d\u00e9j\u00e0 install\u00e9s sur le syst\u00e8me.[2]</p> Bash<pre><code>apt list --installed | wc -l\n</code></pre> <p>Cette commande compte le nombre total de paquets install\u00e9s.</p>"},{"location":"_projects/_formation-bash/bash-chap05/#verifier-les-mises-a-jour-disponibles","title":"V\u00e9rifier les mises \u00e0 jour disponibles","text":"Bash<pre><code>apt list --upgradable\n</code></pre> <p>Affiche la liste des paquets install\u00e9s pour lesquels une version plus r\u00e9cente est disponible dans les d\u00e9p\u00f4ts.[2]</p>"},{"location":"_projects/_formation-bash/bash-chap05/#obtenir-des-statistiques-sur-les-depots","title":"Obtenir des statistiques sur les d\u00e9p\u00f4ts","text":"Bash<pre><code>apt stats\n</code></pre> <p>Affiche des informations g\u00e9n\u00e9rales sur l'\u00e9tat des d\u00e9p\u00f4ts et du cache local.</p>"},{"location":"_projects/_formation-bash/bash-chap05/#chapitre-52-utiliser-apt-pour-installer-mettre-a-jour-et-supprimer-des-paquets","title":"Chapitre 5.2 : Utiliser APT pour installer, mettre \u00e0 jour et supprimer des paquets \u2699\ufe0f","text":""},{"location":"_projects/_formation-bash/bash-chap05/#installation-de-paquets","title":"Installation de paquets","text":""},{"location":"_projects/_formation-bash/bash-chap05/#mise-a-jour-de-lindex-des-paquets","title":"Mise \u00e0 jour de l'index des paquets","text":"<p>Avant d'installer un programme, il est recommand\u00e9 de mettre \u00e0 jour l'index local des paquets. Cet index contient une liste de tous les paquets disponibles dans les d\u00e9p\u00f4ts configur\u00e9s et leurs versions respectives.</p> Bash<pre><code>sudo apt update\n</code></pre> <p>Cette commande t\u00e9l\u00e9charge les listes des paquets disponibles depuis les serveurs des d\u00e9p\u00f4ts. L'utilisation de <code>sudo</code> est n\u00e9cessaire car l'op\u00e9ration requiert des privil\u00e8ges administrateur. Cette \u00e9tape doit \u00eatre effectu\u00e9e r\u00e9guli\u00e8rement pour assurer l'acc\u00e8s aux versions les plus r\u00e9centes des logiciels.[2]</p> <p>Exemple complet :</p> Bash<pre><code>sudo apt update\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\n4 packages can be upgraded. Run 'apt list --upgradable' to see them.\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#installation-dun-paquet-simple","title":"Installation d'un paquet simple","text":"Bash<pre><code>sudo apt install nom_du_paquet\n</code></pre> <p>Cette commande installe un paquet sp\u00e9cifique \u00e0 partir des d\u00e9p\u00f4ts. APT r\u00e9sout automatiquement les d\u00e9pendances, c'est-\u00e0-dire qu'il identifie et installe tous les logiciels auxquels le paquet d\u00e9pend.[2]</p> <p>Exemple pratique :</p> Bash<pre><code>sudo apt install git\n</code></pre> <p>APT affichera un r\u00e9sum\u00e9 des paquets \u00e0 installer, incluant les d\u00e9pendances, et demandera une confirmation :</p> Text Only<pre><code>Reading package lists... Done\nBuilding dependency tree... Done\nThe following NEW packages will be installed:\n  git git-man liberror-perl\n0 upgraded, 3 newly installed, 0 removed\nNeed to get 6,234 kB of archives.\nAfter this operation, 21.4 MB of additional disk space will be used.\nDo you want to continue? [Y/n]\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#installation-de-plusieurs-paquets-simultanement","title":"Installation de plusieurs paquets simultan\u00e9ment","text":"Bash<pre><code>sudo apt install paquet1 paquet2 paquet3\n</code></pre> <p>Cette commande installe plusieurs paquets en une seule op\u00e9ration, ce qui \u00e9conomise du temps et des ressources r\u00e9seau.[2]</p> <p>Exemple :</p> Bash<pre><code>sudo apt install vim curl wget\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#installation-dune-version-specifique","title":"Installation d'une version sp\u00e9cifique","text":"Bash<pre><code>sudo apt install nom_du_paquet=version_sp\u00e9cifique\n</code></pre> <p>Permet d'installer une version particuli\u00e8re d'un paquet plut\u00f4t que la version par d\u00e9faut des d\u00e9p\u00f4ts.[2]</p> <p>Exemple :</p> Bash<pre><code>sudo apt install python3=3.10.4-1\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#mise-a-jour-des-paquets","title":"Mise \u00e0 jour des paquets","text":""},{"location":"_projects/_formation-bash/bash-chap05/#mise-a-jour-de-tous-les-paquets-installes","title":"Mise \u00e0 jour de tous les paquets install\u00e9s","text":"Bash<pre><code>sudo apt upgrade\n</code></pre> <p>Cette commande met \u00e0 jour tous les paquets install\u00e9s vers leurs versions les plus r\u00e9centes disponibles dans les d\u00e9p\u00f4ts.[2] Les paquets sont mis \u00e0 jour de mani\u00e8re \u00ab s\u00fbre \u00bb : APT n'ajoutera pas ou ne supprimera pas de paquets pour r\u00e9soudre des conflits.</p> <p>Exemple :</p> Bash<pre><code>sudo apt upgrade\nReading package lists... Done\nBuilding dependency tree... Done\nThe following packages will be upgraded:\n  curl gnupg2 openssl\n3 upgraded, 0 newly installed, 0 removed\nNeed to get 2,445 kB of archives.\nAfter this operation, 1,024 kB of additional disk space will be used.\nDo you want to continue? [Y/n]\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#mise-a-jour-agressive-dist-upgrade","title":"Mise \u00e0 jour agressive (dist-upgrade)","text":"Bash<pre><code>sudo apt full-upgrade\n</code></pre> <p>ou</p> Bash<pre><code>sudo apt dist-upgrade\n</code></pre> <p>Cette commande effectue une mise \u00e0 jour plus compl\u00e8te qui peut supprimer ou ajouter des paquets si n\u00e9cessaire pour r\u00e9soudre les conflits de d\u00e9pendances. Elle est g\u00e9n\u00e9ralement utilis\u00e9e lors de mises \u00e0 jour majeures du syst\u00e8me d'exploitation.[2]</p>"},{"location":"_projects/_formation-bash/bash-chap05/#mise-a-jour-dun-paquet-specifique","title":"Mise \u00e0 jour d'un paquet sp\u00e9cifique","text":"Bash<pre><code>sudo apt upgrade nom_du_paquet\n</code></pre> <p>Permet de mettre \u00e0 jour un seul paquet plut\u00f4t que tous les paquets install\u00e9s.</p>"},{"location":"_projects/_formation-bash/bash-chap05/#suppression-de-paquets","title":"Suppression de paquets","text":""},{"location":"_projects/_formation-bash/bash-chap05/#desinstallation-simple","title":"D\u00e9sinstallation simple","text":"Bash<pre><code>sudo apt remove nom_du_paquet\n</code></pre> <p>Cette commande supprime le paquet sp\u00e9cifi\u00e9 du syst\u00e8me. Cependant, les fichiers de configuration associ\u00e9s au paquet sont conserv\u00e9s, ce qui permet de r\u00e9installer le paquet ult\u00e9rieurement sans perdre les param\u00e8tres personnalis\u00e9s.[2]</p> <p>Exemple :</p> Bash<pre><code>sudo apt remove chromium\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#suppression-complete-avec-fichiers-de-configuration","title":"Suppression compl\u00e8te avec fichiers de configuration","text":"Bash<pre><code>sudo apt purge nom_du_paquet\n</code></pre> <p>Cette commande effectue une suppression compl\u00e8te du paquet, incluant tous les fichiers de configuration et les donn\u00e9es associ\u00e9es.[2]</p> <p>Exemple :</p> Bash<pre><code>sudo apt purge mysql-server\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#suppression-des-paquets-inutilises","title":"Suppression des paquets inutilis\u00e9s","text":"Bash<pre><code>sudo apt autoremove\n</code></pre> <p>Cette commande identifie et supprime les paquets de d\u00e9pendance qui ne sont plus requis par aucun paquet install\u00e9. Cette op\u00e9ration aide \u00e0 lib\u00e9rer de l'espace disque et \u00e0 maintenir le syst\u00e8me propre.[2]</p> Bash<pre><code>sudo apt clean\n</code></pre> <p>Supprime les fichiers .deb t\u00e9l\u00e9charg\u00e9s et conserv\u00e9s dans le cache, lib\u00e9rant ainsi de l'espace disque.</p>"},{"location":"_projects/_formation-bash/bash-chap05/#chapitre-53-installer-un-programme-avec-apt-et-apt-get","title":"Chapitre 5.3 : Installer un programme avec apt et apt-get \ud83d\udee0\ufe0f","text":""},{"location":"_projects/_formation-bash/bash-chap05/#differences-entre-apt-et-apt-get","title":"Diff\u00e9rences entre apt et apt-get","text":"<p>Historiquement, <code>apt-get</code> et <code>apt-cache</code> sont les commandes de bas niveau fournies par APT. La commande <code>apt</code> a \u00e9t\u00e9 introduite ult\u00e9rieurement comme interface de haut niveau, combinant les fonctionnalit\u00e9s des deux outils pr\u00e9c\u00e9dents dans une interface plus conviviale.</p> Aspect apt apt-get Interface Moderne et conviviale Bas niveau, plus verbeux Sortie Format\u00e9e et lisible D\u00e9taill\u00e9e et technique Stabilit\u00e9 Peut changer entre versions Interface stable Recommandation Scripts modernes et utilisation interactive Scripts existants et compatibilit\u00e9 Fonctionnalit\u00e9s Combine apt-get et apt-cache Sp\u00e9cialis\u00e9e pour l'installation"},{"location":"_projects/_formation-bash/bash-chap05/#flux-dinstallation-complet-avec-apt","title":"Flux d'installation complet avec apt","text":"<p>Un processus d'installation typique suit les \u00e9tapes suivantes :</p>"},{"location":"_projects/_formation-bash/bash-chap05/#etape-1-mettre-a-jour-lindex","title":"\u00c9tape 1 : Mettre \u00e0 jour l'index","text":"Bash<pre><code>sudo apt update\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#etape-2-rechercher-le-paquet","title":"\u00c9tape 2 : Rechercher le paquet","text":"Bash<pre><code>apt search postgresql\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#etape-3-obtenir-des-informations-detaillees","title":"\u00c9tape 3 : Obtenir des informations d\u00e9taill\u00e9es","text":"Bash<pre><code>apt show postgresql\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#etape-4-installer-le-paquet","title":"\u00c9tape 4 : Installer le paquet","text":"Bash<pre><code>sudo apt install postgresql\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#etape-5-verifier-linstallation","title":"\u00c9tape 5 : V\u00e9rifier l'installation","text":"Bash<pre><code>apt list --installed | grep postgresql\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#flux-dinstallation-complet-avec-apt-get","title":"Flux d'installation complet avec apt-get","text":"<p>Le processus avec <code>apt-get</code> est similaire mais utilise une syntaxe l\u00e9g\u00e8rement diff\u00e9rente :</p> Bash<pre><code>sudo apt-get update\napt-cache search mariadb\napt-cache show mariadb-server\nsudo apt-get install mariadb-server\napt-get list --installed | grep mariadb\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#script-dinstallation-automatisee","title":"Script d'installation automatis\u00e9e","text":"<p>Pour automatiser des installations r\u00e9currentes, il est possible de cr\u00e9er des scripts bash :</p> Bash<pre><code>#!/bin/bash\n\n# Script d'installation des outils de d\u00e9veloppement couramment utilis\u00e9s\n\necho \"Mise \u00e0 jour de l'index des paquets...\"\nsudo apt update\n\necho \"Installation des outils essentiels...\"\nsudo apt install -y \\\n    build-essential \\\n    curl \\\n    wget \\\n    git \\\n    vim \\\n    nano \\\n    htop \\\n    tmux\n\necho \"Installation des environnements de d\u00e9veloppement...\"\nsudo apt install -y \\\n    python3 \\\n    python3-pip \\\n    nodejs \\\n    npm \\\n    ruby\n\necho \"Installation des bases de donn\u00e9es...\"\nsudo apt install -y \\\n    postgresql \\\n    mysql-server \\\n    redis-server\n\necho \"Installation termin\u00e9e !\"\necho \"Les paquets suivants ont \u00e9t\u00e9 install\u00e9s :\"\napt list --installed | grep -E \"build-essential|curl|wget|git\"\n</code></pre> <p>Sauvegarder ce script dans un fichier <code>install.sh</code> et l'ex\u00e9cuter :</p> Bash<pre><code>chmod +x install.sh\n./install.sh\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#gestion-des-dependances","title":"Gestion des d\u00e9pendances","text":"<p>APT r\u00e9sout automatiquement les d\u00e9pendances, mais il est utile de comprendre ce processus. Lorsqu'un paquet est install\u00e9, APT examine ses d\u00e9pendances et installe automatiquement tous les paquets requis.</p> <p>Exemple :</p> Bash<pre><code>sudo apt install nginx\n</code></pre> <p>APT reconna\u00eet que nginx d\u00e9pend de plusieurs paquets (libpcre3, openssl, etc.) et les installe automatiquement sans intervention manuelle.</p> <p>Pour afficher les d\u00e9pendances d'un paquet sans l'installer :</p> Bash<pre><code>apt-cache depends nginx\n</code></pre> <p>Cela affichera une arborescence de toutes les d\u00e9pendances du paquet.</p>"},{"location":"_projects/_formation-bash/bash-chap05/#chapitre-54-utiliser-le-gestionnaire-de-paquets-snap","title":"Chapitre 5.4 : Utiliser le gestionnaire de paquets Snap \ud83d\udcf1","text":""},{"location":"_projects/_formation-bash/bash-chap05/#quest-ce-que-snap","title":"Qu'est-ce que Snap ?","text":"<p>Snap est un gestionnaire de paquets moderne d\u00e9velopp\u00e9 par Canonical, la soci\u00e9t\u00e9 derri\u00e8re Ubuntu. \u00c0 la diff\u00e9rence d'APT qui repose sur les d\u00e9p\u00f4ts traditionnels de Debian, Snap utilise une approche conteneuris\u00e9e, o\u00f9 chaque application est empaquet\u00e9e avec toutes ses d\u00e9pendances dans un conteneur isol\u00e9.[1]</p>"},{"location":"_projects/_formation-bash/bash-chap05/#avantages-du-format-snap","title":"Avantages du format Snap","text":"<ul> <li>Isolation des applications : Chaque snap s'ex\u00e9cute dans un environnement isol\u00e9, r\u00e9duisant les conflits de d\u00e9pendances</li> <li>Compatibilit\u00e9 multiplateforme : Les snaps fonctionnent sur toutes les distributions Linux majeures</li> <li>Mises \u00e0 jour automatiques : Les snaps se mettent \u00e0 jour automatiquement sans intervention manuelle</li> <li>Versioning ind\u00e9pendant : Possibilit\u00e9 d'installer diff\u00e9rentes versions d'une m\u00eame application c\u00f4te \u00e0 c\u00f4te</li> <li>S\u00e9curit\u00e9 renforc\u00e9e : Les snaps fonctionnent en mode confinement (confinement sandbox)</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap05/#inconvenients-du-format-snap","title":"Inconv\u00e9nients du format Snap","text":"<ul> <li>Consommation d'espace disque : Les snaps occupent g\u00e9n\u00e9ralement plus d'espace que les paquets APT car ils incluent toutes leurs d\u00e9pendances[1]</li> <li>Vitesse de d\u00e9marrage : Le temps de d\u00e9marrage peut \u00eatre plus lent en raison du processus de montage du conteneur</li> <li>Adoption limit\u00e9e : Snap est principalement utilis\u00e9 par Ubuntu et n'est pas largement adopt\u00e9 par les autres distributions</li> <li>Contr\u00f4le d\u00e9centralis\u00e9 : Certaines critiques soulev\u00e9es concernent le r\u00f4le centralis\u00e9 de Canonical dans la distribution des snaps</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap05/#installation-de-snap-sur-ubuntu","title":"Installation de Snap sur Ubuntu","text":""},{"location":"_projects/_formation-bash/bash-chap05/#verification-de-linstallation-existante","title":"V\u00e9rification de l'installation existante","text":"<p>Snap est g\u00e9n\u00e9ralement pr\u00e9-install\u00e9 sur les versions r\u00e9centes d'Ubuntu. Pour v\u00e9rifier l'installation :</p> Bash<pre><code>snap version\n</code></pre> <p>Si Snap n'est pas install\u00e9, la sortie affichera un message d'erreur.</p>"},{"location":"_projects/_formation-bash/bash-chap05/#installation-de-snapd","title":"Installation de snapd","text":"Bash<pre><code>sudo apt update\nsudo apt install snapd\n</code></pre> <p>Apr\u00e8s l'installation, il peut \u00eatre n\u00e9cessaire de red\u00e9marrer le syst\u00e8me ou de recharger la variable PATH :</p> Bash<pre><code>source /etc/profile\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#verification-du-service-snapd","title":"V\u00e9rification du service snapd","text":"Bash<pre><code>sudo systemctl status snapd\n</code></pre> <p>Cela affichera l'\u00e9tat du service snapd (actif ou inactif).</p> <p>Si le service n'est pas actif :</p> Bash<pre><code>sudo systemctl enable snapd.service\nsudo systemctl start snapd.service\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#chapitre-55-le-gestionnaire-de-paquets-snap-guide-detaille","title":"Chapitre 5.5 : Le gestionnaire de paquets Snap - Guide d\u00e9taill\u00e9 \ud83c\udfaf","text":""},{"location":"_projects/_formation-bash/bash-chap05/#structure-et-fonctionnement-des-snaps","title":"Structure et fonctionnement des snaps","text":"<p>Un snap est un conteneur d'application auto-contenu incluant :</p> <ul> <li>L'application elle-m\u00eame</li> <li>Toutes les d\u00e9pendances requises (biblioth\u00e8ques, runtime)</li> <li>Les fichiers de configuration</li> <li>Les m\u00e9tadonn\u00e9es d'installation</li> </ul> <p>Cette structure garantit que l'application fonctionne de mani\u00e8re coh\u00e9rente quel que soit l'environnement du syst\u00e8me h\u00f4te.</p>"},{"location":"_projects/_formation-bash/bash-chap05/#rechercher-des-snaps","title":"Rechercher des snaps","text":""},{"location":"_projects/_formation-bash/bash-chap05/#recherche-dans-le-snap-store","title":"Recherche dans le Snap Store","text":"Bash<pre><code>snap find nom_de_l_application\n</code></pre> <p>Cette commande recherche dans le Snap Store officiel tous les snaps correspondant au mot-cl\u00e9 sp\u00e9cifi\u00e9.[1]</p> <p>Exemple pratique :</p> Bash<pre><code>snap find vlc\n</code></pre> <p>La sortie affichera :</p> Text Only<pre><code>Name           Version   Publisher   Notes\nvlc            3.0.16    videolan    -\nvlc-mozilla    3.0.16    videolan    -\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#obtenir-des-informations-detaillees-sur-un-snap","title":"Obtenir des informations d\u00e9taill\u00e9es sur un snap","text":"Bash<pre><code>snap info nom_du_snap\n</code></pre> <p>Affiche des informations compl\u00e8tes sur un snap sp\u00e9cifique, incluant les canaux de version disponibles, la taille du snap, les permissions requises, et la description d\u00e9taill\u00e9e.[1]</p> <p>Exemple :</p> Bash<pre><code>snap info firefox\n</code></pre> <p>La sortie inclura :</p> Text Only<pre><code>name:      firefox\nsummary:   Mozilla Firefox web browser\npublisher: Mozilla\nstore-url: https://snapcraft.io/firefox\ncontact:   Mozilla Messaging &lt;firefox-dev@mozilla.org&gt;\nlicense:   MPL-2.0\ndescription:\n  The Firefox browser is fast and user-friendly.\nchannels:\n  latest/stable:    117.0.1-1            (3151) 292MB -\n  latest/candidate: 118.0-2              (3172) 293MB -\n  latest/beta:      119.0b1-1            (3173) 294MB -\n  latest/edge:      120.0a1-1            (3174) 295MB -\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#installation-de-snaps","title":"Installation de snaps","text":""},{"location":"_projects/_formation-bash/bash-chap05/#installation-simple","title":"Installation simple","text":"Bash<pre><code>sudo snap install nom_du_snap\n</code></pre> <p>Installe le snap depuis le canal stable par d\u00e9faut.[1]</p> <p>Exemple :</p> Bash<pre><code>sudo snap install spotify\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#installation-dune-version-beta-ou-de-developpement","title":"Installation d'une version b\u00eata ou de d\u00e9veloppement","text":"Bash<pre><code>sudo snap install nom_du_snap --channel=beta\n</code></pre> <p>Ou :</p> Bash<pre><code>sudo snap install nom_du_snap --channel=edge\n</code></pre> <p>Les canaux disponibles d\u00e9pendent du snap sp\u00e9cifique. Les canaux courants sont : - <code>stable</code> : Version stable recommand\u00e9e - <code>candidate</code> : Pr\u00e9-version candidate de la prochaine version stable - <code>beta</code> : Version b\u00eata avec nouvelles fonctionnalit\u00e9s - <code>edge</code> : Version en d\u00e9veloppement actif, possiblement instable[1]</p> <p>Exemple :</p> Bash<pre><code>sudo snap install code --channel=edge\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#installation-dune-version-classique","title":"Installation d'une version classique","text":"Bash<pre><code>sudo snap install nom_du_snap --classic\n</code></pre> <p>Le mode classique d\u00e9sactive le confinement du snap, le permettant d'acc\u00e9der au syst\u00e8me de fichiers complet. Cela est g\u00e9n\u00e9ralement utilis\u00e9 pour les snaps qui ne peuvent pas fonctionner avec le confinement par d\u00e9faut.[1]</p>"},{"location":"_projects/_formation-bash/bash-chap05/#lister-et-gerer-les-snaps-installes","title":"Lister et g\u00e9rer les snaps install\u00e9s","text":""},{"location":"_projects/_formation-bash/bash-chap05/#lister-tous-les-snaps","title":"Lister tous les snaps","text":"Bash<pre><code>snap list\n</code></pre> <p>Affiche tous les snaps install\u00e9s sur le syst\u00e8me avec leur version actuelle et la taille consomm\u00e9e.[1]</p> <p>La sortie ressemblera \u00e0 :</p> Text Only<pre><code>Name               Version      Rev    Tracking   Publisher   Notes\ncore               20230901+git 14784  stable     canonical   core\nfirefox            117.0.1-1    3151   stable     mozilla     -\nsnapd              2.60         19721  stable     canonical   snapd\nspotify            1.2.26.1187  67     stable     spotify     -\nubuntu-image       2.0          -      -          -           -\nvlc                3.0.16       6749   stable     videolan    -\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#obtenir-des-informations-sur-un-snap-installe","title":"Obtenir des informations sur un snap install\u00e9","text":"Bash<pre><code>snap list nom_du_snap\n</code></pre> <p>Affiche les d\u00e9tails d'un snap install\u00e9 sp\u00e9cifique.</p>"},{"location":"_projects/_formation-bash/bash-chap05/#verifier-les-services-fournis-par-les-snaps","title":"V\u00e9rifier les services fournis par les snaps","text":"Bash<pre><code>snap services\n</code></pre> <p>Liste tous les services g\u00e9r\u00e9s par les snaps install\u00e9s.</p>"},{"location":"_projects/_formation-bash/bash-chap05/#mise-a-jour-des-snaps","title":"Mise \u00e0 jour des snaps","text":""},{"location":"_projects/_formation-bash/bash-chap05/#mise-a-jour-automatique","title":"Mise \u00e0 jour automatique","text":"<p>Par d\u00e9faut, les snaps se mettent \u00e0 jour automatiquement. Cette mise \u00e0 jour se produit g\u00e9n\u00e9ralement une fois par jour \u00e0 une heure al\u00e9atoire.[1]</p>"},{"location":"_projects/_formation-bash/bash-chap05/#mise-a-jour-manuelle","title":"Mise \u00e0 jour manuelle","text":"Bash<pre><code>sudo snap refresh\n</code></pre> <p>Force la mise \u00e0 jour imm\u00e9diate de tous les snaps.[1]</p> <p>Exemple :</p> Bash<pre><code>sudo snap refresh\nFetching snap information\n...\nfirefox 117.0.1-1 from Mozilla refreshed\nspotfiy 1.2.26.1187 from Spotify refreshed\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#mise-a-jour-dun-snap-specifique","title":"Mise \u00e0 jour d'un snap sp\u00e9cifique","text":"Bash<pre><code>sudo snap refresh nom_du_snap\n</code></pre> <p>Met \u00e0 jour uniquement le snap sp\u00e9cifi\u00e9.[1]</p> <p>Exemple :</p> Bash<pre><code>sudo snap refresh vlc\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#geler-les-mises-a-jour","title":"Geler les mises \u00e0 jour","text":"<p>Pour emp\u00eacher la mise \u00e0 jour automatique d'un snap sp\u00e9cifique :</p> Bash<pre><code>sudo snap refresh --hold=24h nom_du_snap\n</code></pre> <p>Cette commande g\u00e8le les mises \u00e0 jour pendant 24 heures. Le param\u00e8tre peut \u00eatre modifi\u00e9 (par exemple <code>48h</code> pour 48 heures).[2]</p> <p>Pour r\u00e9activer les mises \u00e0 jour :</p> Bash<pre><code>sudo snap refresh --unhold nom_du_snap\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#suppression-de-snaps","title":"Suppression de snaps","text":""},{"location":"_projects/_formation-bash/bash-chap05/#desinstallation-simple_1","title":"D\u00e9sinstallation simple","text":"Bash<pre><code>sudo snap remove nom_du_snap\n</code></pre> <p>Supprime le snap du syst\u00e8me.[1]</p> <p>Exemple :</p> Bash<pre><code>sudo snap remove spotify\n</code></pre> <p>La sortie affichera :</p> Text Only<pre><code>spotify removed\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#suppression-avec-conservation-des-donnees","title":"Suppression avec conservation des donn\u00e9es","text":"<p>Par d\u00e9faut, <code>snap remove</code> conserve les donn\u00e9es de configuration de l'utilisateur. Pour une suppression compl\u00e8te incluant les donn\u00e9es :</p> Bash<pre><code>sudo snap remove --purge nom_du_snap\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#execution-des-services-snap","title":"Ex\u00e9cution des services snap","text":""},{"location":"_projects/_formation-bash/bash-chap05/#afficher-letat-des-services","title":"Afficher l'\u00e9tat des services","text":"Bash<pre><code>snap services\n</code></pre> <p>Liste tous les services disponibles fournis par les snaps avec leur \u00e9tat (actif ou inactif).</p>"},{"location":"_projects/_formation-bash/bash-chap05/#demarrer-et-arreter-des-services","title":"D\u00e9marrer et arr\u00eater des services","text":"Bash<pre><code>sudo snap start nom_du_service\nsudo snap stop nom_du_service\n</code></pre> <p>Exemple :</p> Bash<pre><code>sudo snap start hello-world\nsudo snap stop hello-world\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#acces-aux-applications-snap","title":"Acc\u00e8s aux applications Snap","text":""},{"location":"_projects/_formation-bash/bash-chap05/#installation-du-snap-store-graphique","title":"Installation du Snap Store graphique","text":"<p>Pour les utilisateurs pr\u00e9f\u00e9rant une interface graphique :</p> Bash<pre><code>sudo snap install snap-store\n</code></pre> <p>Le Snap Store fournit une interface visuelle pour rechercher, installer et g\u00e9rer les snaps, similaire \u00e0 l'app store des syst\u00e8mes mobiles.[4]</p>"},{"location":"_projects/_formation-bash/bash-chap05/#lancement-des-applications","title":"Lancement des applications","text":"<p>Les snaps s'ex\u00e9cutent g\u00e9n\u00e9ralement via le menu d'applications du bureau. En ligne de commande :</p> Bash<pre><code>firefox\nvlc\nspotify\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#depannage-des-snaps","title":"D\u00e9pannage des snaps","text":""},{"location":"_projects/_formation-bash/bash-chap05/#verifier-le-statut-dun-snap","title":"V\u00e9rifier le statut d'un snap","text":"Bash<pre><code>snap info nom_du_snap\nsnap changes\n</code></pre> <p>La commande <code>snap changes</code> affiche l'historique des op\u00e9rations effectu\u00e9es sur les snaps.</p>"},{"location":"_projects/_formation-bash/bash-chap05/#obtenir-des-logs","title":"Obtenir des logs","text":"Bash<pre><code>snap logs nom_du_snap -f\n</code></pre> <p>Affiche les logs du snap en temps r\u00e9el (param\u00e8tre <code>-f</code> pour suivre les modifications).</p>"},{"location":"_projects/_formation-bash/bash-chap05/#reinstaller-un-snap-corrompu","title":"R\u00e9installer un snap corrompu","text":"Bash<pre><code>sudo snap remove nom_du_snap\nsudo snap install nom_du_snap\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#comparaison-apt-vs-snap","title":"Comparaison APT vs Snap \ud83d\udd04","text":""},{"location":"_projects/_formation-bash/bash-chap05/#tableau-comparatif-detaille","title":"Tableau comparatif d\u00e9taill\u00e9","text":"Crit\u00e8re APT Snap Origine Debian/Ubuntu natif Canonical (Ubuntu) Paquet D\u00e9p\u00f4t centralis\u00e9 Debian Conteneur isol\u00e9 D\u00e9pendances Partag\u00e9es au niveau syst\u00e8me Incluses dans le snap Taille disque Petite \u00e0 moyenne Grande (d\u00e9pendances incluses) Vitesse d'installation Rapide Plus lente (t\u00e9l\u00e9chargement conteneur) Mises \u00e0 jour Manuelles par d\u00e9faut Automatiques par d\u00e9faut Compatibilit\u00e9 Debian/Ubuntu et d\u00e9riv\u00e9es Toutes les distributions Linux Confinement Non (acc\u00e8s syst\u00e8me complet) Oui (isolation et s\u00e9curit\u00e9) Versions multiples G\u00e9n\u00e9ralement une par d\u00e9p\u00f4t Plusieurs canaux disponibles Adoption Tr\u00e8s largement adopt\u00e9e Principalement Ubuntu Performance Excellente Bonne avec l\u00e9ger surco\u00fbt Interface Ligne de commande CLI et GUI (Snap Store)"},{"location":"_projects/_formation-bash/bash-chap05/#recommandations-dutilisation","title":"Recommandations d'utilisation","text":"<p>Utiliser APT pour :</p> <ul> <li>Les serveurs Linux o\u00f9 la stabilit\u00e9 et la performance sont primordiales</li> <li>L'installation de logiciels syst\u00e8me fondamentaux</li> <li>Les applications n\u00e9cessitant un acc\u00e8s direct aux ressources syst\u00e8me</li> <li>Les environnements n\u00e9cessitant une compatibilit\u00e9 maximale avec les autres distributions Debian</li> <li>Les situations o\u00f9 l'espace disque est limit\u00e9[1]</li> </ul> <p>Utiliser Snap pour :</p> <ul> <li>Les utilisateurs de bureau Ubuntu cherchant la simplicit\u00e9</li> <li>L'installation rapide d'applications graphiques r\u00e9centes</li> <li>Les situations n\u00e9cessitant des mises \u00e0 jour automatiques</li> <li>Les environnements multi-distributions</li> <li>Les applications n\u00e9cessitant l'isolation pour des raisons de s\u00e9curit\u00e9</li> <li>Les cas o\u00f9 plusieurs versions de la m\u00eame application sont requises[1]</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap05/#bonnes-pratiques-et-workflows-avances","title":"Bonnes pratiques et workflows avanc\u00e9s \ud83d\udca1","text":""},{"location":"_projects/_formation-bash/bash-chap05/#script-de-maintenance-systeme-complet","title":"Script de maintenance syst\u00e8me complet","text":"Bash<pre><code>#!/bin/bash\n\n# Script de maintenance syst\u00e8me combinant APT et Snap\n\necho \"=== D\u00e9but de la maintenance syst\u00e8me ===\"\necho \"Date: $(date)\"\n\n# Section APT\necho -e \"\\n--- Gestion APT ---\"\necho \"Mise \u00e0 jour de l'index APT...\"\nsudo apt update\n\necho \"V\u00e9rification des mises \u00e0 jour disponibles...\"\nUPGRADABLE=$(apt list --upgradable 2&gt;/dev/null | wc -l)\nif [ $UPGRADABLE -gt 1 ]; then\n    echo \"Packages \u00e0 mettre \u00e0 jour : $((UPGRADABLE - 1))\"\n    apt list --upgradable\n    echo \"Installation des mises \u00e0 jour...\"\n    sudo apt upgrade -y\nelse\n    echo \"Aucune mise \u00e0 jour disponible\"\nfi\n\necho \"Suppression des paquets inutilis\u00e9s...\"\nsudo apt autoremove -y\n\necho \"Nettoyage du cache APT...\"\nsudo apt clean\n\n# Section Snap\necho -e \"\\n--- Gestion Snap ---\"\necho \"V\u00e9rification des snaps...\"\nif command -v snap &amp;&gt; /dev/null; then\n    echo \"Mise \u00e0 jour des snaps...\"\n    sudo snap refresh\n\n    echo \"Snaps install\u00e9s :\"\n    snap list\nelse\n    echo \"Snap n'est pas install\u00e9\"\nfi\n\n# Rapport final\necho -e \"\\n=== Fin de la maintenance ===\"\necho \"Espace disque utilis\u00e9 :\"\ndf -h | grep -E \"^/dev\"\necho \"Date: $(date)\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#installation-dune-pile-de-developpement-complet","title":"Installation d'une pile de d\u00e9veloppement complet","text":"<p>Pour installer un environnement de d\u00e9veloppement web moderne :</p> Bash<pre><code>#!/bin/bash\n\necho \"Installation d'une pile de d\u00e9veloppement web...\"\n\n# Backend\necho \"Installation des outils backend...\"\nsudo apt install -y \\\n    git \\\n    curl \\\n    wget \\\n    build-essential \\\n    python3 \\\n    python3-pip \\\n    nodejs \\\n    npm \\\n    postgresql \\\n    postgresql-contrib\n\n# Frontend et outils\necho \"Installation des outils frontend...\"\nsudo apt install -y \\\n    ruby \\\n    ruby-dev\n\n# Snaps pour les applications modernes\necho \"Installation des snaps...\"\nsudo snap install --classic code\nsudo snap install postman\nsudo snap install docker\n\n# V\u00e9rification\necho \"V\u00e9rification de l'installation...\"\necho \"Git version: $(git --version)\"\necho \"Python version: $(python3 --version)\"\necho \"Node version: $(node --version)\"\necho \"PostgreSQL version: $(psql --version)\"\n\necho \"Installation termin\u00e9e !\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#resolution-des-problemes-courants","title":"R\u00e9solution des probl\u00e8mes courants \ud83d\udc1b","text":""},{"location":"_projects/_formation-bash/bash-chap05/#probleme-e-could-not-open-lock-file","title":"Probl\u00e8me : \u00ab E: Could not open lock file \u00bb","text":"<p>Cause : Une autre instance d'APT est en cours d'ex\u00e9cution.</p> <p>Solution :</p> Bash<pre><code>ps aux | grep apt\n</code></pre> <p>Attendre que les processus APT se terminent ou v\u00e9rifier s'il existe un gestionnaire graphique en cours d'ex\u00e9cution.</p>"},{"location":"_projects/_formation-bash/bash-chap05/#probleme-dependances-non-satisfaites","title":"Probl\u00e8me : D\u00e9pendances non satisfaites","text":"Bash<pre><code>sudo apt --fix-broken install\n</code></pre> <p>ou</p> Bash<pre><code>sudo apt install -f\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#probleme-paquet-introuvable","title":"Probl\u00e8me : Paquet introuvable","text":"<p>Si un paquet n'existe pas apr\u00e8s <code>sudo apt update</code>, s'assurer que les d\u00e9p\u00f4ts appropri\u00e9s sont activ\u00e9s :</p> Bash<pre><code>sudo add-apt-repository ppa:repository/ppa\nsudo apt update\nsudo apt install paquet\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#probleme-snap-refusant-de-sinstaller","title":"Probl\u00e8me : Snap refusant de s'installer","text":"<p>V\u00e9rifier que le service snapd est actif :</p> Bash<pre><code>sudo systemctl restart snapd\nsudo snap list\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap05/#conclusion-et-prochaines-etapes","title":"Conclusion et prochaines \u00e9tapes \ud83c\udf93","text":"<p>L'installation et la gestion des programmes sous Linux via APT et Snap repr\u00e9sente une comp\u00e9tence fondamentale pour tout administrateur ou d\u00e9veloppeur syst\u00e8me. APT offre stabilit\u00e9 et int\u00e9gration native aux syst\u00e8mes Debian/Ubuntu, tandis que Snap fournit modernit\u00e9, portabilit\u00e9 et automatisation.</p> <p>La ma\u00eetrise de ces deux outils permet de g\u00e9rer efficacement les applications syst\u00e8me et contribue \u00e0 maintenir un environnement Linux sain et performant. Le choix entre APT et Snap d\u00e9pend du contexte sp\u00e9cifique, de l'environnement de d\u00e9ploiement et des exigences en mati\u00e8re de performance et de stabilit\u00e9.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-bash/bash-chap06/","title":"Citations","text":"<ul> <li>https://www.hostwinds.fr/tutorials/how-to-use-nano-editor-linux</li> <li>https://www.hostinger.com/fr/tutoriels/nano</li> <li>https://blog.stephane-robert.info/docs/admin-serveurs/linux/nano/</li> <li>https://labex.io/fr/tutorials/linux-linux-simple-text-editing-271339</li> <li>https://tuto.joliciel.org/docs/OPS/Linux/Installer_utiliser_nano/</li> <li>https://www.youtube.com/watch?v=CTOfEcT7B1g</li> <li>http://doc.ubuntu-fr.org/nano</li> <li>https://www.youtube.com/watch?v=gKCmyYLyMIw</li> <li>https://www.framboise314.fr/wp-content/uploads/2018/09/Utiliser_nano.pdf</li> <li>https://nfrappe.fr/doc-0/doku.php?id=logiciel%3Asysteme%3Aediteurs%3Anano%3Astart</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap06/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 286</li> <li>completion_tokens: 4803</li> <li>total_tokens: 5089</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.072, 'request_cost': 0.006, 'total_cost': 0.079}</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap06/#content","title":"Content","text":""},{"location":"_projects/_formation-bash/bash-chap06/#chapitre-6-lire-modifier-et-compresser-des-fichiers","title":"Chapitre 6 : Lire, modifier et compresser des fichiers","text":""},{"location":"_projects/_formation-bash/bash-chap06/#les-extensions-de-fichier-et-la-commande-file","title":"Les extensions de fichier et la commande file","text":""},{"location":"_projects/_formation-bash/bash-chap06/#comprendre-les-extensions-de-fichier-sous-linux","title":"Comprendre les extensions de fichier sous Linux","text":"<p>Contrairement \u00e0 Windows, Linux ne d\u00e9pend pas des extensions de fichier pour identifier le type d'un fichier. Le syst\u00e8me utilise plut\u00f4t les informations internes du fichier (magic numbers) pour d\u00e9terminer sa nature r\u00e9elle. Les extensions servent principalement de convention de nommage pour les utilisateurs et les applications.</p> <p>Sous Linux, les extensions courantes incluent :</p> <ul> <li><code>.txt</code> pour les fichiers texte brut</li> <li><code>.sh</code> pour les scripts shell</li> <li><code>.log</code> pour les fichiers journaux</li> <li><code>.tar</code>, <code>.gz</code>, <code>.bz2</code> pour les archives compress\u00e9es</li> <li><code>.conf</code> pour les fichiers de configuration</li> <li><code>.bin</code> pour les fichiers binaires ex\u00e9cutables</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap06/#la-commande-file","title":"La commande file","text":"<p>La commande <code>file</code> permet d'identifier le type r\u00e9el d'un fichier en inspectant son contenu plut\u00f4t que son extension[1]. Cette commande lit les premiers octets du fichier (les magic numbers) pour d\u00e9terminer son type.</p> <p>Syntaxe basique :</p> Bash<pre><code>file nom_du_fichier\n</code></pre> <p>Exemples pratiques :</p> Bash<pre><code>file /etc/passwd\n# R\u00e9sultat : ASCII text\n\nfile /bin/bash\n# R\u00e9sultat : ELF 64-bit LSB executable\n\nfile image.jpg\n# R\u00e9sultat : JPEG image data, JFIF standard\n\nfile archive.tar.gz\n# R\u00e9sultat : gzip compressed data, from Unix\n</code></pre> <p>Options utiles :</p> Bash<pre><code># Afficher le type MIME\nfile -i document.pdf\n# R\u00e9sultat : application/pdf; charset=binary\n\n# Analyser plusieurs fichiers\nfile /etc/hostname /etc/hosts /etc/fstab\n\n# Inclure les fichiers sp\u00e9ciaux (sockets, pipes)\nfile -s /dev/sda\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap06/#cas-dusage-pratique","title":"Cas d'usage pratique","text":"<p>La commande <code>file</code> devient indispensable lors de la gestion de fichiers sans extension ou avec une extension erron\u00e9e :</p> Bash<pre><code># Un fichier nomm\u00e9 \"document\" sans extension\nfile document\n# Affiche le type r\u00e9el du fichier\n\n# V\u00e9rifier l'int\u00e9grit\u00e9 d'un t\u00e9l\u00e9chargement\nfile fichier_telecharge\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap06/#compresser-des-fichiers","title":"Compresser des fichiers","text":""},{"location":"_projects/_formation-bash/bash-chap06/#principes-fondamentaux-de-la-compression","title":"Principes fondamentaux de la compression","text":"<p>La compression r\u00e9duit la taille des fichiers en \u00e9liminant les donn\u00e9es redondantes. Linux propose plusieurs algorithmes de compression avec des niveaux de compression diff\u00e9rents affectant la taille finale et le temps de traitement.</p>"},{"location":"_projects/_formation-bash/bash-chap06/#loutil-gzip","title":"L'outil gzip","text":"<p>gzip est l'utilitaire de compression le plus courant sous Linux. Il utilise l'algorithme DEFLATE et cr\u00e9e des fichiers avec l'extension <code>.gz</code>.</p> <p>Compression simple :</p> Bash<pre><code>gzip fichier.txt\n# Cr\u00e9e : fichier.txt.gz (fichier original supprim\u00e9)\n</code></pre> <p>Compression sans supprimer l'original :</p> Bash<pre><code>gzip -c fichier.txt &gt; fichier.txt.gz\n</code></pre> <p>Niveaux de compression (1-9) :</p> Bash<pre><code># Compression rapide mais moins efficace\ngzip -1 fichier.txt\n\n# Compression optimale (d\u00e9faut : niveau 6)\ngzip -9 fichier.txt\n</code></pre> <p>D\u00e9compression :</p> Bash<pre><code>gunzip fichier.txt.gz\n# Ou\ngzip -d fichier.txt.gz\n</code></pre> <p>Afficher le contenu sans d\u00e9compresser :</p> Bash<pre><code>zcat fichier.txt.gz\nzless fichier.txt.gz\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap06/#loutil-bzip2","title":"L'outil bzip2","text":"<p>bzip2 offre une meilleure compression que gzip mais est plus lent. Les fichiers g\u00e9n\u00e9r\u00e9s utilisent l'extension <code>.bz2</code>.</p> Bash<pre><code># Compresser\nbzip2 fichier.txt\n\n# D\u00e9compresser\nbunzip2 fichier.txt.bz2\n# Ou\nbzip2 -d fichier.txt.bz2\n\n# Afficher le contenu\nbzcat fichier.txt.bz2\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap06/#loutil-xz","title":"L'outil xz","text":"<p>xz offre la meilleure compression mais au d\u00e9triment de la vitesse. Extension : <code>.xz</code>.</p> Bash<pre><code># Compresser\nxz fichier.txt\n\n# D\u00e9compresser\nunxz fichier.txt.xz\n# Ou\nxz -d fichier.txt.xz\n\n# Afficher le contenu\nxzcat fichier.txt.xz\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap06/#comparaison-des-algorithmes","title":"Comparaison des algorithmes","text":"Algorithme Extension Vitesse Compression Utilisation gzip .gz Rapide Moyenne G\u00e9n\u00e9ral, archives web bzip2 .bz2 Lent Bonne Distributions Linux xz .xz Tr\u00e8s lent Excellente Fichiers de source, distributions"},{"location":"_projects/_formation-bash/bash-chap06/#cas-dusage-pratique-compression-dun-repertoire","title":"Cas d'usage pratique : compression d'un r\u00e9pertoire","text":"<p>Bien que la compression simple s'applique \u00e0 des fichiers individuels, les r\u00e9pertoires complets n\u00e9cessitent d'abord une archivage :</p> Bash<pre><code># Cr\u00e9er une archive compress\u00e9e\ntar -czf backup.tar.gz /chemin/vers/repertoire/\n\n# Cr\u00e9er une archive avec bzip2\ntar -cjf backup.tar.bz2 /chemin/vers/repertoire/\n\n# Cr\u00e9er une archive avec xz\ntar -cJf backup.tar.xz /chemin/vers/repertoire/\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap06/#lediteur-de-texte-nano","title":"L'\u00e9diteur de texte nano","text":""},{"location":"_projects/_formation-bash/bash-chap06/#introduction-a-nano","title":"Introduction \u00e0 nano","text":"<p>Nano est un \u00e9diteur de texte en ligne de commande simple et convivial, d\u00e9j\u00e0 install\u00e9 sur la plupart des distributions Linux[3]. Contrairement \u00e0 des \u00e9diteurs comme Vim ou Emacs, nano ne n\u00e9cessite pas d'apprentissage complexe et constitue l'outil id\u00e9al pour les d\u00e9butants[4].</p>"},{"location":"_projects/_formation-bash/bash-chap06/#installation","title":"Installation","text":"<p>Sur les distributions bas\u00e9es sur Debian/Ubuntu :</p> Bash<pre><code>sudo apt-get install nano\n</code></pre> <p>Sur les distributions bas\u00e9es sur CentOS/RHEL :</p> Bash<pre><code>yum install nano\n</code></pre> <p>Nano est g\u00e9n\u00e9ralement pr\u00e9install\u00e9, cette \u00e9tape n'est donc souvent pas n\u00e9cessaire[2].</p>"},{"location":"_projects/_formation-bash/bash-chap06/#creer-et-ouvrir-des-fichiers","title":"Cr\u00e9er et ouvrir des fichiers","text":"<p>Cr\u00e9er un nouveau fichier :</p> Bash<pre><code>nano newfile.txt\n</code></pre> <p>Ouvrir un fichier existant :</p> Bash<pre><code>nano existingfile.txt\n</code></pre> <p>Une nouvelle fen\u00eatre s'ouvre affichant l'interface de l'\u00e9diteur. Les touches fl\u00e9ch\u00e9es du clavier permettent de d\u00e9placer le curseur[2].</p>"},{"location":"_projects/_formation-bash/bash-chap06/#raccourcis-clavier-essentiels","title":"Raccourcis clavier essentiels","text":""},{"location":"_projects/_formation-bash/bash-chap06/#navigation-dans-le-fichier","title":"Navigation dans le fichier","text":"Action Raccourci D\u00e9but de ligne <code>Ctrl + A</code> Fin de ligne <code>Ctrl + E</code> Aller \u00e0 une ligne sp\u00e9cifique <code>Ctrl + _</code> puis num\u00e9ro Page pr\u00e9c\u00e9dente <code>Ctrl + Y</code> Page suivante <code>Ctrl + V</code> D\u00e9placer caract\u00e8re par caract\u00e8re Fl\u00e8ches du clavier"},{"location":"_projects/_formation-bash/bash-chap06/#edition-de-texte","title":"\u00c9dition de texte","text":"Action Raccourci Enregistrer le fichier <code>Ctrl + O</code> Quitter nano <code>Ctrl + X</code> Couper la ligne en cours <code>Ctrl + K</code> Coller <code>Ctrl + U</code> Justifier un paragraphe <code>Ctrl + J</code> Annuler <code>Ctrl + _</code> puis <code>U</code> Afficher la position du curseur <code>Ctrl + C</code> Ins\u00e9rer un fichier <code>Ctrl + R</code>"},{"location":"_projects/_formation-bash/bash-chap06/#recherche-et-remplacement","title":"Recherche et remplacement","text":"Action Raccourci Chercher du texte <code>Ctrl + W</code> Recherche et remplacement <code>Ctrl + \\</code>"},{"location":"_projects/_formation-bash/bash-chap06/#selection-de-texte","title":"S\u00e9lection de texte","text":"<p>Pour s\u00e9lectionner du texte afin de le couper ou le copier :</p> Bash<pre><code># Activer/d\u00e9sactiver la marque\nAlt + A\n\n# Couper la s\u00e9lection\nCtrl + K\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap06/#flux-de-travail-typique","title":"Flux de travail typique","text":"<ol> <li>Ouvrir le fichier : <code>nano nom_fichier</code></li> <li>\u00c9diter le contenu en utilisant les fl\u00e8ches et les touches</li> <li>Enregistrer : <code>Ctrl + O</code> puis appuyer sur Entr\u00e9e</li> <li>Quitter : <code>Ctrl + X</code></li> </ol> <p>Si des modifications n'ont pas \u00e9t\u00e9 enregistr\u00e9es, nano invite \u00e0 sauvegarder avant la fermeture.</p>"},{"location":"_projects/_formation-bash/bash-chap06/#configuration-avancee-de-nano","title":"Configuration avanc\u00e9e de nano","text":"<p>La configuration de nano s'effectue via le fichier <code>~/.nanorc</code>. Pour \u00e9diter ce fichier :</p> Bash<pre><code>nano ~/.nanorc\n</code></pre> <p>Options de configuration courantes :</p> Bash<pre><code># Afficher les num\u00e9ros de ligne\nset linenumbers\n\n# Retour automatique \u00e0 la ligne\nset softwrap\n\n# D\u00e9finir la taille de tabulation \u00e0 4 espaces\nset tabsize 4\n\n# Conserver l'indentation d'une ligne \u00e0 l'autre\nset autoindent\n\n# Activer la souris pour cliquer et d\u00e9placer le curseur\nset mouse\n\n# Activer la coloration syntaxique pour Python\ninclude \"/usr/share/nano/python.nanorc\"\n\n# Activer la coloration syntaxique pour HTML\ninclude \"/usr/share/nano/html.nanorc\"\n</code></pre> <p>Application de la coloration syntaxique :</p> <p>Apr\u00e8s modification du fichier <code>.nanorc</code>, les changements s'appliquent au prochain lancement de nano[1].</p>"},{"location":"_projects/_formation-bash/bash-chap06/#conseil-dapprentissage-progressif","title":"Conseil d'apprentissage progressif","text":"<p>Il n'est pas n\u00e9cessaire de m\u00e9moriser tous les raccourcis imm\u00e9diatement[3]. L'apprentissage doit d\u00e9buter par les op\u00e9rations fondamentales :</p> <ul> <li><code>Ctrl + O</code> (enregistrer)</li> <li><code>Ctrl + X</code> (quitter)</li> <li><code>Ctrl + W</code> (chercher)</li> <li><code>Ctrl + K</code> / <code>Ctrl + U</code> (couper/coller)</li> </ul> <p>Les autres raccourcis s'int\u00e8grent progressivement selon les besoins. Rappel : tous les raccourcis disponibles s'affichent en bas de l'\u00e9cran pendant l'utilisation de nano, aucune m\u00e9morisation compl\u00e8te n'est donc requise[3].</p>"},{"location":"_projects/_formation-bash/bash-chap06/#lire-efficacement-des-fichiers-avec-less-tail-et-head","title":"Lire efficacement des fichiers avec less, tail et head","text":""},{"location":"_projects/_formation-bash/bash-chap06/#principes-daffichage-des-fichiers","title":"Principes d'affichage des fichiers","text":"<p>Afficher le contenu complet d'un fichier volumineux dans le terminal n'est pas toujours efficace. Linux propose des outils sp\u00e9cialis\u00e9s permettant une navigation fluide et un affichage partiel des contenus.</p>"},{"location":"_projects/_formation-bash/bash-chap06/#loutil-cat","title":"L'outil cat","text":"<p>cat affiche le contenu complet d'un fichier dans le terminal :</p> Bash<pre><code>cat /etc/passwd\n</code></pre> <p>Cet outil devient impraticable pour les fichiers volumineux, car l'affichage d\u00e9file rapidement sans possibilit\u00e9 de pause.</p>"},{"location":"_projects/_formation-bash/bash-chap06/#loutil-head","title":"L'outil head","text":"<p>head affiche les premi\u00e8res lignes d'un fichier. Par d\u00e9faut, elle affiche 10 lignes.</p> Bash<pre><code># Afficher les 10 premi\u00e8res lignes (par d\u00e9faut)\nhead /etc/passwd\n\n# Afficher les 20 premi\u00e8res lignes\nhead -n 20 /etc/passwd\n\n# Afficher les 5 premiers caract\u00e8res\nhead -c 5 /etc/passwd\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap06/#loutil-tail","title":"L'outil tail","text":"<p>tail affiche les derni\u00e8res lignes d'un fichier. Tr\u00e8s utile pour consulter les fichiers journaux.</p> Bash<pre><code># Afficher les 10 derni\u00e8res lignes (par d\u00e9faut)\ntail /var/log/syslog\n\n# Afficher les 20 derni\u00e8res lignes\ntail -n 20 /var/log/syslog\n\n# Afficher les lignes \u00e0 partir de la ligne 50\ntail -n +50 /var/log/syslog\n\n# Suivi en temps r\u00e9el (tr\u00e8s utile pour les logs)\ntail -f /var/log/syslog\n\n# Arr\u00eater le suivi : Ctrl + C\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap06/#loutil-less","title":"L'outil less","text":"<p>less est un visualiseur interactif permettant de naviguer dans un fichier avec une pagination compl\u00e8te. Contrairement \u00e0 <code>more</code>, <code>less</code> permet la navigation aussi bien vers l'avant que vers l'arri\u00e8re.</p> <p>Lancement :</p> Bash<pre><code>less /etc/passwd\n</code></pre> <p>Commandes de navigation dans less :</p> Commande Action <code>Barre d'espace</code> Avancer d'une page <code>B</code> Reculer d'une page <code>G</code> Aller \u00e0 la fin du fichier <code>1G</code> Aller au d\u00e9but du fichier <code>/texte</code> Chercher du texte en avant <code>?texte</code> Chercher du texte en arri\u00e8re <code>N</code> Aller \u00e0 l'occurrence suivante <code>Maj + N</code> Aller \u00e0 l'occurrence pr\u00e9c\u00e9dente <code>=</code> Afficher la position actuelle <code>Q</code> Quitter less"},{"location":"_projects/_formation-bash/bash-chap06/#cas-dusage-pratique_1","title":"Cas d'usage pratique","text":"<p>Consulter les fichiers journaux :</p> Bash<pre><code># Voir les 50 derni\u00e8res lignes du journal syst\u00e8me\ntail -n 50 /var/log/syslog\n\n# Suivre un journal en temps r\u00e9el\ntail -f /var/log/apache2/access.log\n\n# Naviguer dans un journal volumineux\nless /var/log/auth.log\n</code></pre> <p>Inspirer le d\u00e9but et la fin d'un fichier :</p> Bash<pre><code># Voir l'en-t\u00eate d'un fichier CSV\nhead -n 5 data.csv\n\n# Voir les derniers enregistrements\ntail -n 10 data.csv\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap06/#creer-des-archives","title":"Cr\u00e9er des archives","text":""},{"location":"_projects/_formation-bash/bash-chap06/#comprendre-larchivage-versus-la-compression","title":"Comprendre l'archivage versus la compression","text":"<p>L'archivage regroupe plusieurs fichiers et r\u00e9pertoires en un seul fichier conteneur. La compression r\u00e9duit ensuite la taille de cet archive. Ces deux op\u00e9rations sont souvent combin\u00e9es.</p>"},{"location":"_projects/_formation-bash/bash-chap06/#loutil-tar","title":"L'outil tar","text":"<p>tar (Tape Archive) cr\u00e9e des archives contenant plusieurs fichiers et r\u00e9pertoires, pr\u00e9servant la structure hi\u00e9rarchique[1].</p> <p>Syntaxe de base :</p> Bash<pre><code>tar [options] [archive.tar] [fichiers/r\u00e9pertoires]\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap06/#options-principales-de-tar","title":"Options principales de tar","text":"Option Signification <code>c</code> Cr\u00e9er une archive <code>x</code> Extraire une archive <code>v</code> Mode verbeux (afficher les fichiers trait\u00e9s) <code>f</code> Sp\u00e9cifier le nom du fichier archive <code>z</code> Compresser/d\u00e9compresser avec gzip (.tar.gz) <code>j</code> Compresser/d\u00e9compresser avec bzip2 (.tar.bz2) <code>J</code> Compresser/d\u00e9compresser avec xz (.tar.xz)"},{"location":"_projects/_formation-bash/bash-chap06/#creer-des-archives_1","title":"Cr\u00e9er des archives","text":"<p>Archive simple sans compression :</p> Bash<pre><code># Cr\u00e9er une archive\ntar -cvf backup.tar /home/user/documents/\n\n# Lister le contenu sans extraire\ntar -tvf backup.tar\n</code></pre> <p>Archive compress\u00e9e avec gzip :</p> Bash<pre><code># Cr\u00e9er et compresser\ntar -czf backup.tar.gz /home/user/documents/\n\n# Afficher le contenu du .tar.gz\ntar -tzf backup.tar.gz\n</code></pre> <p>Archive compress\u00e9e avec bzip2 :</p> Bash<pre><code># Cr\u00e9er et compresser\ntar -cjf backup.tar.bz2 /home/user/documents/\n\n# Afficher le contenu\ntar -tjf backup.tar.bz2\n</code></pre> <p>Archive compress\u00e9e avec xz :</p> Bash<pre><code># Cr\u00e9er et compresser\ntar -cJf backup.tar.xz /home/user/documents/\n\n# Afficher le contenu\ntar -tJf backup.tar.xz\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap06/#extraire-des-archives","title":"Extraire des archives","text":"<p>Extraire une archive simple :</p> Bash<pre><code># Extraire dans le r\u00e9pertoire courant\ntar -xvf backup.tar\n\n# Extraire dans un r\u00e9pertoire sp\u00e9cifique\ntar -xvf backup.tar -C /destination/\n</code></pre> <p>Extraire une archive compress\u00e9e :</p> Bash<pre><code># gzip (tar reconna\u00eet automatiquement le format)\ntar -xzf backup.tar.gz\n\n# bzip2\ntar -xjf backup.tar.bz2\n\n# xz\ntar -xJf backup.tar.xz\n\n# Ou simplement (tar d\u00e9tecte automatiquement)\ntar -xf backup.tar.gz\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap06/#cas-dusage-pratique-creer-une-sauvegarde-complete","title":"Cas d'usage pratique : cr\u00e9er une sauvegarde compl\u00e8te","text":"Bash<pre><code># Cr\u00e9er une sauvegarde dat\u00e9e et compress\u00e9e du r\u00e9pertoire personnel\ntar -czf backup_$(date +%Y%m%d).tar.gz /home/user/\n\n# Cr\u00e9er une archive excluant certains r\u00e9pertoires\ntar -czf backup.tar.gz --exclude='.cache' --exclude='.tmp' /home/user/\n\n# Cr\u00e9er une archive \u00e0 partir d'une liste de fichiers\ntar -czf selection.tar.gz /home/user/documents/ /home/user/images/ /etc/hostname\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap06/#comparaison-des-formats-darchive","title":"Comparaison des formats d'archive","text":"Format Taille Vitesse Utilisation .tar Tr\u00e8s grande Instantan\u00e9e Archivage seul .tar.gz Moyenne Rapide Sauvegarde g\u00e9n\u00e9rale .tar.bz2 Petite Lent Distributions Linux .tar.xz Tr\u00e8s petite Tr\u00e8s lent Distributions, sources"},{"location":"_projects/_formation-bash/bash-chap06/#parcours-dapprentissage-integre","title":"Parcours d'apprentissage int\u00e9gr\u00e9","text":""},{"location":"_projects/_formation-bash/bash-chap06/#phase-1-fondations-semaine-1","title":"Phase 1 : Fondations (Semaine 1)","text":"<p>L'apprentissage d\u00e9bute par la compr\u00e9hension des types de fichiers et l'utilisation de la commande <code>file</code> pour identifier les contenus. Cette \u00e9tape \u00e9tablit les bases conceptuelles n\u00e9cessaires.</p> <p>L'apprenant ex\u00e9cute plusieurs commandes <code>file</code> sur des fichiers vari\u00e9s du syst\u00e8me pour comprendre comment Linux cat\u00e9gorise les contenus ind\u00e9pendamment des extensions.</p>"},{"location":"_projects/_formation-bash/bash-chap06/#phase-2-edition-simple-semaine-2","title":"Phase 2 : \u00c9dition simple (Semaine 2)","text":"<p>Apr\u00e8s cette introduction, l'apprenant ma\u00eetrise nano en commen\u00e7ant par les op\u00e9rations basiques : cr\u00e9er un fichier, \u00e9diter du texte, enregistrer et quitter. Cette phase met l'accent sur l'acquisition de confiance plut\u00f4t que la m\u00e9morisation compl\u00e8te des raccourcis.</p> <p>Des exercices pratiques incluent la cr\u00e9ation de scripts simples, la modification de fichiers de configuration et l'utilisation des raccourcis fondamentaux.</p>"},{"location":"_projects/_formation-bash/bash-chap06/#phase-3-consultation-efficace-semaine-3","title":"Phase 3 : Consultation efficace (Semaine 3)","text":"<p>Une fois \u00e0 l'aise avec l'\u00e9dition, l'apprenant apprend \u00e0 lire efficacement les fichiers volumineux en utilisant <code>head</code>, <code>tail</code> et <code>less</code>. Cette \u00e9tape introduit les patterns r\u00e9els de travail : consulter les journaux syst\u00e8me, inspecter les premi\u00e8res lignes de fichiers de donn\u00e9es, naviguer dans les fichiers de configuration.</p> <p>Des cas d'usage pratiques incluent la surveillance en temps r\u00e9el avec <code>tail -f</code> et la navigation interactive avec <code>less</code>.</p>"},{"location":"_projects/_formation-bash/bash-chap06/#phase-4-gestion-des-espaces-disque-semaine-4","title":"Phase 4 : Gestion des espaces disque (Semaine 4)","text":"<p>La compression et l'archivage arrivent une fois que l'apprenant ma\u00eetrise la lecture et la modification de fichiers individuels. Cette phase traite de la gestion efficace des ressources disque.</p> <p>L'apprenant cr\u00e9e des archives de sauvegarde, compare l'efficacit\u00e9 des diff\u00e9rents algorithmes de compression et met en place une strat\u00e9gie de sauvegarde simple mais efficace.</p>"},{"location":"_projects/_formation-bash/bash-chap06/#integration-progressive","title":"Int\u00e9gration progressive","text":"<p>Chaque \u00e9tape renforce les connaissances pr\u00e9c\u00e9dentes :</p> <ol> <li>Identifier les fichiers avec <code>file</code> permet de savoir quand utiliser nano ou <code>less</code></li> <li>Ma\u00eetriser nano permet de cr\u00e9er les fichiers avant de les archiver</li> <li>Utiliser <code>head</code> et <code>tail</code> aide \u00e0 inspecter les contenus avant archivage</li> <li>Cr\u00e9er des archives et les compresser met en pratique toutes les comp\u00e9tences pr\u00e9c\u00e9dentes</li> </ol>"},{"location":"_projects/_formation-bash/bash-chap06/#exercices-pratiques-dintegration","title":"Exercices pratiques d'int\u00e9gration","text":"<p>Exercice 1 : Inspection et \u00e9dition</p> Bash<pre><code># 1. Identifier le type d'un fichier\nfile /etc/hostname\n\n# 2. \u00c9diter le fichier avec nano\nnano /etc/hostname\n\n# 3. Consulter les premi\u00e8res lignes\nhead /etc/hosts\n\n# 4. Consulter les derni\u00e8res lignes du journal\ntail /var/log/syslog\n</code></pre> <p>Exercice 2 : Archivage d'un projet</p> Bash<pre><code># 1. Cr\u00e9er une structure de projet\nmkdir -p projet/src projet/docs\n\n# 2. Cr\u00e9er des fichiers avec nano\nnano projet/src/main.sh\nnano projet/docs/README.txt\n\n# 3. Compresser l'archive\ntar -czf projet_backup.tar.gz projet/\n\n# 4. V\u00e9rifier l'archive\ntar -tzf projet_backup.tar.gz\n\n# 5. Nettoyer et extraire ailleurs\nrm -rf projet\ntar -xzf projet_backup.tar.gz\n</code></pre> <p>Exercice 3 : Gestion des logs</p> Bash<pre><code># 1. Consulter les derni\u00e8res entr\u00e9es\ntail -n 20 /var/log/auth.log\n\n# 2. Suivre un log en temps r\u00e9el\ntail -f /var/log/syslog\n\n# 3. Naviguer dans un log volumineux\nless /var/log/auth.log\n\n# 4. Archiver les anciens logs\ntar -czf logs_archive_$(date +%Y%m%d).tar.gz /var/log/*.log.1\n</code></pre> <p>Ce parcours d'apprentissage assure une progression logique o\u00f9 chaque comp\u00e9tence s'appuie sur les pr\u00e9c\u00e9dentes, cr\u00e9ant ainsi une base solide pour travailler efficacement avec les fichiers sous Linux.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-bash/bash-chap07/","title":"Citations","text":"<ul> <li>https://wiki.lezinter.net/_/Cours:Manipulation_de_fichiers_avec_Bash</li> <li>https://www.youtube.com/watch?v=jsl8yw8R0To</li> <li>https://www.it-connect.fr/trier-des-fichiers-selon-une-date-avec-find/</li> <li>https://www.youtube.com/watch?v=WZqUQPRSBBQ</li> <li>https://www.datanovia.com/books/linux/fr/data-manipulation.html</li> <li>https://blog.stephane-robert.info/docs/admin-serveurs/linux/commandes-avancees/</li> <li>https://abs.traduc.org/abs-fr/ch16s04.html</li> <li>https://fr.scribd.com/document/702285177/3-Exercices-Commandes-pipe</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap07/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 307</li> <li>completion_tokens: 6770</li> <li>total_tokens: 7077</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.102, 'request_cost': 0.006, 'total_cost': 0.108}</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap07/#content","title":"Content","text":""},{"location":"_projects/_formation-bash/bash-chap07/#guide-complet-rechercher-trier-et-filtrer-des-fichiers-sous-linux-et-bash","title":"\ud83d\udcda Guide Complet : Rechercher, Trier et Filtrer des Fichiers sous Linux et Bash","text":""},{"location":"_projects/_formation-bash/bash-chap07/#introduction-au-module","title":"\ud83c\udfaf Introduction au Module","text":"<p>La gestion efficace des fichiers constitue une comp\u00e9tence fondamentale dans l'administration Linux et la programmation Bash. Ce module pr\u00e9sente les outils essentiels permettant de localiser, manipuler et traiter les donn\u00e9es textuelles. Les commandes couvertes ici forment l'\u00e9pine dorsale du traitement de fichiers en ligne de commande, permettant d'accomplir des t\u00e2ches complexes de mani\u00e8re rapide et efficace.</p>"},{"location":"_projects/_formation-bash/bash-chap07/#1-localiser-un-fichier-rapidement-avec-locate","title":"1\ufe0f\u20e3 Localiser un Fichier Rapidement avec <code>locate</code>","text":"<p>La commande <code>locate</code> constitue le point de d\u00e9part pour la recherche de fichiers. Contrairement \u00e0 <code>find</code>, qui parcourt le syst\u00e8me de fichiers en temps r\u00e9el, <code>locate</code> consulte une base de donn\u00e9es pr\u00e9-index\u00e9e, offrant une recherche extr\u00eamement rapide.</p>"},{"location":"_projects/_formation-bash/bash-chap07/#fonctionnement-et-configuration","title":"Fonctionnement et Configuration","text":"<p><code>locate</code> maintient une base de donn\u00e9es des fichiers et r\u00e9pertoires du syst\u00e8me, mise \u00e0 jour quotidiennement par d\u00e9faut. Cette approche permet des recherches pratiquement instantan\u00e9es, m\u00eame sur des syst\u00e8mes volumineux contenant des millions de fichiers.</p> Bash<pre><code># Syntaxe basique\nlocate nom_fichier\n\n# Exemple concret\nlocate bash.rc\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#options-essentielles","title":"Options Essentielles","text":"Option Description Exemple <code>-i</code> Recherche insensible \u00e0 la casse <code>locate -i BASH.RC</code> <code>-c</code> Affiche le nombre de r\u00e9sultats <code>locate -c bash</code> <code>-r</code> Utilise les expressions r\u00e9guli\u00e8res <code>locate -r '\\.conf$'</code> <code>-S</code> Affiche les statistiques de la base <code>locate -S</code>"},{"location":"_projects/_formation-bash/bash-chap07/#mise-a-jour-de-la-base-de-donnees","title":"Mise \u00e0 Jour de la Base de Donn\u00e9es","text":"Bash<pre><code># Mettre \u00e0 jour manuellement la base de donn\u00e9es\nsudo updatedb\n\n# V\u00e9rifier le statut de la base\nlocate -S\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#limitation-et-precision","title":"Limitation et Pr\u00e9cision","text":"<p><code>locate</code> poss\u00e8de une limitation importante : elle ne d\u00e9tecte que les fichiers pr\u00e9sents dans sa base de donn\u00e9es. Les fichiers cr\u00e9\u00e9s r\u00e9cemment n'appara\u00eetront que lors de la prochaine mise \u00e0 jour. Pour une recherche en temps r\u00e9el, <code>find</code> s'av\u00e8re n\u00e9cessaire.</p>"},{"location":"_projects/_formation-bash/bash-chap07/#2-la-commande-find-recherche-avancee-de-fichiers","title":"2\ufe0f\u20e3 La Commande <code>find</code> : Recherche Avanc\u00e9e de Fichiers","text":""},{"location":"_projects/_formation-bash/bash-chap07/#presentation-generale-de-find","title":"Pr\u00e9sentation G\u00e9n\u00e9rale de <code>find</code>","text":"<p><code>find</code> constitue l'outil le plus puissant et flexible pour rechercher des fichiers sous Linux. Contrairement \u00e0 <code>locate</code>, elle effectue une recherche en temps r\u00e9el dans la hi\u00e9rarchie des r\u00e9pertoires, permettant l'application de crit\u00e8res de filtrage complexes.</p>"},{"location":"_projects/_formation-bash/bash-chap07/#syntaxe-fondamentale","title":"Syntaxe Fondamentale","text":"Bash<pre><code>find [chemin] [options] [crit\u00e8res] [actions]\n</code></pre> <p>D\u00e9composition : - chemin : Le r\u00e9pertoire de d\u00e9part (par d\u00e9faut, le r\u00e9pertoire courant) - options : Des drapeaux modifiant le comportement - crit\u00e8res : Les conditions de s\u00e9lection des fichiers - actions : Les op\u00e9rations \u00e0 effectuer sur les r\u00e9sultats</p>"},{"location":"_projects/_formation-bash/bash-chap07/#recherche-par-nom","title":"Recherche par Nom","text":"Bash<pre><code># Rechercher tous les fichiers .txt dans le r\u00e9pertoire courant\nfind . -name \"*.txt\"\n\n# Rechercher en ignorant la casse\nfind . -iname \"*.TXT\"\n\n# Recherche dans un r\u00e9pertoire sp\u00e9cifique\nfind /home/utilisateur -name \"document.pdf\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#recherche-par-type","title":"Recherche par Type","text":"Bash<pre><code># Rechercher uniquement les r\u00e9pertoires\nfind . -type d -name \"log*\"\n\n# Rechercher uniquement les fichiers r\u00e9guliers\nfind . -type f -name \"*.conf\"\n\n# Rechercher les liens symboliques\nfind . -type l\n\n# Rechercher les fichiers sp\u00e9ciaux (sockets, tuyaux)\nfind . -type s\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#recherche-par-date","title":"Recherche par Date","text":"<p>La recherche temporelle permet de filtrer les fichiers selon plusieurs crit\u00e8res de date[3] :</p> Bash<pre><code># Fichiers modifi\u00e9s il y a plus de 30 jours\nfind /home/mickael -type f -name \"*.txt\" -mtime +30\n\n# Fichiers modifi\u00e9s il y a moins de 7 jours\nfind . -type f -mtime -7\n\n# Fichiers modifi\u00e9s exactement il y a 1 jour\nfind . -type f -mtime 1\n</code></pre> <p>Les options temporelles principales :</p> Option Signification <code>-mtime</code> Date de derni\u00e8re modification (en jours) <code>-atime</code> Date de dernier acc\u00e8s (en jours) <code>-ctime</code> Date de dernier changement de m\u00e9tadonn\u00e9es (en jours) <code>-mmin</code> Date de modification (en minutes)[3] <code>-amin</code> Date d'acc\u00e8s (en minutes) <code>-cmin</code> Changement de m\u00e9tadonn\u00e9es (en minutes) <p>Notation des p\u00e9riodes : - <code>+N</code> : plus de N unit\u00e9s - <code>-N</code> : moins de N unit\u00e9s - <code>N</code> : exactement N unit\u00e9s</p> Bash<pre><code># Fichiers modifi\u00e9s il y a moins de 30 minutes\nfind /home/utilisateur -type f -name \"*.txt\" -mmin -30\n\n# Fichiers acc\u00e9d\u00e9s il y a plus d'une heure\nfind . -type f -amin +60\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#recherche-par-taille","title":"Recherche par Taille","text":"Bash<pre><code># Fichiers de plus de 100 Mo\nfind . -type f -size +100M\n\n# Fichiers de moins de 1 Mo\nfind . -type f -size -1M\n\n# Fichiers d'exactement 5 Ko\nfind . -type f -size 5k\n\n# Unit\u00e9s support\u00e9es : c (octets), k (Ko), M (Mo), G (Go)\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#recherche-par-permissions","title":"Recherche par Permissions","text":"Bash<pre><code># Fichiers lisibles par tous\nfind . -type f -perm -004\n\n# Fichiers accessibles en lecture/\u00e9criture pour le propri\u00e9taire uniquement\nfind . -type f -perm 600\n\n# Fichiers ex\u00e9cutables\nfind . -type f -perm /111\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#recherche-avancee-avec-conditions","title":"Recherche Avanc\u00e9e avec Conditions","text":"Bash<pre><code># Combiner plusieurs crit\u00e8res (AND logique)\nfind . -type f -name \"*.log\" -mtime +7\n\n# Fichiers ou r\u00e9pertoires (OR logique)\nfind . \\( -name \"*.tmp\" -o -name \"*.bak\" \\)\n\n# Exclusion de crit\u00e8res (NOT logique)\nfind . -type f ! -name \"*.txt\"\n\n# Plusieurs exclusions\nfind . -type f ! -name \"*.txt\" ! -name \"*.pdf\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#actions-sur-les-resultats","title":"Actions sur les R\u00e9sultats","text":"Bash<pre><code># Afficher les r\u00e9sultats (action par d\u00e9faut)\nfind . -type f -name \"*.log\" -print\n\n# Supprimer les fichiers trouv\u00e9s (attention !)\nfind . -type f -name \"*.tmp\" -delete\n\n# Ex\u00e9cuter une commande personnalis\u00e9e\nfind . -type f -name \"*.txt\" -exec cat {} \\;\n\n# Utiliser xargs pour passer les r\u00e9sultats \u00e0 une autre commande\nfind . -type f -name \"*.log\" | xargs ls -lh\n\n# Afficher les r\u00e9sultats s\u00e9par\u00e9s par des z\u00e9ros (plus s\u00fbr avec xargs)\nfind . -type f -name \"*.log\" -print0 | xargs -0 ls -lh\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#recherche-par-date-avec-format-avance","title":"Recherche par Date avec Format Avanc\u00e9","text":"<p>Une fonctionnalit\u00e9 m\u00e9connue permet de sp\u00e9cifier une date pr\u00e9cise[3] :</p> Bash<pre><code># Fichiers modifi\u00e9s apr\u00e8s une date sp\u00e9cifique\nfind . -newermt \"2025-03-04\"\n\n# Fichiers modifi\u00e9s avant une date\nfind . ! -newermt \"2025-03-04\"\n\n# Format complet avec heure\nfind . -newermt \"2025-03-04 21:01:39\"\n\n# Utiliser les variantes pour acc\u00e8s et changements\nfind . -neweract \"2025-03-04\"\nfind . -newerct \"2025-03-03\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#3-filtrer-les-donnees-avec-grep","title":"3\ufe0f\u20e3 Filtrer les Donn\u00e9es avec <code>grep</code>","text":""},{"location":"_projects/_formation-bash/bash-chap07/#introduction-a-grep","title":"Introduction \u00e0 <code>grep</code>","text":"<p><code>grep</code> signifie \"Global Regular Expression Print\". Cette commande recherche des lignes contenant un motif sp\u00e9cifique dans un fichier ou un flux de donn\u00e9es. Elle constitue l'outil de filtrage le plus utilis\u00e9 en Bash[1][4].</p>"},{"location":"_projects/_formation-bash/bash-chap07/#syntaxe-basique","title":"Syntaxe Basique","text":"Bash<pre><code># Rechercher un mot dans un fichier\ngrep motif fichier\n\n# Exemple concret\ngrep \"error\" /var/log/syslog\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#options-essentielles_1","title":"Options Essentielles","text":"Bash<pre><code># Recherche insensible \u00e0 la casse\ngrep -i \"ERROR\" fichier.txt\n\n# Afficher le num\u00e9ro de ligne\ngrep -n \"pattern\" fichier.txt\n\n# Inverser la s\u00e9lection (lignes ne contenant pas le motif)\ngrep -v \"pattern\" fichier.txt\n\n# Compter les occurrences\ngrep -c \"pattern\" fichier.txt\n\n# Afficher le contexte (lignes avant et apr\u00e8s)\ngrep -B 2 -A 2 \"pattern\" fichier.txt\n\n# Recherche r\u00e9cursive dans tous les fichiers et sous-r\u00e9pertoires\ngrep -r \"motif\" /chemin/\n\n# Expression r\u00e9guli\u00e8re \u00e9tendue\ngrep -E \"^[0-9]+\" fichier.txt\n\n# Afficher uniquement la partie correspondante du motif\ngrep -o \"pattern\" fichier.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#utilisation-avancee-avec-expressions-regulieres","title":"Utilisation Avanc\u00e9e avec Expressions R\u00e9guli\u00e8res","text":"Bash<pre><code># Rechercher les lignes commen\u00e7ant par un chiffre\ngrep \"^[0-9]\" fichier.txt\n\n# Lignes se terminant par \".txt\"\ngrep \"\\.txt$\" fichier.txt\n\n# Mots entiers uniquement\ngrep -w \"server\" config.conf\n\n# Une ou plusieurs occurrences\ngrep \"e\\+\" fichier.txt\n\n# Exactement deux occurrences\ngrep \"e\\{2\\}\" fichier.txt\n\n# Plages de caract\u00e8res\ngrep \"[a-zA-Z0-9]\" fichier.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#combinaison-avec-dautres-commandes","title":"Combinaison avec d'autres Commandes","text":"Bash<pre><code># Pipeline avec grep\ncat fichier.txt | grep \"error\"\n\n# Filtrer le r\u00e9sultat de ps\nps aux | grep \"bash\"\n\n# Compter les utilisateurs actifs\nwho | grep -c \"^\"\n\n# Afficher les fichiers contenant un motif sp\u00e9cifique\nls -la | grep \"\\.conf$\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#4-trier-les-resultats-avec-sort","title":"4\ufe0f\u20e3 Trier les R\u00e9sultats avec <code>sort</code>","text":""},{"location":"_projects/_formation-bash/bash-chap07/#principes-fondamentaux-de-sort","title":"Principes Fondamentaux de <code>sort</code>","text":"<p>La commande <code>sort</code> trie les lignes d'un fichier ou d'un flux de donn\u00e9es selon divers crit\u00e8res. Elle constitue un \u00e9l\u00e9ment incontournable du traitement de donn\u00e9es en Bash[1][6][7].</p>"},{"location":"_projects/_formation-bash/bash-chap07/#tri-basique","title":"Tri Basique","text":"Bash<pre><code># Tri alphab\u00e9tique croissant (par d\u00e9faut)\nsort fichier.txt\n\n# Tri alphab\u00e9tique d\u00e9croissant\nsort -r fichier.txt\n\n# Tri num\u00e9rique (important pour les nombres)\nsort -n fichier.txt\n\n# Tri num\u00e9rique d\u00e9croissant\nsort -nr fichier.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#options-de-tri-specialisees","title":"Options de Tri Sp\u00e9cialis\u00e9es","text":"Option Description Exemple <code>-f</code> Ignorer la casse (majuscules/minuscules) <code>sort -f fichier.txt</code> <code>-d</code> Tri dictionnaire <code>sort -d fichier.txt</code> <code>-u</code> Unique (supprimer les doublons) <code>sort -u fichier.txt</code> <code>-R</code> M\u00e9lange al\u00e9atoire[5] <code>sort -R fichier.txt</code> <code>-k</code> Trier sur une colonne sp\u00e9cifique <code>sort -k 2 fichier.txt</code> <code>-t</code> D\u00e9finir le s\u00e9parateur de champs <code>sort -t: -k 1 /etc/passwd</code>"},{"location":"_projects/_formation-bash/bash-chap07/#tri-sur-colonnes-et-champs","title":"Tri sur Colonnes et Champs","text":"Bash<pre><code># Tri sur la premi\u00e8re colonne (index 1)\nsort -k 1 donnees.csv\n\n# Tri sur la deuxi\u00e8me colonne\nsort -k 2 donnees.txt\n\n# Tri sur le 5\u00e8me caract\u00e8re de la premi\u00e8re colonne\nsort -k 1.5 donnees.csv\n\n# D\u00e9finir un s\u00e9parateur personnalis\u00e9 (deux-points)\nsort -t: -k 3 -n /etc/passwd\n\n# Tri primaire sur colonne 1, tri secondaire sur colonne 2\nsort -k 1,1 -k 2,2n donnees.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#combinaison-avec-dautres-commandes_1","title":"Combinaison avec d'autres Commandes","text":"Bash<pre><code># Obtenir le nombre minimum/maximum\nsort -n fichier.txt | head -n 1  # Minimum\nsort -n fichier.txt | tail -n 1  # Maximum\n\n# Combiner avec uniq pour analyser les doublons\nsort fichier.txt | uniq\n\n# Supprimer les doublons et afficher la fr\u00e9quence\nsort fichier.txt | uniq -c\n\n# Tri par fr\u00e9quence (le plus courant en premier)\nsort fichier.txt | uniq -c | sort -nr\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#5-commandes-de-manipulation-de-texte-rev-tac-cut-uniq","title":"5\ufe0f\u20e3 Commandes de Manipulation de Texte : <code>rev</code>, <code>tac</code>, <code>cut</code>, <code>uniq</code>","text":""},{"location":"_projects/_formation-bash/bash-chap07/#rev-inverser-les-lignes","title":"<code>rev</code> : Inverser les Lignes","text":"<p>La commande <code>rev</code> inverse l'ordre des caract\u00e8res dans chaque ligne, utile pour des manipulations textuelles sp\u00e9ciales.</p> Bash<pre><code># Inverser les caract\u00e8res d'une ligne\necho \"hello\" | rev\n# R\u00e9sultat : olleh\n\n# Inverser le contenu d'un fichier ligne par ligne\nrev fichier.txt\n\n# Trouver les rimes (inverser les mots pour comparer les terminaisons)\ncat texte.txt | tr ' ' '\\n' | rev | sort | uniq -c\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#tac-inverser-lordre-des-lignes","title":"<code>tac</code> : Inverser l'Ordre des Lignes","text":"<p><code>tac</code> (l'inverse de <code>cat</code>) affiche un fichier en ordre inverse, ligne par ligne.</p> Bash<pre><code># Afficher un fichier de bas en haut\ntac fichier.txt\n\n# Combiner avec grep pour obtenir la derni\u00e8re occurrence\ntac fichier.log | grep \"error\" | head -n 1\n\n# Consulter les \u00e9v\u00e9nements les plus r\u00e9cents en premier\ntac /var/log/syslog | head -n 20\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#cut-extraire-des-colonnes","title":"<code>cut</code> : Extraire des Colonnes","text":"<p><code>cut</code> extrait des colonnes ou des champs sp\u00e9cifiques d'un fichier texte.</p> Bash<pre><code># Extraire les caract\u00e8res 1 \u00e0 5\ncut -c 1-5 fichier.txt\n\n# Extraire les caract\u00e8res 1, 3, 5\ncut -c 1,3,5 fichier.txt\n\n# Extraire un champ avec s\u00e9parateur\ncut -d: -f 1 /etc/passwd  # Affiche les noms d'utilisateurs\n\n# Extraire plusieurs champs\ncut -d, -f 1,3 donnees.csv\n\n# Compl\u00e9ment de s\u00e9lection (tous sauf le champ 2)\ncut -d: -f 1,3- /etc/passwd\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#uniq-supprimer-ou-analyser-les-doublons","title":"<code>uniq</code> : Supprimer ou Analyser les Doublons","text":"<p><code>uniq</code> d\u00e9tecte ou supprime les lignes dupliqu\u00e9es cons\u00e9cutives[1].</p> Bash<pre><code># Supprimer les doublons cons\u00e9cutifs (doit \u00eatre tri\u00e9 d'abord)\nsort fichier.txt | uniq\n\n# Afficher uniquement les doublons\nsort fichier.txt | uniq -d\n\n# Afficher les hapax (lignes uniques)\nsort fichier.txt | uniq -u\n\n# Compter les occurrences de chaque ligne\nsort fichier.txt | uniq -c\n\n# Afficher le nombre de doublons seulement\nsort fichier.txt | uniq -c | grep -v \"^[[:space:]]*1\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#cas-dusage-integre-analyse-de-mots","title":"Cas d'Usage Int\u00e9gr\u00e9 : Analyse de Mots","text":"Bash<pre><code># Convertir un texte en liste de mots tri\u00e9s avec fr\u00e9quence[1]\ncat texte.txt | tr ' ' '\\n' | sort | uniq -c | sort -nr\n\n# Trouver les mots apparaissant exactement 5 fois\ncat texte.txt | tr ' ' '\\n' | sort | uniq -c | grep \"^[[:space:]]*5\"\n\n# Rechercher un mot sp\u00e9cifique dans la liste des mots\ncat texte.txt | tr ' ' '\\n' | sort | uniq -c | grep \"saucisson\"\n\n# Analyser les rimes (mots invers\u00e9s)[1]\ncat texte.txt | tr ' ' '\\n' | rev | sort | uniq -c\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#6-la-commande-sed-edition-de-flux","title":"6\ufe0f\u20e3 La Commande <code>sed</code> : \u00c9dition de Flux","text":""},{"location":"_projects/_formation-bash/bash-chap07/#introduction-a-sed","title":"Introduction \u00e0 <code>sed</code>","text":"<p><code>sed</code> (Stream EDitor) \u00e9dite des flux de texte selon des commandes sp\u00e9cifi\u00e9es, permettant de transformer du texte de mani\u00e8re automatis\u00e9e et script\u00e9e.</p>"},{"location":"_projects/_formation-bash/bash-chap07/#syntaxe-basique_1","title":"Syntaxe Basique","text":"Bash<pre><code>sed [options] 'commande' fichier\n\n# Option -e pour plusieurs commandes\nsed -e 'commande1' -e 'commande2' fichier\n\n# Option -i pour \u00e9diter en place\nsed -i 'commande' fichier\n\n# En mode pipeline\ncat fichier | sed 'commande'\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#substitution-commande-s","title":"Substitution : Commande <code>s</code>","text":"Bash<pre><code># Substitution basique (premi\u00e8re occurrence par ligne)\nsed 's/ancien/nouveau/' fichier.txt\n\n# Substitution globale (toutes les occurrences)\nsed 's/ancien/nouveau/g' fichier.txt\n\n# Substitution avec confirmation interactive\nsed 's/ancien/nouveau/p' fichier.txt\n\n# Insensible \u00e0 la casse\nsed 's/ancien/nouveau/i' fichier.txt\n\n# Afficher uniquement les lignes modifi\u00e9es (avec -n)\nsed -n 's/ancien/nouveau/p' fichier.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#selection-de-lignes","title":"S\u00e9lection de Lignes","text":"Bash<pre><code># Op\u00e9rer sur les lignes 1 \u00e0 5\nsed '1,5s/ancien/nouveau/' fichier.txt\n\n# Op\u00e9rer sur la ligne 10 uniquement\nsed '10s/ancien/nouveau/' fichier.txt\n\n# Op\u00e9rer sur les lignes correspondant \u00e0 un motif\nsed '/pattern/s/ancien/nouveau/' fichier.txt\n\n# Plages avec motifs\nsed '/debut/,/fin/s/ancien/nouveau/' fichier.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#suppressions-et-additions","title":"Suppressions et Additions","text":"Bash<pre><code># Supprimer les lignes vides\nsed '/^$/d' fichier.txt\n\n# Supprimer les lignes contenant un motif\nsed '/motif/d' fichier.txt\n\n# Supprimer les lignes 1 \u00e0 5\nsed '1,5d' fichier.txt\n\n# Ajouter une ligne apr\u00e8s une ligne correspondante\nsed '/motif/a\\Nouvelle ligne' fichier.txt\n\n# Ins\u00e9rer une ligne avant une ligne correspondante\nsed '/motif/i\\Nouvelle ligne' fichier.txt\n\n# Remplacer une ligne enti\u00e8re\nsed '/motif/c\\Ligne de remplacement' fichier.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#extraction-et-affichage-selectif","title":"Extraction et Affichage S\u00e9lectif","text":"Bash<pre><code># Afficher uniquement les lignes 10 \u00e0 20\nsed -n '10,20p' fichier.txt\n\n# Afficher les lignes correspondant \u00e0 un motif\nsed -n '/motif/p' fichier.txt\n\n# Afficher les lignes pr\u00e9c\u00e9dant un motif\nsed -n '/motif/!p' fichier.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#expressions-regulieres-dans-sed","title":"Expressions R\u00e9guli\u00e8res dans <code>sed</code>","text":"Bash<pre><code># Utiliser des groupes de capture\nsed 's/\\([a-z]*\\) \\([a-z]*\\)/\\2 \\1/' fichier.txt\n\n# Caract\u00e8res sp\u00e9ciaux\nsed 's/\\$/\u20ac/g' fichier.txt\n\n# D\u00e9limiteurs personnalis\u00e9s (utile pour les chemins)\nsed 's|/ancien/chemin|/nouveau/chemin|g' fichier.txt\n\n# Ancres de ligne\nsed 's/^/PREFIX-/' fichier.txt  # Ajouter un pr\u00e9fixe\nsed 's/$/-SUFFIX/' fichier.txt  # Ajouter un suffixe\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#7-la-commande-awk-traitement-avance-de-donnees","title":"7\ufe0f\u20e3 La Commande <code>awk</code> : Traitement Avanc\u00e9 de Donn\u00e9es","text":""},{"location":"_projects/_formation-bash/bash-chap07/#introduction-a-awk","title":"Introduction \u00e0 <code>awk</code>","text":"<p><code>awk</code> constitue un outil puissant pour l'analyse et la transformation de donn\u00e9es textuelles structur\u00e9es. Contrairement \u00e0 <code>sed</code> qui op\u00e8re ligne par ligne, <code>awk</code> traite les donn\u00e9es champ par champ, offrant des capacit\u00e9s de programmation plus avanc\u00e9es.</p>"},{"location":"_projects/_formation-bash/bash-chap07/#principes-fondamentaux","title":"Principes Fondamentaux","text":"Bash<pre><code># Syntaxe de base\nawk 'pattern { action }' fichier\n\n# Afficher la totalit\u00e9 du fichier\nawk '{ print }' fichier.txt\n\n# Afficher le premier champ (colonne)\nawk '{ print $1 }' fichier.txt\n\n# Afficher les champs 1 et 3\nawk '{ print $1, $3 }' fichier.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#variables-speciales","title":"Variables Sp\u00e9ciales","text":"Variable Description <code>$0</code> Ligne enti\u00e8re <code>$1, $2, ...</code> Champs individuels <code>NF</code> Nombre de champs <code>NR</code> Num\u00e9ro de ligne courant <code>FILENAME</code> Nom du fichier trait\u00e9 <code>FS</code> S\u00e9parateur de champs (par d\u00e9faut : espace) <code>OFS</code> S\u00e9parateur de sortie <code>ORS</code> S\u00e9parateur de ligne de sortie"},{"location":"_projects/_formation-bash/bash-chap07/#utilisation-pratique","title":"Utilisation Pratique","text":"Bash<pre><code># Afficher avec un s\u00e9parateur personnalis\u00e9\nawk -F: '{ print $1, $3 }' /etc/passwd\n\n# Afficher le nombre de champs par ligne\nawk '{ print NF }' fichier.txt\n\n# Afficher le num\u00e9ro de ligne et le contenu\nawk '{ print NR, $0 }' fichier.txt\n\n# Afficher les lignes plus longues que 80 caract\u00e8res\nawk 'length($0) &gt; 80 { print }' fichier.txt\n\n# Filtrer les lignes correspondant \u00e0 une condition\nawk '$3 &gt; 100 { print $1, $3 }' donnees.txt\n\n# Afficher les champs en ordre inverse\nawk '{ for(i=NF; i&gt;=1; i--) printf \"%s \", $i; print \"\" }' fichier.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#motifs-et-conditions","title":"Motifs et Conditions","text":"Bash<pre><code># Motif sp\u00e9cifique\nawk '/pattern/ { print }' fichier.txt\n\n# Lignes ne correspondant pas au motif\nawk '!/pattern/ { print }' fichier.txt\n\n# Condition num\u00e9rique\nawk '$2 &gt; 50 { print $1, $2 }' donnees.txt\n\n# Condition combin\u00e9e\nawk '$1 == \"admin\" &amp;&amp; $3 &gt; 1000 { print }' fichier.txt\n\n# Lignes vides\nawk 'NF == 0 { print \"Ligne vide d\u00e9tect\u00e9e\" }' fichier.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#actions-avancees","title":"Actions Avanc\u00e9es","text":"Bash<pre><code># Calculer la somme d'une colonne\nawk '{ sum += $2 } END { print \"Total:\", sum }' donnees.txt\n\n# Compter les occurrences\nawk '{ count[$1]++ } END { for(mot in count) print mot, count[mot] }' fichier.txt\n\n# Moyenne d'une colonne\nawk '{ sum += $2; n++ } END { print \"Moyenne:\", sum/n }' donnees.txt\n\n# Afficher les lignes dupliqu\u00e9es\nawk '!seen[$0]++' fichier.txt\n\n# Traiter les d\u00e9but et fin d'un fichier\nawk 'BEGIN { print \"D\u00e9but du traitement\" } { print NR, $0 } END { print \"Total:\", NR }' fichier.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#cas-dusage-pratique-analyse-dacces","title":"Cas d'Usage Pratique : Analyse d'Acc\u00e8s","text":"Bash<pre><code># Compter les acc\u00e8s par adresse IP dans un fichier log\nawk '{ print $1 }' access.log | sort | uniq -c | sort -nr\n\n# Extraire et analyser les heures de connexion\nawk '{ print $4 }' access.log | cut -d: -f1 | sort | uniq -c\n\n# Calculer le volume de donn\u00e9es par utilisateur\nawk '{ total[$1] += $10 } END { for(user in total) print user, total[user] }' access.log\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#8-integration-pratique-pipeline-complet","title":"8\ufe0f\u20e3 Int\u00e9gration Pratique : Pipeline Complet","text":""},{"location":"_projects/_formation-bash/bash-chap07/#exemple-complet-analyse-de-fichier-log","title":"Exemple Complet : Analyse de Fichier Log","text":"Bash<pre><code># Rechercher les erreurs, les trier par fr\u00e9quence, et afficher les top 10\ngrep \"ERROR\" /var/log/application.log | \\\n  awk '{ print $NF }' | \\\n  sort | \\\n  uniq -c | \\\n  sort -nr | \\\n  head -n 10\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#exemple-traitement-de-donnees-csv","title":"Exemple : Traitement de Donn\u00e9es CSV","text":"Bash<pre><code># Extraire les utilisateurs avec un salaire sup\u00e9rieur \u00e0 50000\nawk -F, '$3 &gt; 50000 { print $1, $2, $3 }' employes.csv | \\\n  sort -t, -k3 -nr\n\n# G\u00e9n\u00e9rer un rapport\nawk -F, 'BEGIN { print \"Rapport des employ\u00e9s\" } \\\n  { sum += $3; count++ } \\\n  END { print \"Salaire moyen:\", sum/count }' employes.csv\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#exemple-nettoyage-de-fichier","title":"Exemple : Nettoyage de Fichier","text":"Bash<pre><code># Supprimer les espaces en d\u00e9but et fin de ligne, puis les doublons\nsed 's/^[[:space:]]*//;s/[[:space:]]*$//' fichier.txt | \\\n  sort | \\\n  uniq &gt; fichier_propre.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap07/#9-chemin-dapprentissage-recommande","title":"9\ufe0f\u20e3 Chemin d'Apprentissage Recommand\u00e9","text":""},{"location":"_projects/_formation-bash/bash-chap07/#phase-1-les-fondamentaux-semaine-1","title":"Phase 1 : Les Fondamentaux (Semaine 1)","text":"<p>Commencer par ma\u00eetriser les commandes de base :</p> <ol> <li><code>locate</code> et <code>find</code> : Comprendre comment parcourir le syst\u00e8me de fichiers</li> <li><code>grep</code> : Apprendre \u00e0 filtrer du contenu texte</li> <li><code>sort</code> : Ma\u00eetriser les diff\u00e9rents types de tri</li> </ol> <p>\u00c0 cette phase, l'apprenti doit \u00eatre capable de : - Localiser un fichier sp\u00e9cifique - Rechercher du texte dans des fichiers - Trier des listes de donn\u00e9es</p>"},{"location":"_projects/_formation-bash/bash-chap07/#phase-2-manipulation-intermediaire-semaine-2-3","title":"Phase 2 : Manipulation Interm\u00e9diaire (Semaine 2-3)","text":"<p>Progresser vers des outils de transformation :</p> <ol> <li><code>rev</code>, <code>tac</code>, <code>cut</code>, <code>uniq</code> : Manipuler la structure du texte</li> <li>Combinaison de pipelines : Cha\u00eener plusieurs commandes</li> </ol> <p>Les comp\u00e9tences acquises : - Transformer et restructurer des donn\u00e9es - Extraire des colonnes sp\u00e9cifiques - D\u00e9tecter et g\u00e9rer les doublons</p>"},{"location":"_projects/_formation-bash/bash-chap07/#phase-3-edition-et-traitement-semaine-4-5","title":"Phase 3 : \u00c9dition et Traitement (Semaine 4-5)","text":"<p>Approfondir avec des outils puissants :</p> <ol> <li><code>sed</code> : \u00c9dition en flux, substitution, extraction s\u00e9lective</li> <li><code>awk</code> : Traitement avanc\u00e9 de donn\u00e9es, programmation l\u00e9g\u00e8re</li> </ol> <p>\u00c0 cette \u00e9tape, la capacit\u00e9 \u00e0 traiter des fichiers volumineux et complexes se d\u00e9veloppe.</p>"},{"location":"_projects/_formation-bash/bash-chap07/#phase-4-integration-et-automatisation-semaine-6","title":"Phase 4 : Int\u00e9gration et Automatisation (Semaine 6+)","text":"<p>Combiner tous les outils :</p> <ol> <li>Cr\u00e9er des scripts Bash complexes utilisant les pipelines</li> <li>Automatiser le traitement de donn\u00e9es r\u00e9currentes</li> <li>Optimiser les performances pour les gros fichiers</li> </ol>"},{"location":"_projects/_formation-bash/bash-chap07/#progression-pratique-exercices-suggeres","title":"Progression Pratique : Exercices Sugg\u00e9r\u00e9s","text":"<p>Niveau 1 : Recherche Bash<pre><code># Trouver tous les fichiers .sh modifi\u00e9s aujourd'hui\nfind . -name \"*.sh\" -type f -mtime 0\n\n# Chercher les erreurs de connexion en SSH\ngrep \"Failed password\" /var/log/auth.log\n</code></pre></p> <p>Niveau 2 : Tri et Analyse Bash<pre><code># Afficher les top 5 des utilisateurs ayant le plus de fichiers\nfind /home -type f | cut -d/ -f3 | sort | uniq -c | sort -nr | head -5\n\n# G\u00e9n\u00e9rer un rapport de fr\u00e9quence de mots\ncat fichier.txt | tr ' ' '\\n' | grep -v '^$' | sort | uniq -c | sort -nr\n</code></pre></p> <p>Niveau 3 : Transformation Avanc\u00e9e Bash<pre><code># Convertir CSV en format humanis\u00e9\nawk -F, 'BEGIN { print \"Nom\\tD\u00e9partement\\tSalaire\" } \\\n  { printf \"%s\\t%s\\t%.2f\u20ac\\n\", $1, $2, $3 }' employes.csv\n\n# Nettoyer et analyser un fichier log\nsed 's/\\[.*\\]//g' access.log | awk '{ print $1 }' | \\\n  sort | uniq -c | sort -nr\n</code></pre></p> <p>Niveau 4 : Cas R\u00e9el Bash<pre><code># G\u00e9n\u00e9rer un rapport quotidien des erreurs syst\u00e8me\ngrep \"$(date +%Y-%m-%d)\" /var/log/syslog | \\\n  grep -i \"error\\|critical\" | \\\n  awk '{ print $NF }' | \\\n  sort | uniq -c | sort -nr &gt; rapport_erreurs.txt\n\n# Archiver les fichiers log anciens\nfind /var/log -name \"*.log\" -type f -mtime +30 -exec gzip {} \\;\n</code></pre></p>"},{"location":"_projects/_formation-bash/bash-chap07/#conclusion-et-points-cles","title":"\ud83d\udd1f Conclusion et Points Cl\u00e9s","text":"<p>La ma\u00eetrise de ces commandes constitue la fondation d'une utilisation efficace de Linux et Bash. Chaque outil poss\u00e8de un objectif sp\u00e9cifique :</p> <ul> <li>Localisation : <code>locate</code>, <code>find</code></li> <li>Filtrage : <code>grep</code></li> <li>Tri : <code>sort</code></li> <li>Transformation : <code>rev</code>, <code>tac</code>, <code>cut</code>, <code>uniq</code></li> <li>\u00c9dition : <code>sed</code></li> <li>Analyse Avanc\u00e9e : <code>awk</code></li> </ul> <p>L'apprentissage progressif, partant des commandes simples vers des combinaisons complexes, permet de construire une compr\u00e9hension solide. La pratique r\u00e9guli\u00e8re avec des cas r\u00e9els consolide ces connaissances et d\u00e9veloppe l'intuition n\u00e9cessaire pour r\u00e9soudre efficacement les probl\u00e8mes courants d'administration syst\u00e8me et de traitement de donn\u00e9es.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-bash/bash-chap08/","title":"Citations","text":"<ul> <li>https://tutoriels.lws.fr/vps/initiation-au-script-bash-linux-avec-exemples</li> <li>https://www.datacamp.com/fr/tutorial/how-to-write-bash-script-tutorial</li> <li>https://blog.stephane-robert.info/docs/admin-serveurs/linux/shells-linux/bash/</li> <li>https://www-inf.telecom-sudparis.eu/COURS/CSC3102/Supports/ci5-processus/ci-processus.pptx.pdf</li> <li>https://www.hostinger.com/fr/tutoriels/gerer-processus-linux-ligne-commande</li> <li>https://linux.goffinet.org/administration/processus-et-demarrage/processus-linux/</li> <li>https://perso.liris.cnrs.fr/pierre-antoine.champin/enseignement/linux/s4.html</li> <li>https://serverspace.io/fr/support/help/bash-cheat-sheet/</li> <li>https://www.it-connect.fr/cours-tutoriels/administration-systemes/scripting/bash/</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap08/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 295</li> <li>completion_tokens: 6893</li> <li>total_tokens: 7188</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.103, 'request_cost': 0.006, 'total_cost': 0.11}</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap08/#content","title":"Content","text":""},{"location":"_projects/_formation-bash/bash-chap08/#les-processus-sous-linux-et-bash-guide-complet","title":"\ud83d\udcda Les Processus sous Linux et Bash - Guide Complet","text":""},{"location":"_projects/_formation-bash/bash-chap08/#introduction-aux-processus","title":"Introduction aux Processus \ud83d\udd04","text":"<p>Un processus est l'ex\u00e9cution d'un programme en cours d'ex\u00e9cution sous Linux[7]. Chaque processus qui s'ex\u00e9cute sur un syst\u00e8me Linux est une instance ind\u00e9pendante d'un programme avec son propre contexte d'ex\u00e9cution, ses ressources et son identifiant unique. Comprendre le fonctionnement des processus est fondamental pour administrer un syst\u00e8me Linux efficacement, car ils constituent les briques \u00e9l\u00e9mentaires de tout ce qui s'ex\u00e9cute sur la machine.</p>"},{"location":"_projects/_formation-bash/bash-chap08/#identification-des-processus","title":"Identification des Processus","text":"<p>Chaque processus en cours d'ex\u00e9cution sur un syst\u00e8me Linux re\u00e7oit un num\u00e9ro unique appel\u00e9 PID (Process IDentifier)[7]. Ce PID permet de r\u00e9f\u00e9rencer, contr\u00f4ler et monitorer le processus. Au-del\u00e0 du PID, chaque processus poss\u00e8de \u00e9galement un PPID (Parent Process IDentifier), qui est l'identifiant du processus parent qui l'a cr\u00e9\u00e9. Cette relation parent-enfant cr\u00e9e une hi\u00e9rarchie de processus o\u00f9 chaque processus (\u00e0 l'exception du processus init avec le PID 1) a un processus parent.</p> <p>Au sein des scripts Bash, plusieurs variables sp\u00e9ciales permettent d'acc\u00e9der \u00e0 des informations relatives aux processus[4]:</p> <ul> <li>$$ : Repr\u00e9sente le PID du processus Bash courant</li> <li>$PPID : Repr\u00e9sente le PID du processus parent du Bash courant</li> </ul> <p>Ces variables permettent au programmeur d'interroger l'environnement de son script et de comprendre sa place dans l'\u00e9cosyst\u00e8me des processus en cours.</p>"},{"location":"_projects/_formation-bash/bash-chap08/#variables-denvironnement-essentielles","title":"Variables d'Environnement Essentielles","text":"<p>L'environnement de chaque processus contient plusieurs variables critiques[4]:</p> <ul> <li>PS1 : Le prompt par d\u00e9faut (g\u00e9n\u00e9ralement <code>$</code>)</li> <li>PATH : Liste des r\u00e9pertoires o\u00f9 le syst\u00e8me cherche les commandes ex\u00e9cutables, avec les chemins s\u00e9par\u00e9s par des deux-points <code>:</code></li> </ul> <p>La commande <code>env</code> affiche l'ensemble des variables d'environnement du processus courant[4], ce qui permet de diagnostiquer le contexte d'ex\u00e9cution.</p>"},{"location":"_projects/_formation-bash/bash-chap08/#visualiser-les-processus-en-temps-reel-avec-top","title":"Visualiser les Processus en Temps R\u00e9el avec top \u23f1\ufe0f","text":""},{"location":"_projects/_formation-bash/bash-chap08/#presentation-et-utilisation","title":"Pr\u00e9sentation et Utilisation","text":"<p>La commande <code>top</code> est un outil interactif qui affiche une liste dynamique et actualis\u00e9e des processus en cours d'ex\u00e9cution sur le syst\u00e8me[5]. Contrairement \u00e0 d'autres commandes qui fournissent un snapshot statique, <code>top</code> rafra\u00eechit continuellement l'affichage, g\u00e9n\u00e9ralement chaque seconde par d\u00e9faut, permettant d'observer en temps r\u00e9el la consommation des ressources syst\u00e8me.</p>"},{"location":"_projects/_formation-bash/bash-chap08/#structure-de-laffichage-top","title":"Structure de l'Affichage top","text":"<p>Lorsqu'on lance la commande <code>top</code>, l'\u00e9cran se divise en plusieurs sections:</p> <p>En-t\u00eate du syst\u00e8me: Les premi\u00e8res lignes affichent des informations globales sur le syst\u00e8me, notamment: - L'heure actuelle et le temps d'uptime (temps depuis le dernier red\u00e9marrage) - Le nombre d'utilisateurs connect\u00e9s - La charge moyenne du syst\u00e8me sur 1, 5 et 15 minutes - L'utilisation m\u00e9moire totale (RAM) - L'utilisation du swap</p> <p>Tableau des processus: La section principale liste chaque processus avec plusieurs colonnes: - PID: Identifiant du processus - USER: Utilisateur propri\u00e9taire du processus - PR: Priorit\u00e9 du processus - NI: Valeur de \"nice\" (ajustement de priorit\u00e9) - VIRT: M\u00e9moire virtuelle utilis\u00e9e - RES: M\u00e9moire physique (RAM) utilis\u00e9e - SHR: M\u00e9moire partag\u00e9e - S: \u00c9tat du processus (R=running, S=sleeping, Z=zombie, etc.) - %CPU: Pourcentage d'utilisation CPU - %MEM: Pourcentage d'utilisation m\u00e9moire - TIME+: Temps CPU cumul\u00e9 depuis le d\u00e9marrage du processus - COMMAND: Nom de la commande/programme</p>"},{"location":"_projects/_formation-bash/bash-chap08/#commandes-interactives-dans-top","title":"Commandes Interactives dans top","text":"<p>Lorsque <code>top</code> est en cours d'ex\u00e9cution, plusieurs touches permettent de contr\u00f4ler l'affichage:</p> <ul> <li>k: Tue un processus (demande le PID)</li> <li>r: Change la priorit\u00e9 d'un processus (nice)</li> <li>h: Affiche l'aide</li> <li>q: Quitte top</li> <li>Espace: Force un rafra\u00eechissement imm\u00e9diat</li> <li>u: Filtre les processus par utilisateur</li> <li>M: Trie les processus par utilisation m\u00e9moire</li> <li>P: Trie les processus par utilisation CPU (d\u00e9faut)</li> <li>T: Trie les processus par temps CPU</li> <li>f: Personnalise les colonnes affich\u00e9es</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap08/#exemple-dutilisation","title":"Exemple d'Utilisation","text":"Bash<pre><code># Lancer top avec rafra\u00eechissement toutes les 2 secondes\ntop -d 2\n\n# Lancer top en affichant seulement 10 processus avant de quitter\ntop -n 1 | head -20\n\n# Lancer top en filtrant les processus d'un utilisateur sp\u00e9cifique\ntop -u nomutilisateur\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#cas-dusage-pratiques","title":"Cas d'Usage Pratiques","text":"<p>La commande <code>top</code> s'av\u00e8re particuli\u00e8rement utile pour: - Diagnostiquer les probl\u00e8mes de performance: Identifier rapidement quel processus consume le plus de CPU ou de m\u00e9moire - Monitorer l'activit\u00e9 syst\u00e8me en temps r\u00e9el: Observer comment les ressources sont distribu\u00e9es - D\u00e9tecter les fuites m\u00e9moire: Voir si la consommation m\u00e9moire d'un processus augmente constamment - Identifier les processus zombies: Les processus \u00e0 l'\u00e9tat Z qui doivent \u00eatre nettoy\u00e9s</p>"},{"location":"_projects/_formation-bash/bash-chap08/#visualiser-un-snapshot-des-processus-avec-ps-et-pstree","title":"Visualiser un Snapshot des Processus avec ps et pstree \ud83d\udcf8","text":""},{"location":"_projects/_formation-bash/bash-chap08/#la-commande-ps","title":"La Commande ps","text":"<p>Contrairement \u00e0 <code>top</code> qui propose une vue dynamique, <code>ps</code> (Process Status) fournit un snapshot statique des processus \u00e0 un moment donn\u00e9[5]. Elle ne s'actualise pas automatiquement et n\u00e9cessite d'\u00eatre relanc\u00e9e pour obtenir une nouvelle vue.</p>"},{"location":"_projects/_formation-bash/bash-chap08/#syntaxe-et-options-courantes","title":"Syntaxe et Options Courantes","text":"Bash<pre><code># Afficher tous les processus de l'utilisateur courant\nps\n\n# Afficher tous les processus du syst\u00e8me (avec options BSD)\nps aux\n\n# Afficher tous les processus avec leur arborescence parent-enfant\nps ef\n\n# Afficher seulement les processus en cours d'ex\u00e9cution (pas les threads)\nps -e\n\n# Afficher un processus sp\u00e9cifique\nps -p PID\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#interpretation-de-la-sortie-ps-aux","title":"Interpr\u00e9tation de la Sortie ps aux","text":"<p>Lorsqu'on ex\u00e9cute <code>ps aux</code>, plusieurs colonnes apparaissent:</p> Colonne Signification USER Utilisateur propri\u00e9taire du processus PID Identifiant unique du processus %CPU Pourcentage d'utilisation CPU %MEM Pourcentage d'utilisation m\u00e9moire VSZ M\u00e9moire virtuelle en kilobytes RSS M\u00e9moire physique en kilobytes TTY Terminal associ\u00e9 au processus (? = pas de TTY) STAT \u00c9tat du processus START Moment du d\u00e9marrage du processus TIME Temps CPU total utilis\u00e9 COMMAND Commande qui a lanc\u00e9 le processus"},{"location":"_projects/_formation-bash/bash-chap08/#etats-des-processus-colonne-stat","title":"\u00c9tats des Processus (Colonne STAT)","text":"<ul> <li>R: Processus en cours d'ex\u00e9cution (Running)</li> <li>S: Processus endormi en attente d'\u00e9v\u00e9nement (Sleeping)</li> <li>D: Processus en sommeil non interruptible (Disk I/O)</li> <li>Z: Processus zombie (termin\u00e9 mais pas nettoy\u00e9)</li> <li>T: Processus arr\u00eat\u00e9 (stopped)</li> <li>W: Processus en page sur disque</li> <li>X: Processus mort</li> <li>&lt;: Processus avec haute priorit\u00e9 (moins de nice)</li> <li>N: Processus avec basse priorit\u00e9 (plus de nice)</li> <li>L: Processus avec pages verrouill\u00e9es en m\u00e9moire</li> <li>s: Leader de session</li> <li>l: Multi-thread\u00e9</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap08/#exemples-dutilisation-avancee","title":"Exemples d'Utilisation Avanc\u00e9e","text":"Bash<pre><code># Rechercher un processus sp\u00e9cifique\nps aux | grep bash\n\n# Afficher les processus avec plus de d\u00e9tails\nps -ef\n\n# Afficher les processus en arborescence\nps -e --forest\n\n# Afficher seulement les PID et commandes\nps -eo pid,cmd\n\n# Afficher les processus tri\u00e9s par utilisation m\u00e9moire\nps aux --sort=-%mem | head -10\n\n# Afficher les processus tri\u00e9s par utilisation CPU\nps aux --sort=-%cpu | head -10\n\n# Afficher les threads d'un processus sp\u00e9cifique\nps -eLf | grep PID_CIBLE\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#la-commande-pstree","title":"La Commande pstree","text":"<p><code>pstree</code> affiche l'arborescence des processus de mani\u00e8re visuelle et hi\u00e9rarchique[6], ce qui facilite la compr\u00e9hension des relations parent-enfant. C'est particuli\u00e8rement utile pour comprendre comment les processus sont li\u00e9s les uns aux autres.</p> Bash<pre><code># Afficher l'arborescence compl\u00e8te des processus\npstree\n\n# Afficher l'arborescence avec les PID\npstree -p\n\n# Afficher l'arborescence pour un utilisateur sp\u00e9cifique\npstree -u nomutilisateur\n\n# Afficher l'arborescence sans compaction des processus identiques\npstree -a\n\n# Afficher l'arborescence \u00e0 partir d'un processus sp\u00e9cifique\npstree -p PID\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#exemple-de-sortie-pstree","title":"Exemple de Sortie pstree","text":"<p>Une sortie typique ressemble \u00e0:</p> Text Only<pre><code>init\u2500\u252c\u2500acpid\n     \u251c\u2500cron\n     \u251c\u2500dbus-daemon\n     \u251c\u2500getty\n     \u251c\u2500httpd\u2500\u2500\u2500\u252c\u2500httpd\n     \u2502         \u251c\u2500httpd\n     \u2502         \u2514\u2500httpd\n     \u251c\u2500sshd\n     \u251c\u2500syslog-ng\n     \u2514\u2500systemd-journald\n</code></pre> <p>Cette repr\u00e9sentation graphique montre imm\u00e9diatement que le processus httpd (serveur web) a trois processus enfants, ce qui est typique pour un serveur multiprocessus.</p>"},{"location":"_projects/_formation-bash/bash-chap08/#envoyer-des-signaux-aux-processus","title":"Envoyer des Signaux aux Processus \ud83d\udce1","text":""},{"location":"_projects/_formation-bash/bash-chap08/#comprendre-les-signaux","title":"Comprendre les Signaux","text":"<p>Les signaux sont des m\u00e9canismes de communication entre processus et le syst\u00e8me d'exploitation[5]. Un signal est une notification asynchrone envoy\u00e9e \u00e0 un processus pour lui demander d'effectuer une action sp\u00e9cifique. Les signaux permettent de contr\u00f4ler finement le comportement des processus en cours d'ex\u00e9cution.</p>"},{"location":"_projects/_formation-bash/bash-chap08/#signaux-linux-essentiels","title":"Signaux Linux Essentiels","text":"Signal Num\u00e9ro Comportement Usage SIGHUP 1 Raccroch\u00e9 (fermeture de terminal) Red\u00e9marrage de certains services SIGINT 2 Interruption (Ctrl+C) Arr\u00eat rapide SIGQUIT 3 Quitter avec core dump Diagnostic SIGKILL 9 Tuer le processus (irr\u00e9sistible) Arr\u00eat forc\u00e9 SIGTERM 15 Terminer le processus (d\u00e9faut) Arr\u00eat gracieux SIGSTOP 19 Suspendre le processus Pause SIGCONT 18 Continuer le processus suspendu Reprise SIGUSR1 10 Signal utilisateur 1 D\u00e9fini par l'application SIGUSR2 12 Signal utilisateur 2 D\u00e9fini par l'application"},{"location":"_projects/_formation-bash/bash-chap08/#la-commande-kill","title":"La Commande kill","text":"<p>La commande <code>kill</code> envoie un signal \u00e0 un processus identifi\u00e9 par son PID:</p> Bash<pre><code># Envoyer SIGTERM (arr\u00eat gracieux) - d\u00e9faut\nkill PID\n\n# Envoyer SIGKILL (arr\u00eat forc\u00e9) - irr\u00e9sistible\nkill -9 PID\nkill -KILL PID\n\n# Envoyer SIGSTOP (suspendre)\nkill -STOP PID\n\n# Envoyer SIGCONT (reprendre)\nkill -CONT PID\n\n# Envoyer SIGHUP (red\u00e9marrage)\nkill -HUP PID\n\n# Envoyer un signal sp\u00e9cifique\nkill -TERM PID\nkill -15 PID\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#la-commande-killall","title":"La Commande killall","text":"<p><code>killall</code> permet d'envoyer un signal \u00e0 tous les processus d'un nom donn\u00e9:</p> Bash<pre><code># Terminer tous les processus nomm\u00e9s \"firefox\"\nkillall firefox\n\n# Forcer l'arr\u00eat de tous les processus \"bash\"\nkillall -9 bash\n\n# Afficher quels processus seraient tu\u00e9s sans les tuer vraiment\nkillall -i bash\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#la-commande-pkill","title":"La Commande pkill","text":"<p><code>pkill</code> combine les fonctionnalit\u00e9s de <code>ps</code> et <code>kill</code> en permettant de chercher les processus par pattern et de leur envoyer un signal:</p> Bash<pre><code># Terminer tous les processus contenant \"apache\" dans leur commande\npkill apache\n\n# Forcer l'arr\u00eat de tous les processus d'un utilisateur sp\u00e9cifique\npkill -u nomutilisateur\n\n# Terminer tous les processus dont le nom commence par \"python\"\npkill ^python\n\n# Terminer les processus cr\u00e9\u00e9s avant une certaine dur\u00e9e\npkill -f \"processus_ancien\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#script-exemple-monitoring-et-controle-de-processus","title":"Script Exemple: Monitoring et Contr\u00f4le de Processus","text":"Bash<pre><code>#!/bin/bash\n\n# Script pour monitorer un processus et le red\u00e9marrer s'il s'arr\u00eate\n\nPROCESS_NAME=\"mon_application\"\nCHECK_INTERVAL=5\n\nwhile true; do\n    # V\u00e9rifier si le processus existe\n    if ! pgrep -f \"$PROCESS_NAME\" &gt; /dev/null; then\n        echo \"Processus $PROCESS_NAME arr\u00eat\u00e9, relance...\"\n        /chemin/vers/$PROCESS_NAME &amp;\n        sleep 2\n    fi\n\n    # Attendre avant le prochain check\n    sleep $CHECK_INTERVAL\ndone\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#executer-des-processus-en-arriere-plan","title":"Ex\u00e9cuter des Processus en Arri\u00e8re Plan \u2699\ufe0f","text":""},{"location":"_projects/_formation-bash/bash-chap08/#concepts-fondamentaux","title":"Concepts Fondamentaux","text":"<p>En Linux, chaque commande ex\u00e9cut\u00e9e peut s'ex\u00e9cuter soit au premier plan (foreground) soit en arri\u00e8re-plan (background). Lorsqu'une commande s'ex\u00e9cute au premier plan, elle monopolise le terminal et l'utilisateur doit attendre sa compl\u00e8tion. En arri\u00e8re-plan, le processus s'ex\u00e9cute ind\u00e9pendamment, permettant \u00e0 l'utilisateur de continuer \u00e0 utiliser le terminal.</p>"},{"location":"_projects/_formation-bash/bash-chap08/#lancer-un-processus-en-arriere-plan","title":"Lancer un Processus en Arri\u00e8re-Plan","text":"<p>Pour ex\u00e9cuter une commande en arri\u00e8re-plan, il suffit d'ajouter un <code>&amp;</code> \u00e0 la fin de la commande:</p> Bash<pre><code># Lancer une commande en arri\u00e8re-plan\n./mon_script.sh &amp;\n\n# Lancer plusieurs commandes en arri\u00e8re-plan\nbackup_database.sh &amp;\nclean_logs.sh &amp;\ngenerate_reports.sh &amp;\n\n# Lancer avec redirection d'output\n./application.sh &gt; output.log 2&gt;&amp;1 &amp;\n</code></pre> <p>Apr\u00e8s avoir lanc\u00e9 une commande en arri\u00e8re-plan, le shell affiche un num\u00e9ro de travail (job number) entre crochets et le PID du processus.</p>"},{"location":"_projects/_formation-bash/bash-chap08/#gestion-des-travaux-avec-jobs","title":"Gestion des Travaux avec jobs","text":"<p>La commande <code>jobs</code> affiche la liste de tous les travaux lanc\u00e9s depuis le shell courant:</p> Bash<pre><code># Afficher tous les travaux\njobs\n\n# Afficher les travaux avec leurs PID\njobs -l\n\n# Afficher seulement les travaux en cours d'ex\u00e9cution\njobs -r\n\n# Afficher seulement les travaux arr\u00eat\u00e9s\njobs -s\n</code></pre> <p>La sortie de <code>jobs</code> ressemble \u00e0:</p> Text Only<pre><code>[1]   Running                 ./backup.sh &amp;\n[2]-  Running                 ./monitoring.sh &amp;\n[3]+  Stopped                 tail -f /var/log/syslog\n</code></pre> <p>Les symboles <code>+</code> et <code>-</code> indiquent les travaux par d\u00e9faut (le <code>+</code> est le plus r\u00e9cent).</p>"},{"location":"_projects/_formation-bash/bash-chap08/#suspendre-et-reprendre-les-processus","title":"Suspendre et Reprendre les Processus","text":"<ul> <li>Ctrl+Z: Suspend le processus au premier plan (l'envoit en arri\u00e8re-plan avec l'\u00e9tat Stopped)</li> <li>fg: Ram\u00e8ne un travail d'arri\u00e8re-plan au premier plan</li> <li>bg: Continue l'ex\u00e9cution d'un travail suspendu en arri\u00e8re-plan</li> </ul> Bash<pre><code># Supposons qu'on a lanc\u00e9: tail -f /var/log/syslog\n# Appuyer sur Ctrl+Z pour le suspendre\n\n# Afficher les travaux\njobs\n\n# Reprendre en arri\u00e8re-plan\nbg\n\n# Ou ramener au premier plan\nfg\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#controle-avance-des-processus","title":"Contr\u00f4le Avanc\u00e9 des Processus","text":"Bash<pre><code># Ramener le travail num\u00e9ro 1 au premier plan\nfg %1\n\n# Continuer le travail num\u00e9ro 2 en arri\u00e8re-plan\nbg %2\n\n# Ramener le dernier travail suspendu au premier plan\nfg\n\n# Continuer le dernier travail en arri\u00e8re-plan\nbg\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#script-exemple-orchestration-de-taches-en-arriere-plan","title":"Script Exemple: Orchestration de T\u00e2ches en Arri\u00e8re-Plan","text":"Bash<pre><code>#!/bin/bash\n\n# Script pour ex\u00e9cuter plusieurs t\u00e2ches en parall\u00e8le en arri\u00e8re-plan\n\necho \"D\u00e9marrage des t\u00e2ches...\"\n\n# Lancer les t\u00e2ches en arri\u00e8re-plan\nlong_task_1.sh &gt; /tmp/task1.log 2&gt;&amp;1 &amp;\nPID_1=$!\n\nlong_task_2.sh &gt; /tmp/task2.log 2&gt;&amp;1 &amp;\nPID_2=$!\n\nlong_task_3.sh &gt; /tmp/task3.log 2&gt;&amp;1 &amp;\nPID_3=$!\n\necho \"T\u00e2che 1 (PID: $PID_1)\"\necho \"T\u00e2che 2 (PID: $PID_2)\"\necho \"T\u00e2che 3 (PID: $PID_3)\"\n\n# Attendre que toutes les t\u00e2ches se terminent\nwait $PID_1 $PID_2 $PID_3\n\necho \"Toutes les t\u00e2ches sont compl\u00e9t\u00e9es!\"\n\n# V\u00e9rifier les codes de sortie\nif [ $? -eq 0 ]; then\n    echo \"Succ\u00e8s!\"\nelse\n    echo \"Une t\u00e2che a \u00e9chou\u00e9!\"\nfi\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#utilisation-de-nohup-pour-la-persistance","title":"Utilisation de nohup pour la Persistance","text":"<p>Lorsqu'on ferme la session terminal, tous les processus enfants re\u00e7oivent un signal SIGHUP. Pour \u00e9viter cela, on utilise <code>nohup</code>:</p> Bash<pre><code># Ex\u00e9cuter une commande qui survivra \u00e0 la fermeture du terminal\nnohup ./longue_application.sh &gt; output.log 2&gt;&amp;1 &amp;\n\n# D\u00e9tacher un processus du terminal courant avec disown\n./application.sh &amp;\ndisown\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#les-daemons-ou-services","title":"Les Daemons ou Services \ud83d\udda5\ufe0f","text":""},{"location":"_projects/_formation-bash/bash-chap08/#definition-et-caracteristiques","title":"D\u00e9finition et Caract\u00e9ristiques","text":"<p>Un daemon (ou service) est un processus qui s'ex\u00e9cute en arri\u00e8re-plan de mani\u00e8re continue, sans interaction directe avec l'utilisateur. Les daemons fournissent des services aux autres processus et sont essentiels au fonctionnement du syst\u00e8me. Contrairement aux processus normaux, les daemons n'ont g\u00e9n\u00e9ralement pas de terminal associ\u00e9 et continuent \u00e0 s'ex\u00e9cuter m\u00eame quand aucun utilisateur n'est connect\u00e9.</p>"},{"location":"_projects/_formation-bash/bash-chap08/#caracteristiques-des-daemons","title":"Caract\u00e9ristiques des Daemons","text":"<ul> <li>Pas de terminal associ\u00e9: Les daemons s'ex\u00e9cutent sans TTY (terminal)</li> <li>Ex\u00e9cution en arri\u00e8re-plan: Ils ne bloquent pas le shell</li> <li>Longue dur\u00e9e de vie: Ils restent actifs jusqu'\u00e0 l'arr\u00eat du syst\u00e8me ou leur arr\u00eat explicite</li> <li>Processus orphelin au d\u00e9marrage: Les daemons sont g\u00e9n\u00e9ralement reparent\u00e9s au processus init (PID 1)</li> <li>Redirection des I/O: Les entr\u00e9es/sorties sont g\u00e9n\u00e9ralement redirig\u00e9es vers <code>/dev/null</code> ou des fichiers journaux</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap08/#identification-des-daemons","title":"Identification des Daemons","text":"<p>En examinant la sortie de <code>ps</code>, les daemons se reconnaissent par:</p> Bash<pre><code># Les daemons n'ont pas de TTY associ\u00e9 (colonne TTY = ?)\nps aux | grep ?\n</code></pre> <p>Des exemples courants de daemons:</p> <ul> <li>sshd: Daemon SSH pour l'acc\u00e8s distant</li> <li>httpd ou apache2: Serveur web</li> <li>mysqld: Serveur de base de donn\u00e9es MySQL</li> <li>cron: Planificateur de t\u00e2ches</li> <li>syslog-ng: Collecteur de logs</li> <li>ntpd: Synchronisation de l'heure</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap08/#demarrage-et-arret-des-services","title":"D\u00e9marrage et Arr\u00eat des Services","text":"<p>Sous les syst\u00e8mes modernes utilisant systemd:</p> Bash<pre><code># D\u00e9marrer un service\nsystemctl start nom_service\n\n# Arr\u00eater un service\nsystemctl stop nom_service\n\n# Red\u00e9marrer un service\nsystemctl restart nom_service\n\n# Rechcharger la configuration sans red\u00e9marrer\nsystemctl reload nom_service\n\n# Activer un service au d\u00e9marrage\nsystemctl enable nom_service\n\n# D\u00e9sactiver un service au d\u00e9marrage\nsystemctl disable nom_service\n\n# Afficher l'\u00e9tat d'un service\nsystemctl status nom_service\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#creation-dun-service-personnalise","title":"Cr\u00e9ation d'un Service Personnalis\u00e9","text":"<p>Pour cr\u00e9er un daemon personnalis\u00e9, il faut d'abord cr\u00e9er le unit file systemd:</p> Bash<pre><code># Cr\u00e9er le fichier de service\nsudo nano /etc/systemd/system/mon_service.service\n</code></pre> <p>Contenu typique d'un unit file:</p> INI<pre><code>[Unit]\nDescription=Mon Service Personnalis\u00e9\nAfter=network.target\n\n[Service]\nType=simple\nUser=nomutilisateur\nWorkingDirectory=/chemin/vers/application\nExecStart=/chemin/vers/mon_application\nRestart=on-failure\nRestartSec=10\n\n[Install]\nWantedBy=multi-user.target\n</code></pre> <p>Ensuite, recharger les configurations et d\u00e9marrer le service:</p> Bash<pre><code># Recharger la configuration systemd\nsudo systemctl daemon-reload\n\n# D\u00e9marrer le service\nsudo systemctl start mon_service\n\n# V\u00e9rifier l'\u00e9tat\nsudo systemctl status mon_service\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#script-bash-pour-creer-un-daemon-basique","title":"Script Bash pour Cr\u00e9er un Daemon Basique","text":"Bash<pre><code>#!/bin/bash\n\n# Script daemon simple avec logging\n\nLOGFILE=\"/var/log/mon_daemon.log\"\nPIDFILE=\"/var/run/mon_daemon.pid\"\n\n# Fonction pour loguer les \u00e9v\u00e9nements\nlog_event() {\n    echo \"[$(date '+%Y-%m-%d %H:%M:%S')] $1\" &gt;&gt; \"$LOGFILE\"\n}\n\n# V\u00e9rifier si d\u00e9j\u00e0 en cours d'ex\u00e9cution\nif [ -f \"$PIDFILE\" ]; then\n    PID=$(cat \"$PIDFILE\")\n    if ps -p $PID &gt; /dev/null 2&gt;&amp;1; then\n        echo \"Le daemon est d\u00e9j\u00e0 en cours d'ex\u00e9cution (PID: $PID)\"\n        exit 1\n    fi\nfi\n\n# D\u00e9marrer le daemon en arri\u00e8re-plan\n(\n    # \u00c9crire le PID\n    echo $$ &gt; \"$PIDFILE\"\n\n    log_event \"Daemon d\u00e9marr\u00e9\"\n\n    # Boucle principale\n    while true; do\n        log_event \"Ex\u00e9cution du travail p\u00e9riodique\"\n\n        # Effectuer le travail ici\n        # ...\n\n        # Attendre avant le prochain cycle\n        sleep 60\n    done\n) &amp;\n\necho \"Daemon lanc\u00e9 avec PID: $!\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#gestion-des-logs-pour-les-daemons","title":"Gestion des Logs pour les Daemons","text":"<p>Les daemons g\u00e9n\u00e8rent g\u00e9n\u00e9ralement des logs. La gestion appropri\u00e9e est cruciale:</p> Bash<pre><code># V\u00e9rifier les logs d'un service\njournalctl -u nom_service\n\n# Afficher les 50 derni\u00e8res lignes\njournalctl -u nom_service -n 50\n\n# Afficher les logs en temps r\u00e9el\njournalctl -u nom_service -f\n\n# Afficher les logs depuis une heure\njournalctl -u nom_service --since \"1 hour ago\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#relation-processus-parent-et-hierarchie","title":"Relation Processus-Parent et Hi\u00e9rarchie \ud83c\udf33","text":""},{"location":"_projects/_formation-bash/bash-chap08/#larborescence-des-processus","title":"L'Arborescence des Processus","text":"<p>Chaque processus Linux (sauf init avec PID 1) poss\u00e8de exactement un processus parent. Cette relation cr\u00e9e une hi\u00e9rarchie d'arborescence o\u00f9 le processus init est \u00e0 la racine. Comprendre cette hi\u00e9rarchie est essentiel pour g\u00e9rer les processus efficacement.</p>"},{"location":"_projects/_formation-bash/bash-chap08/#visualiser-larborescence","title":"Visualiser l'Arborescence","text":"Bash<pre><code># Afficher l'arborescence compl\u00e8te avec pstree\npstree\n\n# Afficher l'arborescence avec les PID\npstree -p\n\n# Afficher l'arborescence d'un utilisateur sp\u00e9cifique\npstree -u nomutilisateur\n\n# Afficher l'arborescence \u00e0 partir d'un processus sp\u00e9cifique\npstree -p PID\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#reparentage-automatique","title":"Reparentage Automatique","text":"<p>Lorsqu'un processus parent se termine avant ses enfants, le syst\u00e8me d'exploitation orpheline ces processus. Sous Linux, les processus orphelins sont automatiquement reparent\u00e9s au processus init (PID 1), ce qui garantit qu'ils peuvent \u00eatre monitorer et contr\u00f4ler.</p>"},{"location":"_projects/_formation-bash/bash-chap08/#script-exemple-analyse-de-la-hierarchie-des-processus","title":"Script Exemple: Analyse de la Hi\u00e9rarchie des Processus","text":"Bash<pre><code>#!/bin/bash\n\n# Script pour analyser les processus enfants d'un processus parent\n\nif [ -z \"$1\" ]; then\n    echo \"Usage: $0 &lt;PID&gt;\"\n    exit 1\nfi\n\nPARENT_PID=$1\n\necho \"Processus parent: PID $PARENT_PID\"\necho \"\"\n\n# Afficher le processus parent\nps -p $PARENT_PID\n\necho \"\"\necho \"Processus enfants directs:\"\n\n# Utiliser ps pour trouver les enfants\nps --ppid $PARENT_PID\n\necho \"\"\necho \"Toute l'arborescence:\"\n\n# Utiliser pstree\npstree -p $PARENT_PID\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#commandes-de-diagnostic-avance","title":"Commandes de Diagnostic Avanc\u00e9 \ud83d\udd0d","text":""},{"location":"_projects/_formation-bash/bash-chap08/#utilisation-combinee-de-ps-top-et-pstree","title":"Utilisation Combin\u00e9e de ps, top et pstree","text":"<p>Pour un diagnostic complet des processus:</p> Bash<pre><code># 1. Identifier les processus consommant le plus de ressources\nps aux --sort=-%cpu | head -10\nps aux --sort=-%mem | head -10\n\n# 2. V\u00e9rifier la hi\u00e9rarchie d'un processus sp\u00e9cifique\npstree -p NOM_PROCESSUS\n\n# 3. Monitorer les changements en temps r\u00e9el\ntop -p PID1,PID2,PID3\n\n# 4. Chercher un processus sp\u00e9cifique et obtenir tous les d\u00e9tails\nps -ef | grep processus_cible\nps -p PID -o pid,ppid,cmd,etime,user\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#recherche-avancee-avec-grep-et-awk","title":"Recherche Avanc\u00e9e avec grep et awk","text":"Bash<pre><code># Trouver tous les processus d'un utilisateur sp\u00e9cifique consommant plus de 10% CPU\nps aux | awk '$1==\"nomutilisateur\" &amp;&amp; $3&gt;10'\n\n# Trouver tous les processus qui utilisent plus de 50MB de RAM\nps aux | awk '$6&gt;50000'\n\n# Afficher les informations structur\u00e9es d'un processus\nps -p PID -o pid,ppid,cmd,vsz,rss,etime,%cpu,%mem\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#concepts-de-priorite-et-nice","title":"Concepts de Priorit\u00e9 et Nice \ud83c\udfaf","text":""},{"location":"_projects/_formation-bash/bash-chap08/#comprendre-les-priorites","title":"Comprendre les Priorit\u00e9s","text":"<p>Chaque processus a une priorit\u00e9 qui d\u00e9termine la fr\u00e9quence \u00e0 laquelle le CPU l'ex\u00e9cute. Les processus avec une priorit\u00e9 plus \u00e9lev\u00e9e re\u00e7oivent plus de temps CPU.</p>"},{"location":"_projects/_formation-bash/bash-chap08/#valeur-de-nice","title":"Valeur de Nice","text":"<p>La valeur de nice est utilis\u00e9e pour ajuster la priorit\u00e9: - Valeur de nice de -20 = priorit\u00e9 tr\u00e8s haute (seulement root) - Valeur de nice de 0 = priorit\u00e9 standard (d\u00e9faut) - Valeur de nice de +19 = priorit\u00e9 tr\u00e8s basse</p>"},{"location":"_projects/_formation-bash/bash-chap08/#modifier-la-priorite","title":"Modifier la Priorit\u00e9","text":"Bash<pre><code># Lancer un processus avec une valeur de nice sp\u00e9cifique\nnice -n 10 ./mon_application.sh\n\n# Lancer avec priorit\u00e9 haute (seulement root)\nnice -n -5 ./important_task.sh\n\n# Modifier la priorit\u00e9 d'un processus existant\nrenice +5 -p PID\nrenice -10 -p PID\n\n# Modifier la priorit\u00e9 pour tous les processus d'un utilisateur\nrenice +5 -u nomutilisateur\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap08/#conclusion-chemin-dapprentissage-propose","title":"Conclusion: Chemin d'Apprentissage Propos\u00e9 \ud83c\udf93","text":"<p>Pour ma\u00eetriser la gestion des processus sous Linux, le chemin d'apprentissage recommand\u00e9 est:</p> <p>Phase 1 - Fondamentaux (1-2 semaines) Commencer par comprendre les concepts de base: PIDs, PPIDs, et la hi\u00e9rarchie des processus. Utiliser <code>ps</code> pour examiner les processus existants et comprendre les colonnes de sortie. Pratiquer avec <code>pstree</code> pour visualiser les relations parent-enfant.</p> <p>Phase 2 - Monitoring (2-3 semaines) Maitriser <code>top</code> pour l'observation en temps r\u00e9el des ressources. Apprendre \u00e0 identifier les processus probl\u00e9matiques et comprendre l'utilisation CPU/m\u00e9moire. Pratiquer la filtration et le tri des processus.</p> <p>Phase 3 - Contr\u00f4le (2-3 semaines) Apprendre \u00e0 envoyer des signaux avec <code>kill</code>, <code>killall</code> et <code>pkill</code>. Comprendre les diff\u00e9rents signaux (SIGTERM, SIGKILL, etc.) et leurs utilisations appropri\u00e9es. Pratiquer l'arr\u00eat gracieux vs forc\u00e9 des processus.</p> <p>Phase 4 - Ex\u00e9cution en Arri\u00e8re-Plan (1-2 semaines) Maitriser le lancement de processus en arri\u00e8re-plan avec <code>&amp;</code>. Apprendre \u00e0 utiliser <code>jobs</code>, <code>fg</code> et <code>bg</code> pour contr\u00f4ler les travaux. Pratiquer l'orchestration de multiples t\u00e2ches parall\u00e8les.</p> <p>Phase 5 - Services et Daemons (2-3 semaines) Comprendre le concept de daemon et ses caract\u00e9ristiques. Utiliser <code>systemctl</code> pour g\u00e9rer les services. Cr\u00e9er des services personnalis\u00e9s avec les unit files systemd. Apprendre la gestion des logs avec <code>journalctl</code>.</p> <p>Phase 6 - Scripting et Automatisation (3-4 semaines) Combiner toutes les connaissances pour cr\u00e9er des scripts bash sophistiqu\u00e9s de monitoring et de contr\u00f4le de processus. Utiliser les variables sp\u00e9ciales <code>$$</code> et <code>$PPID</code>. Cr\u00e9er des syst\u00e8mes de watchdog qui relancent les processus d\u00e9faillants. Impl\u00e9menter la gestion des signaux dans les scripts.</p> <p>Cette progression cr\u00e9e une base solide passant du plus simple (observation) au plus complexe (cr\u00e9ation et gestion de services personnalis\u00e9s), permettant au praticien de progresser graduellement en ma\u00eetrisant chaque aspect des processus Linux avant d'aborder le suivant.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-bash/bash-chap09/","title":"Citations","text":"<ul> <li>https://www.it-connect.fr/la-commande-chmod/</li> <li>https://www.linux.digibeatrix.com/fr/security-and-user-management/linux-chmod-permission-guide/</li> <li>http://doc.ubuntu-fr.org/permissions</li> <li>https://www.linuxtricks.fr/wiki/droits-sous-linux-utilisateurs-groupes-permissions</li> <li>https://linux.goffinet.org/administration/securite-locale/permissions-linux/</li> <li>https://labex.io/fr/tutorials/linux-how-to-elevate-linux-command-permissions-435783</li> <li>https://blog.stephane-robert.info/docs/admin-serveurs/linux/shells-linux/bash/</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap09/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 283</li> <li>completion_tokens: 5700</li> <li>total_tokens: 5983</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.086, 'request_cost': 0.006, 'total_cost': 0.092}</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap09/#content","title":"Content","text":""},{"location":"_projects/_formation-bash/bash-chap09/#chapitre-9-les-permissions-sous-linux","title":"Chapitre 9 : Les permissions sous Linux \ud83d\udd10","text":""},{"location":"_projects/_formation-bash/bash-chap09/#introduction-aux-permissions","title":"Introduction aux permissions","text":"<p>Les permissions constituent le fondement du syst\u00e8me de s\u00e9curit\u00e9 sous Linux. Elles d\u00e9finissent qui peut acc\u00e9der \u00e0 un fichier ou un r\u00e9pertoire et quelles op\u00e9rations sont autoris\u00e9es. Chaque fichier et r\u00e9pertoire poss\u00e8de un ensemble de permissions qui r\u00e9gissent l'acc\u00e8s pour trois cat\u00e9gories d'utilisateurs : le propri\u00e9taire du fichier, les membres du groupe associ\u00e9, et tous les autres utilisateurs.[1]</p> <p>Les permissions Linux reposent sur trois types d'actions possibles : la lecture \u00ae, l'\u00e9criture (w) et l'ex\u00e9cution (x). La lecture permet de voir le contenu d'un fichier ou de lister un r\u00e9pertoire. L'\u00e9criture permet de modifier un fichier, son contenu, ou d'ajouter et supprimer des fichiers dans un r\u00e9pertoire. L'ex\u00e9cution permet d'ex\u00e9cuter un fichier ou d'entrer dans un r\u00e9pertoire (permission n\u00e9cessaire pour ex\u00e9cuter un script Bash, par exemple).[1]</p>"},{"location":"_projects/_formation-bash/bash-chap09/#afficher-les-permissions","title":"Afficher les permissions","text":""},{"location":"_projects/_formation-bash/bash-chap09/#utiliser-la-commande-ls","title":"Utiliser la commande ls","text":"<p>Pour consulter les permissions d'un fichier ou d'un r\u00e9pertoire, la commande ls -l doit \u00eatre utilis\u00e9e.[1][2] Cette commande affiche les informations du fichier au format suivant :</p> Bash<pre><code>ls -l\n</code></pre> <p>Un r\u00e9sultat typique ressemble \u00e0 ceci :</p> Text Only<pre><code>-rw-r--r-- 1 user group 1234 Apr 13 2025 sample.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap09/#interpreter-laffichage-des-permissions","title":"Interpr\u00e9ter l'affichage des permissions","text":"<p>La cha\u00eene de caract\u00e8res <code>-rw-r--r--</code> situ\u00e9s \u00e0 gauche repr\u00e9sente les autorisations d'acc\u00e8s du fichier.[2] Cette cha\u00eene se d\u00e9compose de la mani\u00e8re suivante :</p> <p>Le premier caract\u00e8re indique le type de fichier : - <code>-</code> : fichier ordinaire - <code>d</code> : r\u00e9pertoire (directory) - <code>l</code> : lien symbolique - <code>b</code> : p\u00e9riph\u00e9rique de type bloc - <code>s</code> : socket</p> <p>Les 9 caract\u00e8res restants repr\u00e9sentent les permissions divis\u00e9es en trois blocs de trois caract\u00e8res chacun :[1][2]</p> Position Caract\u00e8res Signification 1-3 Premier bloc Permissions du propri\u00e9taire (user) 4-6 Deuxi\u00e8me bloc Permissions du groupe (group) 7-9 Troisi\u00e8me bloc Permissions des autres (others) <p>Au sein de chaque bloc de trois caract\u00e8res, l'ordre est toujours le m\u00eame :</p> <ul> <li>Position 1 : <code>r</code> (lecture) ou <code>-</code> (pas de lecture)</li> <li>Position 2 : <code>w</code> (\u00e9criture) ou <code>-</code> (pas d'\u00e9criture)</li> <li>Position 3 : <code>x</code> (ex\u00e9cution) ou <code>-</code> (pas d'ex\u00e9cution)</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap09/#exemple-dinterpretation","title":"Exemple d'interpr\u00e9tation","text":"<p>Prenons l'exemple <code>-rw-r--r--</code> :[2]</p> <ul> <li><code>-</code> : c'est un fichier ordinaire</li> <li><code>rw-</code> : le propri\u00e9taire peut lire et \u00e9crire, mais pas ex\u00e9cuter</li> <li><code>r--</code> : le groupe peut seulement lire</li> <li><code>r--</code> : les autres peuvent seulement lire</li> </ul> <p>Cette configuration signifie que seul le propri\u00e9taire peut modifier ce fichier, tandis que tous les autres utilisateurs ne peuvent que le consulter.[2]</p>"},{"location":"_projects/_formation-bash/bash-chap09/#representation-numerique-des-permissions","title":"Repr\u00e9sentation num\u00e9rique des permissions","text":""},{"location":"_projects/_formation-bash/bash-chap09/#conversion-en-notation-octale","title":"Conversion en notation octale","text":"<p>Les permissions peuvent \u00e9galement \u00eatre exprim\u00e9es de mani\u00e8re num\u00e9rique ou octale (notation utilisant des chiffres de 0 \u00e0 7).[2] Chaque permission a une valeur num\u00e9rique :</p> <ul> <li><code>r</code> (lecture) = 4</li> <li><code>w</code> (\u00e9criture) = 2</li> <li><code>x</code> (ex\u00e9cution) = 1</li> </ul> <p>Pour d\u00e9terminer la permission d'un bloc, il suffit d'additionner les valeurs :[3]</p> Combinaison Calcul Valeur Symbole Signification Aucun droit - 0 <code>---</code> Pas d'acc\u00e8s Ex\u00e9cution seule 1 1 <code>--x</code> Ex\u00e9cution uniquement \u00c9criture seule 2 2 <code>-w-</code> \u00c9criture uniquement \u00c9criture + ex\u00e9cution 2+1 3 <code>-wx</code> \u00c9criture et ex\u00e9cution Lecture seule 4 4 <code>r--</code> Lecture uniquement Lecture + ex\u00e9cution 4+1 5 <code>r-x</code> Lecture et ex\u00e9cution Lecture + \u00e9criture 4+2 6 <code>rw-</code> Lecture et \u00e9criture Tous les droits 4+2+1 7 <code>rwx</code> Lecture, \u00e9criture, ex\u00e9cution"},{"location":"_projects/_formation-bash/bash-chap09/#composition-du-mode-numerique","title":"Composition du mode num\u00e9rique","text":"<p>Pour exprimer les permissions compl\u00e8tes d'un fichier en notation num\u00e9rique, il faut combiner les chiffres des trois blocs (propri\u00e9taire, groupe, autres). Par exemple :[3]</p> <ul> <li><code>755</code> signifie :</li> <li><code>7</code> (propri\u00e9taire) = lecture + \u00e9criture + ex\u00e9cution = <code>rwx</code></li> <li><code>5</code> (groupe) = lecture + ex\u00e9cution = <code>r-x</code></li> <li> <p><code>5</code> (autres) = lecture + ex\u00e9cution = <code>r-x</code></p> </li> <li> <p><code>644</code> signifie :</p> </li> <li><code>6</code> (propri\u00e9taire) = lecture + \u00e9criture = <code>rw-</code></li> <li><code>4</code> (groupe) = lecture = <code>r--</code></li> <li><code>4</code> (autres) = lecture = <code>r--</code></li> </ul>"},{"location":"_projects/_formation-bash/bash-chap09/#configuration-de-permission-rw-r-r-","title":"Configuration de permission <code>-rw-r--r--</code>","text":"<p>Pour d\u00e9finir les permissions \u00e0 <code>-rw-r--r--</code>, il suffit de r\u00e9gler la permission sur <code>644</code> :[2]</p> <ul> <li><code>6</code> = <code>rw-</code> (lecture + \u00e9criture pour le propri\u00e9taire)</li> <li><code>4</code> = <code>r--</code> (lecture seule pour le groupe)</li> <li><code>4</code> = <code>r--</code> (lecture seule pour les autres)</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap09/#modifier-les-permissions-avec-chmod","title":"Modifier les permissions avec chmod","text":""},{"location":"_projects/_formation-bash/bash-chap09/#syntaxe-generale","title":"Syntaxe g\u00e9n\u00e9rale","text":"<p>La commande <code>chmod</code> permet de modifier les permissions d'acc\u00e8s des fichiers et r\u00e9pertoires.[1][2] Elle accepte deux formats de sp\u00e9cification : num\u00e9rique et symbolique.</p>"},{"location":"_projects/_formation-bash/bash-chap09/#methode-numerique","title":"M\u00e9thode num\u00e9rique","text":"<p>La sp\u00e9cification num\u00e9rique est la plus directe. Elle utilise le format : <code>chmod [permissions] [fichier]</code>[2]</p> <p>Exemples :</p> Bash<pre><code>chmod 755 script.sh\nchmod 644 document.txt\nchmod 600 confidential.txt\n</code></pre> <p>Le premier exemple accorde des permissions <code>755</code> au fichier <code>script.sh</code>, ce qui signifie que le propri\u00e9taire peut lire, \u00e9crire et ex\u00e9cuter le fichier, tandis que le groupe et les autres utilisateurs peuvent seulement le lire et l'ex\u00e9cuter.[2]</p>"},{"location":"_projects/_formation-bash/bash-chap09/#methode-symbolique","title":"M\u00e9thode symbolique","text":"<p>La m\u00e9thode symbolique utilise des lettres pour sp\u00e9cifier les permissions. Elle offre plus de flexibilit\u00e9 car elle permet de modifier seulement certaines permissions sans les r\u00e9\u00e9crire enti\u00e8rement.[1]</p> <p>La syntaxe est : <code>chmod [qui][op\u00e9ration][permissions] [fichier]</code></p> <p>Les cat\u00e9gories d'utilisateurs :</p> Symbole Signification <code>u</code> user (propri\u00e9taire) <code>g</code> group (groupe) <code>o</code> others (autres) <code>a</code> all (tous les utilisateurs, \u00e9quivalent de \"ugo\") <p>Les op\u00e9rations :</p> Symbole Signification <code>+</code> Ajoute la permission <code>-</code> Retire la permission <code>=</code> Modifie la permission actuelle (\u00e9crase compl\u00e8tement) <p>Les permissions :</p> Symbole Signification <code>r</code> read (lecture) <code>w</code> write (\u00e9criture) <code>x</code> execute (ex\u00e9cution)"},{"location":"_projects/_formation-bash/bash-chap09/#exemples-pratiques-avec-la-methode-symbolique","title":"Exemples pratiques avec la m\u00e9thode symbolique","text":"<p>Ajouter le droit de lecture \u00e0 tout le monde :</p> Bash<pre><code>chmod a+r fichier\n</code></pre> <p>Cette commande ajoute la permission de lecture pour le propri\u00e9taire, le groupe et les autres.[4]</p> <p>Ajouter le droit de modification au groupe :</p> Bash<pre><code>chmod g+w fichier\n</code></pre> <p>Le groupe peut d\u00e9sormais modifier le fichier.[4]</p> <p>Retirer le droit de lecture aux autres :</p> Bash<pre><code>chmod o-r fichier\n</code></pre> <p>Les utilisateurs autres que le propri\u00e9taire et le groupe ne peuvent plus lire le fichier.[4]</p> <p>Enlever le droit d'\u00e9criture pour les autres :</p> Bash<pre><code>chmod o-w fichier3\n</code></pre> <p>Ajouter le droit d'ex\u00e9cution \u00e0 tout le monde :</p> Bash<pre><code>chmod a+x fichier\n</code></pre> <p>Combiner plusieurs op\u00e9rations :</p> Bash<pre><code>chmod u+rwx,g+rx-w,o+r-wx fichier3\n</code></pre> <p>Cette commande applique les trois modifications suivantes :[3] - Ajoute la permission de lecture, d'\u00e9criture et d'ex\u00e9cution au propri\u00e9taire - Ajoute la permission de lecture et d'ex\u00e9cution au groupe, puis retire l'\u00e9criture - Ajoute la permission de lecture aux autres, puis retire l'\u00e9criture et l'ex\u00e9cution</p>"},{"location":"_projects/_formation-bash/bash-chap09/#cas-dusage-courants","title":"Cas d'usage courants","text":"<p>Rendre un script ex\u00e9cutable :</p> Bash<pre><code>chmod +x monscript.sh\nchmod a+x monscript.sh\n</code></pre> <p>Ou avec la m\u00e9thode num\u00e9rique :[2]</p> Bash<pre><code>chmod 755 script.sh\n</code></pre> <p>Fichiers sensibles (acc\u00e8s propri\u00e9taire seul) :</p> Bash<pre><code>chmod 600 fichier_sensible\n</code></pre> <p>Cette configuration (<code>-rw-------</code>) signifie que seul le propri\u00e9taire peut lire et \u00e9crire le fichier.[2]</p> <p>R\u00e9pertoires priv\u00e9s :</p> Bash<pre><code>chmod 700 repertoire_prive\n</code></pre> <p>Cette configuration (<code>-rwx------</code>) signifie que seul le propri\u00e9taire peut acc\u00e9der au r\u00e9pertoire.[2]</p>"},{"location":"_projects/_formation-bash/bash-chap09/#verifier-les-modifications","title":"V\u00e9rifier les modifications","text":"<p>Apr\u00e8s avoir d\u00e9fini les permissions avec <code>chmod</code>, il est recommand\u00e9 de toujours v\u00e9rifier le r\u00e9sultat avec <code>ls -l</code> :[2]</p> Bash<pre><code>chmod 755 backup.sh\nls -l backup.sh\n</code></pre> <p>Pour v\u00e9rifier plusieurs fichiers \u00e0 la fois, utiliser un pipe :</p> Bash<pre><code>ls -l | grep '.sh'\n</code></pre> <p>Cela affiche uniquement les fichiers avec l'extension <code>.sh</code> (script shell).[2]</p>"},{"location":"_projects/_formation-bash/bash-chap09/#fonctionnement-detaille-des-permissions","title":"Fonctionnement d\u00e9taill\u00e9 des permissions","text":""},{"location":"_projects/_formation-bash/bash-chap09/#permissions-et-fichiers","title":"Permissions et fichiers","text":"<p>Pour les fichiers ordinaires, les trois permissions jouent les r\u00f4les suivants :</p> <p>Lecture \u00ae : Permet de lire le contenu du fichier. Sans cette permission, il est impossible d'afficher ou de copier le fichier.</p> <p>\u00c9criture (w) : Permet de modifier le contenu du fichier. Sans cette permission, m\u00eame le propri\u00e9taire ne peut pas le modifier.</p> <p>Ex\u00e9cution (x) : Permet d'ex\u00e9cuter le fichier comme un programme ou un script. Cette permission est essentielle pour les scripts shell.</p>"},{"location":"_projects/_formation-bash/bash-chap09/#permissions-et-repertoires","title":"Permissions et r\u00e9pertoires","text":"<p>Pour les r\u00e9pertoires, les permissions fonctionnent diff\u00e9remment :</p> <p>Lecture \u00ae : Permet de lister le contenu du r\u00e9pertoire (utiliser <code>ls</code>).</p> <p>\u00c9criture (w) : Permet de cr\u00e9er, supprimer ou renommer des fichiers \u00e0 l'int\u00e9rieur du r\u00e9pertoire. Cette permission modifie directement le contenu du r\u00e9pertoire.</p> <p>Ex\u00e9cution (x) : Permet de traverser le r\u00e9pertoire, c'est-\u00e0-dire d'entrer dedans et d'acc\u00e9der aux fichiers qu'il contient. Cette permission est crucial pour acc\u00e9der aux fichiers d'un r\u00e9pertoire.</p>"},{"location":"_projects/_formation-bash/bash-chap09/#les-utilisateurs-sous-linux","title":"Les utilisateurs sous Linux","text":""},{"location":"_projects/_formation-bash/bash-chap09/#ajouter-un-utilisateur","title":"Ajouter un utilisateur","text":"<p>Pour cr\u00e9er un nouvel utilisateur, utiliser la commande <code>useradd</code> ou <code>adduser</code> (selon la distribution Linux) :[1]</p> Bash<pre><code>sudo useradd nouveau_utilisateur\n</code></pre> <p>Ou avec plus d'options :</p> Bash<pre><code>sudo useradd -m -s /bin/bash -c \"Nom Complet\" nouveau_utilisateur\n</code></pre> <p>Les options principales sont : - <code>-m</code> : cr\u00e9e le r\u00e9pertoire personnel (home) de l'utilisateur - <code>-s</code> : sp\u00e9cifie le shell par d\u00e9faut - <code>-c</code> : ajoute un commentaire (g\u00e9n\u00e9ralement le nom complet)</p>"},{"location":"_projects/_formation-bash/bash-chap09/#attribuer-un-mot-de-passe","title":"Attribuer un mot de passe","text":"Bash<pre><code>sudo passwd nouveau_utilisateur\n</code></pre> <p>Cette commande demande de saisir et confirmer le mot de passe du nouvel utilisateur.</p>"},{"location":"_projects/_formation-bash/bash-chap09/#supprimer-un-utilisateur","title":"Supprimer un utilisateur","text":"Bash<pre><code>sudo userdel utilisateur\n</code></pre> <p>Pour supprimer \u00e9galement le r\u00e9pertoire personnel :</p> Bash<pre><code>sudo userdel -r utilisateur\n</code></pre> <p>L'option <code>-r</code> supprime le r\u00e9pertoire personnel et son contenu.</p>"},{"location":"_projects/_formation-bash/bash-chap09/#lister-les-utilisateurs","title":"Lister les utilisateurs","text":"<p>Les utilisateurs sont stock\u00e9s dans le fichier <code>/etc/passwd</code>. Pour afficher tous les utilisateurs :</p> Bash<pre><code>cat /etc/passwd\n</code></pre> <p>Chaque ligne repr\u00e9sente un utilisateur avec le format : <code>nom:mot_de_passe_chiffr\u00e9:UID:GID:commentaire:home:shell</code></p> <p>Pour afficher les utilisateurs actuellement connect\u00e9s :</p> Bash<pre><code>who\nw\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap09/#les-groupes-en-detail","title":"Les groupes en d\u00e9tail","text":""},{"location":"_projects/_formation-bash/bash-chap09/#concept-des-groupes","title":"Concept des groupes","text":"<p>Un groupe sous Linux est un ensemble d'utilisateurs. Les groupes permettent d'attribuer des permissions \u00e0 plusieurs utilisateurs simultan\u00e9ment sans devoir les configurer individuellement. Par exemple, tous les d\u00e9veloppeurs d'une \u00e9quipe peuvent faire partie du groupe <code>developers</code>, ce qui permet de leur accorder des permissions sur des fichiers partag\u00e9s de mani\u00e8re centralis\u00e9e.[1]</p>"},{"location":"_projects/_formation-bash/bash-chap09/#ajouter-un-groupe","title":"Ajouter un groupe","text":"<p>Pour cr\u00e9er un nouveau groupe :</p> Bash<pre><code>sudo groupadd nom_groupe\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap09/#supprimer-un-groupe","title":"Supprimer un groupe","text":"Bash<pre><code>sudo groupdel nom_groupe\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap09/#ajouter-un-utilisateur-a-un-groupe","title":"Ajouter un utilisateur \u00e0 un groupe","text":"Bash<pre><code>sudo usermod -a -G nom_groupe utilisateur\n</code></pre> <p>L'option <code>-a</code> ajoute l'utilisateur au groupe (sans le retirer des autres groupes). L'option <code>-G</code> sp\u00e9cifie le groupe secondaire.</p>"},{"location":"_projects/_formation-bash/bash-chap09/#afficher-les-groupes-dun-utilisateur","title":"Afficher les groupes d'un utilisateur","text":"Bash<pre><code>groups utilisateur\n</code></pre> <p>Ou pour l'utilisateur actuel :</p> Bash<pre><code>groups\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap09/#afficher-tous-les-groupes","title":"Afficher tous les groupes","text":"<p>Les groupes sont stock\u00e9s dans le fichier <code>/etc/group</code> :</p> Bash<pre><code>cat /etc/group\n</code></pre> <p>Chaque ligne a le format : <code>nom:mot_de_passe:GID:liste_d'utilisateurs</code></p>"},{"location":"_projects/_formation-bash/bash-chap09/#exemple-pratique","title":"Exemple pratique","text":"<p>Cr\u00e9er un groupe pour des d\u00e9veloppeurs et ajouter des utilisateurs :</p> Bash<pre><code>sudo groupadd developers\nsudo usermod -a -G developers alice\nsudo usermod -a -G developers bob\nsudo usermod -a -G developers charlie\n</code></pre> <p>V\u00e9rifier :</p> Bash<pre><code>cat /etc/group | grep developers\n</code></pre> <p>R\u00e9sultat :</p> Text Only<pre><code>developers:x:1001:alice,bob,charlie\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap09/#modifier-les-proprietaires-de-fichiers","title":"Modifier les propri\u00e9taires de fichiers","text":""},{"location":"_projects/_formation-bash/bash-chap09/#concept-de-propriete","title":"Concept de propri\u00e9t\u00e9","text":"<p>Chaque fichier et r\u00e9pertoire poss\u00e8de un propri\u00e9taire (l'utilisateur qui l'a cr\u00e9\u00e9 ou \u00e0 qui il a \u00e9t\u00e9 attribu\u00e9) et un groupe propri\u00e9taire. Le propri\u00e9taire dispose g\u00e9n\u00e9ralement de plus de permissions sur le fichier que les autres utilisateurs.[2]</p>"},{"location":"_projects/_formation-bash/bash-chap09/#afficher-le-proprietaire","title":"Afficher le propri\u00e9taire","text":"<p>La commande <code>ls -l</code> affiche le propri\u00e9taire et le groupe :</p> Bash<pre><code>ls -l fichier.txt\n</code></pre> <p>R\u00e9sultat :</p> Text Only<pre><code>-rw-r--r-- 1 alice developers 1234 Apr 13 2025 fichier.txt\n</code></pre> <p>Le propri\u00e9taire est <code>alice</code> et le groupe propri\u00e9taire est <code>developers</code>.</p>"},{"location":"_projects/_formation-bash/bash-chap09/#changer-le-proprietaire-avec-chown","title":"Changer le propri\u00e9taire avec chown","text":"<p>La commande <code>chown</code> (change owner) modifie le propri\u00e9taire d'un fichier :[2]</p> Bash<pre><code>sudo chown utilisateur fichier\n</code></pre> <p>Exemple :</p> Bash<pre><code>sudo chown bob fichier.txt\n</code></pre> <p>Le fichier <code>fichier.txt</code> appartient d\u00e9sormais \u00e0 <code>bob</code>.</p>"},{"location":"_projects/_formation-bash/bash-chap09/#changer-le-groupe-proprietaire","title":"Changer le groupe propri\u00e9taire","text":"<p>Changer seulement le groupe :</p> Bash<pre><code>sudo chown :nouveau_groupe fichier\n</code></pre> <p>Exemple :</p> Bash<pre><code>sudo chown :developers fichier.txt\n</code></pre> <p>Le groupe propri\u00e9taire devient <code>developers</code>, le propri\u00e9taire reste inchang\u00e9.</p>"},{"location":"_projects/_formation-bash/bash-chap09/#changer-le-proprietaire-et-le-groupe","title":"Changer le propri\u00e9taire et le groupe","text":"<p>Pour changer \u00e0 la fois le propri\u00e9taire et le groupe :</p> Bash<pre><code>sudo chown utilisateur:groupe fichier\n</code></pre> <p>Exemple :</p> Bash<pre><code>sudo chown alice:developers fichier.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap09/#modifier-recursivement","title":"Modifier r\u00e9cursivement","text":"<p>L'option <code>-R</code> (r\u00e9cursive) modifie le propri\u00e9taire et le groupe d'un r\u00e9pertoire et de tout son contenu :</p> Bash<pre><code>sudo chown -R utilisateur:groupe repertoire\n</code></pre> <p>Exemple :</p> Bash<pre><code>sudo chown -R alice:developers /home/alice/projet/\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap09/#exemples-pratiques","title":"Exemples pratiques","text":"<p>Cr\u00e9er un projet partag\u00e9 :</p> Bash<pre><code>sudo mkdir /home/projets/monprojet\nsudo chown alice:developers /home/projets/monprojet\nsudo chmod 770 /home/projets/monprojet\n</code></pre> <p>Cette configuration permet \u00e0 <code>alice</code> et tous les membres du groupe <code>developers</code> d'acc\u00e9der au r\u00e9pertoire (lecture, \u00e9criture, ex\u00e9cution), tandis que les autres utilisateurs n'y ont aucun acc\u00e8s.</p> <p>Transf\u00e9rer la propri\u00e9t\u00e9 d'un fichier :</p> Bash<pre><code>sudo chown bob:bob document.txt\nls -l document.txt\n</code></pre> <p>R\u00e9sultat :</p> Text Only<pre><code>-rw-r--r-- 1 bob bob 4567 Apr 13 2025 document.txt\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap09/#repartition-pratique-des-taches-et-flux-de-travail","title":"R\u00e9partition pratique des t\u00e2ches et flux de travail","text":""},{"location":"_projects/_formation-bash/bash-chap09/#scenario-1-rendre-un-script-executable","title":"Sc\u00e9nario 1 : Rendre un script ex\u00e9cutable","text":"<p>Un d\u00e9veloppeur cr\u00e9e un script shell mais obtient un message d'erreur lors de son ex\u00e9cution :[2]</p> Bash<pre><code>./monscript.sh\n</code></pre> <p>Erreur :</p> Text Only<pre><code>bash: ./monscript.sh: Permission denied\n</code></pre> <p>Diagnostic : Le fichier ne poss\u00e8de pas la permission d'ex\u00e9cution (x).</p> <p>Solution :</p> Bash<pre><code>chmod +x monscript.sh\n</code></pre> <p>Ou avec la m\u00e9thode num\u00e9rique :</p> Bash<pre><code>chmod 755 monscript.sh\n</code></pre> <p>V\u00e9rification :</p> Bash<pre><code>ls -l monscript.sh\n./monscript.sh\n</code></pre> <p>R\u00e9sultat :</p> Text Only<pre><code>-rwxrwxr-x. 1 francois francois 51 17 jan 05:02 monscript.sh\n</code></pre> <p>Le script s'ex\u00e9cute maintenant correctement.[5]</p>"},{"location":"_projects/_formation-bash/bash-chap09/#scenario-2-proteger-un-fichier-de-configuration-sensible","title":"Sc\u00e9nario 2 : Prot\u00e9ger un fichier de configuration sensible","text":"<p>Un administrateur a cr\u00e9\u00e9 un fichier de configuration contenant des mots de passe :</p> Bash<pre><code># Configuration sensible\nchmod 600 /etc/config/credentials.conf\nls -l /etc/config/credentials.conf\n</code></pre> <p>R\u00e9sultat :</p> Text Only<pre><code>-rw------- 1 admin admin 2345 Apr 13 2025 /etc/config/credentials.conf\n</code></pre> <p>Seul le propri\u00e9taire (<code>admin</code>) peut lire et \u00e9crire le fichier. Personne d'autre n'a acc\u00e8s.[2]</p>"},{"location":"_projects/_formation-bash/bash-chap09/#scenario-3-configuration-dun-repertoire-partage-en-equipe","title":"Sc\u00e9nario 3 : Configuration d'un r\u00e9pertoire partag\u00e9 en \u00e9quipe","text":"<p>Une \u00e9quipe de d\u00e9veloppeurs doit collaborer sur un projet. L'administrateur configure :</p> Bash<pre><code># Cr\u00e9er le r\u00e9pertoire\nsudo mkdir -p /home/projets/webapp\n\n# Assigner le propri\u00e9taire et le groupe\nsudo chown alice:developers /home/projets/webapp\n\n# Attribuer les permissions\nsudo chmod 770 /home/projets/webapp\n\n# V\u00e9rifier\nls -ld /home/projets/webapp\n</code></pre> <p>R\u00e9sultat :</p> Text Only<pre><code>drwxrwx--- 1 alice developers 4096 Apr 13 2025 /home/projets/webapp\n</code></pre> <ul> <li>Le propri\u00e9taire (<code>alice</code>) peut lire, \u00e9crire et entrer dans le r\u00e9pertoire</li> <li>Les membres du groupe <code>developers</code> peuvent aussi lire, \u00e9crire et entrer</li> <li>Les autres utilisateurs n'ont aucun acc\u00e8s[2]</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap09/#scenario-4-rendre-un-programme-accessible-a-tous","title":"Sc\u00e9nario 4 : Rendre un programme accessible \u00e0 tous","text":"<p>Une entreprise installe un logiciel qui doit \u00eatre ex\u00e9cutable par tous les utilisateurs :</p> Bash<pre><code># Assigner le programme au root\nsudo chown root:root /usr/local/bin/monprogramme\n\n# Permissions : propri\u00e9taire peut tout faire, groupe et autres peuvent ex\u00e9cuter\nsudo chmod 755 /usr/local/bin/monprogramme\n\n# V\u00e9rifier\nls -l /usr/local/bin/monprogramme\n</code></pre> <p>R\u00e9sultat :</p> Text Only<pre><code>-rwxr-xr-x 1 root root 45678 Apr 13 2025 /usr/local/bin/monprogramme\n</code></pre> <p>Tous les utilisateurs peuvent ex\u00e9cuter le programme, mais seul <code>root</code> peut le modifier.[2]</p>"},{"location":"_projects/_formation-bash/bash-chap09/#cas-particuliers-et-erreurs-courantes","title":"Cas particuliers et erreurs courantes","text":""},{"location":"_projects/_formation-bash/bash-chap09/#erreur-permission-denied","title":"Erreur \u00ab Permission denied \u00bb","text":"<p>Sympt\u00f4me : <code>bash: ./script.sh: Permission denied</code>[2]</p> <p>Cause : Le fichier n'a pas la permission d'ex\u00e9cution (x).</p> <p>Solution :</p> Bash<pre><code>chmod +x script.sh\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap09/#fichier-cree-sans-permission-de-lecture","title":"Fichier cr\u00e9\u00e9 sans permission de lecture","text":"<p>Sympt\u00f4me : Impossible de lire un fichier cr\u00e9\u00e9.</p> <p>Cause : Les permissions par d\u00e9faut (umask) ont restreint l'acc\u00e8s.</p> <p>Solution :</p> Bash<pre><code>chmod +r fichier\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap09/#impossible-de-supprimer-un-fichier-dans-un-repertoire","title":"Impossible de supprimer un fichier dans un r\u00e9pertoire","text":"<p>Cause : Manque de permission d'\u00e9criture (w) sur le r\u00e9pertoire contenant le fichier.</p> <p>Solution :</p> Bash<pre><code>chmod u+w /chemin/vers/repertoire\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap09/#acces-refuse-a-un-repertoire","title":"Acc\u00e8s refus\u00e9 \u00e0 un r\u00e9pertoire","text":"<p>Cause : Manque de permission d'ex\u00e9cution (x) sur le r\u00e9pertoire.</p> <p>Solution :</p> Bash<pre><code>chmod u+x /chemin/vers/repertoire\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap09/#bonnes-pratiques-de-securite","title":"Bonnes pratiques de s\u00e9curit\u00e9","text":""},{"location":"_projects/_formation-bash/bash-chap09/#principes-generaux","title":"Principes g\u00e9n\u00e9raux","text":"<p>Appliquer le principe du moindre privil\u00e8ge : N'accorder que les permissions strictement n\u00e9cessaires. Par exemple, un fichier de script ne devrait avoir la permission d'\u00e9criture que pour le propri\u00e9taire.[2]</p> <p>V\u00e9rifier r\u00e9guli\u00e8rement les permissions : Utiliser <code>ls -l</code> ou des outils sp\u00e9cialis\u00e9s pour auditer les permissions de fichiers importants.</p> <p>Documenter les changements : Noter quand et pourquoi les permissions ont \u00e9t\u00e9 modifi\u00e9es.</p>"},{"location":"_projects/_formation-bash/bash-chap09/#permissions-recommandees","title":"Permissions recommand\u00e9es","text":"Type de fichier Permission Notation octale Justification Fichier ordinaire <code>-rw-r--r--</code> 644 Propri\u00e9taire peut lire/\u00e9crire, autres en lecture Script ex\u00e9cutable <code>-rwxr-xr-x</code> 755 Propri\u00e9taire peut tout faire, autres ex\u00e9cutent Fichier sensible <code>-rw-------</code> 600 Acc\u00e8s propri\u00e9taire uniquement R\u00e9pertoire partag\u00e9 <code>drwxrwx---</code> 770 Propri\u00e9taire et groupe ont acc\u00e8s, autres non R\u00e9pertoire priv\u00e9 <code>drwx------</code> 700 Acc\u00e8s propri\u00e9taire uniquement R\u00e9pertoire public <code>drwxr-xr-x</code> 755 Tous peuvent lire et traverser"},{"location":"_projects/_formation-bash/bash-chap09/#resume-du-chemin-dapprentissage","title":"R\u00e9sum\u00e9 du chemin d'apprentissage","text":"<p>La ma\u00eetrise des permissions sous Linux n\u00e9cessite une compr\u00e9hension progressive :</p> <p>\u00c9tape 1 - Comprendre la structure : Apprendre \u00e0 lire les neuf caract\u00e8res de permissions avec <code>ls -l</code> et comprendre les trois cat\u00e9gories d'utilisateurs (propri\u00e9taire, groupe, autres).</p> <p>\u00c9tape 2 - Ma\u00eetriser les deux notations : Comprendre la notation symbolique (rwx) et la notation octale (0-7) pour pouvoir utiliser indiff\u00e9remment l'une ou l'autre.</p> <p>\u00c9tape 3 - Utiliser chmod : Modifier les permissions en utilisant d'abord la m\u00e9thode num\u00e9rique (plus simple), puis la m\u00e9thode symbolique (plus flexible).</p> <p>\u00c9tape 4 - G\u00e9rer les utilisateurs et groupes : Cr\u00e9er et configurer des utilisateurs, les organiser en groupes, et comprendre comment cela impact les permissions.</p> <p>\u00c9tape 5 - Modifier la propri\u00e9t\u00e9 : Utiliser <code>chown</code> pour assigner correctement les fichiers aux utilisateurs et groupes appropri\u00e9s.</p> <p>\u00c9tape 6 - Appliquer en pratique : Impl\u00e9menter des sc\u00e9narios r\u00e9els : prot\u00e9ger des fichiers sensibles, cr\u00e9er des espaces partag\u00e9s en \u00e9quipe, g\u00e9rer des scripts et programmes.</p> <p>\u00c9tape 7 - Ma\u00eetriser la s\u00e9curit\u00e9 : Appliquer les bonnes pratiques de s\u00e9curit\u00e9 et \u00e9viter les erreurs courantes qui pourraient comprometttre la s\u00e9curit\u00e9 du syst\u00e8me.</p> <p>Cette progression permet de passer de la th\u00e9orie \u00e0 la pratique de mani\u00e8re progressive et logique, chaque concept s'appuyant sur le pr\u00e9c\u00e9dent.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-bash/bash-chap10/","title":"Citations","text":"<ul> <li>https://www.it-connect.fr/debuter-script-bash-linux/</li> <li>https://linux.goffinet.org/administration/scripts-shell/</li> <li>https://www.datacamp.com/fr/tutorial/how-to-write-bash-script-tutorial</li> <li>https://www.hostinger.com/fr/tutoriels/script-bash</li> <li>https://tutoriels.lws.fr/vps/initiation-au-script-bash-linux-avec-exemples</li> <li>https://blog.stephane-robert.info/docs/admin-serveurs/linux/shells-linux/bash/</li> <li>http://doc.ubuntu-fr.org/tutoriel/script_shell</li> <li>https://www.youtube.com/watch?v=gBCGeLjYBgQ</li> <li>https://www.formatux.fr/formatux-bash/module-010-niveau1/index.html</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap10/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 309</li> <li>completion_tokens: 9026</li> <li>total_tokens: 9335</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.135, 'request_cost': 0.006, 'total_cost': 0.142}</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap10/#content","title":"Content","text":""},{"location":"_projects/_formation-bash/bash-chap10/#guide-complet-des-scripts-shell-bash-sous-linux","title":"\ud83d\udcd8 Guide Complet des Scripts Shell Bash sous Linux","text":""},{"location":"_projects/_formation-bash/bash-chap10/#introduction-aux-scripts-shell","title":"\ud83c\udfaf Introduction aux Scripts Shell","text":"<p>Un script shell est un fichier texte contenant une s\u00e9rie de commandes qui sont ex\u00e9cut\u00e9es en s\u00e9quence par l'interpr\u00e9teur Bash[1][6]. Ces scripts permettent d'automatiser des t\u00e2ches r\u00e9p\u00e9titives et de consolider plusieurs commandes longues en un seul code ex\u00e9cutable[4]. Bash est facilement disponible sur presque toutes les versions de Linux et ne n\u00e9cessite aucune installation s\u00e9pa\u00e9e[4].</p> <p>Un script Bash offre une puissance consid\u00e9rable pour les d\u00e9veloppeurs et administrateurs syst\u00e8mes. Il r\u00e9duit les t\u00e2ches manuelles r\u00e9p\u00e9titives en un simple appel de fonction, am\u00e9liorant ainsi l'efficacit\u00e9 du flux de travail[4].</p>"},{"location":"_projects/_formation-bash/bash-chap10/#structure-fondamentale-dun-script-bash","title":"Structure Fondamentale d'un Script Bash","text":"<p>Tout script Bash doit d\u00e9buter par le shebang, une ligne sp\u00e9ciale qui indique \u00e0 Linux quel interpr\u00e9teur utiliser pour ex\u00e9cuter le code[1][3]. Cette premi\u00e8re ligne est cruciale et d\u00e9finit le chemin de l'interpr\u00e9teur Bash :</p> Bash<pre><code>#!/bin/bash\n</code></pre> <p>Alternativement, une forme plus portable existe :</p> Bash<pre><code>#!/usr/bin/env bash\n</code></pre> <p>Cette seconde approche recherche l'ex\u00e9cutable bash dans le PATH du syst\u00e8me, ce qui la rend plus adapt\u00e9e aux environnements h\u00e9t\u00e9rog\u00e8nes[6].</p> <p>Apr\u00e8s le shebang, le script contient les commandes et les instructions qui forment le corps du programme. Les commentaires peuvent \u00eatre ajout\u00e9s en commen\u00e7ant une ligne par le caract\u00e8re <code>#</code>[1].</p>"},{"location":"_projects/_formation-bash/bash-chap10/#execution-dun-script-bash","title":"Ex\u00e9cution d'un Script Bash","text":"<p>Pour ex\u00e9cuter un script Bash, deux approches principales existent[5] :</p> <p>La premi\u00e8re m\u00e9thode consiste \u00e0 invoquer directement Bash avec le fichier en argument :</p> Bash<pre><code>bash First.sh\n</code></pre> <p>La seconde m\u00e9thode rend le fichier ex\u00e9cutable en modifiant ses permissions, puis l'ex\u00e9cute directement :</p> Bash<pre><code>chmod a+x First.sh\n./First.sh\n</code></pre> <p>La commande <code>chmod a+x</code> conf\u00e8re les droits d'ex\u00e9cution \u00e0 tous les utilisateurs sur le fichier[1]. Sans cette modification, l'ex\u00e9cution directe du script \u00e9chouerait.</p>"},{"location":"_projects/_formation-bash/bash-chap10/#les-developpements-et-les-inhibitions","title":"\ud83d\udd27 Les D\u00e9veloppements et les Inhibitions","text":""},{"location":"_projects/_formation-bash/bash-chap10/#concept-de-developpement-et-dinhibition","title":"Concept de D\u00e9veloppement et d'Inhibition","text":"<p>Dans le contexte des scripts Bash, les d\u00e9veloppements et inhibitions font r\u00e9f\u00e9rence \u00e0 la fa\u00e7on dont Bash traite et interpr\u00e8te les variables, les commandes et les cha\u00eenes de caract\u00e8res. Ce processus d\u00e9termine comment les variables sont remplac\u00e9es par leurs valeurs, comment les commandes de substitution sont ex\u00e9cut\u00e9es, et comment les caract\u00e8res sp\u00e9ciaux sont interpr\u00e9t\u00e9s.</p>"},{"location":"_projects/_formation-bash/bash-chap10/#inhibition-des-caracteres-speciaux","title":"Inhibition des Caract\u00e8res Sp\u00e9ciaux","text":"<p>Bash poss\u00e8de plusieurs m\u00e9canismes pour inhiber ou emp\u00eacher l'interpr\u00e9tation de caract\u00e8res sp\u00e9ciaux :</p> <p>L'\u00e9chappement avec l'antislash : Le caract\u00e8re <code>\\</code> permet d'\u00e9chapper un caract\u00e8re sp\u00e9cial pour emp\u00eacher son interpr\u00e9tation :</p> Bash<pre><code>#!/bin/bash\n\n# Sans \u00e9chappement - le dollar est interpr\u00e9t\u00e9\necho \"$USER\"  # Affiche le nom d'utilisateur\n\n# Avec \u00e9chappement - le dollar est litt\u00e9ral\necho \"\\$USER\"  # Affiche litt\u00e9ralement: $USER\n</code></pre> <p>Les guillemets simples : Ils inhibent compl\u00e8tement l'interpr\u00e9tation de tous les caract\u00e8res sp\u00e9ciaux :</p> Bash<pre><code>#!/bin/bash\n\nUSER=\"Jean\"\necho 'Bonjour $USER'  # Affiche litt\u00e9ralement: Bonjour $USER\necho \"Bonjour $USER\"  # Affiche: Bonjour Jean\n</code></pre> <p>Les guillemets doubles : Ils permettent une inhibition partielle, permettant la substitution des variables mais pas celle des commandes :</p> Bash<pre><code>#!/bin/bash\n\nfichier=\"test.txt\"\necho \"Le fichier est: $fichier\"  # Substitution activ\u00e9e\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#substitution-de-commandes","title":"Substitution de Commandes","text":"<p>La substitution de commandes remplace une commande par son r\u00e9sultat :</p> Bash<pre><code>#!/bin/bash\n\n# Syntaxe ancienne (backticks)\ndate_actuelle=`date`\n\n# Syntaxe moderne (pr\u00e9f\u00e9r\u00e9e)\ndate_actuelle=$(date)\n\necho \"La date actuelle est: $date_actuelle\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#tests-et-expressions-conditionnelles","title":"\ud83e\uddea Tests et Expressions Conditionnelles","text":""},{"location":"_projects/_formation-bash/bash-chap10/#syntaxe-generale-des-tests","title":"Syntaxe G\u00e9n\u00e9rale des Tests","text":"<p>Les tests dans Bash \u00e9valuent des conditions et retournent un code de sortie : 0 pour vrai, non-z\u00e9ro pour faux. Les tests utilisant la syntaxe <code>[ ]</code> ou <code>[[ ]]</code> :</p> Bash<pre><code>[ expression ]\n[[ expression ]]\n</code></pre> <p>La syntaxe <code>[[ ]]</code> est plus moderne et offre des fonctionnalit\u00e9s suppl\u00e9mentaires, bien que <code>[ ]</code> soit plus portable[2].</p>"},{"location":"_projects/_formation-bash/bash-chap10/#tests-sur-les-fichiers","title":"Tests sur les Fichiers","text":"<p>Bash offre une vari\u00e9t\u00e9 de tests pour examiner les propri\u00e9t\u00e9s des fichiers :</p> Bash<pre><code>#!/bin/bash\n\n# Test d'existence de fichier\nif [ -e /etc/passwd ]; then\n    echo \"Le fichier existe\"\nfi\n\n# Test de fichier r\u00e9gulier\nif [ -f /etc/passwd ]; then\n    echo \"C'est un fichier r\u00e9gulier\"\nfi\n\n# Test de r\u00e9pertoire\nif [ -d /home ]; then\n    echo \"C'est un r\u00e9pertoire\"\nfi\n\n# Test de fichier lisible\nif [ -r /etc/passwd ]; then\n    echo \"Le fichier est lisible\"\nfi\n\n# Test de fichier accessible en \u00e9criture\nif [ -w test.txt ]; then\n    echo \"Le fichier est accessible en \u00e9criture\"\nfi\n\n# Test de fichier ex\u00e9cutable\nif [ -x /bin/bash ]; then\n    echo \"Le fichier est ex\u00e9cutable\"\nfi\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#tests-sur-les-chaines-de-caracteres","title":"Tests sur les Cha\u00eenes de Caract\u00e8res","text":"<p>Les tests sur les cha\u00eenes permettent de comparer des textes :</p> Bash<pre><code>#!/bin/bash\n\nchaine1=\"Bonjour\"\nchaine2=\"Bonjour\"\nchaine_vide=\"\"\n\n# Test d'\u00e9galit\u00e9\nif [ \"$chaine1\" = \"$chaine2\" ]; then\n    echo \"Les cha\u00eenes sont identiques\"\nfi\n\n# Test d'in\u00e9galit\u00e9\nif [ \"$chaine1\" != \"Adieu\" ]; then\n    echo \"Les cha\u00eenes sont diff\u00e9rentes\"\nfi\n\n# Test de cha\u00eene vide\nif [ -z \"$chaine_vide\" ]; then\n    echo \"La cha\u00eene est vide\"\nfi\n\n# Test de cha\u00eene non vide\nif [ -n \"$chaine1\" ]; then\n    echo \"La cha\u00eene n'est pas vide\"\nfi\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#tests-numeriques","title":"Tests Num\u00e9riques","text":"<p>Les tests num\u00e9riques permettent de comparer des nombres entiers :</p> Bash<pre><code>#!/bin/bash\n\nnombre1=10\nnombre2=20\n\n# \u00c9galit\u00e9 num\u00e9rique\nif [ \"$nombre1\" -eq \"$nombre2\" ]; then\n    echo \"Les nombres sont \u00e9gaux\"\nfi\n\n# In\u00e9galit\u00e9 num\u00e9rique\nif [ \"$nombre1\" -ne \"$nombre2\" ]; then\n    echo \"Les nombres sont diff\u00e9rents\"\nfi\n\n# Inf\u00e9rieur \u00e0\nif [ \"$nombre1\" -lt \"$nombre2\" ]; then\n    echo \"$nombre1 est inf\u00e9rieur \u00e0 $nombre2\"\nfi\n\n# Sup\u00e9rieur \u00e0\nif [ \"$nombre1\" -gt \"$nombre2\" ]; then\n    echo \"$nombre1 est sup\u00e9rieur \u00e0 $nombre2\"\nfi\n\n# Inf\u00e9rieur ou \u00e9gal \u00e0\nif [ \"$nombre1\" -le \"$nombre2\" ]; then\n    echo \"$nombre1 est inf\u00e9rieur ou \u00e9gal \u00e0 $nombre2\"\nfi\n\n# Sup\u00e9rieur ou \u00e9gal \u00e0\nif [ \"$nombre1\" -ge \"$nombre2\" ]; then\n    echo \"$nombre1 est sup\u00e9rieur ou \u00e9gal \u00e0 $nombre2\"\nfi\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#operateurs-logiques","title":"Op\u00e9rateurs Logiques","text":"<p>Les op\u00e9rateurs logiques permettent de combiner plusieurs expressions :</p> Bash<pre><code>#!/bin/bash\n\nage=25\nrevenu=50000\n\n# Op\u00e9rateur ET logique\nif [ \"$age\" -gt 18 ] &amp;&amp; [ \"$revenu\" -gt 30000 ]; then\n    echo \"\u00c9ligible pour le cr\u00e9dit\"\nfi\n\n# Op\u00e9rateur OU logique\nif [ \"$age\" -lt 18 ] || [ \"$age\" -gt 65 ]; then\n    echo \"Cat\u00e9gorie sp\u00e9ciale\"\nfi\n\n# N\u00e9gation logique\nif [ ! -f /tmp/fichier_inexistant ]; then\n    echo \"Le fichier n'existe pas\"\nfi\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#obtenir-des-donnees-entrees-par-lutilisateur","title":"\ud83d\udce5 Obtenir des Donn\u00e9es Entr\u00e9es par l'Utilisateur","text":""},{"location":"_projects/_formation-bash/bash-chap10/#utilisation-de-la-commande-read","title":"Utilisation de la Commande <code>read</code>","text":"<p>La commande <code>read</code> permet de capturer des donn\u00e9es saisies au clavier par l'utilisateur :</p> Bash<pre><code>#!/bin/bash\n\necho \"Quel est votre nom ?\"\nread nom\n\necho \"Bonjour, $nom !\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#lecture-avec-invite","title":"Lecture Avec Invite","text":"<p>L'option <code>-p</code> permet d'afficher une invite directement :</p> Bash<pre><code>#!/bin/bash\n\nread -p \"Entrez votre nom: \" nom\nread -p \"Entrez votre \u00e2ge: \" age\n\necho \"Vous vous appelez $nom et vous avez $age ans\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#lecture-de-multiples-variables","title":"Lecture de Multiples Variables","text":"<p>Une seule ligne de <code>read</code> peut capturer plusieurs variables :</p> Bash<pre><code>#!/bin/bash\n\nread -p \"Entrez votre pr\u00e9nom et votre nom: \" prenom nom\n\necho \"Pr\u00e9nom: $prenom\"\necho \"Nom: $nom\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#lecture-silencieuse-mots-de-passe","title":"Lecture Silencieuse (Mots de Passe)","text":"<p>L'option <code>-s</code> masque l'affichage des caract\u00e8res saisis, utile pour les mots de passe :</p> Bash<pre><code>#!/bin/bash\n\nread -sp \"Entrez votre mot de passe: \" motdepasse\necho\necho \"Mot de passe re\u00e7u (masqu\u00e9 lors de la saisie)\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#lecture-de-fichiers","title":"Lecture de Fichiers","text":"<p>La commande <code>read</code> peut aussi lire ligne par ligne un fichier :</p> Bash<pre><code>#!/bin/bash\n\nwhile read ligne; do\n    echo \"Ligne lue: $ligne\"\ndone &lt; /etc/hostname\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#parametres-positionnels","title":"Param\u00e8tres Positionnels","text":"<p>Au-del\u00e0 de l'interactivit\u00e9, les scripts re\u00e7oivent des arguments via la ligne de commande :</p> Bash<pre><code>#!/bin/bash\n\necho \"Nom du script: $0\"\necho \"Premier argument: $1\"\necho \"Deuxi\u00e8me argument: $2\"\necho \"Nombre d'arguments: $#\"\necho \"Tous les arguments: $@\"\n</code></pre> <p>Ex\u00e9cution :</p> Bash<pre><code>./script.sh argument1 argument2\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#les-parametres-et-les-variables","title":"\ud83d\udcca Les Param\u00e8tres et les Variables","text":""},{"location":"_projects/_formation-bash/bash-chap10/#declaration-et-assignation-de-variables","title":"D\u00e9claration et Assignation de Variables","text":"<p>Les variables dans Bash sont d\u00e9clar\u00e9es simplement en les assignant :</p> Bash<pre><code>#!/bin/bash\n\n# Assignation simple\nprenom=\"Marie\"\nage=30\nprix=19.99\n\n# Utilisation des variables\necho \"Pr\u00e9nom: $prenom\"\necho \"\u00c2ge: $age\"\necho \"Prix: $prix\"\n</code></pre> <p>Important : Aucun espace n'est autoris\u00e9 autour du signe <code>=</code> lors de l'assignation.</p>"},{"location":"_projects/_formation-bash/bash-chap10/#variables-internes-predefinies","title":"Variables Internes (Pr\u00e9d\u00e9finies)","text":"<p>Bash fournit plusieurs variables pr\u00e9d\u00e9finies :</p> Bash<pre><code>#!/bin/bash\n\n# $0 : Nom du script\necho \"Script: $0\"\n\n# $1, $2, etc. : Arguments positionnels\necho \"Premier argument: $1\"\n\n# $# : Nombre d'arguments\necho \"Nombre d'arguments: $#\"\n\n# $@ : Tous les arguments\necho \"Tous les arguments: $@\"\n\n# $* : Tous les arguments (diff\u00e9rent dans les boucles)\necho \"Tous les arguments (*): $*\"\n\n# $? : Code de retour de la derni\u00e8re commande\nls /tmp\necho \"Code de retour: $?\"\n\n# $$ : PID du processus shell actuel\necho \"PID du shell: $$\"\n\n# $! : PID du dernier processus lanc\u00e9 en arri\u00e8re-plan\nsleep 100 &amp;\necho \"PID du dernier processus: $!\"\n\n# $- : Options du shell\necho \"Options du shell: $-\"\n\n# $PWD : R\u00e9pertoire de travail actuel\necho \"R\u00e9pertoire actuel: $PWD\"\n\n# $HOME : R\u00e9pertoire personnel de l'utilisateur\necho \"R\u00e9pertoire personnel: $HOME\"\n\n# $USER : Nom de l'utilisateur actuel\necho \"Utilisateur: $USER\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#portee-des-variables","title":"Port\u00e9e des Variables","text":"<p>Par d\u00e9faut, les variables sont globales dans le script. Le mot-cl\u00e9 <code>local</code> les rend locales au contexte d'une fonction :</p> Bash<pre><code>#!/bin/bash\n\nvariable_globale=\"Je suis globale\"\n\nma_fonction() {\n    local variable_locale=\"Je suis locale\"\n    echo \"Dans la fonction: $variable_locale\"\n    echo \"Variable globale: $variable_globale\"\n}\n\nma_fonction\n\necho \"Hors de la fonction: $variable_globale\"\n# echo \"Hors de la fonction: $variable_locale\"  # Erreur - variable inexistante\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#substitution-de-variables","title":"Substitution de Variables","text":"<p>Les variables peuvent \u00eatre modifi\u00e9es et manipul\u00e9es :</p> Bash<pre><code>#!/bin/bash\n\ntexte=\"Bonjour le monde\"\n\n# Longueur de la cha\u00eene\necho \"Longueur: ${#texte}\"\n\n# Extraction de sous-cha\u00eene\necho \"Sous-cha\u00eene: ${texte:0:7}\"  # Affiche: Bonjour\n\n# Remplacement\necho \"Remplac\u00e9: ${texte/monde/univers}\"  # Affiche: Bonjour l'univers\n\n# Valeur par d\u00e9faut si variable non d\u00e9finie\necho \"Valeur: ${variable_inexistante:-valeur_defaut}\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#les-fonctions","title":"\ud83d\udd27 Les Fonctions","text":""},{"location":"_projects/_formation-bash/bash-chap10/#definition-et-appel-de-fonctions","title":"D\u00e9finition et Appel de Fonctions","text":"<p>Les fonctions permettent de regrouper du code r\u00e9utilisable :</p> Bash<pre><code>#!/bin/bash\n\n# D\u00e9finition d'une fonction\nsaluer() {\n    echo \"Bonjour, bienvenue dans mon script !\"\n}\n\n# Appel de la fonction\nsaluer\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#fonctions-avec-parametres","title":"Fonctions Avec Param\u00e8tres","text":"<p>Les fonctions re\u00e7oivent des param\u00e8tres comme les scripts principaux :</p> Bash<pre><code>#!/bin/bash\n\n# Fonction avec param\u00e8tres\ncalculer_somme() {\n    local nombre1=$1\n    local nombre2=$2\n    local somme=$((nombre1 + nombre2))\n    echo \"La somme de $nombre1 et $nombre2 est: $somme\"\n}\n\n# Appel de la fonction avec arguments\ncalculer_somme 10 20\ncalculer_somme 5 15\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#retour-de-valeurs","title":"Retour de Valeurs","text":"<p>Les fonctions retournent une valeur d'\u00e9tat (code de sortie) :</p> Bash<pre><code>#!/bin/bash\n\n# Fonction avec code de retour\nverifier_nombre() {\n    if [ \"$1\" -gt 0 ]; then\n        echo \"Nombre positif\"\n        return 0  # Succ\u00e8s\n    else\n        echo \"Nombre z\u00e9ro ou n\u00e9gatif\"\n        return 1  # Erreur\n    fi\n}\n\n# Utilisation du code de retour\nverifier_nombre 5\nif [ $? -eq 0 ]; then\n    echo \"V\u00e9rification r\u00e9ussie\"\nfi\n\nverifier_nombre -3\nif [ $? -ne 0 ]; then\n    echo \"V\u00e9rification \u00e9chou\u00e9e\"\nfi\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#recuperation-de-resultats-depuis-une-fonction","title":"R\u00e9cup\u00e9ration de R\u00e9sultats Depuis une Fonction","text":"<p>Pour retourner des donn\u00e9es, une fonction peut utiliser <code>echo</code> :</p> Bash<pre><code>#!/bin/bash\n\n# Fonction retournant une cha\u00eene\nobtenir_date_formatee() {\n    local format=\"$1\"\n    date +\"$format\"\n}\n\n# Capture du r\u00e9sultat\ndate_longue=$(obtenir_date_formatee \"%d/%m/%Y \u00e0 %H:%M:%S\")\necho \"Date et heure: $date_longue\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#structure-complete-avec-fonction-principale","title":"Structure Compl\u00e8te Avec Fonction Principale","text":"<p>Une organisation professionnelle inclut une fonction <code>main</code> :</p> Bash<pre><code>#!/bin/bash\n\n# Fonction secondaire\ntraiter_fichier() {\n    local fichier=\"$1\"\n    if [ -f \"$fichier\" ]; then\n        echo \"Nombre de lignes dans $fichier: $(wc -l &lt; \"$fichier\")\"\n        return 0\n    else\n        echo \"Erreur: le fichier $fichier n'existe pas\"\n        return 1\n    fi\n}\n\n# Fonction principale\nmain() {\n    if [ $# -lt 1 ]; then\n        echo \"Utilisation: $0 &lt;fichier&gt;\"\n        return 1\n    fi\n\n    traiter_fichier \"$1\"\n}\n\n# Ex\u00e9cution\nmain \"$@\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#les-operations-arithmetiques","title":"\ud83e\uddee Les Op\u00e9rations Arithm\u00e9tiques","text":""},{"location":"_projects/_formation-bash/bash-chap10/#syntaxe-de-larithmetique","title":"Syntaxe de l'Arithm\u00e9tique","text":"<p>Bash offre plusieurs syntaxes pour effectuer des calculs math\u00e9matiques :</p> Bash<pre><code>#!/bin/bash\n\n# Syntaxe $((expression))\nresultat=$((10 + 5))\necho \"10 + 5 = $resultat\"\n\n# Syntaxe $[expression]\nresultat=$[20 - 8]\necho \"20 - 8 = $resultat\"\n\n# Utilisation du programme expr\nresultat=$(expr 15 \\* 3)\necho \"15 * 3 = $resultat\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#operateurs-arithmetiques","title":"Op\u00e9rateurs Arithm\u00e9tiques","text":"Op\u00e9rateur Description Exemple <code>+</code> Addition <code>$((5 + 3))</code> \u2192 8 <code>-</code> Soustraction <code>$((10 - 4))</code> \u2192 6 <code>*</code> Multiplication <code>$((6 * 7))</code> \u2192 42 <code>/</code> Division enti\u00e8re <code>$((20 / 3))</code> \u2192 6 <code>%</code> Modulo (reste) <code>$((20 % 3))</code> \u2192 2 <code>**</code> Exponentiation <code>$((2 ** 8))</code> \u2192 256"},{"location":"_projects/_formation-bash/bash-chap10/#operateurs-composes","title":"Op\u00e9rateurs Compos\u00e9s","text":"<p>Les op\u00e9rateurs compos\u00e9s modifient une variable en place :</p> Bash<pre><code>#!/bin/bash\n\ncompteur=10\n\n# Incr\u00e9ment\n((compteur++))\necho \"Apr\u00e8s ++ : $compteur\"  # 11\n\n# D\u00e9c\u00e9ment\n((compteur--))\necho \"Apr\u00e8s -- : $compteur\"  # 10\n\n# Ajout compos\u00e9\n((compteur += 5))\necho \"Apr\u00e8s += 5 : $compteur\"  # 15\n\n# Soustraction compos\u00e9e\n((compteur -= 3))\necho \"Apr\u00e8s -= 3 : $compteur\"  # 12\n\n# Multiplication compos\u00e9e\n((compteur *= 2))\necho \"Apr\u00e8s *= 2 : $compteur\"  # 24\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#calculs-avec-decimales","title":"Calculs Avec D\u00e9cimales","text":"<p>Bash ne g\u00e8re nativement que les entiers. Pour les d\u00e9cimales, utiliser <code>bc</code> ou <code>awk</code> :</p> Bash<pre><code>#!/bin/bash\n\n# Utilisation de bc\nresultat=$(echo \"scale=2; 10 / 3\" | bc)\necho \"10 / 3 = $resultat\"  # 3.33\n\n# Utilisation d'awk\nresultat=$(awk \"BEGIN {print 5.5 + 2.3}\")\necho \"5.5 + 2.3 = $resultat\"  # 7.8\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#les-branchements-conditionnels","title":"\ud83d\udd00 Les Branchements Conditionnels","text":""},{"location":"_projects/_formation-bash/bash-chap10/#structure-if-then-else","title":"Structure if-then-else","text":"<p>La structure conditionnelle de base :</p> Bash<pre><code>#!/bin/bash\n\nnote=75\n\nif [ \"$note\" -ge 90 ]; then\n    echo \"Excellent!\"\nelif [ \"$note\" -ge 80 ]; then\n    echo \"Tr\u00e8s bien!\"\nelif [ \"$note\" -ge 70 ]; then\n    echo \"Bien!\"\nelse\n    echo \"\u00c0 revoir\"\nfi\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#structure-case","title":"Structure case","text":"<p>L'instruction <code>case</code> simplifie les branchements multiples :</p> Bash<pre><code>#!/bin/bash\n\nread -p \"Choisissez un jour (1-7): \" jour\n\ncase \"$jour\" in\n    1)\n        echo \"Lundi\"\n        ;;\n    2)\n        echo \"Mardi\"\n        ;;\n    3)\n        echo \"Mercredi\"\n        ;;\n    4)\n        echo \"Jeudi\"\n        ;;\n    5)\n        echo \"Vendredi\"\n        ;;\n    6|7)\n        echo \"Weekend\"\n        ;;\n    *)\n        echo \"Jour invalide\"\n        ;;\nesac\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#pattern-matching-avance","title":"Pattern Matching Avanc\u00e9","text":"<p>La structure <code>case</code> supporte les expressions r\u00e9guli\u00e8res :</p> Bash<pre><code>#!/bin/bash\n\nread -p \"Entrez un nom de fichier: \" fichier\n\ncase \"$fichier\" in\n    *.txt)\n        echo \"Fichier texte d\u00e9tect\u00e9\"\n        ;;\n    *.pdf)\n        echo \"Fichier PDF d\u00e9tect\u00e9\"\n        ;;\n    *.jpg|*.png|*.gif)\n        echo \"Fichier image d\u00e9tect\u00e9\"\n        ;;\n    *)\n        echo \"Type de fichier inconnu\"\n        ;;\nesac\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#structure-select","title":"Structure select","text":"<p>L'instruction <code>select</code> cr\u00e9e un menu interactif :</p> Bash<pre><code>#!/bin/bash\n\necho \"Que d\u00e9sirez-vous faire ?\"\nselect choix in \"Cr\u00e9er un fichier\" \"Lister les fichiers\" \"Supprimer un fichier\" \"Quitter\"\ndo\n    case \"$choix\" in\n        \"Cr\u00e9er un fichier\")\n            read -p \"Nom du fichier: \" nom\n            touch \"$nom\"\n            echo \"Fichier cr\u00e9\u00e9\"\n            ;;\n        \"Lister les fichiers\")\n            ls -la\n            ;;\n        \"Supprimer un fichier\")\n            read -p \"Nom du fichier \u00e0 supprimer: \" nom\n            rm \"$nom\"\n            echo \"Fichier supprim\u00e9\"\n            ;;\n        \"Quitter\")\n            break\n            ;;\n        *)\n            echo \"Choix invalide\"\n            ;;\n    esac\ndone\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#les-structures-iteratives","title":"\ud83d\udd01 Les Structures It\u00e9ratives","text":""},{"location":"_projects/_formation-bash/bash-chap10/#boucle-while","title":"Boucle while","text":"<p>La boucle <code>while</code> s'ex\u00e9cute tant qu'une condition est vraie :</p> Bash<pre><code>#!/bin/bash\n\ncompteur=1\n\nwhile [ \"$compteur\" -le 5 ]; do\n    echo \"It\u00e9ration $compteur\"\n    ((compteur++))\ndone\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#boucle-until","title":"Boucle until","text":"<p>La boucle <code>until</code> s'ex\u00e9cute tant qu'une condition est fausse :</p> Bash<pre><code>#!/bin/bash\n\ncompteur=1\n\nuntil [ \"$compteur\" -gt 5 ]; do\n    echo \"It\u00e9ration $compteur\"\n    ((compteur++))\ndone\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#boucle-for","title":"Boucle for","text":"<p>La boucle <code>for</code> it\u00e8re sur une liste de valeurs :</p> Bash<pre><code>#!/bin/bash\n\n# It\u00e9ration sur une liste explicite\nfor jour in \"Lundi\" \"Mardi\" \"Mercredi\" \"Jeudi\" \"Vendredi\"; do\n    echo \"Jour: $jour\"\ndone\n\n# It\u00e9ration sur une s\u00e9quence\nfor nombre in {1..5}; do\n    echo \"Nombre: $nombre\"\ndone\n\n# It\u00e9ration sur les fichiers d'un r\u00e9pertoire\nfor fichier in /etc/*.conf; do\n    echo \"Configuration: $(basename \"$fichier\")\"\ndone\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#boucle-for-classique-style-c","title":"Boucle for Classique (Style C)","text":"<p>Pour une it\u00e9ration num\u00e9rique classique :</p> Bash<pre><code>#!/bin/bash\n\n# Style C avec triple expression\nfor ((i=1; i&lt;=5; i++)); do\n    echo \"It\u00e9ration $i\"\ndone\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#iteration-sur-les-arguments","title":"It\u00e9ration sur les Arguments","text":"<p>Parcourir les param\u00e8tres pass\u00e9s au script :</p> Bash<pre><code>#!/bin/bash\n\necho \"Traitement des arguments:\"\nfor arg in \"$@\"; do\n    echo \"Argument: $arg\"\ndone\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#controle-du-flux-break-et-continue","title":"Contr\u00f4le du Flux : break et continue","text":"<p>Les instructions de contr\u00f4le modifient le flux it\u00e9ratif :</p> Bash<pre><code>#!/bin/bash\n\n# Utilisation de break\nfor i in {1..10}; do\n    if [ \"$i\" -eq 5 ]; then\n        echo \"Arr\u00eat \u00e0 $i\"\n        break\n    fi\n    echo \"Nombre: $i\"\ndone\n\n# Utilisation de continue\nfor i in {1..5}; do\n    if [ \"$i\" -eq 3 ]; then\n        echo \"Saut de $i\"\n        continue\n    fi\n    echo \"Nombre: $i\"\ndone\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#lecture-iterative-de-fichiers","title":"Lecture It\u00e9rative de Fichiers","text":"<p>Traiter chaque ligne d'un fichier :</p> Bash<pre><code>#!/bin/bash\n\nwhile IFS= read -r ligne; do\n    echo \"Ligne trait\u00e9e: $ligne\"\ndone &lt; /etc/passwd\n</code></pre> <p>La variable <code>IFS</code> (Internal Field Separator) contr\u00f4le le s\u00e9parateur de champs. En la fixant \u00e0 vide, on pr\u00e9serve les espaces de la ligne.</p>"},{"location":"_projects/_formation-bash/bash-chap10/#exemples-pratiques-complets","title":"\ud83d\udca1 Exemples Pratiques Complets","text":""},{"location":"_projects/_formation-bash/bash-chap10/#exemple-1-script-de-sauvegarde-incrementale","title":"Exemple 1 : Script de Sauvegarde Incr\u00e9mentale","text":"<p>Ce script cr\u00e9e une sauvegarde dat\u00e9e d'un r\u00e9pertoire :</p> Bash<pre><code>#!/bin/bash\n\n# Configuration\nREPERTOIRE_SOURCE=\"$HOME/Documents\"\nREPERTOIRE_BACKUP=\"$HOME/Backups\"\nDATE=$(date +\"%Y-%m-%d_%H-%M-%S\")\nNOM_ARCHIVE=\"backup_$DATE.tar.gz\"\n\n# V\u00e9rification de l'existence du r\u00e9pertoire de destination\nif [ ! -d \"$REPERTOIRE_BACKUP\" ]; then\n    mkdir -p \"$REPERTOIRE_BACKUP\"\n    echo \"R\u00e9pertoire de sauvegarde cr\u00e9\u00e9\"\nfi\n\n# Cr\u00e9ation de l'archive\necho \"Sauvegarde en cours...\"\ntar -czf \"$REPERTOIRE_BACKUP/$NOM_ARCHIVE\" \"$REPERTOIRE_SOURCE\"\n\n# V\u00e9rification du succ\u00e8s\nif [ $? -eq 0 ]; then\n    echo \"Sauvegarde r\u00e9ussie: $NOM_ARCHIVE\"\n    ls -lh \"$REPERTOIRE_BACKUP/$NOM_ARCHIVE\"\nelse\n    echo \"Erreur lors de la sauvegarde\"\n    exit 1\nfi\n\n# Nettoyage des anciennes sauvegardes (garder 7 derniers jours)\necho \"Nettoyage des anciennes sauvegardes...\"\nfind \"$REPERTOIRE_BACKUP\" -name \"backup_*.tar.gz\" -mtime +7 -delete\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#exemple-2-script-dadministration-systeme","title":"Exemple 2 : Script d'Administration Syst\u00e8me","text":"<p>Affiche les informations du syst\u00e8me :</p> Bash<pre><code>#!/bin/bash\n\nafficher_info_systeme() {\n    echo \"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\"\n    echo \"\u2551     INFORMATIONS SYST\u00c8ME               \u2551\"\n    echo \"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\"\n    echo\n\n    echo \"Nom d'h\u00f4te: $(hostname)\"\n    echo \"Utilisateur: $(whoami)\"\n    echo \"R\u00e9pertoire personnel: $HOME\"\n    echo \"Shell: $SHELL\"\n    echo\n\n    echo \"Syst\u00e8me d'exploitation: $(lsb_release -ds)\"\n    echo \"Noyau: $(uname -r)\"\n    echo \"Architecture: $(uname -m)\"\n    echo\n\n    echo \"Processeurs: $(nproc) cores\"\n    echo \"M\u00e9moire disponible: $(free -h | awk '/^Mem:/ {print $7}')\"\n    echo \"Espace disque: $(df -h / | awk 'NR==2 {print $4 \" disponible sur \" $2}')\"\n    echo\n\n    echo \"Uptime: $(uptime -p)\"\n    echo \"Charge syst\u00e8me: $(uptime | awk -F'load average:' '{print $2}')\"\n}\n\nafficher_info_systeme\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#exemple-3-gestionnaire-de-fichier-de-configuration","title":"Exemple 3 : Gestionnaire de Fichier de Configuration","text":"<p>Applique des configurations selon les pr\u00e9f\u00e9rences :</p> Bash<pre><code>#!/bin/bash\n\nCONFIG_FILE=\"$HOME/.mon_config\"\n\nsauvegarder_config() {\n    cat &gt; \"$CONFIG_FILE\" &lt;&lt; 'EOF'\n# Configuration personnelle\nEDITEUR=\"nano\"\nCOULEURS=\"oui\"\nVERBEUX=\"non\"\nREPERTOIRE_TRAVAIL=\"$HOME/Projets\"\nEOF\n    echo \"Configuration sauvegard\u00e9e\"\n}\n\ncharger_config() {\n    if [ -f \"$CONFIG_FILE\" ]; then\n        source \"$CONFIG_FILE\"\n        echo \"Configuration charg\u00e9e\"\n    else\n        echo \"Fichier de configuration non trouv\u00e9\"\n        sauvegarder_config\n    fi\n}\n\nafficher_config() {\n    if [ -f \"$CONFIG_FILE\" ]; then\n        echo \"Configuration actuelle:\"\n        grep -v \"^#\" \"$CONFIG_FILE\" | grep -v \"^$\"\n    fi\n}\n\nmain() {\n    case \"${1:-afficher}\" in\n        charger)\n            charger_config\n            ;;\n        sauvegarder)\n            sauvegarder_config\n            ;;\n        afficher)\n            afficher_config\n            ;;\n        *)\n            echo \"Utilisation: $0 {charger|sauvegarder|afficher}\"\n            exit 1\n            ;;\n    esac\n}\n\nmain \"$@\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#exemple-4-script-de-verification-de-sante-du-systeme","title":"Exemple 4 : Script de V\u00e9rification de Sant\u00e9 du Syst\u00e8me","text":"<p>Alerte si des seuils sont d\u00e9pass\u00e9s :</p> Bash<pre><code>#!/bin/bash\n\n# Seuils d'alerte\nSEUIL_CPU=80\nSEUIL_MEMOIRE=85\nSEUIL_DISQUE=90\n\nverifier_processeur() {\n    local charge=$(uptime | awk -F'load average:' '{print $2}' | awk '{print $1}')\n    local nb_cores=$(nproc)\n    local pourcentage=$(echo \"scale=0; ($load * 100) / $nb_cores\" | bc)\n\n    if [ \"$pourcentage\" -gt \"$SEUIL_CPU\" ]; then\n        echo \"\u26a0\ufe0f  ALERTE CPU: $pourcentage%\"\n        return 1\n    fi\n    echo \"\u2713 CPU OK: $pourcentage%\"\n    return 0\n}\n\nverifier_memoire() {\n    local memoire_utilisee=$(free | awk '/^Mem:/ {printf \"%.0f\", ($3/$2)*100}')\n\n    if [ \"$memoire_utilisee\" -gt \"$SEUIL_MEMOIRE\" ]; then\n        echo \"\u26a0\ufe0f  ALERTE M\u00c9MOIRE: ${memoire_utilisee}%\"\n        return 1\n    fi\n    echo \"\u2713 M\u00e9moire OK: ${memoire_utilisee}%\"\n    return 0\n}\n\nverifier_disque() {\n    local disque_utilise=$(df / | awk 'NR==2 {print $5}' | sed 's/%//')\n\n    if [ \"$disque_utilise\" -gt \"$SEUIL_DISQUE\" ]; then\n        echo \"\u26a0\ufe0f  ALERTE DISQUE: ${disque_utilise}%\"\n        return 1\n    fi\n    echo \"\u2713 Disque OK: ${disque_utilise}%\"\n    return 0\n}\n\nmain() {\n    echo \"\u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\"\n    echo \"\u2551  V\u00c9RIFICATION DE LA SANT\u00c9 DU SYST\u00c8ME   \u2551\"\n    echo \"\u2551  $(date +\"%d/%m/%Y \u00e0 %H:%M:%S\")       \u2551\"\n    echo \"\u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\"\n    echo\n\n    local status_global=0\n\n    verifier_processeur || status_global=1\n    verifier_memoire || status_global=1\n    verifier_disque || status_global=1\n\n    echo\n    if [ \"$status_global\" -eq 0 ]; then\n        echo \"\u2713 Syst\u00e8me en bon \u00e9tat\"\n    else\n        echo \"\u26a0\ufe0f  Des alertes ont \u00e9t\u00e9 d\u00e9tect\u00e9es\"\n    fi\n\n    return $status_global\n}\n\nmain\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#exemple-5-script-de-gestion-dutilisateurs","title":"Exemple 5 : Script de Gestion d'Utilisateurs","text":"<p>Cr\u00e9e, modifie ou supprime des comptes utilisateurs :</p> Bash<pre><code>#!/bin/bash\n\ncreer_utilisateur() {\n    local nom=\"$1\"\n    local groupe=\"$2\"\n\n    if id \"$nom\" &amp;&gt;/dev/null; then\n        echo \"L'utilisateur $nom existe d\u00e9j\u00e0\"\n        return 1\n    fi\n\n    sudo useradd -m -g \"$groupe\" \"$nom\"\n    if [ $? -eq 0 ]; then\n        echo \"Utilisateur $nom cr\u00e9\u00e9 avec succ\u00e8s\"\n        return 0\n    else\n        echo \"Erreur lors de la cr\u00e9ation de $nom\"\n        return 1\n    fi\n}\n\nlister_utilisateurs() {\n    echo \"Utilisateurs du syst\u00e8me:\"\n    cut -d: -f1 /etc/passwd | tail -n +4\n}\n\nsupprimer_utilisateur() {\n    local nom=\"$1\"\n\n    if ! id \"$nom\" &amp;&gt;/dev/null; then\n        echo \"L'utilisateur $nom n'existe pas\"\n        return 1\n    fi\n\n    read -p \"\u00cates-vous s\u00fbr de vouloir supprimer $nom ? (oui/non): \" confirmation\n\n    if [ \"$confirmation\" = \"oui\" ]; then\n        sudo userdel -r \"$nom\"\n        echo \"Utilisateur $nom supprim\u00e9\"\n        return 0\n    else\n        echo \"Suppression annul\u00e9e\"\n        return 1\n    fi\n}\n\nmain() {\n    case \"${1:-aide}\" in\n        creer)\n            if [ -z \"$2\" ] || [ -z \"$3\" ]; then\n                echo \"Utilisation: $0 creer &lt;nom&gt; &lt;groupe&gt;\"\n                exit 1\n            fi\n            creer_utilisateur \"$2\" \"$3\"\n            ;;\n        lister)\n            lister_utilisateurs\n            ;;\n        supprimer)\n            if [ -z \"$2\" ]; then\n                echo \"Utilisation: $0 supprimer &lt;nom&gt;\"\n                exit 1\n            fi\n            supprimer_utilisateur \"$2\"\n            ;;\n        *)\n            echo \"Utilisation: $0 {creer|lister|supprimer}\"\n            exit 1\n            ;;\n    esac\n}\n\nmain \"$@\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap10/#chemin-dapprentissage-progressif","title":"\ud83c\udf93 Chemin d'Apprentissage Progressif","text":""},{"location":"_projects/_formation-bash/bash-chap10/#premiere-etape-maitrise-des-fondamentaux-2-3-semaines","title":"Premi\u00e8re \u00c9tape : Ma\u00eetrise des Fondamentaux (2-3 semaines)","text":"<p>La progression d\u00e9bute par la compr\u00e9hension de la structure basique d'un script Bash[1][3]. L'apprenant doit devenir \u00e0 l'aise avec la cr\u00e9ation d'un fichier script, l'ajout du shebang, et l'ex\u00e9cution basique de commandes. Cette phase inclut la modification des permissions avec <code>chmod</code> et la familiarisation avec l'environnement Linux terminal.</p> <p>Pendant cette p\u00e9riode, exp\u00e9rimenter avec des scripts simples affichant du texte, invoquant des commandes syst\u00e8me, et comprenant le flux d'ex\u00e9cution lin\u00e9aire. Des exemples \u00e0 ma\u00eetriser : affichage de l'heure syst\u00e8me, listing de fichiers, cr\u00e9ation de r\u00e9pertoires.</p>"},{"location":"_projects/_formation-bash/bash-chap10/#deuxieme-etape-variables-et-entrees-utilisateur-3-4-semaines","title":"Deuxi\u00e8me \u00c9tape : Variables et Entr\u00e9es Utilisateur (3-4 semaines)","text":"<p>Une fois les fondamentaux assimil\u00e9s, l'\u00e9tape suivante concerne la manipulation des variables et l'interaction avec l'utilisateur. Comprendre comment stocker des donn\u00e9es, les r\u00e9cup\u00e9rer depuis la ligne de commande avec les param\u00e8tres positionnels, et les capturer interactivement avec <code>read</code>.</p> <p>Cette phase introduit \u00e9galement les variables pr\u00e9d\u00e9finies de Bash comme <code>$#</code>, <code>$@</code>, <code>$$</code>, <code>$?</code>. Exp\u00e9rimenter avec des scripts qui demandent des informations \u00e0 l'utilisateur et les r\u00e9utilisent dans le traitement.</p>"},{"location":"_projects/_formation-bash/bash-chap10/#troisieme-etape-tests-et-conditions-4-5-semaines","title":"Troisi\u00e8me \u00c9tape : Tests et Conditions (4-5 semaines)","text":"<p>Apr\u00e8s avoir ma\u00eetris\u00e9 les variables, l'apprenant doit comprendre les m\u00e9canismes de d\u00e9cision. Les tests sur les fichiers, les comparaisons num\u00e9riques et textuelles, et les op\u00e9rateurs logiques deviennent essentiels. Cette phase est fondamentale pour toute automatisation r\u00e9elle.</p> <p>Construire des scripts qui \u00e9valuent des conditions, prennent des d\u00e9cisions bas\u00e9es sur des r\u00e9sultats, et g\u00e8rent diff\u00e9rents sc\u00e9narios d'erreur. Tester des fichiers existants, comparer des valeurs, combiner des conditions avec <code>&amp;&amp;</code> et <code>||</code>.</p>"},{"location":"_projects/_formation-bash/bash-chap10/#quatrieme-etape-fonctions-et-organisation-du-code-5-6-semaines","title":"Quatri\u00e8me \u00c9tape : Fonctions et Organisation du Code (5-6 semaines)","text":"<p>L'introduction des fonctions apporte un changement de paradigme important. Plut\u00f4t que d'\u00e9crire du code lin\u00e9aire, l'apprenant organise d\u00e9sormais le code en modules r\u00e9utilisables. Cette phase enseigne la structure professionnelle avec une fonction <code>main</code>, la port\u00e9e des variables, et la r\u00e9utilisabilit\u00e9 du code.</p> <p>Refactoriser des scripts pr\u00e9c\u00e9dents en utilisant des fonctions. Cr\u00e9er des biblioth\u00e8ques de fonctions pouvant \u00eatre r\u00e9utilis\u00e9es. Comprendre le retour de valeurs et le passage de param\u00e8tres.</p>"},{"location":"_projects/_formation-bash/bash-chap10/#cinquieme-etape-boucles-et-iteration-6-7-semaines","title":"Cinqui\u00e8me \u00c9tape : Boucles et It\u00e9ration (6-7 semaines)","text":"<p>Les structures it\u00e9ratives permettent de traiter des collections de donn\u00e9es et de r\u00e9p\u00e9ter des t\u00e2ches. Cette phase couvre les boucles <code>for</code>, <code>while</code>, et <code>until</code>, ainsi que les m\u00e9canismes de contr\u00f4le <code>break</code> et <code>continue</code>.</p> <p>Des cas d'usage pratiques incluent le traitement de fichiers dans un r\u00e9pertoire, l'it\u00e9ration sur les param\u00e8tres pass\u00e9s au script, ou le traitement ligne par ligne d'un fichier. La compr\u00e9hension du s\u00e9parateur de champs (IFS) devient importante.</p>"},{"location":"_projects/_formation-bash/bash-chap10/#sixieme-etape-operations-arithmetiques-et-calculs-7-8-semaines","title":"Sixi\u00e8me \u00c9tape : Op\u00e9rations Arithm\u00e9tiques et Calculs (7-8 semaines)","text":"<p>Bien que Bash soit con\u00e7u pour l'administration syst\u00e8me plut\u00f4t que les calculs complexes, il supporte les op\u00e9rations arithm\u00e9tiques enti\u00e8res natives. Cette phase enseigne la syntaxe <code>$(( ))</code>, les op\u00e9rateurs compos\u00e9s, et quand faire appel \u00e0 des outils externes comme <code>bc</code> pour les d\u00e9cimales.</p> <p>Construire des scripts de calcul simple, des compteurs, des conversions d'unit\u00e9s. Comprendre les limitations et savoir quand d\u00e9l\u00e9guer les calculs complexes \u00e0 d'autres outils.</p>"},{"location":"_projects/_formation-bash/bash-chap10/#septieme-etape-branchements-avances-et-menus-8-9-semaines","title":"Septi\u00e8me \u00c9tape : Branchements Avanc\u00e9s et Menus (8-9 semaines)","text":"<p>Au-del\u00e0 du simple <code>if-then-else</code>, l'instruction <code>case</code> offre une meilleure readabilit\u00e9 pour les d\u00e9cisions multiples. La structure <code>select</code> cr\u00e9e des interfaces de menu interactives. Cette phase am\u00e9liore l'exp\u00e9rience utilisateur des scripts.</p> <p>Convertir des blocs <code>if</code> imbriqu\u00e9s en structures <code>case</code> plus lisibles. Cr\u00e9er des menus interactifs o\u00f9 l'utilisateur choisit parmi plusieurs options. Impl\u00e9menter des validations robustes des entr\u00e9es utilisateur.</p>"},{"location":"_projects/_formation-bash/bash-chap10/#huitieme-etape-scripts-complexes-et-production-9-10-semaines","title":"Huiti\u00e8me \u00c9tape : Scripts Complexes et Production (9-10 semaines)","text":"<p>La derni\u00e8re \u00e9tape de ce cycle synth\u00e9tise tout l'apprentissage. L'apprenant cr\u00e9e des scripts complets, bien structur\u00e9s, \u00e0 usage professionnel. Gestion d'erreurs compl\u00e8te, logging appropri\u00e9, documentation du code, gestion des signaux du syst\u00e8me.</p> <p>Exemples avanc\u00e9s : scripts de sauvegarde automatique, monitoring syst\u00e8me, gestion de bases de donn\u00e9es simples, orchestration de t\u00e2ches complexes, int\u00e9gration avec le cron pour l'automatisation programm\u00e9e.</p>"},{"location":"_projects/_formation-bash/bash-chap10/#pratique-continue-et-projets-personnels","title":"Pratique Continue et Projets Personnels","text":"<p>Tout au long de ce parcours, la pratique constante est essentielle. Commencer par reproduire les exemples pr\u00e9sent\u00e9s, puis les modifier, puis en cr\u00e9er de nouveaux adapt\u00e9s \u00e0 des besoins sp\u00e9cifiques. Les projets personnels renforcent la compr\u00e9hension et b\u00e2tissent la confiance.</p> <p>Des id\u00e9es de projets progressifs : script de gestion personnelle de fichiers, outil de surveillance des logs syst\u00e8me, gestionnaire de configurations personnelles, automatisation de t\u00e2ches administratives r\u00e9currentes, cr\u00e9ation d'outils collaboratifs pour l'\u00e9quipe.</p>"},{"location":"_projects/_formation-bash/bash-chap10/#concepts-interconnectes","title":"\ud83d\udd17 Concepts Interconnect\u00e9s","text":"<p>La puissance de Bash r\u00e9side dans la combinaison de ces \u00e9l\u00e9ments. Un script complet[2] de gestion de fichiers pourrait associer :</p> <ul> <li>Des tests pour v\u00e9rifier l'existence des fichiers</li> <li>Des boucles pour traiter plusieurs fichiers</li> <li>Des fonctions pour organiser le code</li> <li>Des variables pour stocker les r\u00e9sultats interm\u00e9diaires</li> <li>Des conditions pour g\u00e9rer les diff\u00e9rents cas</li> <li>De l'arithm\u00e9tique pour calculer des statistiques</li> </ul> <p>Cette composition cr\u00e9e des outils puissants d'automatisation et d'administration syst\u00e8me. Bash transforme ainsi les t\u00e2ches r\u00e9p\u00e9titives et manuelles en processus automatis\u00e9s, am\u00e9liorant l'efficacit\u00e9 et r\u00e9duisant les erreurs humaines.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-bash/bash-chap11/","title":"Citations","text":"<ul> <li>https://www.hostinger.com/fr/tutoriels/variable-d-environnement-linux</li> <li>https://www.digitalocean.com/community/tutorials/how-to-read-and-set-environmental-and-shell-variables-on-linux-fr</li> <li>https://www.it-connect.fr/definir-des-variables-denvironnement-sous-linux/</li> <li>http://doc.ubuntu-fr.org/variables_d_environnement</li> <li>https://www.youtube.com/watch?v=NiVdWplY7Xo</li> <li>https://labex.io/fr/tutorials/linux-how-to-make-environment-variables-persistent-in-linux-409875</li> <li>https://blog.stephane-robert.info/docs/admin-serveurs/linux/shells-linux/bash/</li> <li>https://buzut.net/maitriser-les-variables-d-environnement/</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap11/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 264</li> <li>completion_tokens: 7158</li> <li>total_tokens: 7422</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.107, 'request_cost': 0.006, 'total_cost': 0.114}</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap11/#content","title":"Content","text":""},{"location":"_projects/_formation-bash/bash-chap11/#chapitre-11-modifier-son-environnement-sous-linux-et-bash","title":"\ud83d\udcda Chapitre 11 : Modifier son environnement sous Linux et Bash","text":""},{"location":"_projects/_formation-bash/bash-chap11/#introduction-aux-variables-denvironnement","title":"Introduction aux variables d'environnement","text":"<p>Les variables d'environnement constituent un \u00e9l\u00e9ment fondamental de tout syst\u00e8me Linux. Elles agissent comme des conteneurs d'informations globales accessibles \u00e0 l'ensemble des programmes et processus ex\u00e9cut\u00e9s sur le syst\u00e8me. Ces variables influencent directement le comportement des logiciels et des commandes shell, en fournissant des param\u00e8tres de configuration essentiels.[1]</p> <p>Une variable d'environnement peut \u00eatre d\u00e9finie comme une paire cl\u00e9-valeur o\u00f9 la cl\u00e9 est le nom de la variable (toujours en majuscules par convention) et la valeur est le contenu qu'elle renferme. Contrairement aux variables shell ordinaires qui ne sont accessibles que dans le shell actuel, les variables d'environnement se propagent aux processus enfants g\u00e9n\u00e9r\u00e9s par le shell parent.[2]</p>"},{"location":"_projects/_formation-bash/bash-chap11/#distinction-entre-variables-shell-et-variables-denvironnement","title":"Distinction entre variables shell et variables d'environnement","text":"<p>La diff\u00e9renciation entre ces deux types de variables repr\u00e9sente un point d'apprentissage critique. Une variable shell locale, cr\u00e9\u00e9e sans la commande <code>export</code>, reste confin\u00e9e au shell actuel et n'est pas transmise aux sous-processus. En revanche, une variable d'environnement, cr\u00e9\u00e9e avec la commande <code>export</code>, est h\u00e9rit\u00e9e par tous les processus enfants lanc\u00e9s depuis ce shell.[2]</p> <p>Pour illustrer cette distinction, consid\u00e9rer l'exemple suivant :</p> Bash<pre><code># Cr\u00e9ation d'une variable shell locale\nTEST_VAR=\"Hello World\"\n\n# Tentative d'acc\u00e8s dans un sous-shell\nbash\necho $TEST_VAR\n# R\u00e9sultat : vide (la variable n'est pas accessible)\nexit\n\n# Cr\u00e9ation d'une variable d'environnement\nexport TEST_VAR=\"Hello World\"\n\n# Acc\u00e8s dans un sous-shell\nbash\necho $TEST_VAR\n# R\u00e9sultat : Hello World (la variable est accessible)\nexit\n</code></pre> <p>Cette distinction fondamentale d\u00e9termine la port\u00e9e et la disponibilit\u00e9 des variables lors de l'ex\u00e9cution des scripts et des commandes.</p>"},{"location":"_projects/_formation-bash/bash-chap11/#utilite-pratique-des-variables-denvironnement","title":"Utilit\u00e9 pratique des variables d'environnement","text":"<p>Les variables d'environnement servent plusieurs objectifs critiques dans un environnement Linux :</p> <p>Configuration syst\u00e8me : Des variables comme <code>PATH</code> d\u00e9finissent o\u00f9 le syst\u00e8me recherche les ex\u00e9cutables, tandis que <code>HOME</code> indique le r\u00e9pertoire personnel de l'utilisateur.</p> <p>Configuration applicative : De nombreux logiciels consulte des variables d'environnement pour adapter leur comportement, notamment les chemins de base de donn\u00e9es, les cl\u00e9s d'API, ou les niveaux de journalisation.</p> <p>Environnement de shell : Des variables comme <code>SHELL</code>, <code>TERM</code>, et <code>PS1</code> d\u00e9finissent le type de shell, le type de terminal \u00e9mul\u00e9, et l'apparence du prompt.</p> <p>H\u00e9ritage de processus : Les processus enfants h\u00e9ritent automatiquement des variables d'environnement du processus parent, permettant une transmission hi\u00e9rarchique de la configuration.[2]</p>"},{"location":"_projects/_formation-bash/bash-chap11/#definition-temporaire-versus-definition-permanente","title":"D\u00e9finition temporaire versus d\u00e9finition permanente","text":"<p>Une distinction essentielle doit \u00eatre \u00e9tablie entre les modifications temporaires et permanentes des variables d'environnement.</p>"},{"location":"_projects/_formation-bash/bash-chap11/#modifications-temporaires","title":"Modifications temporaires","text":"<p>L'utilisation de la commande <code>export</code> dans le terminal produit une modification qui persiste uniquement pour la session shell actuelle. Cette approche convient pour les tests ou les configurations ponctuelles.[1]</p> Bash<pre><code># D\u00e9finition temporaire d'une variable\nexport MY_VAR=\"valeur_temporaire\"\n\n# V\u00e9rification\necho $MY_VAR\n# R\u00e9sultat : valeur_temporaire\n\n# Apr\u00e8s red\u00e9marrage du syst\u00e8me ou fermeture du terminal, la variable dispara\u00eet\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#modifications-permanentes","title":"Modifications permanentes","text":"<p>Pour que les variables d'environnement persistent apr\u00e8s le red\u00e9marrage du syst\u00e8me ou la fermeture du terminal, elles doivent \u00eatre \u00e9crites dans les fichiers de configuration du shell. Cette approche garantit que la configuration est charg\u00e9e automatiquement \u00e0 chaque nouvelle session.[1]</p>"},{"location":"_projects/_formation-bash/bash-chap11/#les-fichiers-denvironnement","title":"Les fichiers d'environnement","text":"<p>La gestion de l'environnement sous Linux passe obligatoirement par la compr\u00e9hension des fichiers de configuration du shell. Plusieurs fichiers interviennent \u00e0 diff\u00e9rents niveaux de priorit\u00e9 et de port\u00e9e.</p>"},{"location":"_projects/_formation-bash/bash-chap11/#architecture-generale-des-fichiers-denvironnement","title":"Architecture g\u00e9n\u00e9rale des fichiers d'environnement","text":"<p>L'ordre de chargement des fichiers de configuration suit une hi\u00e9rarchie pr\u00e9cise qui d\u00e9termine quelles variables sont d\u00e9finies et dans quel contexte. Cette hi\u00e9rarchie varie selon que le shell est un shell de connexion (login shell) ou un shell interactif ordinaire.[2]</p>"},{"location":"_projects/_formation-bash/bash-chap11/#le-fichier-bashrc","title":"Le fichier ~/.bashrc","text":"<p>Le fichier <code>~/.bashrc</code> est le fichier de configuration utilisateur le plus couramment modifi\u00e9 pour d\u00e9finir des variables d'environnement persistantes au niveau de l'utilisateur actuel. Ce fichier est ex\u00e9cut\u00e9 automatiquement chaque fois qu'un shell bash interactif non-login est lanc\u00e9.[1][2]</p> <p>Syntaxe et \u00e9dition du fichier ~/.bashrc</p> Bash<pre><code># Ouverture du fichier avec nano\nsudo nano ~/.bashrc\n\n# Ou avec l'utilisateur courant (sans sudo)\nnano ~/.bashrc\n</code></pre> <p>\u00c0 l'int\u00e9rieur du fichier, les variables doivent \u00eatre d\u00e9finies avec la syntaxe <code>export</code> :</p> Bash<pre><code># Exemple de variables dans ~/.bashrc\nexport MY_PROJECT=\"/home/utilisateur/mon_projet\"\nexport API_KEY=\"123456789\"\nexport LOG_LEVEL=\"debug\"\nexport DATABASE_URL=\"https://example.tld/database\"\n</code></pre> <p>Sauvegarde et activation des modifications</p> <p>Apr\u00e8s modification du fichier avec nano ou vi :</p> <ol> <li>Appuyer sur <code>Ctrl+X</code>, <code>Y</code>, puis <code>Entr\u00e9e</code> pour nano</li> <li>Appuyer sur <code>\u00c9chap</code>, <code>:wq</code>, puis <code>Entr\u00e9e</code> pour vi</li> </ol> <p>Pour appliquer imm\u00e9diatement les modifications \u00e0 la session shell actuelle sans la fermer :</p> Bash<pre><code>source ~/.bashrc\n</code></pre> <p>La prochaine fois qu'un shell bash interactif est lanc\u00e9, les variables d\u00e9finies dans <code>~/.bashrc</code> sont automatiquement charg\u00e9es.[1][2]</p>"},{"location":"_projects/_formation-bash/bash-chap11/#le-fichier-profile","title":"Le fichier ~/.profile","text":"<p>Le fichier <code>~/.profile</code> s'ex\u00e9cute lors de la connexion \u00e0 un shell de connexion (login shell) et avant que <code>~/.bashrc</code> soit lu. Contrairement \u00e0 <code>~/.bashrc</code> qui cible les shells interactifs, <code>~/.profile</code> est utilis\u00e9 pour configurer l'environnement global de connexion.[1]</p> <p>Ce fichier est particuli\u00e8rement utile pour d\u00e9finir des variables qui doivent \u00eatre disponibles dans tous les shells de connexion, y compris les shells non-bash comme <code>sh</code> ou <code>ksh</code>.</p> Bash<pre><code># \u00c9dition de ~/.profile\nnano ~/.profile\n\n# Ajout de variables\nexport JAVA_HOME=\"/usr/lib/jvm/java-11-openjdk\"\nexport CLASSPATH=\"$CLASSPATH:$JAVA_HOME/lib\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#le-fichier-etcenvironment","title":"Le fichier /etc/environment","text":"<p>Le fichier <code>/etc/environment</code> d\u00e9finit les variables d'environnement au niveau du syst\u00e8me entier, applicables \u00e0 tous les utilisateurs. Contrairement \u00e0 <code>~/.bashrc</code> ou <code>~/.profile</code>, ce fichier est lu par le syst\u00e8me lors du processus de d\u00e9marrage, avant m\u00eame que les shells utilisateur ne soient initialis\u00e9s.[1]</p> <p>Importante remarque syntaxique : Le fichier <code>/etc/environment</code> utilise une syntaxe l\u00e9g\u00e8rement diff\u00e9rente - les variables ne doivent pas \u00eatre pr\u00e9c\u00e9d\u00e9es du mot-cl\u00e9 <code>export</code>[1] :</p> Bash<pre><code># \u00c9dition de /etc/environment\nsudo nano /etc/environment\n\n# Syntaxe correcte (sans export)\nJAVA_HOME=\"/usr/lib/jvm/java-11-openjdk\"\nMY_SYSTEM_VAR=\"valeur_globale\"\nDATABASE_HOST=\"db.example.com\"\n</code></pre> <p>Pour appliquer les modifications \u00e0 <code>/etc/environment</code>, il est n\u00e9cessaire de se reconnecter ou de red\u00e9marrer le syst\u00e8me :</p> Bash<pre><code>reboot\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#le-repertoire-etcprofiled","title":"Le r\u00e9pertoire /etc/profile.d/","text":"<p>Le r\u00e9pertoire <code>/etc/profile.d/</code> constitue un m\u00e9canisme alternatif \u00e9l\u00e9gant pour d\u00e9finir des variables d'environnement au niveau du syst\u00e8me. Ce r\u00e9pertoire contient des fichiers shell suppl\u00e9mentaires ex\u00e9cut\u00e9s lors de la connexion \u00e0 un shell de connexion.[3]</p> <p>Cette approche offre plusieurs avantages : - Meilleure organisation que de modifier directement <code>/etc/environment</code> - Facile \u00e0 g\u00e9rer lors de l'installation/d\u00e9sinstallation d'applications - Chaque application peut maintenir son propre fichier de configuration</p> <p>Cr\u00e9ation d'un fichier de variables personnalis\u00e9es</p> Bash<pre><code># Cr\u00e9ation d'un nouveau fichier dans /etc/profile.d/\nsudo nano /etc/profile.d/mon_app.sh\n\n# Contenu du fichier (avec export)\nexport APP_HOME=\"/opt/mon_application\"\nexport APP_CONFIG=\"/etc/mon_application\"\nexport APP_LOG=\"/var/log/mon_application\"\n</code></pre> <p>Les fichiers dans <code>/etc/profile.d/</code> doivent avoir l'extension <code>.sh</code> et sont automatiquement ex\u00e9cut\u00e9s lors d'une nouvelle connexion shell.</p>"},{"location":"_projects/_formation-bash/bash-chap11/#hierarchie-de-chargement-des-fichiers","title":"Hi\u00e9rarchie de chargement des fichiers","text":"<p>L'ordre de chargement des fichiers de configuration suit une s\u00e9quence pr\u00e9cise :</p> <p>Pour un shell de connexion (login shell) : 1. <code>/etc/profile</code> (fichier syst\u00e8me) 2. Fichiers dans <code>/etc/profile.d/</code> 3. <code>~/.profile</code> (fichier utilisateur) 4. <code>~/.bash_profile</code> (s'il existe)</p> <p>Pour un shell interactif ordinaire : 1. <code>~/.bashrc</code> (fichier utilisateur)</p> <p>Pour un shell non-interactif : 1. Variable d'environnement <code>BASH_ENV</code> (si d\u00e9finie)</p> <p>Cette hi\u00e9rarchie explique pourquoi une variable d\u00e9finie dans <code>/etc/environment</code> est disponible globalement, tandis qu'une variable d\u00e9finie dans <code>~/.bashrc</code> ne s'applique qu'\u00e0 l'utilisateur courant dans les shells interactifs.[2]</p>"},{"location":"_projects/_formation-bash/bash-chap11/#les-commandes-env-et-printenv","title":"Les commandes env et printenv","text":"<p>Ces deux commandes constituent les outils essentiels pour afficher, examiner et manipuler les variables d'environnement dans un terminal Linux.</p>"},{"location":"_projects/_formation-bash/bash-chap11/#la-commande-printenv","title":"La commande printenv","text":"<p>La commande <code>printenv</code> affiche toutes les variables d'environnement actuelles ou la valeur d'une variable sp\u00e9cifique.[1]</p> <p>Affichage de toutes les variables</p> Bash<pre><code>printenv\n</code></pre> <p>Cette commande produit une liste exhaustive de toutes les variables d'environnement disponibles dans la session courante :</p> Text Only<pre><code>PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\nHOME=/home/utilisateur\nUSER=utilisateur\nSHELL=/bin/bash\nTERM=xterm-256color\nLANG=fr_FR.UTF-8\nPWD=/home/utilisateur\nLOGNAME=utilisateur\n</code></pre> <p>Affichage d'une variable sp\u00e9cifique</p> Bash<pre><code>printenv HOME\n# R\u00e9sultat : /home/utilisateur\n\nprintenv PATH\n# R\u00e9sultat : /usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#la-commande-env","title":"La commande env","text":"<p>La commande <code>env</code> offre plusieurs fonctionnalit\u00e9s compl\u00e9mentaires. Elle peut afficher l'environnement complet, mais elle poss\u00e8de \u00e9galement la capacit\u00e9 unique de modifier l'environnement pour une seule commande sans affecter la session actuelle.[2]</p> <p>Affichage de l'environnement complet</p> Bash<pre><code>env\n</code></pre> <p>Le r\u00e9sultat ressemble fortement \u00e0 celui de <code>printenv</code>, bien que l'ordre et la pr\u00e9sentation puissent varier l\u00e9g\u00e8rement.</p> <p>Modification temporaire de l'environnement pour une seule commande</p> Bash<pre><code># Ex\u00e9cution d'une commande avec des variables modifi\u00e9es\nenv VAR1=\"valeur1\" VAR2=\"valeur2\" command_to_run\n\n# Exemple concret : ex\u00e9cution d'un script avec des variables personnalis\u00e9es\nenv API_KEY=\"secret123\" DATABASE_URL=\"mongodb://localhost\" ./mon_script.sh\n</code></pre> <p>Cette capacit\u00e9 s'av\u00e8re extr\u00eamement utile pour : - Tester des scripts avec diff\u00e9rentes configurations sans les modifications permanentes - Surcharger temporairement des variables d'environnement existantes - Ex\u00e9cuter des commandes dans un environnement isol\u00e9</p> <p>Redirection et combinaison avec d'autres commandes</p> Bash<pre><code># Envoyer la sortie de env dans un fichier\nenv &gt; mon_environnement.txt\n\n# Compter le nombre de variables\nenv | wc -l\n\n# Chercher une variable sp\u00e9cifique\nenv | grep JAVA\n\n# Tri\u00e9e les variables alphab\u00e9tiquement\nenv | sort\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#la-commande-set","title":"La commande set","text":"<p>La commande <code>set</code>, bien que l\u00e9g\u00e8rement diff\u00e9rente, fournit des informations compl\u00e9mentaires sur l'environnement shell.[2]</p> Bash<pre><code># Affichage de toutes les variables shell et d'environnement\nset\n\n# R\u00e9sultat incluant les variables locales, les fonctions et les options du shell\nBASH=/bin/bash\nBASHOPTS=checkwinsize:cmdhist:expand_aliases:extglob:extquote:force_fignore:histappend:interactive_comments:login_shell:progcomp:promptvars:sourcepath\nBASH_ALIASES=()\nBASH_ARGC=()\nBASH_ARGV=()\n# ... et bien d'autres\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#la-commande-echo-avec-les-variables","title":"La commande echo avec les variables","text":"<p>Pour acc\u00e9der \u00e0 la valeur d'une variable et l'afficher, la syntaxe utilise le signe dollar (<code>$</code>) :</p> Bash<pre><code># Affichage d'une variable\necho $HOME\n# R\u00e9sultat : /home/utilisateur\n\necho $USER\n# R\u00e9sultat : utilisateur\n\n# Utilisation dans des cha\u00eenes de caract\u00e8res\necho \"Je suis l'utilisateur $USER dans le r\u00e9pertoire $HOME\"\n# R\u00e9sultat : Je suis l'utilisateur utilisateur dans le r\u00e9pertoire /home/utilisateur\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#tableau-comparatif-des-commandes","title":"Tableau comparatif des commandes","text":"Commande Affichage de l'environnement Modification temporaire Variables locales Fonctions shell <code>printenv</code> \u2705 Oui \u274c Non \u274c Non \u274c Non <code>env</code> \u2705 Oui \u2705 Oui \u274c Non \u274c Non <code>set</code> \u2705 Oui \u274c Non \u2705 Oui \u2705 Oui <code>echo $VAR</code> \u2705 Sp\u00e9cifique \u274c Non \u2705 Oui \u274c Non"},{"location":"_projects/_formation-bash/bash-chap11/#les-alias-et-la-variable-ps1","title":"Les alias et la variable PS1","text":""},{"location":"_projects/_formation-bash/bash-chap11/#les-alias-definition-et-utilite","title":"Les alias : d\u00e9finition et utilit\u00e9","text":"<p>Un alias bash constitue un raccourci personnalis\u00e9 pour une commande ou une s\u00e9rie de commandes. Les alias permettent de simplifier les commandes fr\u00e9quemment utilis\u00e9es en rempla\u00e7ant une longue commande par un mot-cl\u00e9 court et m\u00e9morisable.[1]</p> <p>Cas d'usage courants des alias : - Abr\u00e9ger les commandes longues ou complexes - Ajouter des options de s\u00e9curit\u00e9 aux commandes dangereuses - Cr\u00e9er des commandes compos\u00e9es personnalis\u00e9es - Am\u00e9liorer la productivit\u00e9 et r\u00e9duire les erreurs de frappe</p>"},{"location":"_projects/_formation-bash/bash-chap11/#creation-temporaire-dalias","title":"Cr\u00e9ation temporaire d'alias","text":"<p>La cr\u00e9ation temporaire d'un alias affecte uniquement la session shell actuelle. Cette approche convient pour les tests ou les exp\u00e9rimentations.</p> Bash<pre><code># Syntaxe de base\nalias nom_alias='commande'\n\n# Exemple : alias pour lister les fichiers avec d\u00e9tails\nalias ll='ls -lh'\n\n# Exemple : alias pour la navigation\nalias ..='cd ..'\nalias ...='cd ../..'\n\n# Exemple : alias pour des commandes de suppression s\u00e9curis\u00e9e\nalias rm='rm -i'  # demande confirmation avant suppression\nalias mv='mv -i'  # demande confirmation en cas de collision\n\n# Utilisation de l'alias\nll\n# Ex\u00e9cute en r\u00e9alit\u00e9 : ls -lh\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#affichage-des-alias-existants","title":"Affichage des alias existants","text":"Bash<pre><code># Affichage de tous les alias\nalias\n\n# R\u00e9sultat possible :\nalias ll='ls -l'\nalias la='ls -A'\nalias l='ls -CF'\n\n# Affichage d'un alias sp\u00e9cifique\nalias ll\n# R\u00e9sultat : alias ll='ls -l'\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#suppression-dalias","title":"Suppression d'alias","text":"Bash<pre><code># Suppression d'un alias pour la session actuelle\nunalias nom_alias\n\n# Suppression de tous les alias\nunalias -a\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#creation-permanente-dalias","title":"Cr\u00e9ation permanente d'alias","text":"<p>Pour que les alias persistent apr\u00e8s la fermeture du terminal, ils doivent \u00eatre d\u00e9finis dans le fichier <code>~/.bashrc</code> :</p> Bash<pre><code># \u00c9dition du fichier\nnano ~/.bashrc\n\n# Ajout d'alias dans le fichier (g\u00e9n\u00e9ralement \u00e0 la fin)\nalias ll='ls -lh'\nalias la='ls -la'\nalias ..='cd ..'\nalias ...='cd ../..'\nalias grep='grep --color=auto'\nalias mkdir='mkdir -pv'\nalias mount='mount | column -t'\nalias psaux='ps aux | grep'\nalias df='df -h'\nalias du='du -ch'\nalias clear='clear &amp;&amp; echo \"\u00c9cran effac\u00e9\"'\nalias md5='md5sum'\nalias sha1='sha1sum'\n\n# Sauvegarde et fermeture\n# Ctrl+X, Y, Entr\u00e9e (pour nano)\n</code></pre> <p>Apr\u00e8s modification, charger les alias imm\u00e9diatement :</p> Bash<pre><code>source ~/.bashrc\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#alias-complexes-avec-plusieurs-commandes","title":"Alias complexes avec plusieurs commandes","text":"<p>Les alias peuvent ex\u00e9cuter plusieurs commandes en succession :</p> Bash<pre><code># Alias combinant plusieurs commandes\nalias mkedit='mkdir -pv $1 &amp;&amp; cd $1'\n\n# Alias pour nettoyer le syst\u00e8me\nalias cleanup='sudo apt-get update &amp;&amp; sudo apt-get upgrade -y &amp;&amp; sudo apt-get autoremove -y'\n\n# Alias pour afficher les 10 r\u00e9pertoires les plus volumineux\nalias diskusage='du -s */ | sort -rn | head -n 10'\n\n# Alias pour synchroniser l'heure\nalias synctime='timedatectl set-ntp true &amp;&amp; timedatectl status'\n</code></pre> <p>Important : Pour les alias complexes avec des param\u00e8tres, il est pr\u00e9f\u00e9rable de cr\u00e9er une fonction bash plut\u00f4t qu'un alias.</p>"},{"location":"_projects/_formation-bash/bash-chap11/#creation-de-fonctions-bash-pour-les-besoins-avances","title":"Cr\u00e9ation de fonctions bash pour les besoins avanc\u00e9s","text":"<p>Lorsque les alias deviennent trop complexes ou n\u00e9cessitent des param\u00e8tres, les fonctions bash offrent une meilleure solution :</p> Bash<pre><code># D\u00e9finition d'une fonction dans ~/.bashrc\n# Fonction pour cr\u00e9er un r\u00e9pertoire et y entrer\nmkcd() {\n    mkdir -pv \"$1\"\n    cd \"$1\"\n}\n\n# Fonction pour rechercher dans les fichiers\nsearch() {\n    grep -r \"$1\" . --include=\"*.${2:-*}\"\n}\n\n# Fonction pour afficher l'utilisation disque format\u00e9e\ndiskspace() {\n    du -sh \"$1\" | sort -rh\n}\n\n# Utilisation\nmkcd nouveau_projet\nsearch \"motif\" \"txt\"\ndiskspace ~\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#la-variable-ps1-personnalisation-du-prompt","title":"La variable PS1 : personnalisation du prompt","text":"<p>La variable <code>PS1</code> (Prompt String 1) contr\u00f4le l'apparence du prompt affich\u00e9 dans le terminal. Cette variable constitue un outil puissant pour personnaliser l'environnement de travail et am\u00e9liorer la lisibilit\u00e9 du terminal.</p>"},{"location":"_projects/_formation-bash/bash-chap11/#comprendre-la-structure-de-ps1","title":"Comprendre la structure de PS1","text":"<p>Le prompt par d\u00e9faut dans bash ressemble g\u00e9n\u00e9ralement \u00e0 :</p> Text Only<pre><code>utilisateur@hote:~/repertoire$\n</code></pre> <p>Cette apparence est contr\u00f4l\u00e9e par la variable <code>PS1</code>. La valeur par d\u00e9faut est souvent :</p> Bash<pre><code>\\u@\\h:\\w\\$\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#codes-dechappement-de-ps1","title":"Codes d'\u00e9chappement de PS1","text":"<p>Les codes sp\u00e9ciaux dans <code>PS1</code> repr\u00e9sentent diff\u00e9rents \u00e9l\u00e9ments du syst\u00e8me :</p> Code Signification Exemple <code>\\u</code> Nom d'utilisateur <code>utilisateur</code> <code>\\h</code> Nom d'h\u00f4te court <code>hote</code> <code>\\H</code> Nom d'h\u00f4te complet <code>hote.domaine.com</code> <code>\\w</code> R\u00e9pertoire courant (chemin complet) <code>/home/utilisateur/projets</code> <code>\\W</code> R\u00e9pertoire courant (dossier uniquement) <code>projets</code> <code>\\d</code> Date au format \"Jou Moi Date\" <code>Jeu 03 D\u00e9c</code> <code>\\t</code> Heure au format HH:MM:SS <code>14:32:45</code> <code>\\T</code> Heure au format HH:MM:SS (12h) <code>02:32:45</code> <code>\\@</code> Heure au format HH:MM am/pm <code>02:32 pm</code> <code>\\n</code> Nouvelle ligne Saute \u00e0 la ligne suivante <code>\\$</code> <code>#</code> si root, sinon <code>$</code> <code>$</code> ou <code>#</code> <code>\\!</code> Num\u00e9ro de l'historique <code>42</code> <code>\\\\</code> Barre oblique inverse <code>\\</code>"},{"location":"_projects/_formation-bash/bash-chap11/#codes-de-couleur-pour-ps1","title":"Codes de couleur pour PS1","text":"<p>Les codes de couleur utilisent la s\u00e9quence d'\u00e9chappement ANSI. Bien que complexes, ils offrent un contr\u00f4le complet sur l'apparence visuelle du prompt.</p> <p>Les codes ANSI basiques utilisent la format <code>\\e[COULEURm</code> :</p> Bash<pre><code># Codes de couleur simples\n\\e[30m  # Noir\n\\e[31m  # Rouge\n\\e[32m  # Vert\n\\e[33m  # Jaune\n\\e[34m  # Bleu\n\\e[35m  # Magenta\n\\e[36m  # Cyan\n\\e[37m  # Blanc\n\\e[0m   # R\u00e9initialiser \u00e0 la couleur par d\u00e9faut\n\n# Mod\u00e8le combin\u00e9\n\\e[1;33m  # Jaune en gras\n\\e[1;31m  # Rouge en gras\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#exemples-de-personnalisation-de-ps1","title":"Exemples de personnalisation de PS1","text":"<p>Prompt minimaliste et color\u00e9</p> Bash<pre><code># \u00c9dition du fichier\nnano ~/.bashrc\n\n# Recherche et modification de PS1\nexport PS1=\"\\[\\e[1;32m\\]\\u@\\h:\\[\\e[0m\\]\\w\\$ \"\n\n# Explication :\n# \\[\\e[1;32m\\] : D\u00e9but de la couleur verte en gras\n# \\u@\\h:        : Utilisateur@h\u00f4te:\n# \\[\\e[0m\\]     : R\u00e9initialisation des couleurs\n# \\w\\$          : R\u00e9pertoire courant et symbole $\n</code></pre> <p>R\u00e9sultat visuel : Text Only<pre><code>utilisateur@hote:~/repertoire$ \n</code></pre> (o\u00f9 \"utilisateur@hote:\" s'affiche en vert)</p> <p>Prompt avec horodatage</p> Bash<pre><code>export PS1=\"\\[\\e[1;34m\\][\\t]\\[\\e[0m\\] \\[\\e[1;32m\\]\\u@\\h:\\[\\e[0m\\]\\w\\$ \"\n\n# R\u00e9sultat visuel :\n[14:32:45] utilisateur@hote:~/repertoire$ \n</code></pre> <p>Prompt multi-ligne</p> Bash<pre><code>export PS1=\"\\[\\e[1;32m\\]\\u@\\h\\[\\e[0m\\] \\[\\e[1;33m\\]\\w\\[\\e[0m\\]\\n\\[\\e[1;31m\\]\u2192\\[\\e[0m\\] \"\n\n# R\u00e9sultat visuel :\nutilisateur@hote ~/repertoire\n\u2192 \n</code></pre> <p>Prompt avec statut de la derni\u00e8re commande</p> Bash<pre><code># Cette version montre le code de statut et change de couleur en cas d'erreur\nexport PS1=\"\\[\\e[1;32m\\]\\u@\\h\\[\\e[0m\\] \\[\\e[1;34m\\]\\w\\[\\e[0m\\] \\$([ \\$? = 0 ] &amp;&amp; echo '\\[\\e[1;32m\\]\u2713' || echo '\\[\\e[1;31m\\]\u2717')\\[\\e[0m\\] \\$ \"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#variables-ps-supplementaires","title":"Variables PS suppl\u00e9mentaires","text":"<p>Bien que <code>PS1</code> soit la plus importante, d'autres variables de prompt existent pour des cas sp\u00e9cifiques :</p> <p>PS2 : Prompt de continuation</p> <p>Utilis\u00e9 lorsqu'une commande s'\u00e9tend sur plusieurs lignes :</p> Bash<pre><code>export PS2=\"\\[\\e[1;33m\\]\u2192\\[\\e[0m\\] \"\n\n# Exemple d'utilisation (apr\u00e8s avoir saisi une commande incompl\u00e8te) :\n$ echo \"ceci est une\n&gt; commande longue\"\n</code></pre> <p>PS3 : Prompt pour la boucle select</p> Bash<pre><code>export PS3=\"S\u00e9lectionnez une option : \"\n\n# Utilisation dans un script\nselect option in \"Option 1\" \"Option 2\" \"Quitter\"\ndo\n    case $option in\n        \"Option 1\") echo \"Vous avez choisi 1\" ;;\n        \"Option 2\") echo \"Vous avez choisi 2\" ;;\n        \"Quitter\") break ;;\n    esac\ndone\n</code></pre> <p>PS4 : Prompt pour le d\u00e9bogage</p> Bash<pre><code>export PS4=\"\\[\\e[1;35m\\][DEBUG]\\[\\e[0m\\] \"\n\n# Utilisation lors du d\u00e9bogage de scripts :\nbash -x mon_script.sh\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#sauvegarde-des-modifications-de-ps1","title":"Sauvegarde des modifications de PS1","text":"<p>Pour rendre permanents les changements de <code>PS1</code>, modifier le fichier <code>~/.bashrc</code> :</p> Bash<pre><code>nano ~/.bashrc\n\n# Localiser la ligne PS1= existante ou ajouter en fin de fichier\nexport PS1=\"\\[\\e[1;32m\\]\\u@\\h:\\[\\e[0m\\]\\w\\$ \"\n\n# Sauvegarder et fermer\nsource ~/.bashrc\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#tableau-recapitulatif-des-elements-de-configuration-denvironnement","title":"Tableau r\u00e9capitulatif des \u00e9l\u00e9ments de configuration d'environnement","text":"\u00c9l\u00e9ment Port\u00e9e Fichier de configuration Persistance Variables d'environnement utilisateur Utilisateur actuel <code>~/.bashrc</code> ou <code>~/.profile</code> \u2705 Persistant Variables d'environnement syst\u00e8me Tous les utilisateurs <code>/etc/environment</code> ou <code>/etc/profile.d/</code> \u2705 Persistant Alias utilisateur Utilisateur actuel <code>~/.bashrc</code> \u2705 Persistant PS1 (prompt) Utilisateur actuel <code>~/.bashrc</code> \u2705 Persistant Variables temporaires Session actuelle Commande <code>export</code> \u274c Temporaire Alias temporaires Session actuelle Commande <code>alias</code> \u274c Temporaire"},{"location":"_projects/_formation-bash/bash-chap11/#synthese-pratique-flux-de-travail-complet","title":"Synth\u00e8se pratique : Flux de travail complet","text":""},{"location":"_projects/_formation-bash/bash-chap11/#scenario-1-configuration-dune-application-personnalisee","title":"Sc\u00e9nario 1 : Configuration d'une application personnalis\u00e9e","text":"<p>Un d\u00e9veloppeur souhaite configurer une application avec des variables d'environnement personnalis\u00e9es :</p> Bash<pre><code># 1. \u00c9dition de ~/.bashrc pour les variables utilisateur\nnano ~/.bashrc\n\n# 2. Ajout des variables (\u00e0 la fin du fichier)\nexport APP_HOME=\"/home/utilisateur/mon_app\"\nexport APP_CONFIG=\"/home/utilisateur/mon_app/config\"\nexport LOG_LEVEL=\"debug\"\nexport DATABASE_URL=\"postgresql://localhost/mydb\"\n\n# 3. Ajout d'alias utiles\nalias startapp=\"cd $APP_HOME &amp;&amp; npm start\"\nalias stopapp=\"pkill -f 'npm start'\"\nalias applog=\"tail -f $APP_HOME/logs/app.log\"\n\n# 4. Personnalisation du prompt\nexport PS1=\"\\[\\e[1;36m\\][APP]\\[\\e[0m\\] \\[\\e[1;32m\\]\\u@\\h:\\[\\e[0m\\]\\w\\$ \"\n\n# 5. Sauvegarde\nsource ~/.bashrc\n\n# 6. V\u00e9rification\necho $APP_HOME\nprintenv | grep APP\nalias | grep app\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#scenario-2-configuration-systeme-multi-utilisateurs","title":"Sc\u00e9nario 2 : Configuration syst\u00e8me multi-utilisateurs","text":"<p>Un administrateur syst\u00e8me configure un serveur pour plusieurs d\u00e9veloppeurs :</p> Bash<pre><code># 1. Configuration au niveau du syst\u00e8me\nsudo nano /etc/profile.d/app_config.sh\n\n# 2. Contenu du fichier (version pour tous les utilisateurs)\nexport COMPANY_PROJECT=\"/opt/company\"\nexport SHARED_CONFIG=\"/etc/company/config\"\nexport LOG_DIR=\"/var/log/company\"\n\n# 3. V\u00e9rification de la syntaxe\nsudo source /etc/profile.d/app_config.sh\n\n# 4. Test pour chaque utilisateur\nsu - utilisateur1 -c \"echo $COMPANY_PROJECT\"\nsu - utilisateur2 -c \"echo $COMPANY_PROJECT\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#scenario-3-script-automatise-de-configuration","title":"Sc\u00e9nario 3 : Script automatis\u00e9 de configuration","text":"<p>Un d\u00e9veloppeur cr\u00e9e un script qui configure automatiquement tout l'environnement :</p> Bash<pre><code>#!/bin/bash\n# Script : setup_environment.sh\n\n# Couleurs pour l'affichage\nRED='\\e[1;31m'\nGREEN='\\e[1;32m'\nBLUE='\\e[1;34m'\nNC='\\e[0m'\n\necho -e \"${BLUE}Configuration de l'environnement...${NC}\"\n\n# V\u00e9rifier que nano ou vi est disponible\nif ! command -v nano &amp;&gt; /dev/null; then\n    echo -e \"${RED}nano n'est pas install\u00e9${NC}\"\n    exit 1\nfi\n\n# Chemin du fichier bashrc\nBASHRC_FILE=\"$HOME/.bashrc\"\n\n# Variables \u00e0 ajouter\nVARIABLES=(\n    'export PROJECT_ROOT=\"$HOME/projects\"'\n    'export API_KEY=\"secretkey123\"'\n    'export LOG_LEVEL=\"info\"'\n)\n\n# Alias \u00e0 ajouter\nALIASES=(\n    'alias ll=\"ls -lh\"'\n    'alias la=\"ls -la\"'\n    'alias goproject=\"cd $PROJECT_ROOT\"'\n)\n\n# Ajouter les variables\necho -e \"${BLUE}Ajout des variables...${NC}\"\nfor var in \"${VARIABLES[@]}\"; do\n    if ! grep -q \"$var\" \"$BASHRC_FILE\"; then\n        echo \"$var\" &gt;&gt; \"$BASHRC_FILE\"\n        echo -e \"${GREEN}\u2713 Ajout : $var${NC}\"\n    fi\ndone\n\n# Ajouter les alias\necho -e \"${BLUE}Ajout des alias...${NC}\"\nfor alias in \"${ALIASES[@]}\"; do\n    if ! grep -q \"$alias\" \"$BASHRC_FILE\"; then\n        echo \"$alias\" &gt;&gt; \"$BASHRC_FILE\"\n        echo -e \"${GREEN}\u2713 Ajout : $alias${NC}\"\n    fi\ndone\n\n# Charger la nouvelle configuration\necho -e \"${BLUE}Chargement de la configuration...${NC}\"\nsource \"$BASHRC_FILE\"\n\necho -e \"${GREEN}Configuration termin\u00e9e avec succ\u00e8s !${NC}\"\necho -e \"${BLUE}Variables disponibles :${NC}\"\nprintenv | grep PROJECT\necho -e \"${BLUE}Aliases disponibles :${NC}\"\nalias | grep -E \"(ll|la|goproject)\"\n</code></pre> <p>Ex\u00e9cution du script :</p> Bash<pre><code>chmod +x setup_environment.sh\n./setup_environment.sh\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap11/#points-cles-a-retenir","title":"Points cl\u00e9s \u00e0 retenir","text":"<p>L'apprentissage de la gestion de l'environnement sous Linux et Bash repose sur plusieurs compr\u00e9hensions fondamentales :</p> <p>1. Hi\u00e9rarchie des modifications : Les modifications temporaires avec <code>export</code> ou <code>env</code> ne persistent pas, tandis que les modifications dans les fichiers de configuration (<code>.bashrc</code>, <code>.profile</code>, <code>/etc/environment</code>) sont permanentes.</p> <p>2. Propagation aux processus enfants : Seules les variables d'environnement (cr\u00e9\u00e9es avec <code>export</code>) sont transmises aux sous-processus, pas les variables shell ordinaires.</p> <p>3. Ordre de chargement : Comprendre quand et dans quel ordre les fichiers de configuration sont ex\u00e9cut\u00e9s d\u00e9termine le comportement final de l'environnement.</p> <p>4. Outils de diagnostic : Les commandes <code>printenv</code>, <code>env</code>, et <code>set</code> offrent diff\u00e9rentes perspectives sur l'environnement et servent \u00e0 diagnostiquer les probl\u00e8mes de configuration.</p> <p>5. Personnalisation progressive : Commencer par des modifications simples (alias basiques) avant de progresser vers des configurations plus complexes (fonctions bash, scripts d'automatisation).</p> <p>6. Port\u00e9e et responsabilit\u00e9 : Distinguer entre la configuration utilisateur (fichiers dans le r\u00e9pertoire home) et la configuration syst\u00e8me (fichiers dans <code>/etc/</code>) pour \u00e9viter les conflits et maintenir une s\u00e9paration des responsabilit\u00e9s.</p> <p>La ma\u00eetrise de ces concepts permet de cr\u00e9er un environnement de travail efficace, productif et bien organis\u00e9 sous Linux et Bash.[1][2][3]</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-bash/bash-chap12/","title":"Citations","text":"<ul> <li>https://docs.rockylinux.org/10/fr/guides/automation/anacron/</li> <li>https://linux-fra.com/?p=1949</li> <li>http://doc.ubuntu-fr.org/anacron</li> <li>https://eric-wurbel.pedaweb.univ-amu.fr/extranet/Enseignement/R202/TP6.html</li> <li>https://docs.gandi.net/fr/hebergement_web/operations_courantes/anacron.html</li> <li>https://docs.redhat.com/fr/documentation/red_hat_enterprise_linux/7/html/system_administrators_guide/ch-automating_system_tasks</li> <li>https://lea-linux.org/documentations/Programmation_de_travaux_avec_at_cron_anacron</li> <li>http://doc.ubuntu-fr.org/cron</li> <li>https://tuxcare.com/fr/blog/centos-crontab/</li> <li>https://blog.stephane-robert.info/docs/admin-serveurs/linux/cron/</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap12/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 263</li> <li>completion_tokens: 8580</li> <li>total_tokens: 8843</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.129, 'request_cost': 0.006, 'total_cost': 0.135}</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap12/#content","title":"Content","text":""},{"location":"_projects/_formation-bash/bash-chap12/#les-taches-cron-et-anacron-sous-linux","title":"Les T\u00e2ches Cron et Anacron sous Linux \ud83d\udc27","text":""},{"location":"_projects/_formation-bash/bash-chap12/#introduction-aux-taches-planifiees","title":"Introduction aux t\u00e2ches planifi\u00e9es","text":"<p>La planification de t\u00e2ches est un \u00e9l\u00e9ment fondamental de l'administration syst\u00e8me Linux. Elle permet d'automatiser l'ex\u00e9cution de scripts, de commandes ou de logiciels \u00e0 des moments pr\u00e9cis ou selon des cycles r\u00e9guliers, sans intervention manuelle. Linux propose plusieurs outils pour accomplir cette automatisation, chacun con\u00e7u pour des cas d'usage sp\u00e9cifiques.[2][6]</p> <p>Les deux principaux outils de planification r\u00e9currente sont cron et anacron. Bien qu'ils partagent des objectifs similaires, ils fonctionnent selon des principes diff\u00e9rents et s'adressent \u00e0 des contextes d'utilisation distincts. Comprendre leurs diff\u00e9rences et savoir quand utiliser l'un ou l'autre est essentiel pour une gestion efficace des syst\u00e8mes Linux.</p>"},{"location":"_projects/_formation-bash/bash-chap12/#introduction-aux-cron","title":"Introduction aux Cron \u23f0","text":""},{"location":"_projects/_formation-bash/bash-chap12/#quest-ce-que-cron","title":"Qu'est-ce que cron ?","text":"<p>Cron est un d\u00e9mon syst\u00e8me (service en arri\u00e8re-plan) con\u00e7u pour ex\u00e9cuter des t\u00e2ches programm\u00e9es \u00e0 des intervalles de temps sp\u00e9cifi\u00e9s.[4][8][9] Ce d\u00e9mon s'ex\u00e9cute en permanence sur les syst\u00e8mes Unix/Linux et repr\u00e9sente le ma\u00eetre incontest\u00e9 de l'automatisation des t\u00e2ches planifi\u00e9es.</p>"},{"location":"_projects/_formation-bash/bash-chap12/#fonctionnement-fondamental-de-cron","title":"Fonctionnement fondamental de cron","text":"<p>Le service cron fonctionne selon un cycle r\u00e9gulier et m\u00e9thodique :[4][10]</p> <ul> <li>Cron se r\u00e9veille toutes les minutes et examine l'ensemble des crontab charg\u00e9es dans le syst\u00e8me</li> <li>Pour chaque minute, il v\u00e9rifie toutes les commandes planifi\u00e9es pour d\u00e9terminer si elles doivent \u00eatre ex\u00e9cut\u00e9es durant cette minute sp\u00e9cifique</li> <li>Toute sortie g\u00e9n\u00e9r\u00e9e par l'ex\u00e9cution de commandes est envoy\u00e9e par courrier \u00e9lectronique au propri\u00e9taire de la crontab</li> <li>De plus, cron examine toutes les minutes si les fichiers de configuration ont chang\u00e9 et les relit automatiquement si n\u00e9cessaire</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap12/#cas-dusage-ideal-pour-cron","title":"Cas d'usage id\u00e9al pour cron","text":"<p>Cron convient particuli\u00e8rement aux machines qui fonctionnent en continu 24 heures sur 24 et 7 jours sur 7, telles que :[2]</p> <ul> <li>Les serveurs web et serveurs de bases de donn\u00e9es</li> <li>Les syst\u00e8mes d'h\u00e9bergement mutualis\u00e9</li> <li>Les machines virtuelles fonctionnant sans interruption</li> <li>Les ordinateurs de bureau qui restent allum\u00e9s en permanence</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap12/#limitation-majeure-de-cron","title":"Limitation majeure de cron","text":"<p>La principale limitation de cron est qu'il ne rattrape pas les t\u00e2ches manqu\u00e9es. Si une machine est \u00e9teinte au moment pr\u00e9vu pour l'ex\u00e9cution d'une t\u00e2che planifi\u00e9e avec cron, la t\u00e2che ne s'ex\u00e9cutera simplement pas.[2][7] Par exemple, si une t\u00e2che de sauvegarde est programm\u00e9e tous les minuits et que l'ordinateur portable est \u00e9teint \u00e0 ce moment-l\u00e0, le script de sauvegarde ne sera pas ex\u00e9cut\u00e9 et aucune tentative de rattrapage ne sera effectu\u00e9e.</p>"},{"location":"_projects/_formation-bash/bash-chap12/#syntaxe-pour-la-crontab","title":"Syntaxe pour la Crontab \ud83d\udcdd","text":""},{"location":"_projects/_formation-bash/bash-chap12/#structure-generale-dune-entree-crontab","title":"Structure g\u00e9n\u00e9rale d'une entr\u00e9e crontab","text":"<p>Chaque ligne d'une crontab (fichier de planification cron) suit un format standard compos\u00e9 de six champs :[2][4]</p> Text Only<pre><code>minute heure jour_du_mois mois jour_de_la_semaine commande\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap12/#detail-de-chaque-champ","title":"D\u00e9tail de chaque champ","text":"Champ Plage Description Exemples minute 0-59 Minute de l'heure 0, 15, 30, 45, */5 heure 0-23 Heure du jour (format 24h) 0, 6, 12, 18, 23 jour_du_mois 1-31 Jour du mois 1, 15, 31 mois 1-12 Mois de l'ann\u00e9e 1 (janvier), 6 (juin), 12 (d\u00e9cembre) jour_de_la_semaine 0-6 Jour de la semaine (0=dimanche, 6=samedi) 0, 1, 5 commande - Commande ou script \u00e0 ex\u00e9cuter /usr/bin/backup.sh, echo \"test\""},{"location":"_projects/_formation-bash/bash-chap12/#operateurs-et-caracteres-speciaux","title":"Op\u00e9rateurs et caract\u00e8res sp\u00e9ciaux","text":"<p>La syntaxe crontab supporte plusieurs op\u00e9rateurs pour cr\u00e9er des expressions complexes :</p> <p>L'ast\u00e9risque (*)</p> <p>L'ast\u00e9risque repr\u00e9sente \"toutes les valeurs\" possibles pour ce champ. Par exemple, <code>*</code> dans le champ des heures signifie \"chaque heure\".</p> Text Only<pre><code>0 * * * * /usr/bin/script.sh\n</code></pre> <p>Cette ligne ex\u00e9cute le script <code>/usr/bin/script.sh</code> \u00e0 00:00 (minuit) de chaque jour.</p> <p>La virgule (,)</p> <p>La virgule permet de sp\u00e9cifier plusieurs valeurs distinctes.</p> Text Only<pre><code>0 9,12,17 * * * /usr/bin/rapport.sh\n</code></pre> <p>Cette ligne ex\u00e9cute le script \u00e0 9h, 12h et 17h chaque jour.</p> <p>L'intervalle (-)</p> <p>Le tiret d\u00e9finit une plage de valeurs.</p> Text Only<pre><code>0 9-17 * * * /usr/bin/verification.sh\n</code></pre> <p>Cette ligne ex\u00e9cute le script chaque heure de 9h \u00e0 17h, c'est-\u00e0-dire \u00e0 9h00, 10h00, 11h00... jusqu'\u00e0 17h00.</p> <p>L'intervalle avec r\u00e9p\u00e9tition (*/n)</p> <p>L'expression <code>*/n</code> ex\u00e9cute une t\u00e2che tous les n intervalles.</p> Text Only<pre><code>*/15 * * * * /usr/bin/sync.sh\n</code></pre> <p>Cette ligne ex\u00e9cute le script toutes les 15 minutes (\u00e0 0, 15, 30, 45 minutes de chaque heure).</p> Text Only<pre><code>0 */6 * * * /usr/bin/maintenance.sh\n</code></pre> <p>Cette ligne ex\u00e9cute le script toutes les 6 heures (\u00e0 0h, 6h, 12h, 18h).</p>"},{"location":"_projects/_formation-bash/bash-chap12/#noms-symboliques","title":"Noms symboliques","text":"<p>Pour am\u00e9liorer la lisibilit\u00e9, crontab accepte les noms anglais pour les mois et les jours de la semaine :</p> <p>Mois : jan, feb, mar, apr, may, jun, jul, aug, sep, oct, nov, dec</p> <p>Jours : sun, mon, tue, wed, thu, fri, sat</p> Text Only<pre><code>0 10 15 mar fri /usr/bin/rapport-trimestriel.sh\n</code></pre> <p>Cette ligne ex\u00e9cute le script le 15 mars \u00e0 10h s'il tombe un vendredi.</p>"},{"location":"_projects/_formation-bash/bash-chap12/#cas-particuliers-et-raccourcis","title":"Cas particuliers et raccourcis","text":"<p>Crontab propose des raccourcis pratiques pour les t\u00e2ches courantes :</p> Text Only<pre><code>@yearly    0 0 1 1 *       Ex\u00e9cute une fois par ann\u00e9e (1er janvier \u00e0 minuit)\n@annually  0 0 1 1 *       Identique \u00e0 @yearly\n@monthly   0 0 1 * *       Ex\u00e9cute une fois par mois (1er jour du mois \u00e0 minuit)\n@weekly    0 0 * * 0       Ex\u00e9cute une fois par semaine (dimanche \u00e0 minuit)\n@daily     0 0 * * *       Ex\u00e9cute une fois par jour (\u00e0 minuit)\n@midnight  0 0 * * *       Identique \u00e0 @daily\n@hourly    0 * * * *       Ex\u00e9cute une fois par heure (\u00e0 la minute 0)\n@reboot    -               Ex\u00e9cute une seule fois au d\u00e9marrage du syst\u00e8me\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap12/#exemple-de-crontab","title":"Exemple de Crontab \ud83d\udccb","text":""},{"location":"_projects/_formation-bash/bash-chap12/#edition-et-gestion-de-la-crontab","title":"\u00c9dition et gestion de la crontab","text":"<p>Pour \u00e9diter la crontab de l'utilisateur courant :</p> Bash<pre><code>crontab -e\n</code></pre> <p>Cette commande ouvre un \u00e9diteur de texte (g\u00e9n\u00e9ralement vi ou nano) permettant de modifier les t\u00e2ches programm\u00e9es.</p>"},{"location":"_projects/_formation-bash/bash-chap12/#exemple-de-crontab-commentee","title":"Exemple de crontab comment\u00e9e","text":"<p>Voici un fichier <code>/etc/crontab</code> typique avec annotations explicatives :</p> Text Only<pre><code># /etc/crontab : fichier de crontab syst\u00e8me\n# Le format est identique aux crontab utilisateur, mais avec un champ suppl\u00e9mentaire\n# pour sp\u00e9cifier l'utilisateur qui ex\u00e9cutera la t\u00e2che\n\nSHELL=/bin/bash\nPATH=/sbin:/bin:/usr/sbin:/usr/bin\nMAILTO=root\n\n# Sauvegarde quotidienne \u00e0 2h30 du matin\n30 2 * * * root /usr/local/bin/backup-daily.sh\n\n# Nettoyage des fichiers temporaires tous les jours \u00e0 3h\n0 3 * * * root /usr/local/bin/cleanup-temp.sh\n\n# Synchronisation des donn\u00e9es vers le serveur distant tous les jours \u00e0 22h\n0 22 * * * root /usr/local/bin/sync-remote.sh\n\n# Mise \u00e0 jour du syst\u00e8me le 1er jour du mois \u00e0 1h du matin\n0 1 1 * * root /usr/bin/apt update &amp;&amp; /usr/bin/apt upgrade -y\n\n# V\u00e9rification du disque dur tous les jours \u00e0 4h, du lundi au vendredi\n0 4 * * 1-5 root /usr/local/bin/check-disk.sh\n\n# Rapport de s\u00e9curit\u00e9 chaque dimanche \u00e0 6h\n0 6 * * 0 root /usr/local/bin/security-report.sh\n\n# Ex\u00e9cution horaire d'un script de maintenance\n0 * * * * root /usr/local/bin/hourly-maintenance.sh\n\n# Nettoyage des logs tous les 4 heures\n0 */4 * * * root /usr/local/bin/clean-logs.sh\n\n# Red\u00e9marrage des services critiques tous les jours \u00e0 5h du matin\n0 5 * * * root systemctl restart apache2 mysql\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap12/#deconstruction-dexemples-pratiques","title":"D\u00e9construction d'exemples pratiques","text":"<p>Exemple 1 : Sauvegarde quotidienne</p> Text Only<pre><code>30 2 * * * /home/user/backup.sh\n</code></pre> <ul> <li>30 : \u00e0 la 30\u00e8me minute</li> <li>2 : \u00e0 2h du matin</li> <li>* : tous les jours du mois</li> <li>* : tous les mois</li> <li>* : tous les jours de la semaine</li> <li>R\u00e9sultat : Le script s'ex\u00e9cute chaque jour \u00e0 2h30</li> </ul> <p>Exemple 2 : T\u00e2che tous les jours ouvrables</p> Text Only<pre><code>0 9 * * 1-5 /usr/local/bin/work-tasks.sh\n</code></pre> <ul> <li>0 : \u00e0 la minute 0</li> <li>9 : \u00e0 9h du matin</li> <li>* : tous les jours du mois</li> <li>* : tous les mois</li> <li>1-5 : du lundi (1) au vendredi (5)</li> <li>R\u00e9sultat : Le script s'ex\u00e9cute \u00e0 9h chaque jour ouvrable</li> </ul> <p>Exemple 3 : T\u00e2che toutes les deux heures</p> Text Only<pre><code>0 */2 * * * /usr/local/bin/frequent-check.sh\n</code></pre> <ul> <li>0 : \u00e0 la minute 0</li> <li>*/2 : chaque 2 heures (0, 2, 4, 6... 22)</li> <li>* : tous les jours du mois</li> <li>* : tous les mois</li> <li>* : tous les jours de la semaine</li> <li>R\u00e9sultat : Le script s'ex\u00e9cute \u00e0 0h, 2h, 4h, 6h... 22h</li> </ul> <p>Exemple 4 : T\u00e2che le 15 de chaque mois</p> Text Only<pre><code>0 0 15 * * /usr/local/bin/monthly-tasks.sh\n</code></pre> <ul> <li>0 : \u00e0 la minute 0</li> <li>0 : \u00e0 0h (minuit)</li> <li>15 : le 15 du mois</li> <li>* : tous les mois</li> <li>* : tous les jours de la semaine</li> <li>R\u00e9sultat : Le script s'ex\u00e9cute \u00e0 minuit le 15 de chaque mois</li> </ul> <p>Exemple 5 : Utilisation des raccourcis</p> Text Only<pre><code>@hourly /usr/local/bin/check-status.sh\n@daily /usr/local/bin/maintenance.sh\n@weekly /usr/local/bin/full-backup.sh\n</code></pre> <p>Ces raccourcis sont plus lisibles que leur \u00e9quivalent num\u00e9rique.</p>"},{"location":"_projects/_formation-bash/bash-chap12/#script-de-sauvegarde-planifie","title":"Script de sauvegarde planifi\u00e9","text":"<p>Voici un exemple pratique : un script de sauvegarde \u00e0 ex\u00e9cuter quotidiennement via cron.</p> Bash<pre><code>#!/bin/bash\n# Script: backup-daily.sh\n# Description: Sauvegarde quotidienne des donn\u00e9es syst\u00e8me\n# Scheduled: 0 2 * * * (2h du matin chaque jour)\n\nBACKUP_DIR=\"/var/backups\"\nSOURCE_DIR=\"/home/data\"\nDATE=$(date +%Y-%m-%d_%H-%M-%S)\nBACKUP_FILE=\"$BACKUP_DIR/backup_$DATE.tar.gz\"\nLOG_FILE=\"/var/log/backup.log\"\n\n# Cr\u00e9er le r\u00e9pertoire de sauvegarde s'il n'existe pas\nmkdir -p \"$BACKUP_DIR\"\n\n# Effectuer la sauvegarde\necho \"[$(date)] D\u00e9but de la sauvegarde de $SOURCE_DIR\" &gt;&gt; \"$LOG_FILE\"\n\nif tar -czf \"$BACKUP_FILE\" \"$SOURCE_DIR\" 2&gt;&gt; \"$LOG_FILE\"; then\n    SIZE=$(du -h \"$BACKUP_FILE\" | cut -f1)\n    echo \"[$(date)] Sauvegarde r\u00e9ussie: $BACKUP_FILE (taille: $SIZE)\" &gt;&gt; \"$LOG_FILE\"\nelse\n    echo \"[$(date)] ERREUR: \u00c9chec de la sauvegarde\" &gt;&gt; \"$LOG_FILE\"\n    exit 1\nfi\n\n# Supprimer les sauvegardes de plus de 30 jours\nfind \"$BACKUP_DIR\" -name \"backup_*.tar.gz\" -mtime +30 -delete\necho \"[$(date)] Nettoyage des anciennes sauvegardes effectu\u00e9\" &gt;&gt; \"$LOG_FILE\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap12/#commandes-de-gestion-de-crontab","title":"Commandes de gestion de crontab","text":"<p>Afficher la crontab actuelle :</p> Bash<pre><code>crontab -l\n</code></pre> <p>Supprimer la crontab :</p> Bash<pre><code>crontab -r\n</code></pre> <p>\u00c9diter la crontab :</p> Bash<pre><code>crontab -e\n</code></pre> <p>Installer une crontab \u00e0 partir d'un fichier :</p> Bash<pre><code>crontab /chemin/vers/fichier\n</code></pre> <p>Afficher la crontab d'un autre utilisateur (root requis) :</p> Bash<pre><code>crontab -u nomdutilisateur -l\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap12/#anacron-la-solution-pour-les-machines-non-permanentes","title":"Anacron : La Solution pour les Machines non Permanentes \ud83d\udcbe","text":""},{"location":"_projects/_formation-bash/bash-chap12/#quest-ce-quanacron","title":"Qu'est-ce qu'anacron ?","text":"<p>Anacron est un utilitaire con\u00e7u pour ex\u00e9cuter des commandes p\u00e9riodiquement, avec une fr\u00e9quence d\u00e9finie en jours plut\u00f4t qu'en minutes comme cron.[1][2][3] Il fonctionne diff\u00e9remment de cron et s'adresse sp\u00e9cifiquement aux machines qui ne fonctionnent pas en continu.</p> <p>La grande particularit\u00e9 d'anacron est qu'il garantit l'ex\u00e9cution des t\u00e2ches m\u00eame si la machine \u00e9tait \u00e9teinte au moment pr\u00e9vu, \u00e0 condition que la machine soit red\u00e9marr\u00e9e dans l'intervalle de temps imparti.[2]</p>"},{"location":"_projects/_formation-bash/bash-chap12/#differences-fondamentales-entre-cron-et-anacron","title":"Diff\u00e9rences fondamentales entre cron et anacron","text":"Aspect Cron Anacron Fr\u00e9quence Exprim\u00e9e en minutes, heures, jours Exprim\u00e9e uniquement en jours Temps d'acc\u00e8s Pr\u00e9cis, \u00e0 la minute pr\u00e8s Approximatif (une fois par jour) Rattrapage Ne rattrape pas les t\u00e2ches manqu\u00e9es Rattrape les t\u00e2ches si la machine \u00e9tait \u00e9teinte Cas d'usage Serveurs 24/7, t\u00e2ches horaires Ordinateurs portables, de bureau, ordinateurs intermittents Utilisateurs Peut \u00eatre utilis\u00e9 par tous les utilisateurs Principalement r\u00e9serv\u00e9 \u00e0 root Relance D\u00e9mon permanent Doit \u00eatre relanc\u00e9 r\u00e9guli\u00e8rement"},{"location":"_projects/_formation-bash/bash-chap12/#fonctionnement-danacron","title":"Fonctionnement d'anacron","text":"<p>Anacron fonctionne selon un m\u00e9canisme bas\u00e9 sur les fichiers d'horodatage (timestamp files).[1][3][4]</p> <ol> <li> <p>V\u00e9rification du timestamp : Anacron lit le fichier de configuration <code>/etc/anacrontab</code> et examine les fichiers d'horodatage correspondants, situ\u00e9s g\u00e9n\u00e9ralement dans <code>/var/spool/anacron/</code>.</p> </li> <li> <p>Calcul de la diff\u00e9rence : Pour chaque t\u00e2che, anacron compare la date actuelle avec la date d'ex\u00e9cution pr\u00e9c\u00e9dente stock\u00e9e dans le fichier timestamp.</p> </li> <li> <p>D\u00e9cision d'ex\u00e9cution : Si la diff\u00e9rence entre la date actuelle et la derni\u00e8re ex\u00e9cution d\u00e9passe le nombre de jours sp\u00e9cifi\u00e9 dans la configuration, anacron ex\u00e9cute la t\u00e2che.</p> </li> <li> <p>Attente : Avant d'ex\u00e9cuter la commande, anacron attend le d\u00e9lai (en minutes) sp\u00e9cifi\u00e9 pour laisser le syst\u00e8me se stabiliser apr\u00e8s le d\u00e9marrage.</p> </li> <li> <p>Mise \u00e0 jour du timestamp : Une fois la t\u00e2che ex\u00e9cut\u00e9e, anacron enregistre la date d'ex\u00e9cution dans le fichier d'horodatage pour la prochaine v\u00e9rification.</p> </li> </ol>"},{"location":"_projects/_formation-bash/bash-chap12/#cycle-de-vie-danacron","title":"Cycle de vie d'anacron","text":"<p>Il est important de noter qu'anacron n'est pas un d\u00e9mon permanent.[3] Apr\u00e8s l'ex\u00e9cution de ses t\u00e2ches, il se ferme. Pour cette raison, anacron doit \u00eatre relanc\u00e9 r\u00e9guli\u00e8rement. Historiquement, cela \u00e9tait assur\u00e9 par une t\u00e2che cron (voir <code>/etc/cron.d/anacron</code>), qui le lan\u00e7ait toutes les heures entre 7h30 et 23h30. Aujourd'hui, sur les syst\u00e8mes modernes, cette planification est assur\u00e9e par un service et un \"timer\" systemd plut\u00f4t que par une t\u00e2che cron traditionnelle.</p> Bash<pre><code>systemctl cat anacron.timer\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap12/#configuration-danacron-etcanacrontab","title":"Configuration d'anacron : <code>/etc/anacrontab</code>","text":""},{"location":"_projects/_formation-bash/bash-chap12/#structure-du-fichier","title":"Structure du fichier","text":"<p>Le fichier <code>/etc/anacrontab</code> contient les t\u00e2ches anacron, avec un format similaire \u00e0 crontab mais simplifi\u00e9.[1][2][4]</p> Text Only<pre><code>period delay job-identifier command\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap12/#detail-des-champs","title":"D\u00e9tail des champs","text":"Champ Description Exemple period Intervalle en jours 1 (quotidien), 7 (hebdomadaire), 30 (mensuel) delay D\u00e9lai d'attente en minutes avant l'ex\u00e9cution 5, 10, 30, 45 job-identifier Identifiant unique pour la t\u00e2che cron.daily, cron.weekly, backup command Commande ou script \u00e0 ex\u00e9cuter /usr/bin/run-parts /etc/cron.daily"},{"location":"_projects/_formation-bash/bash-chap12/#exemple-de-fichier-anacrontab","title":"Exemple de fichier anacrontab","text":"Text Only<pre><code># /etc/anacrontab\n# Ex\u00e9cuter les t\u00e2ches dans /etc/cron.daily quotidiennement\n# Attendre 5 minutes apr\u00e8s le d\u00e9marrage, puis v\u00e9rifier\n# Si non ex\u00e9cut\u00e9 aujourd'hui, lancer la t\u00e2che\n\n1 5 cron.daily nice run-parts /etc/cron.daily\n\n# Ex\u00e9cuter les t\u00e2ches dans /etc/cron.weekly hebdomadairement\n# Attendre 25 minutes apr\u00e8s le d\u00e9marrage, puis v\u00e9rifier\n# Si non ex\u00e9cut\u00e9 depuis une semaine, lancer la t\u00e2che\n\n7 25 cron.weekly nice run-parts /etc/cron.weekly\n\n# Ex\u00e9cuter les t\u00e2ches dans /etc/cron.monthly mensuellement\n# Attendre 45 minutes apr\u00e8s le d\u00e9marrage, puis v\u00e9rifier\n# Si non ex\u00e9cut\u00e9 depuis un mois, lancer la t\u00e2che\n\n@monthly 45 cron.monthly nice run-parts /etc/cron.monthly\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap12/#deconstruction-dun-exemple-anacron","title":"D\u00e9construction d'un exemple anacron","text":"<p>Analysons la premi\u00e8re ligne du fichier anacrontab :</p> Text Only<pre><code>1 5 cron.daily nice run-parts /etc/cron.daily\n</code></pre> <ul> <li>1 : P\u00e9riode de 1 jour. Anacron v\u00e9rifiera si la t\u00e2che a \u00e9t\u00e9 ex\u00e9cut\u00e9e dans les derni\u00e8res 24 heures.</li> <li>5 : D\u00e9lai de 5 minutes. Apr\u00e8s le d\u00e9marrage de la machine, anacron attendra 5 minutes avant d'ex\u00e9cuter cette t\u00e2che.</li> <li>cron.daily : Identifiant unique pour cette t\u00e2che. Le fichier d'horodatage correspondant est <code>/var/spool/anacron/cron.daily</code>.</li> <li>nice run-parts /etc/cron.daily : La commande \u00e0 ex\u00e9cuter. Elle lance tous les scripts se trouvant dans le r\u00e9pertoire <code>/etc/cron.daily</code> avec une priorit\u00e9 r\u00e9duite (nice).</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap12/#contraintes-dexecution-danacron","title":"Contraintes d'ex\u00e9cution d'anacron","text":"<p>Bien que anacron soit flexible, certaines contraintes s'appliquent par d\u00e9faut :[1]</p> <ol> <li> <p>Plage horaire restreinte : Par d\u00e9faut, anacron ne peut ex\u00e9cuter ses t\u00e2ches que de 3h \u00e0 22h (ou 23h selon la configuration).</p> </li> <li> <p>D\u00e9lai al\u00e9atoire entre t\u00e2ches : Lorsque le premier travail est en cours d'ex\u00e9cution, les t\u00e2ches suivantes subissent un d\u00e9lai al\u00e9atoire de 0 \u00e0 45 minutes pour \u00e9viter une surcharge syst\u00e8me.</p> </li> <li> <p>V\u00e9rification du fichier de lock : Pour \u00e9viter l'ex\u00e9cution simultan\u00e9e de la m\u00eame t\u00e2che, anacron utilise des fichiers de verrous.</p> </li> </ol>"},{"location":"_projects/_formation-bash/bash-chap12/#fichiers-dhorodatage-danacron","title":"Fichiers d'horodatage d'anacron","text":"<p>Les fichiers d'horodatage sont stock\u00e9s dans <code>/var/spool/anacron/</code> :[1][4]</p> Bash<pre><code>ls -la /var/spool/anacron/\n</code></pre> <p>Exemple de sortie :</p> Text Only<pre><code>-rw------- 1 root root 19 Dec  3 09:15 cron.daily\n-rw------- 1 root root 19 Nov 26 08:30 cron.weekly\n-rw------- 1 root root 19 Oct 31 10:45 cron.monthly\n</code></pre> <p>Chaque fichier contient simplement la date de la derni\u00e8re ex\u00e9cution :</p> Bash<pre><code>cat /var/spool/anacron/cron.daily\n</code></pre> <p>Exemple de contenu :</p> Text Only<pre><code>20251203\n</code></pre> <p>Cela signifie que la t\u00e2che <code>cron.daily</code> a \u00e9t\u00e9 ex\u00e9cut\u00e9e le 3 d\u00e9cembre 2025.</p>"},{"location":"_projects/_formation-bash/bash-chap12/#options-de-ligne-de-commande-pour-anacron","title":"Options de ligne de commande pour anacron","text":"<p>Anacron peut \u00eatre utilis\u00e9 directement avec plusieurs options :[3]</p> Option Description <code>-f</code> Force l'ex\u00e9cution imm\u00e9diate des t\u00e2ches, en ignorant les fichiers d'horodatage <code>-u</code> Met \u00e0 jour la date courante dans les fichiers d'horodatage, mais ne lance rien <code>-s</code> Met en s\u00e9rie l'ex\u00e9cution des t\u00e2ches (une seule \u00e0 la fois) <code>-n</code> Ignore le d\u00e9lai sp\u00e9cifi\u00e9 et ex\u00e9cute les t\u00e2ches imm\u00e9diatement <p>Exemples d'utilisation :</p> Bash<pre><code># Forcer l'ex\u00e9cution de toutes les t\u00e2ches anacron maintenant\nanacron -f\n\n# Mettre \u00e0 jour les timestamps sans ex\u00e9cuter les t\u00e2ches\nanacron -u\n\n# Ex\u00e9cuter les t\u00e2ches en s\u00e9rie (une \u00e0 la fois)\nanacron -s\n\n# Ignorer les d\u00e9lais et ex\u00e9cuter imm\u00e9diatement\nanacron -n\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap12/#cas-pratique-sauvegarde-avec-anacron","title":"Cas pratique : Sauvegarde avec anacron","text":"<p>Voici un exemple pratique de configuration anacron pour une sauvegarde sur un ordinateur portable :</p> Text Only<pre><code># /etc/anacrontab - Configuration pour ordinateur portable\n\n# Sauvegarde quotidienne - Attendre 10 minutes apr\u00e8s le d\u00e9marrage\n1 10 backup.daily /usr/local/bin/backup-daily.sh\n\n# Nettoyage des fichiers temporaires - Attendre 20 minutes\n7 20 cleanup.weekly /usr/local/bin/cleanup-temp.sh\n\n# Synchronisation avec le serveur distant - Attendre 30 minutes\n14 30 sync.monthly /usr/local/bin/sync-remote.sh\n</code></pre> <p>Script de sauvegarde correspondant :</p> Bash<pre><code>#!/bin/bash\n# Script: backup-daily.sh\n# Description: Sauvegarde quotidienne pour ordinateur portable\n# Scheduled: Anacron, quotidien, 10 minutes apr\u00e8s d\u00e9marrage\n\nBACKUP_DIR=\"$HOME/.backups\"\nIMPORTANT_DIRS=(\"$HOME/Documents\" \"$HOME/Projets\" \"$HOME/Photos\")\nDATE=$(date +%Y-%m-%d_%H-%M-%S)\nBACKUP_FILE=\"$BACKUP_DIR/backup_$DATE.tar.gz\"\nLOG_FILE=\"$BACKUP_DIR/backup.log\"\n\n# Cr\u00e9er le r\u00e9pertoire de sauvegarde s'il n'existe pas\nmkdir -p \"$BACKUP_DIR\"\n\necho \"[$(date)] === D\u00e9but de la sauvegarde ===\" &gt;&gt; \"$LOG_FILE\"\n\n# Sauvegarde des r\u00e9pertoires importants\nfor DIR in \"${IMPORTANT_DIRS[@]}\"; do\n    if [ -d \"$DIR\" ]; then\n        echo \"[$(date)] Sauvegarde de $DIR...\" &gt;&gt; \"$LOG_FILE\"\n        tar -czf \"$BACKUP_DIR/backup_$(basename $DIR)_$DATE.tar.gz\" \"$DIR\" 2&gt;&gt; \"$LOG_FILE\"\n    fi\ndone\n\necho \"[$(date)] Sauvegarde compl\u00e9t\u00e9e\" &gt;&gt; \"$LOG_FILE\"\n\n# Supprimer les sauvegardes de plus de 7 jours\nfind \"$BACKUP_DIR\" -name \"backup_*.tar.gz\" -mtime +7 -delete\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap12/#relations-entre-cron-et-anacron","title":"Relations entre Cron et Anacron \ud83d\udd17","text":""},{"location":"_projects/_formation-bash/bash-chap12/#configuration-par-defaut-sur-les-systemes-linux","title":"Configuration par d\u00e9faut sur les syst\u00e8mes Linux","text":"<p>Sur la plupart des distributions Linux modernes, cron et anacron travaillent ensemble de fa\u00e7on harmonieuse.[4] En regardant les fichiers <code>/etc/crontab</code> et <code>/etc/anacrontab</code>, on d\u00e9couvre que :</p> <ul> <li>Si anacron est install\u00e9, il est configur\u00e9 par d\u00e9faut pour ex\u00e9cuter les t\u00e2ches quotidiennes, hebdomadaires et mensuelles pr\u00e9sentes dans les r\u00e9pertoires <code>/etc/cron.daily</code>, <code>/etc/cron.weekly</code> et <code>/etc/cron.monthly</code>.</li> <li>Si anacron n'est pas install\u00e9, cron ex\u00e9cute ces m\u00eames t\u00e2ches directement.</li> </ul> <p>Cela signifie qu'anacron remplace partiellement cron pour les t\u00e2ches r\u00e9currentes simples.</p>"},{"location":"_projects/_formation-bash/bash-chap12/#integration-dans-etccrond0hourly","title":"Int\u00e9gration dans <code>/etc/cron.d/0hourly</code>","text":"<p>Le fichier <code>/etc/cron.d/0hourly</code> est un bon exemple d'int\u00e9gration :[1]</p> Text Only<pre><code># Run the hourly jobs\n\nSHELL=/bin/bash\n\nPATH=/sbin:/bin:/usr/sbin:/usr/bin\n\nMAILTO=root\n\n01 * * * * root run-parts /etc/cron.hourly\n</code></pre> <p>Ce fichier est g\u00e9r\u00e9 directement par cron et ex\u00e9cute toutes les t\u00e2ches du r\u00e9pertoire <code>/etc/cron.hourly</code> \u00e0 la premi\u00e8re minute de chaque heure.</p>"},{"location":"_projects/_formation-bash/bash-chap12/#verification-du-service-cron-actif","title":"V\u00e9rification du service cron actif","text":"<p>Pour v\u00e9rifier que les t\u00e2ches sont bien ex\u00e9cut\u00e9es par le service appropri\u00e9 :</p> Bash<pre><code>journalctl -u crond.service\n</code></pre> <p>Ou sur les syst\u00e8mes utilisant systemd :</p> Bash<pre><code>systemctl status cron\nsystemctl status anacron\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap12/#bonnes-pratiques-et-recommandations","title":"Bonnes pratiques et recommandations \ud83c\udfaf","text":""},{"location":"_projects/_formation-bash/bash-chap12/#pour-cron","title":"Pour cron","text":"<ol> <li>Utiliser des chemins absolus : Toujours sp\u00e9cifier le chemin complet des commandes et scripts pour \u00e9viter les erreurs de r\u00e9pertoire de travail.</li> </ol> Text Only<pre><code># \u274c Mauvais\n0 2 * * * backup.sh\n\n# \u2705 Bon\n0 2 * * * /usr/local/bin/backup.sh\n</code></pre> <ol> <li>Rediriger les sorties : Rediriger stdout et stderr vers un fichier pour un d\u00e9bogage plus facile.</li> </ol> Text Only<pre><code># \u2705 Bonne pratique\n0 2 * * * /usr/local/bin/backup.sh &gt;&gt; /var/log/backup.log 2&gt;&amp;1\n</code></pre> <ol> <li>Tester les scripts : Toujours tester le script manuellement avant de le planifier.</li> </ol> Bash<pre><code>/usr/local/bin/backup.sh\n# V\u00e9rifier les erreurs\necho $?\n</code></pre> <ol> <li>Documenter les t\u00e2ches : Ajouter des commentaires expliquant chaque t\u00e2che.</li> </ol> Text Only<pre><code># Sauvegarde quotidienne \u00e0 2h30 du matin\n30 2 * * * /usr/local/bin/backup.sh\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap12/#pour-anacron","title":"Pour anacron","text":"<ol> <li>Adapter les d\u00e9lais \u00e0 la machine : Augmenter les d\u00e9lais si la machine est lente ou surcharg\u00e9e.</li> </ol> Text Only<pre><code># Pour une machine puissante\n1 5 cron.daily nice run-parts /etc/cron.daily\n\n# Pour une machine lente\n1 15 cron.daily nice run-parts /etc/cron.daily\n</code></pre> <ol> <li>Utiliser des d\u00e9lais diff\u00e9rents : Espacer les t\u00e2ches pour \u00e9viter une surcharge.</li> </ol> Text Only<pre><code>1 5 backup1 /usr/local/bin/backup1.sh\n7 30 backup2 /usr/local/bin/backup2.sh\n14 55 backup3 /usr/local/bin/backup3.sh\n</code></pre> <ol> <li>V\u00e9rifier les logs : Consulter les logs d'ex\u00e9cution pour s'assurer que les t\u00e2ches s'ex\u00e9cutent.</li> </ol> Bash<pre><code>grep anacron /var/log/syslog\ntail -f /var/log/cron\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap12/#matrice-de-decision-cron-vs-anacron","title":"Matrice de d\u00e9cision : Cron vs Anacron \ud83d\uddc2\ufe0f","text":"<p>Avant de choisir entre cron et anacron, utiliser cette matrice de d\u00e9cision :</p> Situation Recommandation Justification Serveur fonctionnant 24/7 Cron Les t\u00e2ches doivent s'ex\u00e9cuter pr\u00e9cis\u00e9ment aux heures pr\u00e9vues Ordinateur portable ou de bureau Anacron Rattrape les t\u00e2ches manqu\u00e9es quand l'ordinateur est rallum\u00e9 T\u00e2che horaire ou minute-pr\u00e9cise Cron Anacron n'offre que la pr\u00e9cision journali\u00e8re T\u00e2che quotidienne/hebdomadaire/mensuelle Anacron Granularit\u00e9 suffisante et meilleure adaptation aux machines intermittentes Machine qui s'\u00e9teint r\u00e9guli\u00e8rement Anacron Garantit l'ex\u00e9cution m\u00eame si la machine \u00e9tait \u00e9teinte Plusieurs t\u00e2ches \u00e0 ex\u00e9cuter la m\u00eame minute Cron Plus de flexibilit\u00e9 et contr\u00f4le Environnement d'h\u00e9bergement partag\u00e9 Cron Meilleure isolation entre utilisateurs Script de maintenance syst\u00e8me critique Anacron Ex\u00e9cution garantie au moins une fois par jour"},{"location":"_projects/_formation-bash/bash-chap12/#concepts-avances-et-optimisations","title":"Concepts avanc\u00e9s et optimisations \u26a1","text":""},{"location":"_projects/_formation-bash/bash-chap12/#nice-et-priorites-dexecution","title":"Nice et priorit\u00e9s d'ex\u00e9cution","text":"<p>Dans les exemples anacron, on remarque l'utilisation de la commande <code>nice</code>. Cette commande ajuste la priorit\u00e9 d'ex\u00e9cution d'un processus :[1]</p> Bash<pre><code>nice -n 19 /usr/local/bin/heavy-backup.sh\n</code></pre> <ul> <li><code>-n 19</code> : Priorit\u00e9 la plus basse (t\u00e2che ex\u00e9cut\u00e9e quand le syst\u00e8me n'a rien d'autre \u00e0 faire)</li> <li><code>-n 0</code> : Priorit\u00e9 normale</li> <li><code>-n -20</code> : Priorit\u00e9 la plus haute (r\u00e9serv\u00e9e \u00e0 root)</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap12/#execution-limitee-en-ressources","title":"Ex\u00e9cution limit\u00e9e en ressources","text":"<p>Pour limiter l'impact d'une t\u00e2che cron sur les ressources syst\u00e8me :</p> Bash<pre><code># Limiter \u00e0 50% de CPU et 500 Mo de RAM\n0 2 * * * ionice -c3 /usr/local/bin/limited-backup.sh\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap12/#gestion-des-erreurs-dans-les-taches","title":"Gestion des erreurs dans les t\u00e2ches","text":"<p>Les sorties d'erreur et les statuts de sortie sont cruciaux pour le d\u00e9bogage :</p> Bash<pre><code>#!/bin/bash\n# Script avec gestion d'erreur\n\nset -e  # Sortir en cas d'erreur\n\nexec 1&gt;/var/log/backup.log\nexec 2&gt;&amp;1\n\necho \"D\u00e9but de la sauvegarde : $(date)\"\n\nif ! tar -czf /backup/data.tar.gz /home/data; then\n    echo \"ERREUR: \u00c9chec de la sauvegarde\"\n    exit 1\nfi\n\necho \"Sauvegarde compl\u00e9t\u00e9e avec succ\u00e8s : $(date)\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap12/#stockage-des-resultats-dans-des-bases-de-donnees","title":"Stockage des r\u00e9sultats dans des bases de donn\u00e9es","text":"<p>Pour une meilleure tra\u00e7abilit\u00e9, enregistrer les r\u00e9sultats dans une base de donn\u00e9es :</p> Bash<pre><code>#!/bin/bash\n# Script avec enregistrement en base de donn\u00e9es\n\nTASK_NAME=\"backup\"\nSTART_TIME=$(date +%s)\nSTATUS=\"STARTED\"\n\n# Effectuer la t\u00e2che\nif /usr/local/bin/backup.sh; then\n    STATUS=\"SUCCESS\"\n    DURATION=$(($(date +%s) - START_TIME))\nelse\n    STATUS=\"FAILED\"\n    DURATION=$(($(date +%s) - START_TIME))\nfi\n\n# Enregistrer dans la base de donn\u00e9es (exemple avec sqlite3)\nsqlite3 /var/db/tasks.db &lt;&lt;EOF\nINSERT INTO task_log (task_name, status, duration, timestamp)\nVALUES ('$TASK_NAME', '$STATUS', $DURATION, datetime('now'));\nEOF\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap12/#depannage-et-diagnostique","title":"D\u00e9pannage et diagnostique \ud83d\udd27","text":""},{"location":"_projects/_formation-bash/bash-chap12/#cron-ne-sexecute-pas","title":"Cron ne s'ex\u00e9cute pas","text":"<ol> <li>V\u00e9rifier si le service est en cours d'ex\u00e9cution :</li> </ol> Bash<pre><code>systemctl status cron\n# ou\nsystemctl status crond\n</code></pre> <ol> <li>V\u00e9rifier la syntaxe de la crontab :</li> </ol> Bash<pre><code>crontab -l  # Afficher la crontab actuelle\n</code></pre> <ol> <li>Consulter les logs :</li> </ol> Bash<pre><code>journalctl -u cron -n 50\ntail -f /var/log/cron\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap12/#anacron-ne-sexecute-pas","title":"Anacron ne s'ex\u00e9cute pas","text":"<ol> <li>V\u00e9rifier le timer systemd :</li> </ol> Bash<pre><code>systemctl status anacron.timer\nsystemctl list-timers --all | grep anacron\n</code></pre> <ol> <li>Forcer l'ex\u00e9cution pour tester :</li> </ol> Bash<pre><code>anacron -f\n</code></pre> <ol> <li>Consulter les fichiers d'horodatage :</li> </ol> Bash<pre><code>ls -la /var/spool/anacron/\ncat /var/spool/anacron/cron.daily\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap12/#emails-de-cron-manquants","title":"Emails de cron manquants","text":"<p>Si cron n'envoie pas les emails de sortie :</p> <ol> <li>V\u00e9rifier la variable MAILTO :</li> </ol> Bash<pre><code>grep MAILTO /etc/crontab\ncrontab -l | grep MAILTO\n</code></pre> <ol> <li>Installer postfix ou sendmail :</li> </ol> Bash<pre><code>apt install postfix\n# ou\nyum install postfix\n</code></pre> <ol> <li>Rediriger manuellement :</li> </ol> Text Only<pre><code>0 2 * * * /usr/local/bin/backup.sh &gt;&gt; /var/log/backup.log 2&gt;&amp;1\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap12/#conclusion-et-cheminement-dapprentissage","title":"Conclusion et cheminement d'apprentissage \ud83d\udcda","text":""},{"location":"_projects/_formation-bash/bash-chap12/#progression-recommandee","title":"Progression recommand\u00e9e","text":"<p>La ma\u00eetrise de cron et anacron suit un cheminement logique :</p> <ol> <li> <p>\u00c9tape 1 : Comprendre les bases de cron - Apprendre la syntaxe simple et les cas d'usage courants. Pratiquer avec des t\u00e2ches simples comme l'affichage de l'heure ou la cr\u00e9ation de fichiers de test.</p> </li> <li> <p>\u00c9tape 2 : Cr\u00e9er des scripts ex\u00e9cutables - D\u00e9velopper des scripts bash testables en ligne de commande avant de les ajouter \u00e0 cron.</p> </li> <li> <p>\u00c9tape 3 : Int\u00e9grer des t\u00e2ches \u00e0 cron - Planifier les scripts cr\u00e9\u00e9s avec des fr\u00e9quences variables et v\u00e9rifier l'ex\u00e9cution via les logs.</p> </li> <li> <p>\u00c9tape 4 : D\u00e9couvrir anacron - Comprendre les limitations de cron et pourquoi anacron offre une solution meilleure pour les machines intermittentes.</p> </li> <li> <p>\u00c9tape 5 : Cas d'usage complexes - Combiner cron et anacron, g\u00e9rer les erreurs, impl\u00e9menter la redondance et la surveillance.</p> </li> <li> <p>\u00c9tape 6 : Optimisation en production - Appliquer les bonnes pratiques, monitorer l'ex\u00e9cution, et maintenir une documentation pr\u00e9cise.</p> </li> </ol>"},{"location":"_projects/_formation-bash/bash-chap12/#competences-acquises","title":"Comp\u00e9tences acquises","text":"<p>\u00c0 la fin de ce module, ma\u00eetriser :</p> <ul> <li>\u2713 La syntaxe compl\u00e8te de crontab et anacrontab</li> <li>\u2713 La cr\u00e9ation et la gestion des fichiers de configuration</li> <li>\u2713 La diff\u00e9rence fondamentale entre cron et anacron</li> <li>\u2713 Le choix appropri\u00e9 de l'outil selon le contexte</li> <li>\u2713 La cr\u00e9ation de scripts robustes et testables</li> <li>\u2713 La gestion des erreurs et la journalisation</li> <li>\u2713 Le d\u00e9pannage et la r\u00e9solution de probl\u00e8mes courants</li> <li>\u2713 L'optimisation des performances et des ressources</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap12/#points-cles-a-retenir","title":"Points cl\u00e9s \u00e0 retenir","text":"<ul> <li>Cron est le d\u00e9mon de base pour les t\u00e2ches programm\u00e9es pr\u00e9cises sur les syst\u00e8mes toujours actifs.</li> <li>Anacron garantit l'ex\u00e9cution des t\u00e2ches m\u00eame sur les machines intermittentes.</li> <li>Les fichiers d'horodatage d'anacron permettent de rattraper les t\u00e2ches manqu\u00e9es.</li> <li>La syntaxe crontab utilise cinq ou six champs pour d\u00e9finir le moment d'ex\u00e9cution.</li> <li>Les redirections (&gt;, &gt;&gt;, 2&gt;&amp;1) sont essentielles pour d\u00e9boguer les t\u00e2ches planifi\u00e9es.</li> <li>La documentation et les commentaires facilitent la maintenance \u00e0 long terme.</li> </ul> <p>La ma\u00eetrise de ces outils est fondamentale pour devenir un administrateur syst\u00e8me Linux efficace et capable de g\u00e9rer l'automatisation complexe dans tous les contextes possibles.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-bash/bash-chap13/","title":"Citations","text":"<ul> <li>https://docs.cherryservers.com/knowledge/how-to-connect-to-a-linux-server-using-ssh</li> <li>https://hostman.com/tutorials/how-to-install-and-configure-ssh-on-an-ubuntu-server/</li> <li>https://www.zenarmor.com/docs/linux-tutorials/how-to-configure-and-enable-ssh-in-ubuntu</li> <li>https://www.geeksforgeeks.org/linux-unix/linux-ssh-server-sshd-configuration-and-security-options-with-examples/</li> <li>https://www.ssh.com/academy/ssh/command</li> <li>https://supporthost.com/it/connessione-ssh/</li> <li>https://www.youtube.com/watch?v=wZ5uMcqxjXo</li> <li>https://guide.debianizzati.org/index.php/OpenSSH</li> <li>https://www.digitalocean.com/community/tutorials/how-to-use-ssh-to-connect-to-a-remote-server</li> <li>https://introserv.com/it/tutorials/changing-the-ssh-port/</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap13/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 296</li> <li>completion_tokens: 2721</li> <li>total_tokens: 3017</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.041, 'request_cost': 0.006, 'total_cost': 0.048}</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap13/#content","title":"Content","text":"Markdown<pre><code># Chapitre 13 : Le protocole SSH\n\nLe protocole SSH (Secure Shell) est un protocole r\u00e9seau cryptographique utilis\u00e9 pour \u00e9tablir des connexions s\u00e9curis\u00e9es \u00e0 distance entre deux syst\u00e8mes. Il permet de g\u00e9rer des serveurs, d\u2019ex\u00e9cuter des commandes, de transf\u00e9rer des fichiers et de configurer des tunnels s\u00e9curis\u00e9s. Ce chapitre d\u00e9taille les aspects fondamentaux du protocole SSH, avec des exemples pratiques, des scripts Bash, des tableaux explicatifs et des sch\u00e9mas illustratifs.\n\n---\n\n## Introduction au protocole SSH\n\nSSH est un protocole standard pour l\u2019acc\u00e8s s\u00e9curis\u00e9 \u00e0 distance \u00e0 des syst\u00e8mes Linux/Unix. Il remplace les protocoles anciens et non s\u00e9curis\u00e9s comme Telnet ou rlogin.\n\n### Fonctionnalit\u00e9s principales\n\n- Acc\u00e8s \u00e0 distance s\u00e9curis\u00e9 (chiffrement des donn\u00e9es)\n- Authentification forte (mot de passe, cl\u00e9s RSA/DSA/ECDSA)\n- Transfert de fichiers (SCP, SFTP)\n- Tunneling et redirection de ports\n\n### Architecture SSH\n\nSSH fonctionne selon un mod\u00e8le client-serveur :\n- Le **client SSH** initie la connexion (ex : `ssh`, PuTTY)\n- Le **serveur SSH** (sshd) \u00e9coute sur un port (par d\u00e9faut 22) et g\u00e8re les connexions entrantes\n\n### Versions du protocole\n\n| Version | Description |\n|---------|-------------|\n| SSH-1   | Ancienne version, vuln\u00e9rable, d\u00e9conseill\u00e9e |\n| SSH-2   | Version actuelle, s\u00e9curis\u00e9e, recommand\u00e9e |\n\n---\n\n## Connexion \u00e0 un serveur\n\nLa connexion SSH se fait via la commande `ssh` sur la plupart des syst\u00e8mes Linux, macOS et Windows (avec OpenSSH ou PuTTY).\n\n### Syntaxe de base\n\n```bash\nssh [options] [utilisateur@]adresse_ip [-p port]\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap13/#exemple-de-connexion","title":"Exemple de connexion","text":"Bash<pre><code>ssh admin@192.168.1.10\n</code></pre> <ul> <li>Si le port n\u2019est pas le 22, sp\u00e9cifier avec <code>-p</code> : Bash<pre><code>ssh admin@192.168.1.10 -p 2222\n</code></pre></li> </ul>"},{"location":"_projects/_formation-bash/bash-chap13/#schema-de-connexion-ssh","title":"Sch\u00e9ma de connexion SSH","text":"Text Only<pre><code>+----------------+       +-----------------+\n|   Client SSH   | ----&gt; |   Serveur SSH   |\n| (ssh, PuTTY)   |       |   (sshd)        |\n+----------------+       +-----------------+\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap13/#configuration-securisee-du-serveur","title":"Configuration s\u00e9curis\u00e9e du serveur","text":"<p>Configurer correctement le serveur SSH est essentiel pour \u00e9viter les attaques.</p>"},{"location":"_projects/_formation-bash/bash-chap13/#installation-du-serveur-ssh-ubuntudebian","title":"Installation du serveur SSH (Ubuntu/Debian)","text":"Bash<pre><code>sudo apt update\nsudo apt install openssh-server\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap13/#fichier-de-configuration","title":"Fichier de configuration","text":"<p>Le fichier principal est <code>/etc/ssh/sshd_config</code>.</p>"},{"location":"_projects/_formation-bash/bash-chap13/#exemple-de-configuration-securisee","title":"Exemple de configuration s\u00e9curis\u00e9e","text":"Text Only<pre><code># D\u00e9sactiver l'acc\u00e8s root\nPermitRootLogin no\n\n# Changer le port par d\u00e9faut\nPort 2222\n\n# D\u00e9sactiver l'authentification par mot de passe\nPasswordAuthentication no\n\n# Autoriser uniquement l'authentification par cl\u00e9\nPubkeyAuthentication yes\n\n# Limiter les utilisateurs autoris\u00e9s\nAllowUsers admin user1\n\n# D\u00e9sactiver les protocoles anciens\nProtocol 2\n\n# Limiter le nombre de tentatives\nMaxAuthTries 3\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap13/#redemarrer-le-service-ssh","title":"Red\u00e9marrer le service SSH","text":"Bash<pre><code>sudo systemctl restart ssh\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap13/#tableau-des-options-de-securite","title":"Tableau des options de s\u00e9curit\u00e9","text":"Option Valeur recommand\u00e9e Description PermitRootLogin no Interdire l\u2019acc\u00e8s root PasswordAuthentication no D\u00e9sactiver l\u2019authentification par mot de passe PubkeyAuthentication yes Activer l\u2019authentification par cl\u00e9 Port 2222 Changer le port par d\u00e9faut AllowUsers admin user1 Limiter les utilisateurs autoris\u00e9s Protocol 2 Utiliser SSH-2 uniquement MaxAuthTries 3 Limiter les tentatives"},{"location":"_projects/_formation-bash/bash-chap13/#proteger-ses-cles-privees-et-configurer-des-options-ssh-sur-le-client","title":"Prot\u00e9ger ses cl\u00e9s priv\u00e9es et configurer des options SSH sur le client","text":"<p>Les cl\u00e9s SSH sont sensibles. Il est crucial de les prot\u00e9ger.</p>"},{"location":"_projects/_formation-bash/bash-chap13/#generation-dune-paire-de-cles","title":"G\u00e9n\u00e9ration d\u2019une paire de cl\u00e9s","text":"Bash<pre><code>ssh-keygen -t rsa -b 4096 -C \"comment\"\n</code></pre> <ul> <li><code>-t rsa</code> : type de cl\u00e9</li> <li><code>-b 4096</code> : taille de la cl\u00e9</li> <li><code>-C \"comment\"</code> : commentaire optionnel</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap13/#protection-des-cles","title":"Protection des cl\u00e9s","text":"<ul> <li>Stocker la cl\u00e9 priv\u00e9e dans <code>~/.ssh/id_rsa</code></li> <li>Prot\u00e9ger la cl\u00e9 avec un mot de passe (passphrase)</li> <li>Changer les permissions : Bash<pre><code>chmod 600 ~/.ssh/id_rsa\nchmod 644 ~/.ssh/id_rsa.pub\n</code></pre></li> </ul>"},{"location":"_projects/_formation-bash/bash-chap13/#configuration-du-client-ssh","title":"Configuration du client SSH","text":"<p>Le fichier <code>~/.ssh/config</code> permet de configurer des options par d\u00e9faut.</p>"},{"location":"_projects/_formation-bash/bash-chap13/#exemple-de-configuration","title":"Exemple de configuration","text":"Text Only<pre><code>Host mon-serveur\n    HostName 192.168.1.10\n    User admin\n    Port 2222\n    IdentityFile ~/.ssh/id_rsa\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap13/#tableau-des-options-de-configuration-client","title":"Tableau des options de configuration client","text":"Option Description Host Alias pour la connexion HostName Adresse IP ou nom d\u2019h\u00f4te User Utilisateur distant Port Port SSH IdentityFile Chemin vers la cl\u00e9 priv\u00e9e"},{"location":"_projects/_formation-bash/bash-chap13/#developpement-distant-avec-ssh-et-vs-code","title":"D\u00e9veloppement distant avec SSH et VS Code","text":"<p>VS Code permet de d\u00e9velopper directement sur un serveur distant via SSH.</p>"},{"location":"_projects/_formation-bash/bash-chap13/#installation-de-lextension-remote-ssh","title":"Installation de l\u2019extension Remote-SSH","text":"<ul> <li>Ouvrir VS Code</li> <li>Installer l\u2019extension \"Remote-SSH\"</li> <li>Se connecter via l\u2019ic\u00f4ne \"Remote Explorer\"</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap13/#connexion-avec-vs-code","title":"Connexion avec VS Code","text":"<ul> <li>Cliquer sur \"Connect to Host\"</li> <li>Entrer la configuration SSH (alias, IP, port, cl\u00e9)</li> </ul>"},{"location":"_projects/_formation-bash/bash-chap13/#schema-de-developpement-distant","title":"Sch\u00e9ma de d\u00e9veloppement distant","text":"Text Only<pre><code>+----------------+       +-----------------+       +-----------------+\n|   VS Code      | ----&gt; |   SSH Client    | ----&gt; |   Serveur SSH   |\n|   (Local)      |       |   (ssh)         |       |   (sshd)        |\n+----------------+       +-----------------+       +-----------------+\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap13/#les-paires-de-cle","title":"Les paires de cl\u00e9","text":"<p>Les paires de cl\u00e9s SSH sont compos\u00e9es d\u2019une cl\u00e9 publique et d\u2019une cl\u00e9 priv\u00e9e.</p>"},{"location":"_projects/_formation-bash/bash-chap13/#generation-dune-paire-de-cles_1","title":"G\u00e9n\u00e9ration d\u2019une paire de cl\u00e9s","text":"Bash<pre><code>ssh-keygen -t rsa -b 4096 -C \"admin@serveur\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap13/#copie-de-la-cle-publique-sur-le-serveur","title":"Copie de la cl\u00e9 publique sur le serveur","text":"Bash<pre><code>ssh-copy-id admin@192.168.1.10\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap13/#structure-des-fichiers","title":"Structure des fichiers","text":"Fichier Description <code>id_rsa</code> Cl\u00e9 priv\u00e9e <code>id_rsa.pub</code> Cl\u00e9 publique <code>authorized_keys</code> Cl\u00e9s publiques autoris\u00e9es sur le serveur"},{"location":"_projects/_formation-bash/bash-chap13/#schema-de-generation-et-dutilisation-des-cles","title":"Sch\u00e9ma de g\u00e9n\u00e9ration et d\u2019utilisation des cl\u00e9s","text":"Text Only<pre><code>+----------------+       +-----------------+\n|   Client SSH   | ----&gt; |   Serveur SSH   |\n|   (id_rsa)     |       |   (authorized_keys) |\n+----------------+       +-----------------+\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap13/#exemples-de-scripts-bash","title":"Exemples de scripts Bash","text":""},{"location":"_projects/_formation-bash/bash-chap13/#script-de-connexion-ssh","title":"Script de connexion SSH","text":"Bash<pre><code>#!/bin/bash\n# Connexion SSH \u00e0 un serveur\nssh admin@192.168.1.10 -p 2222\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap13/#script-de-generation-de-cles","title":"Script de g\u00e9n\u00e9ration de cl\u00e9s","text":"Bash<pre><code>#!/bin/bash\n# G\u00e9n\u00e9ration d'une paire de cl\u00e9s SSH\nssh-keygen -t rsa -b 4096 -C \"admin@serveur\"\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap13/#script-de-copie-de-cle-publique","title":"Script de copie de cl\u00e9 publique","text":"Bash<pre><code>#!/bin/bash\n# Copie de la cl\u00e9 publique sur le serveur\nssh-copy-id admin@192.168.1.10\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap13/#tableaux-recapitulatifs","title":"Tableaux r\u00e9capitulatifs","text":""},{"location":"_projects/_formation-bash/bash-chap13/#tableau-des-commandes-ssh","title":"Tableau des commandes SSH","text":"Commande Description <code>ssh user@host</code> Connexion SSH <code>ssh-keygen</code> G\u00e9n\u00e9ration de cl\u00e9s <code>ssh-copy-id</code> Copie de la cl\u00e9 publique <code>scp</code> Transfert de fichiers <code>sftp</code> Transfert de fichiers s\u00e9curis\u00e9"},{"location":"_projects/_formation-bash/bash-chap13/#tableau-des-options-de-securite_1","title":"Tableau des options de s\u00e9curit\u00e9","text":"Option Valeur recommand\u00e9e Description PermitRootLogin no Interdire l\u2019acc\u00e8s root PasswordAuthentication no D\u00e9sactiver l\u2019authentification par mot de passe PubkeyAuthentication yes Activer l\u2019authentification par cl\u00e9 Port 2222 Changer le port par d\u00e9faut AllowUsers admin user1 Limiter les utilisateurs autoris\u00e9s Protocol 2 Utiliser SSH-2 uniquement MaxAuthTries 3 Limiter les tentatives"},{"location":"_projects/_formation-bash/bash-chap13/#schemas-et-illustrations","title":"Sch\u00e9mas et illustrations","text":""},{"location":"_projects/_formation-bash/bash-chap13/#schema-de-connexion-ssh_1","title":"Sch\u00e9ma de connexion SSH","text":"Text Only<pre><code>+----------------+       +-----------------+\n|   Client SSH   | ----&gt; |   Serveur SSH   |\n| (ssh, PuTTY)   |       |   (sshd)        |\n+----------------+       +-----------------+\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap13/#schema-de-generation-et-dutilisation-des-cles_1","title":"Sch\u00e9ma de g\u00e9n\u00e9ration et d\u2019utilisation des cl\u00e9s","text":"Text Only<pre><code>+----------------+       +-----------------+\n|   Client SSH   | ----&gt; |   Serveur SSH   |\n|   (id_rsa)     |       |   (authorized_keys) |\n+----------------+       +-----------------+\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap13/#schema-de-developpement-distant_1","title":"Sch\u00e9ma de d\u00e9veloppement distant","text":"Text Only<pre><code>+----------------+       +-----------------+       +-----------------+\n|   VS Code      | ----&gt; |   SSH Client    | ----&gt; |   Serveur SSH   |\n|   (Local)      |       |   (ssh)         |       |   (sshd)        |\n+----------------+       +-----------------+       +-----------------+\n</code></pre>"},{"location":"_projects/_formation-bash/bash-chap13/#conclusion","title":"Conclusion","text":"<p>Le protocole SSH est un outil essentiel pour l\u2019administration syst\u00e8me et le d\u00e9veloppement distant. Une configuration s\u00e9curis\u00e9e, l\u2019utilisation de paires de cl\u00e9s et la protection des cl\u00e9s priv\u00e9es sont des pratiques fondamentales pour garantir la s\u00e9curit\u00e9 des connexions \u00e0 distance.</p>"},{"location":"_projects/_formation-bash/bash-chap13/#references","title":"R\u00e9f\u00e9rences","text":"<ul> <li>Cherry Servers - How to connect to a Linux server using SSH</li> <li>Hostman - How to install and configure SSH on an Ubuntu server</li> <li>Zenarmor - How to Configure and Enable SSH in Ubuntu</li> <li>GeeksforGeeks - Linux SSH Server (sshd) Configuration and Security</li> <li>SSH Academy - SSH command usage, options, and configuration in Linux</li> <li>Supporthost - Connexion SSH</li> <li>Guide Debianizzati - OpenSSH</li> <li>DigitalOcean - How to Use SSH to Connect to a Remote Server</li> <li>Introserv - Modification de la porte SSH ```</li> </ul> <p> Partager sur X</p>"},{"location":"_projects/_formation-docker/docker-chap01/","title":"Citations","text":"<ul> <li>https://www.dawan.fr/a-propos/la-societe/virtualisation-et-conteneur-les-avantages-cles-de-docker</li> <li>https://about.gitlab.com/fr-fr/blog/what-is-docker-comprehensive-guide/</li> <li>https://dyma.fr/blog/docker-et-ses-conteneurs/</li> <li>https://pole-innovation.reactic.io/nouvelles-technologies/avantages-docker</li> <li>https://www.innosys.fr/ssii-esn-paris/comprendre-docker-et-ses-avantages-pour-les-tpe-et-pme/</li> <li>https://www.redhat.com/fr/topics/containers/what-is-docker</li> <li>https://datascientest.com/docker-guide-complet</li> <li>https://blog.stephane-robert.info/docs/conteneurs/moteurs-conteneurs/docker/</li> <li>https://www.axopen.com/blog/2021/03/docker-presentation-concepts-cles/</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap01/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 274</li> <li>completion_tokens: 6238</li> <li>total_tokens: 6512</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.094, 'request_cost': 0.006, 'total_cost': 0.1}</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap01/#content","title":"Content","text":""},{"location":"_projects/_formation-docker/docker-chap01/#introduction-a-docker","title":"Introduction \u00e0 Docker \ud83d\udc33","text":"<p>Docker est une technologie r\u00e9volutionnaire qui a transform\u00e9 la mani\u00e8re dont les applications sont d\u00e9velopp\u00e9es, test\u00e9es et d\u00e9ploy\u00e9es. Cette introduction exhaustive explore les fondamentaux de Docker et les concepts essentiels pour d\u00e9buter un parcours de ma\u00eetrise de cette plateforme.</p>"},{"location":"_projects/_formation-docker/docker-chap01/#a-quoi-sert-docker","title":"\u00c0 quoi sert Docker ?","text":"<p>Docker r\u00e9sout un probl\u00e8me fondamental en informatique : l'incompatibilit\u00e9 entre environnements. Traditionnellement, les d\u00e9veloppeurs rencontraient des situations o\u00f9 une application fonctionnait parfaitement sur leur machine locale mais \u00e9chouait en production. Cette probl\u00e9matique, souvent appel\u00e9e \"\u00e7a marche sur ma machine\", dispara\u00eet compl\u00e8tement avec Docker.[1]</p> <p>Docker est une technologie de conteneurisation qui empaquette le code d'application, ses d\u00e9pendances et ses biblioth\u00e8ques dans une unit\u00e9 standardis\u00e9e appel\u00e9e conteneur.[2] Cette approche offre plusieurs b\u00e9n\u00e9fices majeurs :</p> <p>Coh\u00e9rence entre les environnements : Une application conteneuris\u00e9e fonctionne de mani\u00e8re identique sur le poste de d\u00e9veloppement, les serveurs de test, et les infrastructures de production, \u00e9liminant ainsi les divergences d'environnement.[5]</p> <p>Isolation des applications : Chaque conteneur dispose de son propre espace d'ex\u00e9cution, \u00e9vitant les conflits entre diff\u00e9rentes versions de biblioth\u00e8ques ou de d\u00e9pendances. Si une application dans un conteneur rencontre des probl\u00e8mes, elle n'affectera pas les autres applications.[2][5]</p> <p>Efficacit\u00e9 des ressources : Contrairement aux machines virtuelles traditionnelles qui n\u00e9cessitent un syst\u00e8me d'exploitation complet, Docker utilise une approche plus l\u00e9g\u00e8re. Les conteneurs partagent le noyau de l'h\u00f4te tout en maintenant une isolation compl\u00e8te, r\u00e9duisant ainsi l'empreinte m\u00e9moire et CPU.[2][3]</p> <p>D\u00e9ploiement simplifi\u00e9 : L'empaquetage de l'application et de ses d\u00e9pendances dans un conteneur unique simplifie consid\u00e9rablement les processus de d\u00e9ploiement et r\u00e9duit les risques d'erreur.[2]</p> <p>Scalabilit\u00e9 rapide : Dupliquer un conteneur est extr\u00eamement simple, permettant une mont\u00e9e en charge horizontale ais\u00e9e selon les besoins applicatifs.[4]</p>"},{"location":"_projects/_formation-docker/docker-chap01/#comment-fonctionne-docker","title":"Comment fonctionne Docker","text":""},{"location":"_projects/_formation-docker/docker-chap01/#les-principes-fondamentaux","title":"Les principes fondamentaux","text":"<p>Docker r\u00e9volutionne la virtualisation en exploitant les capacit\u00e9s natives du noyau Linux pour cr\u00e9er des environnements d'ex\u00e9cution l\u00e9gers et isol\u00e9s.[2] Contrairement \u00e0 la virtualisation traditionnelle qui cr\u00e9e une simulation compl\u00e8te d'un ordinateur physique, Docker utilise une approche diff\u00e9rente bas\u00e9e sur la conteneurisation.</p>"},{"location":"_projects/_formation-docker/docker-chap01/#conteneurs-vs-machines-virtuelles","title":"Conteneurs vs Machines virtuelles","text":"<p>Pour comprendre le fonctionnement de Docker, il est essentiel de saisir les diff\u00e9rences entre conteneurs et machines virtuelles :</p> Aspect Machines Virtuelles Conteneurs Docker Syst\u00e8me d'exploitation Chacune a son propre OS complet Partagent le noyau de l'h\u00f4te Taille Plusieurs gigaoctets (OS + application) Quelques m\u00e9gaoctets (application seule) Temps de d\u00e9marrage Plusieurs minutes Quelques millisecondes Performance Surcharge d'\u00e9mulation mat\u00e9rielle Performance quasi-native Densit\u00e9 Quelques VMs par serveur Plusieurs conteneurs par serveur Isolation Compl\u00e8te au niveau mat\u00e9riel Isolation au niveau processus"},{"location":"_projects/_formation-docker/docker-chap01/#architecture-de-docker","title":"Architecture de Docker","text":"<p>Docker fonctionne selon une architecture client-serveur :</p> <ul> <li>Le Client Docker : Interface en ligne de commande (CLI) ou API graphique avec laquelle l'utilisateur interagit</li> <li>Le Daemon Docker : Service serveur ex\u00e9cut\u00e9 en arri\u00e8re-plan qui g\u00e8re les conteneurs</li> <li>Les Images Docker : Blueprints ou mod\u00e8les contenant toutes les d\u00e9pendances et configurations n\u00e9cessaires</li> <li>Les Conteneurs : Instances en ex\u00e9cution des images</li> <li>Les Registres : D\u00e9p\u00f4ts centralis\u00e9s (comme Docker Hub) o\u00f9 sont stock\u00e9es les images</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap01/#mecanisme-disolation","title":"M\u00e9canisme d'isolation","text":"<p>Docker utilise plusieurs technologies Linux pour cr\u00e9er cette isolation :[2]</p> <p>Espaces de noms (Namespaces) : Isolent les ressources syst\u00e8me pour chaque conteneur (processus, r\u00e9seau, syst\u00e8me de fichiers, etc.)</p> <p>Groupes de contr\u00f4le (cgroups) : Limitent et g\u00e8rent les ressources (CPU, m\u00e9moire) disponibles pour chaque conteneur</p> <p>Syst\u00e8me de fichiers en couches : Utilise un syst\u00e8me de fichiers Union qui empile des couches, permettant l'efficacit\u00e9 du stockage et la r\u00e9utilisabilit\u00e9</p>"},{"location":"_projects/_formation-docker/docker-chap01/#le-systeme-de-couches","title":"Le syst\u00e8me de couches","text":"<p>Docker utilise un m\u00e9canisme intelligent de mise en cache des couches.[8] Chaque instruction dans un Dockerfile cr\u00e9e une couche. Si une couche n'a pas chang\u00e9 depuis la derni\u00e8re construction, Docker r\u00e9utilise cette couche \u00e0 partir du cache, acc\u00e9l\u00e9rant consid\u00e9rablement le processus de construction.</p> <p>Exemple de structure en couches :</p> Text Only<pre><code>Couche de base : Image Ubuntu\n   \u2193\nCouche 1 : Installation de Node.js\n   \u2193\nCouche 2 : Copie du code source\n   \u2193\nCouche 3 : Installation des d\u00e9pendances npm\n   \u2193\nCouche 4 : Configuration des ports\n   \u2193\nConteneur final : Ensemble des couches pr\u00e9c\u00e9dentes\n</code></pre> <p>Cette architecture en couches offre plusieurs avantages : r\u00e9duction de l'espace disque utilis\u00e9, acc\u00e9l\u00e9ration des reconstructions, et facilit\u00e9 du partage d'images.[1]</p>"},{"location":"_projects/_formation-docker/docker-chap01/#journal-des-modifications","title":"Journal des modifications","text":"<p>D\u00e8s lors qu'un utilisateur op\u00e8re des changements sur un fichier image Docker, une couche est cr\u00e9\u00e9e et un journal des modifications est mis \u00e0 jour, permettant un contr\u00f4le total des modifications r\u00e9alis\u00e9es. Cette fonction de superposition de couches permet aussi de facilement restaurer une version pr\u00e9c\u00e9dente.[1]</p>"},{"location":"_projects/_formation-docker/docker-chap01/#a-labordage","title":"\u00c0 l'abordage ! \ud83d\ude80","text":""},{"location":"_projects/_formation-docker/docker-chap01/#les-premiers-concepts-essentiels","title":"Les premiers concepts essentiels","text":"<p>Avant de plonger dans l'installation, il est important de comprendre les entit\u00e9s cl\u00e9s avec lesquelles on travaillera :</p> <p>Images Docker : Ce sont des mod\u00e8les immuables qui contiennent tout ce qui est n\u00e9cessaire pour ex\u00e9cuter une application : le code, les d\u00e9pendances, les variables d'environnement, les fichiers de configuration. Une image est cr\u00e9\u00e9e \u00e0 partir d'un fichier appel\u00e9 Dockerfile qui contient des instructions pour construire cette image.</p> <p>Conteneurs : Ce sont des instances en ex\u00e9cution d'une image. Si une image est un moule, un conteneur est l'objet cr\u00e9\u00e9 \u00e0 partir de ce moule. Plusieurs conteneurs peuvent \u00eatre lanc\u00e9s \u00e0 partir de la m\u00eame image.</p> <p>Dockerfile : C'est un fichier texte contenant une s\u00e9rie d'instructions pour construire une image Docker. Chaque instruction cr\u00e9e une couche dans l'image.</p> <p>Docker Hub : C'est le registre public par d\u00e9faut o\u00f9 sont stock\u00e9es les images Docker. On peut y t\u00e9l\u00e9charger des images pr\u00e9-construites ou y publier les siennes.</p> <p>docker-compose : Un outil qui permet de d\u00e9finir et d'ex\u00e9cuter plusieurs conteneurs Docker en m\u00eame temps, id\u00e9al pour les applications multi-conteneurs.[4]</p>"},{"location":"_projects/_formation-docker/docker-chap01/#le-flux-de-travail-typique","title":"Le flux de travail typique","text":"<p>Le cycle de vie Docker suit g\u00e9n\u00e9ralement ce processus :</p> <ol> <li>Cr\u00e9er : \u00c9crire un Dockerfile d\u00e9crivant l'application et ses d\u00e9pendances</li> <li>Construire : Ex\u00e9cuter la commande <code>docker build</code> pour cr\u00e9er une image \u00e0 partir du Dockerfile</li> <li>Tester : Lancer des conteneurs \u00e0 partir de l'image pour tester l'application</li> <li>Pousser : T\u00e9l\u00e9charger l'image vers un registre comme Docker Hub</li> <li>D\u00e9ployer : Lancer des conteneurs en production bas\u00e9s sur cette image</li> <li>Maintenir : G\u00e9rer les mises \u00e0 jour et les versions</li> </ol>"},{"location":"_projects/_formation-docker/docker-chap01/#installation-de-docker-sur-linux-et-macos","title":"Installation de Docker sur Linux et macOS","text":""},{"location":"_projects/_formation-docker/docker-chap01/#installation-sur-linux-ubuntudebian","title":"Installation sur Linux (Ubuntu/Debian)","text":"<p>Docker fonctionne nativement sur Linux, offrant la meilleure performance et la compl\u00e8te compatibilit\u00e9. Voici le processus d'installation complet :</p> <p>\u00c9tape 1 : Pr\u00e9requis syst\u00e8me</p> <p>Docker n\u00e9cessite une version r\u00e9cente du syst\u00e8me d'exploitation. Les versions recommand\u00e9es sont : - Ubuntu 20.04 LTS ou plus r\u00e9cent - Debian 10 ou plus r\u00e9cent</p> <p>\u00c9tape 2 : D\u00e9pendances pr\u00e9alables</p> <p>Avant l'installation, mettre \u00e0 jour les r\u00e9f\u00e9rences des paquets :</p> Bash<pre><code>sudo apt-get update\nsudo apt-get install -y apt-transport-https ca-certificates curl gnupg lsb-release\n</code></pre> <p>\u00c9tape 3 : Ajout du d\u00e9p\u00f4t Docker officiel</p> <p>Ajouter la cl\u00e9 GPG officielle de Docker :</p> Bash<pre><code>curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n</code></pre> <p>Ajouter le d\u00e9p\u00f4t Docker :</p> Bash<pre><code>echo \\\n  \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n</code></pre> <p>\u00c9tape 4 : Installation du moteur Docker</p> Bash<pre><code>sudo apt-get update\nsudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin\n</code></pre> <p>\u00c9tape 5 : Configuration des permissions utilisateur</p> <p>Par d\u00e9faut, les commandes Docker n\u00e9cessitent des droits administrateur. Pour \u00e9viter de taper <code>sudo</code> \u00e0 chaque fois :</p> Bash<pre><code># Cr\u00e9er le groupe docker (g\u00e9n\u00e9ralement d\u00e9j\u00e0 cr\u00e9\u00e9)\nsudo groupadd docker\n\n# Ajouter l'utilisateur courant au groupe docker\nsudo usermod -aG docker $USER\n\n# Activer les modifications du groupe\nnewgrp docker\n</code></pre> <p>\u00c9tape 6 : V\u00e9rification de l'installation</p> Bash<pre><code>docker --version\ndocker run hello-world\n</code></pre> <p>La deuxi\u00e8me commande t\u00e9l\u00e9charge et ex\u00e9cute un petit conteneur de test. Si tout fonctionne correctement, le message \"Hello from Docker!\" s'affiche.</p>"},{"location":"_projects/_formation-docker/docker-chap01/#installation-sur-macos","title":"Installation sur macOS","text":"<p>Sur macOS, Docker ne peut pas s'ex\u00e9cuter directement car le moteur Docker n\u00e9cessite Linux. Cependant, Docker Desktop for Mac fournit une virtualisation transparente de Linux.</p> <p>\u00c9tape 1 : Pr\u00e9requis syst\u00e8me</p> <ul> <li>macOS 11 (Big Sur) ou plus r\u00e9cent</li> <li>Processeur Apple Silicon (M1, M2, etc.) ou Intel</li> <li>Au moins 4 GB de RAM allou\u00e9 \u00e0 Docker</li> <li>VirtualizationFramework activ\u00e9 (par d\u00e9faut sur tous les Macs modernes)</li> </ul> <p>\u00c9tape 2 : T\u00e9l\u00e9chargement et installation</p> <p>Deux versions sont disponibles selon le type de processeur :</p> <p>Pour les Macs avec processeur Apple Silicon (M1, M2, M3) : Bash<pre><code># T\u00e9l\u00e9charger Docker Desktop (version ARM64)\n# Puis double-cliquer sur le fichier DMG t\u00e9l\u00e9charg\u00e9\n# L'application Docker.app appara\u00eet dans le dossier Applications\n</code></pre></p> <p>Pour les Macs avec processeur Intel : Bash<pre><code># T\u00e9l\u00e9charger Docker Desktop (version x86_64)\n# Puis double-cliquer sur le fichier DMG t\u00e9l\u00e9charg\u00e9\n# L'application Docker.app appara\u00eet dans le dossier Applications\n</code></pre></p> <p>\u00c9tape 3 : Configuration initiale</p> <p>Lancer Docker.app depuis le dossier Applications. Docker appara\u00eet dans la barre de menu macOS en haut \u00e0 droite. Une fen\u00eatre de bienvenue s'affiche avec les instructions d'initialisation.</p> <p>\u00c9tape 4 : Autoriser les permissions</p> <p>Docker demande le mot de passe administrateur pour installer les composants requis. Le fournir comme demand\u00e9.</p> <p>\u00c9tape 5 : Configuration des ressources</p> <p>Acc\u00e9der \u00e0 Docker Desktop \u2192 Preferences \u2192 Resources pour configurer :</p> <ul> <li>CPUs : Nombre de c\u0153urs CPU allou\u00e9s (recommand\u00e9 : au moins 2)</li> <li>Memory : Quantit\u00e9 de RAM allou\u00e9e (recommand\u00e9 : au moins 4 GB)</li> <li>Disk Image Size : Taille maximale du stockage pour les images et conteneurs</li> <li>Swap : M\u00e9moire d'\u00e9change disponible</li> </ul> <p>\u00c9tape 6 : V\u00e9rification de l'installation</p> <p>Ouvrir Terminal et ex\u00e9cuter :</p> Bash<pre><code>docker --version\ndocker run hello-world\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap01/#configuration-commune-linux-et-macos","title":"Configuration commune (Linux et macOS)","text":"<p>Apr\u00e8s l'installation, quelques configurations suppl\u00e9mentaires sont recommand\u00e9es :</p> <p>Activer le d\u00e9marrage automatique de Docker au d\u00e9marrage du syst\u00e8me</p> <p>Sur macOS, Docker Desktop s'active automatiquement. Sur Linux :</p> Bash<pre><code>sudo systemctl enable docker\nsudo systemctl start docker\n</code></pre> <p>Configurer Docker daemon</p> <p>Cr\u00e9er ou \u00e9diter le fichier de configuration Docker :</p> Bash<pre><code>sudo nano /etc/docker/daemon.json\n</code></pre> <p>Exemple de configuration basique :</p> JSON<pre><code>{\n  \"debug\": false,\n  \"storage-driver\": \"overlay2\",\n  \"log-driver\": \"json-file\",\n  \"log-opts\": {\n    \"max-size\": \"10m\",\n    \"max-file\": \"3\"\n  }\n}\n</code></pre> <p>Red\u00e9marrer le daemon :</p> Bash<pre><code>sudo systemctl restart docker\n</code></pre> <p>V\u00e9rifier la sant\u00e9 de l'installation</p> Bash<pre><code>docker system info\ndocker ps\ndocker images\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap01/#lecosysteme-docker","title":"L'\u00e9cosyst\u00e8me Docker \ud83c\udf0d","text":"<p>Docker n'existe pas en isolation. Il s'inscrit dans un \u00e9cosyst\u00e8me riche d'outils et de services qui \u00e9tendent ses capacit\u00e9s.</p>"},{"location":"_projects/_formation-docker/docker-chap01/#docker-hub","title":"Docker Hub","text":"<p>Docker Hub est le registre public par d\u00e9faut et le c\u0153ur de l'\u00e9cosyst\u00e8me Docker. C'est une plateforme centralis\u00e9e o\u00f9 des millions d'images Docker pr\u00e9-construites sont stock\u00e9es et mises \u00e0 disposition.</p> <p>Fonctionnalit\u00e9s principales :</p> <ul> <li>D\u00e9p\u00f4t d'images publiques : Acc\u00e8s \u00e0 une immense biblioth\u00e8que d'images officielles et de la communaut\u00e9</li> <li>D\u00e9p\u00f4ts priv\u00e9s : Possibilit\u00e9 de cr\u00e9er des d\u00e9p\u00f4ts priv\u00e9s pour stocker ses propres images</li> <li>Webhooks : Notifications automatiques lors de mises \u00e0 jour</li> <li>Int\u00e9gration CI/CD : Automatisation des constructions d'images</li> </ul> <p>Exemples d'images officielles populaires :</p> <ul> <li><code>ubuntu</code> : Syst\u00e8me d'exploitation Ubuntu</li> <li><code>node</code> : Environnement Node.js</li> <li><code>python</code> : Environnement Python</li> <li><code>nginx</code> : Serveur web Nginx</li> <li><code>mysql</code> : Base de donn\u00e9es MySQL</li> <li><code>postgres</code> : Base de donn\u00e9es PostgreSQL</li> <li><code>redis</code> : Cache en m\u00e9moire Redis</li> </ul> <p>Utilisation basique :</p> Bash<pre><code># Rechercher une image\ndocker search node\n\n# T\u00e9l\u00e9charger une image\ndocker pull node:18\n\n# Voir les images locales\ndocker images\n\n# Identifier une image\ndocker inspect node:18\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap01/#docker-compose","title":"Docker Compose","text":"<p>Docker Compose est un outil qui permet de d\u00e9finir et d'ex\u00e9cuter des applications multi-conteneurs.[4] Au lieu de lancer chaque conteneur individuellement avec des commandes Docker complexes, on \u00e9crit une configuration YAML unique.</p> <p>Fichier docker-compose.yml typique :</p> YAML<pre><code>version: '3.8'\n\nservices:\n  web:\n    image: node:18\n    container_name: mon-app\n    ports:\n      - \"3000:3000\"\n    environment:\n      - NODE_ENV=production\n    volumes:\n      - ./app:/app\n    working_dir: /app\n    command: npm start\n    depends_on:\n      - db\n\n  db:\n    image: postgres:14\n    container_name: ma-base-donnees\n    environment:\n      POSTGRES_USER: utilisateur\n      POSTGRES_PASSWORD: motdepasse\n      POSTGRES_DB: mabase\n    volumes:\n      - ./data:/var/lib/postgresql/data\n    ports:\n      - \"5432:5432\"\n\n  cache:\n    image: redis:7\n    container_name: mon-cache\n    ports:\n      - \"6379:6379\"\n</code></pre> <p>Commandes principales :</p> Bash<pre><code># D\u00e9marrer tous les services\ndocker-compose up -d\n\n# Arr\u00eater les services\ndocker-compose down\n\n# Voir les logs\ndocker-compose logs -f\n\n# Ex\u00e9cuter une commande dans un service\ndocker-compose exec web npm test\n\n# Reconstruire les images\ndocker-compose up -d --build\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap01/#registres-docker-alternatifs","title":"Registres Docker alternatifs","text":"<p>Bien que Docker Hub soit le registre par d\u00e9faut, d'autres options existent :</p> <p>GitHub Container Registry : Int\u00e9gration native avec GitHub pour stocker et g\u00e9rer les images Docker.</p> <p>GitLab Container Registry : Solution compl\u00e8te de DevSecOps avec registre d'images int\u00e9gr\u00e9.[2]</p> <p>Amazon ECR (Elastic Container Registry) : Registre Docker g\u00e9r\u00e9 par AWS.</p> <p>Google Container Registry : Registre Google Cloud pour les images conteneurs.</p> <p>Azure Container Registry : Registre Microsoft pour les conteneurs.</p>"},{"location":"_projects/_formation-docker/docker-chap01/#docker-swarm","title":"Docker Swarm","text":"<p>Docker Swarm est une solution native d'orchestration de conteneurs int\u00e9gr\u00e9e directement dans Docker. Elle permet de g\u00e9rer un cluster de machines Docker et de d\u00e9ployer des services \u00e0 grande \u00e9chelle.</p> <p>Concepts cl\u00e9s :</p> <ul> <li>Cluster : Groupe de machines ex\u00e9cutant le daemon Docker</li> <li>N\u0153uds : Les machines individuelles du cluster</li> <li>Services : Description d\u00e9clarative du travail d\u00e9sir\u00e9</li> <li>T\u00e2ches : Instances d'un service ex\u00e9cut\u00e9es sur des n\u0153uds</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap01/#kubernetes","title":"Kubernetes","text":"<p>Bien qu'ext\u00e9rieur \u00e0 l'\u00e9cosyst\u00e8me Docker stricto sensu, Kubernetes est l'orchestrateur de conteneurs le plus populaire aujourd'hui. Docker Desktop inclut une option pour ex\u00e9cuter Kubernetes localement.</p> <p>Diff\u00e9rences cl\u00e9s entre Docker Swarm et Kubernetes :</p> Aspect Docker Swarm Kubernetes Complexit\u00e9 Simple Complexe mais puissant Courbe d'apprentissage Douce Abrupte Scalabilit\u00e9 Bonne Excellente \u00c9cosyst\u00e8me Petit Massif Production Moyennes entreprises Grandes organisations"},{"location":"_projects/_formation-docker/docker-chap01/#outils-de-gestion-et-monitoring","title":"Outils de gestion et monitoring","text":"<p>L'\u00e9cosyst\u00e8me Docker propose plusieurs outils pour g\u00e9rer et monitorer les conteneurs :</p> <p>Portainer : Interface web pour g\u00e9rer les conteneurs et les images sans ligne de commande.</p> <p>Rancher : Plateforme compl\u00e8te de gestion de conteneurs et Kubernetes.</p> <p>Docker Desktop Dashboard : Interface visuelle int\u00e9gr\u00e9e \u00e0 Docker Desktop pour macOS et Windows.</p> <p>Prometheus et Grafana : Stack de monitoring pour collecter les m\u00e9triques et visualiser les donn\u00e9es.</p>"},{"location":"_projects/_formation-docker/docker-chap01/#installation-de-docker-sur-windows","title":"Installation de Docker sur Windows \ud83e\ude9f","text":"<p>Docker sur Windows pr\u00e9sente un d\u00e9fi unique : le moteur Docker n\u00e9cessite une structure Linux, alors que Windows est un syst\u00e8me d'exploitation diff\u00e9rent. Deux solutions existent pour r\u00e9soudre ce probl\u00e8me.</p>"},{"location":"_projects/_formation-docker/docker-chap01/#docker-desktop-for-windows","title":"Docker Desktop for Windows","text":"<p>C'est la solution la plus simple et la plus recommand\u00e9e pour la plupart des utilisateurs Windows.</p> <p>Pr\u00e9requis syst\u00e8me</p> <ul> <li>Syst\u00e8me d'exploitation : Windows 10 (version 2004 ou plus) ou Windows 11</li> <li>Processeur : Avec support de la virtualisation (Intel ou AMD)</li> <li>RAM : Minimum 4 GB (8 GB recommand\u00e9)</li> <li>Disque : Au moins 10 GB d'espace libre</li> <li>Virtualisation : Hyper-V ou WSL2 (Windows Subsystem for Linux 2) activ\u00e9</li> </ul> <p>V\u00e9rifier si Hyper-V est activ\u00e9</p> PowerShell<pre><code># Ouvrir PowerShell en administrateur\nGet-WindowsOptionalFeature -Online | Where-Object {$_.FeatureName -eq \"Microsoft-Hyper-V\"}\n</code></pre> <p>Si Hyper-V n'est pas activ\u00e9, l'ex\u00e9cuter :</p> PowerShell<pre><code>Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Hyper-V -All\n</code></pre> <p>\u00c9tape 1 : T\u00e9l\u00e9chargement</p> <p>T\u00e9l\u00e9charger Docker Desktop for Windows depuis le site officiel Docker. Deux versions sont disponibles :</p> <ul> <li>Docker Desktop Installer.exe (pour installation classique)</li> <li>Docker Desktop Portable (version portable, sans installation)</li> </ul> <p>\u00c9tape 2 : Installation</p> <p>Double-cliquer sur l'installateur. L'assistant d'installation guide \u00e0 travers les \u00e9tapes :</p> <ol> <li>Accepter la licence</li> <li>Confirmer le chemin d'installation</li> <li>S\u00e9lectionner les options d'int\u00e9gration shell</li> <li>Choisir entre Hyper-V et WSL2 comme backend</li> </ol> <p>Recommandation : WSL2 est g\u00e9n\u00e9ralement recommand\u00e9 pour de meilleures performances sur Windows 10 et 11 modernes.</p> <p>\u00c9tape 3 : Red\u00e9marrage obligatoire</p> <p>Docker demande un red\u00e9marrage pour activer les composants du syst\u00e8me. Effectuer le red\u00e9marrage.</p> <p>\u00c9tape 4 : Premi\u00e8re ex\u00e9cution</p> <p>Apr\u00e8s red\u00e9marrage, lancer Docker Desktop depuis le menu D\u00e9marrer. L'application s'ajoute \u00e0 la barre d'\u00e9tat syst\u00e8me. La premi\u00e8re ex\u00e9cution prend quelques minutes pour initialiser les composants.</p> <p>\u00c9tape 5 : V\u00e9rification</p> <p>Ouvrir PowerShell ou CMD et v\u00e9rifier l'installation :</p> PowerShell<pre><code>docker --version\ndocker run hello-world\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap01/#wsl-2-vs-hyper-v","title":"WSL 2 vs Hyper-V","text":"<p>WSL 2 (Windows Subsystem for Linux 2) : - Performance sup\u00e9rieure sur Windows - Consommation m\u00e9moire plus efficace - Recommand\u00e9 pour la plupart des cas d'usage - Fourni avec Windows 10 version 2004 et ult\u00e9rieur</p> <p>Configuration WSL 2 :</p> PowerShell<pre><code># V\u00e9rifier la version de WSL\nwsl --list --verbose\n\n# D\u00e9finir WSL 2 comme version par d\u00e9faut\nwsl --set-default-version 2\n\n# Installer ou mettre \u00e0 jour une distribution Linux\nwsl --install -d Ubuntu\n</code></pre> <p>Hyper-V : - Virtualisation compl\u00e8te - Isolation compl\u00e8te de Linux - Peut \u00eatre moins efficace en ressources - Compatible avec les \u00e9ditions Professional et ult\u00e9rieures de Windows</p> <p>S\u00e9lectionner le backend dans Docker Desktop \u2192 Settings \u2192 General.</p>"},{"location":"_projects/_formation-docker/docker-chap01/#configuration-avancee-de-docker-desktop-on-windows","title":"Configuration avanc\u00e9e de Docker Desktop on Windows","text":"<p>Allocation de ressources</p> <p>Acc\u00e9der \u00e0 Docker Desktop \u2192 Settings \u2192 Resources pour configurer :</p> <ul> <li>CPUs : Nombre de c\u0153urs (recommand\u00e9 : 4+)</li> <li>Memory : RAM allou\u00e9e (recommand\u00e9 : 6-8 GB)</li> <li>Disk image size : Taille du stockage virtuel</li> <li>Swap : M\u00e9moire de swap</li> </ul> <p>Int\u00e9gration VSCode</p> <p>Docker s'int\u00e8gre parfaitement avec Visual Studio Code. Installer l'extension \"Remote - Containers\" pour d\u00e9velopper directement dans des conteneurs.</p> <p>Cr\u00e9er un fichier <code>.devcontainer/devcontainer.json</code> :</p> JSON<pre><code>{\n  \"name\": \"Mon environnement Dev\",\n  \"image\": \"mcr.microsoft.com/devcontainers/base:ubuntu\",\n  \"features\": {\n    \"ghcr.io/devcontainers/features/docker-in-docker:2\": {}\n  },\n  \"customizations\": {\n    \"vscode\": {\n      \"extensions\": [\n        \"ms-vscode.vscode-typescript-next\",\n        \"dbaeumer.vscode-eslint\"\n      ]\n    }\n  }\n}\n</code></pre> <p>Gestion des volumes partag\u00e9s</p> <p>Pour partager des dossiers Windows avec les conteneurs :</p> PowerShell<pre><code># Dans Docker Desktop \u2192 Settings \u2192 Resources \u2192 File Sharing\n# Ajouter les chemins \u00e0 partager\n\n# Exemple d'utilisation\ndocker run -v C:\\Users\\nom\\projets:/data image:latest\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap01/#installation-via-wsl-2-avec-docker-engine","title":"Installation via WSL 2 avec Docker Engine","text":"<p>Une approche alternative consiste \u00e0 installer Docker Engine directement dans WSL 2, sans Docker Desktop.</p> <p>\u00c9tape 1 : Installer WSL 2</p> PowerShell<pre><code>wsl --install -d Ubuntu\n</code></pre> <p>\u00c9tape 2 : Acc\u00e9der \u00e0 WSL 2</p> PowerShell<pre><code>wsl\n</code></pre> <p>\u00c9tape 3 : Installer Docker dans WSL 2</p> Bash<pre><code># Mettre \u00e0 jour les paquets\nsudo apt-get update\n\n# Installer les d\u00e9pendances\nsudo apt-get install -y docker.io docker-compose\n\n# Ajouter l'utilisateur au groupe docker\nsudo usermod -aG docker $USER\n\n# Red\u00e9marrer WSL\nexit\nwsl\n</code></pre> <p>\u00c9tape 4 : V\u00e9rifier l'installation</p> Bash<pre><code>docker --version\ndocker run hello-world\n</code></pre> <p>Avantages de cette approche : - Consommation m\u00e9moire plus l\u00e9g\u00e8re - Pas besoin de Docker Desktop - Performances d'ex\u00e9cution natives</p> <p>Inconv\u00e9nients : - Gestion manuelle des ressources - D\u00e9marrage manuel du daemon Docker n\u00e9cessaire - Moins de support pour l'interface graphique</p>"},{"location":"_projects/_formation-docker/docker-chap01/#depannage-commun-sur-windows","title":"D\u00e9pannage commun sur Windows","text":"<p>Docker daemon ne d\u00e9marre pas</p> PowerShell<pre><code># V\u00e9rifier l'\u00e9tat du service Docker\nGet-Service Docker\n\n# Red\u00e9marrer le service\nRestart-Service Docker\n\n# Consulter les logs\nGet-EventLog -LogName Application -Source Docker | Select-Object TimeGenerated, Message\n</code></pre> <p>Probl\u00e8mes de performance</p> <ul> <li>Augmenter la RAM allou\u00e9e \u00e0 Docker Desktop</li> <li>Activer WSL 2 si Hyper-V est utilis\u00e9</li> <li>V\u00e9rifier les antivirus qui pourraient ralentir les op\u00e9rations disque</li> <li>Nettoyer les images et conteneurs inutilis\u00e9s</li> </ul> <p>Erreur \"Cannot connect to Docker daemon\"</p> PowerShell<pre><code># Red\u00e9marrer Docker Desktop\n# Ou relancer le service\nRestart-Service Docker\n\n# R\u00e9initialiser Docker\ndocker system reset\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap01/#resume-du-parcours-dapprentissage","title":"R\u00e9sum\u00e9 du parcours d'apprentissage","text":"<p>Le parcours d'introduction \u00e0 Docker s'articule autour de plusieurs \u00e9tapes interconnect\u00e9es :</p> <p>Phase 1 : Compr\u00e9hension conceptuelle : L'apprenant d\u00e9couvre le probl\u00e8me que Docker r\u00e9sout et saisit les avantages fondamentaux qu'il offre. Cette phase \u00e9tablit la motivation pour l'apprentissage.</p> <p>Phase 2 : M\u00e9canismes techniques : L'apprenant apprend comment Docker fonctionne r\u00e9ellement, incluant les concepts de conteneurs, d'images, de couches et d'isolation. Cette compr\u00e9hension technique cr\u00e9e la base pour manipuler efficacement Docker.</p> <p>Phase 3 : Installation pratique : Adapt\u00e9 au syst\u00e8me d'exploitation sp\u00e9cifique de l'apprenant, ce module guide l'installation \u00e9tape par \u00e9tape. Le choix du syst\u00e8me d'exploitation d\u00e9termine le chemin sp\u00e9cifique : Linux offre la solution la plus directe, macOS n\u00e9cessite une virtualisation transparente, et Windows pr\u00e9sente les d\u00e9fis les plus complexes mais des solutions \u00e9l\u00e9gantes.</p> <p>Phase 4 : \u00c9cosyst\u00e8me et outils : L'apprenant d\u00e9couvre les outils et services qui compl\u00e8tent Docker, particuli\u00e8rement Docker Hub pour la distribution d'images et Docker Compose pour les applications multi-conteneurs.</p> <p>Phase 5 : Premiers pas pratiques : Avec Docker install\u00e9 et configur\u00e9, l'apprenant peut commencer \u00e0 t\u00e9l\u00e9charger des images, ex\u00e9cuter des conteneurs simples et comprendre le flux de travail de base.</p> <p>Cette progression logique du conceptuel au pratique, du simple au complexe, pr\u00e9pare solidement l'apprenant pour les modules suivants qui couvriront la cr\u00e9ation d'images Docker personnalis\u00e9es, la gestion de conteneurs avanc\u00e9e et l'orchestration.[1][2][3][4][5][6][7]</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-docker/docker-chap02/","title":"Citations","text":"<ul> <li>https://blog.alphorm.com/cycle-de-vie-des-conteneurs-docker</li> <li>https://syslearn.fr/docker-ses-caracteristiques/</li> <li>https://blog.stephane-robert.info/docs/conteneurs/moteurs-conteneurs/docker/</li> <li>https://labex.io/fr/tutorials/docker-how-to-track-docker-container-status-418069</li> <li>https://www.datacamp.com/fr/blog/docker-interview-questions</li> <li>https://www.hostinger.com/fr/tutoriels/tutoriel-docker</li> <li>https://learn.microsoft.com/fr-fr/dotnet/architecture/microservices/container-docker-introduction/</li> <li>https://sysblog.informatique.univ-paris-diderot.fr/2019/03/08/docker-facile-en-7-etapes/</li> <li>https://scalastic.io/cka-certification-day-1-docker/</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap02/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 318</li> <li>completion_tokens: 8073</li> <li>total_tokens: 8391</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.121, 'request_cost': 0.006, 'total_cost': 0.128}</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap02/#content","title":"Content","text":""},{"location":"_projects/_formation-docker/docker-chap02/#chapitre-2-decouvrir-les-bases-de-docker","title":"Chapitre 2 : D\u00e9couvrir les Bases de Docker","text":""},{"location":"_projects/_formation-docker/docker-chap02/#premier-conteneur-et-lancement-pratique","title":"Premier Conteneur et Lancement Pratique","text":""},{"location":"_projects/_formation-docker/docker-chap02/#comprendre-les-fondamentaux","title":"Comprendre les Fondamentaux","text":"<p>Docker fonctionne selon un mod\u00e8le client-serveur o\u00f9 le Daemon Docker (dockerd) repr\u00e9sente le service central g\u00e9rant les images, les conteneurs et leur cycle de vie[9]. Lorsqu'une personne ex\u00e9cute une commande Docker, elle communique avec ce daemon qui traite les requ\u00eates du client.</p> <p>Un conteneur Docker est une instance ex\u00e9cutable d'une image Docker[2]. Lorsqu'une image est ex\u00e9cut\u00e9e, elle se transforme en conteneur, cr\u00e9ant un environnement isol\u00e9 avec son propre syst\u00e8me de fichiers, ses propres processus et son propre r\u00e9seau, bien que partageant le noyau du syst\u00e8me d'exploitation h\u00f4te[2].</p>"},{"location":"_projects/_formation-docker/docker-chap02/#lancer-un-premiers-conteneurs","title":"Lancer un Premiers Conteneurs","text":"<p>La commande de base pour lancer un conteneur est la suivante :</p> Bash<pre><code>docker run alpine\n</code></pre> <p>Cette commande t\u00e9l\u00e9charge l'image alpine et lance un conteneur bas\u00e9 sur cette image[1]. Pour v\u00e9rifier l'\u00e9tat du conteneur, la commande suivante affiche tous les conteneurs, y compris ceux arr\u00eat\u00e9s :</p> Bash<pre><code>docker ps -a\n</code></pre> <p>Le r\u00e9sultat montre que le conteneur a d\u00e9marr\u00e9 il y a quelques minutes avant de s'arr\u00eater de lui-m\u00eame[1]. Cette d\u00e9monstration illustre le cycle de vie \u00e9ph\u00e9m\u00e8re des conteneurs ex\u00e9cutant des t\u00e2ches ponctuelles.</p>"},{"location":"_projects/_formation-docker/docker-chap02/#le-flux-de-travail-docker-du-dockerfile-au-conteneur","title":"Le Flux de Travail Docker : Du Dockerfile au Conteneur","text":"<p>Le processus de travail avec Docker suit une s\u00e9quence logique[2] :</p> \u00c9tape Description Exemple Construction d'une image Le d\u00e9veloppeur \u00e9crit un Dockerfile sp\u00e9cifiant comment l'image doit \u00eatre construite (OS de base, d\u00e9pendances, code \u00e0 copier, commande au d\u00e9marrage) <code>FROM ubuntu:22.04</code> Cr\u00e9ation de l'image Le Dockerfile est compil\u00e9 en image Docker r\u00e9utilisable <code>docker build -t mon-app:1.0 .</code> Instanciation du conteneur L'image est ex\u00e9cut\u00e9e, cr\u00e9ant un conteneur isol\u00e9 <code>docker run mon-app:1.0</code> Couches d'images Les images Docker sont construites en couches empil\u00e9es, chaque instruction du Dockerfile cr\u00e9ant une nouvelle couche en lecture seule Architecture layered filesystem"},{"location":"_projects/_formation-docker/docker-chap02/#le-cycle-de-vie-dun-conteneur","title":"Le Cycle de Vie d'un Conteneur","text":""},{"location":"_projects/_formation-docker/docker-chap02/#les-etats-dun-conteneur","title":"Les \u00c9tats d'un Conteneur","text":"<p>Un conteneur Docker passe par un cycle de vie bien d\u00e9fini qui d\u00e9termine les \u00e9tats dans lesquels le conteneur peut se trouver et comment il fonctionne dans ces \u00e9tats[5]. Comprendre ce cycle est fondamental pour g\u00e9rer efficacement les applications conteneuris\u00e9es.</p>"},{"location":"_projects/_formation-docker/docker-chap02/#cycle-de-vie-de-base-vs-cycle-de-vie-avance","title":"Cycle de Vie de Base vs Cycle de Vie Avanc\u00e9","text":"<p>Le cycle de vie des conteneurs se divise en deux mod\u00e8les distincts selon l'utilisation pr\u00e9vue[1] :</p> <p>Cycle de Vie de Base</p> <p>Le cycle de vie de base est adapt\u00e9 aux t\u00e2ches temporaires et ponctuelles[1]. Dans ce mod\u00e8le, les conteneurs sont des artisans temporaires, d\u00e9di\u00e9s \u00e0 des missions sp\u00e9cifiques. Que ce soit pour des compilations rapides, des traitements de donn\u00e9es ou des op\u00e9rations de courte dur\u00e9e, le cycle de vie de base offre une solution agile et efficace.</p> <p>Le processus fonctionne comme suit :</p> <ul> <li>Lancement et ex\u00e9cution : \u00c0 partir d'une image Docker, le conteneur \u00e9merge, pr\u00eat \u00e0 accomplir sa mission assign\u00e9e[1]</li> <li>Ex\u00e9cution de la t\u00e2che : Une fois le processus ou la t\u00e2che termin\u00e9(e), le conteneur se retire aussi discr\u00e8tement qu'il est apparu[1]</li> <li>Arr\u00eat automatique : Le conteneur s'arr\u00eate en seulement quelques secondes apr\u00e8s la fin de sa mission, m\u00eame si aucune action n'a \u00e9t\u00e9 entreprise depuis le lancement[1]</li> </ul> <p>Cycle de Vie Avanc\u00e9</p> <p>Le cycle de vie avanc\u00e9 est con\u00e7u pour les applications en mode service, offrant une disponibilit\u00e9 continue[1]. Dans ce royaume, les conteneurs deviennent des gardiens fid\u00e8les, fournissant des services continus et accessibles \u00e0 tout moment.</p> <p>Les caract\u00e9ristiques principales incluent :</p> <ul> <li>Persistance : Les conteneurs continuent de fonctionner pour r\u00e9pondre aux demandes des clients[1]</li> <li>Accessibilit\u00e9 externe : Les conteneurs du cycle de vie avanc\u00e9 sont souvent accessibles par des clients externes, ce qui en fait des \u00e9l\u00e9ments essentiels pour les applications distribu\u00e9es[1]</li> <li>Infrastructure robuste : Cette approche offre une infrastructure robuste pour r\u00e9pondre aux demandes les plus exigeantes, qu'il s'agisse d'applications Web, de services back-end ou de bases de donn\u00e9es[1]</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap02/#tableau-comparatif-des-deux-cycles-de-vie","title":"Tableau Comparatif des Deux Cycles de Vie","text":"Aspect Cycle de Vie de Base Cycle de Vie Avanc\u00e9 Utilisation pr\u00e9vue T\u00e2ches temporaires et ponctuelles Applications en mode service Persistance \u00c9ph\u00e9m\u00e8re, se termine apr\u00e8s la t\u00e2che Persistant, continue de fonctionner Dur\u00e9e de vie Quelques secondes \u00e0 quelques minutes Ind\u00e9fini, selon les besoins Accessibilit\u00e9 G\u00e9n\u00e9ralement interne ou locale Accessible par des clients externes Cas d'usage Compilations, traitements de donn\u00e9es, op\u00e9rations ponctuelles Applications Web, services back-end, bases de donn\u00e9es Disponibilit\u00e9 Ponctuelle Continue"},{"location":"_projects/_formation-docker/docker-chap02/#etats-detailles-du-cycle-de-vie","title":"\u00c9tats D\u00e9taill\u00e9s du Cycle de Vie","text":"<p>Bien que les recherches ne d\u00e9taillent pas explicitement chaque \u00e9tat, le cycle de vie complet d'un conteneur inclut g\u00e9n\u00e9ralement :</p> <ol> <li>\u00c9tat Created : Le conteneur a \u00e9t\u00e9 cr\u00e9\u00e9 mais n'est pas encore en cours d'ex\u00e9cution</li> <li>\u00c9tat Running : Le conteneur ex\u00e9cute activement son processus principal</li> <li>\u00c9tat Paused : Le conteneur est gel\u00e9, tous les processus sont suspendus</li> <li>\u00c9tat Stopped : Le conteneur s'est arr\u00eat\u00e9 de mani\u00e8re propre</li> <li>\u00c9tat Restarting : Le conteneur red\u00e9marre apr\u00e8s un arr\u00eat</li> </ol>"},{"location":"_projects/_formation-docker/docker-chap02/#obtenir-de-laide-lister-et-supprimer-des-images-et-des-conteneurs","title":"Obtenir de l'Aide, Lister et Supprimer des Images et des Conteneurs","text":""},{"location":"_projects/_formation-docker/docker-chap02/#obtenir-de-laide-avec-docker","title":"Obtenir de l'Aide avec Docker","text":"<p>Docker offre plusieurs fa\u00e7ons d'acc\u00e9der \u00e0 la documentation et \u00e0 l'aide directement depuis la ligne de commande. La commande la plus fondamentale est :</p> Bash<pre><code>docker help\n</code></pre> <p>Cette commande affiche la liste compl\u00e8te des commandes disponibles et leurs descriptions. Pour obtenir de l'aide sur une commande sp\u00e9cifique, l'utilisateur peut consulter :</p> Bash<pre><code>docker [COMMANDE] --help\n</code></pre> <p>Par exemple, pour obtenir de l'aide sur la commande <code>run</code> :</p> Bash<pre><code>docker run --help\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap02/#lister-les-images-docker","title":"Lister les Images Docker","text":"<p>Pour visualiser toutes les images disponibles localement sur le syst\u00e8me, la commande suivante est utilis\u00e9e :</p> Bash<pre><code>docker images\n</code></pre> <p>Cette commande retourne un tableau affichant :</p> Colonne Description REPOSITORY Le nom ou l'identifiant du d\u00e9p\u00f4t de l'image TAG L'\u00e9tiquette de version de l'image (par d\u00e9faut <code>latest</code>) IMAGE ID L'identifiant unique hexad\u00e9cimal de l'image CREATED La date et l'heure de cr\u00e9ation de l'image SIZE La taille de l'image en m\u00e9gaoctets ou gigaoctets <p>Pour obtenir plus de d\u00e9tails sur les images, notamment les couches, la commande suivante fournit des informations compl\u00e9mentaires :</p> Bash<pre><code>docker image inspect [IMAGE_ID_OU_NOM]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap02/#lister-les-conteneurs","title":"Lister les Conteneurs","text":"<p>Pour afficher tous les conteneurs en cours d'ex\u00e9cution, la commande basique est :</p> Bash<pre><code>docker ps\n</code></pre> <p>Pour inclure les conteneurs arr\u00eat\u00e9s ou en pause, l'option <code>-a</code> (all) est n\u00e9cessaire :</p> Bash<pre><code>docker ps -a\n</code></pre> <p>Le r\u00e9sultat affiche un tableau contenant les informations suivantes :</p> Colonne Signification CONTAINER ID L'identifiant unique du conteneur (hexad\u00e9cimal) IMAGE L'image \u00e0 partir de laquelle le conteneur a \u00e9t\u00e9 lanc\u00e9 COMMAND La commande ex\u00e9cut\u00e9e au d\u00e9marrage du conteneur CREATED La date et l'heure de cr\u00e9ation du conteneur STATUS L'\u00e9tat actuel (Running, Exited, Paused, etc.) PORTS Les ports mapp\u00e9s entre l'h\u00f4te et le conteneur NAMES Le nom assign\u00e9 au conteneur <p>Pour filtrer les conteneurs selon leur \u00e9tat :</p> Bash<pre><code>docker ps -f status=exited\ndocker ps -f status=running\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap02/#supprimer-des-images","title":"Supprimer des Images","text":"<p>Pour supprimer une image Docker locale, la commande utilis\u00e9e est :</p> Bash<pre><code>docker rmi [IMAGE_ID_OU_NOM]\n</code></pre> <p>Exemples pratiques :</p> Bash<pre><code># Supprimer une image par son ID\ndocker rmi a1b2c3d4e5f6\n\n# Supprimer une image par son nom et tag\ndocker rmi ubuntu:22.04\n\n# Forcer la suppression d'une image m\u00eame si elle est utilis\u00e9e\ndocker rmi -f ubuntu:22.04\n</code></pre> <p>Important : Une image ne peut \u00eatre supprim\u00e9e que si aucun conteneur ne l'utilise. Si des conteneurs la r\u00e9f\u00e9rencent, m\u00eame \u00e0 l'\u00e9tat arr\u00eat\u00e9, l'option <code>-f</code> (force) est n\u00e9cessaire pour forcer la suppression[3].</p>"},{"location":"_projects/_formation-docker/docker-chap02/#supprimer-des-conteneurs","title":"Supprimer des Conteneurs","text":"<p>Pour supprimer un conteneur, la commande <code>docker rm</code> est utilis\u00e9e[3]. Cette commande permet de g\u00e9rer le cycle de vie des conteneurs et de supprimer d\u00e9finitivement un conteneur qui n'est plus n\u00e9cessaire[3] :</p> Bash<pre><code>docker rm [CONTAINER_ID_OU_NOM]\n</code></pre> <p>Exemples pratiques :</p> Bash<pre><code># Supprimer un conteneur par son ID\ndocker rm a1b2c3d4e5f6\n\n# Supprimer un conteneur par son nom\ndocker rm mon-conteneur\n\n# Forcer la suppression d'un conteneur en cours d'ex\u00e9cution\ndocker rm -f mon-conteneur\n</code></pre> <p>Pour nettoyer automatiquement les conteneurs arr\u00eat\u00e9s, l'option <code>--rm</code> peut \u00eatre utilis\u00e9e lors du lancement :</p> Bash<pre><code>docker run --rm alpine\n</code></pre> <p>Cette approche garantit que le conteneur est automatiquement supprim\u00e9 une fois qu'il s'arr\u00eate[3].</p>"},{"location":"_projects/_formation-docker/docker-chap02/#gestion-de-lespace-disque-et-du-nettoyage","title":"Gestion de l'Espace Disque et du Nettoyage","text":"<p>Pour visualiser l'utilisation de l'espace disque par les images, conteneurs, volumes et r\u00e9seaux, la commande suivante est tr\u00e8s utile[3] :</p> Bash<pre><code>docker system df\n</code></pre> <p>Le r\u00e9sultat affiche un tableau de r\u00e9sum\u00e9 avec les colonnes suivantes[3] :</p> Colonne Description TYPE Le type de ressource (images, containers, volumes, etc.) TOTAL Le nombre total d'\u00e9l\u00e9ments pour chaque type ACTIVE Le nombre d'\u00e9l\u00e9ments actuellement utilis\u00e9s SIZE L'espace disque total occup\u00e9 par chaque type RECLAIMABLE L'espace disque qui peut \u00eatre r\u00e9cup\u00e9r\u00e9 (r\u00e9utilis\u00e9 ou lib\u00e9r\u00e9) <p>Pour nettoyer les ressources inutilis\u00e9es :</p> Bash<pre><code># Supprimer tous les conteneurs arr\u00eat\u00e9s\ndocker container prune\n\n# Supprimer toutes les images non utilis\u00e9es\ndocker image prune\n\n# Supprimer les volumes non utilis\u00e9s\ndocker volume prune\n\n# Nettoyage complet de tous les \u00e9l\u00e9ments non utilis\u00e9s\ndocker system prune\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap02/#docker-pause-unpause-rename-et-exec","title":"Docker Pause, Unpause, Rename et Exec","text":""},{"location":"_projects/_formation-docker/docker-chap02/#pause-et-unpause-de-conteneurs","title":"Pause et Unpause de Conteneurs","text":"<p>La capacit\u00e9 de mettre en pause et de reprendre les conteneurs offre un contr\u00f4le granulaire sans n\u00e9cessiter l'arr\u00eat complet du conteneur.</p> <p>Mettre en Pause un Conteneur</p> <p>La commande <code>docker pause</code> suspend tous les processus en cours d'ex\u00e9cution dans un conteneur :</p> Bash<pre><code>docker pause [CONTAINER_ID_OU_NOM]\n</code></pre> <p>Lorsqu'un conteneur est mis en pause :</p> <ul> <li>Tous les processus sont gel\u00e9s instantan\u00e9ment</li> <li>La m\u00e9moire et les ressources utilis\u00e9es sont conserv\u00e9es</li> <li>Le conteneur reste assign\u00e9 \u00e0 ses ressources</li> <li>L'\u00e9tat du conteneur change \u00e0 \"Paused\"</li> </ul> <p>Exemple pratique :</p> Bash<pre><code># Lancer un conteneur en arri\u00e8re-plan\ndocker run -d --name mon-app nginx\n\n# Mettre le conteneur en pause\ndocker pause mon-app\n\n# V\u00e9rifier l'\u00e9tat avec docker ps\ndocker ps\n</code></pre> <p>Reprendre l'Ex\u00e9cution d'un Conteneur</p> <p>La commande <code>docker unpause</code> reprend l'ex\u00e9cution d'un conteneur pr\u00e9c\u00e9demment mis en pause :</p> Bash<pre><code>docker unpause [CONTAINER_ID_OU_NOM]\n</code></pre> <p>Exemple pratique :</p> Bash<pre><code># Reprendre le conteneur\ndocker unpause mon-app\n\n# V\u00e9rifier que le conteneur s'ex\u00e9cute \u00e0 nouveau\ndocker ps\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap02/#renommer-un-conteneur","title":"Renommer un Conteneur","text":"<p>La commande <code>docker rename</code> permet de changer le nom d'un conteneur existant[3]. Cette fonctionnalit\u00e9 est utile pour organiser et identifier les conteneurs de mani\u00e8re plus lisible :</p> Bash<pre><code>docker rename [ANCIEN_NOM] [NOUVEAU_NOM]\n</code></pre> <p>Exemple pratique :</p> Bash<pre><code># Renommer un conteneur\ndocker rename mon-app app-production\n\n# V\u00e9rifier le changement\ndocker ps -a\n</code></pre> <p>Points importants concernant le renommage :</p> <ul> <li>Le conteneur peut \u00eatre en cours d'ex\u00e9cution ou arr\u00eat\u00e9</li> <li>Seul le nom change, pas l'ID du conteneur</li> <li>Si le nouveau nom existe d\u00e9j\u00e0, une erreur s'affiche</li> <li>Les r\u00e9f\u00e9rences dans d'autres conteneurs utilisant le nom doivent \u00eatre mises \u00e0 jour</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap02/#executer-des-commandes-dans-un-conteneur-en-cours-dexecution","title":"Ex\u00e9cuter des Commandes dans un Conteneur en Cours d'Ex\u00e9cution","text":"<p>La commande <code>docker exec</code> permet d'ex\u00e9cuter une commande dans un conteneur d\u00e9j\u00e0 en cours d'ex\u00e9cution, sans avoir besoin de cr\u00e9er un nouveau conteneur[3]. C'est un outil puissant pour le d\u00e9bogage, l'administration et l'ex\u00e9cution de t\u00e2ches ad hoc.</p> <p>Syntaxe de Base</p> Bash<pre><code>docker exec [OPTIONS] [CONTAINER_ID_OU_NOM] [COMMANDE]\n</code></pre> <p>Options Courantes</p> Option Description Exemple <code>-i</code> Garder STDIN ouvert m\u00eame sans attachement <code>docker exec -i mon-app</code> <code>-t</code> Allouer un pseudo-terminal <code>docker exec -t mon-app</code> <code>-it</code> Combinaison interactive avec terminal <code>docker exec -it mon-app bash</code> <code>-u</code> Ex\u00e9cuter en tant qu'utilisateur sp\u00e9cifique <code>docker exec -u root mon-app</code> <code>-w</code> D\u00e9finir le r\u00e9pertoire de travail <code>docker exec -w /app mon-app</code> <code>-e</code> D\u00e9finir des variables d'environnement <code>docker exec -e VAR=valeur mon-app</code> <p>Exemples Pratiques</p> <p>Acc\u00e8s interactif au shell d'un conteneur :</p> Bash<pre><code># Lancer un conteneur nginx\ndocker run -d --name serveur nginx\n\n# Acc\u00e9der au shell bash du conteneur\ndocker exec -it serveur bash\n</code></pre> <p>Une fois connect\u00e9 au conteneur, il est possible d'ex\u00e9cuter des commandes comme dans un syst\u00e8me d'exploitation standard :</p> Bash<pre><code># \u00c0 l'int\u00e9rieur du conteneur\nroot@container:/# ls -la\nroot@container:/# cat /etc/os-release\nroot@container:/# exit\n</code></pre> <p>Ex\u00e9cuter une commande sp\u00e9cifique sans acc\u00e8s interactif :</p> Bash<pre><code># Afficher le contenu d'un fichier\ndocker exec mon-app cat /etc/nginx/nginx.conf\n\n# Ex\u00e9cuter un script\ndocker exec mon-app /app/scripts/backup.sh\n\n# V\u00e9rifier le statut d'un service\ndocker exec mon-app service nginx status\n</code></pre> <p>Ex\u00e9cuter une commande en tant qu'utilisateur sp\u00e9cifique :</p> Bash<pre><code># Ex\u00e9cuter en tant que root\ndocker exec -u root mon-app apt-get update\n\n# Ex\u00e9cuter en tant qu'utilisateur non-root\ndocker exec -u appuser mon-app whoami\n</code></pre> <p>Ex\u00e9cuter une commande avec des variables d'environnement :</p> Bash<pre><code># Passer des variables d'environnement\ndocker exec -e ENV=production mon-app /app/start.sh\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap02/#copier-des-fichiers-et-inspecter-un-conteneur","title":"Copier des Fichiers et Inspecter un Conteneur","text":""},{"location":"_projects/_formation-docker/docker-chap02/#copier-des-fichiers-entre-lhote-et-le-conteneur","title":"Copier des Fichiers entre l'H\u00f4te et le Conteneur","text":"<p>La commande <code>docker cp</code> permet de copier des fichiers et des r\u00e9pertoires entre le syst\u00e8me h\u00f4te et un conteneur, ou vice-versa. C'est un outil essentiel pour transf\u00e9rer des configurations, des donn\u00e9es ou des scripts.</p> <p>Syntaxe de Base</p> Bash<pre><code># Copier du conteneur vers l'h\u00f4te\ndocker cp [CONTAINER_ID_OU_NOM]:[CHEMIN_CONTENEUR] [CHEMIN_H\u00d4TE]\n\n# Copier de l'h\u00f4te vers le conteneur\ndocker cp [CHEMIN_H\u00d4TE] [CONTAINER_ID_OU_NOM]:[CHEMIN_CONTENEUR]\n</code></pre> <p>Exemples Pratiques</p> <p>Copier un fichier du conteneur vers l'h\u00f4te :</p> Bash<pre><code># Copier un fichier de configuration\ndocker cp mon-app:/etc/nginx/nginx.conf ./nginx.conf\n\n# Copier un fichier journal\ndocker cp mon-app:/var/log/app.log ./logs/\n</code></pre> <p>Copier un r\u00e9pertoire entier :</p> Bash<pre><code># Copier un r\u00e9pertoire du conteneur vers l'h\u00f4te\ndocker cp mon-app:/app ./app-backup\n\n# Copier un r\u00e9pertoire de l'h\u00f4te vers le conteneur\ndocker cp ./config mon-app:/etc/app\n</code></pre> <p>Copier vers le conteneur :</p> Bash<pre><code># Copier un fichier de configuration\ndocker cp ./app-config.json mon-app:/app/config.json\n\n# Copier un script\ndocker cp ./backup.sh mon-app:/scripts/backup.sh\n</code></pre> <p>Points Importants</p> <ul> <li>Le conteneur peut \u00eatre en cours d'ex\u00e9cution ou arr\u00eat\u00e9</li> <li>Les chemins sont r\u00e9solus relativement au r\u00e9pertoire de travail</li> <li>Les permissions de fichiers sont pr\u00e9serv\u00e9es lors de la copie</li> <li>Les chemins absolus doivent \u00eatre utilis\u00e9s pour clart\u00e9</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap02/#inspecter-un-conteneur","title":"Inspecter un Conteneur","text":"<p>La commande <code>docker inspect</code> fournit des informations d\u00e9taill\u00e9es sur la configuration et l'\u00e9tat d'un conteneur[3]. Cette commande retourne des donn\u00e9es au format JSON contenant une multitude d'informations.</p> <p>Syntaxe de Base</p> Bash<pre><code>docker inspect [CONTAINER_ID_OU_NOM]\n</code></pre> <p>Informations Retourn\u00e9es</p> <p>La commande retourne un objet JSON contenant, entre autres :</p> Information Description Id L'ID complet du conteneur Created L'horodatage de cr\u00e9ation du conteneur Path Le chemin de la commande \u00e0 ex\u00e9cuter Args Les arguments de la commande State L'\u00e9tat actuel du conteneur (Running, Paused, Exited) Image L'image utilis\u00e9e pour cr\u00e9er le conteneur ResolvConfPath Chemin vers le fichier de r\u00e9solution DNS Hostname Le nom d'h\u00f4te du conteneur Env Les variables d'environnement Mounts Les volumes et bindages mont\u00e9s NetworkSettings Configuration r\u00e9seau (IP, ports) Config Configuration du conteneur (utilisateur, working directory) <p>Exemples Pratiques</p> <p>Inspecter un conteneur entier :</p> Bash<pre><code>docker inspect mon-app\n</code></pre> <p>Extraire une information sp\u00e9cifique en utilisant le format personnalis\u00e9 :</p> Bash<pre><code># Obtenir l'adresse IP du conteneur\ndocker inspect -f '{{.NetworkSettings.IPAddress}}' mon-app\n\n# Obtenir l'\u00e9tat du conteneur\ndocker inspect -f '{{.State.Status}}' mon-app\n\n# Obtenir les variables d'environnement\ndocker inspect -f '{{json .Config.Env}}' mon-app\n\n# Obtenir les volumes mont\u00e9s\ndocker inspect -f '{{json .Mounts}}' mon-app\n</code></pre> <p>Inspecter plusieurs conteneurs :</p> Bash<pre><code>docker inspect $(docker ps -q)\n</code></pre> <p>Afficher les informations au format lisible :</p> Bash<pre><code># Afficher en JSON format\u00e9\ndocker inspect mon-app | jq\n\n# Filtrer les informations r\u00e9seau\ndocker inspect mon-app | jq '.[] | .NetworkSettings'\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap02/#volumes-docker-persistance-des-donnees","title":"Volumes Docker : Persistance des Donn\u00e9es","text":"<p>Un probl\u00e8me courant en conteneurisation est la perte de donn\u00e9es critiques lorsque les conteneurs sont arr\u00eat\u00e9s ou supprim\u00e9s, en raison d'une gestion inefficace des donn\u00e9es[1]. Cela peut entra\u00eener la perte de configurations importantes, de journaux d'activit\u00e9s, ou m\u00eame de bases de donn\u00e9es enti\u00e8res, compromettant la stabilit\u00e9 et la fiabilit\u00e9 des applications[1].</p> <p>Utilit\u00e9 des Volumes</p> <p>Les volumes Docker sont utilis\u00e9s pour persister des donn\u00e9es en dehors du cycle de vie des conteneurs[3]. En effet, lorsqu'un conteneur est supprim\u00e9, toutes les donn\u00e9es qu'il contenait disparaissent. Les volumes permettent de sauvegarder ces donn\u00e9es de mani\u00e8re permanente, m\u00eame si le conteneur est supprim\u00e9 et recr\u00e9\u00e9[3].</p> <p>Docker permet de monter des volumes, c'est-\u00e0-dire de connecter une partie du syst\u00e8me de fichiers de l'h\u00f4te au conteneur[3]. Cela permet aussi de partager des donn\u00e9es entre plusieurs conteneurs[3].</p> <p>Syntaxe de Montage de Volumes</p> Bash<pre><code># Lors du lancement d'un conteneur\ndocker run -v [CHEMIN_H\u00d4TE]:[CHEMIN_CONTENEUR] [IMAGE]\n\n# Ou avec une syntaxe plus explicite\ndocker run --volume [CHEMIN_H\u00d4TE]:[CHEMIN_CONTENEUR] [IMAGE]\n</code></pre> <p>Exemple Pratique avec une Base de Donn\u00e9es</p> Bash<pre><code># Cr\u00e9er un conteneur PostgreSQL avec volume persistant\ndocker run -d \\\n  --name db-prod \\\n  -e POSTGRES_PASSWORD=motdepasse \\\n  -v /data/postgresql:/var/lib/postgresql/data \\\n  postgres:15\n\n# M\u00eame apr\u00e8s suppression du conteneur, les donn\u00e9es persistent\ndocker rm db-prod\n\n# Cr\u00e9er un nouveau conteneur utilisant le m\u00eame volume\ndocker run -d \\\n  --name db-prod-2 \\\n  -e POSTGRES_PASSWORD=motdepasse \\\n  -v /data/postgresql:/var/lib/postgresql/data \\\n  postgres:15\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap02/#arreter-et-gerer-les-instances-de-conteneurs","title":"Arr\u00eater et G\u00e9rer les Instances de Conteneurs","text":""},{"location":"_projects/_formation-docker/docker-chap02/#arreter-un-conteneur","title":"Arr\u00eater un Conteneur","text":"<p>La commande <code>docker stop</code> arr\u00eate proprement un conteneur en cours d'ex\u00e9cution[3]. Cette commande envoie un signal SIGTERM au processus principal du conteneur, lui permettant de se terminer gracieusement[3] :</p> Bash<pre><code>docker stop [CONTAINER_ID_OU_NOM]\n</code></pre> <p>Exemple pratique :</p> Bash<pre><code># Arr\u00eater un conteneur\ndocker stop mon-app\n\n# Arr\u00eater plusieurs conteneurs\ndocker stop mon-app app2 app3\n\n# Arr\u00eater tous les conteneurs en cours d'ex\u00e9cution\ndocker stop $(docker ps -q)\n</code></pre> <p>Particularit\u00e9s de l'arr\u00eat</p> <ul> <li>Le conteneur n'est pas supprim\u00e9, seulement arr\u00eat\u00e9</li> <li>Les donn\u00e9es du conteneur sont conserv\u00e9es</li> <li>Un d\u00e9lai de gr\u00e2ce par d\u00e9faut de 10 secondes est accord\u00e9 avant SIGKILL</li> <li>Le d\u00e9lai peut \u00eatre personnalis\u00e9 avec l'option <code>-t</code> :</li> </ul> Bash<pre><code># Attendre 30 secondes avant de forcer l'arr\u00eat\ndocker stop -t 30 mon-app\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap02/#supprimer-un-conteneur","title":"Supprimer un Conteneur","text":"<p>La commande <code>docker rm</code> supprime d\u00e9finitivement un conteneur qui n'est plus n\u00e9cessaire[3]. Contrairement \u00e0 <code>stop</code>, cette commande supprime compl\u00e8tement le conteneur et ses donn\u00e9es[3] :</p> Bash<pre><code>docker rm [CONTAINER_ID_OU_NOM]\n</code></pre> <p>Exemple pratique :</p> Bash<pre><code># Supprimer un conteneur arr\u00eat\u00e9\ndocker rm mon-app\n\n# Supprimer plusieurs conteneurs\ndocker rm mon-app app2 app3\n\n# Forcer la suppression d'un conteneur en cours d'ex\u00e9cution\ndocker rm -f mon-app\n\n# Supprimer tous les conteneurs arr\u00eat\u00e9s\ndocker rm $(docker ps -aq)\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap02/#tableau-comparatif-stop-vs-remove","title":"Tableau Comparatif : Stop vs Remove","text":"Aspect <code>docker stop</code> <code>docker rm</code> Action Arr\u00eate le processus Supprime le conteneur R\u00e9cup\u00e9rabilit\u00e9 Le conteneur peut \u00eatre red\u00e9marr\u00e9 Le conteneur est perdu \u00e0 jamais Donn\u00e9es Les donn\u00e9es sont conserv\u00e9es Les donn\u00e9es sont supprim\u00e9es \u00c9tat requis Conteneur doit \u00eatre en cours d'ex\u00e9cution Conteneur arr\u00eat\u00e9 ou en cours d'ex\u00e9cution avec <code>-f</code> Processus Envoi de SIGTERM Suppression d\u00e9finitive Temps Peut n\u00e9cessiter quelques secondes Imm\u00e9diat"},{"location":"_projects/_formation-docker/docker-chap02/#redemarrer-un-conteneur","title":"Red\u00e9marrer un Conteneur","text":"<p>Pour red\u00e9marrer un conteneur arr\u00eat\u00e9, la commande suivante est utilis\u00e9e :</p> Bash<pre><code>docker start [CONTAINER_ID_OU_NOM]\n</code></pre> <p>Exemple pratique :</p> Bash<pre><code># Red\u00e9marrer un conteneur arr\u00eat\u00e9\ndocker start mon-app\n\n# Red\u00e9marrer plusieurs conteneurs\ndocker start app1 app2 app3\n</code></pre> <p>Pour red\u00e9marrer un conteneur en cours d'ex\u00e9cution ou arr\u00eat\u00e9 :</p> Bash<pre><code>docker restart [CONTAINER_ID_OU_NOM]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap02/#recapitulatif-et-approfondissement","title":"R\u00e9capitulatif et Approfondissement","text":""},{"location":"_projects/_formation-docker/docker-chap02/#synthese-du-chemin-dapprentissage","title":"Synth\u00e8se du Chemin d'Apprentissage","text":"<p>L'apprentissage des bases de Docker suit une progression logique construisant les fondations n\u00e9cessaires pour la gestion professionelle des conteneurs.</p> <p>Phase 1 : Lancement Initial</p> <p>L'apprentissage d\u00e9bute par la compr\u00e9hension du concept fondamental : un conteneur est une instance ex\u00e9cutable d'une image Docker[2]. La premi\u00e8re \u00e9tape pratique consiste \u00e0 lancer un conteneur simple, permettant de visualiser le cycle de vie de base et comprendre comment Docker fonctionne de mani\u00e8re op\u00e9rationnelle.</p> <p>Phase 2 : Gestion et Organisation</p> <p>Une fois les bases comprises, il devient n\u00e9cessaire de g\u00e9rer les ressources Docker. Cette phase couvre :</p> <ul> <li>Lister les images et conteneurs pour visualiser l'\u00e9tat actuel du syst\u00e8me</li> <li>Supprimer les ressources obsol\u00e8tes pour maintenir une propret\u00e9 du syst\u00e8me</li> <li>Utiliser l'aide pour explorer les commandes disponibles</li> </ul> <p>L'importance d'une gestion appropri\u00e9e de l'espace disque est particuli\u00e8rement relev\u00e9e par la possibilit\u00e9 d'une perte de contr\u00f4le sur les ressources Docker si cette gestion n'est pas effectu\u00e9e r\u00e9guli\u00e8rement[3].</p> <p>Phase 3 : Contr\u00f4le Avanc\u00e9</p> <p>Apr\u00e8s avoir ma\u00eetris\u00e9 les op\u00e9rations de base, l'apprentissage avance vers le contr\u00f4le fin des conteneurs :</p> <ul> <li>Pause et Unpause : Permettent le contr\u00f4le granulaire sans arr\u00eat complet</li> <li>Renommage : Facilite l'organisation et l'identification</li> <li>Ex\u00e9cution de commandes : Ouvre les possibilit\u00e9s de d\u00e9bogage et d'administration</li> </ul> <p>Phase 4 : Manipulation de Donn\u00e9es</p> <p>L'interaction avec les conteneurs s'\u00e9tend au transfert de donn\u00e9es :</p> <ul> <li>Copier des fichiers entre l'h\u00f4te et le conteneur</li> <li>Inspecter pour comprendre l'\u00e9tat d\u00e9taill\u00e9</li> <li>Utiliser les volumes pour la persistance des donn\u00e9es</li> </ul> <p>Phase 5 : Cycle de Vie Complet</p> <p>L'apprentissage se conclut par la ma\u00eetrise compl\u00e8te du cycle de vie :</p> <ul> <li>Arr\u00eat gracieux avec <code>docker stop</code></li> <li>Suppression d\u00e9finitive avec <code>docker rm</code></li> <li>Red\u00e9marrage avec <code>docker start</code></li> </ul>"},{"location":"_projects/_formation-docker/docker-chap02/#principes-fondamentaux-retenus","title":"Principes Fondamentaux Retenus","text":"<p>Isolation et L\u00e9g\u00e8ret\u00e9</p> <p>Les conteneurs Docker repr\u00e9sentent une avanc\u00e9e majeure en permettant l'empaquetage d'une application et ses d\u00e9pendances dans un conteneur isol\u00e9, qui peut \u00eatre ex\u00e9cut\u00e9 sur n'importe quel syst\u00e8me[8]. Cette isolation est r\u00e9alis\u00e9e tout en partageant le noyau du syst\u00e8me d'exploitation h\u00f4te, ce qui rend les conteneurs beaucoup plus l\u00e9gers que des machines virtuelles traditionnelles[2].</p> <p>Gestion Appropri\u00e9e des Ressources</p> <p>Comprendre les nuances du cycle de vie des conteneurs permet d'adapter l'infrastructure Docker \u00e0 des sc\u00e9narios d'utilisation vari\u00e9s, allant des t\u00e2ches temporaires aux services persistants[1]. En utilisant le bon mod\u00e8le de cycle de vie, il est possible de maximiser l'utilisation des ressources et minimiser les co\u00fbts op\u00e9rationnels[1].</p> <p>Fiabilit\u00e9 et Reproductibilit\u00e9</p> <p>Le flux de travail Docker du Dockerfile \u00e0 l'image au conteneur garantit une reproductibilit\u00e9 compl\u00e8te[2]. Chaque \u00e9tape est document\u00e9e dans le Dockerfile, cr\u00e9ant des couches immuables qui peuvent \u00eatre r\u00e9utilis\u00e9es et versionn\u00e9es.</p> <p>Persistance et \u00c9tat</p> <p>Bien que les conteneurs soient \u00e9ph\u00e9m\u00e8res par d\u00e9faut, la compr\u00e9hension des volumes permet de concevoir des architectures Docker fiables et \u00e9volutives, capables de r\u00e9pondre aux exigences des applications n\u00e9cessitant la persistance des donn\u00e9es[1].</p>"},{"location":"_projects/_formation-docker/docker-chap02/#points-dapprofondissement-recommandes","title":"Points d'Approfondissement Recommand\u00e9s","text":"<p>Pour Progresser Plus Loin</p> <ul> <li>R\u00e9seaux Docker : Comprendre comment les conteneurs communiquent entre eux et avec le monde ext\u00e9rieur</li> <li>Docker Compose : G\u00e9rer des applications multi-conteneurs de mani\u00e8re d\u00e9clarative</li> <li>Orchestration : D\u00e9couvrir Kubernetes, le standard de facto en 2025 pour l'orchestration de conteneurs \u00e0 grande \u00e9chelle[2]</li> <li>Pipelines CI/CD : Int\u00e9grer Docker dans les processus d'int\u00e9gration continue et de livraison continue[2]</li> <li>Bonnes Pratiques de S\u00e9curit\u00e9 : Configurer les conteneurs de mani\u00e8re s\u00e9curis\u00e9e en production</li> </ul> <p>\u00c9volution de la Comp\u00e9tence</p> <p>Les apprentissages progressent naturellement de la manipulation manuelle de conteneurs individuels \u00e0 la gestion orchestr\u00e9e de flottes enti\u00e8res. La ma\u00eetrise des fondamentaux pr\u00e9sent\u00e9s dans ce chapitre est le pr\u00e9alable indispensable \u00e0 cette \u00e9volution.</p>"},{"location":"_projects/_formation-docker/docker-chap02/#architecture-generale-de-docker","title":"Architecture G\u00e9n\u00e9rale de Docker","text":"<p>Docker s'int\u00e8gre parfaitement avec les plateformes d'orchestration de conteneurs telles que Kubernetes, le standard de facto en 2025[2]. Ces orchestrateurs g\u00e8rent le cycle de vie des conteneurs \u00e0 grande \u00e9chelle : d\u00e9ploiement, mise \u00e0 l'\u00e9chelle automatique, \u00e9quilibrage de charge, auto-r\u00e9paration[2].</p> <p>De plus, les pipelines CI/CD peuvent utiliser des conteneurs Docker pour chaque \u00e9tape : le build de l'application, l'ex\u00e9cution des tests, la cr\u00e9ation de l'image Docker finale[2]. Cela garantit que chaque \u00e9tape du pipeline s'ex\u00e9cute dans un environnement propre et reproductible, \u00e9liminant les incoh\u00e9rences et rendant les tests plus fiables[2].</p>"},{"location":"_projects/_formation-docker/docker-chap02/#exercices-pratiques-de-consolidation","title":"Exercices Pratiques de Consolidation","text":""},{"location":"_projects/_formation-docker/docker-chap02/#exercice-1-cycle-de-vie-complet-dun-conteneur","title":"Exercice 1 : Cycle de Vie Complet d'un Conteneur","text":"<p>Cet exercice guide la personne \u00e0 travers un cycle de vie complet en utilisant les commandes fondamentales.</p> <p>Objectif : Cr\u00e9er, g\u00e9rer, arr\u00eater et nettoyer un conteneur.</p> <p>\u00c9tapes :</p> Bash<pre><code># 1. Lancer un conteneur nginx en arri\u00e8re-plan\ndocker run -d --name web-server nginx\n\n# 2. V\u00e9rifier que le conteneur est en cours d'ex\u00e9cution\ndocker ps\n\n# 3. Mettre le conteneur en pause\ndocker pause web-server\n\n# 4. V\u00e9rifier l'\u00e9tat\ndocker ps\n\n# 5. Reprendre le conteneur\ndocker unpause web-server\n\n# 6. Renommer le conteneur\ndocker rename web-server prod-web\n\n# 7. Arr\u00eater le conteneur\ndocker stop prod-web\n\n# 8. V\u00e9rifier l'\u00e9tat arr\u00eat\u00e9\ndocker ps -a\n\n# 9. Supprimer le conteneur\ndocker rm prod-web\n\n# 10. V\u00e9rifier la suppression\ndocker ps -a\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap02/#exercice-2-inspection-et-copie-de-fichiers","title":"Exercice 2 : Inspection et Copie de Fichiers","text":"<p>Cet exercice pratique l'inspection et la manipulation de fichiers.</p> <p>Objectif : Inspecter un conteneur et transf\u00e9rer des fichiers.</p> Bash<pre><code># 1. Lancer un conteneur\ndocker run -d --name app nginx\n\n# 2. Inspecter le conteneur\ndocker inspect app\n\n# 3. Extraire l'adresse IP\ndocker inspect -f '{{.NetworkSettings.IPAddress}}' app\n\n# 4. Cr\u00e9er un fichier sur l'h\u00f4te\necho \"Configuration de production\" &gt; config.txt\n\n# 5. Copier vers le conteneur\ndocker cp config.txt app:/etc/nginx/config.txt\n\n# 6. V\u00e9rifier la copie\ndocker exec app cat /etc/nginx/config.txt\n\n# 7. Copier un fichier du conteneur vers l'h\u00f4te\ndocker cp app:/etc/nginx/nginx.conf ./nginx.conf.bak\n\n# 8. V\u00e9rifier sur l'h\u00f4te\ncat nginx.conf.bak\n\n# 9. Nettoyer\ndocker rm -f app\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap02/#exercice-3-gestion-des-ressources","title":"Exercice 3 : Gestion des Ressources","text":"<p>Cet exercice d\u00e9montre la gestion efficace de l'espace disque.</p> Bash<pre><code># 1. Afficher l'utilisation des ressources\ndocker system df\n\n# 2. Lancer plusieurs conteneurs\ndocker run -d --name app1 ubuntu sleep 1000\ndocker run -d --name app2 alpine sleep 1000\ndocker run -d --name app3 nginx\n\n# 3. Arr\u00eater tous les conteneurs\ndocker stop $(docker ps -q)\n\n# 4. Afficher les ressources \u00e0 nouveau\ndocker system df\n\n# 5. Nettoyer les conteneurs arr\u00eat\u00e9s\ndocker container prune -f\n\n# 6. V\u00e9rifier l'espace r\u00e9cup\u00e9r\u00e9\ndocker system df\n</code></pre> <p> Partager sur X</p>"},{"location":"_projects/_formation-docker/docker-chap03/","title":"Citations","text":"<ul> <li>https://www.cherryservers.com/blog/docker-build-command</li> <li>https://docs.docker.com/get-started/docker-concepts/building-images/writing-a-dockerfile/</li> <li>https://docs.docker.com/get-started/introduction/build-and-push-first-image/</li> <li>https://docs.docker.com/get-started/workshop/02_our_app/</li> <li>https://chtc.cs.wisc.edu/uw-research-computing/docker-build</li> <li>https://learn.microsoft.com/en-us/dotnet/core/docker/build-container</li> <li>https://docs.docker.com/get-started/docker-concepts/building-images/</li> <li>https://www.youtube.com/watch?v=DQdB7wFEygo</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap03/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 297</li> <li>completion_tokens: 6665</li> <li>total_tokens: 6962</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.1, 'request_cost': 0.006, 'total_cost': 0.107}</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap03/#content","title":"Content","text":""},{"location":"_projects/_formation-docker/docker-chap03/#creer-une-image-docker-avec-un-dockerfile","title":"Cr\u00e9er une image Docker avec un Dockerfile","text":""},{"location":"_projects/_formation-docker/docker-chap03/#introduction-generale","title":"Introduction g\u00e9n\u00e9rale","text":"<p>La cr\u00e9ation d'images Docker est l'une des comp\u00e9tences fondamentales pour ma\u00eetriser la conteneurisation. Une image Docker repr\u00e9sente un blueprint immutable contenant tous les \u00e9l\u00e9ments n\u00e9cessaires pour ex\u00e9cuter une application : le syst\u00e8me d'exploitation, les d\u00e9pendances, le code source et la configuration. Le Dockerfile est le fichier de configuration textuel qui permet de d\u00e9finir comment construire cette image, en suivant une s\u00e9rie d'instructions d\u00e9claratives qui vont progressivement transformer une image de base en une image pr\u00eate pour la production[1][2].</p> <p>Ce chapitre approfondit les m\u00e9canismes internes de cr\u00e9ation d'images, en commen\u00e7ant par les concepts fondamentaux comme <code>docker commit</code>, avant de progresser vers les instructions Dockerfile avanc\u00e9es et les meilleures pratiques d'optimisation.</p>"},{"location":"_projects/_formation-docker/docker-chap03/#fondements-docker-commit-logs-tags-et-history","title":"\ud83d\udce6 Fondements : Docker Commit, Logs, Tags et History","text":""},{"location":"_projects/_formation-docker/docker-chap03/#comprendre-docker-commit","title":"Comprendre Docker Commit","text":"<p>Docker commit est la m\u00e9thode archa\u00efque mais instructive de cr\u00e9er une image Docker. Contrairement au Dockerfile qui utilise une approche d\u00e9clarative, <code>docker commit</code> permet de capturer l'\u00e9tat d'un conteneur en cours d'ex\u00e9cution et de le transformer en image[1]. Cette approche, bien que rarement utilis\u00e9e en production, illustre parfaitement le fonctionnement interne des images.</p> <p>La syntaxe g\u00e9n\u00e9rale est :</p> Bash<pre><code>docker commit [OPTIONS] CONTAINER [REPOSITORY[:TAG]]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap03/#exemple-pratique-de-docker-commit","title":"Exemple pratique de Docker Commit","text":"<p>Commen\u00e7ons par cr\u00e9er un conteneur interactif et effectuer des modifications :</p> Bash<pre><code># Lancer un conteneur nginx interactif\ndocker run -it --name webserver nginx:latest /bin/bash\n\n# \u00c0 l'int\u00e9rieur du conteneur, modifier l'image de base\napt-get update\napt-get install -y curl wget\necho \"Modified Image\" &gt; /usr/share/nginx/html/index.html\nexit\n\n# Cr\u00e9er une nouvelle image \u00e0 partir de ce conteneur\ndocker commit webserver monapp:v1\n</code></pre> <p>Cette approche cr\u00e9e une image <code>monapp:v1</code> qui contient toutes les modifications effectu\u00e9es dans le conteneur. Cependant, cette m\u00e9thode pr\u00e9sente des inconv\u00e9nients majeurs :</p> <ul> <li>Pas de tra\u00e7abilit\u00e9 : impossible de savoir exactement quelles commandes ont \u00e9t\u00e9 ex\u00e9cut\u00e9es</li> <li>Pas de reproductibilit\u00e9 : difficile \u00e0 reproduire sur une autre machine</li> <li>Couches suppl\u00e9mentaires : chaque commit cr\u00e9e une nouvelle couche, augmentant la taille de l'image</li> <li>Mauvaises pratiques : encourages les modifications ad hoc plut\u00f4t que l'infrastructure as code</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap03/#systeme-de-logs-et-historique","title":"Syst\u00e8me de Logs et Historique","text":"<p>La commande <code>docker logs</code> permet d'inspecter la sortie standard et d'erreur d'un conteneur en cours d'ex\u00e9cution ou stopp\u00e9 :</p> Bash<pre><code># Voir les logs d'un conteneur\ndocker logs webserver\n\n# Afficher les 50 derni\u00e8res lignes\ndocker logs --tail 50 webserver\n\n# Afficher les logs en temps r\u00e9el\ndocker logs -f webserver\n\n# Ajouter les timestamps\ndocker logs --timestamps webserver\n</code></pre> <p>L'historique d'une image peut \u00eatre consult\u00e9 avec <code>docker history</code> :</p> Bash<pre><code>docker history monapp:v1\n</code></pre> <p>Cela affiche chaque couche de l'image avec : - L'ID de la couche - La commande qui a cr\u00e9\u00e9 la couche - La taille de la couche - Le timestamp de cr\u00e9ation</p>"},{"location":"_projects/_formation-docker/docker-chap03/#systeme-de-tags","title":"Syst\u00e8me de Tags","text":"<p>Les tags permettent de versionner les images et de les identifier clairement. Un tag Docker suit le format :</p> Text Only<pre><code>[REGISTRY/]REPOSITORY[:TAG]\n</code></pre> <p>Les composants peuvent \u00eatre :</p> \u00c9l\u00e9ment Description Exemple REGISTRY Registre Docker (optionnel, d\u00e9faut: Docker Hub) docker.io, registry.exemple.fr REPOSITORY Nom de l'image nginx, monapp TAG Identifiant de version (optionnel, d\u00e9faut: latest) v1.0, stable, latest"},{"location":"_projects/_formation-docker/docker-chap03/#operations-sur-les-tags","title":"Op\u00e9rations sur les Tags","text":"Bash<pre><code># Tagger une image existante\ndocker tag monapp:v1 monapp:latest\ndocker tag monapp:v1 registry.exemple.fr/monapp:v1\n\n# Lister tous les tags d'une image\ndocker images monapp\n\n# Supprimer un tag\ndocker rmi monapp:latest\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap03/#instructions-cmd-et-entrypoint","title":"\ud83c\udfaf Instructions CMD et ENTRYPOINT","text":"<p>Ces deux instructions sont critiques car elles d\u00e9finissent le comportement par d\u00e9faut du conteneur au d\u00e9marrage. Bien qu'elles semblent similaires, leurs diff\u00e9rences sont fondamentales.</p>"},{"location":"_projects/_formation-docker/docker-chap03/#differences-fondamentales","title":"Diff\u00e9rences fondamentales","text":"<p>CMD d\u00e9finit la commande par d\u00e9faut qui sera ex\u00e9cut\u00e9e si aucune commande n'est sp\u00e9cifi\u00e9e au lancement du conteneur. Elle peut \u00eatre remplac\u00e9e en ligne de commande :</p> Docker<pre><code>FROM nginx:latest\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n</code></pre> <p>ENTRYPOINT d\u00e9finit la commande obligatoire qui s'ex\u00e9cutera toujours, mais peut recevoir des arguments. Elle ne peut \u00eatre remplac\u00e9e que avec le flag <code>--entrypoint</code> :</p> Docker<pre><code>FROM ubuntu:20.04\nENTRYPOINT [\"echo\"]\nCMD [\"Hello, World\"]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap03/#trois-formes-syntaxiques","title":"Trois formes syntaxiques","text":""},{"location":"_projects/_formation-docker/docker-chap03/#forme-shell-deconseillee","title":"Forme Shell (d\u00e9conseill\u00e9e)","text":"Docker<pre><code>CMD nginx -g daemon off;\nENTRYPOINT nginx -g daemon off;\n</code></pre> <p>Cette forme lance la commande \u00e0 travers <code>/bin/sh</code>, ce qui cr\u00e9e un processus shell suppl\u00e9mentaire et emp\u00eache les signaux d'\u00eatre re\u00e7us correctement[2].</p>"},{"location":"_projects/_formation-docker/docker-chap03/#forme-exec-recommandee","title":"Forme Exec (recommand\u00e9e)","text":"Docker<pre><code>CMD [\"nginx\", \"-g\", \"daemon off;\"]\nENTRYPOINT [\"nginx\", \"-g\", \"daemon off;\"]\n</code></pre> <p>Cette forme ex\u00e9cute directement le binaire sans shell interm\u00e9diaire, permettant aux signaux (comme SIGTERM) d'\u00eatre re\u00e7us correctement.</p>"},{"location":"_projects/_formation-docker/docker-chap03/#combinaison-entrypoint-cmd","title":"Combinaison ENTRYPOINT + CMD","text":"<p>C'est l'approche optimale pour cr\u00e9er des conteneurs flexibles :</p> Docker<pre><code>FROM ubuntu:20.04\nRUN apt-get update &amp;&amp; apt-get install -y curl\nENTRYPOINT [\"curl\"]\nCMD [\"https://exemple.fr\"]\n</code></pre> <p>Comportements : Bash<pre><code># Utilise le CMD par d\u00e9faut\ndocker run monapp\n# Affiche le contenu de https://exemple.fr\n\n# Remplace le CMD\ndocker run monapp https://autre.fr\n# Affiche le contenu de https://autre.fr\n\n# Remplace l'ENTRYPOINT (rare)\ndocker run --entrypoint echo monapp \"bonjour\"\n# Affiche: bonjour\n</code></pre></p>"},{"location":"_projects/_formation-docker/docker-chap03/#cas-dusage-pratique","title":"Cas d'usage pratique","text":"<p>Pour une application d'analyse de logs :</p> Docker<pre><code>FROM python:3.11-slim\nWORKDIR /app\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\nCOPY app.py .\n\nENTRYPOINT [\"python\", \"app.py\"]\nCMD [\"--help\"]\n</code></pre> <ul> <li><code>docker run monapp</code> : affiche l'aide</li> <li><code>docker run monapp /var/log/app.log</code> : analyse le fichier sp\u00e9cifi\u00e9</li> <li><code>docker run --entrypoint bash monapp</code> : lance un shell pour debug</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap03/#etapes-de-la-construction-dune-image","title":"\ud83c\udfd7\ufe0f \u00c9tapes de la construction d'une image","text":"<p>La construction d'une image Docker suit un processus structur\u00e9 et m\u00e9thodique[1][2]. Comprendre ces \u00e9tapes permet d'optimiser les images et de d\u00e9panner les probl\u00e8mes de construction.</p>"},{"location":"_projects/_formation-docker/docker-chap03/#phase-1-preparation","title":"Phase 1 : Pr\u00e9paration","text":"<p>Avant que Docker n'ex\u00e9cute la premi\u00e8re instruction, il effectue plusieurs op\u00e9rations pr\u00e9liminaires :</p> <ol> <li>Validation du Dockerfile : Docker v\u00e9rifie la syntaxe et la validit\u00e9 du fichier</li> <li>D\u00e9termination du contexte de construction : l'ensemble des fichiers accessible pour les instructions <code>COPY</code> et <code>ADD</code></li> <li>Authentification aupr\u00e8s des registres : si les images de base sont dans des registres priv\u00e9s</li> <li>T\u00e9l\u00e9chargement des images de base : si elles ne sont pas disponibles localement</li> </ol>"},{"location":"_projects/_formation-docker/docker-chap03/#phase-2-execution-des-instructions","title":"Phase 2 : Ex\u00e9cution des instructions","text":"<p>Chaque instruction du Dockerfile cr\u00e9e une couche immuable :</p> Docker<pre><code>FROM ubuntu:20.04              # Couche 1 : image de base\nRUN apt-get update             # Couche 2 : modifications syst\u00e8me\nRUN apt-get install -y curl    # Couche 3 : installation de curl\nCOPY app.py /app/              # Couche 4 : copie du code\nWORKDIR /app                   # Couche 5 : changement de r\u00e9pertoire\nCMD [\"python\", \"app.py\"]       # Couche 6 : configuration (pas de nouvelle couche)\n</code></pre> <p>\u00c0 chaque \u00e9tape, Docker : 1. Lance un conteneur temporaire \u00e0 partir de la couche pr\u00e9c\u00e9dente 2. Ex\u00e9cute l'instruction 3. Cr\u00e9e une nouvelle couche immuable avec un ID unique 4. Arr\u00eate le conteneur temporaire</p>"},{"location":"_projects/_formation-docker/docker-chap03/#phase-3-systeme-de-cache","title":"Phase 3 : Syst\u00e8me de cache","text":"<p>Docker m\u00e9morise chaque couche pour acc\u00e9l\u00e9rer les reconstructions ult\u00e9rieures. L'algorithme fonctionne ainsi :</p> Text Only<pre><code>Si la couche N a d\u00e9j\u00e0 \u00e9t\u00e9 construite pr\u00e9c\u00e9demment\n  \u279c Utiliser le cache\nSinon\n  \u279c Construire la couche et l'ajouter au cache\n</code></pre> <p>Invalidation du cache : si une instruction change ou si les fichiers copi\u00e9s changent, toutes les couches suivantes sont reconstruites.</p>"},{"location":"_projects/_formation-docker/docker-chap03/#exemple-doptimisation-du-cache","title":"Exemple d'optimisation du cache","text":"<p>\u274c Mauvais : le cache est invalid\u00e9 \u00e0 chaque changement de code</p> Docker<pre><code>FROM node:22-alpine\nWORKDIR /app\nCOPY . .                    # Copie tout, y compris node_modules\nRUN npm install\nCMD [\"npm\", \"start\"]\n</code></pre> <p>\u2705 Bon : le cache est pr\u00e9serv\u00e9 tant que les d\u00e9pendances ne changent pas</p> Docker<pre><code>FROM node:22-alpine\nWORKDIR /app\nCOPY package*.json ./       # Copie uniquement les manifests\nRUN npm install\nCOPY . .                    # Copie le reste\nCMD [\"npm\", \"start\"]\n</code></pre> <p>Avec cette structure : - Si seul <code>app.js</code> change : seule la derni\u00e8re couche <code>COPY</code> est reconstruite (rapide) - Si <code>package.json</code> change : <code>npm install</code> et les couches suivantes sont reconstruites</p>"},{"location":"_projects/_formation-docker/docker-chap03/#phase-4-finalisation","title":"Phase 4 : Finalisation","text":"<p>Une fois toutes les instructions ex\u00e9cut\u00e9es :</p> <ol> <li>Cr\u00e9ation de l'image finale : fusion de toutes les couches en une seule image</li> <li>Assignation des m\u00e9tadonn\u00e9es : tags, labels, configuration</li> <li>Stockage en local : l'image est enregistr\u00e9e dans <code>/var/lib/docker/</code></li> </ol>"},{"location":"_projects/_formation-docker/docker-chap03/#instructions-from-workdir-run-copy-et-add","title":"\ud83d\udccb Instructions FROM, WORKDIR, RUN, COPY et ADD","text":"<p>Ces instructions forment l'ossature de tout Dockerfile. Elles sont pr\u00e9sentes dans presque toutes les images.</p>"},{"location":"_projects/_formation-docker/docker-chap03/#instruction-from","title":"Instruction FROM","text":"<p>FROM initialise une nouvelle \u00e9tape de construction et d\u00e9finit l'image de base[1][2]. C'est la premi\u00e8re instruction obligatoire de tout Dockerfile (sauf en cas de multi-stage sans \u00e9tape pr\u00e9c\u00e9dente).</p> Docker<pre><code>FROM [--platform=&lt;platform&gt;] &lt;image&gt;[:&lt;tag&gt;] [AS &lt;name&gt;]\n</code></pre> <p>Exemples :</p> Docker<pre><code># Image Linux minimale bas\u00e9e sur Alpine (\u2248 5 MB)\nFROM alpine:3.19\n\n# Image Node.js compl\u00e8te (\u2248 900 MB)\nFROM node:22\n\n# Image .NET sur Ubuntu\nFROM mcr.microsoft.com/dotnet/runtime:8.0-ubuntu-22.04\n\n# Image multi-architecture\nFROM --platform=linux/amd64 ubuntu:22.04\n\n# Nommage d'\u00e9tape pour multi-stage\nFROM ubuntu:22.04 AS builder\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap03/#considerations-lors-du-choix-dune-image-de-base","title":"Consid\u00e9rations lors du choix d'une image de base","text":"Crit\u00e8re Lightweight (Alpine) Full-Featured (Ubuntu) Specialized (Python) Taille 5-15 MB 50-150 MB 300-500 MB Vitesse de d\u00e9marrage Tr\u00e8s rapide Rapide Rapide Disponibilit\u00e9 des packages Limit\u00e9e Compl\u00e8te Compl\u00e8te Stabilit\u00e9 Excellente Excellente Tr\u00e8s bonne Cas d'usage id\u00e9al Microservices, Edge Outils g\u00e9n\u00e9riques Applications Python"},{"location":"_projects/_formation-docker/docker-chap03/#instruction-workdir","title":"Instruction WORKDIR","text":"<p>WORKDIR d\u00e9finit le r\u00e9pertoire de travail pour toutes les instructions suivantes (<code>RUN</code>, <code>COPY</code>, <code>ADD</code>, <code>CMD</code>, <code>ENTRYPOINT</code>)[2].</p> Docker<pre><code>WORKDIR &lt;chemin&gt;\n</code></pre> Docker<pre><code>FROM ubuntu:22.04\n\nWORKDIR /app\n# \u00c9quivalent \u00e0: cd /app\n\nCOPY application.py .\n# Copie dans /app/application.py (non /application.py)\n\nRUN chmod +x application.py\n# Ex\u00e9cute dans le contexte de /app\n\nCMD [\"./application.py\"]\n# Lance depuis /app\n</code></pre> <p>Avantages de WORKDIR :</p> <ul> <li>Meilleure lisibilit\u00e9 du Dockerfile</li> <li>Isolation des fichiers de l'application</li> <li>\u00c9vite les chemins absolus complexes</li> <li>Peut \u00eatre chang\u00e9 plusieurs fois pour organiser logiquement les \u00e9tapes</li> </ul> Docker<pre><code>FROM ubuntu:22.04\n\nWORKDIR /src\nCOPY . .\nRUN ./build.sh\n\nWORKDIR /app\nCOPY --from=builder /src/output ./\nCMD [\"./app\"]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap03/#instruction-run","title":"Instruction RUN","text":"<p>RUN ex\u00e9cute une commande dans le conteneur et enregistre les modifications dans une nouvelle couche[1][2].</p> Docker<pre><code>RUN &lt;commande&gt;              # Forme shell\nRUN [\"ex\u00e9cutable\", \"param1\", \"param2\"]  # Forme exec\n</code></pre> Docker<pre><code>FROM ubuntu:22.04\n\n# Forme shell\nRUN apt-get update &amp;&amp; apt-get install -y curl wget\n\n# Forme exec\nRUN [\"apt-get\", \"install\", \"-y\", \"curl\"]\n\n# Commandes multiples (combinaison recommand\u00e9e)\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y \\\n        curl \\\n        wget \\\n        git \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap03/#optimisation-des-instructions-run","title":"Optimisation des instructions RUN","text":"Docker<pre><code># \u274c Mauvais : 3 couches cr\u00e9\u00e9es, cache invalidable \u00e0 chaque \u00e9tape\nRUN apt-get update\nRUN apt-get install -y curl\nRUN apt-get install -y wget\n\n# \u2705 Bon : 1 couche cr\u00e9\u00e9e, cache plus stable\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y \\\n        curl \\\n        wget &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n</code></pre> <p>Le nettoyage de <code>/var/lib/apt/lists/</code> est crucial car elle contient les m\u00e9tadonn\u00e9es de packages et occupe des centaines de MB.</p>"},{"location":"_projects/_formation-docker/docker-chap03/#instruction-copy","title":"Instruction COPY","text":"<p>COPY transf\u00e8re des fichiers et r\u00e9pertoires de la machine h\u00f4te vers le conteneur[1][2]. Contrairement \u00e0 <code>ADD</code>, elle n'effectue aucun traitement.</p> Docker<pre><code>COPY [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt; &lt;dest&gt;\n</code></pre> Docker<pre><code>FROM node:22-alpine\n\nWORKDIR /app\n\n# Copier un fichier unique\nCOPY package.json .\n\n# Copier plusieurs fichiers avec glob\nCOPY src/*.js ./src/\nCOPY config.* ./\n\n# Copier un r\u00e9pertoire entier\nCOPY . .\n\n# Copier avec changement de propri\u00e9taire\nCOPY --chown=node:node app.js /app/\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap03/#utilisation-avancee-de-copy","title":"Utilisation avanc\u00e9e de COPY","text":"Docker<pre><code>FROM ubuntu:22.04 AS builder\n\nWORKDIR /build\nCOPY . .\nRUN ./build.sh\n\n# Nouvelle \u00e9tape : copier uniquement les artefacts n\u00e9cessaires\nFROM ubuntu:22.04\n\nCOPY --from=builder /build/dist /app/\n\n# R\u00e9sultat : image finale sans code source ou d\u00e9pendances de build\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap03/#instruction-add","title":"Instruction ADD","text":"<p>ADD est similaire \u00e0 <code>COPY</code> mais effectue des op\u00e9rations suppl\u00e9mentaires :</p> Docker<pre><code>ADD [--chown=&lt;user&gt;:&lt;group&gt;] &lt;src&gt; &lt;dest&gt;\n</code></pre> <p>Capacit\u00e9s sp\u00e9ciales : - D\u00e9compresse automatiquement les archives (<code>.tar</code>, <code>.tar.gz</code>, <code>.zip</code>) - T\u00e9l\u00e9charge des ressources \u00e0 partir d'URLs</p> Docker<pre><code>FROM ubuntu:22.04\n\n# T\u00e9l\u00e9charger et extraire une archive\nADD https://github.com/projet/archive/v1.0.tar.gz /tmp/\n\n# Extraire une archive locale\nADD app.tar.gz /app/\n</code></pre> <p>Recommandations :</p> <ul> <li>Pr\u00e9f\u00e9rer <code>COPY</code> pour la plupart des cas</li> <li>Utiliser <code>ADD</code> uniquement si la d\u00e9compression automatique est b\u00e9n\u00e9fique</li> <li>\u00c9viter les URLs remotes, privil\u00e9gier les ressources locales ou pr\u00e9-t\u00e9l\u00e9charg\u00e9es pour la reproductibilit\u00e9</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap03/#introduction-au-dockerfile","title":"\ud83d\udcd6 Introduction au Dockerfile","text":""},{"location":"_projects/_formation-docker/docker-chap03/#anatomie-generale-dun-dockerfile","title":"Anatomie g\u00e9n\u00e9rale d'un Dockerfile","text":"<p>Un Dockerfile suit une structure logique qui optimise le cache et la maintenabilit\u00e9 :</p> Docker<pre><code># 1. \u00c9tape de base\nFROM ubuntu:22.04\n\n# 2. M\u00e9tadonn\u00e9es\nLABEL maintainer=\"equipe@exemple.fr\" \\\n      version=\"1.0\" \\\n      description=\"Application web exemple\"\n\n# 3. Variables d'environnement\nENV NODE_ENV=production \\\n    PORT=3000\n\n# 4. Installation des d\u00e9pendances syst\u00e8me\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y \\\n        curl \\\n        git \\\n    &amp;&amp; rm -rf /var/lib/apt/lists/*\n\n# 5. Configuration de l'utilisateur (s\u00e9curit\u00e9)\nRUN useradd -m -u 1000 appuser\n\n# 6. R\u00e9pertoire de travail\nWORKDIR /app\n\n# 7. Copie du code (apr\u00e8s les modifications de base)\nCOPY package*.json ./\nRUN npm install --production\n\n# 8. Copie du code source\nCOPY . .\n\n# 9. Changement de propri\u00e9t\u00e9\nRUN chown -R appuser:appuser /app\n\n# 10. Changement d'utilisateur (s\u00e9curit\u00e9)\nUSER appuser\n\n# 11. Exposition de ports\nEXPOSE 3000\n\n# 12. Point d'entr\u00e9e\nENTRYPOINT [\"node\"]\nCMD [\"server.js\"]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap03/#structure-multi-etapes","title":"Structure multi-\u00e9tapes","text":"<p>Les builds multi-\u00e9tapes permettent de r\u00e9duire drastiquement la taille finale :</p> Docker<pre><code># \u00c9tape 1: Build\nFROM golang:1.21 AS builder\n\nWORKDIR /src\nCOPY . .\nRUN CGO_ENABLED=0 go build -o app\n\n# \u00c9tape 2: Runtime (image finale)\nFROM alpine:3.19\n\nCOPY --from=builder /src/app /app/\nENTRYPOINT [\"/app\"]\n</code></pre> <p>R\u00e9sultat : l'image finale contient uniquement le binaire compil\u00e9 (~10 MB), sans toutes les d\u00e9pendances de build (Go SDK, sources, etc.).</p>"},{"location":"_projects/_formation-docker/docker-chap03/#fichier-dockerignore","title":"Fichier .dockerignore","text":"<p>Optimise le contexte de construction en excluant les fichiers inutiles :</p> Text Only<pre><code># .dockerignore\n.git\n.gitignore\nnode_modules\nnpm-debug.log\n.env\n.vscode\n.DS_Store\n*.md\ndist/\nbuild/\n</code></pre> <p>Cela r\u00e9duit significativement la taille du contexte transmis au daemon Docker.</p>"},{"location":"_projects/_formation-docker/docker-chap03/#instructions-arg-env-label-et-commande-inspect","title":"\ud83c\udff7\ufe0f Instructions ARG, ENV, LABEL et commande Inspect","text":"<p>Ces instructions g\u00e8rent les m\u00e9tadonn\u00e9es et la configuration de l'image et des conteneurs.</p>"},{"location":"_projects/_formation-docker/docker-chap03/#instruction-arg","title":"Instruction ARG","text":"<p>ARG d\u00e9finit les variables de construction qui ne sont disponibles que durant la cr\u00e9ation de l'image (pas dans les conteneurs en ex\u00e9cution)[2].</p> Docker<pre><code>ARG &lt;nom&gt;=&lt;valeur_par_d\u00e9faut&gt;\n</code></pre> Docker<pre><code>FROM ubuntu:22.04\n\nARG VERSION=1.0\nARG BUILD_DATE\n\nRUN echo \"Version: $VERSION\"\nRUN echo \"Date de build: $BUILD_DATE\"\n\n# ARG n'existe plus \u00e0 l'ex\u00e9cution\nRUN echo $VERSION  # Affiche vide si pas fourni\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap03/#utilisation-lors-du-build","title":"Utilisation lors du build","text":"Bash<pre><code># Utiliser les valeurs par d\u00e9faut\ndocker build -t monapp .\n\n# Surcharger les variables\ndocker build -t monapp:2.0 \\\n    --build-arg VERSION=2.0 \\\n    --build-arg BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ') \\\n    .\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap03/#instruction-env","title":"Instruction ENV","text":"<p>ENV d\u00e9finit les variables d'environnement disponibles \u00e0 la fois durant le build et dans les conteneurs en ex\u00e9cution[2].</p> Docker<pre><code>ENV &lt;cl\u00e9&gt;=&lt;valeur&gt;\nENV &lt;cl\u00e9&gt; &lt;valeur&gt;\n</code></pre> Docker<pre><code>FROM ubuntu:22.04\n\nENV NODE_ENV=production\nENV PORT 3000\nENV DATABASE_URL=postgresql://localhost/mydb\n\n# Les variables ENV h\u00e9ritent des valeurs pr\u00e9c\u00e9dentes\nENV PATH=\"/app/bin:$PATH\"\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap03/#comparaison-arg-vs-env","title":"Comparaison ARG vs ENV","text":"Aspect ARG ENV Disponible au build \u2705 Oui \u2705 Oui Disponible au runtime \u274c Non \u2705 Oui Dans l'image \u274c Non \u2705 Oui Cas d'usage Tokens, URLs de ressources Configuration, chemins Modifiable au runtime N/A \u2705 Via <code>-e</code>"},{"location":"_projects/_formation-docker/docker-chap03/#instruction-label","title":"Instruction LABEL","text":"<p>LABEL ajoute des m\u00e9tadonn\u00e9es \u00e0 l'image pour faciliter l'organisation et la recherche[2].</p> Docker<pre><code>LABEL &lt;cl\u00e9&gt;=&lt;valeur&gt; &lt;cl\u00e9&gt;=&lt;valeur&gt; ...\n</code></pre> Docker<pre><code>FROM ubuntu:22.04\n\nLABEL maintainer=\"equipe@exemple.fr\"\nLABEL version=\"1.0.0\"\nLABEL description=\"Application web de gestion de projets\"\nLABEL org.opencontainers.image.source=\"https://github.com/exemple/app\"\nLABEL org.opencontainers.image.documentation=\"https://docs.exemple.fr\"\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap03/#conventions-standardisees","title":"Conventions standardis\u00e9es","text":"<p>Il existe des conventions officielles (OCI Image Spec) :</p> Docker<pre><code>LABEL org.opencontainers.image.authors=\"equipe@exemple.fr\"\nLABEL org.opencontainers.image.created=\"2025-01-15T10:30:00Z\"\nLABEL org.opencontainers.image.description=\"Application de gestion\"\nLABEL org.opencontainers.image.documentation=\"https://docs.exemple.fr\"\nLABEL org.opencontainers.image.licenses=\"MIT\"\nLABEL org.opencontainers.image.revision=\"abc123def456\"\nLABEL org.opencontainers.image.source=\"https://github.com/exemple/app\"\nLABEL org.opencontainers.image.title=\"App Manager\"\nLABEL org.opencontainers.image.url=\"https://exemple.fr\"\nLABEL org.opencontainers.image.vendor=\"Exemple Inc\"\nLABEL org.opencontainers.image.version=\"1.0.0\"\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap03/#commande-docker-inspect","title":"Commande Docker Inspect","text":"<p>docker inspect affiche les informations d\u00e9taill\u00e9es sur une image ou un conteneur, y compris tous les labels, variables d'environnement et autres m\u00e9tadonn\u00e9es.</p> Bash<pre><code>docker inspect &lt;image|conteneur&gt;\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap03/#inspection-dune-image","title":"Inspection d'une image","text":"Bash<pre><code># Afficher toutes les informations en JSON\ndocker inspect monapp:1.0\n\n# Extraire des champs sp\u00e9cifiques\ndocker inspect --format='{{.Config.Env}}' monapp:1.0\ndocker inspect --format='{{.Config.Labels}}' monapp:1.0\ndocker inspect --format='{{.Config.Cmd}}' monapp:1.0\ndocker inspect --format='{{.RootFS.Layers}}' monapp:1.0\n</code></pre> <p>Exemple de sortie structur\u00e9e :</p> JSON<pre><code>{\n  \"Id\": \"sha256:abc123...\",\n  \"RepoTags\": [\"monapp:1.0\"],\n  \"Config\": {\n    \"Env\": [\n      \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin\",\n      \"NODE_ENV=production\",\n      \"PORT=3000\"\n    ],\n    \"Labels\": {\n      \"maintainer\": \"equipe@exemple.fr\",\n      \"version\": \"1.0.0\"\n    },\n    \"Cmd\": [\"node\", \"server.js\"],\n    \"Entrypoint\": null,\n    \"WorkingDir\": \"/app\"\n  },\n  \"RootFS\": {\n    \"Type\": \"layers\",\n    \"Layers\": [\n      \"sha256:layer1...\",\n      \"sha256:layer2...\",\n      \"sha256:layer3...\"\n    ]\n  }\n}\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap03/#inspection-dun-conteneur-en-execution","title":"Inspection d'un conteneur en ex\u00e9cution","text":"Bash<pre><code># Afficher toutes les informations\ndocker inspect webserver\n\n# Format humain pour les variables d'environnement\ndocker inspect --format='{{range .Config.Env}}{{println .}}{{end}}' webserver\n\n# Afficher les ports mapp\u00e9s\ndocker inspect --format='{{json .NetworkSettings.Ports}}' webserver\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap03/#exemple-complet-application-nodejs","title":"\ud83d\udd27 Exemple complet : Application Node.js","text":"<p>Pour int\u00e9grer tous les concepts, voici un exemple de Dockerfile production-ready :</p> Docker<pre><code># Multi-\u00e9tape : build\nFROM node:22-alpine AS builder\n\nWORKDIR /src\n\nARG NODE_ENV=production\nENV NODE_ENV=$NODE_ENV\n\n# Copier les manifests\nCOPY package*.json ./\n\n# Installer les d\u00e9pendances (y compris devDependencies pour le build)\nRUN npm ci\n\n# Copier le code source\nCOPY . .\n\n# Build si n\u00e9cessaire (TypeScript, bundling, etc.)\nRUN npm run build\n\n# Multi-\u00e9tape : runtime\nFROM node:22-alpine\n\n# M\u00e9tadonn\u00e9es\nLABEL maintainer=\"equipe@exemple.fr\" \\\n      version=\"1.0.0\" \\\n      description=\"API Node.js\"\n\n# Variables d'environnement\nENV NODE_ENV=production \\\n    PORT=3000\n\n# Installation des d\u00e9pendances de runtime uniquement\nWORKDIR /app\n\nCOPY package*.json ./\nRUN npm ci --only=production &amp;&amp; npm cache clean --force\n\n# Copier l'application build\u00e9e\nCOPY --from=builder /src/dist ./dist\n\n# S\u00e9curit\u00e9 : utiliser un utilisateur non-root\nRUN addgroup -g 1000 node &amp;&amp; \\\n    adduser -D -u 1000 -G node node\n\nUSER node\n\n# Configuration des ports\nEXPOSE 3000\n\n# Healthcheck\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n    CMD node -e \"require('http').get('http://localhost:3000/health', (r) =&gt; {if (r.statusCode !== 200) throw new Error(r.statusCode)})\"\n\n# Point d'entr\u00e9e\nENTRYPOINT [\"node\"]\nCMD [\"dist/server.js\"]\n</code></pre> <p>Points cl\u00e9s : - Deux \u00e9tapes : build isol\u00e9, runtime minimal - ARG pour les variables de build - ENV pour la configuration runtime - Utilisateur non-root pour la s\u00e9curit\u00e9 - LABEL pour les m\u00e9tadonn\u00e9es - HEALTHCHECK pour la supervision</p>"},{"location":"_projects/_formation-docker/docker-chap03/#optimisations-et-meilleures-pratiques","title":"\ud83d\udcca Optimisations et meilleures pratiques","text":""},{"location":"_projects/_formation-docker/docker-chap03/#reduction-de-la-taille-dimage","title":"R\u00e9duction de la taille d'image","text":"Docker<pre><code># \u274c 450 MB\nFROM ubuntu:22.04\nRUN apt-get update &amp;&amp; apt-get install -y python3 python3-pip\nRUN pip install requests beautifulsoup4\nCOPY app.py .\nCMD [\"python3\", \"app.py\"]\n\n# \u2705 180 MB\nFROM python:3.11-slim\nRUN pip install --no-cache-dir requests beautifulsoup4\nCOPY app.py /app/\nWORKDIR /app\nCMD [\"python3\", \"app.py\"]\n\n# \u2705\u2705 60 MB (avec d\u00e9pendances uniquement)\nFROM python:3.11-alpine\nRUN pip install --no-cache-dir requests beautifulsoup4\nCOPY app.py /app/\nWORKDIR /app\nCMD [\"python3\", \"app.py\"]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap03/#optimisation-du-cache-de-construction","title":"Optimisation du cache de construction","text":"Docker<pre><code># Placer les d\u00e9pendances statiques en premier\nCOPY package*.json ./\nRUN npm ci --only=production\n\n# Puis le code fr\u00e9quemment modifi\u00e9\nCOPY . .\n</code></pre> <p>Cela garantit que les d\u00e9pendances ne sont r\u00e9install\u00e9es que si <code>package.json</code> change.</p>"},{"location":"_projects/_formation-docker/docker-chap03/#securite-des-images","title":"S\u00e9curit\u00e9 des images","text":"Docker<pre><code>FROM alpine:3.19\n\n# Cr\u00e9er un utilisateur non-root\nRUN addgroup -g 1000 appuser &amp;&amp; \\\n    adduser -D -u 1000 -G appuser appuser\n\nWORKDIR /app\nCOPY --chown=appuser:appuser . .\n\nUSER appuser\n\nEXPOSE 8080\nCMD [\"./app\"]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap03/#conclusion","title":"Conclusion","text":"<p>La ma\u00eetrise de la cr\u00e9ation d'images Docker passe par la compr\u00e9hension profonde des concepts suivants :</p> <ol> <li>Architecture en couches : chaque instruction cr\u00e9e une couche immuable</li> <li>Syst\u00e8me de cache : optimiser l'ordre des instructions pour b\u00e9n\u00e9ficier du cache</li> <li>M\u00e9tadonn\u00e9es : utiliser ARG, ENV, LABEL pour documenter et configurer</li> <li>Multi-\u00e9tapes : s\u00e9parer la phase de build de la phase runtime</li> <li>S\u00e9curit\u00e9 : utiliser des utilisateurs non-root et minimiser les couches</li> <li>Maintenabilit\u00e9 : suivre les conventions et documenter avec des labels</li> </ol> <p>Ces pratiques permettent de cr\u00e9er des images Docker efficaces, reproductibles et s\u00e9curis\u00e9es pour les environnements de production.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-docker/docker-chap04/","title":"Citations","text":"<ul> <li>https://www.nutrient.io/blog/docker-import-export-vs-load-save/</li> <li>https://docs.docker.com/reference/cli/docker/image/save/</li> <li>https://forums.docker.com/t/docker-image-load-vs-import/147979</li> <li>https://docker-community-leaders.github.io/community/handbooks/docker101/beginners/saving-images-as-tar/</li> <li>https://gist.github.com/2c2be0b66695f987bf22</li> <li>https://forums.docker.com/t/docker-save-load-performance/9245</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap04/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 267</li> <li>completion_tokens: 8859</li> <li>total_tokens: 9126</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.133, 'request_cost': 0.006, 'total_cost': 0.14}</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap04/#content","title":"Content","text":""},{"location":"_projects/_formation-docker/docker-chap04/#chapitre-4-trouver-et-partager-des-images-docker","title":"\ud83d\udce6 Chapitre 4 : Trouver et Partager des Images Docker","text":""},{"location":"_projects/_formation-docker/docker-chap04/#introduction-au-partage-dimages-docker","title":"\ud83c\udfaf Introduction au Partage d'Images Docker","text":"<p>Le partage et la distribution d'images Docker constituent un \u00e9l\u00e9ment central de l'\u00e9cosyst\u00e8me Docker. La capacit\u00e9 \u00e0 exporter, importer, sauvegarder et charger des images permet aux d\u00e9veloppeurs et aux \u00e9quipes d'infrastructure de collaborer efficacement, de maintenir des caches de construction et de g\u00e9rer les d\u00e9pendances sans d\u00e9pendre constamment d'une connexion r\u00e9seau vers des registres distants.</p> <p>Cette section explore en d\u00e9tail les diff\u00e9rentes m\u00e9thodes de gestion des images Docker, en distinguant clairement les commandes qui op\u00e8rent sur les images de celles qui manipulent les conteneurs. La compr\u00e9hension de ces distinctions s'av\u00e8re cruciale pour optimiser les workflows de d\u00e9ploiement et de maintenance.</p>"},{"location":"_projects/_formation-docker/docker-chap04/#presentation-de-docker-hub","title":"\ud83c\udf10 Pr\u00e9sentation de Docker Hub","text":""},{"location":"_projects/_formation-docker/docker-chap04/#quest-ce-que-docker-hub","title":"Qu'est-ce que Docker Hub ?","text":"<p>Docker Hub repr\u00e9sente le registre public par d\u00e9faut de Docker, fonctionnant comme un r\u00e9f\u00e9rentiel centralis\u00e9 pour stocker, partager et g\u00e9rer les images Docker. Cette plateforme offre une infrastructure compl\u00e8te permettant aux d\u00e9veloppeurs et aux organisations de mettre \u00e0 disposition leurs images conteneuris\u00e9es aupr\u00e8s de la communaut\u00e9 mondiale ou en acc\u00e8s restreint.</p>"},{"location":"_projects/_formation-docker/docker-chap04/#architecture-et-fonctionnalites-principales","title":"Architecture et Fonctionnalit\u00e9s Principales","text":"<p>Docker Hub fonctionne selon une architecture client-serveur o\u00f9 les images sont organis\u00e9es en registres. Chaque image peut poss\u00e9der plusieurs versions, identifi\u00e9es par des balises (tags). La plateforme supporte :</p> <ul> <li>Registres Publics : Accessibles \u00e0 tous sans authentification</li> <li>Registres Priv\u00e9s : Accessibles uniquement aux utilisateurs autoris\u00e9s</li> <li>Organisations : Permettant une gestion collaborative d'images</li> <li>Automatisation : Int\u00e9gration avec les d\u00e9p\u00f4ts Git pour des constructions automatiques</li> <li>Analyse de S\u00e9curit\u00e9 : D\u00e9tection de vuln\u00e9rabilit\u00e9s dans les images</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap04/#authentification-et-acces","title":"Authentification et Acc\u00e8s","text":"<p>La connexion \u00e0 Docker Hub s'effectue via la ligne de commande avec la commande suivante :</p> Bash<pre><code>docker login\n</code></pre> <p>Cette commande invite l'utilisateur \u00e0 entrer son nom d'utilisateur et son mot de passe Docker Hub. Une fois authentifi\u00e9, les identifiants sont stock\u00e9s localement, permettant de pousser et de tirer des images priv\u00e9es.</p>"},{"location":"_projects/_formation-docker/docker-chap04/#organisation-des-images","title":"Organisation des Images","text":"<p>Sur Docker Hub, les images sont organis\u00e9es selon une nomenclature sp\u00e9cifique :</p> Text Only<pre><code>[REGISTRE]/[NAMESPACE]/[NOM_IMAGE]:[TAG]\n</code></pre> <p>Par exemple : - <code>docker.io/library/ubuntu:22.04</code> pour une image officielle - <code>docker.io/monnom/monappli:v1.0</code> pour une image personnelle - <code>docker.io/monentreprise/backend:latest</code> pour une image organisationnelle</p>"},{"location":"_projects/_formation-docker/docker-chap04/#recherche-et-decouverte-dimages","title":"Recherche et D\u00e9couverte d'Images","text":"<p>La recherche d'images se r\u00e9alise via :</p> Bash<pre><code>docker search nginx\n</code></pre> <p>Cette commande retourne une liste des images disponibles correspondant \u00e0 la requ\u00eate, avec les m\u00e9tadonn\u00e9es associ\u00e9es telles que : - Le nombre de pulls (t\u00e9l\u00e9chargements) - Le statut \"OFFICIAL\" pour les images certifi\u00e9es - La description courte de l'image</p>"},{"location":"_projects/_formation-docker/docker-chap04/#images-officielles-et-verifiees","title":"Images Officielles et V\u00e9rifi\u00e9es","text":"<p>Docker Hub propose des images officielles, maintenues par des \u00e9quipes d'experts et v\u00e9rifi\u00e9es pour leur qualit\u00e9 et leur s\u00e9curit\u00e9. Ces images b\u00e9n\u00e9ficient d'une maintenance r\u00e9guli\u00e8re, de mises \u00e0 jour de s\u00e9curit\u00e9 et de documentation compl\u00e8te. Les organisations peuvent \u00e9galement obtenir le statut de \"Verified Publisher\" en d\u00e9montrant leur engagement envers la qualit\u00e9.</p>"},{"location":"_projects/_formation-docker/docker-chap04/#les-commandes-export-et-import","title":"\ud83d\udd04 Les Commandes export et import","text":""},{"location":"_projects/_formation-docker/docker-chap04/#principes-fondamentaux","title":"Principes Fondamentaux","text":"<p>Les commandes <code>export</code> et <code>import</code> op\u00e8rent sp\u00e9cifiquement sur les conteneurs, non sur les images. Alors qu'une image repr\u00e9sente un mod\u00e8le ou une configuration, un conteneur constitue une instance en cours d'ex\u00e9cution cr\u00e9\u00e9e \u00e0 partir de cette image.[1] La compr\u00e9hension de cette distinction s'av\u00e8re essentielle pour utiliser correctement ces commandes.</p> <p>La commande <code>export</code> g\u00e9n\u00e8re une capture du syst\u00e8me de fichiers d'un conteneur, comparable \u00e0 un snapshot du disque dur de ce conteneur. Inversement, la commande <code>import</code> prend ce syst\u00e8me de fichiers et le transforme en une nouvelle image Docker utilisable.[1]</p>"},{"location":"_projects/_formation-docker/docker-chap04/#fonctionnement-de-docker-export","title":"Fonctionnement de docker export","text":""},{"location":"_projects/_formation-docker/docker-chap04/#definition-et-utilite","title":"D\u00e9finition et Utilit\u00e9","text":"<p><code>docker export</code> exporte le syst\u00e8me de fichiers entier d'un conteneur sous la forme d'une archive TAR. Cette op\u00e9ration capture l'\u00e9tat actuel du conteneur, qu'il soit en cours d'ex\u00e9cution ou arr\u00eat\u00e9.[1] L'archive r\u00e9sultante contient tous les fichiers et r\u00e9pertoires pr\u00e9sents dans le conteneur, aplatis en une structure de fichiers unique.</p>"},{"location":"_projects/_formation-docker/docker-chap04/#syntaxe-et-utilisation","title":"Syntaxe et Utilisation","text":"Bash<pre><code>docker export CONTENEUR &gt; archive.tar\n</code></pre> <p>ou avec l'option <code>--output</code> :</p> Bash<pre><code>docker export --output archive.tar CONTENEUR\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#exemple-pratique-complet","title":"Exemple Pratique Complet","text":"<p>Consid\u00e9rons le sc\u00e9nario suivant : il est n\u00e9cessaire de capturer l'\u00e9tat d'un conteneur nginx apr\u00e8s y avoir effectu\u00e9 des modifications personnalis\u00e9es.</p> Bash<pre><code># Cr\u00e9er et lancer un conteneur nginx\ndocker run -d --name mon-nginx nginx:latest\n\n# Effectuer des modifications dans le conteneur (exemple simplifi\u00e9)\ndocker exec mon-nginx bash -c \"echo 'Configuration personnalis\u00e9e' &gt; /usr/share/nginx/html/config.txt\"\n\n# Exporter le conteneur\ndocker export mon-nginx &gt; nginx-custom.tar\n\n# V\u00e9rifier la taille du fichier\nls -lh nginx-custom.tar\n</code></pre> <p>Le fichier g\u00e9n\u00e9r\u00e9 contient une snapshot compl\u00e8te du syst\u00e8me de fichiers du conteneur. Pour examiner son contenu :</p> Bash<pre><code># Lister les fichiers contenus dans l'archive\ntar -tf nginx-custom.tar | head -20\n\n# Extraire l'archive pour inspection\nmkdir extracted-fs\ntar -xf nginx-custom.tar -C extracted-fs\nls extracted-fs\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#fonctionnement-de-docker-import","title":"Fonctionnement de docker import","text":""},{"location":"_projects/_formation-docker/docker-chap04/#definition-et-utilite_1","title":"D\u00e9finition et Utilit\u00e9","text":"<p><code>docker import</code> effectue l'op\u00e9ration inverse : elle prend une archive TAR (g\u00e9n\u00e9ralement cr\u00e9\u00e9e par <code>export</code>) et l'importe en tant que nouvelle image Docker.[1] L'image r\u00e9sultante est aplatie, ce qui signifie qu'elle ne conserve qu'une seule couche, contrairement aux images construites via des Dockerfiles qui poss\u00e8dent plusieurs couches.</p>"},{"location":"_projects/_formation-docker/docker-chap04/#syntaxe-et-utilisation_1","title":"Syntaxe et Utilisation","text":"Bash<pre><code>docker import [OPTIONS] TAR_FILE [REPOSITORY[:TAG]]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#exemple-pratique-complet_1","title":"Exemple Pratique Complet","text":"<p>Reprenant l'exemple pr\u00e9c\u00e9dent, l'archive peut maintenant \u00eatre import\u00e9e en tant qu'image :</p> Bash<pre><code># Importer l'archive en tant que nouvelle image\ndocker import nginx-custom.tar ma-nginx-personnalisee:v1.0\n\n# V\u00e9rifier que l'image a \u00e9t\u00e9 cr\u00e9\u00e9e\ndocker images | grep ma-nginx-personnalisee\n\n# Lancer un conteneur \u00e0 partir de cette nouvelle image\ndocker run -d --name conteneur-nginx ma-nginx-personnalisee:v1.0 nginx -g \"daemon off;\"\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#modele-de-donnees-export-vs-import","title":"Mod\u00e8le de Donn\u00e9es : Export vs Import","text":"Aspect D\u00e9tail Source Conteneur en ex\u00e9cution ou arr\u00eat\u00e9 R\u00e9sultat Archive TAR aplatie M\u00e9tadonn\u00e9es Tr\u00e8s limit\u00e9es, perdues lors de l'export Couches Une seule couche (aplatissement) Historique Compl\u00e8tement perdu Taille G\u00e9n\u00e9ralement plus compacte qu'avec <code>save</code> Vitesse G\u00e9n\u00e9ralement plus rapide en raison du streaming Utilisation D\u00e9bogage, snapshots, images de base personnalis\u00e9es"},{"location":"_projects/_formation-docker/docker-chap04/#modifications-de-metadonnees-avec-docker-import","title":"Modifications de M\u00e9tadonn\u00e9es avec docker import","text":"<p>Bien que les m\u00e9tadonn\u00e9es soient perdues lors de l'export, la commande <code>import</code> permet d'ajouter certaines m\u00e9tadonn\u00e9es via l'option <code>--change</code> :</p> Bash<pre><code>docker import --change 'ENTRYPOINT [\"/bin/sh\"]' \\\n              --change 'ENV APP_ENV=production' \\\n              nginx-custom.tar ma-nginx-modifiee:v1.0\n</code></pre> <p>Les modifications possibles incluent : - <code>ENTRYPOINT</code> : Point d'entr\u00e9e du conteneur - <code>ENV</code> : Variables d'environnement - <code>EXPOSE</code> : Ports expos\u00e9s - <code>WORKDIR</code> : R\u00e9pertoire de travail</p>"},{"location":"_projects/_formation-docker/docker-chap04/#cas-dusage-recommandes-pour-exportimport","title":"Cas d'Usage Recommand\u00e9s pour Export/Import","text":""},{"location":"_projects/_formation-docker/docker-chap04/#debogage-de-conteneurs","title":"D\u00e9bogage de Conteneurs","text":"<p>Lorsqu'un conteneur produit un comportement inattendu, exporter son \u00e9tat permet une inspection d\u00e9taill\u00e9e hors ligne :</p> Bash<pre><code># Conteneur en erreur\ndocker export conteneur-defaillant &gt; debug.tar\n\n# Inspection hors ligne du syst\u00e8me de fichiers\ntar -tf debug.tar | grep -i erreur\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#creation-dimages-de-base-personnalisees","title":"Cr\u00e9ation d'Images de Base Personnalis\u00e9es","text":"<p>Certains workflows n\u00e9cessitent une image de base avec un syst\u00e8me de fichiers personnalis\u00e9. Un conteneur modifi\u00e9 peut \u00eatre export\u00e9 puis import\u00e9 en tant qu'image de base :</p> Bash<pre><code># Cr\u00e9er une image de base minimale personnalis\u00e9e\ndocker run -d --name base-system alpine:latest\ndocker exec base-system sh -c \"apk add --no-cache git curl\"\ndocker export base-system &gt; base-personnalisee.tar\ndocker import base-personnalisee.tar ma-base:1.0\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#archivage-et-backup-de-conteneurs","title":"Archivage et Backup de Conteneurs","text":"<p>Bien que non recommand\u00e9 pour la production, exporter un conteneur permet de cr\u00e9er une sauvegarde brute de son syst\u00e8me de fichiers :</p> Bash<pre><code># Backup de conteneur\ndocker export conteneur-important &gt; backup-$(date +%Y%m%d).tar\n\n# Compression pour \u00e9conomiser l'espace\ngzip backup-*.tar\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#limitations-et-considerations-importantes","title":"Limitations et Consid\u00e9rations Importantes","text":"<p>Volumes Non Inclus : Les volumes Docker (nomm\u00e9s ou anonymes) r\u00e9sident en dehors du syst\u00e8me de fichiers racine du conteneur et ne sont donc pas inclus dans l'export.[1] Pour inclure les donn\u00e9es de volumes, il est n\u00e9cessaire de les copier dans le conteneur avant l'export :</p> Bash<pre><code># Copier les donn\u00e9es d'un volume dans le conteneur\ndocker cp ma-donnee:/volume-data /tmp/donnees-locales\ndocker exec -w /tmp mon-conteneur cp -r donnees-locales /conteneur-donnees\n\n# Puis exporter\ndocker export mon-conteneur &gt; conteneur-avec-donnees.tar\n</code></pre> <p>Perte de M\u00e9tadonn\u00e9es Importantes : L'export entra\u00eene la perte d\u00e9finitive de l'historique de construction, des labels, des variables d'environnement et des configurations d'ENTRYPOINT/CMD h\u00e9rit\u00e9es de l'image de base. Ceci rend moins \u00e9vidente la provenance et la configuration originale du conteneur.[1]</p> <p>Pertes de Performance : Bien que rapide en ex\u00e9cution, l'export peut consommer beaucoup de ressources I/O, particuli\u00e8rement pour les conteneurs avec de grands volumes de donn\u00e9es.</p>"},{"location":"_projects/_formation-docker/docker-chap04/#les-commandes-save-et-load","title":"\ud83d\udce4 Les Commandes save et load","text":""},{"location":"_projects/_formation-docker/docker-chap04/#principes-fondamentaux-et-distinction-critique","title":"Principes Fondamentaux et Distinction Critique","text":"<p>Alors que <code>export</code> et <code>import</code> manipulent des conteneurs, <code>save</code> et <code>load</code> op\u00e8rent exclusivement sur les images Docker.[1] Cette distinction fondamentale d\u00e9termine quand et comment utiliser chaque paire de commandes.</p> <p>La commande <code>save</code> enregistre une ou plusieurs images Docker compl\u00e8tes, incluant toutes les couches, les m\u00e9tadonn\u00e9es, l'historique de construction et les balises. L'archive r\u00e9sultante peut \u00eatre transport\u00e9e et reconstruite pr\u00e9cis\u00e9ment en utilisant <code>load</code>, sans d\u00e9pendre d'un registre distant.[1]</p>"},{"location":"_projects/_formation-docker/docker-chap04/#fonctionnement-de-docker-save","title":"Fonctionnement de docker save","text":""},{"location":"_projects/_formation-docker/docker-chap04/#definition-et-caracteristiques","title":"D\u00e9finition et Caract\u00e9ristiques","text":"<p><code>docker save</code> g\u00e9n\u00e8re une archive TAR contenant une ou plusieurs images Docker. Contrairement \u00e0 <code>export</code>, cette commande pr\u00e9serve toute la structure en couches, les m\u00e9tadonn\u00e9es compl\u00e8tes et l'historique de construction. Cette pr\u00e9servation s'av\u00e8re cruciale pour maintenir la fid\u00e9lit\u00e9 de l'image et optimiser les futures op\u00e9rations de construction.[1]</p>"},{"location":"_projects/_formation-docker/docker-chap04/#syntaxe-et-options","title":"Syntaxe et Options","text":"Bash<pre><code>docker save [OPTIONS] IMAGE [IMAGE...]\n</code></pre> <p>Options courantes : - <code>-o, --output</code> : \u00c9crire dans un fichier au lieu de STDOUT - <code>--platform</code> : Sauvegarder uniquement une variante de plateforme sp\u00e9cifique</p>"},{"location":"_projects/_formation-docker/docker-chap04/#exemples-pratiques-detailles","title":"Exemples Pratiques D\u00e9taill\u00e9s","text":"<p>Exemple 1 : Sauvegarde Simple</p> Bash<pre><code># Sauvegarder une image unique\ndocker save busybox &gt; busybox.tar\n\n# V\u00e9rifier la taille\nls -sh busybox.tar\n# R\u00e9sultat typique : 2.7M busybox.tar\n</code></pre> <p>Exemple 2 : Sauvegarde avec Option --output</p> Bash<pre><code># \u00c9quivalent \u00e0 la redirection STDOUT\ndocker save --output nginx.tar nginx\n\n# V\u00e9rifier le contenu\ntar -tf nginx.tar | head -20\n</code></pre> <p>Exemple 3 : Compression avec gzip</p> Bash<pre><code># R\u00e9duire la taille de l'archive\ndocker save myimage:latest | gzip &gt; myimage_latest.tar.gz\n\n# V\u00e9rifier la r\u00e9duction d'espace\nls -lh myimage_latest.tar*\n</code></pre> <p>Exemple 4 : Sauvegarde S\u00e9lective de Tags</p> Bash<pre><code># Sauvegarder plusieurs tags sp\u00e9cifiques\ndocker save -o ubuntu-multi.tar ubuntu:focal ubuntu:jammy ubuntu:latest\n\n# Chaque tag est pr\u00e9serv\u00e9 avec son historique complet\n</code></pre> <p>Exemple 5 : Sauvegarde pour Plateforme Sp\u00e9cifique</p> Bash<pre><code># Sauvegarder uniquement la variante ARM64\ndocker save --platform linux/arm64 alpine:latest &gt; alpine-arm64.tar\n\n# Sauvegarder pour architecture s390x\ndocker save --platform linux/s390x ubuntu:22.04 &gt; ubuntu-s390x.tar\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#structure-interne-dune-archive-save","title":"Structure Interne d'une Archive save","text":"<p>Une archive cr\u00e9\u00e9e par <code>docker save</code> suit une structure sp\u00e9cifique :</p> Text Only<pre><code>archive.tar\n\u251c\u2500\u2500 manifest.json          # M\u00e9tadonn\u00e9es d'index\n\u251c\u2500\u2500 repositories           # Informations de nommage\n\u251c\u2500\u2500 [hash]/                # R\u00e9pertoires de couches\n\u2502   \u251c\u2500\u2500 layer.tar          # Donn\u00e9es de couche\n\u2502   \u251c\u2500\u2500 json               # M\u00e9tadonn\u00e9es de couche\n\u2502   \u2514\u2500\u2500 VERSION            # Version du format\n\u2514\u2500\u2500 ...\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#fonctionnement-de-docker-load","title":"Fonctionnement de docker load","text":""},{"location":"_projects/_formation-docker/docker-chap04/#definition-et-utilite_2","title":"D\u00e9finition et Utilit\u00e9","text":"<p><code>docker load</code> importe une ou plusieurs images \u00e0 partir d'une archive TAR cr\u00e9\u00e9e pr\u00e9c\u00e9demment par <code>docker save</code>. Cette op\u00e9ration reconstruit les images avec toutes leurs couches, leurs m\u00e9tadonn\u00e9es et leurs tags intacts.[1] Aucune connexion r\u00e9seau vers un registre n'est requise.</p>"},{"location":"_projects/_formation-docker/docker-chap04/#syntaxe-et-utilisation_2","title":"Syntaxe et Utilisation","text":"Bash<pre><code>docker load [OPTIONS] &lt; archive.tar\n</code></pre> <p>ou avec l'option <code>--input</code> :</p> Bash<pre><code>docker load --input archive.tar\n</code></pre> <p>ou avec les options courtes :</p> Bash<pre><code>docker load -i archive.tar\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#exemples-pratiques-detailles_1","title":"Exemples Pratiques D\u00e9taill\u00e9s","text":"<p>Exemple 1 : Chargement Simple</p> Bash<pre><code># Charger une image depuis une archive\ndocker load &lt; busybox.tar\n\n# R\u00e9sultat attendu :\n# Loaded image: busybox:latest\n\n# V\u00e9rifier que l'image est disponible\ndocker images busybox\n</code></pre> <p>Exemple 2 : Chargement avec Redirection de Fichier</p> Bash<pre><code># Alternative avec option explicite\ndocker load --input nginx.tar\n\n# L'image nginx:latest est maintenant disponible localement\ndocker run -d -p 80:80 nginx\n</code></pre> <p>Exemple 3 : Chargement depuis Archive Compress\u00e9e</p> Bash<pre><code># D\u00e9compresser et charger en une seule commande\ndocker load &lt; myimage_latest.tar.gz\n\n# Ou utiliser gzip explicitement\ngunzip -c myimage_latest.tar.gz | docker load\n</code></pre> <p>Exemple 4 : Chargement d'Images Multiples</p> Bash<pre><code># L'archive contient plusieurs images (plusieurs tags)\ndocker load &lt; ubuntu-multi.tar\n\n# R\u00e9sultat :\n# Loaded image: ubuntu:focal\n# Loaded image: ubuntu:jammy\n# Loaded image: ubuntu:latest\n\n# V\u00e9rifier tous les tags charg\u00e9s\ndocker images ubuntu\n</code></pre> <p>Exemple 5 : Affichage D\u00e9taill\u00e9 du Chargement</p> Bash<pre><code># Afficher les d\u00e9tails de chaque couche en cours de chargement\ndocker load --input archive.tar 2&gt;&amp;1 | tee load-output.log\n\n# Inspecter le journal pour d\u00e9boguer les probl\u00e8mes\ncat load-output.log\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#comparaison-detaillee-saveload-vs-exportimport","title":"Comparaison D\u00e9taill\u00e9e : save/load vs export/import","text":"Crit\u00e8re docker save/load docker export/import Cible Images Docker Conteneurs Docker Pr\u00e9servation des Couches \u2705 Toutes les couches \u274c Aplatie en une seule Historique \u2705 Pr\u00e9serv\u00e9 compl\u00e8tement \u274c Perdu M\u00e9tadonn\u00e9es \u2705 CMD, ENTRYPOINT, ENV, labels, ports \u26a0\ufe0f Partiellement, via --change Taille de l'Archive \u2705 Plus grande mais compressible \u2705 G\u00e9n\u00e9ralement plus compacte Vitesse d'Export \u23f1\ufe0f Plus lent en raison de la complexit\u00e9 \u23f1\ufe0f G\u00e9n\u00e9ralement plus rapide Fid\u00e9lit\u00e9 \u2705 Copie exacte et tra\u00e7able \u274c Perte significative de contexte Cas d'Usage Id\u00e9al Partage, cache, builds reproductibles D\u00e9bogage, snapshots temporaires Inclusion de Volumes \u274c Non inclus \u274c Non inclus Int\u00e9grit\u00e9 de Signature \u2705 Peut \u00eatre v\u00e9rifi\u00e9e \u274c Non applicable"},{"location":"_projects/_formation-docker/docker-chap04/#cas-dusage-recommandes-pour-saveload","title":"Cas d'Usage Recommand\u00e9s pour save/load","text":""},{"location":"_projects/_formation-docker/docker-chap04/#1-transfert-dimages-entre-systemes-isoles","title":"1. Transfert d'Images Entre Syst\u00e8mes Isol\u00e9s","text":"<p>Dans les environnements sans acc\u00e8s \u00e0 Internet ou sans registre priv\u00e9 disponible, <code>save</code> et <code>load</code> permettent le transfert s\u00e9curis\u00e9 d'images :</p> Bash<pre><code># Sur la machine source (avec Internet)\ndocker save myapp:1.0 | gzip &gt; myapp-1.0.tar.gz\n\n# Transf\u00e9rer le fichier (USB, SCP, email, etc.)\nscp myapp-1.0.tar.gz user@machine-isolee:/tmp/\n\n# Sur la machine cible (isol\u00e9e)\ndocker load &lt; /tmp/myapp-1.0.tar.gz\n\n# V\u00e9rifier et lancer\ndocker images myapp\ndocker run -d myapp:1.0\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#2-caching-de-layers-pour-cicd","title":"2. Caching de Layers pour CI/CD","text":"<p>Dans les pipelines d'int\u00e9gration continue, les couches pr\u00e9c\u00e9demment construites peuvent \u00eatre sauvegard\u00e9es et recharg\u00e9es pour acc\u00e9l\u00e9rer les constructions futures :</p> Bash<pre><code># Pipeline \u00e9tape 1 : Construire et sauvegarder\ndocker build -t mon-app:latest .\ndocker save mon-app:latest &gt; cache.tar\n\n# Stocker cache.tar dans l'artefact de CI\n\n# Pipeline \u00e9tape 2 : Charger le cache et construire \u00e0 partir de celui-ci\ndocker load &lt; cache.tar\n\n# Les couches sont maintenant en cache local\ndocker build -t mon-app:latest --cache-from mon-app:latest .\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#3-archivage-a-long-terme","title":"3. Archivage \u00e0 Long Terme","text":"<p>Pour les images critiques, <code>save</code> cr\u00e9e des archives archivables :</p> Bash<pre><code># Cr\u00e9er une archive dat\u00e9e avec m\u00e9tadonn\u00e9es\nARCHIVE_DATE=$(date +%Y%m%d_%H%M%S)\ndocker save critical-app:v1.0 | gzip &gt; critical-app-v1.0_${ARCHIVE_DATE}.tar.gz\n\n# Stocker le fichier en s\u00e9curit\u00e9\nmv critical-app-*.tar.gz /mnt/archive/docker-images/\n\n# Cr\u00e9er un fichier manifest pour tra\u00e7abilit\u00e9\necho \"Image: critical-app:v1.0\" &gt; /mnt/archive/docker-images/critical-app-v1.0_manifest.txt\ndocker inspect critical-app:v1.0 &gt;&gt; /mnt/archive/docker-images/critical-app-v1.0_manifest.txt\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#4-distribution-dimages-hors-reseau","title":"4. Distribution d'Images Hors R\u00e9seau","text":"<p>Les \u00e9quipes distribuant des images \u00e0 des clients sans connexion r\u00e9seau utilisent couramment cette approche :</p> Bash<pre><code># Pr\u00e9parer un bundle d'images\ndocker save \\\n  appbase:1.0 \\\n  app-frontend:1.0 \\\n  app-backend:1.0 \\\n  app-database:1.0 | gzip &gt; app-bundle-v1.0.tar.gz\n\n# Le client re\u00e7oit un seul fichier facilement transportable\nls -lh app-bundle-v1.0.tar.gz\n# -rw-r--r-- 1 user user 256M app-bundle-v1.0.tar.gz\n\n# Installation chez le client\ndocker load &lt; app-bundle-v1.0.tar.gz\n\n# Tous les composants sont disponibles\ndocker images app-*\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#5-builds-reproductibles-et-deterministes","title":"5. Builds Reproductibles et D\u00e9terministes","text":"<p>Les projets n\u00e9cessitant une reproductibilit\u00e9 absolue (compliance, audit) utilisent <code>save</code> pour garantir que les builds futurs utilisent exactement les m\u00eames couches :</p> Bash<pre><code># Build v1.0\ndocker build -t myapp:v1.0 .\ndocker save myapp:v1.0 &gt; v1.0-exact.tar\n\n# Ann\u00e9es plus tard, d\u00e9pendances disparus du registre\n# Mais la reconstruction exacte reste possible\ndocker load &lt; v1.0-exact.tar\n\n# V\u00e9rifier l'int\u00e9grit\u00e9 du hash\ndocker inspect myapp:v1.0 --format='{{.Id}}'\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#optimisation-des-performances-pour-saveload","title":"Optimisation des Performances pour save/load","text":""},{"location":"_projects/_formation-docker/docker-chap04/#compression-efficace","title":"Compression Efficace","text":"Bash<pre><code># gzip : Compression standard\ndocker save myimage:latest | gzip -9 &gt; image.tar.gz\n\n# pigz : Gzip parall\u00e9lis\u00e9 (plus rapide)\ndocker save myimage:latest | pigz -9 &gt; image.tar.gz\n\n# bzip2 : Compression plus efficace mais plus lent\ndocker save myimage:latest | bzip2 -9 &gt; image.tar.bz2\n\n# Comparaison de tailles\nls -lh image.tar*\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#gestion-darchives-de-grande-taille","title":"Gestion d'Archives de Grande Taille","text":"<p>Pour les images d\u00e9passant plusieurs gigaoctets, des strat\u00e9gies de division s'appliquent :</p> Bash<pre><code># Sauvegarder une grande image\ndocker save huge-app:latest &gt; huge-app.tar\n\n# Diviser en fichiers de 2GB\nsplit -b 2G huge-app.tar huge-app-part_\n\n# Transf\u00e9rer les parties individuellement\n# ...\n\n# R\u00e9assembler sur la machine cible\ncat huge-app-part_* &gt; huge-app.tar\n\n# Charger normalement\ndocker load &lt; huge-app.tar\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#utilisation-de-buildkit-cache-exporters-approche-moderne","title":"Utilisation de BuildKit Cache Exporters (Approche Moderne)","text":"<p>Docker BuildKit offre une alternative plus performante aux simples commandes <code>save</code>/<code>load</code> :</p> Bash<pre><code># Exporter le cache de build localement\ndocker buildx build \\\n  --cache-to type=local,dest=/tmp/buildkit-cache \\\n  --output type=image,push=false \\\n  -t myapp:latest .\n\n# Importer le cache pour les builds suivants\ndocker buildx build \\\n  --cache-from type=local,src=/tmp/buildkit-cache \\\n  -t myapp:latest .\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#considerations-de-securite","title":"Consid\u00e9rations de S\u00e9curit\u00e9","text":""},{"location":"_projects/_formation-docker/docker-chap04/#integrite-des-archives","title":"Int\u00e9grit\u00e9 des Archives","text":"Bash<pre><code># G\u00e9n\u00e9rer un hash pour v\u00e9rifier l'int\u00e9grit\u00e9\ndocker save myimage:latest | tee myimage.tar | sha256sum &gt; myimage.tar.sha256\n\n# V\u00e9rifier l'int\u00e9grit\u00e9 apr\u00e8s transfert\nsha256sum -c myimage.tar.sha256\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#chiffrement-des-archives","title":"Chiffrement des Archives","text":"<p>Pour les environnements sensibles, chiffrer les archives avant transfert :</p> Bash<pre><code># Chiffrer avec gpg\ndocker save myimage:latest | gzip | gpg --symmetric &gt; image.tar.gz.gpg\n\n# D\u00e9chiffrer et charger\ngpg --decrypt image.tar.gz.gpg | gunzip | docker load\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#publier-ses-images-sur-docker-hub","title":"\ud83d\udce4 Publier ses Images sur Docker Hub","text":""},{"location":"_projects/_formation-docker/docker-chap04/#architecture-de-publication","title":"Architecture de Publication","text":"<p>La publication d'images sur Docker Hub suit un processus strictement d\u00e9fini. L'image doit d'abord exister localement, \u00eatre correctement nomm\u00e9e et tagu\u00e9e selon la convention Docker Hub, puis \u00eatre envoy\u00e9e via la commande <code>docker push</code>.</p>"},{"location":"_projects/_formation-docker/docker-chap04/#preparation-de-limage","title":"Pr\u00e9paration de l'Image","text":""},{"location":"_projects/_formation-docker/docker-chap04/#convention-de-nommage","title":"Convention de Nommage","text":"<p>Pour publier une image sur Docker Hub, elle doit suivre cette nomenclature :</p> Text Only<pre><code>docker.io/[USERNAME]/[IMAGE_NAME]:[TAG]\n</code></pre> <p>O\u00f9 : - docker.io : Registre par d\u00e9faut (peut \u00eatre omis) - USERNAME : Nom d'utilisateur Docker Hub - IMAGE_NAME : Nom descriptif de l'image - TAG : Version ou identificateur (par d\u00e9faut \"latest\" si omis)</p>"},{"location":"_projects/_formation-docker/docker-chap04/#exemple-de-nommage-correct","title":"Exemple de Nommage Correct","text":"Bash<pre><code># Nommer l'image correctement\ndocker tag myapp:v1.0 montextura/myapp:v1.0\ndocker tag myapp:v1.0 montextura/myapp:latest\n\n# V\u00e9rifier les tags\ndocker images montextura/myapp\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#authentification-a-docker-hub","title":"Authentification \u00e0 Docker Hub","text":""},{"location":"_projects/_formation-docker/docker-chap04/#connexion-initiale","title":"Connexion Initiale","text":"Bash<pre><code># Se connecter \u00e0 Docker Hub\ndocker login\n\n# Invite interactive :\n# Login with your Docker ID to push and pull images from Docker Hub.\n# If you don't have a Docker ID, head over to https://hub.docker.com to create one.\n# Username: montextura\n# Password: \u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\u2022\n# Login Succeeded\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#stockage-des-identifiants","title":"Stockage des Identifiants","text":"<p>Les identifiants sont stock\u00e9s localement dans <code>~/.docker/config.json</code> (avec chiffrement basique selon la configuration du syst\u00e8me).</p> Bash<pre><code># Afficher la configuration (\u00e0 titre informatif uniquement)\ncat ~/.docker/config.json | jq '.auths'\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#processus-de-push","title":"Processus de Push","text":""},{"location":"_projects/_formation-docker/docker-chap04/#commande-de-base","title":"Commande de Base","text":"Bash<pre><code>docker push montextura/myapp:v1.0\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#sortie-detaillee-du-push","title":"Sortie D\u00e9taill\u00e9e du Push","text":"Text Only<pre><code>The push refers to repository [docker.io/montextura/myapp]\na1d0c7532dbe: Pushed  \ne02e811e3d8d: Pushed\n2731eed57b6d: Pushed\nv1.0: digest: sha256:abc123... size: 1234\n</code></pre> <p>Chaque ligne repr\u00e9sente une couche compress\u00e9e et envoy\u00e9e vers le registre.</p>"},{"location":"_projects/_formation-docker/docker-chap04/#push-complet-avec-tous-les-tags","title":"Push Complet avec Tous les Tags","text":"Bash<pre><code># Pousser sp\u00e9cifiquement plusieurs tags\ndocker push montextura/myapp:v1.0\ndocker push montextura/myapp:latest\n\n# Ou une syntaxe alternative (d\u00e9pend de la version Docker)\ndocker push montextura/myapp --all-tags\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#gestion-des-registres-prives","title":"Gestion des Registres Priv\u00e9s","text":""},{"location":"_projects/_formation-docker/docker-chap04/#creation-dun-registre-prive","title":"Cr\u00e9ation d'un Registre Priv\u00e9","text":"<p>Pour maintenir un contr\u00f4le total, les organisations h\u00e9bergent souvent des registres priv\u00e9s :</p> Bash<pre><code># D\u00e9marrer un registre priv\u00e9 local\ndocker run -d \\\n  -p 5000:5000 \\\n  --name local-registry \\\n  -v registry-data:/var/lib/registry \\\n  registry:latest\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#push-vers-un-registre-prive","title":"Push vers un Registre Priv\u00e9","text":"Bash<pre><code># Retagger pour le registre priv\u00e9\ndocker tag montextura/myapp:v1.0 localhost:5000/myapp:v1.0\n\n# Pousser vers le registre local\ndocker push localhost:5000/myapp:v1.0\n\n# Pull depuis le registre local\ndocker pull localhost:5000/myapp:v1.0\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#registre-prive-distant","title":"Registre Priv\u00e9 Distant","text":"Bash<pre><code># Retagger pour un registre priv\u00e9 distant\ndocker tag montextura/myapp:v1.0 registry.example.com:5000/myapp:v1.0\n\n# Se connecter au registre priv\u00e9\ndocker login registry.example.com:5000\n\n# Pousser\ndocker push registry.example.com:5000/myapp:v1.0\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#creation-dimages-publiables","title":"Cr\u00e9ation d'Images Publiables","text":""},{"location":"_projects/_formation-docker/docker-chap04/#dockerfile-optimal-pour-publication","title":"Dockerfile Optimal pour Publication","text":"Docker<pre><code># Utiliser une image de base officielle l\u00e9g\u00e8re\nFROM alpine:3.18\n\n# D\u00e9finir des m\u00e9tadonn\u00e9es\nLABEL maintainer=\"contact@example.com\"\nLABEL version=\"1.0\"\nLABEL description=\"Application exemple\"\n\n# Installer les d\u00e9pendances\nRUN apk add --no-cache \\\n    python3 \\\n    py3-pip\n\n# Copier le code\nWORKDIR /app\nCOPY . .\n\n# Installer les d\u00e9pendances Python\nRUN pip install --no-cache-dir -r requirements.txt\n\n# Exposer le port\nEXPOSE 5000\n\n# D\u00e9finir l'entrypoint\nENTRYPOINT [\"python3\"]\nCMD [\"app.py\"]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#build-et-publication-complete","title":"Build et Publication Compl\u00e8te","text":"Bash<pre><code># Construire avec le tag appropri\u00e9\ndocker build -t montextura/myapp:v1.0 .\n\n# Ajouter le tag latest\ndocker tag montextura/myapp:v1.0 montextura/myapp:latest\n\n# Se connecter\ndocker login\n\n# Pousser les deux versions\ndocker push montextura/myapp:v1.0\ndocker push montextura/myapp:latest\n\n# V\u00e9rifier sur Docker Hub\n# https://hub.docker.com/r/montextura/myapp\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#gestion-des-versions-et-tags","title":"Gestion des Versions et Tags","text":""},{"location":"_projects/_formation-docker/docker-chap04/#strategies-de-tagging","title":"Strat\u00e9gies de Tagging","text":"<p>Semantic Versioning</p> Bash<pre><code># Version majeure.mineure.patch\ndocker build -t montextura/myapp:1.0.0 .\ndocker build -t montextura/myapp:1.0 .\ndocker build -t montextura/myapp:1 .\ndocker build -t montextura/myapp:latest .\n\n# Pousser tous les tags\ndocker push montextura/myapp:1.0.0\ndocker push montextura/myapp:1.0\ndocker push montextura/myapp:1\ndocker push montextura/myapp:latest\n</code></pre> <p>Date-based Tagging</p> Bash<pre><code>DATE=$(date +%Y%m%d)\ndocker build -t montextura/myapp:${DATE} .\ndocker push montextura/myapp:${DATE}\n</code></pre> <p>Build Number Tagging (pour CI/CD)</p> Bash<pre><code>BUILD_ID=$CI_PIPELINE_ID\ndocker build -t montextura/myapp:build-${BUILD_ID} .\ndocker push montextura/myapp:build-${BUILD_ID}\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#gestion-des-permissions-et-acces","title":"Gestion des Permissions et Acc\u00e8s","text":""},{"location":"_projects/_formation-docker/docker-chap04/#creer-une-equipe-sur-docker-hub","title":"Cr\u00e9er une \u00c9quipe sur Docker Hub","text":"Bash<pre><code># Via l'interface web Docker Hub :\n# 1. Se connecter \u00e0 hub.docker.com\n# 2. Aller \u00e0 \"Teams and Organizations\"\n# 3. Cr\u00e9er une nouvelle \u00e9quipe\n# 4. Ajouter les membres\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#partager-une-image-privee","title":"Partager une Image Priv\u00e9e","text":"Bash<pre><code># Via l'interface web :\n# 1. Aller au d\u00e9p\u00f4t de l'image\n# 2. Aller \u00e0 \"Permissions\"\n# 3. Ajouter les utilisateurs ou \u00e9quipes\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#automatisation-des-publications","title":"Automatisation des Publications","text":""},{"location":"_projects/_formation-docker/docker-chap04/#utiliser-un-personal-access-token","title":"Utiliser un Personal Access Token","text":"Bash<pre><code># Cr\u00e9er un PAT sur Docker Hub (interface web)\n# Utiliser le PAT dans les pipelines CI/CD\n\necho $DOCKER_PAT | docker login -u $DOCKER_USERNAME --password-stdin\n\ndocker push montextura/myapp:v1.0\n\ndocker logout\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#exemple-github-actions","title":"Exemple GitHub Actions","text":"YAML<pre><code>name: Build and Push to Docker Hub\n\non:\n  push:\n    branches: [main]\n    tags: [v*]\n\njobs:\n  build-and-push:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Login to Docker Hub\n        uses: docker/login-action@v2\n        with:\n          username: ${{ secrets.DOCKER_USERNAME }}\n          password: ${{ secrets.DOCKER_PAT }}\n\n      - name: Build and push\n        uses: docker/build-push-action@v4\n        with:\n          context: .\n          push: true\n          tags: montextura/myapp:${{ github.ref_name }}\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#optimisation-des-images-publiees","title":"Optimisation des Images Publi\u00e9es","text":""},{"location":"_projects/_formation-docker/docker-chap04/#reduction-de-la-taille","title":"R\u00e9duction de la Taille","text":"Docker<pre><code># \u274c Mauvaise pratique : image grande\nFROM ubuntu:22.04\nRUN apt-get update &amp;&amp; apt-get install -y build-essential\nCOPY myapp /\nENTRYPOINT [\"/myapp\"]\n\n# \u2705 Bonne pratique : image l\u00e9g\u00e8re\nFROM alpine:3.18\nRUN apk add --no-cache libc6-compat\nCOPY --from=builder /myapp /\nENTRYPOINT [\"/myapp\"]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#build-multi-stage","title":"Build Multi-Stage","text":"Docker<pre><code># Stage 1 : Compilation\nFROM golang:1.21 AS builder\nWORKDIR /build\nCOPY . .\nRUN go build -o myapp .\n\n# Stage 2 : Ex\u00e9cution\nFROM alpine:3.18\nRUN apk add --no-cache ca-certificates\nCOPY --from=builder /build/myapp /\nENTRYPOINT [\"/myapp\"]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#synthese-et-chemins-dapprentissage","title":"\ud83d\udd0d Synth\u00e8se et Chemins d'Apprentissage","text":""},{"location":"_projects/_formation-docker/docker-chap04/#progression-logique-de-lapprentissage","title":"Progression Logique de l'Apprentissage","text":"<p>Le chemin d'apprentissage optimal pour ma\u00eetriser le partage d'images Docker suit une progression logique :</p>"},{"location":"_projects/_formation-docker/docker-chap04/#phase-1-comprehension-des-concepts-fondamentaux","title":"Phase 1 : Compr\u00e9hension des Concepts Fondamentaux","text":"<p>L'apprenant doit d'abord comprendre la distinction fondamentale entre images et conteneurs. Cette distinction sous-tend toutes les commandes de manipulation ult\u00e9rieures. Docker Hub doit \u00eatre explor\u00e9 comme r\u00e9f\u00e9rentiel central, permettant une familiarisation avec l'\u00e9cosyst\u00e8me.</p> Bash<pre><code># Activit\u00e9s de Phase 1\ndocker search nginx\ndocker pull ubuntu:22.04\ndocker images\ndocker run -it ubuntu:22.04 /bin/bash\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#phase-2-maitrise-des-commandes-de-base","title":"Phase 2 : Ma\u00eetrise des Commandes de Base","text":"<p>Une fois les concepts acquis, les commandes <code>save</code>/<code>load</code> doivent \u00eatre pratiqu\u00e9es extensivement. Ces commandes sont plus simples conceptuellement que <code>export</code>/<code>import</code> et constituent les outils les plus couramment utilis\u00e9s.</p> Bash<pre><code># Activit\u00e9s de Phase 2\ndocker save ubuntu:22.04 &gt; ubuntu.tar\ndocker rmi ubuntu:22.04\ndocker load &lt; ubuntu.tar\ndocker save --output nginx.tar nginx:latest\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#phase-3-exploration-des-cas-dusage-specialises","title":"Phase 3 : Exploration des Cas d'Usage Sp\u00e9cialis\u00e9s","text":"<p>Ensuite, les commandes <code>export</code>/<code>import</code> peuvent \u00eatre explor\u00e9es pour comprendre quand et pourquoi les utiliser. Ce stade introduit la complexit\u00e9 de la manipulation des conteneurs et des snapshots.</p> Bash<pre><code># Activit\u00e9s de Phase 3\ndocker run -d --name test-container ubuntu:22.04 sleep 1000\ndocker exec test-container touch /test-file\ndocker export test-container &gt; snapshot.tar\ndocker import snapshot.tar my-snapshot:v1.0\ndocker run my-snapshot:v1.0 ls /test-file\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#phase-4-publication-et-integration","title":"Phase 4 : Publication et Int\u00e9gration","text":"<p>La publication sur Docker Hub consolide tous les concepts pr\u00e9c\u00e9dents. L'apprenant applique ses connaissances pour cr\u00e9er, taguer et distribuer des images.</p> Bash<pre><code># Activit\u00e9s de Phase 4\ndocker build -t montextura/myapp:v1.0 .\ndocker login\ndocker push montextura/myapp:v1.0\ndocker logout\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap04/#tableau-comparatif-complet-des-commandes","title":"Tableau Comparatif Complet des Commandes","text":"Commande Type Source Destination Pr\u00e9servation Utilisation <code>docker save</code> Image Image locale Archive TAR Compl\u00e8te avec couches Transfert, cache, archivage <code>docker load</code> Image Archive TAR Image locale Identique \u00e0 l'original Restauration depuis archive <code>docker export</code> Conteneur Conteneur Archive TAR Syst\u00e8me de fichiers aplati D\u00e9bogage, snapshots <code>docker import</code> Conteneur Archive TAR Nouvelle image Aplatissement en couche unique Cr\u00e9er images de base <code>docker push</code> Image Image locale Registre distant Compl\u00e8te Publication et partage <code>docker pull</code> Image Registre distant Image locale Compl\u00e8te T\u00e9l\u00e9chargement"},{"location":"_projects/_formation-docker/docker-chap04/#reponse-aux-cas-dusage-courants","title":"R\u00e9ponse aux Cas d'Usage Courants","text":"<p>\"Je dois sauvegarder une image pour plus tard\" \u2192 Utilisez <code>docker save</code> + compression</p> <p>\"Je dois d\u00e9boguer un conteneur d\u00e9faillant\" \u2192 Utilisez <code>docker export</code> pour capturer l'\u00e9tat</p> <p>\"Je dois partager mon application avec l'\u00e9quipe\" \u2192 Utilisez <code>docker push</code> vers Docker Hub</p> <p>\"Je dois cr\u00e9er une image personnalis\u00e9e bas\u00e9e sur un conteneur modifi\u00e9\" \u2192 Utilisez <code>docker export</code> + <code>docker import</code></p> <p>\"Je dois transf\u00e9rer des images entre serveurs sans registre\" \u2192 Utilisez <code>docker save</code> + <code>docker load</code></p> <p>\"Je dois cr\u00e9er une base \u00e0 partir d'un conteneur existant\" \u2192 Utilisez <code>docker commit</code> (alternative) ou <code>docker export</code> + <code>docker import</code></p>"},{"location":"_projects/_formation-docker/docker-chap04/#bonnes-pratiques-de-production","title":"Bonnes Pratiques de Production","text":"<p>L'utilisation professionnelle de ces commandes implique l'application de plusieurs principes :</p> <p>Nommage Coh\u00e9rent : Maintenir une convention de nommage stricte facilite la gestion ult\u00e9rieure.</p> <p>Documentation : Accompagner chaque image publi\u00e9e d'une documentation README compl\u00e8te.</p> <p>Tests Avant Publication : V\u00e9rifier syst\u00e9matiquement qu'une image fonctionne correctement avant de la publier.</p> <p>Versioning Strict : \u00c9viter le tag \"latest\" en production, pr\u00e9f\u00e9rer les versions explicites.</p> <p>S\u00e9curit\u00e9 : Scanner les images pour des vuln\u00e9rabilit\u00e9s avant publication.</p> Bash<pre><code># Exemple de workflow complet s\u00e9curis\u00e9\ndocker build -t montextura/myapp:v1.0.1 .\n\n# Tester localement\ndocker run -d --name test montextura/myapp:v1.0.1\ndocker exec test /test-script.sh\ndocker stop test &amp;&amp; docker rm test\n\n# Scanner pour vuln\u00e9rabilit\u00e9s (avec Trivy)\ntrivy image montextura/myapp:v1.0.1\n\n# Publier si OK\ndocker login\ndocker push montextura/myapp:v1.0.1\n\n# Ajouter les tags suppl\u00e9mentaires\ndocker tag montextura/myapp:v1.0.1 montextura/myapp:v1.0\ndocker tag montextura/myapp:v1.0.1 montextura/myapp:latest\ndocker push montextura/myapp:v1.0\ndocker push montextura/myapp:latest\n</code></pre> <p>Cette compr\u00e9hension compl\u00e8te et progressive permet \u00e0 l'apprenant de ma\u00eetriser l'ensemble des outils de gestion d'images Docker et de les appliquer efficacement selon les contextes sp\u00e9cifiques rencontr\u00e9s en pratique.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-docker/docker-chap05/","title":"Citations","text":"<ul> <li>https://www.sfeir.dev/back/dockeriser-une-application-nodejs-pas-a-pas/</li> <li>https://www.youtube.com/watch?v=TRvTtfAloT4</li> <li>https://cours-info.iut-bm.univ-fcomte.fr/upload/supports/S3/web/cot%20serveur/Dockeriser%20une%20application%20Web%20NodeJS.pdf</li> <li>https://www.digitalocean.com/community/tutorials/how-to-build-a-node-js-application-with-docker-quickstart-fr</li> <li>https://docs.docker.com/guides/nodejs/containerize/</li> <li>https://www.hostinger.com/fr/tutoriels/comment-creer-un-conteneur-docker</li> <li>https://snyk.io/fr/blog/10-best-practices-to-containerize-nodejs-web-applications-with-docker/</li> <li>https://www.youtube.com/watch?v=RyvKmOA69oM</li> <li>https://www.stackhero.io/fr-FR/services/Docker/documentations/Node-js</li> <li>https://labex.io/fr/tutorials/docker-how-to-structure-a-dockerfile-for-a-node-js-application-411608</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap05/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 268</li> <li>completion_tokens: 6380</li> <li>total_tokens: 6648</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.096, 'request_cost': 0.006, 'total_cost': 0.103}</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap05/#content","title":"Content","text":""},{"location":"_projects/_formation-docker/docker-chap05/#creer-une-image-docker-pour-un-serveur-nodejs","title":"Cr\u00e9er une image Docker pour un serveur Node.js \ud83d\udc33","text":""},{"location":"_projects/_formation-docker/docker-chap05/#introduction-au-projet","title":"Introduction au projet","text":"<p>La conteneurisation repr\u00e9sente une avanc\u00e9e majeure dans le d\u00e9ploiement d'applications modernes. Docker permet de packager une application Node.js avec toutes ses d\u00e9pendances dans un conteneur isol\u00e9 et portable. Cette approche garantit que l'application fonctionnera de mani\u00e8re identique, quel que soit l'environnement d'ex\u00e9cution : machine locale du d\u00e9veloppeur, serveur de staging ou infrastructure de production.</p> <p>Un serveur Node.js conteneuris\u00e9 offre plusieurs avantages significatifs. Premi\u00e8rement, la coh\u00e9rence entre les environnements de d\u00e9veloppement et de production \u00e9limine les probl\u00e8mes classiques du type \u00ab \u00e7a marche chez moi \u00bb. Deuxi\u00e8mement, la scalabilit\u00e9 devient triviale : un conteneur peut \u00eatre r\u00e9pliqu\u00e9 instantan\u00e9ment sur plusieurs serveurs. Troisi\u00e8mement, la gestion des d\u00e9pendances se simplifie consid\u00e9rablement puisque chaque conteneur dispose de sa propre version de Node.js et des modules npm n\u00e9cessaires.</p> <p>Le flux de travail standard pour conteneuriser une application Node.js suit une progression logique. On commence par d\u00e9finir les instructions de construction dans un Dockerfile, qui d\u00e9crit comment cr\u00e9er l'image. Cette image sert ensuite de mod\u00e8le pour g\u00e9n\u00e9rer des conteneurs ex\u00e9cutables. Chaque conteneur repr\u00e9sente une instance isol\u00e9e de l'application, fonctionnant en arri\u00e8re-plan avec ses propres ressources syst\u00e8me.</p>"},{"location":"_projects/_formation-docker/docker-chap05/#architecture-generale-du-processus","title":"Architecture g\u00e9n\u00e9rale du processus","text":"<p>Le processus de conteneurisation s'articule autour de trois concepts fondamentaux :</p> <p>L'image Docker constitue le mod\u00e8le immuable. Elle contient le syst\u00e8me d'exploitation, l'environnement d'ex\u00e9cution Node.js, les d\u00e9pendances npm et le code source de l'application. Une image Docker se construit une seule fois et peut g\u00e9n\u00e9rer plusieurs conteneurs identiques.</p> <p>Le Dockerfile repr\u00e9sente le fichier de configuration qui d\u00e9finit comment construire l'image. Il contient une s\u00e9rie d'instructions qui sp\u00e9cifient l'image de base, les d\u00e9pendances \u00e0 installer, les fichiers \u00e0 copier et les commandes \u00e0 ex\u00e9cuter.</p> <p>Le conteneur Docker correspond \u00e0 l'instance en cours d'ex\u00e9cution d\u00e9riv\u00e9e d'une image. Chaque conteneur dispose de son propre syst\u00e8me de fichiers, r\u00e9seau et ressources syst\u00e8me, tout en partageant le noyau du syst\u00e8me h\u00f4te.</p>"},{"location":"_projects/_formation-docker/docker-chap05/#creation-du-dockerfile","title":"Cr\u00e9ation du Dockerfile","text":""},{"location":"_projects/_formation-docker/docker-chap05/#structure-fondamentale-dun-dockerfile","title":"Structure fondamentale d'un Dockerfile","text":"<p>Le Dockerfile est un fichier texte sans extension qui \u00e9num\u00e8re les \u00e9tapes de construction de l'image Docker.[1] Chaque ligne du Dockerfile cr\u00e9e une nouvelle couche dans l'image, que Docker met en cache pour optimiser les reconstructions ult\u00e9rieures.[6]</p> <p>Voici un exemple minimal de Dockerfile pour une application Node.js :</p> Docker<pre><code>FROM node:18\n\nWORKDIR /app\n\nCOPY package*.json ./\n\nRUN npm install\n\nCOPY --chown=node:node . .\n\nEXPOSE 3000\n\nENV HOST=0.0.0.0 PORT=3000\n\nCMD [\"node\", \"index.js\"]\n</code></pre> <p>Examinons chaque instruction en d\u00e9tail :</p>"},{"location":"_projects/_formation-docker/docker-chap05/#instruction-from-definir-limage-de-base","title":"Instruction FROM : d\u00e9finir l'image de base","text":"Docker<pre><code>FROM node:18\n</code></pre> <p>L'instruction <code>FROM</code> doit toujours \u00eatre la premi\u00e8re du Dockerfile (\u00e0 l'exception des commentaires et des directives de parser).[2] Elle sp\u00e9cifie l'image de base sur laquelle construire la nouvelle image. Dans cet exemple, on utilise Node.js version 18, qui inclut d\u00e9j\u00e0 Node.js et npm pr\u00e9install\u00e9s.</p> <p>Le choix de l'image de base est crucial pour l'efficacit\u00e9 et la s\u00e9curit\u00e9. Les options principales incluent :</p> <ul> <li><code>node:18</code> : image officielle compl\u00e8te (environ 900 MB)</li> <li><code>node:18-alpine</code> : image all\u00e9g\u00e9e bas\u00e9e sur Alpine Linux (environ 180 MB)</li> <li><code>node:18-slim</code> : version interm\u00e9diaire entre compl\u00e8te et alpine (environ 340 MB)</li> </ul> <p>Les images Alpine offrent des avantages significatifs pour la production. Elles r\u00e9duisent la taille de l'image et diminuent la surface d'attaque en minimisant les composants syst\u00e8me inutiles.</p>"},{"location":"_projects/_formation-docker/docker-chap05/#instruction-workdir-definir-le-repertoire-de-travail","title":"Instruction WORKDIR : d\u00e9finir le r\u00e9pertoire de travail","text":"Docker<pre><code>WORKDIR /app\n</code></pre> <p>Cette instruction \u00e9tablit le r\u00e9pertoire de travail \u00e0 l'int\u00e9rieur du conteneur. Toutes les commandes suivantes (RUN, COPY, CMD, etc.) s'ex\u00e9cutent dans ce contexte. Si le r\u00e9pertoire n'existe pas, Docker le cr\u00e9e automatiquement.</p> <p>L'utilisation de <code>WORKDIR</code> offre plusieurs avantages : elle organise le syst\u00e8me de fichiers du conteneur, elle facilite la compr\u00e9hension du Dockerfile en montrant explicitement o\u00f9 les fichiers se trouvent, et elle pr\u00e9vient les conflits de chemins.</p>"},{"location":"_projects/_formation-docker/docker-chap05/#instructions-copy-transferer-les-fichiers","title":"Instructions COPY : transf\u00e9rer les fichiers","text":"Docker<pre><code>COPY package*.json ./\n</code></pre> <p>Cette premi\u00e8re instruction COPY transf\u00e8re les fichiers <code>package.json</code> et <code>package-lock.json</code> (si pr\u00e9sent) du r\u00e9pertoire local vers le conteneur. L'ast\u00e9risque <code>*</code> agit comme un joker, ce qui rend la commande flexible : elle copie <code>package.json</code> en toute circonstance, et <code>package-lock.json</code> s'il existe.</p> <p>La raison de cette s\u00e9paration en deux \u00e9tapes COPY est strat\u00e9gique. Les d\u00e9pendances npm changent moins fr\u00e9quemment que le code source de l'application. En copiant les fichiers package en premier et en installant les d\u00e9pendances avant de copier le code, on optimise la mise en cache Docker. Si seul le code change, Docker r\u00e9utilise la couche des d\u00e9pendances install\u00e9es, acc\u00e9l\u00e9rant consid\u00e9rablement la reconstruction.</p> Docker<pre><code>COPY --chown=node:node . .\n</code></pre> <p>Cette deuxi\u00e8me instruction COPY transf\u00e8re tous les fichiers restants du r\u00e9pertoire local vers le conteneur. L'option <code>--chown=node:node</code> assigne la propri\u00e9t\u00e9 des fichiers \u00e0 l'utilisateur non-root <code>node</code>, am\u00e9liorant ainsi la s\u00e9curit\u00e9.[4] Cette pratique respecte le principe du moindre privil\u00e8ge en garantissant que l'application ne s'ex\u00e9cute pas en tant que root.</p>"},{"location":"_projects/_formation-docker/docker-chap05/#instruction-run-installer-les-dependances","title":"Instruction RUN : installer les d\u00e9pendances","text":"Docker<pre><code>RUN npm install\n</code></pre> <p>L'instruction <code>RUN</code> ex\u00e9cute des commandes \u00e0 l'int\u00e9rieur du conteneur pendant la construction de l'image. Ici, elle installe les d\u00e9pendances npm sp\u00e9cifi\u00e9es dans <code>package.json</code>. Cette \u00e9tape est cruciale : elle cr\u00e9e une couche contenant tous les modules node_modules, qui seront disponibles lors de l'ex\u00e9cution du conteneur.</p>"},{"location":"_projects/_formation-docker/docker-chap05/#instructions-expose-et-env-configurer-le-conteneur","title":"Instructions EXPOSE et ENV : configurer le conteneur","text":"Docker<pre><code>EXPOSE 3000\n</code></pre> <p>L'instruction <code>EXPOSE</code> documente le port sur lequel l'application \u00e9coute. Elle ne publie pas r\u00e9ellement le port ; elle sert plut\u00f4t de documentation et facilite l'utilisation ult\u00e9rieure de l'option <code>-p</code> dans la commande <code>docker run</code>.</p> Docker<pre><code>ENV HOST=0.0.0.0 PORT=3000\n</code></pre> <p>L'instruction <code>ENV</code> d\u00e9finit des variables d'environnement \u00e0 l'int\u00e9rieur du conteneur. Ici, on configure l'h\u00f4te sur lequel le serveur \u00e9coute (<code>0.0.0.0</code> pour tous les adaptateurs r\u00e9seau) et le port (<code>3000</code>). Ces variables peuvent \u00eatre r\u00e9f\u00e9renc\u00e9es par le code Node.js via <code>process.env</code>.</p>"},{"location":"_projects/_formation-docker/docker-chap05/#instruction-cmd-definir-la-commande-par-defaut","title":"Instruction CMD : d\u00e9finir la commande par d\u00e9faut","text":"Docker<pre><code>CMD [\"node\", \"index.js\"]\n</code></pre> <p>L'instruction <code>CMD</code> sp\u00e9cifie la commande par d\u00e9faut \u00e0 ex\u00e9cuter quand le conteneur d\u00e9marre. Elle doit \u00eatre au format JSON (appel\u00e9 format exec). Cette commande lancera le serveur Node.js en ex\u00e9cutant le fichier <code>index.js</code>.</p>"},{"location":"_projects/_formation-docker/docker-chap05/#exemple-complet-avec-structure-progressive","title":"Exemple complet avec structure progressive","text":"<p>Pour une application Express plus \u00e9labor\u00e9e, voici une structure Dockerfile plus compl\u00e8te :</p> Docker<pre><code># \u00c9tape 1 : Utiliser l'image de base officielle Node.js\nFROM node:18-alpine\n\n# \u00c9tape 2 : D\u00e9finir le r\u00e9pertoire de travail\nWORKDIR /usr/src/app\n\n# \u00c9tape 3 : Copier les fichiers de d\u00e9pendances\nCOPY package*.json ./\n\n# \u00c9tape 4 : Installer les d\u00e9pendances\nRUN npm ci --only=production\n\n# \u00c9tape 5 : Copier le code source\nCOPY --chown=node:node . .\n\n# \u00c9tape 6 : Cr\u00e9er un utilisateur non-root (optionnel mais recommand\u00e9)\nUSER node\n\n# \u00c9tape 7 : Exposer le port\nEXPOSE 8080\n\n# \u00c9tape 8 : D\u00e9finir la sant\u00e9 du conteneur (optionnel)\nHEALTHCHECK --interval=30s --timeout=3s --start-period=5s --retries=3 \\\n  CMD node healthcheck.js\n\n# \u00c9tape 9 : Commande de d\u00e9marrage\nCMD [\"npm\", \"start\"]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#construction-de-limage-docker","title":"Construction de l'image Docker","text":"<p>Une fois le Dockerfile cr\u00e9\u00e9, la construction de l'image utilise la commande <code>docker build</code> :[1]</p> Bash<pre><code>docker build -t sfeir-dev .\n</code></pre> <p>L'option <code>-t</code> sp\u00e9cifie le nom et \u00e9ventuellement le tag de l'image. Le <code>.</code> indique que le contexte de construction est le r\u00e9pertoire courant, o\u00f9 Docker trouve le Dockerfile et tous les fichiers \u00e0 copier.</p> <p>Pour v\u00e9rifier que l'image a \u00e9t\u00e9 correctement construite, on utilise la commande :[1]</p> Bash<pre><code>docker images\n</code></pre> <p>Le r\u00e9sultat affichera les images disponibles localement :</p> Text Only<pre><code>REPOSITORY   TAG      IMAGE ID       CREATED        SIZE\nsfeir-dev    latest   d1b90f727fbc  6 seconds ago   1.1GB\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#utilisation-de-build-arguments","title":"Utilisation de build arguments","text":"<p>Pour rendre les Dockerfile plus flexibles, on peut utiliser les arguments de construction :</p> Docker<pre><code>FROM node:${NODE_VERSION:-18}-alpine\n\nARG APP_PORT=3000\n\nWORKDIR /app\n\nCOPY package*.json ./\n\nRUN npm install\n\nCOPY . .\n\nEXPOSE ${APP_PORT}\n\nCMD [\"node\", \"server.js\"]\n</code></pre> <p>Les arguments se passent lors de la construction :</p> Bash<pre><code>docker build --build-arg NODE_VERSION=20 --build-arg APP_PORT=8080 -t myapp .\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#optimisation-et-dockerignore","title":"Optimisation et .dockerignore","text":""},{"location":"_projects/_formation-docker/docker-chap05/#comprendre-loptimisation-des-images","title":"Comprendre l'optimisation des images","text":"<p>La taille des images Docker affecte directement les temps de d\u00e9ploiement, les ressources disque utilis\u00e9es et les co\u00fbts de transfert r\u00e9seau. Une image non optimis\u00e9e peut facilement d\u00e9passer 1 GB, tandis qu'une image bien con\u00e7ue reste sous 300 MB.[4] L'optimisation repr\u00e9sente donc un enjeu majeur pour la production.</p>"},{"location":"_projects/_formation-docker/docker-chap05/#fichier-dockerignore","title":"Fichier .dockerignore","text":"<p>Le fichier <code>.dockerignore</code> fonctionne de mani\u00e8re similaire \u00e0 <code>.gitignore</code>. Il sp\u00e9cifie les fichiers et r\u00e9pertoires \u00e0 exclure du contexte de construction, r\u00e9duisant ainsi la taille de l'image et acc\u00e9l\u00e9rant le processus de construction.[4]</p> <p>Voici un exemple de <code>.dockerignore</code> appropri\u00e9 pour une application Node.js :</p> Text Only<pre><code>node_modules\nnpm-debug.log\nDockerfile\n.dockerignore\n.git\n.gitignore\nREADME.md\n.env\n.env.local\n.DS_Store\ndist\nbuild\ncoverage\n.npm\n.eslintcache\n.node_repl_history\n*.log\n*.swp\n</code></pre> <p>L'exclusion de <code>node_modules</code> est particuli\u00e8rement importante. Les d\u00e9pendances npm d\u00e9j\u00e0 install\u00e9es localement ne sont pas n\u00e9cessaires puisque <code>RUN npm install</code> les r\u00e9installe dans le conteneur. Leur inclusion inutile augmenterait consid\u00e9rablement la taille du contexte de construction.</p>"},{"location":"_projects/_formation-docker/docker-chap05/#strategies-doptimisation-des-couches","title":"Strat\u00e9gies d'optimisation des couches","text":"<p>Docker met en cache chaque couche cr\u00e9\u00e9e par une instruction du Dockerfile. Comprendre ce m\u00e9canisme de cache permet d'optimiser significativement les temps de reconstruction.[6]</p> <p>Ordre des instructions : les instructions moins fr\u00e9quemment modifi\u00e9es doivent pr\u00e9c\u00e9der les instructions fr\u00e9quemment modifi\u00e9es. Le pattern optimal pour Node.js suit cette structure :</p> Docker<pre><code>FROM node:18-alpine\n\nWORKDIR /app\n\n# Les d\u00e9pendances changent rarement\nCOPY package*.json ./\nRUN npm ci --only=production\n\n# Le code change fr\u00e9quemment\nCOPY . .\n\nEXPOSE 3000\n\nCMD [\"npm\", \"start\"]\n</code></pre> <p>Si le code change mais pas les d\u00e9pendances, Docker r\u00e9utilise la couche contenant <code>node_modules</code>, \u00e9conomisant du temps et des ressources.</p> <p>Multistage builds : cette technique avanc\u00e9e cr\u00e9e une image interm\u00e9diaire pour la compilation, puis copie uniquement les fichiers n\u00e9cessaires dans l'image finale :</p> Docker<pre><code># Stage 1 : Build\nFROM node:18-alpine as builder\n\nWORKDIR /app\n\nCOPY package*.json ./\n\nRUN npm ci\n\nCOPY . .\n\nRUN npm run build\n\n# Stage 2 : Runtime\nFROM node:18-alpine\n\nWORKDIR /app\n\nCOPY package*.json ./\n\nRUN npm ci --only=production\n\nCOPY --from=builder /app/dist ./dist\n\nCMD [\"node\", \"dist/index.js\"]\n</code></pre> <p>Cette approche \u00e9limine les fichiers de d\u00e9veloppement de l'image finale, r\u00e9duisant sa taille consid\u00e9rablement. L'image finale ne contient que le code compil\u00e9 et les d\u00e9pendances de production, pas les d\u00e9pendances de d\u00e9veloppement.</p> <p>Minimiser le nombre de couches : bien que chaque instruction cr\u00e9e une couche, on peut en combiner plusieurs pour r\u00e9duire le nombre total :</p> Docker<pre><code># \u274c Inefficace : plusieurs RUN cr\u00e9ent plusieurs couches\nRUN apt-get update\nRUN apt-get install -y curl\nRUN apt-get install -y git\nRUN apt-get clean\n\n# \u2705 Efficace : un seul RUN cr\u00e9e une seule couche\nRUN apt-get update &amp;&amp; \\\n    apt-get install -y curl git &amp;&amp; \\\n    apt-get clean\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#choix-de-limage-de-base","title":"Choix de l'image de base","text":"<p>La s\u00e9lection de l'image de base a un impact \u00e9norme sur la taille finale et les performances :</p> Image Taille Utilisation <code>node:18</code> ~900 MB D\u00e9veloppement avec tous les outils syst\u00e8me <code>node:18-slim</code> ~340 MB Applications n\u00e9cessitant certains outils syst\u00e8me <code>node:18-alpine</code> ~180 MB Production, applications sans d\u00e9pendances syst\u00e8me complexes <code>node:18-alpine3.18</code> ~180 MB Production avec Alpine 3.18 sp\u00e9cifique <p>Pour la majorit\u00e9 des applications Node.js, Alpine repr\u00e9sente le meilleur compromis entre taille et fonctionnalit\u00e9.</p>"},{"location":"_projects/_formation-docker/docker-chap05/#optimisation-des-dependances-npm","title":"Optimisation des d\u00e9pendances npm","text":"<p>L'utilisation de <code>npm ci</code> \u00e0 la place de <code>npm install</code> am\u00e9liore la reproductibilit\u00e9 en environments de conteneurisation :[4]</p> Docker<pre><code># \u274c Moins optimal\nRUN npm install\n\n# \u2705 Optimal pour production\nRUN npm ci --only=production\n</code></pre> <p>La commande <code>npm ci</code> (continuous integration) installe les versions exactes sp\u00e9cifi\u00e9es dans <code>package-lock.json</code>, tandis que <code>npm install</code> peut installer des versions mineures plus r\u00e9centes. En production, la reproductibilit\u00e9 prime.</p>"},{"location":"_projects/_formation-docker/docker-chap05/#gestion-des-fichiers-de-developpement","title":"Gestion des fichiers de d\u00e9veloppement","text":"<p>Certains fichiers de d\u00e9veloppement (tests, fichiers de configuration, scripts de build) peuvent \u00eatre exclus de l'image de production :</p> Docker<pre><code>FROM node:18-alpine as development\n\nWORKDIR /app\n\nCOPY . .\n\nRUN npm install\n\n# Couche de production sans fichiers inutiles\nFROM node:18-alpine as production\n\nWORKDIR /app\n\nCOPY package*.json ./\n\nRUN npm ci --only=production\n\nCOPY --from=development /app/dist ./dist\n\n# Exclure : .git, .github, tests, scripts, src, tsconfig.json, etc.\n\nCMD [\"node\", \"dist/index.js\"]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#bonnes-pratiques-de-securite-dans-les-images","title":"Bonnes pratiques de s\u00e9curit\u00e9 dans les images","text":"<ul> <li>N'ex\u00e9cuter pas l'application en tant que root : cr\u00e9er un utilisateur d\u00e9di\u00e9</li> <li>Minimiser les capacit\u00e9s du syst\u00e8me : utiliser Alpine ou slim pour r\u00e9duire la surface d'attaque</li> <li>Mettre \u00e0 jour les d\u00e9pendances r\u00e9guli\u00e8rement : utiliser des outils comme Snyk ou Dependabot</li> <li>Scanner les images pour les vuln\u00e9rabilit\u00e9s : utiliser <code>docker scan</code> ou des services externes</li> </ul> <p>Exemple d'image s\u00e9curis\u00e9e :</p> Docker<pre><code>FROM node:18-alpine\n\nRUN addgroup -g 1001 -S nodejs &amp;&amp; adduser -S nodejs -u 1001\n\nWORKDIR /app\n\nCOPY package*.json ./\n\nRUN npm ci --only=production &amp;&amp; npm cache clean --force\n\nCOPY --chown=nodejs:nodejs . .\n\nUSER nodejs\n\nEXPOSE 3000\n\nCMD [\"node\", \"server.js\"]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#publier-et-exposer-des-ports","title":"Publier et exposer des ports","text":""},{"location":"_projects/_formation-docker/docker-chap05/#concepts-de-ports-dans-docker","title":"Concepts de ports dans Docker","text":"<p>La publication de ports \u00e9tablit un mappage entre les ports du conteneur et les ports de la machine h\u00f4te. Sans cette publication, les services \u00e0 l'int\u00e9rieur du conteneur restent inaccessibles depuis l'ext\u00e9rieur.</p> <p>L'instruction <code>EXPOSE</code> dans le Dockerfile documente le port, tandis que l'option <code>-p</code> de <code>docker run</code> effectue le mappage r\u00e9el :[1]</p> Bash<pre><code>docker run -d -p 3000:3000 sfeir-dev\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#mappage-de-ports-syntaxe-et-options","title":"Mappage de ports : syntaxe et options","text":"<p>La syntaxe g\u00e9n\u00e9rale du mappage de ports suit le pattern : <code>[host-ip:]host-port:container-port</code></p> <p>Mappage simple :</p> Bash<pre><code># Le conteneur \u00e9coute sur le port 3000, accessible via le port 3000 de l'h\u00f4te\ndocker run -p 3000:3000 myapp\n</code></pre> <p>Mappage avec port h\u00f4te diff\u00e9rent :</p> Bash<pre><code># Le conteneur \u00e9coute sur le port 3000, mais l'h\u00f4te l'expose sur le port 8080\ndocker run -p 8080:3000 myapp\n</code></pre> <p>Mappage sur une interface r\u00e9seau sp\u00e9cifique :</p> Bash<pre><code># Accessible uniquement depuis localhost\ndocker run -p 127.0.0.1:8080:3000 myapp\n\n# Accessible depuis toutes les interfaces r\u00e9seau\ndocker run -p 0.0.0.0:8080:3000 myapp\n</code></pre> <p>Mappage de plusieurs ports :</p> Bash<pre><code># Exposer plusieurs ports\ndocker run -p 8080:3000 -p 9000:9000 myapp\n</code></pre> <p>Mappage de plage de ports :</p> Bash<pre><code># Mapper une plage de 10 ports\ndocker run -p 8000-8009:3000-3009 myapp\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#exemple-de-deploiement-complet-avec-port-mapping","title":"Exemple de d\u00e9ploiement complet avec port mapping","text":"Bash<pre><code># Construire l'image\ndocker build -t nodejs-server:1.0 .\n\n# Ex\u00e9cuter le conteneur avec mappage de port\ndocker run \\\n  --name my-nodejs-app \\\n  --detach \\\n  --publish 80:3000 \\\n  --restart always \\\n  nodejs-server:1.0\n</code></pre> <p>Les options utilis\u00e9es : - <code>--name</code> : assigne un nom au conteneur pour r\u00e9f\u00e9rence facile - <code>--detach</code> : ex\u00e9cute le conteneur en arri\u00e8re-plan - <code>--publish</code> : mappe le port 80 de l'h\u00f4te vers le port 3000 du conteneur - <code>--restart always</code> : red\u00e9marre automatiquement le conteneur s'il s'arr\u00eate</p>"},{"location":"_projects/_formation-docker/docker-chap05/#inspection-et-gestion-des-ports","title":"Inspection et gestion des ports","text":"<p>Pour lister les conteneurs en cours d'ex\u00e9cution et voir les mappages de ports :[4]</p> Bash<pre><code>docker ps\n</code></pre> <p>R\u00e9sultat exemple :</p> Text Only<pre><code>CONTAINER ID   IMAGE                     COMMAND          CREATED        STATUS        PORTS                  NAMES\ne50ad27074a7   nodejs-server:1.0         \"node app.js\"    3 minutes ago  Up 3 minutes  0.0.0.0:80-&gt;3000/tcp   my-nodejs-app\n</code></pre> <p>Pour obtenir des d\u00e9tails sp\u00e9cifiques sur un conteneur :</p> Bash<pre><code>docker inspect my-nodejs-app | grep -A 10 \"Ports\"\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#configuration-de-lapplication-pour-accepter-les-connexions-externes","title":"Configuration de l'application pour accepter les connexions externes","text":"<p>Pour que l'application Node.js accepte les connexions de toutes les interfaces r\u00e9seau, il faut la configurer correctement. Une application Express typique :</p> JavaScript<pre><code>const express = require('express');\nconst app = express();\n\nconst PORT = process.env.PORT || 3000;\nconst HOST = process.env.HOST || '0.0.0.0';\n\napp.listen(PORT, HOST, () =&gt; {\n  console.log(`Server running at http://${HOST}:${PORT}/`);\n});\n</code></pre> <p>La variable <code>HOST='0.0.0.0'</code> permet \u00e0 l'application d'\u00e9couter sur toutes les interfaces r\u00e9seau du conteneur.</p>"},{"location":"_projects/_formation-docker/docker-chap05/#architectures-multi-conteneurs-avec-partage-de-ports","title":"Architectures multi-conteneurs avec partage de ports","text":"<p>Dans les architectures complexes, plusieurs conteneurs peuvent avoir besoin d'acc\u00e9der les uns aux autres :</p> Bash<pre><code># Cr\u00e9er un r\u00e9seau personnalis\u00e9\ndocker network create myapp-network\n\n# Ex\u00e9cuter le conteneur Node.js\ndocker run \\\n  --name api-server \\\n  --network myapp-network \\\n  --expose 3000 \\\n  nodejs-server:1.0\n\n# Ex\u00e9cuter un conteneur nginx en tant que proxy\ndocker run \\\n  --name nginx-proxy \\\n  --network myapp-network \\\n  --publish 80:80 \\\n  -v /etc/nginx/nginx.conf:/etc/nginx/nginx.conf:ro \\\n  nginx:latest\n</code></pre> <p>Dans cette configuration, Nginx agit comme proxy reverse, route les demandes externes vers le serveur Node.js interne.</p>"},{"location":"_projects/_formation-docker/docker-chap05/#health-checks-et-verification-de-connectivite","title":"Health checks et v\u00e9rification de connectivit\u00e9","text":"<p>V\u00e9rifier que le conteneur s'est d\u00e9ploy\u00e9 correctement et que le port r\u00e9pond :</p> Bash<pre><code># V\u00e9rifier que le port est accessible\ncurl http://localhost:80\n\n# Attendre que le conteneur soit pr\u00eat\ndocker run \\\n  --health-cmd='curl -f http://localhost:3000/health || exit 1' \\\n  --health-interval=30s \\\n  --health-timeout=10s \\\n  --health-retries=3 \\\n  --health-start-period=40s \\\n  nodejs-server:1.0\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#workflow-complet-dune-application-nodejs-en-conteneur","title":"Workflow complet d'une application Node.js en conteneur","text":""},{"location":"_projects/_formation-docker/docker-chap05/#etape-1-preparation-du-projet","title":"\u00c9tape 1 : Pr\u00e9paration du projet","text":"<p>Une application Node.js type poss\u00e8de une structure comme celle-ci :</p> Text Only<pre><code>mon-app/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 index.js\n\u2502   \u2514\u2500\u2500 server.js\n\u251c\u2500\u2500 package.json\n\u251c\u2500\u2500 package-lock.json\n\u251c\u2500\u2500 .dockerignore\n\u251c\u2500\u2500 Dockerfile\n\u2514\u2500\u2500 .gitignore\n</code></pre> <p>Le fichier <code>package.json</code> :</p> JSON<pre><code>{\n  \"name\": \"mon-app\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Application serveur Node.js\",\n  \"main\": \"src/index.js\",\n  \"scripts\": {\n    \"start\": \"node src/index.js\",\n    \"dev\": \"nodemon src/index.js\"\n  },\n  \"dependencies\": {\n    \"express\": \"^4.18.2\"\n  },\n  \"devDependencies\": {\n    \"nodemon\": \"^3.0.1\"\n  }\n}\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#etape-2-creer-le-dockerfile-optimise","title":"\u00c9tape 2 : Cr\u00e9er le Dockerfile optimis\u00e9","text":"Docker<pre><code># Base image\nFROM node:18-alpine\n\n# D\u00e9finir le r\u00e9pertoire de travail\nWORKDIR /app\n\n# Copier les d\u00e9pendances\nCOPY package*.json ./\n\n# Installer les d\u00e9pendances de production\nRUN npm ci --only=production\n\n# Copier le code source\nCOPY --chown=node:node . .\n\n# Exposition du port\nEXPOSE 3000\n\n# D\u00e9finir les variables d'environnement\nENV NODE_ENV=production\n\n# Utiliser l'utilisateur non-root\nUSER node\n\n# Commande de d\u00e9marrage\nCMD [\"npm\", \"start\"]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#etape-3-creer-le-fichier-dockerignore","title":"\u00c9tape 3 : Cr\u00e9er le fichier .dockerignore","text":"Text Only<pre><code>node_modules\nnpm-debug.log\n.git\n.gitignore\nREADME.md\n.env\n.env.local\n.DS_Store\ndist\nbuild\n.npm\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#etape-4-construire-limage","title":"\u00c9tape 4 : Construire l'image","text":"Bash<pre><code># Construire avec un tag\ndocker build -t mon-app:1.0 .\n\n# V\u00e9rifier la cr\u00e9ation\ndocker images | grep mon-app\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#etape-5-executer-le-conteneur","title":"\u00c9tape 5 : Ex\u00e9cuter le conteneur","text":"Bash<pre><code># Ex\u00e9cuter en arri\u00e8re-plan avec mappage de port\ndocker run -d \\\n  --name mon-app-instance \\\n  --publish 8080:3000 \\\n  --restart unless-stopped \\\n  mon-app:1.0\n\n# V\u00e9rifier que le conteneur s'ex\u00e9cute\ndocker ps | grep mon-app\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#etape-6-tester-lapplication","title":"\u00c9tape 6 : Tester l'application","text":"Bash<pre><code># Tester localement\ncurl http://localhost:8080\n\n# Voir les logs du conteneur\ndocker logs mon-app-instance\n\n# Suivre les logs en temps r\u00e9el\ndocker logs -f mon-app-instance\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#etape-7-arreter-et-nettoyer","title":"\u00c9tape 7 : Arr\u00eater et nettoyer","text":"Bash<pre><code># Arr\u00eater le conteneur\ndocker stop mon-app-instance\n\n# Supprimer le conteneur\ndocker rm mon-app-instance\n\n# Supprimer l'image\ndocker rmi mon-app:1.0\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#deploiement-en-production-et-considerations-avancees","title":"D\u00e9ploiement en production et consid\u00e9rations avanc\u00e9es","text":""},{"location":"_projects/_formation-docker/docker-chap05/#variables-denvironnement-en-production","title":"Variables d'environnement en production","text":"<p>Les variables d'environnement ne doivent jamais \u00eatre cod\u00e9es en dur dans le Dockerfile. Elles doivent \u00eatre pass\u00e9es au runtime :</p> Bash<pre><code>docker run \\\n  --env NODE_ENV=production \\\n  --env DATABASE_URL=postgresql://user:pass@db:5432/myapp \\\n  --env JWT_SECRET=secret-key-here \\\n  mon-app:1.0\n</code></pre> <p>Ou utiliser un fichier .env :</p> Bash<pre><code>docker run --env-file .env.production mon-app:1.0\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#gestion-des-volumes-pour-persistence-des-donnees","title":"Gestion des volumes pour persistence des donn\u00e9es","text":"Bash<pre><code>docker run \\\n  --volume /app/logs:/logs \\\n  --volume /app/uploads:/uploads \\\n  mon-app:1.0\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#networking-et-communication-entre-conteneurs","title":"Networking et communication entre conteneurs","text":"Bash<pre><code># Cr\u00e9er un r\u00e9seau\ndocker network create app-network\n\n# Connecter les conteneurs au r\u00e9seau\ndocker run --network app-network --name api mon-app:1.0\ndocker run --network app-network --name db postgres:15\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#orchestration-avec-docker-compose","title":"Orchestration avec Docker Compose","text":"<p>Pour les applications multi-conteneurs :</p> YAML<pre><code>version: '3.8'\n\nservices:\n  api:\n    build: .\n    ports:\n      - \"8080:3000\"\n    environment:\n      - NODE_ENV=production\n      - DATABASE_URL=postgresql://user:pass@db:5432/myapp\n    depends_on:\n      - db\n    networks:\n      - app-network\n\n  db:\n    image: postgres:15\n    environment:\n      - POSTGRES_PASSWORD=password\n    networks:\n      - app-network\n\nnetworks:\n  app-network:\n    driver: bridge\n</code></pre> <p>D\u00e9ployer avec :</p> Bash<pre><code>docker-compose up -d\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap05/#conclusion","title":"Conclusion","text":"<p>La conteneurisation d'une application Node.js avec Docker repr\u00e9sente un passage essentiel vers les practices modernes de d\u00e9veloppement et de d\u00e9ploiement. Le processus, bien que comportant plusieurs \u00e9tapes, offre une structure claire et reproductible.</p> <p>La ma\u00eetrise des concepts fondamentaux\u2014le Dockerfile, les couches d'images, le mappage de ports et l'optimisation\u2014constitue la base pour construire des applications scalables et maintenables. Les patterns pr\u00e9sent\u00e9s ici, du Dockerfile basique aux multistage builds avanc\u00e9s, couvrent la majorit\u00e9 des cas d'usage rencontr\u00e9s en d\u00e9veloppement professionnel.</p> <p>L'optimisation ne doit pas \u00eatre n\u00e9glig\u00e9e, car une image bien con\u00e7ue peut \u00eatre jusqu'\u00e0 5 fois plus petite qu'une image na\u00efve, impactant directement les co\u00fbts et les performances de d\u00e9ploiement. L'adoption de bonnes pratiques de s\u00e9curit\u00e9\u2014utilisateurs non-root, minimisation des couches, exclusion des fichiers inutiles\u2014\u00e9tablit les fondations d'une infrastructure robuste.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-docker/docker-chap06/","title":"Citations","text":"<ul> <li>https://blog.alphorm.com/volumes-docker-guide-complet</li> <li>https://docs.docker.com/engine/storage/tmpfs/</li> <li>https://blog.stephane-robert.info/docs/conteneurs/moteurs-conteneurs/docker/volumes/</li> <li>https://xavki.blog/les-differentes-options-de-persistences-avec-docker/</li> <li>https://docs.docker.com/engine/storage/</li> <li>https://docs.docker.com/engine/storage/volumes/</li> <li>https://xtom.com/blog/docker-persistent-storage-container-volumes/</li> <li>https://labex.io/fr/tutorials/docker-how-to-persist-data-in-docker-volumes-493636</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap06/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 296</li> <li>completion_tokens: 6540</li> <li>total_tokens: 6836</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.098, 'request_cost': 0.006, 'total_cost': 0.105}</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap06/#content","title":"Content","text":""},{"location":"_projects/_formation-docker/docker-chap06/#chapitre-6-persister-des-donnees-avec-docker","title":"\ud83d\udc33 Chapitre 6 : Persister des donn\u00e9es avec Docker","text":""},{"location":"_projects/_formation-docker/docker-chap06/#introduction-a-la-persistance-des-donnees","title":"Introduction \u00e0 la persistance des donn\u00e9es","text":"<p>Par d\u00e9faut, les conteneurs Docker sont \u00e9ph\u00e9m\u00e8res. Cela signifie que toutes les donn\u00e9es g\u00e9n\u00e9r\u00e9es \u00e0 l'int\u00e9rieur d'un conteneur sont perdues d\u00e8s que celui-ci est arr\u00eat\u00e9 ou supprim\u00e9. Cette caract\u00e9ristique pose un probl\u00e8me majeur pour les applications qui n\u00e9cessitent la conservation de donn\u00e9es : bases de donn\u00e9es, fichiers de configuration, logs d'application, etc.[2][5]</p> <p>Docker propose trois m\u00e9canismes distincts pour r\u00e9soudre ce probl\u00e8me et assurer la persistance des donn\u00e9es au-del\u00e0 du cycle de vie du conteneur :[7]</p> <ol> <li>Les volumes : m\u00e9canisme g\u00e9r\u00e9 enti\u00e8rement par Docker</li> <li>Les bind mounts : montages directs vers des r\u00e9pertoires de l'h\u00f4te</li> <li>Les tmpfs mounts : stockage temporaire en m\u00e9moire vive</li> </ol> <p>Chaque approche pr\u00e9sente des caract\u00e9ristiques sp\u00e9cifiques, des avantages et des limitations qui les rendent appropri\u00e9es pour diff\u00e9rents cas d'usage.</p>"},{"location":"_projects/_formation-docker/docker-chap06/#les-volumes-docker","title":"Les volumes Docker","text":""},{"location":"_projects/_formation-docker/docker-chap06/#concept-fondamental","title":"Concept fondamental","text":"<p>Les volumes repr\u00e9sentent le m\u00e9canisme pr\u00e9f\u00e9r\u00e9 et recommand\u00e9 par Docker pour persister les donn\u00e9es g\u00e9n\u00e9r\u00e9es et utilis\u00e9es par les conteneurs.[6] Contrairement aux bind mounts qui d\u00e9pendent de la structure de r\u00e9pertoires de l'h\u00f4te, les volumes sont enti\u00e8rement g\u00e9r\u00e9s par Docker et offrent une abstraction compl\u00e8te du syst\u00e8me de stockage sous-jacent.[8]</p> <p>Les volumes sont stock\u00e9s dans un r\u00e9pertoire sp\u00e9cifique du syst\u00e8me h\u00f4te, typiquement dans <code>/var/lib/docker/volumes/</code> sous Linux.[1] Cette centralisation facilite consid\u00e9rablement la gestion, la sauvegarde et la surveillance des donn\u00e9es persistantes.</p>"},{"location":"_projects/_formation-docker/docker-chap06/#avantages-des-volumes","title":"Avantages des volumes","text":"<ul> <li>Gestion centralis\u00e9e : Docker g\u00e8re automatiquement le cycle de vie du volume</li> <li>Portabilit\u00e9 : les volumes fonctionnent identiquement sur Linux, macOS et Windows</li> <li>Performance : acc\u00e8s direct aux donn\u00e9es sans surcharge de traduction de chemins</li> <li>S\u00e9curit\u00e9 : isolation am\u00e9lior\u00e9e des donn\u00e9es</li> <li>Sauvegardes facilit\u00e9es : proc\u00e9dure standardis\u00e9e pour sauvegarder les volumes</li> <li>Partage entre conteneurs : un m\u00eame volume peut \u00eatre mont\u00e9 dans plusieurs conteneurs</li> <li>Isolation du syst\u00e8me de fichiers du conteneur : les donn\u00e9es ne sont pas m\u00e9lang\u00e9es aux fichiers de l'application</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap06/#creer-et-utiliser-un-volume","title":"Cr\u00e9er et utiliser un volume","text":"<p>La cr\u00e9ation d'un volume s'effectue directement lors du lancement d'un conteneur ou en utilisant la commande d\u00e9di\u00e9e <code>docker volume</code>.</p> Bash<pre><code># Cr\u00e9er un volume explicitement\ndocker volume create mon_volume\n\n# Lister les volumes existants\ndocker volume ls\n\n# Inspecter un volume\ndocker volume inspect mon_volume\n\n# Supprimer un volume\ndocker volume rm mon_volume\n</code></pre> <p>Pour utiliser un volume lors du lancement d'un conteneur, la syntaxe suivante s'applique :</p> Bash<pre><code>docker run -d \\\n  --name mon_conteneur \\\n  -v mon_volume:/data \\\n  nginx:latest\n</code></pre> <p>L'option <code>-v</code> accepte trois champs s\u00e9par\u00e9s par des deux-points : - Le nom du volume (ou le chemin pour un bind mount) - Le point de montage dans le conteneur - Les options de montage (optionnel)</p>"},{"location":"_projects/_formation-docker/docker-chap06/#syntaxe-moderne-avec-mount","title":"Syntaxe moderne avec --mount","text":"<p>La syntaxe <code>--mount</code> est consid\u00e9r\u00e9e comme plus explicite et offre une meilleure lisibilit\u00e9 :</p> Bash<pre><code>docker run -d \\\n  --name mon_conteneur \\\n  --mount type=volume,source=mon_volume,target=/data \\\n  nginx:latest\n</code></pre> <p>Les options disponibles pour <code>--mount type=volume</code> incluent :</p> Option Description <code>type</code> Sp\u00e9cifie le type de montage : <code>volume</code>, <code>bind</code> ou <code>tmpfs</code> <code>source</code> (ou <code>src</code>) Nom du volume existant ou \u00e0 cr\u00e9er automatiquement <code>target</code> (ou <code>destination</code>, <code>dst</code>) Chemin de montage dans le conteneur <code>readonly</code> Monte le volume en lecture seule (par d\u00e9faut : lecture-\u00e9criture)"},{"location":"_projects/_formation-docker/docker-chap06/#utiliser-un-volume-pour-une-base-de-donnees","title":"Utiliser un volume pour une base de donn\u00e9es","text":""},{"location":"_projects/_formation-docker/docker-chap06/#cas-dusage-base-de-donnees-mysql","title":"Cas d'usage : base de donn\u00e9es MySQL","text":"<p>Les bases de donn\u00e9es constituent le cas d'usage id\u00e9al pour les volumes Docker. Les donn\u00e9es doivent persister entre les red\u00e9marrages, \u00eatre accessibles de mani\u00e8re fiable et souvent \u00eatre sauvegard\u00e9es r\u00e9guli\u00e8rement.</p>"},{"location":"_projects/_formation-docker/docker-chap06/#deployer-mysql-avec-un-volume-persistant","title":"D\u00e9ployer MySQL avec un volume persistant","text":"Bash<pre><code>docker run -d \\\n  --name mysql_db \\\n  -e MYSQL_ROOT_PASSWORD=rootpassword \\\n  -e MYSQL_DATABASE=app_db \\\n  -e MYSQL_USER=appuser \\\n  -e MYSQL_PASSWORD=apppassword \\\n  -v db_data:/var/lib/mysql \\\n  -p 3306:3306 \\\n  mysql:8.0\n</code></pre> <p>Dans cet exemple : - Un volume nomm\u00e9 <code>db_data</code> est cr\u00e9\u00e9 automatiquement s'il n'existe pas - Ce volume est mont\u00e9 au point <code>/var/lib/mysql</code> dans le conteneur, o\u00f9 MySQL stocke ses donn\u00e9es - Les donn\u00e9es persisteront m\u00eame apr\u00e8s l'arr\u00eat du conteneur - Le port 3306 est expos\u00e9 pour acc\u00e9der \u00e0 la base de donn\u00e9es depuis l'h\u00f4te</p>"},{"location":"_projects/_formation-docker/docker-chap06/#verifier-les-donnees-persistantes","title":"V\u00e9rifier les donn\u00e9es persistantes","text":"Bash<pre><code># Arr\u00eater le conteneur\ndocker stop mysql_db\n\n# V\u00e9rifier que le volume existe toujours\ndocker volume ls\n\n# Red\u00e9marrer le conteneur\ndocker start mysql_db\n\n# Les donn\u00e9es sont pr\u00e9serv\u00e9es et accessibles\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap06/#cas-dusage-postgresql-avec-initialisation","title":"Cas d'usage : PostgreSQL avec initialisation","text":"Bash<pre><code>docker run -d \\\n  --name postgres_db \\\n  -e POSTGRES_USER=admin \\\n  -e POSTGRES_PASSWORD=password123 \\\n  -e POSTGRES_DB=production_db \\\n  -v postgres_data:/var/lib/postgresql/data \\\n  -v ./init.sql:/docker-entrypoint-initdb.d/init.sql \\\n  -p 5432:5432 \\\n  postgres:15-alpine\n</code></pre> <p>Cet exemple combine un volume persistant avec un bind mount pour l'initialisation de la base de donn\u00e9es.</p>"},{"location":"_projects/_formation-docker/docker-chap06/#les-bind-mounts","title":"Les bind mounts","text":""},{"location":"_projects/_formation-docker/docker-chap06/#concept-et-utilisation","title":"Concept et utilisation","text":"<p>Les bind mounts sont g\u00e9r\u00e9s par l'utilisateur et permettent de monter n'importe quel r\u00e9pertoire ou fichier du syst\u00e8me h\u00f4te \u00e0 l'int\u00e9rieur du conteneur.[1] Contrairement aux volumes, les bind mounts ne sont pas centralis\u00e9s dans <code>/var/lib/docker/volumes/</code> mais peuvent pointer vers n'importe quel chemin du syst\u00e8me de fichiers de l'h\u00f4te.</p> <p>Les donn\u00e9es stock\u00e9es dans un bind mount persisteront apr\u00e8s la suppression du conteneur si elles existent toujours sur le syst\u00e8me h\u00f4te.[1] Cette approche offre une flexibilit\u00e9 maximale mais requiert une gestion manuelle des chemins de fichiers.</p>"},{"location":"_projects/_formation-docker/docker-chap06/#cas-dusage-appropries","title":"Cas d'usage appropri\u00e9s","text":"<ul> <li>D\u00e9veloppement local : partager le code source de l'h\u00f4te avec le conteneur pour permettre les modifications en temps r\u00e9el</li> <li>Fichiers de configuration : monter des fichiers de configuration sp\u00e9cifiques depuis l'h\u00f4te</li> <li>Logs d'application : capturer les logs du conteneur sur le syst\u00e8me h\u00f4te</li> <li>Donn\u00e9es partageables : acc\u00e9der \u00e0 des donn\u00e9es existantes sur l'h\u00f4te sans les dupliquer</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap06/#syntaxe-des-bind-mounts","title":"Syntaxe des bind mounts","text":"Bash<pre><code># Syntaxe courte avec -v\ndocker run -d \\\n  --name mon_app \\\n  -v /chemin/sur/hote:/app/data \\\n  mon_image:latest\n</code></pre> <p>Dans cet exemple : - <code>/chemin/sur/hote</code> est le chemin absolu sur le syst\u00e8me h\u00f4te - <code>/app/data</code> est le point de montage dans le conteneur - Les deux chemins utilisent le s\u00e9parateur <code>/</code> m\u00eame sur Windows</p>"},{"location":"_projects/_formation-docker/docker-chap06/#syntaxe-explicite-avec-mount","title":"Syntaxe explicite avec --mount","text":"Bash<pre><code>docker run -d \\\n  --name mon_app \\\n  --mount type=bind,source=/chemin/sur/hote,target=/app/data,readonly \\\n  mon_image:latest\n</code></pre> <p>Les options disponibles pour <code>--mount type=bind</code> incluent :</p> Option Description <code>type</code> Doit \u00eatre <code>bind</code> <code>source</code> (ou <code>src</code>) Chemin absolu sur le syst\u00e8me h\u00f4te <code>target</code> (ou <code>destination</code>) Chemin de montage dans le conteneur <code>readonly</code> Monte le r\u00e9pertoire en lecture seule <code>bind-propagation</code> Configure la propagation du montage"},{"location":"_projects/_formation-docker/docker-chap06/#exemple-pratique-developpement-dune-application-nodejs","title":"Exemple pratique : d\u00e9veloppement d'une application Node.js","text":""},{"location":"_projects/_formation-docker/docker-chap06/#structure-du-projet","title":"Structure du projet","text":"Text Only<pre><code>mon_projet/\n\u251c\u2500\u2500 package.json\n\u251c\u2500\u2500 server.js\n\u251c\u2500\u2500 app/\n\u2502   \u251c\u2500\u2500 index.js\n\u2502   \u2514\u2500\u2500 config.js\n\u2514\u2500\u2500 logs/\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap06/#lancer-le-conteneur-avec-bind-mount","title":"Lancer le conteneur avec bind mount","text":"Bash<pre><code>docker run -d \\\n  --name node_dev \\\n  -v $(pwd):/app \\\n  -w /app \\\n  -p 3000:3000 \\\n  node:18-alpine \\\n  npm start\n</code></pre> <p>Les modifications apport\u00e9es au code sur l'h\u00f4te se refl\u00e8tent imm\u00e9diatement dans le conteneur. L'application red\u00e9marre automatiquement si un syst\u00e8me comme nodemon est configur\u00e9.</p>"},{"location":"_projects/_formation-docker/docker-chap06/#monter-en-lecture-seule","title":"Monter en lecture seule","text":"<p>Pour certains fichiers comme les configurations, un montage en lecture seule peut \u00eatre appropri\u00e9 :</p> Bash<pre><code>docker run -d \\\n  --name app_production \\\n  --mount type=bind,source=/etc/app/config,target=/app/config,readonly \\\n  mon_app:latest\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap06/#partager-des-volumes-entre-des-conteneurs","title":"Partager des volumes entre des conteneurs","text":""},{"location":"_projects/_formation-docker/docker-chap06/#concept-du-partage","title":"Concept du partage","text":"<p>Un m\u00eame volume peut \u00eatre mont\u00e9 simultan\u00e9ment dans plusieurs conteneurs diff\u00e9rents. Cette approche permet le partage de donn\u00e9es entre conteneurs, une synchronisation en temps r\u00e9el et des architectures complexes o\u00f9 plusieurs services acc\u00e8dent aux m\u00eames donn\u00e9es.</p>"},{"location":"_projects/_formation-docker/docker-chap06/#exemple-partage-entre-application-web-et-base-de-donnees","title":"Exemple : partage entre application web et base de donn\u00e9es","text":"Bash<pre><code># Cr\u00e9er un volume partag\u00e9\ndocker volume create app_data\n\n# Lancer la base de donn\u00e9es\ndocker run -d \\\n  --name mysql_db \\\n  -v app_data:/var/lib/mysql \\\n  -e MYSQL_ROOT_PASSWORD=password \\\n  mysql:8.0\n\n# Lancer l'application web\ndocker run -d \\\n  --name web_app \\\n  -v app_data:/app/data \\\n  -p 8080:8080 \\\n  mon_app:latest\n</code></pre> <p>Les deux conteneurs acc\u00e8dent aux m\u00eames donn\u00e9es via le volume <code>app_data</code>.</p>"},{"location":"_projects/_formation-docker/docker-chap06/#partage-avec-docker-compose","title":"Partage avec docker-compose","text":"<p>La composition de plusieurs conteneurs s'effectue plus facilement avec Docker Compose :</p> YAML<pre><code>version: '3.8'\n\nservices:\n  db:\n    image: mysql:8.0\n    environment:\n      MYSQL_ROOT_PASSWORD: rootpass\n      MYSQL_DATABASE: appdb\n    volumes:\n      - app_data:/var/lib/mysql\n    ports:\n      - \"3306:3306\"\n\n  web:\n    image: nginx:latest\n    volumes:\n      - app_data:/app/shared_data\n      - ./html:/usr/share/nginx/html\n    ports:\n      - \"80:80\"\n    depends_on:\n      - db\n\n  backup:\n    image: busybox:latest\n    volumes:\n      - app_data:/backup\n    command: sh -c \"echo 'Conteneur de backup en attente'\"\n\nvolumes:\n  app_data:\n    driver: local\n</code></pre> <p>Dans cet exemple, trois conteneurs (<code>db</code>, <code>web</code>, <code>backup</code>) partagent le m\u00eame volume <code>app_data</code>.</p>"},{"location":"_projects/_formation-docker/docker-chap06/#effectuer-des-sauvegardes-de-volumes","title":"Effectuer des sauvegardes de volumes","text":""},{"location":"_projects/_formation-docker/docker-chap06/#strategie-de-sauvegarde","title":"Strat\u00e9gie de sauvegarde","text":"<p>La sauvegarde des volumes est une op\u00e9ration critique pour garantir la disponibilit\u00e9 et la r\u00e9cup\u00e9rabilit\u00e9 des donn\u00e9es. Docker propose plusieurs approches pour archiver et restaurer les donn\u00e9es persistantes.</p>"},{"location":"_projects/_formation-docker/docker-chap06/#technique-1-archive-tar-via-un-conteneur-auxiliaire","title":"Technique 1 : Archive tar via un conteneur auxiliaire","text":"Bash<pre><code># Cr\u00e9er une archive du volume\ndocker run --rm \\\n  -v app_data:/app \\\n  -v $(pwd):/backup \\\n  ubuntu:latest \\\n  tar czf /backup/app_data_backup.tar.gz -C /app .\n\n# V\u00e9rifier la sauvegarde\nls -lh app_data_backup.tar.gz\n</code></pre> <p>Cette technique : - Monte le volume \u00e0 sauvegarder dans un conteneur temporaire - Monte un r\u00e9pertoire local de l'h\u00f4te pour recevoir l'archive - Utilise <code>tar</code> pour compresser les donn\u00e9es - Supprime automatiquement le conteneur apr\u00e8s ex\u00e9cution</p>"},{"location":"_projects/_formation-docker/docker-chap06/#technique-2-restauration-dune-sauvegarde","title":"Technique 2 : Restauration d'une sauvegarde","text":"Bash<pre><code># Cr\u00e9er un nouveau volume vierge\ndocker volume create app_data_restored\n\n# Restaurer les donn\u00e9es\ndocker run --rm \\\n  -v app_data_restored:/app \\\n  -v $(pwd):/backup \\\n  ubuntu:latest \\\n  tar xzf /backup/app_data_backup.tar.gz -C /app\n\n# V\u00e9rifier la restauration\ndocker run --rm \\\n  -v app_data_restored:/app \\\n  ubuntu:latest \\\n  ls -la /app\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap06/#technique-3-sauvegarde-a-chaud-dune-base-de-donnees","title":"Technique 3 : Sauvegarde \u00e0 chaud d'une base de donn\u00e9es","text":"<p>Pour une base de donn\u00e9es MySQL :</p> Bash<pre><code># Ex\u00e9cuter un dump sans arr\u00eater le service\ndocker exec mysql_db mysqldump \\\n  -uroot -prootpassword \\\n  --all-databases &gt; backup_$(date +%Y%m%d_%H%M%S).sql\n\n# Compresser la sauvegarde\ngzip backup_*.sql\n\n# V\u00e9rifier\nls -lh backup_*.sql.gz\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap06/#technique-4-restauration-dune-base-de-donnees","title":"Technique 4 : Restauration d'une base de donn\u00e9es","text":"Bash<pre><code># Pr\u00e9parer le fichier de sauvegarde\ngunzip backup_20240115_143022.sql.gz\n\n# Restaurer dans le conteneur\ndocker exec -i mysql_db mysql -uroot -prootpassword &lt; backup_20240115_143022.sql\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap06/#pipeline-de-sauvegarde-automatisee","title":"Pipeline de sauvegarde automatis\u00e9e","text":"<p>Un script bash pour automatiser les sauvegardes quotidiennes :</p> Bash<pre><code>#!/bin/bash\n\nBACKUP_DIR=\"/backups/docker\"\nDATE=$(date +%Y%m%d_%H%M%S)\nVOLUMES=(\"app_data\" \"db_data\" \"config_data\")\n\nmkdir -p $BACKUP_DIR\n\nfor volume in \"${VOLUMES[@]}\"; do\n  echo \"Sauvegarde du volume: $volume\"\n\n  docker run --rm \\\n    -v $volume:/data \\\n    -v $BACKUP_DIR:/backup \\\n    ubuntu:latest \\\n    tar czf /backup/${volume}_${DATE}.tar.gz -C /data .\n\n  if [ $? -eq 0 ]; then\n    echo \"\u2713 Sauvegarde r\u00e9ussie: $volume\"\n  else\n    echo \"\u2717 Erreur de sauvegarde: $volume\"\n    exit 1\n  fi\ndone\n\n# Nettoyer les sauvegardes anciennes (&gt; 30 jours)\nfind $BACKUP_DIR -name \"*.tar.gz\" -mtime +30 -delete\n\necho \"Sauvegarde compl\u00e9t\u00e9e le $DATE\"\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap06/#les-tmpfs-mounts","title":"Les tmpfs mounts","text":""},{"location":"_projects/_formation-docker/docker-chap06/#concept-et-cas-dusage","title":"Concept et cas d'usage","text":"<p>Les tmpfs mounts repr\u00e9sentent un m\u00e9canisme de stockage temporaire et \u00e9ph\u00e9m\u00e8re qui r\u00e9side enti\u00e8rement en m\u00e9moire vive (RAM) du syst\u00e8me h\u00f4te.[1] Contrairement aux volumes et bind mounts qui offrent de la persistance, les donn\u00e9es dans un tmpfs sont volatiles et perdues d\u00e8s que le conteneur s'arr\u00eate ou est supprim\u00e9.[1]</p> <p>L'utilisation de tmpfs offre des performances de lecture et d'\u00e9criture significativement plus rapides en comparaison avec un stockage sur disque.[3] Cette approche convient particuli\u00e8rement pour :</p> <ul> <li>Donn\u00e9es temporaires : fichiers de cache, fichiers temporaires interm\u00e9diaires[3]</li> <li>Donn\u00e9es sensibles : informations d'authentification, cl\u00e9s API, secrets qui ne doivent pas \u00eatre persist\u00e9s[5]</li> <li>Optimisation de performance : \u00e9viter les \u00e9critures sur disque pour les conteneurs trait\u00e9s des donn\u00e9es non-persistantes[6]</li> <li>R\u00e9duction de charge I/O : applications g\u00e9n\u00e9rant d'importants volumes de donn\u00e9es transitoires[5]</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap06/#limitation-importante","title":"Limitation importante","text":"<p>Le tmpfs n'est disponible que sur Docker tournant sous Linux.[2] Les utilisateurs de macOS et Windows utilisant Docker Desktop ne peuvent pas b\u00e9n\u00e9ficier de cette fonctionnalit\u00e9.</p>"},{"location":"_projects/_formation-docker/docker-chap06/#syntaxe-du-tmpfs-avec-tmpfs","title":"Syntaxe du tmpfs avec --tmpfs","text":"Bash<pre><code>docker run -d \\\n  --name mon_conteneur \\\n  --tmpfs /tmp \\\n  mon_image:latest\n</code></pre> <p>La syntaxe <code>--tmpfs</code> accepte un chemin de montage suivi d'options s\u00e9par\u00e9es par des deux-points :</p> Bash<pre><code>docker run --tmpfs &lt;chemin_montage&gt;[:options]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap06/#options-de-configuration-du-tmpfs","title":"Options de configuration du tmpfs","text":"<p>Les options disponibles pour le tmpfs incluent :[2]</p> Option Description <code>size</code> Taille maximale du tmpfs en octets (ex: <code>size=1GB</code>) <code>mode</code> Permissions du syst\u00e8me de fichiers en octal (ex: <code>mode=1777</code>, <code>mode=0770</code>) <code>noexec</code> Emp\u00eacher l'ex\u00e9cution de fichiers dans le tmpfs <code>nodev</code> Emp\u00eacher la cr\u00e9ation de fichiers device <code>nosuid</code> Ignorer les bits setuid et setgid <code>nr_blocks</code> Nombre maximal de blocs pour le tmpfs"},{"location":"_projects/_formation-docker/docker-chap06/#exemple-1-tmpfs-pour-fichiers-temporaires","title":"Exemple 1 : tmpfs pour fichiers temporaires","text":"Bash<pre><code>docker run -d \\\n  --name app_temp \\\n  --tmpfs /app/temp:size=100m,mode=1777 \\\n  mon_app:latest\n</code></pre> <p>Cet exemple : - Cr\u00e9e un tmpfs au chemin <code>/app/temp</code> - Limite la taille \u00e0 100 Mo - Fixe les permissions \u00e0 1777 (accessible par tous)</p>"},{"location":"_projects/_formation-docker/docker-chap06/#exemple-2-tmpfs-securise-pour-secrets","title":"Exemple 2 : tmpfs s\u00e9curis\u00e9 pour secrets","text":"Bash<pre><code>docker run -d \\\n  --name secure_app \\\n  --tmpfs /run/secrets:size=50m,mode=0700,noexec \\\n  mon_app:latest\n</code></pre> <p>Les options appliqu\u00e9es renforcent la s\u00e9curit\u00e9 : - Taille limit\u00e9e \u00e0 50 Mo - Permissions restrictives (0700 = lecture/\u00e9criture/ex\u00e9cution pour propri\u00e9taire uniquement) - Ex\u00e9cution de fichiers interdite</p>"},{"location":"_projects/_formation-docker/docker-chap06/#syntaxe-moderne-avec-mount_1","title":"Syntaxe moderne avec --mount","text":"<p>La syntaxe <code>--mount</code> offre une meilleure lisibilit\u00e9 pour les configurations complexes :</p> Bash<pre><code>docker run -d \\\n  --name mon_conteneur \\\n  --mount type=tmpfs,destination=/app,tmpfs-size=100m,tmpfs-mode=0770 \\\n  mon_image:latest\n</code></pre> <p>Les options disponibles pour <code>--mount type=tmpfs</code> incluent :[2]</p> Option Description <code>destination</code> / <code>dst</code> / <code>target</code> Chemin de montage dans le conteneur <code>tmpfs-size</code> Taille en octets (d\u00e9faut : 50% de la RAM totale)[2] <code>tmpfs-mode</code> Mode en octal (d\u00e9faut : 1777)[2]"},{"location":"_projects/_formation-docker/docker-chap06/#exemple-3-application-nginx-avec-tmpfs","title":"Exemple 3 : Application Nginx avec tmpfs","text":"Bash<pre><code>docker run -d \\\n  --it \\\n  --name tmptest \\\n  --mount type=tmpfs,destination=/app,tmpfs-size=100m \\\n  nginx:latest\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap06/#limitation-du-partage-entre-conteneurs","title":"Limitation du partage entre conteneurs","text":"<p>Contrairement aux volumes et bind mounts, les tmpfs mounts ne peuvent pas \u00eatre partag\u00e9s entre plusieurs conteneurs.[2] Chaque conteneur dispose de son propre espace m\u00e9moire isol\u00e9.</p> Bash<pre><code># \u2717 Ceci n'est pas possible\ndocker run -d \\\n  --tmpfs /shared \\\n  container1\ndocker run -d \\\n  --tmpfs /shared \\\n  container2\n# Les deux conteneurs ont des espaces tmpfs s\u00e9par\u00e9s\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap06/#comportement-du-swap","title":"Comportement du swap","text":"<p>Une particularit\u00e9 importante du tmpfs Linux concerne le swap.[2] Bien que les donn\u00e9es soient stock\u00e9es en m\u00e9moire, le syst\u00e8me d'exploitation peut \u00e9crire le contenu du tmpfs vers le fichier de swap s'il manque de RAM. Cette caract\u00e9ristique peut entra\u00eener une persistance partielle sur le disque dur, contraire \u00e0 l'intention premi\u00e8re du tmpfs.</p>"},{"location":"_projects/_formation-docker/docker-chap06/#utilisation-dun-bind-mount-dans-notre-exemple-dapplication","title":"Utilisation d'un bind mount dans notre exemple d'application","text":""},{"location":"_projects/_formation-docker/docker-chap06/#architecture-de-lapplication-exemple","title":"Architecture de l'application exemple","text":"<p>Consid\u00e9rant une application web Node.js compl\u00e8te avec les exigences suivantes : - Code source en d\u00e9veloppement avec modifications en temps r\u00e9el - Fichiers de configuration sp\u00e9cifiques \u00e0 l'environnement - Logs d'application persistants pour audit - Cache temporaire en m\u00e9moire</p>"},{"location":"_projects/_formation-docker/docker-chap06/#structure-du-projet_1","title":"Structure du projet","text":"Text Only<pre><code>mon_app/\n\u251c\u2500\u2500 docker-compose.yml\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 package.json\n\u251c\u2500\u2500 server.js\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 index.js\n\u2502   \u251c\u2500\u2500 routes.js\n\u2502   \u2514\u2500\u2500 middleware.js\n\u251c\u2500\u2500 config/\n\u2502   \u251c\u2500\u2500 production.json\n\u2502   \u251c\u2500\u2500 development.json\n\u2502   \u2514\u2500\u2500 database.json\n\u251c\u2500\u2500 logs/\n\u2514\u2500\u2500 .dockerignore\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap06/#docker-compose-avec-bind-mounts","title":"Docker Compose avec bind mounts","text":"YAML<pre><code>version: '3.8'\n\nservices:\n  app:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    container_name: mon_app\n    ports:\n      - \"3000:3000\"\n    environment:\n      - NODE_ENV=development\n      - DATABASE_URL=postgres://db:5432/appdb\n    volumes:\n      # Bind mount du code source pour rechargement en temps r\u00e9el\n      - ./src:/app/src\n\n      # Bind mount de la configuration environnementale\n      - ./config:/app/config:ro\n\n      # Bind mount des logs pour audit sur l'h\u00f4te\n      - ./logs:/app/logs\n\n      # tmpfs pour les donn\u00e9es temporaires (cache)\n      - type: tmpfs\n        target: /app/temp\n        tmpfs:\n          size: 100m\n    depends_on:\n      - db\n    command: npm run dev\n\n  db:\n    image: postgres:15-alpine\n    container_name: mon_app_db\n    environment:\n      - POSTGRES_USER=appuser\n      - POSTGRES_PASSWORD=apppassword\n      - POSTGRES_DB=appdb\n    volumes:\n      # Volume persistant pour les donn\u00e9es\n      - db_data:/var/lib/postgresql/data\n\n      # Bind mount pour le script d'initialisation\n      - ./init.sql:/docker-entrypoint-initdb.d/init.sql\n    ports:\n      - \"5432:5432\"\n\nvolumes:\n  db_data:\n    driver: local\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap06/#dockerfile-correspondant","title":"Dockerfile correspondant","text":"Docker<pre><code>FROM node:18-alpine\n\nWORKDIR /app\n\n# Copier les fichiers de d\u00e9pendances\nCOPY package*.json ./\n\n# Installer les d\u00e9pendances\nRUN npm install\n\n# Les fichiers source seront mont\u00e9s via bind mount\n\nEXPOSE 3000\n\nCMD [\"npm\", \"start\"]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap06/#commandes-de-lancement","title":"Commandes de lancement","text":"Bash<pre><code># D\u00e9marrer tous les services\ndocker-compose up -d\n\n# Consulter les logs en temps r\u00e9el\ndocker-compose logs -f app\n\n# Modifier le code source (les changements sont visibles imm\u00e9diatement)\n# Les fichiers dans ./src sont mont\u00e9s directement\n\n# Arr\u00eater les services\ndocker-compose down\n\n# Arr\u00eater et nettoyer (y compris les volumes)\ndocker-compose down -v\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap06/#verification-des-montages","title":"V\u00e9rification des montages","text":"Bash<pre><code># Inspecter le conteneur pour voir les montages\ndocker inspect mon_app | grep -A 10 Mounts\n\n# Voir les volumes mont\u00e9s dans le conteneur\ndocker exec mon_app mount | grep \"/app\"\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap06/#resultat-attendu-de-linspection","title":"R\u00e9sultat attendu de l'inspection","text":"<p>La sortie de <code>docker inspect</code> affichera :</p> JSON<pre><code>\"Mounts\": [\n  {\n    \"Type\": \"bind\",\n    \"Source\": \"/chemin/local/src\",\n    \"Destination\": \"/app/src\",\n    \"Mode\": \"rw\",\n    \"RW\": true\n  },\n  {\n    \"Type\": \"bind\",\n    \"Source\": \"/chemin/local/config\",\n    \"Destination\": \"/app/config\",\n    \"Mode\": \"ro\",\n    \"RW\": false\n  },\n  {\n    \"Type\": \"bind\",\n    \"Source\": \"/chemin/local/logs\",\n    \"Destination\": \"/app/logs\",\n    \"Mode\": \"rw\",\n    \"RW\": true\n  },\n  {\n    \"Type\": \"tmpfs\",\n    \"Source\": \"tmpfs\",\n    \"Destination\": \"/app/temp\"\n  }\n]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap06/#gestion-des-permissions","title":"Gestion des permissions","text":"<p>Les permissions constituent un aspect critique avec les bind mounts. Les fichiers mont\u00e9s conservent les permissions du syst\u00e8me h\u00f4te :</p> Bash<pre><code># V\u00e9rifier les permissions sur l'h\u00f4te\nls -la src/\n\n# \u00c0 l'int\u00e9rieur du conteneur, les permissions sont identiques\ndocker exec mon_app ls -la /app/src/\n\n# Si un utilisateur n'a pas de droits en lecture sur l'h\u00f4te,\n# le conteneur ne peut pas acc\u00e9der aux fichiers\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap06/#resolution-des-problemes-de-permissions","title":"R\u00e9solution des probl\u00e8mes de permissions","text":"Bash<pre><code># Accorder les permissions au r\u00e9pertoire sur l'h\u00f4te\nchmod -R 755 src/\nchmod -R 755 logs/\n\n# Ou avec des permissions plus restrictives si appropri\u00e9\nchmod -R 644 config/\nchmod -R 755 config/\n\n# V\u00e9rifier la propri\u00e9t\u00e9\nls -l | grep \"config\"\n# Si n\u00e9cessaire, changer la propri\u00e9t\u00e9\nchown -R $(whoami):$(whoami) ./\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap06/#comparaison-synthetique-des-trois-approches","title":"Comparaison synth\u00e9tique des trois approches","text":"Caract\u00e9ristique Volumes Bind Mounts Tmpfs Persistance Oui, apr\u00e8s arr\u00eat Oui, apr\u00e8s arr\u00eat Non, donn\u00e9es perdues Gestion Centralis\u00e9e par Docker Manuelle par l'utilisateur Syst\u00e8me d'exploitation Emplacement <code>/var/lib/docker/volumes/</code> N'importe o\u00f9 sur l'h\u00f4te M\u00e9moire RAM Performance Tr\u00e8s bonne Bonne Excellente Portabilit\u00e9 Multi-plateforme Multi-plateforme Linux uniquement Partage entre conteneurs Oui Oui Non Cas d'usage Bases de donn\u00e9es, donn\u00e9es applicatives Code source, configuration, logs Cache, donn\u00e9es temporaires, secrets Sauvegarde Facile et standard Manuelle N/A Isolation Oui Partielle (acc\u00e8s au syst\u00e8me h\u00f4te) Oui"},{"location":"_projects/_formation-docker/docker-chap06/#bonnes-pratiques-de-gestion-des-donnees","title":"Bonnes pratiques de gestion des donn\u00e9es","text":""},{"location":"_projects/_formation-docker/docker-chap06/#securite-et-isolation","title":"S\u00e9curit\u00e9 et isolation","text":"<ul> <li>Utiliser les volumes pour toutes les donn\u00e9es persistantes importantes</li> <li>Appliquer des permissions restrictives sur les fichiers mont\u00e9s</li> <li>Utiliser les tmpfs pour les donn\u00e9es sensibles (secrets, credentials)</li> <li>Limiter la taille des tmpfs pour \u00e9viter une consommation excessive de RAM</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap06/#performance-et-optimisation","title":"Performance et optimisation","text":"<ul> <li>Prioriser les tmpfs pour les donn\u00e9es temporaires n\u00e9cessitant des acc\u00e8s rapides[3]</li> <li>R\u00e9partir les volumes sur diff\u00e9rents disques ou SAN pour \u00e9quilibrer la charge[3]</li> <li>Utiliser les bind mounts en lecture seule quand appropri\u00e9</li> <li>Monitorer l'utilisation des volumes et nettoyer r\u00e9guli\u00e8rement</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap06/#sauvegardes-et-recuperation","title":"Sauvegardes et r\u00e9cup\u00e9ration","text":"<ul> <li>Mettre en place une strat\u00e9gie de sauvegarde automatis\u00e9e pour les volumes critiques</li> <li>Tester r\u00e9guli\u00e8rement la restauration des sauvegardes</li> <li>Documenter les proc\u00e9dures de sauvegarde et r\u00e9cup\u00e9ration</li> <li>Utiliser des solutions externes pour les sauvegardes hors-site</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap06/#gestion-du-cycle-de-vie","title":"Gestion du cycle de vie","text":"<ul> <li>Nettoyage r\u00e9gulier des volumes orphelins :</li> </ul> Bash<pre><code># Identifier les volumes orphelins\ndocker volume ls -f dangling=true\n\n# Nettoyer les volumes orphelins\ndocker volume prune\n</code></pre> <ul> <li>Surveiller l'espace disque utilis\u00e9 par les volumes</li> <li>Planifier les op\u00e9rations de maintenance</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap06/#conclusion-du-chapitre","title":"Conclusion du chapitre","text":"<p>La persistance des donn\u00e9es repr\u00e9sente un \u00e9l\u00e9ment fondamental de toute architecture containeris\u00e9e. Docker fournit trois m\u00e9canismes distincts pour adresser diff\u00e9rents sc\u00e9narios : les volumes pour la persistance g\u00e9r\u00e9e, les bind mounts pour la flexibilit\u00e9 maximale, et les tmpfs pour le stockage temporaire haute performance.</p> <p>Le choix du m\u00e9canisme appropri\u00e9 d\u00e9pend des exigences sp\u00e9cifiques de l'application : donn\u00e9es persistantes critiques (volumes), acc\u00e8s direct au syst\u00e8me de fichiers (bind mounts), ou stockage temporaire haute performance (tmpfs). Une compr\u00e9hension approfondie de ces trois approches permet de construire des architectures Docker robustes, performantes et s\u00fbres.</p> <p>L'impl\u00e9mentation de bonnes pratiques en mati\u00e8re de sauvegarde, s\u00e9curit\u00e9 et optimisation de performance garantit la fiabilit\u00e9 \u00e0 long terme des applications containeris\u00e9es et la protection des donn\u00e9es critiques.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-docker/docker-chap07/","title":"Citations","text":"<ul> <li>https://www.nicelydev.com/docker/reseau-host-bridge</li> <li>https://www.youtube.com/watch?v=-uj1Ofcx09g</li> <li>https://blog.alphorm.com/comprendre-le-reseau-sous-docker</li> <li>https://www.datacamp.com/fr/tutorial/docker-networking</li> <li>https://www.youtube.com/watch?v=69rQCB1sVz4</li> <li>https://blog.stephane-robert.info/docs/conteneurs/moteurs-conteneurs/docker/network/</li> <li>https://labex.io/fr/tutorials/docker-how-to-configure-networking-for-docker-containers-411517</li> <li>https://kb.synology.com/fr-fr/DSM/help/Docker/docker_network?version=6</li> <li>https://xavki.blog/ce-que-vous-devez-savoir-sur-docker-et-ses-reseaux/</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap07/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 279</li> <li>completion_tokens: 5248</li> <li>total_tokens: 5527</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.079, 'request_cost': 0.006, 'total_cost': 0.086}</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap07/#content","title":"Content","text":""},{"location":"_projects/_formation-docker/docker-chap07/#les-reseaux-docker-guide-complet-et-detaille","title":"Les r\u00e9seaux Docker : Guide complet et d\u00e9taill\u00e9","text":""},{"location":"_projects/_formation-docker/docker-chap07/#introduction-aux-reseaux-docker","title":"Introduction aux r\u00e9seaux Docker","text":"<p>Les r\u00e9seaux constituent un \u00e9l\u00e9ment fondamental de Docker, permettant aux conteneurs de communiquer entre eux et avec le monde ext\u00e9rieur. Docker propose plusieurs pilotes r\u00e9seau, chacun adapt\u00e9 \u00e0 des besoins sp\u00e9cifiques. Avant d'explorer les diff\u00e9rents modes de mise en r\u00e9seau, il est essentiel de comprendre les concepts de base qui sous-tendent cette architecture[1][3].</p> <p>Lors de l'installation de Docker, trois r\u00e9seaux sont automatiquement cr\u00e9\u00e9s[3]. Ces r\u00e9seaux par d\u00e9faut permettent aux conteneurs de fonctionner imm\u00e9diatement, mais pour des architectures plus complexes, la cr\u00e9ation de r\u00e9seaux personnalis\u00e9s devient n\u00e9cessaire. La gestion des r\u00e9seaux Docker repr\u00e9sente donc une comp\u00e9tence critique pour tout professionnel travaillant avec des conteneurs[1][3].</p>"},{"location":"_projects/_formation-docker/docker-chap07/#le-reseau-bridge","title":"Le r\u00e9seau Bridge","text":""},{"location":"_projects/_formation-docker/docker-chap07/#fonctionnement-fondamental","title":"Fonctionnement fondamental","text":"<p>Le r\u00e9seau Bridge est le mode r\u00e9seau par d\u00e9faut utilis\u00e9 par Docker lorsqu'un conteneur est cr\u00e9\u00e9 sans sp\u00e9cification de r\u00e9seau particulier[3][6]. Ce mode cr\u00e9e une isolation r\u00e9seau entre l'h\u00f4te et les conteneurs, tout en permettant une communication contr\u00f4l\u00e9e entre ces derniers[1].</p> <p>Lorsqu'un conteneur est lanc\u00e9 sans configuration r\u00e9seau sp\u00e9cifique, il se connecte automatiquement au r\u00e9seau bridge par d\u00e9faut appel\u00e9 docker0[3]. Ce r\u00e9seau fonctionne comme un pont virtuel, d'o\u00f9 son nom. Le m\u00e9canisme de pont utilise une couche interm\u00e9diaire pour g\u00e9rer la communication, ce qui offre une s\u00e9paration nette entre le r\u00e9seau de l'h\u00f4te et celui des conteneurs[1].</p>"},{"location":"_projects/_formation-docker/docker-chap07/#architecture-et-isolation","title":"Architecture et isolation","text":"<p>Le mode Bridge offre une isolation r\u00e9seau importante entre l'h\u00f4te et les conteneurs[1]. Cette isolation signifie que les conteneurs ne partagent pas directement les ports de la machine h\u00f4te. Pour acc\u00e9der \u00e0 un service ex\u00e9cut\u00e9 dans un conteneur depuis la machine locale, il est n\u00e9cessaire de mapper explicitement les ports[1].</p> <p>Le mapping de ports fonctionne selon le principe suivant : un port de la machine h\u00f4te est associ\u00e9 \u00e0 un port du conteneur, cr\u00e9ant ainsi un point d'acc\u00e8s public. Par exemple, le port 8080 de la machine h\u00f4te peut \u00eatre mapp\u00e9 au port 3000 du conteneur, permettant l'acc\u00e8s au service via <code>http://localhost:8080</code>[1].</p>"},{"location":"_projects/_formation-docker/docker-chap07/#avantages-du-reseau-bridge","title":"Avantages du r\u00e9seau Bridge","text":"<ul> <li>S\u00e9curit\u00e9 renforc\u00e9e : L'isolation r\u00e9seau cr\u00e9e une barri\u00e8re de s\u00e9curit\u00e9. Les conteneurs ne sont pas directement expos\u00e9s sur le r\u00e9seau de l'h\u00f4te, r\u00e9duisant les risques de s\u00e9curit\u00e9[1].</li> <li>Contr\u00f4le explicite : Chaque exposition de port doit \u00eatre d\u00e9clar\u00e9e intentionnellement, donnant au gestionnaire du syst\u00e8me un contr\u00f4le complet sur ce qui est accessible[1].</li> <li>Compatibilit\u00e9 : Le mode Bridge fonctionne sur toutes les plateformes, y compris Windows et macOS via Docker Desktop[5].</li> <li>Communication inter-conteneurs : Les conteneurs connect\u00e9s au m\u00eame r\u00e9seau Bridge peuvent communiquer entre eux par leurs noms de conteneur gr\u00e2ce au DNS interne de Docker[2].</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap07/#inconvenients-et-considerations","title":"Inconv\u00e9nients et consid\u00e9rations","text":"<p>L'inconv\u00e9nient principal du mode Bridge r\u00e9side dans les performances. La couche interm\u00e9diaire de mise en r\u00e9seau introduit une surcharge, r\u00e9duisant les performances par rapport au mode Host[1][5]. Pour les applications exigeantes en bande passante ou en latence, cette surcharge peut devenir significative.</p> <p>De plus, la gestion des ports mapp\u00e9s peut devenir complexe dans les architectures contenant de nombreux conteneurs[1].</p>"},{"location":"_projects/_formation-docker/docker-chap07/#creer-ses-reseaux-bridge-personnalises","title":"Cr\u00e9er ses r\u00e9seaux Bridge personnalis\u00e9s","text":""},{"location":"_projects/_formation-docker/docker-chap07/#commande-de-creation-basique","title":"Commande de cr\u00e9ation basique","text":"<p>La cr\u00e9ation d'un r\u00e9seau Bridge personnalis\u00e9 s'effectue avec la commande <code>docker network create</code>[1][4]. Contrairement \u00e0 l'utilisation du bridge par d\u00e9faut, les r\u00e9seaux personnalis\u00e9s offrent une meilleure isolation et un meilleur contr\u00f4le[3].</p> Bash<pre><code>docker network create --driver bridge nom-du-reseau\n</code></pre> <p>Cette commande cr\u00e9e un nouveau r\u00e9seau isol\u00e9. L'option <code>--driver bridge</code> sp\u00e9cifie explicitement que le pilote Bridge doit \u00eatre utilis\u00e9[4].</p>"},{"location":"_projects/_formation-docker/docker-chap07/#configuration-avancee-du-reseau","title":"Configuration avanc\u00e9e du r\u00e9seau","text":"<p>Pour un contr\u00f4le plus granulaire, Docker permet de configurer le sous-r\u00e9seau, la passerelle et la plage d'adresses IP[4].</p> Bash<pre><code>docker network create \\\n  --driver bridge \\\n  --subnet 192.168.100.0/24 \\\n  --gateway 192.168.100.1 \\\n  --ip-range 192.168.100.0/25 \\\n  mon-reseau-personnalise\n</code></pre> <p>Les param\u00e8tres cl\u00e9s sont : - <code>--subnet</code> : D\u00e9finit la plage d'adresses IP totale du r\u00e9seau - <code>--gateway</code> : Sp\u00e9cifie la passerelle du r\u00e9seau - <code>--ip-range</code> : Restreint les adresses IP que les conteneurs peuvent utiliser, distinctes de la plage compl\u00e8te du sous-r\u00e9seau[4]</p>"},{"location":"_projects/_formation-docker/docker-chap07/#inspection-du-reseau-bridge-par-defaut","title":"Inspection du r\u00e9seau Bridge par d\u00e9faut","text":"<p>La visualisation du r\u00e9seau par d\u00e9faut s'effectue avec la commande suivante[3] :</p> Bash<pre><code>docker network ls\n</code></pre> <p>Cette commande affiche tous les r\u00e9seaux disponibles :</p> NETWORK ID NAME DRIVER SCOPE 32cd2d55155f bridge bridge local b7fe5d1b69a7 host host local de5ae709fdcd none none local <p>Pour obtenir des informations d\u00e9taill\u00e9es sur un r\u00e9seau sp\u00e9cifique[3] :</p> Bash<pre><code>docker network inspect bridge\n</code></pre> <p>Cette commande fournit la configuration compl\u00e8te du r\u00e9seau, incluant les options comme <code>enable_icc</code> (inter-container communication), <code>enable_ip_masquerade</code> et d'autres param\u00e8tres[3].</p>"},{"location":"_projects/_formation-docker/docker-chap07/#configuration-du-serveur-et-deploiement-multi-conteneur","title":"Configuration du serveur et d\u00e9ploiement multi-conteneur","text":""},{"location":"_projects/_formation-docker/docker-chap07/#architecture-multi-conteneur-avec-docker-compose","title":"Architecture multi-conteneur avec Docker Compose","text":"<p>Pour des applications complexes impliquant plusieurs services, Docker Compose permet de d\u00e9finir et d'orchestrer plusieurs conteneurs utilisant un r\u00e9seau Bridge[1]. Cette approche simplifie la gestion des architectures multi-conteneurs.</p> <p>Un fichier <code>docker-compose.yml</code> typique pour une architecture Bridge ressemble \u00e0 ceci[1] :</p> YAML<pre><code>version: '3.8'\n\nservices:\n  ubuntu1:\n    image: ubuntu:24.10\n    container_name: ubuntu1\n    command: tail -f /dev/null\n    ports:\n      - \"9000:9000\"\n    networks:\n      - ubuntu_bridge\n\n  ubuntu2:\n    image: ubuntu:24.10\n    container_name: ubuntu2\n    command: tail -f /dev/null\n    networks:\n      - ubuntu_bridge\n\n  ubuntu3:\n    image: ubuntu:24.10\n    container_name: ubuntu3\n    command: tail -f /dev/null\n    networks:\n      - ubuntu_bridge\n\nnetworks:\n  ubuntu_bridge:\n    driver: bridge\n</code></pre> <p>La structure d\u00e9finie ci-dessus cr\u00e9e trois conteneurs Ubuntu interconnect\u00e9s via un r\u00e9seau Bridge nomm\u00e9 <code>ubuntu_bridge</code>. Le premier conteneur expose le port 9000 sur l'h\u00f4te[1].</p>"},{"location":"_projects/_formation-docker/docker-chap07/#deploiement-et-verification","title":"D\u00e9ploiement et v\u00e9rification","text":"<p>Le d\u00e9ploiement s'effectue avec la commande suivante[1] :</p> Bash<pre><code>docker-compose up\n</code></pre> <p>Cette commande cr\u00e9e et d\u00e9marre tous les conteneurs d\u00e9finis dans le fichier de composition. Les conteneurs sont automatiquement connect\u00e9s au r\u00e9seau <code>ubuntu_bridge</code> et peuvent communiquer entre eux par leurs noms de service[1].</p> <p>Pour v\u00e9rifier la communication inter-conteneurs, on peut acc\u00e9der \u00e0 un conteneur et tenter de faire un ping vers un autre[1] :</p> Bash<pre><code>docker exec ubuntu1 ping ubuntu2\n</code></pre> <p>Gr\u00e2ce au DNS interne de Docker, le conteneur ubuntu1 r\u00e9sout le nom <code>ubuntu2</code> vers son adresse IP dans le r\u00e9seau Bridge[2].</p>"},{"location":"_projects/_formation-docker/docker-chap07/#arret-et-redemarrage","title":"Arr\u00eat et red\u00e9marrage","text":"<p>Pour arr\u00eater tous les services, on utilise[1] :</p> Bash<pre><code># Arr\u00eat (Ctrl+C depuis le terminal ou)\ndocker-compose stop\n\n# Red\u00e9marrage\ndocker-compose restart\n\n# Arr\u00eat et suppression des conteneurs\ndocker-compose down\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap07/#connecter-un-serveur-nodejs-et-une-base-de-donnees-mongodb","title":"Connecter un serveur Node.js et une base de donn\u00e9es MongoDB","text":""},{"location":"_projects/_formation-docker/docker-chap07/#architecture-de-lapplication","title":"Architecture de l'application","text":"<p>L'un des cas d'usage les plus courants en production consiste \u00e0 connecter une application Node.js \u00e0 une base de donn\u00e9es MongoDB. Cette architecture d\u00e9montre comment les r\u00e9seaux Bridge permettent une communication s\u00e9curis\u00e9e et isol\u00e9e entre les services[2].</p>"},{"location":"_projects/_formation-docker/docker-chap07/#configuration-docker-compose-pour-nodejs-mongodb","title":"Configuration Docker Compose pour Node.js + MongoDB","text":"<p>Le fichier Docker Compose suivant orchestre cette architecture[2] :</p> YAML<pre><code>version: '3.8'\n\nservices:\n  mongodb:\n    image: mongo:latest\n    container_name: mongodb_db\n    environment:\n      MONGO_INITDB_ROOT_USERNAME: admin\n      MONGO_INITDB_ROOT_PASSWORD: password123\n    ports:\n      - \"27017:27017\"\n    volumes:\n      - mongodb_data:/data/db\n    networks:\n      - app_network\n    healthcheck:\n      test: echo 'db.runCommand(\"ping\").ok' | mongosh localhost:27017/test --quiet\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  nodejs_app:\n    image: node:20\n    container_name: nodejs_server\n    working_dir: /app\n    volumes:\n      - ./app:/app\n    environment:\n      MONGODB_URI: mongodb://admin:password123@mongodb_db:27017/mydb?authSource=admin\n    ports:\n      - \"3000:3000\"\n    depends_on:\n      mongodb:\n        condition: service_healthy\n    networks:\n      - app_network\n    command: npm start\n\nvolumes:\n  mongodb_data:\n\nnetworks:\n  app_network:\n    driver: bridge\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap07/#points-cles-de-cette-configuration","title":"Points cl\u00e9s de cette configuration","text":"<p>Isolation par r\u00e9seau : Les deux services (MongoDB et Node.js) sont connect\u00e9s au m\u00eame r\u00e9seau Bridge nomm\u00e9 <code>app_network</code>. Cette isolation garantit que seules les applications sur ce r\u00e9seau peuvent acc\u00e9der \u00e0 MongoDB[1].</p> <p>Communication par nom de service : Dans le fichier de configuration, l'application Node.js utilise <code>mongodb_db</code> (le nom du conteneur) comme h\u00f4te de base de donn\u00e9es. Le DNS interne de Docker r\u00e9sout ce nom vers l'adresse IP correcte du conteneur MongoDB[2].</p> <p>Authentification et variables d'environnement : Les variables d'environnement permettent de configurer les identifiants de base de donn\u00e9es et l'URI de connexion de mani\u00e8re flexible[2].</p> <p>D\u00e9pendances de service : L'option <code>depends_on</code> avec <code>condition: service_healthy</code> assure que Node.js ne d\u00e9marre que lorsque MongoDB est compl\u00e8tement pr\u00eat \u00e0 accepter les connexions[1].</p> <p>Persistance des donn\u00e9es : Le volume <code>mongodb_data</code> garantit que les donn\u00e9es de la base de donn\u00e9es persistent m\u00eame si le conteneur est arr\u00eat\u00e9 ou supprim\u00e9[1].</p>"},{"location":"_projects/_formation-docker/docker-chap07/#code-nodejs-pour-la-connexion","title":"Code Node.js pour la connexion","text":"<p>Un exemple simple de code Node.js se connectant \u00e0 MongoDB via le r\u00e9seau Docker[2] :</p> JavaScript<pre><code>const { MongoClient } = require('mongodb');\n\nconst mongoUri = process.env.MONGODB_URI || 'mongodb://admin:password123@mongodb_db:27017/mydb?authSource=admin';\n\nconst client = new MongoClient(mongoUri);\n\nasync function connectToDatabase() {\n  try {\n    await client.connect();\n    console.log('\u2705 Connexion \u00e0 MongoDB r\u00e9ussie');\n\n    const database = client.db('mydb');\n    const usersCollection = database.collection('users');\n\n    // Insertion d'un document\n    const result = await usersCollection.insertOne({\n      name: 'Jean Dupont',\n      email: 'jean@example.com',\n      created_at: new Date()\n    });\n\n    console.log(`Document ins\u00e9r\u00e9 avec l'ID: ${result.insertedId}`);\n\n    // R\u00e9cup\u00e9ration des documents\n    const users = await usersCollection.find({}).toArray();\n    console.log('Utilisateurs:', users);\n\n  } catch (error) {\n    console.error('\u274c Erreur de connexion:', error);\n  } finally {\n    await client.close();\n  }\n}\n\nconnectToDatabase();\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap07/#deploiement-de-larchitecture-complete","title":"D\u00e9ploiement de l'architecture compl\u00e8te","text":"<p>Une fois le fichier Docker Compose configur\u00e9, le d\u00e9ploiement s'effectue simplement[1] :</p> Bash<pre><code>docker-compose up -d\n</code></pre> <p>L'option <code>-d</code> lance les conteneurs en arri\u00e8re-plan. Pour v\u00e9rifier que les services communiquent correctement[1] :</p> Bash<pre><code>docker logs nodejs_server\n</code></pre> <p>Ce diagnostic affiche les journaux du conteneur Node.js, permettant de v\u00e9rifier que la connexion \u00e0 MongoDB s'est \u00e9tablie avec succ\u00e8s[1].</p>"},{"location":"_projects/_formation-docker/docker-chap07/#le-reseau-host","title":"Le r\u00e9seau Host","text":""},{"location":"_projects/_formation-docker/docker-chap07/#fonctionnement-fondamental_1","title":"Fonctionnement fondamental","text":"<p>Le mode Host repr\u00e9sente une approche radicalement diff\u00e9rente de la mise en r\u00e9seau Docker[1][5]. Contrairement au mode Bridge, le mode Host permet aux conteneurs de partager directement le r\u00e9seau de la machine h\u00f4te[1]. Cela signifie que le conteneur n'a pas sa propre interface r\u00e9seau virtuelle mais utilise directement l'interface r\u00e9seau de l'h\u00f4te[5].</p> <p>Dans cette configuration, les conteneurs utilisent la m\u00eame adresse IP et les m\u00eames ports que l'h\u00f4te, sans passer par une couche interm\u00e9diaire[1]. Cette approche \u00e9limine compl\u00e8tement l'abstraction r\u00e9seau, cr\u00e9ant une connexion directe au r\u00e9seau de la machine h\u00f4te[1].</p>"},{"location":"_projects/_formation-docker/docker-chap07/#implications-pratiques-du-mode-host","title":"Implications pratiques du mode Host","text":"<p>Pas de mapping de ports requis : En mode Host, le mapping de ports n'est pas n\u00e9cessaire puisque les conteneurs partagent d\u00e9j\u00e0 les ports de l'h\u00f4te[1]. Un service s'ex\u00e9cutant sur le port 8080 dans un conteneur Host est directement accessible sur le port 8080 de la machine h\u00f4te[1][5].</p> <p>Partage complet du r\u00e9seau : Les conteneurs acc\u00e8dent directement \u00e0 toutes les interfaces r\u00e9seau et aux routes de l'h\u00f4te[1]. Cette approche \u00e9limine les limitations impos\u00e9es par le mode Bridge[5].</p> <p>Absence d'isolation r\u00e9seau : L'isolation r\u00e9seau dispara\u00eet compl\u00e8tement. Les conteneurs et l'h\u00f4te partagent le m\u00eame espace r\u00e9seau[1][5]. Cela signifie qu'un conteneur a acc\u00e8s aux m\u00eames services r\u00e9seau que l'h\u00f4te[5].</p>"},{"location":"_projects/_formation-docker/docker-chap07/#avantages-et-inconvenients-du-mode-host","title":"Avantages et inconv\u00e9nients du mode Host","text":"<p>Avantages :</p> <ul> <li>Performance sup\u00e9rieure : Aucune couche interm\u00e9diaire n'intervient, \u00e9liminant la surcharge r\u00e9seau[1][5]. Cette am\u00e9lioration de performance est particuli\u00e8rement importante pour les applications exigeantes en bande passante ou en latence faible[1].</li> <li>Simplification de la configuration : Pas besoin de mapper les ports ou de g\u00e9rer les expositions de service[1].</li> <li>Acc\u00e8s aux services r\u00e9seau locaux : Les conteneurs peuvent acc\u00e9der directement \u00e0 tous les services r\u00e9seau de la machine h\u00f4te[1].</li> </ul> <p>Inconv\u00e9nients :</p> <ul> <li>Risques de s\u00e9curit\u00e9 : L'absence d'isolation cr\u00e9e des risques significatifs[1][5]. Les conteneurs peuvent potentiellement interferer les uns avec les autres et avec les services de l'h\u00f4te[1].</li> <li>Conflits de ports : Si plusieurs conteneurs ou l'h\u00f4te tentent d'utiliser le m\u00eame port, des conflits irr\u00e9vocables surviennent[1][5]. Ce probl\u00e8me rend impossible l'ex\u00e9cution de plusieurs conteneurs utilisant les m\u00eames ports sur le m\u00eame h\u00f4te[1].</li> <li>Portabilit\u00e9 r\u00e9duite : Les conteneurs Host ne sont pas portables entre les h\u00f4tes avec des configurations r\u00e9seau diff\u00e9rentes[1].</li> <li>Limitation de compatibilit\u00e9 : Le mode Host n'est pas disponible sur Windows et macOS[5]. Il fonctionne uniquement sur Linux natif[5].</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap07/#configuration-du-mode-host","title":"Configuration du mode Host","text":"<p>Pour lancer un conteneur en mode Host, on utilise l'option <code>--network host</code>[5] :</p> Bash<pre><code>docker run --network host nginx\n</code></pre> <p>Cette commande d\u00e9marre un conteneur Nginx en mode Host. Le service Nginx est directement accessible sur le port 80 de la machine h\u00f4te[1][5].</p>"},{"location":"_projects/_formation-docker/docker-chap07/#docker-compose-avec-mode-host","title":"Docker Compose avec mode Host","text":"<p>Pour utiliser le mode Host dans Docker Compose, on sp\u00e9cifie <code>network_mode: host</code> dans la configuration du service[1] :</p> YAML<pre><code>version: '3.8'\n\nservices:\n  ubuntu1:\n    image: ubuntu:24.10\n    container_name: ubuntu1\n    command: tail -f /dev/null\n    network_mode: host\n\n  ubuntu2:\n    image: ubuntu:24.10\n    container_name: ubuntu2\n    command: tail -f /dev/null\n    network_mode: host\n\n  ubuntu3:\n    image: ubuntu:24.10\n    container_name: ubuntu3\n    command: tail -f /dev/null\n    network_mode: host\n</code></pre> <p>Dans cette configuration, tous les conteneurs partagent l'interface r\u00e9seau de l'h\u00f4te[1]. Aucun mapping de port n'est d\u00e9fini, car les ports sont directement partag\u00e9s[1].</p>"},{"location":"_projects/_formation-docker/docker-chap07/#demonstration-pratique-du-mode-host","title":"D\u00e9monstration pratique du mode Host","text":"<p>Pour v\u00e9rifier que les conteneurs partagent bien le r\u00e9seau de l'h\u00f4te, on peut ex\u00e9cuter une commande d'affichage de l'adresse IP[1][5] :</p> Bash<pre><code>docker run --network host ubuntu hostname -I\n</code></pre> <p>Cette commande affichera l'adresse IP de la machine h\u00f4te, non une adresse IP de conteneur. Cette d\u00e9monstration prouve que le conteneur utilise directement le r\u00e9seau de l'h\u00f4te[1][5].</p>"},{"location":"_projects/_formation-docker/docker-chap07/#comparaison-detaillee-bridge-vs-host","title":"Comparaison d\u00e9taill\u00e9e : Bridge vs Host","text":""},{"location":"_projects/_formation-docker/docker-chap07/#tableau-recapitulatif","title":"Tableau r\u00e9capitulatif","text":"Caract\u00e9ristique Bridge Host Isolation r\u00e9seau Oui, isolation compl\u00e8te Non, partage du r\u00e9seau Mapping de ports Obligatoire Non n\u00e9cessaire Performance Bonne (avec surcharge) Excellente (pas de surcharge) S\u00e9curit\u00e9 Renforc\u00e9e R\u00e9duite Conflits de ports Peu probables Tr\u00e8s probables Portabilit\u00e9 Excellente Limit\u00e9e Compatibilit\u00e9 Toutes les plateformes Linux uniquement Communication inter-conteneurs Via DNS Docker Direct via localhost Acc\u00e8s aux services h\u00f4te Limit\u00e9 Complet Configuration Mod\u00e9r\u00e9e Simple"},{"location":"_projects/_formation-docker/docker-chap07/#scenarios-dutilisation","title":"Sc\u00e9narios d'utilisation","text":"<p>Utiliser Bridge :</p> <ul> <li>Applications en production n\u00e9cessitant la s\u00e9curit\u00e9</li> <li>Architectures multi-conteneurs complexes</li> <li>D\u00e9ploiement sur Windows ou macOS</li> <li>S\u00e9paration claire entre services</li> <li>Applications web classiques avec plusieurs tiers</li> </ul> <p>Utiliser Host :</p> <ul> <li>Applications requ\u00e9rant une performance maximale</li> <li>Services s'ex\u00e9cutant sur Linux natif</li> <li>Clusters Kubernetes (utilise surtout le mode bridge)</li> <li>Applications legacy n\u00e9cessitant un acc\u00e8s r\u00e9seau complet</li> <li>Conteneurs uniques sans risque de conflit</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap07/#concepts-avances-de-mise-en-reseau-docker","title":"Concepts avanc\u00e9s de mise en r\u00e9seau Docker","text":""},{"location":"_projects/_formation-docker/docker-chap07/#resolution-de-noms-dns-internes","title":"R\u00e9solution de noms DNS internes","text":"<p>Le DNS interne de Docker permet une r\u00e9solution de noms transparente[2]. Lorsqu'un conteneur tente d'acc\u00e9der \u00e0 un autre conteneur par son nom, le serveur DNS de Docker (adresse 127.0.0.11)[3] r\u00e9sout ce nom vers l'adresse IP correcte du conteneur.</p> <p>Cette r\u00e9solution s'effectue automatiquement lorsque les conteneurs sont connect\u00e9s au m\u00eame r\u00e9seau Bridge[2]. Dans le fichier <code>/etc/resolv.conf</code> du conteneur, on retrouve[3] :</p> Text Only<pre><code>nameserver 127.0.0.11\noptions ndots:0\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap07/#inspection-du-reseau","title":"Inspection du r\u00e9seau","text":"<p>Pour obtenir des informations d\u00e9taill\u00e9es sur la configuration d'un r\u00e9seau[3] :</p> Bash<pre><code>docker network inspect bridge\n</code></pre> <p>Cette commande fournit un JSON d\u00e9taill\u00e9 contenant : - Les conteneurs connect\u00e9s et leurs adresses IP - Les options r\u00e9seau (enable_icc, enable_ip_masquerade, etc.) - La configuration de la passerelle - La plage d'adresses IP</p>"},{"location":"_projects/_formation-docker/docker-chap07/#progression-pedagogique-recommandee","title":"Progression p\u00e9dagogique recommand\u00e9e","text":"<p>L'apprentissage des r\u00e9seaux Docker doit suivre une progression logique :</p> <p>\u00c9tape 1 : Compr\u00e9hension du bridge par d\u00e9faut : Commencer par ex\u00e9cuter des conteneurs simples sans configuration r\u00e9seau explicite. Observer comment Docker assigne automatiquement les adresses IP et permet la communication entre conteneurs via le bridge par d\u00e9faut[3].</p> <p>\u00c9tape 2 : Introduction au mapping de ports : Cr\u00e9er des conteneurs ex\u00e9cutant des services (Nginx, Apache) et mapper les ports pour comprendre comment les services deviennent accessibles depuis l'h\u00f4te[1].</p> <p>\u00c9tape 3 : Cr\u00e9ation de r\u00e9seaux personnalis\u00e9s : Cr\u00e9er des r\u00e9seaux Bridge nomm\u00e9s et connecter plusieurs conteneurs, en comprenant les avantages de l'isolation par rapport au bridge par d\u00e9faut[1][4].</p> <p>\u00c9tape 4 : Exploration du DNS interne : Utiliser la r\u00e9solution de noms par conteneur pour \u00e9tablir la communication entre services sans adresses IP statiques[2].</p> <p>\u00c9tape 5 : Introduction \u00e0 Docker Compose : Basculer vers des fichiers de composition pour g\u00e9rer des architectures multi-conteneurs[1].</p> <p>\u00c9tape 6 : Cas r\u00e9el multi-services : Impl\u00e9menter l'architecture Node.js + MongoDB, renfor\u00e7ant la compr\u00e9hension de la communication s\u00e9curis\u00e9e entre services[2].</p> <p>\u00c9tape 7 : Exploration du mode Host : Une fois le mode Bridge ma\u00eetris\u00e9, explorer le mode Host pour comprendre les compromis entre s\u00e9curit\u00e9 et performance[1][5].</p> <p>\u00c9tape 8 : Diagnostique et r\u00e9solution de probl\u00e8mes : Apprendre \u00e0 utiliser <code>docker network inspect</code>, <code>docker logs</code> et <code>docker exec</code> pour d\u00e9boguer les probl\u00e8mes de connectivit\u00e9[3].</p>"},{"location":"_projects/_formation-docker/docker-chap07/#diagnostique-et-resolution-de-problemes","title":"Diagnostique et r\u00e9solution de probl\u00e8mes","text":""},{"location":"_projects/_formation-docker/docker-chap07/#verification-de-la-connectivite","title":"V\u00e9rification de la connectivit\u00e9","text":"<p>Lorsqu'une communication entre conteneurs \u00e9choue, on peut v\u00e9rifier la connectivit\u00e9[1] :</p> Bash<pre><code>docker exec nomduconteneur ping nomduconteneurDistant\n</code></pre> <p>Si le ping \u00e9choue, v\u00e9rifier que les deux conteneurs sont connect\u00e9s au m\u00eame r\u00e9seau[1].</p>"},{"location":"_projects/_formation-docker/docker-chap07/#inspection-detaillee-des-reseaux","title":"Inspection d\u00e9taill\u00e9e des r\u00e9seaux","text":"<p>Pour analyser les configurations r\u00e9seau[3] :</p> Bash<pre><code>docker network inspect nom_du_reseau | grep -A 20 Containers\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap07/#verification-des-ports-mappes","title":"V\u00e9rification des ports mapp\u00e9s","text":"<p>Pour s'assurer que les ports sont correctement mapp\u00e9s[1] :</p> Bash<pre><code>docker ps --format \"table {{.Names}}\\t{{.Ports}}\"\n</code></pre> <p>Cette commande affiche une liste des conteneurs et de leurs mappages de ports[1].</p> <p>Cette formation compl\u00e8te offre une base solide pour comprendre et ma\u00eetriser la mise en r\u00e9seau Docker, essentielle pour construire des applications conteneuris\u00e9es robustes et s\u00e9curis\u00e9es[1][2][3][4][5].</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-docker/docker-chap08/","title":"Citations","text":"<ul> <li>https://xavki.blog/docker-compose-tutoriaux-francais/</li> <li>https://senza-formations.com/nos-articles/tutoriel-docker-compose-orchestrer-plusieurs-conteneurs-facilement</li> <li>https://www.datacamp.com/fr/tutorial/docker-compose-guide</li> <li>https://www.ionos.fr/digitalguide/serveur/configuration/tutoriel-docker-compose/</li> <li>https://blog.stephane-robert.info/docs/conteneurs/orchestrateurs/docker-compose/</li> <li>https://tropars.github.io/downloads/lectures/Docker/formation_docker.pdf</li> <li>https://www.youtube.com/watch?v=04TkqB5WdL0</li> <li>https://www.youtube.com/watch?v=nkg48NLgGxE</li> <li>https://openclassrooms.com/fr/courses/8431896-optimisez-votre-deploiement-en-creant-des-conteneurs-avec-docker/8483935-integrez-votre-container-dans-un-ecosysteme-avec-docker-compose</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap08/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 338</li> <li>completion_tokens: 6222</li> <li>total_tokens: 6560</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.093, 'request_cost': 0.006, 'total_cost': 0.1}</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap08/#content","title":"Content","text":""},{"location":"_projects/_formation-docker/docker-chap08/#docker-compose-guide-complet-et-detaille","title":"Docker Compose : Guide Complet et D\u00e9taill\u00e9","text":""},{"location":"_projects/_formation-docker/docker-chap08/#introduction-a-docker-compose","title":"Introduction \u00e0 Docker Compose","text":"<p>Docker Compose est un outil de ligne de commande fondamental pour g\u00e9rer des applications multi-conteneurs Docker[1]. Il simplifie consid\u00e9rablement l'orchestration de plusieurs conteneurs en utilisant un unique fichier de configuration YAML, permettant de d\u00e9finir tous les services, r\u00e9seaux, volumes et d\u00e9pendances d'une application complexe[3].</p>"},{"location":"_projects/_formation-docker/docker-chap08/#contexte-et-problematique","title":"Contexte et Probl\u00e9matique","text":"<p>Sans Docker Compose, la gestion manuelle de plusieurs conteneurs interconnect\u00e9s devient rapidement fastidieuse. Chaque conteneur doit \u00eatre cr\u00e9\u00e9 individuellement, configur\u00e9 s\u00e9par\u00e9ment, et les connexions r\u00e9seau doivent \u00eatre \u00e9tablies manuellement. Docker Compose r\u00e9sout ce probl\u00e8me en automatisant ces \u00e9tapes et en centralisant toute la configuration dans un seul fichier[3].</p>"},{"location":"_projects/_formation-docker/docker-chap08/#avantages-cles","title":"Avantages Cl\u00e9s","text":"<p>Docker Compose offre plusieurs b\u00e9n\u00e9fices majeurs pour le d\u00e9veloppement et le d\u00e9ploiement :</p> <ul> <li>Simplicit\u00e9 de d\u00e9ploiement : Une seule commande (<code>docker-compose up</code>) suffit pour d\u00e9marrer une application enti\u00e8re avec tous ses composants[2]</li> <li>Coh\u00e9rence : Toute la configuration est centralis\u00e9e et versionn\u00e9e, r\u00e9duisant les erreurs dues \u00e0 des configurations manuelles incoh\u00e9rentes[3]</li> <li>R\u00e9seaux automatiques : Compose cr\u00e9e automatiquement un r\u00e9seau par d\u00e9faut permettant la communication entre tous les conteneurs[3]</li> <li>Gestion des volumes : Les volumes persistants sont g\u00e9r\u00e9s automatiquement et r\u00e9attach\u00e9s lors des red\u00e9marrages[3]</li> <li>D\u00e9veloppement local : Permet de simuler des environnements de production complexes directement sur la machine de d\u00e9veloppement[2]</li> <li>Portabilit\u00e9 : Les configurations fonctionnent de mani\u00e8re identique sur Linux, macOS et Windows[2]</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap08/#prerequis-et-installation","title":"Pr\u00e9requis et Installation","text":""},{"location":"_projects/_formation-docker/docker-chap08/#configuration-requise","title":"Configuration Requise","text":"<p>Pour utiliser Docker Compose, deux approches principales sont disponibles[4] :</p> <ol> <li>Installation binaire autonome : Docker Engine et Docker Compose install\u00e9s s\u00e9par\u00e9ment</li> <li>Docker Desktop : Solution compl\u00e8te incluant Docker Engine, Docker Compose et une interface graphique</li> </ol>"},{"location":"_projects/_formation-docker/docker-chap08/#installation-sur-windows","title":"Installation sur Windows","text":"<p>L'installation sur Windows s'effectue facilement via Docker Desktop[2] :</p> Bash<pre><code># Apr\u00e8s avoir t\u00e9l\u00e9charg\u00e9 et install\u00e9 Docker Desktop, v\u00e9rifier l'installation\ndocker-compose --version\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#installation-sur-linux-et-macos","title":"Installation sur Linux et macOS","text":"<p>Sur les syst\u00e8mes Unix-like, Docker Compose peut \u00eatre install\u00e9 comme un binaire autonome ou en tant que composant de Docker Desktop[2].</p>"},{"location":"_projects/_formation-docker/docker-chap08/#structure-fondamentale-dun-fichier-docker-composeyml","title":"Structure Fondamentale d'un Fichier docker-compose.yml","text":""},{"location":"_projects/_formation-docker/docker-chap08/#anatomie-du-fichier-de-configuration","title":"Anatomie du Fichier de Configuration","text":"<p>Le fichier <code>docker-compose.yml</code> constitue le c\u0153ur de toute configuration Docker Compose[2]. Il utilise la syntaxe YAML pour d\u00e9finir l'ensemble de l'infrastructure conteneuris\u00e9e.</p> YAML<pre><code>version: '3.8'\n\nservices:\n  web:\n    image: nginx:latest\n    ports:\n      - \"80:80\"\n    volumes:\n      - ./html:/usr/share/nginx/html\n    networks:\n      - app-network\n    environment:\n      - NGINX_HOST=example.com\n      - NGINX_PORT=80\n    depends_on:\n      - db\n\n  db:\n    image: mysql:8.0\n    environment:\n      - MYSQL_ROOT_PASSWORD=secret\n      - MYSQL_DATABASE=myapp\n    volumes:\n      - db-data:/var/lib/mysql\n    networks:\n      - app-network\n\nvolumes:\n  db-data:\n\nnetworks:\n  app-network:\n    driver: bridge\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#sections-principales","title":"Sections Principales","text":"<p>Le fichier <code>docker-compose.yml</code> se compose de plusieurs sections cl\u00e9s[2] :</p> <p>Services : D\u00e9finit les conteneurs constituant l'application. Chaque service peut sp\u00e9cifier une image, construire un Dockerfile, configurer des ports, des volumes, des variables d'environnement et des d\u00e9pendances.</p> <p>Volumes : D\u00e9clare les volumes nomm\u00e9s utilis\u00e9s par les services pour la persistance des donn\u00e9es. Ces volumes peuvent \u00eatre mont\u00e9s sur plusieurs conteneurs.</p> <p>Networks : D\u00e9finit les r\u00e9seaux personnalis\u00e9s permettant la communication entre les conteneurs. Par d\u00e9faut, Compose cr\u00e9e un r\u00e9seau bridge.</p> <p>Syntaxe YAML Core[3] : Les \u00e9l\u00e9ments essentiels comprennent <code>services</code> pour les applications conteneuris\u00e9es, <code>images</code> ou <code>build</code> pour sp\u00e9cifier les conteneurs, <code>ports</code> pour exposer les services, <code>volumes</code> pour le stockage persistant, et <code>networks</code> pour la communication interservices.</p>"},{"location":"_projects/_formation-docker/docker-chap08/#premiere-utilisation-de-docker-compose","title":"Premi\u00e8re Utilisation de Docker Compose","text":""},{"location":"_projects/_formation-docker/docker-chap08/#commande-de-base-docker-compose-up","title":"Commande de Base : docker-compose up","text":"<p>La commande <code>docker-compose up</code> constitue le point de d\u00e9part pour utiliser Docker Compose[2].</p> Bash<pre><code># D\u00e9marrer tous les services en mode attach\u00e9 (logs visibles)\ndocker-compose up\n\n# D\u00e9marrer tous les services en arri\u00e8re-plan (-d pour detached)\ndocker-compose up -d\n\n# Reconstruire les images avant de d\u00e9marrer\ndocker-compose up --build\n\n# D\u00e9marrer des services sp\u00e9cifiques uniquement\ndocker-compose up service1 service2\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#ce-qui-se-passe-lors-de-docker-compose-up","title":"Ce qui se Passe Lors de docker-compose up","text":"<p>Lorsque cette commande est ex\u00e9cut\u00e9e, Docker Compose effectue les op\u00e9rations suivantes[2] :</p> <ol> <li>Cr\u00e9e les conteneurs pour chaque service d\u00e9fini</li> <li>\u00c9tablit les r\u00e9seaux sp\u00e9cifi\u00e9s</li> <li>Cr\u00e9e les volumes nomm\u00e9s</li> <li>D\u00e9marre les conteneurs dans l'ordre appropri\u00e9 (en respectant les d\u00e9pendances)</li> <li>Connecte les conteneurs aux r\u00e9seaux</li> <li>Attache les volumes aux points de montage</li> </ol>"},{"location":"_projects/_formation-docker/docker-chap08/#exemple-pratique-application-web-avec-base-de-donnees","title":"Exemple Pratique : Application Web avec Base de Donn\u00e9es","text":"YAML<pre><code>version: '3.8'\n\nservices:\n  webapp:\n    image: python:3.9\n    ports:\n      - \"5000:5000\"\n    volumes:\n      - ./app:/app\n    working_dir: /app\n    command: python app.py\n    environment:\n      - DATABASE_URL=mysql://root:password@db:3306/mydb\n    depends_on:\n      - db\n\n  db:\n    image: mysql:8.0\n    environment:\n      - MYSQL_ROOT_PASSWORD=password\n      - MYSQL_DATABASE=mydb\n    volumes:\n      - mysql-data:/var/lib/mysql\n    ports:\n      - \"3306:3306\"\n\nvolumes:\n  mysql-data:\n</code></pre> <p>Avec cette configuration, une seule commande <code>docker-compose up</code> suffit pour d\u00e9marrer \u00e0 la fois l'application web Python et la base de donn\u00e9es MySQL, avec la connectivit\u00e9 r\u00e9seau automatiquement \u00e9tablie.</p>"},{"location":"_projects/_formation-docker/docker-chap08/#configuration-des-services-images-personnalisees","title":"Configuration des Services : Images Personnalis\u00e9es","text":""},{"location":"_projects/_formation-docker/docker-chap08/#utilisation-dimages-existantes","title":"Utilisation d'Images Existantes","text":"<p>La mani\u00e8re la plus simple de configurer un service consiste \u00e0 utiliser une image existante :</p> YAML<pre><code>services:\n  nginx:\n    image: nginx:latest\n    ports:\n      - \"80:80\"\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#construction-dimages-personnalisees-avec-build","title":"Construction d'Images Personnalis\u00e9es avec build","text":"<p>Pour les projets n\u00e9cessitant une configuration sp\u00e9cifique, l'option <code>build</code> permet de construire une image \u00e0 partir d'un Dockerfile[2].</p> YAML<pre><code>services:\n  app:\n    build:\n      context: ./app\n      dockerfile: Dockerfile\n    ports:\n      - \"8000:8000\"\n</code></pre> <p>Le contexte <code>context</code> sp\u00e9cifie le r\u00e9pertoire contenant le Dockerfile et les fichiers n\u00e9cessaires \u00e0 la construction. Lors de <code>docker-compose up --build</code>, Docker Compose construit l'image avant de lancer le conteneur.</p>"},{"location":"_projects/_formation-docker/docker-chap08/#exemple-complet-avec-dockerfile-personnalise","title":"Exemple Complet avec Dockerfile Personnalis\u00e9","text":"<p>Dockerfile : Docker<pre><code>FROM python:3.9-slim\n\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\nCOPY . .\n\nEXPOSE 5000\n\nCMD [\"python\", \"app.py\"]\n</code></pre></p> <p>docker-compose.yml : YAML<pre><code>version: '3.8'\n\nservices:\n  app:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    ports:\n      - \"5000:5000\"\n    volumes:\n      - ./src:/app/src\n    environment:\n      - FLASK_ENV=development\n      - DEBUG=True\n</code></pre></p>"},{"location":"_projects/_formation-docker/docker-chap08/#gestion-des-reseaux-avec-docker-compose","title":"Gestion des R\u00e9seaux avec Docker Compose","text":""},{"location":"_projects/_formation-docker/docker-chap08/#reseaux-automatiques","title":"R\u00e9seaux Automatiques","text":"<p>Par d\u00e9faut, Docker Compose cr\u00e9e automatiquement un r\u00e9seau bridge pour tous les services[3]. Ce r\u00e9seau permet une communication transparente entre les conteneurs en utilisant les noms des services comme hostnames.</p> YAML<pre><code>version: '3.8'\n\nservices:\n  web:\n    image: nginx:latest\n    # Le conteneur web peut acc\u00e9der au conteneur db via 'db:3306'\n\n  db:\n    image: mysql:8.0\n    # Le conteneur db peut acc\u00e9der au conteneur web via 'web:80'\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#reseaux-personnalises","title":"R\u00e9seaux Personnalis\u00e9s","text":"<p>Pour un contr\u00f4le plus granulaire, il est possible de d\u00e9finir des r\u00e9seaux explicites :</p> YAML<pre><code>version: '3.8'\n\nservices:\n  frontend:\n    image: nginx:latest\n    networks:\n      - frontend-network\n\n  backend:\n    image: python:3.9\n    networks:\n      - backend-network\n      - shared-network\n\n  db:\n    image: mysql:8.0\n    networks:\n      - shared-network\n\nnetworks:\n  frontend-network:\n    driver: bridge\n  backend-network:\n    driver: bridge\n  shared-network:\n    driver: bridge\n</code></pre> <p>Dans cet exemple, le frontend ne peut communiquer qu'avec lui-m\u00eame, le backend peut communiquer avec la base de donn\u00e9es et le r\u00e9seau partag\u00e9, tandis que la base de donn\u00e9es est accessible uniquement depuis le r\u00e9seau partag\u00e9.</p>"},{"location":"_projects/_formation-docker/docker-chap08/#communication-interservices","title":"Communication Interservices","text":"<p>Les services dans le m\u00eame r\u00e9seau peuvent se d\u00e9couvrir mutuellement par nom de service[3]. Par exemple, une application Python peut se connecter \u00e0 MySQL en utilisant simplement <code>mysql://db:3306/database</code>.</p>"},{"location":"_projects/_formation-docker/docker-chap08/#variables-denvironnement-et-configuration","title":"Variables d'Environnement et Configuration","text":""},{"location":"_projects/_formation-docker/docker-chap08/#definition-des-variables-denvironnement","title":"D\u00e9finition des Variables d'Environnement","text":"<p>Les variables d'environnement permettent de configurer les services dynamiquement sans modifier le <code>docker-compose.yml</code>[3].</p> YAML<pre><code>version: '3.8'\n\nservices:\n  app:\n    image: myapp:latest\n    environment:\n      - NODE_ENV=production\n      - DATABASE_HOST=db\n      - DATABASE_PORT=5432\n      - DEBUG=false\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#fichiers-env","title":"Fichiers .env","text":"<p>Pour faciliter la gestion des variables, un fichier <code>.env</code> peut \u00eatre cr\u00e9\u00e9 :</p> Bash<pre><code># .env\nMYSQL_ROOT_PASSWORD=secure_password_123\nMYSQL_DATABASE=production_db\nFLASK_ENV=production\nDEBUG=false\nAPP_PORT=8000\n</code></pre> <p>Puis r\u00e9f\u00e9renc\u00e9 dans le <code>docker-compose.yml</code> :</p> YAML<pre><code>version: '3.8'\n\nservices:\n  app:\n    environment:\n      - FLASK_ENV=${FLASK_ENV}\n      - DEBUG=${DEBUG}\n      - APP_PORT=${APP_PORT}\n\n  db:\n    environment:\n      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}\n      - MYSQL_DATABASE=${MYSQL_DATABASE}\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#substitution-de-variables","title":"Substitution de Variables","text":"<p>Docker Compose substitue automatiquement les variables <code>${VARIABLE}</code> par leurs valeurs du fichier <code>.env</code>[3]. Si une variable n'est pas d\u00e9finie, une cha\u00eene vide est utilis\u00e9e par d\u00e9faut, ou une erreur peut \u00eatre lev\u00e9e selon la configuration.</p>"},{"location":"_projects/_formation-docker/docker-chap08/#configuration-des-dependances-et-du-redemarrage","title":"Configuration des D\u00e9pendances et du Red\u00e9marrage","text":""},{"location":"_projects/_formation-docker/docker-chap08/#depends_on-gestion-de-lordre-de-demarrage","title":"depends_on : Gestion de l'Ordre de D\u00e9marrage","text":"<p>L'option <code>depends_on</code> sp\u00e9cifie les d\u00e9pendances entre services, contr\u00f4lant l'ordre de d\u00e9marrage[2].</p> YAML<pre><code>version: '3.8'\n\nservices:\n  web:\n    image: nginx:latest\n    depends_on:\n      - app\n      - db\n\n  app:\n    build: .\n    depends_on:\n      - db\n\n  db:\n    image: mysql:8.0\n</code></pre> <p>Dans cet exemple, l'ordre de d\u00e9marrage sera : db \u2192 app \u2192 web. Cependant, il est important de noter que <code>depends_on</code> n'attend que le d\u00e9marrage du conteneur, pas sa pleine disponibilit\u00e9. Une application web attendra que MySQL soit en \u00e9coute, ce qui peut n\u00e9cessiter une logique suppl\u00e9mentaire dans l'application.</p>"},{"location":"_projects/_formation-docker/docker-chap08/#attendre-la-disponibilite-des-services","title":"Attendre la Disponibilit\u00e9 des Services","text":"<p>Pour attendre que le service soit r\u00e9ellement pr\u00eat, une approche consiste \u00e0 utiliser des v\u00e9rifications d'\u00e9tat ou une logique de retry dans l'application :</p> YAML<pre><code>version: '3.8'\n\nservices:\n  app:\n    build: .\n    depends_on:\n      - db\n    environment:\n      - DATABASE_HOST=db\n      - DATABASE_RETRY_ATTEMPTS=5\n      - DATABASE_RETRY_DELAY=2\n\n  db:\n    image: mysql:8.0\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#restart-politique-de-redemarrage","title":"restart : Politique de Red\u00e9marrage","text":"<p>L'option <code>restart</code> d\u00e9finit la politique de red\u00e9marrage automatique des conteneurs[2].</p> YAML<pre><code>version: '3.8'\n\nservices:\n  critical_service:\n    image: myapp:latest\n    restart: always\n    # Ce service red\u00e9marrera toujours s'il s'arr\u00eate\n\n  temporary_service:\n    image: worker:latest\n    restart: on-failure\n    # Ce service red\u00e9marrera uniquement en cas d'erreur\n\n  one_time_task:\n    image: cleanup:latest\n    restart: no\n    # Ce service ne red\u00e9marrera jamais\n</code></pre> <p>Les politiques disponibles sont[2] :</p> <ul> <li>no : Pas de red\u00e9marrage automatique</li> <li>always : Toujours red\u00e9marrer, m\u00eame apr\u00e8s un arr\u00eat manuel</li> <li>on-failure : Red\u00e9marrer uniquement si le conteneur s'arr\u00eate avec un code de sortie non-z\u00e9ro</li> <li>unless-stopped : Toujours red\u00e9marrer sauf si le conteneur a \u00e9t\u00e9 explicitement arr\u00eat\u00e9</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap08/#ports-et-volumes-avec-docker-compose","title":"Ports et Volumes avec Docker Compose","text":""},{"location":"_projects/_formation-docker/docker-chap08/#configuration-des-ports","title":"Configuration des Ports","text":"<p>L'option <code>ports</code> expose les ports des conteneurs vers l'h\u00f4te[2].</p> YAML<pre><code>version: '3.8'\n\nservices:\n  web:\n    image: nginx:latest\n    ports:\n      # Syntaxe: \"port_h\u00f4te:port_conteneur\"\n      - \"80:80\"\n      - \"443:443\"\n      - \"8080:3000\"\n      # Liaison sur une interface sp\u00e9cifique\n      - \"127.0.0.1:5000:5000\"\n</code></pre> <p>La notation <code>\"8080:3000\"</code> signifie que le port 8080 de l'h\u00f4te est mapp\u00e9 vers le port 3000 du conteneur[7]. Les requ\u00eates vers <code>localhost:8080</code> acc\u00e8dent au conteneur sur le port 3000.</p>"},{"location":"_projects/_formation-docker/docker-chap08/#exposition-implicite-avec-expose","title":"Exposition Implicite avec expose","text":"<p>Pour permettre la communication entre conteneurs sans exposer vers l'h\u00f4te :</p> YAML<pre><code>version: '3.8'\n\nservices:\n  app:\n    image: myapp:latest\n    expose:\n      - \"3000\"\n    # Le port 3000 est accessible depuis d'autres conteneurs\n    # mais pas depuis l'h\u00f4te\n\n  nginx:\n    image: nginx:latest\n    ports:\n      - \"80:80\"\n    depends_on:\n      - app\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#gestion-des-volumes","title":"Gestion des Volumes","text":"<p>Les volumes permettent la persistance des donn\u00e9es et le partage de fichiers[2].</p> YAML<pre><code>version: '3.8'\n\nservices:\n  db:\n    image: mysql:8.0\n    volumes:\n      # Volume nomm\u00e9 pour la persistance\n      - db-data:/var/lib/mysql\n\n  app:\n    build: .\n    volumes:\n      # Montage de r\u00e9pertoire local pour le d\u00e9veloppement\n      - ./src:/app/src\n      # Montage en lecture seule\n      - ./config:/app/config:ro\n\nvolumes:\n  db-data:\n    # Volume nomm\u00e9 persistant\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#types-de-montages","title":"Types de Montages","text":"Type Syntax Usage Volume Nomm\u00e9 <code>name:/path</code> Persistance de donn\u00e9es, gestion centralis\u00e9e Bind Mount <code>./local:/container</code> D\u00e9veloppement, partage de fichiers h\u00f4te Read-Only <code>./local:/container:ro</code> Configurations immuables, s\u00e9curit\u00e9 Relative Path <code>./relative:/path</code> Chemin relatif au docker-compose.yml"},{"location":"_projects/_formation-docker/docker-chap08/#exemple-complet-application-web-avec-persistance","title":"Exemple Complet : Application Web avec Persistance","text":"YAML<pre><code>version: '3.8'\n\nservices:\n  nginx:\n    image: nginx:latest\n    ports:\n      - \"80:80\"\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf:ro\n      - ./html:/usr/share/nginx/html\n      - nginx-logs:/var/log/nginx\n    depends_on:\n      - app\n\n  app:\n    build:\n      context: ./app\n      dockerfile: Dockerfile\n    volumes:\n      - ./app/src:/app/src\n      - app-cache:/app/.cache\n    environment:\n      - CACHE_DIR=/app/.cache\n\n  db:\n    image: postgres:14\n    volumes:\n      - postgres-data:/var/lib/postgresql/data\n      - ./init.sql:/docker-entrypoint-initdb.d/init.sql\n    environment:\n      - POSTGRES_PASSWORD=secret\n      - POSTGRES_DB=myapp\n\nvolumes:\n  nginx-logs:\n  app-cache:\n  postgres-data:\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#autres-commandes-de-docker-compose","title":"Autres Commandes de docker-compose","text":""},{"location":"_projects/_formation-docker/docker-chap08/#gestion-du-cycle-de-vie","title":"Gestion du Cycle de Vie","text":"Bash<pre><code># Arr\u00eater tous les services (ne supprime pas les conteneurs)\ndocker-compose stop\n\n# Arr\u00eater des services sp\u00e9cifiques\ndocker-compose stop service1 service2\n\n# Red\u00e9marrer tous les services\ndocker-compose restart\n\n# Arr\u00eater et supprimer tous les conteneurs, r\u00e9seaux, volumes\ndocker-compose down\n\n# Down avec suppression des volumes nomm\u00e9s\ndocker-compose down -v\n\n# Down avec suppression des images construites\ndocker-compose down --rmi local\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#visualisation-et-debugging","title":"Visualisation et Debugging","text":"Bash<pre><code># Afficher les logs de tous les services\ndocker-compose logs\n\n# Afficher les logs d'un service sp\u00e9cifique\ndocker-compose logs db\n\n# Afficher les logs en temps r\u00e9el\ndocker-compose logs -f\n\n# Afficher uniquement les 50 derni\u00e8res lignes\ndocker-compose logs --tail=50\n\n# Afficher les conteneurs en cours d'ex\u00e9cution\ndocker-compose ps\n\n# Afficher tous les conteneurs (y compris arr\u00eat\u00e9s)\ndocker-compose ps -a\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#execution-de-commandes","title":"Ex\u00e9cution de Commandes","text":"Bash<pre><code># Ex\u00e9cuter une commande dans un service en cours d'ex\u00e9cution\ndocker-compose exec app bash\n\n# Ex\u00e9cuter une commande sans allocation de terminal\ndocker-compose exec -T db mysql -u root -p password\n\n# Ex\u00e9cuter une commande avec une variable d'environnement\ndocker-compose exec app python manage.py migrate\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#gestion-des-images-et-conteneurs","title":"Gestion des Images et Conteneurs","text":"Bash<pre><code># Construire ou reconstruire les services\ndocker-compose build\n\n# Construire sans cache\ndocker-compose build --no-cache\n\n# Construire un service sp\u00e9cifique\ndocker-compose build app\n\n# Valider le fichier docker-compose.yml\ndocker-compose config\n\n# Afficher le fichier compos\u00e9 r\u00e9solu (apr\u00e8s substitution)\ndocker-compose config --resolve-image-digests\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#scaling-et-performance","title":"Scaling et Performance","text":"Bash<pre><code># D\u00e9marrer plusieurs instances d'un service\ndocker-compose up -d --scale worker=3\n# Lance 3 conteneurs du service 'worker'\n\n# Pause tous les services (suspension, pas arr\u00eat)\ndocker-compose pause\n\n# Reprendre tous les services\ndocker-compose unpause\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#cas-dusage-pratique-application-web-complete","title":"Cas d'Usage Pratique : Application Web Compl\u00e8te","text":""},{"location":"_projects/_formation-docker/docker-chap08/#architecture-multi-tier","title":"Architecture Multi-Tier","text":"<p>Voici un exemple d\u00e9taill\u00e9 d'une application web compl\u00e8te utilisant Docker Compose :</p> YAML<pre><code>version: '3.8'\n\nservices:\n  # Serveur Web Frontal\n  nginx:\n    image: nginx:1.25-alpine\n    container_name: app-nginx\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro\n      - ./nginx/ssl:/etc/nginx/ssl:ro\n      - ./html:/usr/share/nginx/html:ro\n      - nginx-logs:/var/log/nginx\n    networks:\n      - app-network\n    depends_on:\n      - backend\n    restart: unless-stopped\n\n  # Serveur d'Application Backend\n  backend:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: app-backend\n    expose:\n      - \"8000\"\n    volumes:\n      - ./backend/app:/app/app\n      - backend-cache:/app/.cache\n    environment:\n      - FLASK_ENV=production\n      - DATABASE_URL=postgresql://user:password@db:5432/app_db\n      - REDIS_URL=redis://cache:6379/0\n      - SECRET_KEY=${SECRET_KEY}\n      - DEBUG=false\n    networks:\n      - app-network\n    depends_on:\n      - db\n      - cache\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  # Base de Donn\u00e9es\n  db:\n    image: postgres:15-alpine\n    container_name: app-db\n    expose:\n      - \"5432\"\n    volumes:\n      - postgres-data:/var/lib/postgresql/data\n      - ./init-db.sql:/docker-entrypoint-initdb.d/init.sql\n    environment:\n      - POSTGRES_USER=user\n      - POSTGRES_PASSWORD=${DB_PASSWORD}\n      - POSTGRES_DB=app_db\n    networks:\n      - app-network\n    restart: unless-stopped\n\n  # Cache Redis\n  cache:\n    image: redis:7-alpine\n    container_name: app-cache\n    expose:\n      - \"6379\"\n    volumes:\n      - redis-data:/data\n    networks:\n      - app-network\n    restart: unless-stopped\n\n  # Worker en Arri\u00e8re-Plan\n  worker:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    container_name: app-worker\n    command: celery -A app.tasks worker --loglevel=info\n    volumes:\n      - ./backend/app:/app/app\n    environment:\n      - FLASK_ENV=production\n      - DATABASE_URL=postgresql://user:password@db:5432/app_db\n      - REDIS_URL=redis://cache:6379/0\n    networks:\n      - app-network\n    depends_on:\n      - db\n      - cache\n    restart: unless-stopped\n\nvolumes:\n  postgres-data:\n  redis-data:\n  nginx-logs:\n  backend-cache:\n\nnetworks:\n  app-network:\n    driver: bridge\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#fichier-env-correspondant","title":"Fichier .env Correspondant","text":"Bash<pre><code># .env\nSECRET_KEY=your-super-secret-key-here\nDB_PASSWORD=secure_database_password_123\nFLASK_ENV=production\nDEBUG=false\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#utilisation","title":"Utilisation","text":"Bash<pre><code># D\u00e9marrer l'application compl\u00e8te\ndocker-compose up -d\n\n# V\u00e9rifier l'\u00e9tat des services\ndocker-compose ps\n\n# Afficher les logs en temps r\u00e9el\ndocker-compose logs -f\n\n# Ex\u00e9cuter les migrations de la base de donn\u00e9es\ndocker-compose exec backend flask db upgrade\n\n# Arr\u00eater l'application\ndocker-compose down\n\n# Arr\u00eater et supprimer tous les volumes\ndocker-compose down -v\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#bonnes-pratiques-et-optimisations","title":"Bonnes Pratiques et Optimisations","text":""},{"location":"_projects/_formation-docker/docker-chap08/#structure-de-repertoires-recommandee","title":"Structure de R\u00e9pertoires Recommand\u00e9e","text":"Text Only<pre><code>projet/\n\u251c\u2500\u2500 docker-compose.yml\n\u251c\u2500\u2500 docker-compose.prod.yml\n\u251c\u2500\u2500 .env\n\u251c\u2500\u2500 .env.example\n\u251c\u2500\u2500 nginx/\n\u2502   \u251c\u2500\u2500 nginx.conf\n\u2502   \u2514\u2500\u2500 ssl/\n\u251c\u2500\u2500 backend/\n\u2502   \u251c\u2500\u2500 Dockerfile\n\u2502   \u251c\u2500\u2500 requirements.txt\n\u2502   \u2514\u2500\u2500 app/\n\u251c\u2500\u2500 frontend/\n\u2502   \u251c\u2500\u2500 Dockerfile\n\u2502   \u2514\u2500\u2500 src/\n\u2514\u2500\u2500 init-db.sql\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#fichier-envexample","title":"Fichier .env.example","text":"<p>Cr\u00e9er un fichier <code>.env.example</code> pour documenter les variables requises :</p> Bash<pre><code>SECRET_KEY=change_me_in_production\nDB_PASSWORD=change_me_in_production\nFLASK_ENV=development\nDEBUG=true\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#separation-des-configurations","title":"S\u00e9paration des Configurations","text":"<p>Pour diff\u00e9rencier les environnements, utiliser plusieurs fichiers compose :</p> Bash<pre><code># D\u00e9veloppement\ndocker-compose -f docker-compose.yml up\n\n# Production\ndocker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d\n</code></pre> <p>O\u00f9 <code>docker-compose.prod.yml</code> contient les surcharges de configuration :</p> YAML<pre><code>version: '3.8'\n\nservices:\n  backend:\n    restart: always\n    environment:\n      - DEBUG=false\n      - FLASK_ENV=production\n\n  db:\n    volumes:\n      - postgres-data:/var/lib/postgresql/data\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#health-checks","title":"Health Checks","text":"<p>Les v\u00e9rifications de sant\u00e9 permettent \u00e0 Docker Compose de v\u00e9rifier que les services sont op\u00e9rationnels :</p> YAML<pre><code>services:\n  api:\n    image: myapi:latest\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 40s\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#limitation-des-ressources","title":"Limitation des Ressources","text":"<p>Contr\u00f4ler la consommation de ressources :</p> YAML<pre><code>services:\n  worker:\n    image: worker:latest\n    deploy:\n      resources:\n        limits:\n          cpus: '0.5'\n          memory: 512M\n        reservations:\n          cpus: '0.25'\n          memory: 256M\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#logging","title":"Logging","text":"<p>Configurer la sortie des logs pour \u00e9viter le d\u00e9bordement d'espace disque :</p> YAML<pre><code>services:\n  app:\n    image: myapp:latest\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap08/#synthese-et-parcours-dapprentissage","title":"Synth\u00e8se et Parcours d'Apprentissage","text":"<p>Le parcours de ma\u00eetrise de Docker Compose suit une progression logique depuis les concepts fondamentaux jusqu'aux d\u00e9ploiements complexes.</p> <p>Phase 1 : Fondamentaux d\u00e9bute par la compr\u00e9hension de ce qu'est Docker Compose et pourquoi il simplifie la gestion de conteneurs multiples. L'installation et la v\u00e9rification constituent les premi\u00e8res \u00e9tapes concr\u00e8tes.</p> <p>Phase 2 : Configuration de Base implique de apprendre la structure du fichier YAML, les sections essentielles (services, volumes, networks), et comment sp\u00e9cifier les images et les services basiques.</p> <p>Phase 3 : Op\u00e9rations Courantes enseigne les commandes principales (<code>up</code>, <code>down</code>, <code>logs</code>, <code>ps</code>, <code>exec</code>) et comment les utiliser pour g\u00e9rer le cycle de vie des applications.</p> <p>Phase 4 : Configuration Avanc\u00e9e couvre les variables d'environnement, les d\u00e9pendances, les politiques de red\u00e9marrage, et la gestion des ports et volumes. Ces \u00e9l\u00e9ments permettent de cr\u00e9er des configurations plus robustes et flexibles.</p> <p>Phase 5 : Cas d'Usage R\u00e9els applique tous les concepts pr\u00e9c\u00e9dents \u00e0 des applications concr\u00e8tes combinant plusieurs services (web, base de donn\u00e9es, cache, workers).</p> <p>Phase 6 : Optimisation et Production aborde les bonnes pratiques, la s\u00e9paration des environnements, les health checks, et la limitation des ressources pour pr\u00e9parer le d\u00e9ploiement en production.</p> <p>Chaque phase s'appuie sur la pr\u00e9c\u00e9dente, permettant une mont\u00e9e en comp\u00e9tences progressive et une compr\u00e9hension profonde de chaque aspect de Docker Compose. Cette approche progressive transforme Docker Compose d'un outil complexe en un instrument ma\u00eetris\u00e9 pour orchestrer efficacement des applications conteneuris\u00e9es.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-docker/docker-chap09/","title":"Citations","text":"<ul> <li>https://learn.microsoft.com/en-us/visualstudio/containers/tutorial-multicontainer?view=visualstudio</li> <li>https://docs.docker.com/compose/gettingstarted/</li> <li>https://www.freecodecamp.org/news/a-beginners-guide-to-docker-how-to-create-a-client-server-side-with-docker-compose-12c8cf0ae0aa/</li> <li>https://spacelift.io/blog/docker-compose</li> <li>https://docs.docker.com/get-started/workshop/02_our_app/</li> <li>https://faq.teipublisher.com/hosting/docker-compose/</li> <li>https://docs.docker.com/get-started/docker-concepts/building-images/writing-a-dockerfile/</li> <li>https://docker-curriculum.com</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap09/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 290</li> <li>completion_tokens: 5958</li> <li>total_tokens: 6248</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.089, 'request_cost': 0.006, 'total_cost': 0.096}</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap09/#content","title":"Content","text":""},{"location":"_projects/_formation-docker/docker-chap09/#dockerfile-et-docker-compose-pour-une-application-client","title":"Dockerfile et Docker Compose pour une Application Client \ud83d\udc33","text":""},{"location":"_projects/_formation-docker/docker-chap09/#introduction","title":"Introduction","text":"<p>Docker repr\u00e9sente une r\u00e9volution dans le domaine de la conteneurisation et du d\u00e9ploiement d'applications. Pour les d\u00e9veloppeurs travaillant sur des applications client-serveur, ma\u00eetriser Dockerfile et Docker Compose devient essentiel afin de garantir une coh\u00e9rence entre les environnements de d\u00e9veloppement et de production. Ce guide d\u00e9taill\u00e9 explore les concepts fondamentaux et les pratiques avanc\u00e9es n\u00e9cessaires pour construire une architecture applicative robuste et scalable.</p>"},{"location":"_projects/_formation-docker/docker-chap09/#mise-en-place-du-projet-dapplication-cliente","title":"Mise en Place du Projet d'Application Cliente \ud83d\udcc1","text":""},{"location":"_projects/_formation-docker/docker-chap09/#architecture-generale-du-projet","title":"Architecture G\u00e9n\u00e9rale du Projet","text":"<p>La structure initiale d'un projet utilisant Docker Compose pour une application client-serveur doit suivre une organisation logique et maintenable. Un projet type comporte plusieurs r\u00e9pertoires distincts, chacun responsable d'une partie sp\u00e9cifique de l'application[3].</p> Text Only<pre><code>\u251c\u2500\u2500 client/\n\u2502   \u251c\u2500\u2500 Dockerfile\n\u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u251c\u2500\u2500 index.js\n\u2502   \u2502   \u251c\u2500\u2500 package.json\n\u2502   \u2502   \u2514\u2500\u2500 public/\n\u2502   \u2514\u2500\u2500 .dockerignore\n\u251c\u2500\u2500 server/\n\u2502   \u251c\u2500\u2500 Dockerfile\n\u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u251c\u2500\u2500 app.js\n\u2502   \u2502   \u251c\u2500\u2500 package.json\n\u2502   \u2502   \u2514\u2500\u2500 config/\n\u2502   \u2514\u2500\u2500 .dockerignore\n\u251c\u2500\u2500 docker-compose.yml\n\u251c\u2500\u2500 .env\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#initialisation-des-services","title":"Initialisation des Services","text":"<p>Chaque service (client et serveur) commence par une initialisation appropri\u00e9e. Pour une application Node.js c\u00f4t\u00e9 serveur avec Redis en tant que cache, l'initialisation implique la cr\u00e9ation des fichiers de configuration de base[4].</p> <p>Fichier <code>server/package.json</code>:</p> JSON<pre><code>{\n  \"name\": \"server-app\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Application serveur avec Redis\",\n  \"main\": \"app.js\",\n  \"scripts\": {\n    \"start\": \"node app.js\",\n    \"dev\": \"nodemon app.js\"\n  },\n  \"dependencies\": {\n    \"express\": \"^4.18.0\",\n    \"redis\": \"^4.6.0\"\n  },\n  \"devDependencies\": {\n    \"nodemon\": \"^2.0.20\"\n  }\n}\n</code></pre> <p>Fichier <code>server/src/app.js</code>:</p> JavaScript<pre><code>const express = require(\"express\");\nconst { createClient: createRedisClient } = require(\"redis\");\n\n(async function () {\n  const app = express();\n  const redisClient = createRedisClient({\n    url: `redis://redis:6379`\n  });\n\n  await redisClient.connect();\n\n  app.get(\"/api/data\", async (request, response) =&gt; {\n    try {\n      const cachedData = await redisClient.get(\"appData\");\n      if (cachedData) {\n        return response.json({ data: cachedData, source: \"cache\" });\n      }\n\n      const freshData = \"Donn\u00e9es fra\u00eeches du serveur\";\n      await redisClient.setEx(\"appData\", 3600, freshData);\n      response.json({ data: freshData, source: \"server\" });\n    } catch (error) {\n      response.status(500).json({ error: error.message });\n    }\n  });\n\n  app.listen(8080, () =&gt; {\n    console.log(\"Serveur d\u00e9marr\u00e9 sur le port 8080\");\n  });\n})();\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#configuration-de-lapplication-client","title":"Configuration de l'Application Client","text":"<p>L'application client doit \u00eatre capable de communiquer avec le serveur via les noms de services d\u00e9finis dans Docker Compose. L'utilisation de variables d'environnement facilite la portabilit\u00e9 entre environnements.</p> <p>Fichier <code>client/package.json</code>:</p> JSON<pre><code>{\n  \"name\": \"client-app\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Application cliente\",\n  \"main\": \"index.js\",\n  \"scripts\": {\n    \"start\": \"http-server -p 3000 -c-1\",\n    \"dev\": \"http-server -p 3000 -c-1 --watch\"\n  },\n  \"dependencies\": {\n    \"http-server\": \"^14.1.1\"\n  }\n}\n</code></pre> <p>Fichier <code>client/src/index.html</code>:</p> HTML<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"fr\"&gt;\n&lt;head&gt;\n  &lt;meta charset=\"UTF-8\"&gt;\n  &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;\n  &lt;title&gt;Application Client&lt;/title&gt;\n  &lt;style&gt;\n    body { font-family: Arial; max-width: 600px; margin: 50px auto; }\n    button { padding: 10px 20px; font-size: 16px; cursor: pointer; }\n    #result { margin-top: 20px; padding: 10px; background: #f0f0f0; }\n  &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;h1&gt;Application Client-Serveur&lt;/h1&gt;\n  &lt;button onclick=\"fetchData()\"&gt;R\u00e9cup\u00e9rer les donn\u00e9es&lt;/button&gt;\n  &lt;div id=\"result\"&gt;&lt;/div&gt;\n\n  &lt;script&gt;\n    async function fetchData() {\n      try {\n        const response = await fetch('http://localhost:8080/api/data');\n        const data = await response.json();\n        document.getElementById('result').innerHTML = \n          `&lt;p&gt;Donn\u00e9es: ${data.data}&lt;/p&gt;&lt;p&gt;Source: ${data.source}&lt;/p&gt;`;\n      } catch (error) {\n        document.getElementById('result').innerHTML = \n          `&lt;p style=\"color: red;\"&gt;Erreur: ${error.message}&lt;/p&gt;`;\n      }\n    }\n  &lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#mise-en-place-de-lenvironnement-de-production","title":"Mise en Place de l'Environnement de Production \u2699\ufe0f","text":""},{"location":"_projects/_formation-docker/docker-chap09/#creation-des-fichiers-dockerfile","title":"Cr\u00e9ation des Fichiers Dockerfile","text":"<p>Les Dockerfiles pour la production doivent suivre les bonnes pratiques de s\u00e9curit\u00e9 et d'optimisation. Chaque couche doit \u00eatre soigneusement planifi\u00e9e pour minimiser la taille de l'image[1].</p> <p>Fichier <code>server/Dockerfile</code> (Production):</p> Docker<pre><code># \u00c9tape 1: Construction\nFROM node:18-alpine AS builder\n\nWORKDIR /app\nCOPY server/package*.json ./\nRUN npm ci\n\nCOPY server/src ./src\n\n# \u00c9tape 2: Runtime\nFROM node:18-alpine\n\nWORKDIR /app\n\n# Cr\u00e9ation d'un utilisateur non-root pour la s\u00e9curit\u00e9\nRUN addgroup -g 1001 -S nodejs &amp;&amp; adduser -S nodejs -u 1001\n\n# Installation des d\u00e9pendances de production uniquement\nCOPY --from=builder /app/node_modules ./node_modules\nCOPY --from=builder /app/src ./src\nCOPY server/package*.json ./\n\n# Changement de propri\u00e9taire des fichiers\nRUN chown -R nodejs:nodejs /app\n\nUSER nodejs\n\nEXPOSE 8080\n\n# Healthcheck pour Docker Compose\nHEALTHCHECK --interval=20s --timeout=20s --retries=5 \\\n  CMD node -e \"require('http').get('http://localhost:8080/api/data', (r) =&gt; {if (r.statusCode !== 200) throw new Error(r.statusCode)})\"\n\nCMD [\"node\", \"src/app.js\"]\n</code></pre> <p>Fichier <code>client/Dockerfile</code> (Production):</p> Docker<pre><code># \u00c9tape 1: Construction\nFROM node:18-alpine AS builder\n\nWORKDIR /app\nCOPY client/package*.json ./\nRUN npm ci\n\n# \u00c9tape 2: Runtime avec serveur HTTP l\u00e9ger\nFROM node:18-alpine\n\nWORKDIR /app\n\nRUN addgroup -g 1001 -S nodejs &amp;&amp; adduser -S nodejs -u 1001\n\nCOPY --from=builder /app/node_modules ./node_modules\nCOPY client/package*.json ./\nCOPY client/src ./src\n\nRUN chown -R nodejs:nodejs /app\n\nUSER nodejs\n\nEXPOSE 3000\n\nHEALTHCHECK --interval=30s --timeout=10s --retries=3 \\\n  CMD wget --quiet --tries=1 --spider http://localhost:3000 || exit 1\n\nCMD [\"npm\", \"start\"]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#optimisation-des-images-docker","title":"Optimisation des Images Docker","text":"<p>Les images Docker en production doivent \u00eatre l\u00e9g\u00e8res et s\u00e9curis\u00e9es. L'utilisation de builds multi-\u00e9tapes r\u00e9duit significativement la taille finale des images en \u00e9liminant les d\u00e9pendances de d\u00e9veloppement.</p> Aspect Avantage Impl\u00e9mentation Multi-stage builds R\u00e9duit la taille de 70-80% S\u00e9pare les \u00e9tapes de compilation et runtime Alpine Linux Image de base tr\u00e8s l\u00e9g\u00e8re (5MB) Utilisation de <code>node:18-alpine</code> .dockerignore Exclut les fichiers inutiles Fichiers <code>node_modules</code>, <code>.git</code>, logs Utilisateur non-root Am\u00e9liore la s\u00e9curit\u00e9 Cr\u00e9ation d'un utilisateur d\u00e9di\u00e9 Healthchecks Monitoring automatique V\u00e9rifie l'accessibilit\u00e9 des services <p>Fichier <code>.dockerignore</code> (\u00e0 la racine):</p> Text Only<pre><code>node_modules\nnpm-debug.log\n.git\n.gitignore\nREADME.md\n.env\ndist\nbuild\ncoverage\n.nyc_output\n.DS_Store\n*.log\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#gestion-des-variables-denvironnement","title":"Gestion des Variables d'Environnement","text":"<p>L'utilisation de fichiers <code>.env</code> permet une configuration flexible selon l'environnement.</p> <p>Fichier <code>.env</code>:</p> Text Only<pre><code># Environnement\nNODE_ENV=production\n\n# Serveur\nSERVER_PORT=8080\nSERVER_HOST=0.0.0.0\n\n# Client\nCLIENT_PORT=3000\nCLIENT_HOST=0.0.0.0\n\n# Redis\nREDIS_HOST=redis\nREDIS_PORT=6379\nREDIS_PASSWORD=\n\n# Registry Docker (optionnel)\nDOCKER_REGISTRY=myregistry.azurecr.io/\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#mise-en-place-de-docker-compose","title":"Mise en Place de Docker Compose \ud83d\udd17","text":""},{"location":"_projects/_formation-docker/docker-chap09/#configuration-du-fichier-docker-composeyml","title":"Configuration du Fichier docker-compose.yml","text":"<p>Docker Compose centralise la configuration de tous les services dans un seul fichier YAML, simplifiant la gestion des d\u00e9pendances et de la communication inter-conteneurs[2][4].</p> <p>Fichier <code>docker-compose.yml</code>:</p> YAML<pre><code>version: '3.9'\n\nservices:\n  # Service Redis pour le cache\n  redis:\n    image: redis:7-alpine\n    container_name: app-redis\n    ports:\n      - \"6379:6379\"\n    volumes:\n      - redis_data:/data\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    networks:\n      - app-network\n    restart: unless-stopped\n\n  # Service Serveur\n  server:\n    build:\n      context: .\n      dockerfile: server/Dockerfile\n    container_name: app-server\n    environment:\n      - NODE_ENV=production\n      - REDIS_HOST=redis\n      - REDIS_PORT=6379\n      - SERVER_PORT=8080\n    ports:\n      - \"8080:8080\"\n    depends_on:\n      redis:\n        condition: service_healthy\n    volumes:\n      - ./server/src:/app/src\n    networks:\n      - app-network\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"node\", \"-e\", \"require('http').get('http://localhost:8080/api/data', (r) =&gt; {if (r.statusCode !== 200) throw new Error(r.statusCode)})\"]\n      interval: 20s\n      timeout: 10s\n      retries: 5\n\n  # Service Client\n  client:\n    build:\n      context: .\n      dockerfile: client/Dockerfile\n    container_name: app-client\n    environment:\n      - NODE_ENV=production\n      - CLIENT_PORT=3000\n    ports:\n      - \"3000:3000\"\n    depends_on:\n      server:\n        condition: service_healthy\n    volumes:\n      - ./client/src:/app/src\n    networks:\n      - app-network\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"wget\", \"--quiet\", \"--tries=1\", \"--spider\", \"http://localhost:3000\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\nvolumes:\n  redis_data:\n    driver: local\n\nnetworks:\n  app-network:\n    driver: bridge\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#comprendre-la-structure-docker-compose","title":"Comprendre la Structure Docker Compose","text":"<p>Services: Chaque service repr\u00e9sente un conteneur ind\u00e9pendant avec ses propres ressources et configuration[4].</p> <p>Volumes: Permettent la persistance des donn\u00e9es et le partage de fichiers entre l'h\u00f4te et les conteneurs. Deux types existent: - Volumes nomm\u00e9s: G\u00e9r\u00e9s par Docker (<code>redis_data</code>) - Volumes li\u00e9s: Points de montage du syst\u00e8me de fichiers h\u00f4te (<code>./server/src:/app/src</code>)</p> <p>Networks: Cr\u00e9ent un r\u00e9seau priv\u00e9 permettant la communication par noms de services. Les conteneurs peuvent se joindre via <code>http://service-name:port</code>[1].</p> <p>Conditions de D\u00e9pendance: D\u00e9finissent l'ordre de d\u00e9marrage des services. La condition <code>service_healthy</code> v\u00e9rifie les healthchecks avant de d\u00e9marrer les d\u00e9pendants.</p>"},{"location":"_projects/_formation-docker/docker-chap09/#commandes-docker-compose-essentielles","title":"Commandes Docker Compose Essentielles","text":"Bash<pre><code># D\u00e9marrer les services\ndocker compose up\n\n# D\u00e9marrer en arri\u00e8re-plan\ndocker compose up -d\n\n# Arr\u00eater les services\ndocker compose down\n\n# Arr\u00eater et supprimer les volumes\ndocker compose down -v\n\n# Visualiser les logs\ndocker compose logs -f\n\n# Logs d'un service sp\u00e9cifique\ndocker compose logs -f server\n\n# Reconstruire les images\ndocker compose build\n\n# Reconstruire et red\u00e9marrer\ndocker compose up -d --build\n\n# Ex\u00e9cuter une commande dans un conteneur\ndocker compose exec server npm run dev\n\n# Voir l'\u00e9tat des services\ndocker compose ps\n\n# Nettoyer les ressources non utilis\u00e9es\ndocker compose down --remove-orphans\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#lancer-les-tests-pendant-le-developpement","title":"Lancer les Tests Pendant le D\u00e9veloppement \ud83e\uddea","text":""},{"location":"_projects/_formation-docker/docker-chap09/#configuration-du-developpement","title":"Configuration du D\u00e9veloppement","text":"<p>Le d\u00e9veloppement local n\u00e9cessite une configuration diff\u00e9rente de la production, avec des outils de monitoring et de reload automatique.</p> <p>Fichier <code>docker-compose.dev.yml</code> (Override):</p> YAML<pre><code>version: '3.9'\n\nservices:\n  server:\n    environment:\n      - NODE_ENV=development\n    volumes:\n      - ./server/src:/app/src\n      - server_node_modules:/app/node_modules\n    command: npm run dev\n    ports:\n      - \"9229:9229\"  # Port de d\u00e9bogage Node.js\n\n  client:\n    environment:\n      - NODE_ENV=development\n    volumes:\n      - ./client/src:/app/src\n      - client_node_modules:/app/node_modules\n    command: npm run dev\n\n  # Service de test optionnel\n  tests:\n    build:\n      context: .\n      dockerfile: Dockerfile.test\n    depends_on:\n      - server\n      - redis\n    volumes:\n      - ./tests:/app/tests\n      - ./coverage:/app/coverage\n    networks:\n      - app-network\n    environment:\n      - CI=true\n\nvolumes:\n  server_node_modules:\n  client_node_modules:\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#fichier-de-tests","title":"Fichier de Tests","text":"<p>Fichier <code>Dockerfile.test</code>:</p> Docker<pre><code>FROM node:18-alpine\n\nWORKDIR /app\n\nCOPY server/package*.json ./\nRUN npm ci --only=dev &amp;&amp; npm install jest supertest\n\nCOPY server/src ./src\nCOPY tests ./tests\n\nCMD [\"npm\", \"test\"]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#suite-de-tests","title":"Suite de Tests","text":"<p>Fichier <code>tests/server.test.js</code>:</p> JavaScript<pre><code>const request = require('supertest');\nconst http = require('http');\n\ndescribe('API Server Tests', () =&gt; {\n  let app;\n  const baseURL = 'http://server:8080';\n\n  test('GET /api/data devrait retourner les donn\u00e9es', async () =&gt; {\n    const response = await request('http://server:8080')\n      .get('/api/data')\n      .expect(200);\n\n    expect(response.body).toHaveProperty('data');\n    expect(response.body).toHaveProperty('source');\n    expect(['cache', 'server']).toContain(response.body.source);\n  });\n\n  test('Multiple requests devraient utiliser le cache', async () =&gt; {\n    // Premier appel\n    const response1 = await request('http://server:8080')\n      .get('/api/data')\n      .expect(200);\n\n    // Deuxi\u00e8me appel rapide\n    const response2 = await request('http://server:8080')\n      .get('/api/data')\n      .expect(200);\n\n    expect(response2.body.source).toBe('cache');\n  });\n\n  test('Connexion au serveur devrait r\u00e9ussir', async () =&gt; {\n    const response = await request('http://server:8080')\n      .get('/api/data')\n      .timeout(5000);\n\n    expect(response.status).not.toBe(0);\n  });\n});\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#commandes-de-test","title":"Commandes de Test","text":"Bash<pre><code># Lancer les tests avec composition override\ndocker compose -f docker-compose.yml -f docker-compose.dev.yml up tests\n\n# Lancer les tests une seule fois\ndocker compose run --rm tests npm test\n\n# Lancer les tests avec couverture\ndocker compose run --rm tests npm run test:coverage\n\n# Lancer les tests en mode watch\ndocker compose run -it tests npm test -- --watch\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#debogage-dapplication","title":"D\u00e9bogage d'Application","text":"<p>D\u00e9bogage Node.js c\u00f4t\u00e9 serveur:</p> Bash<pre><code># D\u00e9marrer avec d\u00e9bogage activ\u00e9\ndocker compose run -p 9229:9229 server npm run dev\n\n# Dans l'IDE (VS Code .vscode/launch.json):\n</code></pre> <p>Fichier <code>.vscode/launch.json</code>:</p> JSON<pre><code>{\n  \"version\": \"0.2.0\",\n  \"configurations\": [\n    {\n      \"name\": \"Docker Server Debug\",\n      \"type\": \"node\",\n      \"request\": \"attach\",\n      \"port\": 9229,\n      \"address\": \"localhost\",\n      \"restart\": true,\n      \"sourceMaps\": true,\n      \"localRoot\": \"${workspaceFolder}/server\",\n      \"remoteRoot\": \"/app\"\n    }\n  ]\n}\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#mise-en-place-du-live-reload","title":"Mise en Place du Live Reload \ud83d\udd04","text":""},{"location":"_projects/_formation-docker/docker-chap09/#configuration-du-live-reload-pour-le-client","title":"Configuration du Live Reload pour le Client","text":"<p>Le live reload permet de voir les modifications du code en temps r\u00e9el sans red\u00e9marrer les conteneurs. Plusieurs approches existent selon la technologie utilis\u00e9e.</p> <p>Fichier <code>client/src/watch.js</code> (Solution simple avec http-server):</p> JavaScript<pre><code>const fs = require('fs');\nconst path = require('path');\n\nconst watchDir = path.join(__dirname);\nconst extensions = ['.html', '.css', '.js'];\n\nconsole.log(`Watching for changes in ${watchDir}`);\n\nfs.watch(watchDir, { recursive: true }, (eventType, filename) =&gt; {\n  if (extensions.some(ext =&gt; filename.endsWith(ext))) {\n    console.log(`Fichier modifi\u00e9: ${filename}`);\n  }\n});\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#configuration-avec-webpack-dev-server","title":"Configuration avec Webpack Dev Server","text":"<p>Pour les applications React ou Vue.js, Webpack Dev Server offre un meilleur support du hot reload.</p> <p>Fichier <code>client/webpack.config.js</code>:</p> JavaScript<pre><code>const path = require('path');\n\nmodule.exports = {\n  mode: 'development',\n  entry: './src/index.js',\n  output: {\n    path: path.resolve(__dirname, 'dist'),\n    filename: 'bundle.js',\n  },\n  devServer: {\n    host: '0.0.0.0',\n    port: 3000,\n    hot: true,\n    contentBase: path.join(__dirname, 'src'),\n    compress: true,\n    historyApiFallback: true,\n    proxy: {\n      '/api': {\n        target: 'http://server:8080',\n        changeOrigin: true,\n        pathRewrite: { '^/api': '/api' }\n      }\n    }\n  },\n  devtool: 'source-map'\n};\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#configuration-du-live-reload-cote-serveur","title":"Configuration du Live Reload C\u00f4t\u00e9 Serveur","text":"<p>Fichier <code>server/src/app.js</code> (Avec auto-reload):</p> JavaScript<pre><code>const express = require(\"express\");\nconst { createClient: createRedisClient } = require(\"redis\");\nconst fs = require(\"fs\");\nconst path = require(\"path\");\n\nlet config = loadConfig();\n\nfunction loadConfig() {\n  try {\n    return JSON.parse(fs.readFileSync(path.join(__dirname, '../config.json'), 'utf8'));\n  } catch {\n    return { maxConnections: 100, timeout: 30000 };\n  }\n}\n\n// Surveiller les changements de configuration\nfs.watchFile(path.join(__dirname, '../config.json'), (curr, prev) =&gt; {\n  console.log('Configuration mise \u00e0 jour');\n  config = loadConfig();\n});\n\n(async function () {\n  const app = express();\n  const redisClient = createRedisClient({\n    url: `redis://redis:6379`\n  });\n\n  await redisClient.connect();\n\n  app.get(\"/api/data\", async (request, response) =&gt; {\n    try {\n      const cachedData = await redisClient.get(\"appData\");\n      if (cachedData) {\n        return response.json({ \n          data: cachedData, \n          source: \"cache\",\n          config: config\n        });\n      }\n\n      const freshData = \"Donn\u00e9es fra\u00eeches du serveur\";\n      await redisClient.setEx(\"appData\", 3600, freshData);\n      response.json({ \n        data: freshData, \n        source: \"server\",\n        config: config\n      });\n    } catch (error) {\n      response.status(500).json({ error: error.message });\n    }\n  });\n\n  app.listen(8080, () =&gt; {\n    console.log(\"Serveur d\u00e9marr\u00e9 sur le port 8080\");\n  });\n})();\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#utilisation-de-volumes-pour-le-live-reload","title":"Utilisation de Volumes pour le Live Reload","text":"<p>Docker Compose configure d\u00e9j\u00e0 les volumes pour permettre le live reload:</p> YAML<pre><code>services:\n  server:\n    volumes:\n      - ./server/src:/app/src  # Recharge automatique du code\n\n  client:\n    volumes:\n      - ./client/src:/app/src  # Recharge automatique du code\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#configuration-complete-avec-live-reload","title":"Configuration Compl\u00e8te avec Live Reload","text":"<p>Fichier <code>docker-compose.dev.yml</code> (Complet):</p> YAML<pre><code>version: '3.9'\n\nservices:\n  redis:\n    environment:\n      - LOGLEVEL=debug\n\n  server:\n    build:\n      context: .\n      dockerfile: server/Dockerfile\n      args:\n        - NODE_ENV=development\n    environment:\n      - NODE_ENV=development\n      - DEBUG=app:*\n    volumes:\n      - ./server/src:/app/src:cached\n      - ./server/config.json:/app/config.json\n      - server_node_modules:/app/node_modules\n    command: npm run dev\n    stdin_open: true\n    tty: true\n    ports:\n      - \"9229:9229\"  # D\u00e9bogage\n\n  client:\n    build:\n      context: .\n      dockerfile: client/Dockerfile\n      args:\n        - NODE_ENV=development\n    environment:\n      - NODE_ENV=development\n      - DANGEROUSLY_DISABLE_HOST_CHECK=true\n    volumes:\n      - ./client/src:/app/src:cached\n      - client_node_modules:/app/node_modules\n    command: npm run dev\n    stdin_open: true\n    tty: true\n    ports:\n      - \"3001:3000\"  # Port diff\u00e9rent pour \u00e9viter les conflits\n\nvolumes:\n  server_node_modules:\n  client_node_modules:\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#scripts-packagejson-pour-le-developpement","title":"Scripts Package.json pour le D\u00e9veloppement","text":"<p>Fichier <code>server/package.json</code> (Scripts complets):</p> JSON<pre><code>{\n  \"scripts\": {\n    \"start\": \"node src/app.js\",\n    \"dev\": \"nodemon src/app.js --watch src --ext js,json\",\n    \"test\": \"jest\",\n    \"test:watch\": \"jest --watch\",\n    \"test:coverage\": \"jest --coverage\",\n    \"lint\": \"eslint src/\"\n  }\n}\n</code></pre> <p>Fichier <code>client/package.json</code> (Scripts complets):</p> JSON<pre><code>{\n  \"scripts\": {\n    \"start\": \"http-server -p 3000 -c-1\",\n    \"dev\": \"webpack serve --mode development\",\n    \"build\": \"webpack --mode production\",\n    \"test\": \"jest\",\n    \"test:watch\": \"jest --watch\"\n  }\n}\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#utilisation-pratique-du-live-reload","title":"Utilisation Pratique du Live Reload","text":"Bash<pre><code># D\u00e9marrer l'environnement de d\u00e9veloppement avec live reload\ndocker compose -f docker-compose.yml -f docker-compose.dev.yml up\n\n# Modifier un fichier dans server/src/app.js\n# Le serveur red\u00e9marre automatiquement\n\n# Modifier un fichier dans client/src/index.html\n# Le navigateur se recharge automatiquement\n\n# Afficher les logs en temps r\u00e9el\ndocker compose logs -f\n\n# Afficher uniquement les logs du serveur\ndocker compose logs -f server\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap09/#workflow-complet-du-developpement-a-la-production","title":"Workflow Complet : Du D\u00e9veloppement \u00e0 la Production \ud83d\ude80","text":""},{"location":"_projects/_formation-docker/docker-chap09/#phase-de-developpement","title":"Phase de D\u00e9veloppement","text":"<ol> <li> <p>Configuration initiale: Bash<pre><code>docker compose -f docker-compose.yml -f docker-compose.dev.yml up\n</code></pre></p> </li> <li> <p>Modifications du code: Les fichiers se rechargent automatiquement via les volumes</p> </li> <li> <p>Ex\u00e9cution des tests: Bash<pre><code>docker compose run --rm tests npm test\n</code></pre></p> </li> <li> <p>D\u00e9bogage: Utiliser les ports expos\u00e9s (9229 pour Node.js)</p> </li> </ol>"},{"location":"_projects/_formation-docker/docker-chap09/#transition-vers-la-production","title":"Transition vers la Production","text":"<ol> <li> <p>Construction des images: Bash<pre><code>docker compose build --no-cache\n</code></pre></p> </li> <li> <p>Tests d'int\u00e9gration: Bash<pre><code>docker compose run --rm tests npm run test:integration\n</code></pre></p> </li> <li> <p>Optimisation des images: Bash<pre><code>docker image ls\ndocker image inspect app-server\n</code></pre></p> </li> <li> <p>D\u00e9ploiement: Bash<pre><code>docker compose -f docker-compose.yml up -d\n</code></pre></p> </li> </ol>"},{"location":"_projects/_formation-docker/docker-chap09/#bonnes-pratiques-et-optimisations","title":"Bonnes Pratiques et Optimisations \ud83d\udca1","text":""},{"location":"_projects/_formation-docker/docker-chap09/#securite","title":"S\u00e9curit\u00e9","text":"<ul> <li>Utiliser toujours des utilisateurs non-root dans les conteneurs[1]</li> <li>Mettre \u00e0 jour r\u00e9guli\u00e8rement les images de base</li> <li>Utiliser <code>.dockerignore</code> pour exclure les fichiers sensibles</li> <li>Ne pas inclure les secrets directement dans les images</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap09/#performance","title":"Performance","text":"<ul> <li>Utiliser des builds multi-\u00e9tapes pour r\u00e9duire la taille des images</li> <li>Mettre en cache les couches Dockerfile en pla\u00e7ant les commandes immuables en premier</li> <li>Utiliser Alpine Linux comme image de base</li> <li>Optimiser l'ordre des commandes RUN pour le cache</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap09/#maintenabilite","title":"Maintenabilit\u00e9","text":"<ul> <li>Documenter la structure du projet dans un README.md</li> <li>Utiliser des versions sp\u00e9cifiques pour les d\u00e9pendances</li> <li>Organiser les configurations par fichiers s\u00e9par\u00e9s</li> <li>Impl\u00e9menter des healthchecks pour tous les services</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap09/#monitoring-et-logging","title":"Monitoring et Logging","text":"YAML<pre><code>services:\n  server:\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n</code></pre> <p>Cette approche structur\u00e9e et d\u00e9taill\u00e9e permet de construire une application Docker robuste, s\u00e9curis\u00e9e et facilement maintenable tout en offrant une exp\u00e9rience de d\u00e9veloppement fluide et productive.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-docker/docker-chap10/","title":"Citations","text":"<ul> <li>https://www.youtube.com/watch?v=EqgXJptKRAs</li> <li>https://blog.stephane-robert.info/docs/conteneurs/orchestrateurs/docker-compose/</li> <li>https://senza-formations.com/nos-articles/tutoriel-docker-compose-orchestrer-plusieurs-conteneurs-facilement</li> <li>https://learn.microsoft.com/fr-fr/dotnet/architecture/microservices/multi-container-microservice-net-applications/multi-container-applications-docker-compose</li> <li>https://www.datacamp.com/fr/tutorial/docker-compose-guide</li> <li>https://documentation.suse.com/fr-fr/sle-micro/6.0/html/Micro-compose/index.html</li> <li>https://www.ionos.fr/digitalguide/serveur/configuration/tutoriel-docker-compose/</li> <li>https://labex.io/fr/tutorials/docker-how-to-use-docker-compose-for-multi-container-deployments-411622</li> <li>https://xavki.blog/docker-compose-tutoriaux-francais/</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap10/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 314</li> <li>completion_tokens: 7666</li> <li>total_tokens: 7980</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.115, 'request_cost': 0.006, 'total_cost': 0.122}</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap10/#content","title":"Content","text":""},{"location":"_projects/_formation-docker/docker-chap10/#docker-compose-avec-plusieurs-services","title":"Docker Compose avec plusieurs services \ud83d\udc33","text":""},{"location":"_projects/_formation-docker/docker-chap10/#introduction-a-docker-compose","title":"Introduction \u00e0 Docker Compose","text":"<p>Docker Compose est un outil fondamental pour orchestrer des applications multi-conteneurs. Plut\u00f4t que de g\u00e9rer manuellement plusieurs conteneurs Docker avec des commandes individuelles, Docker Compose permet de d\u00e9finir l'int\u00e9gralit\u00e9 de l'application dans un fichier de configuration unique[2][3]. Cet outil simplifie consid\u00e9rablement le workflow de d\u00e9veloppement et de d\u00e9ploiement en \u00e9liminant les erreurs manuelles et en augmentant la productivit\u00e9[5].</p> <p>L'avantage principal de Docker Compose r\u00e9side dans sa capacit\u00e9 \u00e0 d\u00e9marrer et g\u00e9rer plusieurs conteneurs en une seule commande[3], tout en g\u00e9rant automatiquement les r\u00e9seaux, les volumes et les d\u00e9pendances entre services[5].</p>"},{"location":"_projects/_formation-docker/docker-chap10/#architecture-generale-dun-projet-docker-compose","title":"Architecture g\u00e9n\u00e9rale d'un projet Docker Compose","text":"<p>Un projet Docker Compose repose sur la coordination de plusieurs services qui communiquent entre eux[1]. L'architecture type d'une application multi-conteneurs comprend :</p> <ul> <li>Service frontal : g\u00e9n\u00e9ralement un serveur web (Nginx) qui expose l'application</li> <li>Service API : une application backend (Node.js, Python, etc.)</li> <li>Service base de donn\u00e9es : une instance de donn\u00e9es persistantes (PostgreSQL, MySQL, Redis)</li> <li>Services compl\u00e9mentaires : cache, monitoring, reverse proxy</li> </ul> <p>Docker Compose cr\u00e9e automatiquement un r\u00e9seau par d\u00e9faut permettant \u00e0 tous les services de communiquer entre eux[2], tout en g\u00e9rant les volumes et assurant leur rattachement automatique en cas de remplacement ou de red\u00e9marrage du service[5].</p>"},{"location":"_projects/_formation-docker/docker-chap10/#structure-fondamentale-du-fichier-docker-composeyml","title":"Structure fondamentale du fichier docker-compose.yml","text":"<p>Le fichier <code>docker-compose.yml</code> constitue le c\u0153ur de la configuration Docker Compose[2][3]. Ce fichier YAML d\u00e9crit l'int\u00e9gralit\u00e9 de la composition des services, des r\u00e9seaux et des volumes[4].</p>"},{"location":"_projects/_formation-docker/docker-chap10/#sections-principales-du-fichier","title":"Sections principales du fichier","text":"<p>Un fichier <code>docker-compose.yml</code> se compose de trois sections cl\u00e9s[3] :</p> <p>Services : Repr\u00e9sentent les conteneurs \u00e0 d\u00e9ployer. Chaque service poss\u00e8de un nom unique et contient des instructions sur l'image Docker, les ports \u00e0 exposer et les d\u00e9pendances[3].</p> <p>R\u00e9seaux : Permettent aux services de communiquer entre eux. Par d\u00e9faut, Docker Compose cr\u00e9e un r\u00e9seau, mais il est possible de d\u00e9finir des r\u00e9seaux personnalis\u00e9s pour un contr\u00f4le plus pr\u00e9cis[2][3].</p> <p>Volumes : G\u00e8rent la persistance des donn\u00e9es en attachant des espaces de stockage aux conteneurs[3].</p>"},{"location":"_projects/_formation-docker/docker-chap10/#exemple-de-structure-basique","title":"Exemple de structure basique","text":"YAML<pre><code>version: '3.8'\n\nservices:\n  web:\n    image: nginx:latest\n    ports:\n      - \"80:80\"\n    depends_on:\n      - app\n    networks:\n      - frontend\n\n  app:\n    image: node:16\n    ports:\n      - \"3000:3000\"\n    environment:\n      - NODE_ENV=production\n    depends_on:\n      - db\n    networks:\n      - frontend\n      - backend\n\n  db:\n    image: postgres:latest\n    environment:\n      POSTGRES_PASSWORD: example\n    volumes:\n      - db_data:/var/lib/postgresql/data\n    networks:\n      - backend\n\nnetworks:\n  frontend:\n  backend:\n\nvolumes:\n  db_data:\n</code></pre> <p>Cette structure illustre la s\u00e9paration des services, la gestion des ports, les variables d'environnement et la connectivit\u00e9 r\u00e9seau.</p>"},{"location":"_projects/_formation-docker/docker-chap10/#mise-en-place-de-la-configuration-client","title":"Mise en place de la configuration client","text":"<p>La configuration client dans une architecture Docker Compose correspond g\u00e9n\u00e9ralement \u00e0 l'interface utilisateur servie par un serveur web. Cette couche frontal est responsable de la pr\u00e9sentation et de l'interaction avec l'utilisateur.</p>"},{"location":"_projects/_formation-docker/docker-chap10/#role-du-service-client","title":"R\u00f4le du service client","text":"<p>Le service client utilise g\u00e9n\u00e9ralement un serveur web comme Nginx pour servir le contenu statique (HTML, CSS, JavaScript) et effectuer le reverse proxy vers les services backend[3]. Cette approche offre plusieurs avantages :</p> <ul> <li>S\u00e9paration des responsabilit\u00e9s : le client reste isol\u00e9 des logiques m\u00e9tier</li> <li>Performance : Nginx peut cacher et servir les assets statiques efficacement</li> <li>S\u00e9curit\u00e9 : le reverse proxy agit comme tampon entre Internet et les services internes</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap10/#configuration-du-service-nginx-client","title":"Configuration du service Nginx client","text":"YAML<pre><code>services:\n  client:\n    image: nginx:alpine\n    container_name: frontend-client\n    ports:\n      - \"3000:80\"\n    volumes:\n      - ./client/dist:/usr/share/nginx/html:ro\n      - ./nginx/client.conf:/etc/nginx/nginx.conf:ro\n    depends_on:\n      - api\n    networks:\n      - frontend\n</code></pre> <p>Cette configuration expose le service client sur le port 3000, monte les fichiers statiques depuis le r\u00e9pertoire <code>client/dist</code> et utilise une configuration Nginx personnalis\u00e9e.</p>"},{"location":"_projects/_formation-docker/docker-chap10/#variables-denvironnement-client","title":"Variables d'environnement client","text":"YAML<pre><code>services:\n  client:\n    image: node:16-alpine\n    build:\n      context: ./client\n      dockerfile: Dockerfile\n    environment:\n      - REACT_APP_API_URL=http://api:3001\n      - REACT_APP_ENV=production\n    ports:\n      - \"3000:3000\"\n    networks:\n      - frontend\n</code></pre> <p>Les variables d'environnement permettent au client de pointer vers les services backend sans modification du code source.</p>"},{"location":"_projects/_formation-docker/docker-chap10/#mise-en-place-de-lapi-nodejs","title":"Mise en place de l'API Node.js","text":"<p>L'API Node.js constitue le c\u0153ur m\u00e9tier de l'application, exposant les endpoints pour les op\u00e9rations CRUD et la logique applicative. Cette couche assure la communication entre le client et la base de donn\u00e9es.</p>"},{"location":"_projects/_formation-docker/docker-chap10/#service-api-nodejs","title":"Service API Node.js","text":"YAML<pre><code>services:\n  api:\n    build:\n      context: ./api\n      dockerfile: Dockerfile\n    container_name: nodejs-api\n    ports:\n      - \"3001:3001\"\n    environment:\n      - NODE_ENV=production\n      - DATABASE_URL=postgresql://user:password@db:5432/appdb\n      - REDIS_URL=redis://cache:6379\n      - LOG_LEVEL=info\n      - API_PORT=3001\n    depends_on:\n      - db\n      - cache\n    volumes:\n      - ./api/src:/app/src\n      - /app/node_modules\n    networks:\n      - backend\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3001/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#dockerfile-pour-nodejs","title":"Dockerfile pour Node.js","text":"Docker<pre><code>FROM node:16-alpine\n\nWORKDIR /app\n\nCOPY package*.json ./\n\nRUN npm install --production\n\nCOPY . .\n\nEXPOSE 3001\n\nCMD [\"npm\", \"start\"]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#structure-du-projet-nodejs","title":"Structure du projet Node.js","text":"<p>Le service Node.js n\u00e9cessite une organisation sp\u00e9cifique :</p> Text Only<pre><code>api/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 index.js\n\u2502   \u251c\u2500\u2500 routes/\n\u2502   \u251c\u2500\u2500 controllers/\n\u2502   \u251c\u2500\u2500 models/\n\u2502   \u2514\u2500\u2500 middleware/\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 package.json\n\u2514\u2500\u2500 .env\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#variables-denvironnement-critique","title":"Variables d'environnement critique","text":"Variable Description Exemple NODE_ENV Environnement d'ex\u00e9cution production DATABASE_URL String de connexion PostgreSQL postgresql://user:pass@db:5432/db REDIS_URL Connexion au cache Redis redis://cache:6379 API_PORT Port d'\u00e9coute de l'API 3001 LOG_LEVEL Niveau de verbosit\u00e9 des logs info"},{"location":"_projects/_formation-docker/docker-chap10/#exemple-de-service-api-minimal","title":"Exemple de service API minimal","text":"JavaScript<pre><code>// src/index.js\nconst express = require('express');\nconst { Pool } = require('pg');\nconst redis = require('redis');\n\nconst app = express();\nconst PORT = process.env.API_PORT || 3001;\n\n// Connexion PostgreSQL\nconst pool = new Pool({\n  connectionString: process.env.DATABASE_URL\n});\n\n// Connexion Redis\nconst redisClient = redis.createClient({\n  url: process.env.REDIS_URL\n});\n\napp.get('/health', (req, res) =&gt; {\n  res.json({ status: 'ok' });\n});\n\napp.get('/api/users', async (req, res) =&gt; {\n  try {\n    const result = await pool.query('SELECT * FROM users');\n    res.json(result.rows);\n  } catch (error) {\n    res.status(500).json({ error: error.message });\n  }\n});\n\napp.listen(PORT, () =&gt; {\n  console.log(`API running on port ${PORT}`);\n});\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#introduction-a-larchitecture-du-projet","title":"Introduction \u00e0 l'architecture du projet","text":"<p>L'architecture d'un projet Docker Compose multi-services suit un mod\u00e8le en couches o\u00f9 chaque service assume une responsabilit\u00e9 sp\u00e9cifique et communique avec les autres via le r\u00e9seau Docker[1].</p>"},{"location":"_projects/_formation-docker/docker-chap10/#modele-architectural-recommande","title":"Mod\u00e8le architectural recommand\u00e9","text":"<p>L'architecture recommand\u00e9e suit un pattern de s\u00e9paration en trois couches :</p> <p>Couche pr\u00e9sentation (Frontend) : Servie par Nginx, responsable de l'interface utilisateur et du rendu c\u00f4t\u00e9 client.</p> <p>Couche application (API) : Impl\u00e9ment\u00e9e avec Node.js, contenant la logique m\u00e9tier et les endpoints REST.</p> <p>Couche donn\u00e9es (Database) : G\u00e9r\u00e9e par PostgreSQL, stockant les donn\u00e9es persistantes de l'application.</p>"},{"location":"_projects/_formation-docker/docker-chap10/#schema-de-communication","title":"Sch\u00e9ma de communication","text":"Text Only<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   Client    \u2502 (Port 3000)\n\u2502  (Nginx)    \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 HTTP (port 3001)\n       \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502   API       \u2502 (Port 3001)\n\u2502  (Node.js)  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n       \u2502 TCP (port 5432)\n       \u2193\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502  Database   \u2502 (Port 5432)\n\u2502 (PostgreSQL)\u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#configuration-complete-multi-services","title":"Configuration compl\u00e8te multi-services","text":"YAML<pre><code>version: '3.8'\n\nservices:\n  client:\n    build:\n      context: ./client\n      dockerfile: Dockerfile\n    container_name: app-client\n    ports:\n      - \"3000:3000\"\n    depends_on:\n      - api\n    networks:\n      - frontend\n    restart: always\n\n  api:\n    build:\n      context: ./api\n      dockerfile: Dockerfile\n    container_name: app-api\n    ports:\n      - \"3001:3001\"\n    environment:\n      DATABASE_URL: postgresql://appuser:apppass@db:5432/appdb\n      NODE_ENV: production\n    depends_on:\n      db:\n        condition: service_healthy\n    networks:\n      - backend\n      - frontend\n    restart: always\n\n  db:\n    image: postgres:14-alpine\n    container_name: app-db\n    environment:\n      POSTGRES_USER: appuser\n      POSTGRES_PASSWORD: apppass\n      POSTGRES_DB: appdb\n    volumes:\n      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql\n      - db_volume:/var/lib/postgresql/data\n    networks:\n      - backend\n    restart: always\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U appuser\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\nnetworks:\n  frontend:\n    driver: bridge\n  backend:\n    driver: bridge\n\nvolumes:\n  db_volume:\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#avantages-de-cette-architecture","title":"Avantages de cette architecture","text":"<ul> <li>Isolation r\u00e9seau : les services sont s\u00e9par\u00e9s sur des r\u00e9seaux distincts selon leur fonction</li> <li>Scalabilit\u00e9 : chaque service peut \u00eatre modifi\u00e9 ind\u00e9pendamment</li> <li>Maintenabilit\u00e9 : la s\u00e9paration des responsabilit\u00e9s facilite les mises \u00e0 jour</li> <li>R\u00e9silience : les services incluent des v\u00e9rifications de sant\u00e9</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap10/#mise-en-place-du-reverse-proxy-nginx","title":"Mise en place du reverse proxy nginx","text":"<p>Le reverse proxy Nginx occupe une position cruciale dans l'architecture en agissant comme point d'entr\u00e9e unique de l'application et en distribuant le trafic vers les services appropri\u00e9s[3].</p>"},{"location":"_projects/_formation-docker/docker-chap10/#role-du-reverse-proxy","title":"R\u00f4le du reverse proxy","text":"<p>Le reverse proxy assume plusieurs fonctions critiques :</p> <ul> <li>Routage du trafic : dirige les requ\u00eates vers le service appropri\u00e9 bas\u00e9 sur le chemin URL</li> <li>\u00c9quilibrage de charge : distribue les requ\u00eates entre plusieurs instances si n\u00e9cessaire</li> <li>Cache : stocke les r\u00e9ponses fr\u00e9quentes pour r\u00e9duire la latence</li> <li>Compression : compresse les r\u00e9ponses pour \u00e9conomiser la bande passante</li> <li>HTTPS/TLS : g\u00e8re le chiffrement des connexions entrantes</li> <li>Authentification : peut valider les requ\u00eates avant leur transmission</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap10/#service-nginx-reverse-proxy","title":"Service Nginx reverse proxy","text":"YAML<pre><code>services:\n  nginx:\n    image: nginx:alpine\n    container_name: app-nginx\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro\n      - ./nginx/conf.d:/etc/nginx/conf.d:ro\n      - ./nginx/ssl:/etc/nginx/ssl:ro\n      - nginx_cache:/var/cache/nginx\n    depends_on:\n      - api\n      - client\n    networks:\n      - frontend\n    restart: always\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#configuration-nginx-complete","title":"Configuration Nginx compl\u00e8te","text":"Nginx Configuration File<pre><code># nginx.conf\nuser nginx;\nworker_processes auto;\nerror_log /var/log/nginx/error.log warn;\npid /var/run/nginx.pid;\n\nevents {\n    worker_connections 1024;\n}\n\nhttp {\n    include /etc/nginx/mime.types;\n    default_type application/octet-stream;\n\n    log_format main '$remote_addr - $remote_user [$time_local] \"$request\" '\n                    '$status $body_bytes_sent \"$http_referer\" '\n                    '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n    access_log /var/log/nginx/access.log main;\n\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n    keepalive_timeout 65;\n    types_hash_max_size 2048;\n    client_max_body_size 20M;\n\n    # Gzip compression\n    gzip on;\n    gzip_vary on;\n    gzip_proxied any;\n    gzip_comp_level 6;\n    gzip_types text/plain text/css text/xml text/javascript \n               application/json application/javascript application/xml+rss \n               application/rss+xml font/truetype font/opentype \n               application/vnd.ms-fontobject image/svg+xml;\n\n    # Cache configuration\n    proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=api_cache:10m \n                     max_size=100m inactive=60m use_temp_path=off;\n\n    upstream api_backend {\n        least_conn;\n        server api:3001 max_fails=3 fail_timeout=30s;\n    }\n\n    upstream client_frontend {\n        server client:3000;\n    }\n\n    server {\n        listen 80;\n        server_name _;\n\n        # Redirection HTTP vers HTTPS\n        return 301 https://$host$request_uri;\n    }\n\n    server {\n        listen 443 ssl http2;\n        server_name example.com www.example.com;\n\n        ssl_certificate /etc/nginx/ssl/cert.pem;\n        ssl_certificate_key /etc/nginx/ssl/key.pem;\n        ssl_protocols TLSv1.2 TLSv1.3;\n        ssl_ciphers HIGH:!aNULL:!MD5;\n        ssl_prefer_server_ciphers on;\n\n        # API routing\n        location /api/ {\n            proxy_pass http://api_backend;\n            proxy_http_version 1.1;\n            proxy_set_header Upgrade $http_upgrade;\n            proxy_set_header Connection 'upgrade';\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n            proxy_set_header X-Forwarded-Proto $scheme;\n            proxy_cache_bypass $http_upgrade;\n            proxy_cache api_cache;\n            proxy_cache_valid 200 60m;\n            proxy_cache_key \"$scheme$request_method$host$request_uri\";\n        }\n\n        # Frontend routing\n        location / {\n            proxy_pass http://client_frontend;\n            proxy_http_version 1.1;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        }\n\n        # Health check endpoint\n        location /health {\n            access_log off;\n            return 200 \"healthy\\n\";\n            add_header Content-Type text/plain;\n        }\n    }\n\n    include /etc/nginx/conf.d/*.conf;\n}\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#configuration-par-domaine","title":"Configuration par domaine","text":"Nginx Configuration File<pre><code># conf.d/api.conf\nupstream api_servers {\n    server api:3001;\n}\n\nserver {\n    listen 80;\n    server_name api.example.com;\n\n    location / {\n        proxy_pass http://api_servers;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#verification-de-sante-nginx","title":"V\u00e9rification de sant\u00e9 Nginx","text":"YAML<pre><code>services:\n  nginx:\n    image: nginx:alpine\n    healthcheck:\n      test: [\"CMD\", \"wget\", \"--quiet\", \"--tries=1\", \"--spider\", \"http://localhost/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 40s\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#fin-de-la-mise-en-place-de-lenvironnement-de-production","title":"Fin de la mise en place de l'environnement de production","text":"<p>La finition de l'environnement de production implique la configuration compl\u00e8te de tous les services et la mise en place des m\u00e9canismes de surveillance, de r\u00e9cup\u00e9ration automatique et de persistance des donn\u00e9es.</p>"},{"location":"_projects/_formation-docker/docker-chap10/#configuration-de-production-complete","title":"Configuration de production compl\u00e8te","text":"YAML<pre><code>version: '3.8'\n\nservices:\n  nginx:\n    image: nginx:alpine\n    container_name: nginx-proxy\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro\n      - ./nginx/ssl:/etc/nginx/ssl:ro\n      - nginx_cache:/var/cache/nginx\n    depends_on:\n      - api\n      - client\n    networks:\n      - frontend\n    restart: always\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n\n  client:\n    build:\n      context: ./client\n      dockerfile: Dockerfile.prod\n    container_name: client-app\n    environment:\n      - REACT_APP_API_URL=/api\n      - NODE_ENV=production\n    depends_on:\n      - api\n    networks:\n      - frontend\n    restart: always\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n\n  api:\n    build:\n      context: ./api\n      dockerfile: Dockerfile\n    container_name: nodejs-api\n    environment:\n      - NODE_ENV=production\n      - DATABASE_URL=postgresql://produser:securepass@db:5432/proddb\n      - REDIS_URL=redis://cache:6379\n      - LOG_LEVEL=info\n      - API_PORT=3001\n    depends_on:\n      db:\n        condition: service_healthy\n      cache:\n        condition: service_healthy\n    networks:\n      - backend\n      - frontend\n    restart: always\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3001/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n\n  db:\n    image: postgres:14-alpine\n    container_name: postgres-db\n    environment:\n      - POSTGRES_USER=produser\n      - POSTGRES_PASSWORD=securepass\n      - POSTGRES_DB=proddb\n      - POSTGRES_INITDB_ARGS=-c max_connections=100\n    volumes:\n      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql:ro\n      - db_volume:/var/lib/postgresql/data\n    networks:\n      - backend\n    restart: always\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U produser\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n\n  cache:\n    image: redis:7-alpine\n    container_name: redis-cache\n    command: redis-server --appendonly yes --requirepass redispass\n    volumes:\n      - redis_volume:/data\n    networks:\n      - backend\n    restart: always\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"--raw\", \"incr\", \"ping\"]\n      interval: 10s\n      timeout: 3s\n      retries: 3\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n\nnetworks:\n  frontend:\n    driver: bridge\n  backend:\n    driver: bridge\n\nvolumes:\n  db_volume:\n  redis_volume:\n  nginx_cache:\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#variables-denvironnement-de-production","title":"Variables d'environnement de production","text":"Text Only<pre><code># .env.production\nNODE_ENV=production\nDATABASE_URL=postgresql://produser:securepass@db:5432/proddb\nREDIS_URL=redis://:redispass@cache:6379\nAPI_PORT=3001\nLOG_LEVEL=info\nAPI_WORKERS=4\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#commandes-de-gestion-docker-compose","title":"Commandes de gestion Docker Compose","text":"<p>Pour d\u00e9marrer l'environnement complet en arri\u00e8re-plan[3] :</p> Bash<pre><code>docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d\n</code></pre> <p>Pour arr\u00eater les services :</p> Bash<pre><code>docker-compose down\n</code></pre> <p>Pour afficher les logs de tous les services :</p> Bash<pre><code>docker-compose logs -f\n</code></pre> <p>Pour afficher l'\u00e9tat des services[3] :</p> Bash<pre><code>docker-compose ps\n</code></pre> <p>Pour red\u00e9marrer un service sp\u00e9cifique :</p> Bash<pre><code>docker-compose restart api\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#strategies-de-sauvegarde","title":"Strat\u00e9gies de sauvegarde","text":"YAML<pre><code>services:\n  backup:\n    image: alpine:latest\n    container_name: backup-service\n    volumes:\n      - db_volume:/backup/db\n      - redis_volume:/backup/redis\n      - ./backups:/backups\n    command: |\n      sh -c 'while true; do\n        tar -czf /backups/db-$(date +\\%Y\\%m\\%d-\\%H\\%M\\%S).tar.gz /backup/db\n        tar -czf /backups/redis-$(date +\\%Y\\%m\\%d-\\%H\\%M\\%S).tar.gz /backup/redis\n        find /backups -name \"*.tar.gz\" -mtime +7 -delete\n        sleep 86400\n      done'\n    networks:\n      - backend\n    restart: always\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#mise-en-place-du-service-pour-la-base-de-donnees","title":"Mise en place du service pour la base de donn\u00e9es","text":"<p>La base de donn\u00e9es constitue l'\u00e9l\u00e9ment fondamental de persistance pour l'application. PostgreSQL est le choix privil\u00e9gi\u00e9 pour les applications d'entreprise en raison de ses capacit\u00e9s ACID, de sa scalabilit\u00e9 et de son support avanc\u00e9 des types de donn\u00e9es.</p>"},{"location":"_projects/_formation-docker/docker-chap10/#service-postgresql","title":"Service PostgreSQL","text":"YAML<pre><code>services:\n  db:\n    image: postgres:14-alpine\n    container_name: postgres-database\n    environment:\n      POSTGRES_USER: appuser\n      POSTGRES_PASSWORD: apppassword\n      POSTGRES_DB: applicationdb\n      POSTGRES_INITDB_ARGS: \"-c shared_buffers=256MB -c max_connections=200\"\n    ports:\n      - \"5432:5432\"\n    volumes:\n      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql:ro\n      - ./db/migrations:/migrations:ro\n      - db_data:/var/lib/postgresql/data\n    networks:\n      - backend\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U appuser -d applicationdb\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n      start_period: 10s\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n\nvolumes:\n  db_data:\n    driver: local\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#initialisation-de-la-base-de-donnees","title":"Initialisation de la base de donn\u00e9es","text":"SQL<pre><code>-- db/init.sql\n\n-- Cr\u00e9ation des sch\u00e9mas\nCREATE SCHEMA IF NOT EXISTS public;\n\n-- Cr\u00e9ation des tables\nCREATE TABLE IF NOT EXISTS users (\n    id SERIAL PRIMARY KEY,\n    username VARCHAR(50) UNIQUE NOT NULL,\n    email VARCHAR(100) UNIQUE NOT NULL,\n    password_hash VARCHAR(255) NOT NULL,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE TABLE IF NOT EXISTS products (\n    id SERIAL PRIMARY KEY,\n    name VARCHAR(255) NOT NULL,\n    description TEXT,\n    price DECIMAL(10, 2) NOT NULL,\n    stock_quantity INTEGER DEFAULT 0,\n    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\nCREATE TABLE IF NOT EXISTS orders (\n    id SERIAL PRIMARY KEY,\n    user_id INTEGER NOT NULL REFERENCES users(id),\n    product_id INTEGER NOT NULL REFERENCES products(id),\n    quantity INTEGER NOT NULL,\n    total_price DECIMAL(10, 2) NOT NULL,\n    order_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n    status VARCHAR(20) DEFAULT 'pending'\n);\n\n-- Cr\u00e9ation des index\nCREATE INDEX idx_users_email ON users(email);\nCREATE INDEX idx_products_name ON products(name);\nCREATE INDEX idx_orders_user_id ON orders(user_id);\nCREATE INDEX idx_orders_product_id ON orders(product_id);\n\n-- Insertion des donn\u00e9es de base\nINSERT INTO users (username, email, password_hash) VALUES\n('admin', 'admin@example.com', '$2b$10$...'),\n('user1', 'user1@example.com', '$2b$10$...');\n\nINSERT INTO products (name, description, price, stock_quantity) VALUES\n('Produit 1', 'Description du produit 1', 29.99, 100),\n('Produit 2', 'Description du produit 2', 49.99, 50);\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#configuration-avancee-postgresql","title":"Configuration avanc\u00e9e PostgreSQL","text":"YAML<pre><code>services:\n  db:\n    image: postgres:14-alpine\n    environment:\n      POSTGRES_USER: appuser\n      POSTGRES_PASSWORD: securepassword\n      POSTGRES_DB: applicationdb\n      POSTGRES_INITDB_ARGS: |\n        -c max_connections=200\n        -c shared_buffers=512MB\n        -c effective_cache_size=1GB\n        -c maintenance_work_mem=128MB\n        -c checkpoint_completion_target=0.9\n        -c wal_buffers=16MB\n        -c default_statistics_target=100\n    volumes:\n      - ./db/postgresql.conf:/etc/postgresql/postgresql.conf:ro\n      - ./db/init.sql:/docker-entrypoint-initdb.d/init.sql:ro\n      - db_data:/var/lib/postgresql/data\n      - db_backups:/backups\n    command:\n      - \"postgres\"\n      - \"-c\"\n      - \"config_file=/etc/postgresql/postgresql.conf\"\n    networks:\n      - backend\n    restart: always\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#gestion-des-migrations","title":"Gestion des migrations","text":"JavaScript<pre><code>// api/src/migrations/migrate.js\nconst { Pool } = require('pg');\nconst fs = require('fs');\nconst path = require('path');\n\nconst pool = new Pool({\n  connectionString: process.env.DATABASE_URL\n});\n\nasync function runMigrations() {\n  const migrationsDir = path.join(__dirname, 'sql');\n  const files = fs.readdirSync(migrationsDir).sort();\n\n  for (const file of files) {\n    if (file.endsWith('.sql')) {\n      const sql = fs.readFileSync(path.join(migrationsDir, file), 'utf-8');\n      try {\n        await pool.query(sql);\n        console.log(`\u2713 Migration execut\u00e9e: ${file}`);\n      } catch (error) {\n        console.error(`\u2717 Erreur migration ${file}:`, error.message);\n        throw error;\n      }\n    }\n  }\n\n  await pool.end();\n}\n\nrunMigrations().catch(console.error);\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#strategies-de-sauvegarde-postgresql","title":"Strat\u00e9gies de sauvegarde PostgreSQL","text":"YAML<pre><code>services:\n  db-backup:\n    image: postgres:14-alpine\n    container_name: postgres-backup\n    environment:\n      PGPASSWORD: apppassword\n    volumes:\n      - ./backups:/backups\n      - ./backup-script.sh:/backup-script.sh:ro\n    command: /bin/sh /backup-script.sh\n    depends_on:\n      - db\n    networks:\n      - backend\n    restart: always\n</code></pre> Bash<pre><code>#!/bin/bash\n# backup-script.sh\n\nBACKUP_DIR=\"/backups\"\nDB_USER=\"appuser\"\nDB_HOST=\"db\"\nDB_NAME=\"applicationdb\"\nRETENTION_DAYS=7\n\nwhile true; do\n  TIMESTAMP=$(date +%Y%m%d_%H%M%S)\n  BACKUP_FILE=\"$BACKUP_DIR/backup_$TIMESTAMP.sql.gz\"\n\n  pg_dump -h \"$DB_HOST\" -U \"$DB_USER\" \"$DB_NAME\" | \\\n  gzip &gt; \"$BACKUP_FILE\"\n\n  if [ $? -eq 0 ]; then\n    echo \"[$(date)] \u2713 Sauvegarde cr\u00e9\u00e9e: $BACKUP_FILE\"\n  else\n    echo \"[$(date)] \u2717 Erreur lors de la sauvegarde\"\n  fi\n\n  # Suppression des anciennes sauvegardes\n  find \"$BACKUP_DIR\" -name \"backup_*.sql.gz\" -mtime +$RETENTION_DAYS -delete\n\n  # Attendre 24 heures avant la prochaine sauvegarde\n  sleep 86400\ndone\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#exemple-de-requete-nodejs-vers-postgresql","title":"Exemple de requ\u00eate Node.js vers PostgreSQL","text":"JavaScript<pre><code>// api/src/db/userRepository.js\nconst { Pool } = require('pg');\n\nclass UserRepository {\n  constructor(pool) {\n    this.pool = pool;\n  }\n\n  async findAll() {\n    const query = 'SELECT id, username, email, created_at FROM users ORDER BY created_at DESC';\n    const result = await this.pool.query(query);\n    return result.rows;\n  }\n\n  async findById(id) {\n    const query = 'SELECT id, username, email, created_at FROM users WHERE id = $1';\n    const result = await this.pool.query(query, [id]);\n    return result.rows[0] || null;\n  }\n\n  async create(username, email, passwordHash) {\n    const query = `\n      INSERT INTO users (username, email, password_hash) \n      VALUES ($1, $2, $3) \n      RETURNING id, username, email, created_at\n    `;\n    const result = await this.pool.query(query, [username, email, passwordHash]);\n    return result.rows[0];\n  }\n\n  async update(id, username, email) {\n    const query = `\n      UPDATE users \n      SET username = $2, email = $3, updated_at = CURRENT_TIMESTAMP \n      WHERE id = $1 \n      RETURNING id, username, email, updated_at\n    `;\n    const result = await this.pool.query(query, [id, username, email]);\n    return result.rows[0] || null;\n  }\n\n  async delete(id) {\n    const query = 'DELETE FROM users WHERE id = $1 RETURNING id';\n    const result = await this.pool.query(query, [id]);\n    return result.rows.length &gt; 0;\n  }\n}\n\nmodule.exports = UserRepository;\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#configuration-de-securite-postgresql","title":"Configuration de s\u00e9curit\u00e9 PostgreSQL","text":"SQL<pre><code>-- db/security.sql\n\n-- Cr\u00e9ation d'un r\u00f4le d'application restreint\nCREATE ROLE app_user WITH LOGIN PASSWORD 'securepassword';\n\n-- Acc\u00e8s limit\u00e9 aux tables\nGRANT CONNECT ON DATABASE applicationdb TO app_user;\nGRANT USAGE ON SCHEMA public TO app_user;\nGRANT SELECT, INSERT, UPDATE, DELETE ON ALL TABLES IN SCHEMA public TO app_user;\n\n-- Audit des modifications\nCREATE TABLE audit_log (\n    id SERIAL PRIMARY KEY,\n    table_name VARCHAR(100),\n    operation VARCHAR(10),\n    old_data JSONB,\n    new_data JSONB,\n    changed_by VARCHAR(100),\n    changed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n);\n\n-- Trigger pour l'audit\nCREATE OR REPLACE FUNCTION audit_trigger()\nRETURNS TRIGGER AS $$\nBEGIN\n    INSERT INTO audit_log (table_name, operation, old_data, new_data, changed_by)\n    VALUES (TG_TABLE_NAME, TG_OP, to_jsonb(OLD), to_jsonb(NEW), current_user);\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#commandes-essentielles-docker-compose","title":"Commandes essentielles Docker Compose","text":"<p>Les commandes fondamentales pour g\u00e9rer l'application multi-conteneurs sont[3] :</p> Bash<pre><code># D\u00e9marrer les services en arri\u00e8re-plan\ndocker-compose up -d\n\n# Arr\u00eater et supprimer les conteneurs\ndocker-compose down\n\n# Afficher les logs de tous les services\ndocker-compose logs -f\n\n# Afficher les logs d'un service sp\u00e9cifique\ndocker-compose logs -f api\n\n# Afficher l'\u00e9tat des services\ndocker-compose ps\n\n# Red\u00e9marrer les services\ndocker-compose restart\n\n# Reconstruire les images\ndocker-compose build\n\n# Reconstruire et red\u00e9marrer un service\ndocker-compose up -d --build api\n\n# Ex\u00e9cuter une commande dans un conteneur\ndocker-compose exec api npm test\n\n# Afficher la configuration fusionn\u00e9e\ndocker-compose config\n\n# Valider la syntaxe du fichier\ndocker-compose config --quiet\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap10/#bonnes-pratiques-pour-docker-compose","title":"Bonnes pratiques pour Docker Compose","text":"<p>L'adoption de bonnes pratiques assure la qualit\u00e9, la maintenabilit\u00e9 et la s\u00e9curit\u00e9 des applications multi-conteneurs[3] :</p> <ul> <li>Utiliser des versions d'image sp\u00e9cifiques : \u00c9viter <code>latest</code> et pr\u00e9f\u00e9rer des tags de version stables comme <code>postgres:14-alpine</code></li> <li>S\u00e9parer les configurations : Utiliser <code>.env</code> pour les variables sensibles plut\u00f4t que de les coder en dur</li> <li>Organiser les services : Grouper les services par fonction dans des r\u00e9seaux s\u00e9par\u00e9s</li> <li>Impl\u00e9menter les v\u00e9rifications de sant\u00e9 : Permettre aux conteneurs de signaler leur \u00e9tat de fonctionnement</li> <li>G\u00e9rer les volumes : D\u00e9finir explicitement les volumes pour la persistance des donn\u00e9es critiques</li> <li>Documenter la configuration : Ajouter des commentaires explicitant les choix architecturaux</li> <li>Utiliser des images l\u00e9g\u00e8res : Privil\u00e9gier les images alpine pour r\u00e9duire la taille et les surface d'attaque</li> <li>Impl\u00e9menter la gestion des logs : Configurer le driver de log appropri\u00e9 avec rotation des fichiers</li> </ul> <p>Cette approche syst\u00e9matique garantit une base solide pour la gestion des applications multi-conteneurs en environnement de production.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-docker/docker-chap11/","title":"Citations","text":"<ul> <li>https://www.aqsone.com/fr/blog/mettre-en-production-vos-applications-avec-docker</li> <li>https://www.orpheebesson.fr/blog/mettre-en-production-une-application-web-avec-docker</li> <li>https://www.datacamp.com/fr/tutorial/docker-tutorial</li> <li>https://www.hostinger.com/fr/tutoriels/tutoriel-docker</li> <li>https://senza-formations.com/nos-articles/comment-installer-docker-et-configurer-ses-premiers-conteneurs-pas-a-pas</li> <li>https://blog.stephane-robert.info/docs/conteneurs/moteurs-conteneurs/docker/</li> <li>https://www.alfa-safety.fr/blog/docker-en-production-les-bonnes-pratiques/</li> <li>https://www.nas-forum.com/forum/topic/65309-tuto-docker-introduction/</li> <li>https://www.youtube.com/watch?v=f2-XKw-bkSM</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap11/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 306</li> <li>completion_tokens: 4770</li> <li>total_tokens: 5076</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.072, 'request_cost': 0.006, 'total_cost': 0.078}</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap11/#content","title":"Content","text":""},{"location":"_projects/_formation-docker/docker-chap11/#guide-complet-mise-en-production-avec-docker-et-docker-compose","title":"\ud83d\udce6 Guide Complet : Mise en Production avec Docker et Docker Compose","text":""},{"location":"_projects/_formation-docker/docker-chap11/#introduction-a-la-mise-en-production","title":"Introduction \u00e0 la Mise en Production","text":"<p>La mise en production constitue une \u00e9tape critique dans le cycle de vie d'une application. Elle implique de passer d'un environnement de d\u00e9veloppement local \u00e0 un environnement accessible aux utilisateurs finaux. Docker facilite grandement ce processus en garantissant la coh\u00e9rence entre les environnements de d\u00e9veloppement et de production[1][2].</p> <p>La conteneurisation avec Docker offre plusieurs avantages pour la mise en production :</p> <ul> <li>Portabilit\u00e9 : Les conteneurs s'ex\u00e9cutent de mani\u00e8re identique sur n'importe quel serveur</li> <li>Isolement : Chaque application fonctionne dans son propre environnement isol\u00e9</li> <li>Scalabilit\u00e9 : Il est facile de dupliquer et de g\u00e9rer plusieurs instances</li> <li>Maintenabilit\u00e9 : Les d\u00e9pendances sont fig\u00e9es dans l'image Docker</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap11/#creation-du-vps-virtual-private-server","title":"Cr\u00e9ation du VPS (Virtual Private Server)","text":""},{"location":"_projects/_formation-docker/docker-chap11/#preparation-du-serveur","title":"Pr\u00e9paration du Serveur","text":"<p>Avant de d\u00e9ployer une application Docker en production, il convient de pr\u00e9parer correctement le serveur qui l'h\u00e9bergera. Cette pr\u00e9paration inclut plusieurs \u00e9tapes essentielles[2].</p> <p>Pr\u00e9requis mat\u00e9riels recommand\u00e9s :</p> <ul> <li>Processeur 64 bits</li> <li>4 Go de RAM minimum</li> <li>10 Go d'espace disque disponible</li> <li>Acc\u00e8s root ou acc\u00e8s sudo</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap11/#installation-de-docker-sur-le-serveur","title":"Installation de Docker sur le Serveur","text":"<p>L'installation de Docker sur le serveur de production suit une proc\u00e9dure standardis\u00e9e. Apr\u00e8s avoir provisionn\u00e9e une instance VPS aupr\u00e8s d'un fournisseur d'h\u00e9bergement (OVH, Hetzner, DigitalOcean, etc.), l'administrateur doit se connecter au serveur via SSH et ex\u00e9cuter les commandes d'installation appropri\u00e9es.</p> <p>Sur un syst\u00e8me bas\u00e9 sur Debian/Ubuntu, la proc\u00e9dure ressemble \u00e0 ceci :</p> Bash<pre><code># Mise \u00e0 jour du syst\u00e8me\nsudo apt-get update\nsudo apt-get upgrade -y\n\n# Installation des d\u00e9pendances n\u00e9cessaires\nsudo apt-get install -y \\\n  apt-transport-https \\\n  ca-certificates \\\n  curl \\\n  gnupg \\\n  lsb-release\n\n# Ajout de la cl\u00e9 GPG officielle de Docker\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg\n\n# Ajout du repository Docker\necho \\\n  \"deb [arch=amd64 signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\n# Installation de Docker Engine\nsudo apt-get update\nsudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin\n\n# V\u00e9rification de l'installation\ndocker --version\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap11/#configuration-de-lacces-utilisateur","title":"Configuration de l'Acc\u00e8s Utilisateur","text":"<p>Par d\u00e9faut, seul l'utilisateur root peut ex\u00e9cuter les commandes Docker. Pour am\u00e9liorer l'ergonomie et la s\u00e9curit\u00e9, il est recommand\u00e9 d'ajouter l'utilisateur de d\u00e9ploiement au groupe Docker[5] :</p> Bash<pre><code># Cr\u00e9ation d'un utilisateur de d\u00e9ploiement\nsudo useradd -m -s /bin/bash deployer\n\n# Ajout du utilisateur au groupe docker\nsudo usermod -aG docker deployer\n\n# Application des modifications au groupe\nnewgrp docker\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap11/#structure-du-projet-et-preparation","title":"Structure du Projet et Pr\u00e9paration","text":""},{"location":"_projects/_formation-docker/docker-chap11/#organisation-des-fichiers","title":"Organisation des Fichiers","text":"<p>Une application destin\u00e9e \u00e0 la production doit suivre une structure organis\u00e9e. Voici une organisation recommand\u00e9e :</p> Text Only<pre><code>mon-application/\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 app.py\n\u2502   \u251c\u2500\u2500 requirements.txt\n\u2502   \u2514\u2500\u2500 templates/\n\u251c\u2500\u2500 .github/\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u2514\u2500\u2500 deploy.yml\n\u251c\u2500\u2500 docker-compose.yml\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 .dockerignore\n\u251c\u2500\u2500 .env.production\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap11/#creation-du-dockerfile-pour-la-production","title":"Cr\u00e9ation du Dockerfile pour la Production","text":"<p>Le Dockerfile constitue le c\u0153ur de la conteneurisation. Contrairement aux Dockerfiles de d\u00e9veloppement, ceux destin\u00e9s \u00e0 la production doivent \u00eatre optimis\u00e9s pour la taille, les performances et la s\u00e9curit\u00e9[1][3].</p> <p>Voici un exemple complet pour une application Python avec Streamlit :</p> Docker<pre><code>FROM python:3.10-alpine\n\nEXPOSE 8501\n\nWORKDIR /app\n\nCOPY requirements.txt ./requirements.txt\n\nRUN pip3 install -r requirements.txt\n\nCOPY . .\n\nCMD streamlit run my_app.py\n</code></pre> <p>Explicitation des instructions :</p> <ul> <li>FROM : Sp\u00e9cifie l'image de base. <code>python:3.10-alpine</code> offre une image l\u00e9g\u00e8re optimis\u00e9e pour la production</li> <li>EXPOSE : Documente le port sur lequel l'application \u00e9coute</li> <li>WORKDIR : D\u00e9finit le r\u00e9pertoire de travail dans le conteneur</li> <li>COPY : Copie les fichiers du contexte de construction vers l'image</li> <li>RUN : Ex\u00e9cute les commandes pendant la construction de l'image</li> <li>CMD : D\u00e9finit la commande lanc\u00e9e au d\u00e9marrage du conteneur</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap11/#construction-de-limage-docker","title":"Construction de l'Image Docker","text":"<p>Une fois le Dockerfile d\u00e9fini, la construction de l'image s'effectue via la commande suivante[1] :</p> Bash<pre><code># Construction de l'image\ndocker build -t streamlit_app .\n\n# V\u00e9rification de la cr\u00e9ation\ndocker images | grep streamlit_app\n</code></pre> <p>L'option <code>-t</code> ajoute un tag \u00e0 l'image, facilitant son identification. Le point final (<code>.</code>) indique que le Dockerfile se trouve dans le r\u00e9pertoire courant.</p>"},{"location":"_projects/_formation-docker/docker-chap11/#utilisation-de-docker-compose-en-production","title":"Utilisation de Docker Compose en Production","text":""},{"location":"_projects/_formation-docker/docker-chap11/#concept-fondamental","title":"Concept Fondamental","text":"<p>Docker Compose permet de g\u00e9rer plusieurs conteneurs interd\u00e9pendants avec une seule commande. En production, ce fichier doit d\u00e9finir l'ensemble de la pile applicative[2][3].</p>"},{"location":"_projects/_formation-docker/docker-chap11/#architecture-multi-conteneur","title":"Architecture Multi-Conteneur","text":"<p>Une application en production typique comprend plusieurs composants :</p> Composant R\u00f4le Image Port Frontend Interface utilisateur Application frontend 3000 Backend Logique applicative Application backend 3333 Base de donn\u00e9es Persistance des donn\u00e9es PostgreSQL/MySQL 5432/3306 Reverse proxy Routage et SSL Traefik 80/443 Cache Performance Redis 6379"},{"location":"_projects/_formation-docker/docker-chap11/#exemple-de-docker-composeyml","title":"Exemple de docker-compose.yml","text":"YAML<pre><code>version: '3.9'\n\nservices:\n  backend:\n    build:\n      context: .\n      dockerfile: Dockerfile\n    container_name: app_backend\n    ports:\n      - \"3333:3333\"\n    environment:\n      - DATABASE_URL=postgresql://user:password@db:5432/appdb\n      - REDIS_URL=redis://cache:6379\n    depends_on:\n      - db\n      - cache\n    volumes:\n      - ./logs:/app/logs\n    restart: unless-stopped\n    networks:\n      - app_network\n\n  frontend:\n    build:\n      context: ./frontend\n      dockerfile: Dockerfile\n    container_name: app_frontend\n    ports:\n      - \"3000:3000\"\n    depends_on:\n      - backend\n    environment:\n      - REACT_APP_API_URL=http://backend:3333\n    restart: unless-stopped\n    networks:\n      - app_network\n\n  db:\n    image: postgres:15-alpine\n    container_name: app_db\n    environment:\n      - POSTGRES_USER=user\n      - POSTGRES_PASSWORD=password\n      - POSTGRES_DB=appdb\n    volumes:\n      - db_data:/var/lib/postgresql/data\n    restart: unless-stopped\n    networks:\n      - app_network\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U user\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  cache:\n    image: redis:7-alpine\n    container_name: app_cache\n    restart: unless-stopped\n    networks:\n      - app_network\n    healthcheck:\n      test: [\"CMD\", \"redis-cli\", \"ping\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n\n  reverse_proxy:\n    image: traefik:v2.10\n    container_name: app_reverse_proxy\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n      - \"8080:8080\"\n    volumes:\n      - /var/run/docker.sock:/var/run/docker.sock\n      - ./traefik/traefik.yml:/traefik.yml:ro\n      - ./traefik/config.yml:/config.yml:ro\n      - letsencrypt:/letsencrypt\n    restart: unless-stopped\n    networks:\n      - app_network\n\nvolumes:\n  db_data:\n  letsencrypt:\n\nnetworks:\n  app_network:\n    driver: bridge\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap11/#lancement-de-la-production","title":"Lancement de la Production","text":"<p>Avec Docker Compose configur\u00e9, le lancement de l'ensemble de la pile s'effectue simplement[2][3] :</p> Bash<pre><code># Lancement en mode d\u00e9tach\u00e9\ndocker compose up -d\n\n# Affichage des logs\ndocker compose logs -f\n\n# Arr\u00eat des services\ndocker compose down\n\n# Arr\u00eat avec suppression des volumes\ndocker compose down -v\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap11/#mise-en-place-du-certificat-tls","title":"Mise en Place du Certificat TLS","text":""},{"location":"_projects/_formation-docker/docker-chap11/#concepts-de-base","title":"Concepts de Base","text":"<p>TLS (Transport Layer Security) chiffre les communications entre le client et le serveur. En production, tout site web accessible publiquement doit utiliser HTTPS. Let's Encrypt fournit des certificats TLS gratuits, largement utilis\u00e9s avec Certbot[2].</p>"},{"location":"_projects/_formation-docker/docker-chap11/#configuration-de-traefik-avec-lets-encrypt","title":"Configuration de Traefik avec Let's Encrypt","text":"<p>Traefik est un reverse proxy moderne qui automatise la gestion des certificats TLS. Voici la configuration recommand\u00e9e :</p> <p>traefik/traefik.yml :</p> YAML<pre><code>api:\n  insecure: true\n  dashboard: true\n\nentryPoints:\n  http:\n    address: \":80\"\n    http:\n      redirections:\n        entrypoint:\n          to: https\n          scheme: https\n  https:\n    address: \":443\"\n\ncertificatesResolvers:\n  letsencrypt:\n    acme:\n      email: admin@example.com\n      storage: /letsencrypt/acme.json\n      httpChallenge:\n        entryPoint: http\n      certificatesDuration: 2160h\n\nproviders:\n  docker:\n    endpoint: \"unix:///var/run/docker.sock\"\n    exposedByDefault: false\n  file:\n    filename: /config.yml\n    watch: true\n</code></pre> <p>traefik/config.yml :</p> YAML<pre><code>http:\n  routers:\n    backend:\n      rule: \"Host(`api.example.com`)\"\n      service: backend_service\n      entryPoints:\n        - https\n      tls:\n        certResolver: letsencrypt\n\n    frontend:\n      rule: \"Host(`example.com`)\"\n      service: frontend_service\n      entryPoints:\n        - https\n      tls:\n        certResolver: letsencrypt\n\n  services:\n    backend_service:\n      loadBalancer:\n        servers:\n          - url: \"http://backend:3333\"\n\n    frontend_service:\n      loadBalancer:\n        servers:\n          - url: \"http://frontend:3000\"\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap11/#renouvellement-automatique-des-certificats","title":"Renouvellement Automatique des Certificats","text":"<p>Let's Encrypt \u00e9met des certificats valides 90 jours. Le renouvellement automatique constitue une n\u00e9cessit\u00e9 op\u00e9rationnelle[2].</p> <p>Traefik g\u00e8re automatiquement ce renouvellement si configur\u00e9 correctement. Les certificats sont stock\u00e9s dans <code>/letsencrypt/acme.json</code>. Il est crucial de persister ce volume :</p> Bash<pre><code># V\u00e9rification du statut du certificat\ndocker compose exec reverse_proxy cat /letsencrypt/acme.json | grep -o '\"NotAfter\":\"[^\"]*\"' | head -1\n\n# For\u00e7age du renouvellement (si n\u00e9cessaire)\ndocker compose restart reverse_proxy\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap11/#utilisation-de-pm2","title":"Utilisation de PM2","text":""},{"location":"_projects/_formation-docker/docker-chap11/#concepts-fondamentaux","title":"Concepts Fondamentaux","text":"<p>PM2 constitue un gestionnaire de processus pour Node.js permettant de maintenir les applications en ligne. Bien que Docker soit pr\u00e9f\u00e9r\u00e9 pour la conteneurisation en production, PM2 reste utile dans certains contextes hybrides ou pour des d\u00e9ploiements l\u00e9gers[2].</p>"},{"location":"_projects/_formation-docker/docker-chap11/#integration-pm2-dans-docker","title":"Int\u00e9gration PM2 dans Docker","text":"<p>Pour une application Node.js d\u00e9ploy\u00e9e avec PM2 :</p> <p>Dockerfile :</p> Docker<pre><code>FROM node:18-alpine\n\nWORKDIR /app\n\nCOPY package*.json ./\n\nRUN npm ci --only=production\nRUN npm install -g pm2\n\nCOPY . .\n\nEXPOSE 3000\n\nCMD [\"pm2-runtime\", \"start\", \"ecosystem.config.js\"]\n</code></pre> <p>ecosystem.config.js :</p> JavaScript<pre><code>module.exports = {\n  apps: [\n    {\n      name: 'app',\n      script: './src/app.js',\n      instances: 'max',\n      exec_mode: 'cluster',\n      env: {\n        NODE_ENV: 'production',\n        PORT: 3000\n      },\n      error_file: './logs/pm2-error.log',\n      out_file: './logs/pm2-out.log',\n      log_date_format: 'YYYY-MM-DD HH:mm:ss Z',\n      merge_logs: true,\n      autorestart: true,\n      max_memory_restart: '500M',\n      watch: false\n    }\n  ]\n};\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap11/#environnement-de-production","title":"Environnement de Production","text":""},{"location":"_projects/_formation-docker/docker-chap11/#configuration-des-variables-denvironnement","title":"Configuration des Variables d'Environnement","text":"<p>La gestion des secrets et des configurations d\u00e9pend de l'environnement. En production, les donn\u00e9es sensibles ne doivent jamais \u00eatre commises dans le d\u00e9p\u00f4t Git[2].</p> <p>.env.production :</p> Bash<pre><code># Configuration g\u00e9n\u00e9rale\nNODE_ENV=production\nDEBUG=false\n\n# Bases de donn\u00e9es\nDATABASE_URL=postgresql://prod_user:secure_password@db:5432/production_db\nREDIS_URL=redis://cache:6379\n\n# Authentification\nJWT_SECRET=your_super_secret_key_here\nAPI_KEY=production_api_key\n\n# Services externes\nSMTP_HOST=smtp.example.com\nSMTP_PORT=587\nSMTP_USER=noreply@example.com\nSMTP_PASSWORD=email_password\n\n# Domaines\nFRONTEND_URL=https://example.com\nBACKEND_URL=https://api.example.com\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap11/#chargement-des-variables","title":"Chargement des Variables","text":"<p>Dans docker-compose.yml :</p> YAML<pre><code>services:\n  backend:\n    env_file:\n      - .env.production\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap11/#mise-du-projet-sur-gitlab","title":"Mise du Projet sur GitLab","text":""},{"location":"_projects/_formation-docker/docker-chap11/#configuration-du-depot","title":"Configuration du D\u00e9p\u00f4t","text":"<p>L'h\u00e9bergement du code source sur une plateforme comme GitLab facilite le versioning et l'int\u00e9gration continue[2].</p> Bash<pre><code># Initialisation du d\u00e9p\u00f4t Git\ngit init\ngit remote add origin https://gitlab.com/username/mon-application.git\n\n# Premier commit\ngit add .\ngit commit -m \"Initial commit: application structure\"\ngit push -u origin main\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap11/#fichier-gitignore-pour-docker","title":"Fichier .gitignore pour Docker","text":"Text Only<pre><code># Fichiers environnement\n.env\n.env.local\n.env.*.local\n\n# D\u00e9pendances\nnode_modules/\n__pycache__/\n*.pyc\nvenv/\n\n# Logs et donn\u00e9es\nlogs/\n*.log\nnpm-debug.log\n\n# Volumes Docker\nvolumes/\ndb_data/\n\n# IDE\n.vscode/\n.idea/\n*.swp\n*.swo\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap11/#lancement-de-la-production_1","title":"Lancement de la Production","text":""},{"location":"_projects/_formation-docker/docker-chap11/#deploiement-initial","title":"D\u00e9ploiement Initial","text":"<p>Le d\u00e9ploiement d'une application en production implique plusieurs v\u00e9rifications pr\u00e9alables :</p> Bash<pre><code># Acc\u00e8s au serveur\nssh deployer@your_server_ip\n\n# Clonage du d\u00e9p\u00f4t\ngit clone https://gitlab.com/username/mon-application.git\ncd mon-application\n\n# Cr\u00e9ation du fichier .env avec les secrets de production\nnano .env.production\n\n# Lancement de l'application\ndocker compose -f docker-compose.yml up -d\n\n# V\u00e9rification du statut\ndocker compose ps\ndocker compose logs -f\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap11/#mise-a-jour-de-lapplication","title":"Mise \u00e0 Jour de l'Application","text":"<p>Lors d'une mise \u00e0 jour :</p> Bash<pre><code># R\u00e9cup\u00e9ration des derni\u00e8res modifications\ngit pull origin main\n\n# Reconstruction des images si le Dockerfile a chang\u00e9\ndocker compose up -d --build\n\n# Nettoyage des ressources obsol\u00e8tes\ndocker system prune -a -f\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap11/#monitoring-et-maintenance","title":"Monitoring et Maintenance","text":"Bash<pre><code># Affichage des logs en temps r\u00e9el\ndocker compose logs -f backend\n\n# Statistiques d'utilisation des ressources\ndocker stats\n\n# Inspection d'un conteneur\ndocker compose exec backend sh\n\n# Red\u00e9marrage d'un service\ndocker compose restart backend\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap11/#automatisation-avec-github-actionsgitlab-ci","title":"Automatisation avec GitHub Actions/GitLab CI","text":""},{"location":"_projects/_formation-docker/docker-chap11/#workflow-de-deploiement-automatise","title":"Workflow de D\u00e9ploiement Automatis\u00e9","text":"<p>L'automatisation du d\u00e9ploiement r\u00e9duit les erreurs humaines et acc\u00e9l\u00e8re les mises en production[2].</p> <p>.github/workflows/deploy.yml :</p> YAML<pre><code>name: Build, push, and deploy Docker images to the server\n\non:\n  push:\n    branches: [\"main\"]\n\nenv:\n  REGISTRY: ghcr.io\n  DOCKER_IMAGE_PRODUCTION_TAG: production\n\njobs:\n  build_and_push:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v3\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - name: Login to GitHub Container Registry\n        uses: docker/login-action@v2\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Build and push Docker image\n        uses: docker/build-push-action@v4\n        with:\n          context: .\n          push: true\n          tags: |\n            ${{ env.REGISTRY }}/${{ github.repository }}:${{ env.DOCKER_IMAGE_PRODUCTION_TAG }}\n            ${{ env.REGISTRY }}/${{ github.repository }}:latest\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n\n  deploy:\n    needs: build_and_push\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Deploy to production server\n        uses: appleboy/ssh-action@master\n        with:\n          host: ${{ secrets.PRODUCTION_SERVER_IP }}\n          username: ${{ secrets.PRODUCTION_SERVER_USER }}\n          key: ${{ secrets.PRODUCTION_SERVER_SSH_KEY }}\n          script: |\n            cd /home/deployer/mon-application\n            git pull origin main\n            docker compose pull\n            docker compose up -d\n            docker compose logs backend\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap11/#bonnes-pratiques-en-production","title":"Bonnes Pratiques en Production","text":""},{"location":"_projects/_formation-docker/docker-chap11/#securite","title":"S\u00e9curit\u00e9","text":"<ul> <li>Principe du moindre privil\u00e8ge : N'exposer que les ports n\u00e9cessaires</li> <li>Secrets management : Utiliser des gestionnaires de secrets (HashiCorp Vault, AWS Secrets Manager)</li> <li>Mises \u00e0 jour r\u00e9guli\u00e8res : Maintenir les images de base \u00e0 jour</li> <li>Scanning d'images : Analyser les images pour les vuln\u00e9rabilit\u00e9s</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap11/#performance","title":"Performance","text":"<ul> <li>Limites de ressources : D\u00e9finir des limites CPU et m\u00e9moire</li> </ul> YAML<pre><code>services:\n  backend:\n    deploy:\n      resources:\n        limits:\n          cpus: '1'\n          memory: 512M\n        reservations:\n          cpus: '0.5'\n          memory: 256M\n</code></pre> <ul> <li>Healthchecks : V\u00e9rifier la disponibilit\u00e9 des services</li> <li>Caching : Utiliser Redis ou Memcached pour le cache applicatif</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap11/#observabilite","title":"Observabilit\u00e9","text":"<ul> <li>Logs centralis\u00e9s : Aggr\u00e9ger les logs avec ELK ou Loki</li> <li>Monitoring : Utiliser Prometheus et Grafana</li> <li>Tracing distribu\u00e9 : Impl\u00e9menter Jaeger pour suivre les requ\u00eates</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap11/#disaster-recovery","title":"Disaster Recovery","text":"<ul> <li>Sauvegardes r\u00e9guli\u00e8res : Exporter les volumes de donn\u00e9es</li> </ul> Bash<pre><code># Sauvegarde d'une base de donn\u00e9es\ndocker compose exec db mysqldump -u user -p password dbname &gt; backup.sql\n\n# Sauvegarde d'un volume Docker\ndocker run --rm -v db_data:/data -v $(pwd):/backup \\\n  alpine tar czf /backup/db_data_backup.tar.gz -C /data .\n</code></pre> <ul> <li>R\u00e9plication : Mettre en place une strat\u00e9gie multi-r\u00e9gions</li> <li>Rollback rapide : Conserver les versions pr\u00e9c\u00e9dentes des images</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap11/#optimisation-et-evolution","title":"Optimisation et \u00c9volution","text":""},{"location":"_projects/_formation-docker/docker-chap11/#scaling-horizontal","title":"Scaling Horizontal","text":"<p>Pour g\u00e9rer une charge croissante, il faut ajouter plusieurs instances :</p> YAML<pre><code>services:\n  backend:\n    deploy:\n      replicas: 3\n      update_config:\n        parallelism: 1\n        delay: 10s\n      restart_policy:\n        condition: on-failure\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap11/#orchestration-avec-docker-swarm","title":"Orchestration avec Docker Swarm","text":"<p>Pour des d\u00e9ploiements \u00e0 plus grande \u00e9chelle :</p> Bash<pre><code># Initialisation du Swarm\ndocker swarm init\n\n# D\u00e9ploiement d'un stack\ndocker stack deploy -c docker-compose.yml mon_app\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap11/#migration-vers-kubernetes","title":"Migration vers Kubernetes","text":"<p>Pour des besoins de scalabilit\u00e9 massifs et d'orchestration avanc\u00e9e, Kubernetes repr\u00e9sente l'\u00e9tape suivante naturelle apr\u00e8s Docker Compose et Docker Swarm.</p>"},{"location":"_projects/_formation-docker/docker-chap11/#conclusion","title":"Conclusion","text":"<p>La mise en production d'applications avec Docker et Docker Compose offre une base solide pour des d\u00e9ploiements fiables et reproductibles. L'ensemble des \u00e9l\u00e9ments pr\u00e9sent\u00e9s\u2014configuration d'infrastructure, gestion des certificats TLS, automatisation des d\u00e9ploiements, et monitoring\u2014constituent les piliers d'une strat\u00e9gie de production robuste. L'apprentissage progressif de ces concepts, combin\u00e9 \u00e0 une compr\u00e9hension des bonnes pratiques, permet de b\u00e2tir des syst\u00e8mes production-ready, maintenables et \u00e9volutifs.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-docker/docker-chap12/","title":"Citations","text":"<ul> <li>https://oclock.io/deployer-docker-developper-symfony</li> <li>https://knplabs.com/fr/blog/comment-dockeriser-un-projet-symfony</li> <li>https://w3r.one/fr/blog/web/symfony/deploiement-integration-continue-symfony</li> <li>https://symfony.com/doc/current/setup/docker.html</li> <li>https://www.youtube.com/watch?v=dBjOBV64bIg</li> <li>https://kevinrolin.be/blog/cest-quoi-docker-et-comment-lutiliser-pour-un-projet-symfony</li> <li>https://www.youtube.com/watch?v=g_UWtPgUsJo</li> <li>https://www.maxpou.fr/blog/docker-pour-symfony/</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap12/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 302</li> <li>completion_tokens: 7436</li> <li>total_tokens: 7738</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.112, 'request_cost': 0.006, 'total_cost': 0.118}</li> </ul>"},{"location":"_projects/_formation-docker/docker-chap12/#content","title":"Content","text":""},{"location":"_projects/_formation-docker/docker-chap12/#docker-avec-php-et-symfony","title":"Docker avec PHP et Symfony","text":""},{"location":"_projects/_formation-docker/docker-chap12/#mise-en-place-du-service-php-avec-symfony","title":"Mise en place du service PHP avec Symfony","text":""},{"location":"_projects/_formation-docker/docker-chap12/#fondamentaux-de-lintegration-php-dans-docker","title":"Fondamentaux de l'int\u00e9gration PHP dans Docker","text":"<p>L'int\u00e9gration de PHP dans un environnement Docker pour d\u00e9velopper avec Symfony repose sur la compr\u00e9hension des conteneurs et de leur interaction avec l'application web. Contrairement \u00e0 une installation locale classique, Docker permet de disposer d'un environnement isol\u00e9, reproductible et coh\u00e9rent entre le d\u00e9veloppement et la production.</p> <p>Le processus d\u00e9bute par la cr\u00e9ation d'une image Docker personnalis\u00e9e bas\u00e9e sur une image PHP officielle. L'image de base <code>php:8.2-fpm-alpine</code> ou <code>php:8.1-fpm</code> constitue le point de d\u00e9part id\u00e9al pour une application Symfony[1][2]. Alpine Linux offre une image minimale et l\u00e9g\u00e8re, tandis que FPM (FastCGI Process Manager) permet la communication avec le serveur web (Nginx ou Apache) via le protocole FastCGI.</p>"},{"location":"_projects/_formation-docker/docker-chap12/#structure-du-dockerfile-pour-php","title":"Structure du Dockerfile pour PHP","text":"<p>La cr\u00e9ation d'un Dockerfile personnalis\u00e9 commence par d\u00e9finir clairement les besoins sp\u00e9cifiques de l'application Symfony. Le fichier configure l'environnement PHP avec toutes les extensions n\u00e9cessaires au fonctionnement optimal de l'application.</p> Docker<pre><code>FROM php:8.2-fpm-alpine\n\n# D\u00e9finition des variables d'environnement\nENV PHPUSER=symfony\nENV PHPGROUP=symfony\nENV UID=1000\nENV GID=1000\n\n# Installation des d\u00e9pendances syst\u00e8me\nRUN apk add --no-cache \\\n    autoconf \\\n    g++ \\\n    make\n\n# Configuration des extensions PHP pour Symfony\nRUN docker-php-ext-configure intl\nRUN docker-php-ext-install -j\"$(nproc)\" \\\n    pdo \\\n    pdo_mysql \\\n    intl \\\n    zip \\\n    mbstring\n\n# Cr\u00e9ation du r\u00e9pertoire applicatif\nRUN mkdir -p /var/www/html/public\n\n# Copie de l'application\nCOPY ./src /var/www/html\n\n# D\u00e9finition de l'utilisateur PHP\nRUN addgroup -g 1006 --system symfony\nRUN adduser -G www-data --system -D -s /bin/sh -u 1006 symfony\n\nWORKDIR /var/www/html\n\nCMD [\"php-fpm\"]\n</code></pre> <p>Ce Dockerfile \u00e9tablit une foundation solide pour ex\u00e9cuter une application Symfony[1]. Les extensions PHP install\u00e9es incluent PDO et PDO MySQL pour la gestion des bases de donn\u00e9es via Doctrine, ainsi que d'autres extensions essentielles comme intl pour l'internationalisation et zip pour la manipulation d'archives.</p>"},{"location":"_projects/_formation-docker/docker-chap12/#integration-dans-docker-composeyml","title":"Int\u00e9gration dans docker-compose.yml","text":"<p>Le service PHP doit \u00eatre d\u00e9fini dans le fichier de composition Docker qui orchestre l'ensemble des services de l'application[1][2].</p> YAML<pre><code>version: '3.8'\n\nservices:\n  php:\n    build:\n      context: .\n      dockerfile: php.dockerfile\n    args:\n      - UID=${UID:-1000}\n      - GID=${GID:-1000}\n    volumes:\n      - ./src:/var/www/html\n    environment:\n      - DATABASE_URL=mysql://root:password@mysql:3306/symfony_db\n      - APP_ENV=dev\n      - APP_DEBUG=1\n    restart: on-failure\n    user: 1000:1000\n    networks:\n      - symfony\n    env_file:\n      - .env\n\nnetworks:\n  symfony:\n    driver: bridge\n</code></pre> <p>La directive <code>volumes</code> cr\u00e9e un mapping entre le r\u00e9pertoire source local (<code>./src</code>) et le r\u00e9pertoire dans le conteneur (<code>/var/www/html</code>). Ce m\u00e9canisme permet une synchronisation bidirectionnelle du code, facilitant le d\u00e9veloppement avec rechargement instantan\u00e9 des modifications[1][2].</p>"},{"location":"_projects/_formation-docker/docker-chap12/#introduction-aux-environnements-php","title":"Introduction aux environnements PHP","text":""},{"location":"_projects/_formation-docker/docker-chap12/#configuration-multi-environnements-avec-symfony","title":"Configuration multi-environnements avec Symfony","text":"<p>Symfony propose une gestion native des environnements (dev, prod, test) qui s'int\u00e8gre parfaitement avec Docker. Le fichier <code>.env</code> \u00e0 la racine du projet sp\u00e9cifie le mode d'ex\u00e9cution et les param\u00e8tres de connexion \u00e0 la base de donn\u00e9es.</p> Text Only<pre><code># .env\nAPP_ENV=dev\nAPP_DEBUG=1\nDATABASE_URL=\"mysql://root:root_password@mysql:3306/symfony_db\"\nMAILER_DSN=\"smtp://mailer:1025\"\nREDIS_URL=\"redis://redis:6379\"\n</code></pre> <p>Chaque environnement dispose de fichiers de configuration sp\u00e9cifiques dans le r\u00e9pertoire <code>config/packages/</code>. L'environnement de d\u00e9veloppement active des outils de diagnostic comme le Web Profiler et la barre d'outils Symfony, tandis que l'environnement de production d\u00e9sactive ces fonctionnalit\u00e9s pour optimiser les performances et la s\u00e9curit\u00e9.</p>"},{"location":"_projects/_formation-docker/docker-chap12/#gestion-des-variables-denvironnement","title":"Gestion des variables d'environnement","text":"<p>Docker facilite l'injection de variables d'environnement via plusieurs m\u00e9canismes. Le fichier <code>docker-compose.yml</code> peut d\u00e9finir directement les variables, les charger depuis un fichier <code>.env</code>, ou les passer lors de l'ex\u00e9cution du conteneur.</p> YAML<pre><code>services:\n  php:\n    environment:\n      # Variables directes\n      - SYMFONY_ENV=dev\n      # Variables dynamiques\n      - DATABASE_HOST=mysql\n      - DATABASE_PORT=3306\n      - DATABASE_NAME=symfony_db\n      - DATABASE_USER=root\n      - DATABASE_PASSWORD=${MYSQL_ROOT_PASSWORD}\n    env_file:\n      - .env\n      - .env.local\n</code></pre> <p>Cette approche garantit la coh\u00e9rence entre les environnements locaux et de production tout en maintenant les donn\u00e9es sensibles s\u00e9par\u00e9es des fichiers du projet.</p>"},{"location":"_projects/_formation-docker/docker-chap12/#gestion-des-packages-php","title":"Gestion des packages PHP","text":"<p>La gestion des d\u00e9pendances PHP s'effectue via Composer, le gestionnaire de packages standard de l'\u00e9cosyst\u00e8me PHP. Un service Composer d\u00e9di\u00e9 dans Docker automatise l'installation et la mise \u00e0 jour des d\u00e9pendances sans n\u00e9cessiter une installation locale de Composer[1].</p> Docker<pre><code>FROM composer:2\n\nRUN adduser -g www-data -s /bin/sh -D symfony\n\nWORKDIR /var/www/html\n</code></pre> YAML<pre><code>composer:\n  build:\n    context: .\n    dockerfile: composer.dockerfile\n  volumes:\n    - ./src:/var/www/html\n  working_dir: /var/www/html\n  networks:\n    - symfony\n</code></pre> <p>L'ex\u00e9cution de Composer dans Docker s'effectue via :</p> Bash<pre><code>docker compose run --rm --user $(id -u):$(id -g) composer create-project symfony/skeleton:\"6.3.*\" ./\ndocker compose run --rm composer install\ndocker compose run --rm composer require symfony/console\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap12/#mise-en-place-des-services-php-fpm-et-webpack-encore","title":"Mise en place des services PHP-FPM et Webpack Encore","text":""},{"location":"_projects/_formation-docker/docker-chap12/#php-fpm-architecture-et-configuration","title":"PHP-FPM : Architecture et configuration","text":"<p>PHP-FPM (FastCGI Process Manager) constitue le c\u0153ur de l'architecture web moderne avec Docker. Contrairement aux modules PHP Apache, FPM s'ex\u00e9cute comme un service ind\u00e9pendant qui communique avec le serveur web via le protocole FastCGI. Cette s\u00e9paration offre une flexibilit\u00e9 et une scalabilit\u00e9 sup\u00e9rieures.</p> <p>La configuration de PHP-FPM s'effectue dans le fichier <code>/etc/php-fpm.conf</code> ou via les fichiers de pool dans <code>/usr/local/etc/php-fpm.d/</code>. Le pool <code>www.conf</code> d\u00e9finit les param\u00e8tres cruciaux du processus worker.</p> INI<pre><code>; www.conf\n[www]\nuser = symfony\ngroup = www-data\nlisten = 0.0.0.0:9000\nlisten.backlog = -1\npm = dynamic\npm.max_children = 5\npm.start_servers = 2\npm.min_spare_servers = 1\npm.max_spare_servers = 3\n</code></pre> <p>Cette configuration permet \u00e0 PHP-FPM d'accueillir plusieurs requ\u00eates simultan\u00e9es avec gestion dynamique du pool de processus workers. Le conteneur expose le port 9000 sur lequel le serveur web se connecte.</p>"},{"location":"_projects/_formation-docker/docker-chap12/#webpack-encore-pour-la-gestion-des-assets","title":"Webpack Encore pour la gestion des assets","text":"<p>Webpack Encore automatise la compilation et l'optimisation des assets (CSS, JavaScript, images). Son int\u00e9gration dans Docker n\u00e9cessite un service Node.js d\u00e9di\u00e9 qui observe les modifications des fichiers source et recompile automatiquement lors du d\u00e9veloppement.</p> Docker<pre><code>FROM node:18-alpine\n\nWORKDIR /var/www/html\n\nRUN npm install -g npm@latest\n\nCOPY ./src/package.json ./src/package-lock.json ./\n\nRUN npm install\n\nCOPY ./src .\n\nENTRYPOINT [\"npm\", \"run\"]\nCMD [\"watch\"]\n</code></pre> YAML<pre><code>webpack:\n  build:\n    context: .\n    dockerfile: webpack.dockerfile\n  volumes:\n    - ./src:/var/www/html\n  networks:\n    - symfony\n  command: npm run watch\n</code></pre> <p>Le fichier <code>webpack.config.js</code> dans le r\u00e9pertoire source configure la compilation des assets :</p> JavaScript<pre><code>const Encore = require('@symfony/webpack-encore');\n\nEncore\n  .setOutputPath('public/build/')\n  .setPublicPath('/build')\n  .addEntry('app', './assets/app.js')\n  .addStyleEntry('styles', './assets/styles/main.scss')\n  .splitEntryChunks()\n  .enableSingleRuntimeChunk()\n  .cleanupOutputBeforeBuild()\n  .enableBuildNotifications()\n  .enableSourceMaps(!Encore.isProduction())\n  .enableVersioning(Encore.isProduction())\n  .configureBabel(config =&gt; {\n    config.plugins.push('@babel/plugin-proposal-class-properties');\n  });\n\nmodule.exports = Encore.getWebpackConfig();\n</code></pre> <p>La compilation pendant le d\u00e9veloppement s'effectue avec <code>npm run watch</code>, tandis que <code>npm run build</code> g\u00e9n\u00e8re les assets optimis\u00e9s pour la production.</p>"},{"location":"_projects/_formation-docker/docker-chap12/#mise-en-production","title":"Mise en production","text":""},{"location":"_projects/_formation-docker/docker-chap12/#optimisation-des-images-docker-pour-la-production","title":"Optimisation des images Docker pour la production","text":"<p>La transition vers la production implique une r\u00e9flexion strat\u00e9gique sur les couches Docker et les tailles d'image. L'approche multi-stage permet de conserver une image finale r\u00e9duite en taille.</p> Docker<pre><code># Stage 1 : Construction\nFROM php:8.2-fpm-alpine as builder\n\nRUN apk add --no-cache --virtual .build-deps \\\n    autoconf \\\n    g++ \\\n    make\n\nRUN docker-php-ext-configure intl\nRUN docker-php-ext-install -j\"$(nproc)\" \\\n    pdo \\\n    pdo_mysql \\\n    intl\n\nCOPY ./src /app\n\nWORKDIR /app\n\nRUN composer install --no-dev --optimize-autoloader\n\n# Stage 2 : Runtime\nFROM php:8.2-fpm-alpine\n\nRUN apk add --no-cache \\\n    mysql-client\n\nRUN docker-php-ext-install \\\n    pdo \\\n    pdo_mysql \\\n    intl\n\nCOPY --from=builder /app /var/www/html\n\nWORKDIR /var/www/html\n\nCMD [\"php-fpm\"]\n</code></pre> <p>Cette technique r\u00e9duit consid\u00e9rablement la taille finale de l'image en \u00e9liminant les d\u00e9pendances de compilation utilis\u00e9es uniquement pendant la construction.</p>"},{"location":"_projects/_formation-docker/docker-chap12/#configuration-php-optimisee-pour-la-production","title":"Configuration PHP optimis\u00e9e pour la production","text":"<p>L'environnement de production n\u00e9cessite une configuration PHP stricte bas\u00e9e sur des principes de performance et de s\u00e9curit\u00e9[3].</p> INI<pre><code>; production-php.ini\ndisplay_errors = Off\nlog_errors = On\nerror_log = /var/log/php-errors.log\n\n; OPCache pour le cache des bytecode compil\u00e9s\nopcache.enable=1\nopcache.enable_cli=1\nopcache.memory_consumption=256\nopcache.interned_strings_buffer=16\nopcache.max_accelerated_files=20000\nopcache.validate_timestamps=0\nopcache.revalidate_freq=0\n\n; S\u00e9curit\u00e9\nexpose_php = Off\nallow_url_fopen = Off\nallow_url_include = Off\n\n; Performance\nmax_execution_time = 30\nmemory_limit = 256M\nupload_max_filesize = 20M\npost_max_size = 20M\n</code></pre> <p>L'activation d'OPCache acc\u00e9l\u00e8re l'ex\u00e9cution du code PHP en mettant en cache les fichiers bytecode compil\u00e9s, r\u00e9duisant ainsi les temps de traitement \u00e0 chaque requ\u00eate[3].</p>"},{"location":"_projects/_formation-docker/docker-chap12/#gestion-des-migrations-et-fixtures","title":"Gestion des migrations et fixtures","text":"<p>Le d\u00e9ploiement en production requiert l'ex\u00e9cution de migrations de base de donn\u00e9es et potentiellement le chargement de fixtures initiales. Ces op\u00e9rations s'effectuent avant le d\u00e9marrage de l'application.</p> Docker<pre><code>FROM php:8.2-fpm-alpine\n\n# ... configuration php ...\n\nCOPY ./src /var/www/html\n\nWORKDIR /var/www/html\n\nRUN chmod +x ./bin/console\n\nENTRYPOINT [\"./bin/console\"]\nCMD [\"doctrine:migrations:migrate\", \"--no-interaction\"]\n</code></pre> YAML<pre><code>php:\n  build:\n    context: .\n    dockerfile: php.dockerfile\n  depends_on:\n    mysql:\n      condition: service_healthy\n  environment:\n    - DATABASE_URL=mysql://root:password@mysql:3306/symfony_db\n  networks:\n    - symfony\n\nmysql:\n  image: mysql:8.0\n  environment:\n    - MYSQL_ROOT_PASSWORD=password\n    - MYSQL_DATABASE=symfony_db\n  healthcheck:\n    test: [\"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\"]\n    timeout: 5s\n    retries: 5\n  networks:\n    - symfony\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap12/#mise-en-place-du-service-mysql","title":"Mise en place du service MySQL","text":""},{"location":"_projects/_formation-docker/docker-chap12/#configuration-du-conteneur-mysql","title":"Configuration du conteneur MySQL","text":"<p>MySQL constitue la couche de persistance des donn\u00e9es pour la majorit\u00e9 des applications Symfony. Son int\u00e9gration dans Docker s'effectue simplement via l'utilisation d'une image officielle MySQL pr\u00e9-configur\u00e9e.</p> YAML<pre><code>mysql:\n  image: mysql:8.0\n  container_name: symfony-mysql\n  environment:\n    MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD:-root_password}\n    MYSQL_DATABASE: ${MYSQL_DATABASE:-symfony_db}\n    MYSQL_USER: ${MYSQL_USER:-symfony}\n    MYSQL_PASSWORD: ${MYSQL_PASSWORD:-symfony_password}\n  ports:\n    - \"${MYSQL_PORT:-3306}:3306\"\n  volumes:\n    - mysql_data:/var/lib/mysql\n    - ./docker/mysql/init.sql:/docker-entrypoint-initdb.d/init.sql\n  restart: unless-stopped\n  networks:\n    - symfony\n  healthcheck:\n    test: [\"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\", \"-u\", \"root\", \"-p${MYSQL_ROOT_PASSWORD}\"]\n    timeout: 5s\n    retries: 5\n    interval: 10s\n\nvolumes:\n  mysql_data:\n    driver: local\n</code></pre> <p>Le volume nomm\u00e9 <code>mysql_data</code> persiste les donn\u00e9es entre les red\u00e9marrages du conteneur, garantissant la conservation des informations de la base de donn\u00e9es[2].</p>"},{"location":"_projects/_formation-docker/docker-chap12/#doctrine-orm-et-configuration-de-la-base-de-donnees","title":"Doctrine ORM et configuration de la base de donn\u00e9es","text":"<p>Doctrine ORM offre une abstraction \u00e9l\u00e9gante pour l'interaction avec la base de donn\u00e9es. Sa configuration s'effectue via le fichier <code>.env</code> qui sp\u00e9cifie l'URL de connexion :</p> Text Only<pre><code>DATABASE_URL=\"mysql://symfony:symfony_password@mysql:3306/symfony_db\"\n</code></pre> <p>Les entit\u00e9s Symfony d\u00e9finissent la structure des tables via des annotations ou des attributs PHP :</p> PHP<pre><code>&lt;?php\n\nnamespace App\\Entity;\n\nuse Doctrine\\ORM\\Mapping as ORM;\n\n#[ORM\\Entity]\n#[ORM\\Table(name: \"users\")]\nclass User\n{\n    #[ORM\\Id]\n    #[ORM\\GeneratedValue]\n    #[ORM\\Column(type: \"integer\")]\n    private int $id;\n\n    #[ORM\\Column(type: \"string\", length: 255)]\n    private string $email;\n\n    #[ORM\\Column(type: \"string\", length: 255)]\n    private string $password;\n\n    #[ORM\\Column(type: \"datetime\")]\n    private \\DateTime $createdAt;\n\n    // Getters et setters...\n}\n</code></pre> <p>La g\u00e9n\u00e9ration et la synchronisation des tables s'effectuent via les commandes Doctrine :</p> Bash<pre><code>docker compose exec php bin/console doctrine:database:create\ndocker compose exec php bin/console doctrine:migrations:diff\ndocker compose exec php bin/console doctrine:migrations:migrate\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap12/#gestion-des-donnees-de-test-et-fixtures","title":"Gestion des donn\u00e9es de test et fixtures","text":"<p>DoctrineFixturesBundle automatise le chargement de donn\u00e9es de test pour l'environnement de d\u00e9veloppement :</p> PHP<pre><code>&lt;?php\n\nnamespace App\\DataFixtures;\n\nuse App\\Entity\\User;\nuse Doctrine\\Bundle\\FixturesBundle\\Fixture;\nuse Doctrine\\Persistence\\ObjectManager;\nuse Symfony\\Component\\PasswordHasher\\Hasher\\UserPasswordHasherInterface;\n\nclass UserFixtures extends Fixture\n{\n    private UserPasswordHasherInterface $passwordHasher;\n\n    public function __construct(UserPasswordHasherInterface $passwordHasher)\n    {\n        $this-&gt;passwordHasher = $passwordHasher;\n    }\n\n    public function load(ObjectManager $manager): void\n    {\n        for ($i = 0; $i &lt; 10; ++$i) {\n            $user = new User();\n            $user-&gt;setEmail(\"user{$i}@example.com\");\n            $user-&gt;setPassword(\n                $this-&gt;passwordHasher-&gt;hashPassword($user, 'password')\n            );\n            $user-&gt;setCreatedAt(new \\DateTime());\n            $manager-&gt;persist($user);\n        }\n\n        $manager-&gt;flush();\n    }\n}\n</code></pre> <p>L'ex\u00e9cution du chargement de fixtures s'effectue avec :</p> Bash<pre><code>docker compose exec php bin/console doctrine:fixtures:load\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap12/#mise-en-place-du-service-nodejs","title":"Mise en place du service Node.js","text":""},{"location":"_projects/_formation-docker/docker-chap12/#installation-et-configuration-de-nodejs","title":"Installation et configuration de Node.js","text":"<p>Node.js s'int\u00e8gre dans l'architecture Docker pour g\u00e9rer les processus qui requi\u00e8rent JavaScript c\u00f4t\u00e9 serveur, particuli\u00e8rement pour Webpack Encore et les outils de build des assets[1].</p> Docker<pre><code>FROM node:18-alpine\n\nWORKDIR /var/www/html\n\nENV NODE_ENV=development\n\n# Installation des d\u00e9pendances globales\nRUN npm install -g npm@latest yarn\n\n# Copie des fichiers de configuration\nCOPY ./src/package.json ./src/package-lock.json ./\n\n# Installation des d\u00e9pendances du projet\nRUN npm install\n\nCOPY ./src .\n\nEXPOSE 8080\n\nCMD [\"npm\", \"run\", \"watch\"]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap12/#gestion-des-dependances-npm","title":"Gestion des d\u00e9pendances npm","text":"<p>Le fichier <code>package.json</code> d\u00e9funit les scripts et d\u00e9pendances Node.js de l'application :</p> JSON<pre><code>{\n  \"name\": \"symfony-app\",\n  \"version\": \"1.0.0\",\n  \"private\": true,\n  \"description\": \"Symfony application with Docker\",\n  \"scripts\": {\n    \"dev\": \"webpack-dev-server --mode development\",\n    \"watch\": \"webpack --mode development --watch\",\n    \"build\": \"webpack --mode production\",\n    \"lint\": \"eslint assets/js/**/*.js\",\n    \"test\": \"jest\"\n  },\n  \"dependencies\": {\n    \"axios\": \"^1.4.0\",\n    \"bootstrap\": \"^5.3.0\",\n    \"jquery\": \"^3.6.0\"\n  },\n  \"devDependencies\": {\n    \"@babel/core\": \"^7.22.0\",\n    \"@babel/preset-env\": \"^7.22.0\",\n    \"@symfony/webpack-encore\": \"^4.4.0\",\n    \"webpack\": \"^5.88.0\",\n    \"webpack-cli\": \"^5.1.0\",\n    \"sass\": \"^1.64.0\",\n    \"sass-loader\": \"^13.3.0\",\n    \"webpack-dev-server\": \"^4.15.0\"\n  }\n}\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap12/#webpack-encore-et-la-compilation-des-assets","title":"Webpack Encore et la compilation des assets","text":"<p>Webpack Encore simplifie la configuration de Webpack en proposant une API fluide adapt\u00e9e \u00e0 Symfony[1]. La compilation des assets CSS et JavaScript s'effectue automatiquement en d\u00e9veloppement et de mani\u00e8re optimis\u00e9e en production.</p> JavaScript<pre><code>const Encore = require('@symfony/webpack-encore');\nconst path = require('path');\n\nif (!Encore.isRuntimeEnvironmentConfigured()) {\n  Encore\n    .setOutputPath('public/build/')\n    .setPublicPath('/build');\n}\n\nEncore\n  .addEntry('app', './assets/app.js')\n  .addStyleEntry('app', './assets/styles/app.scss')\n  .splitEntryChunks()\n  .enableSingleRuntimeChunk()\n  .cleanupOutputBeforeBuild()\n  .enableBuildNotifications()\n  .enableSourceMaps(!Encore.isProduction())\n  .enableVersioning(Encore.isProduction())\n  .configureBabel(config =&gt; {\n    config.plugins.push('@babel/plugin-proposal-class-properties');\n  })\n  .configureDefinePlugin(options =&gt; {\n    options.__DEV__ = JSON.stringify(!Encore.isProduction());\n  });\n\nmodule.exports = Encore.getWebpackConfig();\n</code></pre> <p>Le service Node.js du docker-compose observe les modifications et recompile automatiquement :</p> YAML<pre><code>node:\n  build:\n    context: .\n    dockerfile: node.dockerfile\n  volumes:\n    - ./src:/var/www/html\n  command: npm run watch\n  networks:\n    - symfony\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap12/#mise-en-place-du-service-nginx","title":"Mise en place du service NGINX","text":""},{"location":"_projects/_formation-docker/docker-chap12/#configuration-fondamentale-de-nginx","title":"Configuration fondamentale de NGINX","text":"<p>NGINX remplace avantageusement Apache dans les environnements dockeris\u00e9s en raison de son architecture l\u00e9g\u00e8re et haute-performance. Le serveur web re\u00e7oit les requ\u00eates HTTP et les transmet \u00e0 PHP-FPM via FastCGI[2].</p> Docker<pre><code>FROM nginx:1.25-alpine\n\nCOPY ./docker/nginx/default.conf /etc/nginx/conf.d/default.conf\n\nEXPOSE 80\nEXPOSE 443\n\nCMD [\"nginx\", \"-g\", \"daemon off;\"]\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap12/#configuration-du-virtual-host-nginx","title":"Configuration du virtual host NGINX","text":"<p>Le fichier de configuration NGINX configure le routage des requ\u00eates vers PHP-FPM et la livraison des fichiers statiques :</p> Nginx Configuration File<pre><code>upstream php {\n    server php:9000;\n}\n\nserver {\n    listen 80;\n    server_name localhost;\n\n    root /var/www/html/public;\n\n    client_max_body_size 20M;\n\n    # Logs\n    access_log /var/log/nginx/access.log;\n    error_log /var/log/nginx/error.log;\n\n    # Fichiers statiques\n    location ~* \\.(js|css|png|jpg|jpeg|gif|ico|svg|woff|woff2|ttf|eot)$ {\n        expires 30d;\n        add_header Cache-Control \"public, immutable\";\n        access_log off;\n    }\n\n    # Assets compil\u00e9s par Webpack Encore\n    location /build/ {\n        expires 30d;\n        add_header Cache-Control \"public, immutable\";\n    }\n\n    # Fichier robots.txt\n    location = /robots.txt {\n        access_log off;\n    }\n\n    # Fichier favicon\n    location = /favicon.ico {\n        access_log off;\n        log_not_found off;\n    }\n\n    # Rewrite toutes les requ\u00eates vers index.php\n    location / {\n        try_files $uri $uri/ /index.php$is_args$args;\n    }\n\n    # Traitement des fichiers PHP\n    location ~ ^/index\\.php(/|$) {\n        fastcgi_pass php;\n        fastcgi_split_path_info ^(.+\\.php)(/.*)$;\n\n        include fastcgi_params;\n        fastcgi_param SCRIPT_FILENAME $realpath_root$fastcgi_script_name;\n        fastcgi_param DOCUMENT_ROOT $realpath_root;\n        fastcgi_param HTTP_X_FORWARDED_FOR $proxy_add_x_forwarded_for;\n        fastcgi_param HTTP_X_FORWARDED_PROTO $scheme;\n\n        fastcgi_buffer_size 128k;\n        fastcgi_buffers 4 256k;\n        fastcgi_busy_buffers_size 256k;\n\n        internal;\n    }\n\n    # Refus des acc\u00e8s aux fichiers non publics\n    location ~ \\.php$ {\n        return 404;\n    }\n\n    # S\u00e9curit\u00e9 : refus des fichiers cache\n    location ~ /\\. {\n        deny all;\n        access_log off;\n        log_not_found off;\n    }\n}\n</code></pre> <p>Cette configuration achemine intelligemment le trafic : les assets statiques sont servies directement par NGINX avec mise en cache, tandis que les requ\u00eates dynamiques sont transmises \u00e0 PHP-FPM.</p>"},{"location":"_projects/_formation-docker/docker-chap12/#integration-dans-docker-composeyml_1","title":"Int\u00e9gration dans docker-compose.yml","text":"<p>Le service NGINX s'int\u00e8gre dans la composition Docker avec d\u00e9pendance du service PHP :</p> YAML<pre><code>nginx:\n  image: nginx:1.25-alpine\n  container_name: symfony-nginx\n  build:\n    context: .\n    dockerfile: docker/nginx/Dockerfile\n  ports:\n    - \"${NGINX_PORT:-80}:80\"\n    - \"${NGINX_SSL_PORT:-443}:443\"\n  volumes:\n    - ./src:/var/www/html:ro\n    - ./docker/nginx/default.conf:/etc/nginx/conf.d/default.conf:ro\n    - ./docker/nginx/ssl:/etc/nginx/ssl:ro\n  depends_on:\n    - php\n  restart: unless-stopped\n  networks:\n    - symfony\n  healthcheck:\n    test: [\"CMD\", \"wget\", \"--quiet\", \"--tries=1\", \"--spider\", \"http://localhost/\"]\n    timeout: 5s\n    retries: 5\n    interval: 10s\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap12/#https-et-certificats-ssl","title":"HTTPS et certificats SSL","text":"<p>La configuration HTTPS pour la production requiert des certificats SSL valides :</p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name example.com www.example.com;\n    return 301 https://$server_name$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    server_name example.com www.example.com;\n\n    ssl_certificate /etc/nginx/ssl/cert.pem;\n    ssl_certificate_key /etc/nginx/ssl/key.pem;\n\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_ciphers HIGH:!aNULL:!MD5;\n    ssl_prefer_server_ciphers on;\n\n    ssl_session_cache shared:SSL:10m;\n    ssl_session_timeout 10m;\n\n    # Configuration identique au server 80\n    root /var/www/html/public;\n\n    # ... reste de la configuration ...\n}\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap12/#orchestration-complete-avec-docker-composeyml","title":"Orchestration compl\u00e8te avec docker-compose.yml","text":""},{"location":"_projects/_formation-docker/docker-chap12/#structure-complete-dune-application-symfony","title":"Structure compl\u00e8te d'une application Symfony","text":"<p>L'orchestration de tous les services s'effectue via un fichier <code>docker-compose.yml</code> centralis\u00e9 qui d\u00e9finit les interd\u00e9pendances et les configurations communes :</p> YAML<pre><code>version: '3.8'\n\nservices:\n  mysql:\n    image: mysql:8.0\n    container_name: symfony-mysql\n    environment:\n      MYSQL_ROOT_PASSWORD: ${MYSQL_ROOT_PASSWORD:-root}\n      MYSQL_DATABASE: ${MYSQL_DATABASE:-symfony_db}\n      MYSQL_USER: ${MYSQL_USER:-symfony}\n      MYSQL_PASSWORD: ${MYSQL_PASSWORD:-symfony}\n    ports:\n      - \"${MYSQL_PORT:-3306}:3306\"\n    volumes:\n      - mysql_data:/var/lib/mysql\n      - ./docker/mysql/init.sql:/docker-entrypoint-initdb.d/init.sql\n    restart: unless-stopped\n    networks:\n      - symfony\n    healthcheck:\n      test: [\"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\"]\n      timeout: 5s\n      retries: 5\n      interval: 10s\n\n  php:\n    build:\n      context: .\n      dockerfile: docker/php/Dockerfile\n    container_name: symfony-php\n    environment:\n      APP_ENV: ${APP_ENV:-dev}\n      APP_DEBUG: ${APP_DEBUG:-1}\n      DATABASE_URL: mysql://${MYSQL_USER}:${MYSQL_PASSWORD}@mysql:3306/${MYSQL_DATABASE}\n    volumes:\n      - ./src:/var/www/html\n      - ./docker/php/conf.d:/usr/local/etc/php/conf.d:ro\n    depends_on:\n      mysql:\n        condition: service_healthy\n    restart: unless-stopped\n    networks:\n      - symfony\n    user: \"1000:1000\"\n\n  nginx:\n    build:\n      context: .\n      dockerfile: docker/nginx/Dockerfile\n    container_name: symfony-nginx\n    ports:\n      - \"${NGINX_PORT:-80}:80\"\n    volumes:\n      - ./src:/var/www/html:ro\n      - ./docker/nginx/default.conf:/etc/nginx/conf.d/default.conf:ro\n    depends_on:\n      - php\n    restart: unless-stopped\n    networks:\n      - symfony\n    healthcheck:\n      test: [\"CMD\", \"wget\", \"--quiet\", \"--tries=1\", \"--spider\", \"http://localhost/\"]\n      timeout: 5s\n      retries: 5\n\n  composer:\n    build:\n      context: .\n      dockerfile: docker/composer/Dockerfile\n    container_name: symfony-composer\n    volumes:\n      - ./src:/var/www/html\n    working_dir: /var/www/html\n    networks:\n      - symfony\n    user: \"${UID:-1000}:${GID:-1000}\"\n    profiles:\n      - tools\n\n  node:\n    build:\n      context: .\n      dockerfile: docker/node/Dockerfile\n    container_name: symfony-node\n    volumes:\n      - ./src:/var/www/html\n    working_dir: /var/www/html\n    command: npm run watch\n    networks:\n      - symfony\n    profiles:\n      - tools\n\nvolumes:\n  mysql_data:\n    driver: local\n\nnetworks:\n  symfony:\n    driver: bridge\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap12/#fichier-env-pour-la-configuration-locale","title":"Fichier .env pour la configuration locale","text":"<p>Le fichier <code>.env</code> sp\u00e9cifie les valeurs par d\u00e9faut pour l'environnement de d\u00e9veloppement :</p> Text Only<pre><code># Application\nAPP_ENV=dev\nAPP_DEBUG=1\nSYMFONY_ENV=dev\n\n# Database\nMYSQL_ROOT_PASSWORD=root\nMYSQL_DATABASE=symfony_db\nMYSQL_USER=symfony\nMYSQL_PASSWORD=symfony\nMYSQL_PORT=3306\n\n# Nginx\nNGINX_PORT=80\n\n# Identifiants\nUID=1000\nGID=1000\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap12/#demarrage-et-gestion-de-lenvironnement","title":"D\u00e9marrage et gestion de l'environnement","text":""},{"location":"_projects/_formation-docker/docker-chap12/#commandes-essentielles","title":"Commandes essentielles","text":"<p>Le lancement initial de tous les conteneurs n\u00e9cessite la construction des images puis le d\u00e9marrage orchestr\u00e9 :</p> Bash<pre><code># Construction des images et d\u00e9marrage\ndocker compose up --build\n\n# D\u00e9marrage en arri\u00e8re-plan\ndocker compose up -d\n\n# Affichage des logs\ndocker compose logs -f\n\n# Logs d'un service sp\u00e9cifique\ndocker compose logs -f php\n\n# Ex\u00e9cution de commandes dans un conteneur\ndocker compose exec php bin/console cache:clear\ndocker compose exec php bin/console doctrine:database:create\ndocker compose exec php bin/console doctrine:migrations:migrate\n\n# Arr\u00eat des conteneurs\ndocker compose down\n\n# Arr\u00eat et suppression des volumes\ndocker compose down -v\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap12/#initialisation-dune-nouvelle-application-symfony","title":"Initialisation d'une nouvelle application Symfony","text":"<p>La cr\u00e9ation d'une application Symfony vierge s'effectue via Docker :</p> Bash<pre><code>mkdir symfony-app &amp;&amp; cd symfony-app\n\n# Initialisation des r\u00e9pertoires\nmkdir src docker/php docker/nginx docker/node docker/composer\n\n# Cr\u00e9ation des Dockerfiles (comme indiqu\u00e9 pr\u00e9c\u00e9demment)\n\n# Cr\u00e9ation du docker-compose.yml\n\n# Cr\u00e9ation de l'application Symfony\ndocker compose run --rm --user $(id -u):$(id -g) composer create-project symfony/skeleton:\"6.3.*\" ./\n\n# Installation des d\u00e9pendances suppl\u00e9mentaires\ndocker compose exec composer require symfony/orm-pack\ndocker compose exec composer require symfony/asset\ndocker compose exec composer require symfony/console\n\n# Initialisation npm\ndocker compose exec node npm init -y\n\n# D\u00e9marrage des services\ndocker compose up -d\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap12/#workflow-de-developpement","title":"Workflow de d\u00e9veloppement","text":"<p>Le cycle de d\u00e9veloppement avec Docker fonctionne de mani\u00e8re it\u00e9rative :</p> <ol> <li>Modification du code source dans le r\u00e9pertoire local</li> <li>Les volumes synchronisent automatiquement les modifications dans les conteneurs</li> <li>Symfony rechargement automatique d\u00e9tecte les modifications et met \u00e0 jour le cache</li> <li>Webpack Encore recompile les assets automatiquement en mode watch</li> <li>Les requ\u00eates HTTP sont servies imm\u00e9diatement par NGINX et PHP-FPM</li> </ol>"},{"location":"_projects/_formation-docker/docker-chap12/#commandes-utiles-pour-le-developpement","title":"Commandes utiles pour le d\u00e9veloppement","text":"Bash<pre><code># Acc\u00e8s au shell PHP pour ex\u00e9cuter des commandes Symfony\ndocker compose exec php bash\n\n# Ex\u00e9cution de tests unitaires\ndocker compose exec php vendor/bin/phpunit\n\n# Analyse du code avec PHP_CodeSniffer\ndocker compose exec php vendor/bin/phpcs src/\n\n# Formatage du code automatique\ndocker compose exec php vendor/bin/phpcbf src/\n\n# Inspection de la base de donn\u00e9es\ndocker compose exec mysql mysql -u symfony -p symfony_db\n\n# G\u00e9n\u00e9ration de migrations\ndocker compose exec php bin/console doctrine:migrations:diff\n\n# Consultation des variables d'environnement\ndocker compose exec php printenv\n\n# Inspection des volumes\ndocker volume ls\ndocker volume inspect symfony_mysql_data\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap12/#considerations-avancees","title":"Consid\u00e9rations avanc\u00e9es","text":""},{"location":"_projects/_formation-docker/docker-chap12/#optimisation-des-performances","title":"Optimisation des performances","text":"<p>L'utilisation de <code>.dockerignore</code> r\u00e9duit le contexte de build et acc\u00e9l\u00e8re la construction des images :</p> Text Only<pre><code>.git\n.gitignore\n.docker\nvendor\nnode_modules\n.env.local\n.symfony.local\npublic/uploads\nvar/cache\nvar/log\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap12/#debugging-avec-xdebug","title":"Debugging avec Xdebug","text":"<p>L'int\u00e9gration de Xdebug dans l'environnement de d\u00e9veloppement facilite le d\u00e9bogage :</p> Docker<pre><code>RUN pecl install xdebug &amp;&amp; docker-php-ext-enable xdebug\n\nCOPY docker/php/xdebug.ini /usr/local/etc/php/conf.d/xdebug.ini\n</code></pre> INI<pre><code>; xdebug.ini\nxdebug.mode=develop,debug\nxdebug.client_host=host.docker.internal\nxdebug.client_port=9003\nxdebug.start_with_request=yes\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap12/#monitoring-et-logs","title":"Monitoring et logs","text":"<p>La centralisation des logs offre une visibilit\u00e9 sur l'ensemble de l'infrastructure :</p> YAML<pre><code>services:\n  php:\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n</code></pre>"},{"location":"_projects/_formation-docker/docker-chap12/#strategies-de-backup-et-restauration","title":"Strat\u00e9gies de backup et restauration","text":"<p>La persistance des donn\u00e9es requiert une strat\u00e9gie de backup r\u00e9guli\u00e8re :</p> Bash<pre><code># Backup de la base de donn\u00e9es\ndocker compose exec mysql mysqldump -u root -p symfony_db &gt; backup.sql\n\n# Restauration de la base de donn\u00e9es\ndocker compose exec -T mysql mysql -u root -p symfony_db &lt; backup.sql\n\n# Backup des volumes\ndocker run --rm -v symfony_mysql_data:/data -v $(pwd):/backup alpine tar czf /backup/mysql_backup.tar.gz -C /data .\n</code></pre> <p>Cette architecture compl\u00e8te fournit une base robuste et scalable pour d\u00e9velopper, tester et d\u00e9ployer des applications Symfony avec Docker, tout en maintenant la coh\u00e9rence entre les environnements de d\u00e9veloppement et de production.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-git/git-chap01/","title":"Citations","text":"<ul> <li>https://outils101.telecom-paris.fr/git_git/</li> <li>https://about.gitlab.com/fr-fr/topics/version-control/what-is-git-version-control/</li> <li>https://datascientest.com/git-tutoriel-sur-le-systeme-de-controle-de-versions-du-developpeur</li> <li>https://blog.stephane-robert.info/docs/developper/version/git/</li> <li>https://learn.microsoft.com/fr-fr/devops/develop/git/what-is-git</li> <li>https://git-scm.com/book/fr/v2/D%C3%A9marrage-rapide-%C3%80-propos-de-la-gestion-de-version</li> <li>https://www.atlassian.com/fr/git/tutorials/what-is-version-control</li> <li>https://markdown.data-ensta.fr/s/introduction-versioning-git</li> <li>https://openclassrooms.com/fr/courses/7162856-gerez-du-code-avec-git-et-github/7165703-decouvrez-la-magie-du-controle-de-versions</li> <li>https://www.datacamp.com/fr/courses/introduction-to-git</li> </ul>"},{"location":"_projects/_formation-git/git-chap01/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 270</li> <li>completion_tokens: 5148</li> <li>total_tokens: 5418</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.077, 'request_cost': 0.006, 'total_cost': 0.084}</li> </ul>"},{"location":"_projects/_formation-git/git-chap01/#content","title":"Content","text":""},{"location":"_projects/_formation-git/git-chap01/#guide-complet-introduction-a-git","title":"\ud83d\udcda Guide Complet : Introduction \u00e0 Git","text":""},{"location":"_projects/_formation-git/git-chap01/#presentation-de-git","title":"Pr\u00e9sentation de Git \ud83c\udfaf","text":"<p>Git est un syst\u00e8me de contr\u00f4le de version distribu\u00e9 open source[2][4] cr\u00e9\u00e9 en 2005 par Linus Torvalds, le d\u00e9veloppeur du noyau Linux. Cet outil est devenu la norme mondiale pour le contr\u00f4le de version et s'est impos\u00e9 comme incontournable dans l'\u00e9cosyst\u00e8me du d\u00e9veloppement logiciel[4].</p>"},{"location":"_projects/_formation-git/git-chap01/#quest-ce-qui-rend-git-unique","title":"Qu'est-ce qui rend Git unique ?","text":"<p>Git se distingue par sa nature distribu\u00e9e[2][5], ce qui signifie que chaque d\u00e9veloppeur dispose d'une copie locale compl\u00e8te du projet, incluant l'historique entier des modifications[5]. Contrairement aux syst\u00e8mes centralis\u00e9s o\u00f9 tous les utilisateurs se connectent \u00e0 un r\u00e9pertoire central unique[3], Git permet une flexibilit\u00e9 de travail consid\u00e9rablement augment\u00e9e.</p>"},{"location":"_projects/_formation-git/git-chap01/#les-caracteristiques-principales-de-git","title":"Les caract\u00e9ristiques principales de Git","text":"<p>Rapidit\u00e9 et efficacit\u00e9[2] : Git dispose d'un d\u00e9p\u00f4t local sur la machine de chaque d\u00e9veloppeur contenant l'historique complet du projet. Cette architecture \u00e9limine les d\u00e9lais de communication avec un serveur central, permettant \u00e0 Git d'effectuer imm\u00e9diatement des calculs de diff\u00e9rence locale[2].</p> <p>Nature open source[4] : Disponible sur pratiquement tous les syst\u00e8mes d'exploitation, Git offre une solution accessible \u00e0 tous avec une communaut\u00e9 active de contributeurs.</p> <p>Flexibilit\u00e9 des workflows[2] : Les \u00e9quipes peuvent impl\u00e9menter diverses strat\u00e9gies de gestion de branche adapt\u00e9es \u00e0 la taille du projet, \u00e0 la composition de l'\u00e9quipe ou aux processus sp\u00e9cifiques, incluant la centralisation, la gestion par fonctionnalit\u00e9s, le d\u00e9veloppement bas\u00e9 sur le tronc ou GitFlow[2].</p> <p>Collaboration am\u00e9lior\u00e9e[2] : Le mod\u00e8le de gestion de branches facilite le d\u00e9veloppement collaboratif, permettant aux membres d'\u00e9quipe de cr\u00e9er des branches, d'exp\u00e9rimenter et de fusionner le code dans la branche principale[2].</p>"},{"location":"_projects/_formation-git/git-chap01/#quest-ce-quun-systeme-de-controle-de-version","title":"Qu'est-ce qu'un syst\u00e8me de contr\u00f4le de version ? \ud83d\udd04","text":""},{"location":"_projects/_formation-git/git-chap01/#definition-et-objectifs","title":"D\u00e9finition et objectifs","text":"<p>Un syst\u00e8me de contr\u00f4le de version (Version Control System - VCS) est un logiciel permettant de suivre l'\u00e9volution d'un fichier ou d'un ensemble de fichiers au cours du temps[6]. Les objectifs premiers d'un tel syst\u00e8me sont multiples[1] :</p> <ul> <li>Suivre les modifications apport\u00e9es \u00e0 un ou des fichiers</li> <li>Enregistrer les modifications des donn\u00e9es</li> <li>Horodater les modifications pour conna\u00eetre quand chaque changement a \u00e9t\u00e9 effectu\u00e9</li> <li>Documenter les informations d'auteur pour identifier qui a effectu\u00e9 les modifications</li> <li>Capturer les raisons des modifications via des messages de commit explicites</li> <li>Permettre de revenir en arri\u00e8re en cas de probl\u00e8me ou d'erreur</li> <li>Permettre un travail temporaire sur des versions alternatives via les branches</li> </ul>"},{"location":"_projects/_formation-git/git-chap01/#avantages-concrets-du-controle-de-version","title":"Avantages concrets du contr\u00f4le de version","text":"<p>La mise en place d'un syst\u00e8me de contr\u00f4le de version apporte des b\u00e9n\u00e9fices tangibles[2] :</p> <p>Am\u00e9lioration de la productivit\u00e9 des \u00e9quipes : Les \u00e9quipes logicielles peuvent cr\u00e9er des versions exp\u00e9rimentales sans craindre d'endommager le code source de fa\u00e7on permanente[2]. Gr\u00e2ce au contr\u00f4le de version, il est possible de suivre et de fusionner les branches, d'auditer les modifications et d'activer le travail simultan\u00e9[2].</p> <p>Tra\u00e7abilit\u00e9 et d\u00e9bogage : En cas de bug d\u00e9tect\u00e9 plusieurs versions apr\u00e8s sa cr\u00e9ation, il est possible de tester les versions par dichotomie pour identifier rapidement le commit probl\u00e9matique[1]. Sur un projet d'\u00e9quipe, le commit contient l'information de l'auteur, permettant d'aller demander des explications directement au responsable[1].</p> <p>R\u00e9cup\u00e9ration apr\u00e8s sinistre : Un exemple classique concerne les \u00e9tudiants qui travaillent pendant trois mois sans sauvegarde et perdent tout sur crash disque la veille du rendu[1]. Avec un contr\u00f4le de version, ces donn\u00e9es sont sauvegard\u00e9es et r\u00e9cup\u00e9rables.</p> <p>Investigation de regressions : Quand un changement de comportement est signal\u00e9 entre deux versions anciennes (par exemple v2 et v3) alors qu'on en est \u00e0 la v7 et que l'\u00e9quipe a enti\u00e8rement chang\u00e9, le contr\u00f4le de version permet de reconstruire ces versions, de comparer les journaux et d'isoler le fichier fautif en utilisant les commentaires de chaque version[1].</p>"},{"location":"_projects/_formation-git/git-chap01/#les-deux-modeles-principaux","title":"Les deux mod\u00e8les principaux","text":"<p>Mod\u00e8le centralis\u00e9[3] : Tous les utilisateurs se connectent \u00e0 un r\u00e9pertoire (repository) central unique. Chaque op\u00e9ration n\u00e9cessite une communication avec le serveur central.</p> <p>Mod\u00e8le distribu\u00e9 (Git)[3][5] : Chaque d\u00e9veloppeur poss\u00e8de une copie locale compl\u00e8te du d\u00e9p\u00f4t entier, incluant l'historique complet[4]. Cette approche facilite le travail en mode hors connexion ou \u00e0 distance[5]. Les d\u00e9veloppeurs valident leur travail localement, puis synchronisent leur copie avec le serveur[5].</p>"},{"location":"_projects/_formation-git/git-chap01/#les-concepts-cles-de-git","title":"Les concepts cl\u00e9s de Git \ud83d\udd11","text":""},{"location":"_projects/_formation-git/git-chap01/#le-depot-git","title":"Le d\u00e9p\u00f4t Git","text":"<p>Un d\u00e9p\u00f4t Git est l'ensemble des donn\u00e9es du syst\u00e8me de contr\u00f4le de version[1]. Il comprend au minimum toutes les versions de tous les fichiers (ou les moyens de les reconstituer), ainsi que toutes les informations d'auteur, de temps, de d\u00e9pendance et de branches[1].</p> <p>Sur le syst\u00e8me de fichiers, un d\u00e9p\u00f4t Git se reconna\u00eet par la pr\u00e9sence d'un r\u00e9pertoire <code>.git</code> dans le r\u00e9pertoire racine du d\u00e9p\u00f4t. Ce r\u00e9pertoire contient tout l'historique des modifications sur tous les fichiers[1].</p>"},{"location":"_projects/_formation-git/git-chap01/#les-trois-etats-des-fichiers","title":"Les trois \u00e9tats des fichiers","text":"<p>Dans Git, les fichiers peuvent se trouver dans l'un des trois \u00e9tats suivants[2] :</p> <p>\u00c9tat modifi\u00e9 : Un fichier a \u00e9t\u00e9 modifi\u00e9 mais n'a pas encore \u00e9t\u00e9 valid\u00e9 dans la base de donn\u00e9es. Les changements existent uniquement sur le syst\u00e8me de fichiers local.</p> <p>\u00c9tat index\u00e9 : Un fichier est configur\u00e9 pour \u00eatre inclus dans la prochaine validation (commit). Cette \u00e9tape pr\u00e9pare les fichiers \u00e0 \u00eatre sauvegard\u00e9s d\u00e9finitivement.</p> <p>\u00c9tat valid\u00e9 : Les donn\u00e9es ont \u00e9t\u00e9 stock\u00e9es dans la base de donn\u00e9es Git. Cette validation rend les changements permanents dans l'historique du projet.</p>"},{"location":"_projects/_formation-git/git-chap01/#larchitecture-distribuee","title":"L'architecture distribu\u00e9e","text":"<p>Chaque d\u00e9veloppeur poss\u00e8de une copie compl\u00e8te de l'historique du projet[4], permettant un travail local ind\u00e9pendant. Cette architecture offre plusieurs avantages[5] :</p> <ul> <li>Les repositorys locaux sont enti\u00e8rement op\u00e9rationnels, facilitant le travail hors connexion</li> <li>Les d\u00e9veloppeurs peuvent valider leur travail localement avant de synchroniser avec le serveur</li> <li>Ce paradigme diff\u00e8re radicalement de la gestion de version centralis\u00e9e o\u00f9 la synchronisation serveur est pr\u00e9alable \u00e0 toute nouvelle version</li> </ul>"},{"location":"_projects/_formation-git/git-chap01/#configuration-initiale-de-git","title":"Configuration initiale de Git \u2699\ufe0f","text":""},{"location":"_projects/_formation-git/git-chap01/#installation-de-git","title":"Installation de Git","text":"<p>Git est disponible sur pratiquement tous les syst\u00e8mes d'exploitation[4]. L'installation varie selon la plateforme :</p> <p>Sur Linux (Debian/Ubuntu) : Bash<pre><code>sudo apt-get update\nsudo apt-get install git\n</code></pre></p> <p>Sur Linux (RedHat/CentOS) : Bash<pre><code>sudo yum install git\n</code></pre></p> <p>Sur macOS : Bash<pre><code>brew install git\n</code></pre></p> <p>Sur Windows : T\u00e9l\u00e9charger l'installateur depuis git-scm.com et ex\u00e9cuter l'installation graphique.</p>"},{"location":"_projects/_formation-git/git-chap01/#verifier-linstallation","title":"V\u00e9rifier l'installation","text":"<p>Apr\u00e8s installation, v\u00e9rifier que Git fonctionne correctement :</p> Bash<pre><code>git --version\n</code></pre> <p>Cette commande affiche la version install\u00e9e, confirmant une installation r\u00e9ussie.</p>"},{"location":"_projects/_formation-git/git-chap01/#configuration-globale","title":"Configuration globale","text":"<p>Git n\u00e9cessite une configuration minimale avant utilisation. Les deux informations essentielles sont le nom d'utilisateur et l'adresse email, qui seront associ\u00e9s \u00e0 tous les commits effectu\u00e9s.</p> <p>Configurer le nom d'utilisateur : Bash<pre><code>git config --global user.name \"Pr\u00e9nom Nom\"\n</code></pre></p> <p>Configurer l'adresse email : Bash<pre><code>git config --global user.email \"email@example.com\"\n</code></pre></p> <p>L'option <code>--global</code> applique ces param\u00e8tres \u00e0 tous les projets Git de l'utilisateur. Pour configurer uniquement un projet sp\u00e9cifique, omettre l'option <code>--global</code>.</p>"},{"location":"_projects/_formation-git/git-chap01/#verifier-la-configuration","title":"V\u00e9rifier la configuration","text":"<p>Consulter la configuration \u00e9tablie :</p> Bash<pre><code>git config --global --list\n</code></pre> <p>Cette commande affiche tous les param\u00e8tres de configuration globale. Pour un projet sp\u00e9cifique, ex\u00e9cuter sans l'option <code>--global</code>.</p>"},{"location":"_projects/_formation-git/git-chap01/#configuration-avancee-optionnelle","title":"Configuration avanc\u00e9e (optionnelle)","text":"<p>D'autres configurations peuvent am\u00e9liorer l'exp\u00e9rience utilisateur :</p> <p>Configurer l'\u00e9diteur par d\u00e9faut : Bash<pre><code>git config --global core.editor \"nano\"\n</code></pre></p> <p>Configurer l'outil de fusion (merge tool) : Bash<pre><code>git config --global merge.tool \"meld\"\n</code></pre></p> <p>Afficher les couleurs dans la sortie : Bash<pre><code>git config --global color.ui true\n</code></pre></p> <p>Configurer les alias (raccourcis personnalis\u00e9s) : Bash<pre><code>git config --global alias.st status\ngit config --global alias.co checkout\ngit config --global alias.br branch\n</code></pre></p> <p>Ces alias permettent d'utiliser <code>git st</code> au lieu de <code>git status</code>, par exemple, acc\u00e9l\u00e9rant le workflow quotidien.</p>"},{"location":"_projects/_formation-git/git-chap01/#a-labordage-premier-projet-git","title":"\u00c0 l'abordage ! \ud83d\ude80 : Premier projet Git","text":""},{"location":"_projects/_formation-git/git-chap01/#initialiser-un-nouveau-depot","title":"Initialiser un nouveau d\u00e9p\u00f4t","text":"<p>Pour d\u00e9marrer un projet Git, acc\u00e9der au r\u00e9pertoire du projet et initialiser un d\u00e9p\u00f4t :</p> Bash<pre><code>cd mon_projet\ngit init\n</code></pre> <p>Cette commande cr\u00e9e un r\u00e9pertoire <code>.git</code> cach\u00e9 contenant toute la structure n\u00e9cessaire au suivi des versions.</p>"},{"location":"_projects/_formation-git/git-chap01/#cloner-un-depot-existant","title":"Cloner un d\u00e9p\u00f4t existant","text":"<p>Pour travailler sur un projet existant, cloner le d\u00e9p\u00f4t distant :</p> <p>Acc\u00e8s en lecture seule (HTTPS) : Bash<pre><code>git clone https://gitlab.telecom-paris.fr/proj103/admin/ue_outils.git\n</code></pre></p> <p>Acc\u00e8s en lecture/\u00e9criture (SSH) : Bash<pre><code>git clone git@gitlab.enst.fr:proj103/admin/ue_outils.git\n</code></pre></p> <p>La deuxi\u00e8me option n\u00e9cessite la configuration pr\u00e9alable d'une cl\u00e9 SSH pour l'authentification.</p>"},{"location":"_projects/_formation-git/git-chap01/#verifier-letat-du-depot","title":"V\u00e9rifier l'\u00e9tat du d\u00e9p\u00f4t","text":"<p>Avant de commencer \u00e0 travailler, consulter l'\u00e9tat actuel :</p> Bash<pre><code>git status\n</code></pre> <p>Cette commande affiche les fichiers modifi\u00e9s, supprim\u00e9s ou nouveaux, ainsi que l'\u00e9tat du staging area.</p>"},{"location":"_projects/_formation-git/git-chap01/#ajouter-des-fichiers-au-staging-area","title":"Ajouter des fichiers au staging area","text":"<p>Pr\u00e9parer les fichiers pour le commit :</p> <p>Ajouter un fichier sp\u00e9cifique : Bash<pre><code>git add nom_du_fichier.txt\n</code></pre></p> <p>Ajouter tous les fichiers modifi\u00e9s : Bash<pre><code>git add .\n</code></pre></p> <p>Ajouter tous les fichiers d'un r\u00e9pertoire : Bash<pre><code>git add chemin/du/repertoire/\n</code></pre></p>"},{"location":"_projects/_formation-git/git-chap01/#effectuer-un-commit","title":"Effectuer un commit","text":"<p>Valider les changements avec un message descriptif :</p> Bash<pre><code>git commit -m \"Description claire des modifications\"\n</code></pre> <p>Les messages de commit doivent \u00eatre explicites et informatifs. Un bon message commence par un verbe au pr\u00e9sent : \"Ajouter\", \"Corriger\", \"Mettre \u00e0 jour\", etc.</p> <p>Exemple d'un bon commit : Bash<pre><code>git commit -m \"Ajouter la fonction d'authentification utilisateur\"\n</code></pre></p>"},{"location":"_projects/_formation-git/git-chap01/#consulter-lhistorique","title":"Consulter l'historique","text":"<p>Visualiser tous les commits effectu\u00e9s :</p> Bash<pre><code>git log\n</code></pre> <p>Cela affiche la liste des commits avec leur identifiant unique (SHA), l'auteur, la date et le message.</p> <p>Pour un affichage plus compact : Bash<pre><code>git log --oneline\n</code></pre></p>"},{"location":"_projects/_formation-git/git-chap01/#presentation-de-bash-et-commandes-linux","title":"Pr\u00e9sentation de Bash et commandes Linux \ud83d\udc27","text":""},{"location":"_projects/_formation-git/git-chap01/#quest-ce-que-bash","title":"Qu'est-ce que Bash ?","text":"<p>Bash (Bourne Again Shell) est un interpr\u00e9teur de commandes Unix/Linux, c'est-\u00e0-dire un programme qui ex\u00e9cute les commandes tap\u00e9es par l'utilisateur. C'est l'interface de ligne de commande (Command Line Interface - CLI) la plus couramment utilis\u00e9e sur les syst\u00e8mes Unix et Linux.</p>"},{"location":"_projects/_formation-git/git-chap01/#utilite-pour-git","title":"Utilit\u00e9 pour Git","text":"<p>Git fonctionne principalement via une interface de ligne de commande. Ma\u00eetriser Bash permet une utilisation efficace et productive de Git. M\u00eame sur Windows avec l'interface graphique, comprendre les commandes Bash am\u00e9liore significativement l'exp\u00e9rience utilisateur.</p>"},{"location":"_projects/_formation-git/git-chap01/#commandes-linux-essentielles","title":"Commandes Linux essentielles","text":"<p>Navigation dans le syst\u00e8me de fichiers</p> <p>Bash<pre><code>pwd\n</code></pre> Affiche le r\u00e9pertoire courant (Present Working Directory).</p> <p>Bash<pre><code>ls\n</code></pre> Liste les fichiers et r\u00e9pertoires du r\u00e9pertoire courant.</p> <p>Options utiles : - <code>ls -l</code> : affichage d\u00e9taill\u00e9 avec permissions et dates - <code>ls -a</code> : affiche les fichiers cach\u00e9s (commen\u00e7ant par un point) - <code>ls -la</code> : combinaison des deux options pr\u00e9c\u00e9dentes</p> <p>Bash<pre><code>cd repertoire\n</code></pre> Change de r\u00e9pertoire (Change Directory).</p> <p>Bash<pre><code>cd ..\n</code></pre> Remonte d'un niveau dans l'arborescence.</p> <p>Bash<pre><code>cd ~\n</code></pre> Retourne au r\u00e9pertoire utilisateur (home directory).</p> <p>Gestion des fichiers et r\u00e9pertoires</p> <p>Bash<pre><code>mkdir nom_repertoire\n</code></pre> Cr\u00e9e un nouveau r\u00e9pertoire (Make Directory).</p> <p>Bash<pre><code>touch nom_fichier.txt\n</code></pre> Cr\u00e9e un fichier vide ou met \u00e0 jour la date d'acc\u00e8s si le fichier existe.</p> <p>Bash<pre><code>cp source destination\n</code></pre> Copie un fichier (Copy).</p> <p>Bash<pre><code>cp -r repertoire_source repertoire_destination\n</code></pre> Copie un r\u00e9pertoire entier et son contenu r\u00e9cursivement.</p> <p>Bash<pre><code>mv ancienne_position nouvelle_position\n</code></pre> D\u00e9place ou renomme un fichier (Move).</p> <p>Bash<pre><code>rm nom_fichier\n</code></pre> Supprime un fichier (Remove). Attention : la suppression est d\u00e9finitive.</p> <p>Bash<pre><code>rm -r nom_repertoire\n</code></pre> Supprime un r\u00e9pertoire et tout son contenu.</p> <p>Consultation et \u00e9dition de fichiers</p> <p>Bash<pre><code>cat nom_fichier.txt\n</code></pre> Affiche le contenu entier d'un fichier (Concatenate).</p> <p>Bash<pre><code>head -n 10 nom_fichier.txt\n</code></pre> Affiche les 10 premi\u00e8res lignes d'un fichier.</p> <p>Bash<pre><code>tail -n 10 nom_fichier.txt\n</code></pre> Affiche les 10 derni\u00e8res lignes d'un fichier.</p> <p>Bash<pre><code>nano nom_fichier.txt\n</code></pre> Ouvre l'\u00e9diteur de texte Nano pour \u00e9diter le fichier.</p> <p>Bash<pre><code>vim nom_fichier.txt\n</code></pre> Ouvre l'\u00e9diteur de texte Vim, plus puissant mais avec une courbe d'apprentissage plus raide.</p> <p>Commandes de recherche et de filtrage</p> <p>Bash<pre><code>grep \"motif\" nom_fichier.txt\n</code></pre> Recherche les lignes contenant un motif sp\u00e9cifique (Global Regular Expression Print).</p> <p>Bash<pre><code>grep -r \"motif\" repertoire/\n</code></pre> Recherche r\u00e9cursivement dans un r\u00e9pertoire.</p> <p>Bash<pre><code>find repertoire/ -name \"*.txt\"\n</code></pre> Trouve tous les fichiers avec l'extension <code>.txt</code> dans le r\u00e9pertoire.</p> <p>Commandes de gestion des permissions</p> <p>Bash<pre><code>chmod 755 nom_fichier\n</code></pre> Change les permissions d'un fichier (Change Mode).</p> <p>Bash<pre><code>chown utilisateur:groupe nom_fichier\n</code></pre> Change le propri\u00e9taire d'un fichier (Change Owner).</p> <p>Commandes utilitaires</p> <p>Bash<pre><code>echo \"Texte\"\n</code></pre> Affiche du texte sur la sortie standard.</p> <p>Bash<pre><code>man commande\n</code></pre> Affiche le manuel (manual) de la commande sp\u00e9cifi\u00e9e.</p> <p>Bash<pre><code>whoami\n</code></pre> Affiche le nom de l'utilisateur actuel.</p> <p>Bash<pre><code>date\n</code></pre> Affiche la date et l'heure actuelles.</p>"},{"location":"_projects/_formation-git/git-chap01/#combinaison-de-commandes","title":"Combinaison de commandes","text":"<p>Bash offre une grande flexibilit\u00e9 pour combiner les commandes :</p> <p>Redirection de sortie vers un fichier : Bash<pre><code>echo \"Contenu\" &gt; fichier.txt\n</code></pre></p> <p>Ajout \u00e0 la fin d'un fichier : Bash<pre><code>echo \"Ligne suppl\u00e9mentaire\" &gt;&gt; fichier.txt\n</code></pre></p> <p>Pipe (|) : Utilis\u00e9 pour passer la sortie d'une commande \u00e0 une autre : Bash<pre><code>ls -la | grep \".txt\"\n</code></pre> Cela affiche uniquement les fichiers <code>.txt</code> du r\u00e9pertoire courant.</p>"},{"location":"_projects/_formation-git/git-chap01/#variables-denvironnement","title":"Variables d'environnement","text":"<p>Les variables permettent de stocker des informations :</p> <p>Bash<pre><code>export MA_VARIABLE=\"valeur\"\n</code></pre> Cr\u00e9e une variable accessible dans tous les processus enfants.</p> <p>Bash<pre><code>echo $MA_VARIABLE\n</code></pre> Affiche la valeur de la variable.</p> <p>Quelques variables importantes :</p> <ul> <li><code>$HOME</code> : le r\u00e9pertoire utilisateur</li> <li><code>$PATH</code> : la liste des r\u00e9pertoires o\u00f9 les commandes sont cherch\u00e9es</li> <li><code>$USER</code> : le nom de l'utilisateur actuel</li> <li><code>$PWD</code> : le r\u00e9pertoire courant</li> </ul>"},{"location":"_projects/_formation-git/git-chap01/#environnement","title":"Environnement \ud83c\udf0d","text":""},{"location":"_projects/_formation-git/git-chap01/#configuration-de-lenvironnement-de-travail","title":"Configuration de l'environnement de travail","text":"<p>Une configuration appropri\u00e9e de l'environnement est cruciale pour une utilisation productive de Git.</p>"},{"location":"_projects/_formation-git/git-chap01/#terminal-et-cli","title":"Terminal et CLI","text":"<p>Choisir un terminal appropri\u00e9</p> <ul> <li>Linux : GNOME Terminal, Konsole (KDE), ou terminaux l\u00e9gers comme xterm</li> <li>macOS : Terminal natif, ou iTerm2 pour des fonctionnalit\u00e9s avanc\u00e9es</li> <li>Windows : Git Bash (fourni avec l'installation Git), PowerShell, ou Windows Terminal</li> </ul> <p>Git Bash sur Windows</p> <p>Git Bash \u00e9mule un environnement Unix/Linux sur Windows, permettant l'utilisation des m\u00eames commandes Linux. C'est la solution recommand\u00e9e pour une coh\u00e9rence cross-plateforme.</p>"},{"location":"_projects/_formation-git/git-chap01/#variables-denvironnement-pour-git","title":"Variables d'environnement pour Git","text":"<p>V\u00e9rifier la variable PATH</p> <p>Git doit \u00eatre accessible depuis n'importe quel r\u00e9pertoire. V\u00e9rifier que Git est dans le PATH :</p> Bash<pre><code>which git\n</code></pre> <p>Sur Windows, cela peut s'\u00e9crire : Bash<pre><code>where git\n</code></pre></p> <p>Configurer le HOME</p> Bash<pre><code>echo $HOME\n</code></pre> <p>Ce r\u00e9pertoire contient les fichiers de configuration, notamment <code>.gitconfig</code> o\u00f9 sont stock\u00e9s les param\u00e8tres globaux.</p>"},{"location":"_projects/_formation-git/git-chap01/#fichier-de-configuration-gitconfig","title":"Fichier de configuration <code>.gitconfig</code>","text":"<p>Ce fichier contient tous les param\u00e8tres de configuration globale de Git. Il se trouve g\u00e9n\u00e9ralement dans le r\u00e9pertoire utilisateur.</p> <p>Afficher le fichier : Bash<pre><code>cat ~/.gitconfig\n</code></pre></p> <p>Un exemple de fichier <code>.gitconfig</code> : INI<pre><code>[user]\n    name = Jean Dupont\n    email = jean.dupont@example.com\n[core]\n    editor = nano\n    quotePath = false\n[color]\n    ui = true\n[alias]\n    st = status\n    co = checkout\n    br = branch\n    ci = commit\n[merge]\n    tool = meld\n</code></pre></p>"},{"location":"_projects/_formation-git/git-chap01/#cles-ssh-pour-lauthentification","title":"Cl\u00e9s SSH pour l'authentification","text":"<p>Pour \u00e9viter d'entrer le mot de passe \u00e0 chaque interaction avec un serveur Git distant, configurer une authentification SSH.</p> <p>G\u00e9n\u00e9rer une paire de cl\u00e9s SSH : Bash<pre><code>ssh-keygen -t rsa -b 4096 -C \"email@example.com\"\n</code></pre></p> <p>Les cl\u00e9s seront g\u00e9n\u00e9r\u00e9es dans <code>~/.ssh/</code> : - <code>id_rsa</code> : cl\u00e9 priv\u00e9e (\u00e0 garder secr\u00e8te) - <code>id_rsa.pub</code> : cl\u00e9 publique (\u00e0 partager avec le serveur)</p> <p>Ajouter la cl\u00e9 \u00e0 l'agent SSH : Bash<pre><code>eval $(ssh-agent -s)\nssh-add ~/.ssh/id_rsa\n</code></pre></p> <p>Configurer Git pour utiliser SSH</p> <p>Modifier la configuration : Bash<pre><code>git config --global core.sshCommand \"ssh -i ~/.ssh/id_rsa\"\n</code></pre></p>"},{"location":"_projects/_formation-git/git-chap01/#fichier-gitignore","title":"Fichier <code>.gitignore</code>","text":"<p>Ce fichier, plac\u00e9 \u00e0 la racine du d\u00e9p\u00f4t, indique \u00e0 Git les fichiers ou r\u00e9pertoires \u00e0 ignorer.</p> <p>Exemple de contenu <code>.gitignore</code> pour un projet Python : Text Only<pre><code># R\u00e9pertoires\n__pycache__/\n*.pyc\n.env\nvenv/\n\n# IDEs\n.vscode/\n.idea/\n*.swp\n*.swo\n\n# Fichiers g\u00e9n\u00e9r\u00e9s\n*.log\n*.tmp\nbuild/\ndist/\n\n# Secrets\nconfig_secret.json\n*.key\n</code></pre></p> <p>Pour un projet Node.js : Text Only<pre><code>node_modules/\nnpm-debug.log\n.env\ndist/\nbuild/\n.DS_Store\n</code></pre></p>"},{"location":"_projects/_formation-git/git-chap01/#gestion-des-droits-dacces","title":"Gestion des droits d'acc\u00e8s","text":"<p>Assurer que les fichiers de configuration sont accessibles uniquement par l'utilisateur :</p> Bash<pre><code>chmod 600 ~/.ssh/id_rsa\nchmod 644 ~/.ssh/id_rsa.pub\nchmod 600 ~/.gitconfig\n</code></pre>"},{"location":"_projects/_formation-git/git-chap01/#tests-de-connectivite","title":"Tests de connectivit\u00e9","text":"<p>V\u00e9rifier la connexion \u00e0 un serveur Git distant :</p> Bash<pre><code>ssh -T git@github.com\n</code></pre> <p>Pour GitLab : Bash<pre><code>ssh -T git@gitlab.com\n</code></pre></p> <p>Un message confirmant l'authentification indique que tout est configur\u00e9 correctement.</p>"},{"location":"_projects/_formation-git/git-chap01/#resume-du-parcours-dapprentissage","title":"R\u00e9sum\u00e9 du parcours d'apprentissage \ud83d\udcd6","text":"<p>La progression d'apprentissage commence par comprendre les fondamentaux du contr\u00f4le de version, essentiels pour saisir pourquoi Git existe et quels probl\u00e8mes il r\u00e9sout. Cette compr\u00e9hension th\u00e9orique pose les bases mentales n\u00e9cessaires.</p> <p>Ensuite, le parcours se concentre sur Git lui-m\u00eame, en mettant l'accent sur son architecture distribu\u00e9e et ses avantages par rapport aux syst\u00e8mes centralis\u00e9s. Cette \u00e9tape permet de comprendre les principes uniques qui rendent Git si puissant.</p> <p>La configuration initiale repr\u00e9sente un passage obligatoire avant toute utilisation pratique. Sans cette \u00e9tape, Git ne peut pas fonctionner correctement, d'o\u00f9 son importance dans le parcours.</p> <p>L'\u00e9tape \"\u00c0 l'abordage !\" introduit les op\u00e9rations pratiques essentielles : initialiser un d\u00e9p\u00f4t, y ajouter des fichiers, et effectuer les premiers commits. C'est ici que la th\u00e9orie rencontre la pratique.</p> <p>Parall\u00e8lement, la ma\u00eetrise de Bash et des commandes Linux devient indispensable. Git s'utilise via le terminal, et naviguer efficacement dans le syst\u00e8me de fichiers est un pr\u00e9requis pour manipuler Git sans friction.</p> <p>Enfin, la configuration de l'environnement finalise la pr\u00e9paration. Avec SSH configur\u00e9, les fichiers <code>.gitignore</code> en place et l'environnement correctement param\u00e9tr\u00e9, l'apprenant dispose d'une base solide pour progresser vers des concepts plus avanc\u00e9s comme les branches, la fusion et la collaboration d'\u00e9quipe.</p> <p>Ce cheminement garantit que l'apprenant comprend non seulement comment utiliser Git, mais aussi pourquoi chaque \u00e9tape est n\u00e9cessaire, cr\u00e9ant une compr\u00e9hension durable et applicable \u00e0 des projets r\u00e9els.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-git/git-chap02/","title":"Citations","text":"<ul> <li>https://www.debian-fr.org/t/sauvegarder-un-dossier-avec-git/23928</li> <li>https://www.datacamp.com/fr/tutorial/git-commit</li> <li>http://tutoriel-git.readthedocs.io/fr/latest/Modif.html</li> <li>https://debugue.ecrituresnumeriques.ca/saison-04/seance-05-git-archivage-et-partage-des-donnees/</li> <li>https://www.atlassian.com/fr/git/tutorials/saving-changes/git-commit</li> <li>https://blog.stephane-robert.info/docs/developper/version/git/</li> <li>https://www.youtube.com/watch?v=anP0LBVhUzA</li> <li>https://www.youtube.com/watch?v=syXt9-AdfPs</li> <li>https://grafikart.fr/tutoriels/init-config-add-log-585</li> <li>https://cirst.uqam.ca/outils_bin/git-les-bonnes-pratiques/</li> </ul>"},{"location":"_projects/_formation-git/git-chap02/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 296</li> <li>completion_tokens: 5412</li> <li>total_tokens: 5708</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.081, 'request_cost': 0.006, 'total_cost': 0.088}</li> </ul>"},{"location":"_projects/_formation-git/git-chap02/#content","title":"Content","text":""},{"location":"_projects/_formation-git/git-chap02/#chapitre-2-les-bases-de-git","title":"Chapitre 2 : Les bases de Git","text":""},{"location":"_projects/_formation-git/git-chap02/#introduction-aux-fondamentaux-de-git","title":"\ud83d\udccc Introduction aux fondamentaux de Git","text":"<p>Git fonctionne selon un mod\u00e8le en trois \u00e9tapes fondamentales pour g\u00e9rer les modifications d'un projet. Avant de manipuler les donn\u00e9es, l'apprenti utilisateur doit comprendre l'architecture sous-jacente de Git, qui repose sur trois zones principales : le r\u00e9pertoire de travail (working directory), l'index (staging area) et le d\u00e9p\u00f4t (repository). Ce chapitre explore en profondeur chacun des m\u00e9canismes essentiels permettant de ma\u00eetriser la gestion des versions avec Git.[1][2][3]</p>"},{"location":"_projects/_formation-git/git-chap02/#creer-des-sauvegardes-avec-git-commit","title":"Cr\u00e9er des sauvegardes avec git commit","text":""},{"location":"_projects/_formation-git/git-chap02/#concept-fondamental-du-commit","title":"\ud83d\udd0d Concept fondamental du commit","text":"<p>Un commit repr\u00e9sente un instantan\u00e9 fig\u00e9 du projet \u00e0 un moment donn\u00e9 dans le temps.[5] C'est une photographie compl\u00e8te de l'\u00e9tat des fichiers, accompagn\u00e9e d'un message descriptif et de m\u00e9tadonn\u00e9es (auteur, date, hash unique). Chaque commit cr\u00e9e un point de contr\u00f4le auquel il est possible de revenir ult\u00e9rieurement, formant ainsi l'historique complet du projet.[2][5]</p>"},{"location":"_projects/_formation-git/git-chap02/#anatomie-dun-commit","title":"Anatomie d'un commit","text":"<p>Chaque commit contient les \u00e9l\u00e9ments suivants :</p> <p>Identifiant unique (hash SHA-1) \u2014 Une cha\u00eene de 40 caract\u00e8res g\u00e9n\u00e9rant une signature num\u00e9rique unique du commit.</p> <p>Message de commit \u2014 Une description textuelle des modifications apport\u00e9es. La premi\u00e8re ligne (50 caract\u00e8res maximum) constitue le r\u00e9sum\u00e9, suivi optionnellement de d\u00e9tails suppl\u00e9mentaires.</p> <p>Auteur et Committer \u2014 M\u00e9tadonn\u00e9es enregistrant l'identit\u00e9 de la personne ayant cr\u00e9\u00e9 le commit et celle ayant effectu\u00e9 l'op\u00e9ration.</p> <p>Timestamp \u2014 Date et heure pr\u00e9cises du commit.</p> <p>Snapshot du projet \u2014 L'\u00e9tat complet des fichiers ayant \u00e9t\u00e9 stag\u00e9s.</p>"},{"location":"_projects/_formation-git/git-chap02/#processus-de-creation-dun-commit","title":"Processus de cr\u00e9ation d'un commit","text":"<p>La cr\u00e9ation d'un commit suit un flux en deux \u00e9tapes distinctes. D'abord, les modifications doivent \u00eatre ajout\u00e9es \u00e0 l'index (staging area) via <code>git add</code>. Ensuite, l'op\u00e9ration <code>git commit</code> capture l'instantan\u00e9 de ce qui a \u00e9t\u00e9 stag\u00e9.[2]</p> Bash<pre><code># Premi\u00e8re \u00e9tape : ajouter les fichiers \u00e0 l'index\ngit add fichier1.txt fichier2.py\n\n# Deuxi\u00e8me \u00e9tape : cr\u00e9er le commit\ngit commit -m \"Description des modifications apport\u00e9es\"\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#syntaxe-de-base-du-commit","title":"Syntaxe de base du commit","text":"<p>La m\u00e9thode la plus simple et directe pour cr\u00e9er un commit consiste \u00e0 utiliser le flag <code>-m</code> suivi du message entre guillemets :[2][5]</p> Bash<pre><code>git commit -m \"Correction du bug dans l'authentification utilisateur\"\n</code></pre> <p>Lorsque le flag <code>-m</code> est omis, Git ouvre automatiquement l'\u00e9diteur de texte configur\u00e9 par d\u00e9faut, permettant la r\u00e9daction d'un message plus \u00e9labor\u00e9.[5]</p>"},{"location":"_projects/_formation-git/git-chap02/#commits-avec-plusieurs-fichiers","title":"Commits avec plusieurs fichiers","text":"<p>Pour inclure plusieurs fichiers modifi\u00e9s dans un m\u00eame commit, deux approches existent :</p> <p>Ajouter chaque fichier individuellement :</p> Bash<pre><code>git add init.d apt/source.list\ngit commit -m \"Mise \u00e0 jour des configurations syst\u00e8me\"\n</code></pre> <p>Ajouter tous les fichiers non ignor\u00e9s du r\u00e9pertoire :</p> Bash<pre><code>git add .\ngit commit -m \"Synchronisation compl\u00e8te des modifications\"\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#mettre-a-jour-les-fichiers-avant-commit","title":"Mettre \u00e0 jour les fichiers avant commit","text":"<p>Apr\u00e8s avoir lanc\u00e9 <code>git add</code> sur certains fichiers, si d'autres modifications surviennent, un nouveau <code>git add</code> est n\u00e9cessaire pour les inclure. Alternativement, le flag <code>-a</code> avec commit ajoute automatiquement tous les fichiers modifi\u00e9s (\u00e0 l'exception des fichiers non suivis) :[3]</p> Bash<pre><code>git commit -a -m \"Enregistrement de toutes les modifications suivies\"\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#commits-avec-modification-retrospective","title":"Commits avec modification r\u00e9trospective","text":"<p>Apr\u00e8s la cr\u00e9ation d'un commit, il est parfois n\u00e9cessaire de corriger le message ou d'ajouter un fichier oubli\u00e9. La commande <code>--amend</code> permet cette rectification :[2]</p> Bash<pre><code># Corriger le message du dernier commit\ngit commit --amend -m \"Message corrig\u00e9\"\n\n# Ajouter un fichier oubli\u00e9 au dernier commit\ngit add fichier-oubli\u00e9.txt\ngit commit --amend\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#affichage-de-lhistorique-des-commits","title":"Affichage de l'historique des commits","text":"<p>La commande <code>git log</code> \u00e9num\u00e8re tous les commits du projet, en commen\u00e7ant par le plus r\u00e9cent :[1][3]</p> Bash<pre><code>git log\n</code></pre> <p>Cette commande affiche pour chaque commit : - Le hash SHA-1 (identifiant unique) - L'auteur et sa date - Le message de commit</p>"},{"location":"_projects/_formation-git/git-chap02/#annulation-de-commits","title":"Annulation de commits","text":"<p>Deux strat\u00e9gies permettent d'annuler les commits effectu\u00e9s.</p> <p>La premi\u00e8re approche, utilisant <code>git revert</code>, applique l'inverse des modifications tout en conservant l'historique :</p> Bash<pre><code>git revert &lt;hash-du-commit&gt;\n</code></pre> <p>La seconde approche, utilisant <code>git reset</code>, supprime le commit et peut conserver ou abandonner les modifications :</p> Bash<pre><code># Annuler le dernier commit en conservant les modifications\ngit reset HEAD^\n\n# Annuler le dernier commit et abandonner les modifications\ngit reset --hard HEAD^\n\n# Revenir \u00e0 un commit sp\u00e9cifique\ngit reset --hard &lt;hash-du-commit&gt;\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#ignorer-des-fichiers-et-des-dossiers","title":"Ignorer des fichiers et des dossiers","text":""},{"location":"_projects/_formation-git/git-chap02/#necessite-du-fichier-gitignore","title":"\ud83c\udfaf N\u00e9cessit\u00e9 du fichier .gitignore","text":"<p>Au sein d'un projet, certains fichiers ne doivent jamais \u00eatre versionn\u00e9s : fichiers temporaires, d\u00e9pendances t\u00e9l\u00e9charg\u00e9es, fichiers de configuration personnels, ou secrets. Le fichier <code>.gitignore</code> instruit Git de n\u00e9gliger ces fichiers lors des op\u00e9rations d'ajout et de commit.[1][10]</p>"},{"location":"_projects/_formation-git/git-chap02/#structure-et-placement-du-gitignore","title":"Structure et placement du .gitignore","text":"<p>Le fichier <code>.gitignore</code> doit \u00eatre cr\u00e9\u00e9 \u00e0 la racine du d\u00e9p\u00f4t Git. Ses directives s'appliquent au r\u00e9pertoire contenant le fichier et \u00e0 tous les sous-r\u00e9pertoires.[1]</p> Bash<pre><code># Cr\u00e9er et \u00e9diter le fichier .gitignore\ncat /etc/.gitignore\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#syntaxe-des-regles-gitignore","title":"Syntaxe des r\u00e8gles .gitignore","text":"<p>Chaque ligne du fichier <code>.gitignore</code> d\u00e9finit un motif \u00e0 ignorer. Voici les conventions principales :</p> <p>Commentaires \u2014 Les lignes commen\u00e7ant par <code>#</code> sont ignor\u00e9es.</p> <p>Mod\u00e8les jokers \u2014 Le caract\u00e8re <code>*</code> remplace z\u00e9ro ou plusieurs caract\u00e8res.</p> <p>Mod\u00e8les de r\u00e9pertoires \u2014 Une barre oblique <code>/</code> en fin de ligne d\u00e9signe un r\u00e9pertoire.</p> <p>Exceptions \u2014 Le pr\u00e9fixe <code>!</code> exclut un fichier de la r\u00e8gle d'ignorage pr\u00e9c\u00e9dente.</p>"},{"location":"_projects/_formation-git/git-chap02/#exemples-concrets-de-gitignore","title":"Exemples concrets de .gitignore","text":"Text Only<pre><code># Ignorer les fichiers temporaires\n*~\n*.tmp\n*.bak\n\n# Ignorer les fichiers de syst\u00e8me d'exploitation\n.DS_Store\nThumbs.db\n.directory\n\n# Ignorer les r\u00e9pertoires de d\u00e9pendances\nnode_modules/\nvenv/\n__pycache__/\n\n# Ignorer les fichiers de configuration sensibles\n.env\nconfig/secrets.yml\n.aws/credentials\n\n# Ignorer les fichiers de build\ndist/\nbuild/\n*.o\n\n# Exception : inclure un fichier sp\u00e9cifique\n!config/example.yml\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#impact-du-gitignore-sur-les-commandes-git","title":"Impact du .gitignore sur les commandes Git","text":"<p>Une fois le <code>.gitignore</code> configur\u00e9, la commande <code>git status</code> n'affichera plus les fichiers ignor\u00e9s.[1] Lors de <code>git add .</code>, seuls les fichiers non ignor\u00e9s seront ajout\u00e9s.</p> Bash<pre><code># Cr\u00e9er un fichier .gitignore\necho \"*~\" &gt; .gitignore\n\n# V\u00e9rifier l'\u00e9tat\ngit status\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#application-du-gitignore-aux-fichiers-existants","title":"Application du .gitignore aux fichiers existants","text":"<p>Si un fichier \u00e9tait d\u00e9j\u00e0 suivi par Git avant son ajout au <code>.gitignore</code>, le fichier continuera \u00e0 \u00eatre suivi. Pour arr\u00eater le suivi d'un fichier d\u00e9j\u00e0 enregistr\u00e9 :</p> Bash<pre><code># Arr\u00eater le suivi du fichier sans le supprimer\ngit rm --cached nom-du-fichier\n\n# Confirmer avec un commit\ngit commit -m \"Arr\u00eat du suivi du fichier\"\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#afficher-les-differences-entre-repertoire-index-et-sauvegarde-avec-git-diff","title":"Afficher les diff\u00e9rences entre r\u00e9pertoire, index et sauvegarde avec git diff","text":""},{"location":"_projects/_formation-git/git-chap02/#trois-zones-a-comparer","title":"\ud83d\udd04 Trois zones \u00e0 comparer","text":"<p>Git distingue trois \u00e9tats pour chaque fichier :</p> <ol> <li>Le r\u00e9pertoire de travail (working directory) \u2014 Les fichiers actuellement sur le disque dur, modifiables librement.</li> <li>L'index (staging area) \u2014 La zone interm\u00e9diaire contenant les fichiers en attente de commit.</li> <li>Le d\u00e9p\u00f4t (repository) \u2014 Les fichiers valid\u00e9s et enregistr\u00e9s dans l'historique Git.</li> </ol> <p>La commande <code>git diff</code> permet d'examiner les modifications entre ces trois zones.</p>"},{"location":"_projects/_formation-git/git-chap02/#visualiser-les-differences-non-stagees","title":"Visualiser les diff\u00e9rences non stag\u00e9es","text":"<p>Pour afficher les modifications apport\u00e9es au r\u00e9pertoire de travail qui n'ont pas encore \u00e9t\u00e9 stag\u00e9es :</p> Bash<pre><code>git diff\n</code></pre> <p>Cette commande compare l'index avec le r\u00e9pertoire de travail, montrant les additions (lignes vertes avec <code>+</code>) et les suppressions (lignes rouges avec <code>-</code>).</p>"},{"location":"_projects/_formation-git/git-chap02/#visualiser-les-differences-stagees","title":"Visualiser les diff\u00e9rences stag\u00e9es","text":"<p>Pour afficher les modifications qui ont \u00e9t\u00e9 ajout\u00e9es \u00e0 l'index et qui seront incluses dans le prochain commit :</p> Bash<pre><code>git diff --staged\n</code></pre> <p>Ou l'alias \u00e9quivalent :</p> Bash<pre><code>git diff --cached\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#visualiser-les-differences-avec-le-dernier-commit","title":"Visualiser les diff\u00e9rences avec le dernier commit","text":"<p>Pour comparer le r\u00e9pertoire de travail avec le dernier commit sauvegard\u00e9 :</p> Bash<pre><code>git diff HEAD\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#exemple-concret-de-flux-git-diff","title":"Exemple concret de flux git diff","text":"<p>Supposons un fichier <code>app.py</code> initialement commit\u00e9 contenant :</p> Python<pre><code>def greet(name):\n    return f\"Hello {name}\"\n</code></pre> <p>L'utilisateur apporte les modifications suivantes :</p> Python<pre><code>def greet(name, greeting=\"Hello\"):\n    return f\"{greeting} {name}!\"\n</code></pre> <p>Avant d'ajouter le fichier, <code>git diff</code> r\u00e9v\u00e8le :</p> Diff<pre><code>diff --git a/app.py b/app.py\nindex 1234567..abcdefg 100644\n--- a/app.py\n+++ b/app.py\n@@ -1,2 +1,2 @@\n-def greet(name):\n-    return f\"Hello {name}\"\n+def greet(name, greeting=\"Hello\"):\n+    return f\"{greeting} {name}!\"\n</code></pre> <p>Apr\u00e8s <code>git add app.py</code> et une nouvelle modification :</p> Python<pre><code>def greet(name, greeting=\"Hello\", punctuation=\"\"):\n    return f\"{greeting} {name}{punctuation}!\"\n</code></pre> <p><code>git diff</code> montre uniquement la nouvelle modification :</p> Diff<pre><code>@@ -1,2 +1,2 @@\n def greet(name, greeting=\"Hello\"):\n-    return f\"{greeting} {name}!\"\n+    return f\"{greeting} {name}{punctuation}!\"\n</code></pre> <p>Tandis que <code>git diff --staged</code> affiche la premi\u00e8re modification.</p>"},{"location":"_projects/_formation-git/git-chap02/#etat-dun-fichier-et-fonctionnement-de-lindex","title":"\u00c9tat d'un fichier et fonctionnement de l'index","text":""},{"location":"_projects/_formation-git/git-chap02/#cycle-de-vie-dun-fichier-dans-git","title":"\ud83d\udcca Cycle de vie d'un fichier dans Git","text":"<p>Chaque fichier suivis par Git traverse plusieurs \u00e9tats au cours de sa dur\u00e9e de vie au sein du projet.</p>"},{"location":"_projects/_formation-git/git-chap02/#les-quatre-etats-principaux","title":"Les quatre \u00e9tats principaux","text":"<p>Non suivi (Untracked) \u2014 Le fichier existe dans le r\u00e9pertoire de travail mais n'a jamais \u00e9t\u00e9 ajout\u00e9 \u00e0 Git. Git l'ignore compl\u00e8tement.</p> <p>Modifi\u00e9 (Modified) \u2014 Un fichier suivi a \u00e9t\u00e9 modifi\u00e9 dans le r\u00e9pertoire de travail mais n'a pas \u00e9t\u00e9 stag\u00e9. Cette modification n'appara\u00eetra dans le prochain commit que si le fichier est ajout\u00e9 \u00e0 l'index.</p> <p>Stag\u00e9 (Staged) \u2014 Le fichier a \u00e9t\u00e9 ajout\u00e9 \u00e0 l'index via <code>git add</code> et sera inclus dans le prochain commit.</p> <p>Commit\u00e9 (Committed) \u2014 Le fichier est enregistr\u00e9 de mani\u00e8re permanente dans le d\u00e9p\u00f4t Git.</p>"},{"location":"_projects/_formation-git/git-chap02/#visualisation-des-etats-avec-git-status","title":"Visualisation des \u00e9tats avec git status","text":"<p>La commande <code>git status</code> affiche l'\u00e9tat courant du r\u00e9pertoire de travail et de l'index :[1][3]</p> Bash<pre><code>git status\n</code></pre> <p>Exemple de sortie :</p> Text Only<pre><code>On branch master\n\nChanges to be committed:\n  (use \"git reset HEAD &lt;file&gt;...\" to unstage)\n        modified:   config.py\n        new file:   auth.py\n\nChanges not staged for commit:\n  (use \"git commit -a\" ...)\n        modified:   main.py\n\nUntracked files:\n  (use \"git add &lt;file&gt;...\" to track)\n        temp.log\n        backup/\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#comprendre-lindex-staging-area","title":"Comprendre l'index (staging area)","text":"<p>L'index est une zone interm\u00e9diaire entre le r\u00e9pertoire de travail et le d\u00e9p\u00f4t. Son r\u00f4le consiste \u00e0 permettre une s\u00e9lection pr\u00e9cise des modifications \u00e0 inclure dans le prochain commit. Plusieurs modifications peuvent exister sur un fichier, mais seule la version stag\u00e9e sera commise.[2][3]</p>"},{"location":"_projects/_formation-git/git-chap02/#flux-detat-typique","title":"Flux d'\u00e9tat typique","text":"Text Only<pre><code>Fichier cr\u00e9\u00e9\n     \u2193\nNon suivi (untracked)\n     \u2193 git add\nStag\u00e9 (staged)\n     \u2193 git commit\nCommit\u00e9 (committed)\n     \u2193 Modification du fichier\nModifi\u00e9 (modified)\n     \u2193 git add\nStag\u00e9 (staged)\n     \u2193 git commit\nCommit\u00e9 (committed)\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#transitions-detat-par-fichier","title":"Transitions d'\u00e9tat par fichier","text":"<p>Supposons la cr\u00e9ation d'un nouveau fichier <code>utils.py</code> :</p> Bash<pre><code># \u00c9tat initial : Non suivi\ngit status\n# Untracked files:\n#   utils.py\n\n# Transition vers stag\u00e9\ngit add utils.py\ngit status\n# Changes to be committed:\n#   new file:   utils.py\n\n# Transition vers commit\u00e9\ngit commit -m \"Ajout du module utils\"\ngit status\n# On branch master\n# nothing to commit, working tree clean\n\n# Modification du fichier\necho \"# Nouvelle fonction\" &gt;&gt; utils.py\ngit status\n# Changes not staged for commit:\n#   modified:   utils.py\n\n# Stag\u00e9 \u00e0 nouveau\ngit add utils.py\ngit status\n# Changes to be committed:\n#   modified:   utils.py\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#revenir-a-un-etat-anterieur","title":"Revenir \u00e0 un \u00e9tat ant\u00e9rieur","text":"<p>Pour annuler la modification d'un fichier avant de le stager, la commande <code>git checkout</code> restaure la version du dernier commit :[3]</p> Bash<pre><code>git checkout -- fichier-modifi\u00e9.py\n</code></pre> <p>Pour retirer un fichier de l'index sans l'effacer du disque :</p> Bash<pre><code>git reset HEAD fichier-stag\u00e9.py\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#le-suivi-des-fichiers","title":"Le suivi des fichiers","text":""},{"location":"_projects/_formation-git/git-chap02/#concept-du-suivi-de-fichiers","title":"\ud83d\udd17 Concept du suivi de fichiers","text":"<p>Git ne consid\u00e8re que deux cat\u00e9gories de fichiers : ceux qui sont suivis (tracked) et ceux qui ne le sont pas (untracked). Un fichier suivi est un fichier qui a \u00e9t\u00e9 ajout\u00e9 \u00e0 Git au moins une fois dans son historique. Git continue \u00e0 surveiller ce fichier m\u00eame s'il n'a pas chang\u00e9.</p>"},{"location":"_projects/_formation-git/git-chap02/#demarrage-du-suivi","title":"D\u00e9marrage du suivi","text":"<p>Pour commencer le suivi d'un fichier nouveau, l'utilisation de <code>git add</code> est obligatoire :[1]</p> Bash<pre><code>git add nouveau-fichier.txt\ngit status\n</code></pre> <p>Apr\u00e8s cette op\u00e9ration, le fichier passe de l'\u00e9tat \"untracked\" \u00e0 l'\u00e9tat \"new file\" (pr\u00eat \u00e0 \u00eatre commit\u00e9).</p>"},{"location":"_projects/_formation-git/git-chap02/#arret-du-suivi-dun-fichier","title":"Arr\u00eat du suivi d'un fichier","text":"<p>Un fichier suivi peut cesser d'\u00eatre suivi. Deux approches existent :</p> <p>Suppression du fichier et arr\u00eat du suivi :</p> Bash<pre><code>git rm fichier-obsolete.txt\ngit commit -m \"Suppression du fichier obsol\u00e8te\"\n</code></pre> <p>Arr\u00eat du suivi sans suppression du fichier local :</p> Bash<pre><code>git rm --cached fichier-a-ignorer.txt\ngit commit -m \"Arr\u00eat du suivi du fichier\"\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#affichage-des-fichiers-suivis","title":"Affichage des fichiers suivis","text":"<p>Pour v\u00e9rifier quels fichiers sont actuellement suivis :</p> Bash<pre><code>git ls-files\n</code></pre> <p>Cette commande \u00e9num\u00e8re tous les fichiers pr\u00e9sents dans l'index (c'est-\u00e0-dire ceux qui ont \u00e9t\u00e9 ajout\u00e9s et commit\u00e9s \u00e0 un moment donn\u00e9).</p>"},{"location":"_projects/_formation-git/git-chap02/#fichiers-suivis-dans-un-repertoire-existant","title":"Fichiers suivis dans un r\u00e9pertoire existant","text":"<p>Lorsque l'on cr\u00e9e un d\u00e9p\u00f4t Git dans un r\u00e9pertoire contenant des fichiers existants, aucun fichier n'est automatiquement suivi. Il faut explicitement les ajouter :[1]</p> Bash<pre><code>cd /mon/projet/existant\ngit init\ngit add .\ngit commit -m \"Commit initial du projet\"\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#supprimer-un-fichier-ou-un-dossier","title":"Supprimer un fichier ou un dossier","text":""},{"location":"_projects/_formation-git/git-chap02/#suppression-de-fichiers-avec-git","title":"\ud83d\uddd1\ufe0f Suppression de fichiers avec Git","text":"<p>La suppression via Git diff\u00e8re de la simple suppression depuis l'explorateur de fichiers. Git doit \u00eatre inform\u00e9 de la suppression, qui devient elle-m\u00eame une modification \u00e0 commiter.</p>"},{"location":"_projects/_formation-git/git-chap02/#suppression-simple-dun-fichier","title":"Suppression simple d'un fichier","text":"<p>La commande <code>git rm</code> supprime le fichier du r\u00e9pertoire de travail et le retire du suivi Git simultan\u00e9ment :[3]</p> Bash<pre><code>git rm fichier-a-supprimer.txt\ngit status\n# Changes to be committed:\n#   deleted:    fichier-a-supprimer.txt\n\ngit commit -m \"Suppression du fichier\"\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#suppression-en-conservant-le-fichier-local","title":"Suppression en conservant le fichier local","text":"<p>Parfois, il est souhaitable de cesser le suivi d'un fichier sans le supprimer du disque (par exemple, un fichier de configuration personnelle). L'option <code>--cached</code> r\u00e9alise cette op\u00e9ration :[3]</p> Bash<pre><code>git rm --cached config-local.ini\ngit status\n# Untracked files:\n#   config-local.ini\n\ngit commit -m \"Arr\u00eat du suivi du fichier de configuration local\"\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#suppression-de-repertoires","title":"Suppression de r\u00e9pertoires","text":"<p>Pour supprimer un r\u00e9pertoire entier et tous ses fichiers :</p> Bash<pre><code>git rm -r dossier-a-supprimer/\ngit commit -m \"Suppression du r\u00e9pertoire\"\n</code></pre> <p>L'option <code>-r</code> (r\u00e9cursive) garantit la suppression de tous les fichiers du r\u00e9pertoire.</p>"},{"location":"_projects/_formation-git/git-chap02/#gestion-des-repertoires-vides","title":"Gestion des r\u00e9pertoires vides","text":"<p>Git ne suit que les fichiers, pas les r\u00e9pertoires vides. Un r\u00e9pertoire dispara\u00eet automatiquement de Git si tous ses fichiers sont supprim\u00e9s. Pour conserver un r\u00e9pertoire vide, une convention courante consiste \u00e0 ajouter un fichier <code>.gitkeep</code> vide :</p> Bash<pre><code>mkdir dossier-a-conserver\ntouch dossier-a-conserver/.gitkeep\ngit add dossier-a-conserver/.gitkeep\ngit commit -m \"Cr\u00e9ation du r\u00e9pertoire avec fichier .gitkeep\"\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#suppression-accidentelle-et-restauration","title":"Suppression accidentelle et restauration","text":"<p>Si un fichier a \u00e9t\u00e9 supprim\u00e9 accidentellement du r\u00e9pertoire de travail mais pas du d\u00e9p\u00f4t, la restauration est possible :</p> Bash<pre><code>git checkout -- fichier-supprime.txt\n</code></pre> <p>Si la suppression a d\u00e9j\u00e0 \u00e9t\u00e9 commise, il faut revenir \u00e0 un commit ant\u00e9rieur ou utiliser <code>git revert</code>.</p>"},{"location":"_projects/_formation-git/git-chap02/#exemple-complet-de-gestion-des-suppressions","title":"Exemple complet de gestion des suppressions","text":"Bash<pre><code># Cr\u00e9er un fichier et le commiter\necho \"Donn\u00e9es temporaires\" &gt; temp.txt\ngit add temp.txt\ngit commit -m \"Ajout du fichier temporaire\"\n\n# Cr\u00e9er un r\u00e9pertoire avec plusieurs fichiers\nmkdir logs\necho \"Log 1\" &gt; logs/app.log\necho \"Log 2\" &gt; logs/system.log\ngit add logs/\ngit commit -m \"Ajout du r\u00e9pertoire de logs\"\n\n# Supprimer le fichier temporaire\ngit rm temp.txt\ngit commit -m \"Suppression du fichier temporaire\"\n\n# Supprimer tout le r\u00e9pertoire de logs\ngit rm -r logs/\ngit commit -m \"Suppression du r\u00e9pertoire de logs\"\n\n# V\u00e9rifier l'historique\ngit log --oneline\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#integration-et-pratique-des-concepts","title":"\ud83c\udf93 Int\u00e9gration et pratique des concepts","text":""},{"location":"_projects/_formation-git/git-chap02/#flux-de-travail-complet-du-fichier-au-commit","title":"Flux de travail complet : Du fichier au commit","text":"<p>L'apprentissage des bases de Git se concr\u00e9tise par la ma\u00eetrise d'un flux de travail coh\u00e9rent. Voici un sc\u00e9nario p\u00e9dagogique englobant tous les concepts pr\u00e9sent\u00e9s :</p> <p>\u00c9tape 1 : Initialisation du projet et configuration du .gitignore</p> Bash<pre><code># Cr\u00e9er un nouveau projet\nmkdir mon-app\ncd mon-app\n\n# Initialiser le d\u00e9p\u00f4t\ngit init\n\n# Configurer l'utilisateur\ngit config user.name \"D\u00e9veloppeur\"\ngit config user.email \"dev@example.com\"\n\n# Cr\u00e9er le .gitignore\ncat &gt; .gitignore &lt;&lt; EOF\n# Fichiers temporaires\n*.tmp\n*.bak\n*~\n\n# D\u00e9pendances\nnode_modules/\nvenv/\n\n# Fichiers sensibles\n.env\nEOF\n\n# Ajouter et commiter le .gitignore\ngit add .gitignore\ngit commit -m \"Ajout de la configuration Git\"\n</code></pre> <p>\u00c9tape 2 : Cr\u00e9ation de fichiers et suivi initial</p> Bash<pre><code># Cr\u00e9er des fichiers du projet\necho \"console.log('Application');\" &gt; app.js\necho \"from flask import Flask\" &gt; server.py\necho \"# Documentation du projet\" &gt; README.md\n\n# V\u00e9rifier l'\u00e9tat\ngit status\n\n# Ajouter les fichiers\ngit add .\n\n# V\u00e9rifier l'index\ngit status\n\n# Cr\u00e9er le commit initial\ngit commit -m \"Commit initial du projet\"\n</code></pre> <p>\u00c9tape 3 : Modification et gestion des changements</p> Bash<pre><code># Modifier app.js\necho \"console.log('Version 2');\" &gt;&gt; app.js\n\n# Cr\u00e9er un fichier temporaire (ignor\u00e9)\necho \"donn\u00e9es\" &gt; temp.txt\n\n# V\u00e9rifier l'\u00e9tat\ngit status\n\n# Observer les diff\u00e9rences\ngit diff\n\n# Ajouter la modification et ignorer le fichier temporaire\ngit add app.js\n\n# V\u00e9rifier les fichiers stag\u00e9s\ngit diff --staged\n\n# Cr\u00e9er le commit\ngit commit -m \"Am\u00e9lioration du script d'application\"\n</code></pre> <p>\u00c9tape 4 : Suppression et gestion des fichiers</p> Bash<pre><code># Cr\u00e9er un fichier devenu obsol\u00e8te\necho \"Ancienne configuration\" &gt; config-old.py\ngit add config-old.py\ngit commit -m \"Ajout de configuration (ancienne version)\"\n\n# Supprimer le fichier\ngit rm config-old.py\ngit commit -m \"Suppression de la configuration obsol\u00e8te\"\n\n# V\u00e9rifier l'historique\ngit log --oneline\n</code></pre>"},{"location":"_projects/_formation-git/git-chap02/#tableau-recapitulatif-des-commandes-principales","title":"Tableau r\u00e9capitulatif des commandes principales","text":"Commande Fonction Exemple <code>git add &lt;fichier&gt;</code> Ajouter un fichier \u00e0 l'index <code>git add app.py</code> <code>git add .</code> Ajouter tous les fichiers non ignor\u00e9s <code>git add .</code> <code>git commit -m \"message\"</code> Cr\u00e9er un commit <code>git commit -m \"Ajout de fonctionnalit\u00e9\"</code> <code>git status</code> Afficher l'\u00e9tat du r\u00e9pertoire <code>git status</code> <code>git diff</code> Comparer r\u00e9pertoire et index <code>git diff</code> <code>git diff --staged</code> Comparer index et d\u00e9p\u00f4t <code>git diff --staged</code> <code>git log</code> Afficher l'historique <code>git log</code> <code>git rm &lt;fichier&gt;</code> Supprimer et arr\u00eater le suivi <code>git rm old.py</code> <code>git checkout -- &lt;fichier&gt;</code> Restaurer un fichier <code>git checkout -- file.py</code> <code>git reset HEAD &lt;fichier&gt;</code> Retirer de l'index <code>git reset HEAD staged.py</code>"},{"location":"_projects/_formation-git/git-chap02/#points-cles-a-retenir","title":"Points cl\u00e9s \u00e0 retenir","text":"<p>L'architecture ternaire de Git (r\u00e9pertoire de travail, index, d\u00e9p\u00f4t) constitue le fondement de tout travail avec Git.[1][2][3] La compr\u00e9hension des trois zones et du cycle de vie des fichiers permet une gestion pr\u00e9cise des modifications. Le <code>.gitignore</code> \u00e9limine l'ajout accidentel de fichiers non souhait\u00e9s. Les commandes <code>git diff</code>, <code>git status</code> et <code>git log</code> offrent une visibilit\u00e9 compl\u00e8te sur l'\u00e9tat du projet. Enfin, la suppression de fichiers suit les m\u00eames principes : toute modification doit \u00eatre explicitement ajout\u00e9e et commise pour devenir permanente dans l'historique Git.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-git/git-chap03/","title":"Citations","text":"<ul> <li>https://graphite.com/guides/git-blame</li> <li>https://dev.to/ruqaiya_beguwala/day-730-git-blame-l-see-who-changed-a-specific-line-in-a-file-3lmm</li> <li>https://www.cloudbees.com/blog/git-blame-explained</li> <li>https://git-scm.com/docs/git-blame</li> <li>https://www.atlassian.com/git/tutorials/inspecting-a-repository/git-blame</li> <li>https://www.kosli.com/blog/the-ultimate-guide-to-git-blame-a-how-to-with-examples/</li> <li>https://git-scm.com/docs/git-log</li> </ul>"},{"location":"_projects/_formation-git/git-chap03/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 272</li> <li>completion_tokens: 6593</li> <li>total_tokens: 6865</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.099, 'request_cost': 0.006, 'total_cost': 0.106}</li> </ul>"},{"location":"_projects/_formation-git/git-chap03/#content","title":"Content","text":""},{"location":"_projects/_formation-git/git-chap03/#chapitre-3-inspecter-un-repertoire-et-des-fichiers","title":"Chapitre 3 : Inspecter un r\u00e9pertoire et des fichiers","text":""},{"location":"_projects/_formation-git/git-chap03/#introduction","title":"\ud83c\udfaf Introduction","text":"<p>L'inspection d'un r\u00e9pertoire Git et de ses fichiers constitue une comp\u00e9tence fondamentale pour tout d\u00e9veloppeur travaillant avec le contr\u00f4le de version. Ce chapitre d\u00e9taille les outils et techniques permettant de comprendre l'historique des modifications, d'identifier les auteurs de chaque ligne de code et d'utiliser les interfaces visuelles modernes pour explorer le d\u00e9p\u00f4t. L'apprentissage progresse de mani\u00e8re logique : d'abord les commandes en ligne de commande, puis les outils visuels int\u00e9gr\u00e9s dans les \u00e9diteurs de code.</p>"},{"location":"_projects/_formation-git/git-chap03/#visualiser-lhistorique-dun-projet-git-avec-git-log","title":"\ud83d\udcdc Visualiser l'historique d'un projet Git avec git log","text":""},{"location":"_projects/_formation-git/git-chap03/#comprendre-git-log","title":"Comprendre git log","text":"<p>La commande <code>git log</code> repr\u00e9sente l'un des outils les plus puissants pour examiner l'historique d'un projet. Elle affiche l'ensemble des commits enregistr\u00e9s dans le d\u00e9p\u00f4t, en commen\u00e7ant par le plus r\u00e9cent. Chaque commit contient des informations pr\u00e9cieuses : un identifiant unique (hash), l'auteur, la date, et le message descriptif de la modification.</p>"},{"location":"_projects/_formation-git/git-chap03/#syntaxe-fondamentale","title":"Syntaxe fondamentale","text":"Bash<pre><code>git log\n</code></pre> <p>Cette commande basique affiche tous les commits avec les d\u00e9tails complets : hash du commit, auteur, date et heure, ainsi que le message associ\u00e9. La sortie s'affiche dans un paginateur, permettant de naviguer avec les touches directionnelles ou de quitter avec la touche 'q'.</p>"},{"location":"_projects/_formation-git/git-chap03/#formats-de-sortie-personnalises","title":"Formats de sortie personnalis\u00e9s","text":""},{"location":"_projects/_formation-git/git-chap03/#affichage-sur-une-seule-ligne","title":"Affichage sur une seule ligne","text":"Bash<pre><code>git log --oneline\n</code></pre> <p>Ce format condense chaque commit sur une seule ligne, affichant les sept premiers caract\u00e8res du hash suivi du message du commit. Cette repr\u00e9sentation facilite la visualisation rapide de l'historique, particuli\u00e8rement utile pour les projets comportant de nombreux commits.</p> <p>Exemple de sortie : Text Only<pre><code>a1b2c3d (HEAD -&gt; main) Ajout de la fonctionnalit\u00e9 de connexion\ne4f5g6h Correction du bug d'authentification\ni7j8k9l Refactorisation de la structure du projet\nm0n1o2p Documentation initiale\n</code></pre></p>"},{"location":"_projects/_formation-git/git-chap03/#format-personnalise-avec-format","title":"Format personnalis\u00e9 avec --format","text":"Bash<pre><code>git log --format=\"%h - %an, %ar : %s\"\n</code></pre> <p>Ce format affiche le hash court, le nom de l'auteur, la date relative et le sujet du commit. Les codes disponibles incluent :</p> <ul> <li><code>%h</code> : hash court du commit</li> <li><code>%an</code> : nom de l'auteur</li> <li><code>%ae</code> : email de l'auteur</li> <li><code>%ar</code> : date relative</li> <li><code>%ai</code> : date au format ISO</li> <li><code>%s</code> : sujet du commit</li> <li><code>%b</code> : corps du message</li> </ul>"},{"location":"_projects/_formation-git/git-chap03/#representation-graphique-avec-graph","title":"Repr\u00e9sentation graphique avec --graph","text":"Bash<pre><code>git log --oneline --graph --all --decorate\n</code></pre> <p>Cette commande affiche l'historique sous forme d'arborescence, particuli\u00e8rement utile pour visualiser les branches et les fusions. Le param\u00e8tre <code>--all</code> inclut toutes les branches, tandis que <code>--decorate</code> ajoute les noms des branches et des tags.</p> <p>Exemple de sortie : Text Only<pre><code>* a1b2c3d (HEAD -&gt; main) Fusion de la branche feature/auth\n|\\\n| * e4f5g6h (feature/auth) Ajout du syst\u00e8me d'authentification\n| * i7j8k9l Cr\u00e9ation du module de validation\n|/\n* m0n1o2p Initialisation du projet\n</code></pre></p>"},{"location":"_projects/_formation-git/git-chap03/#filtrer-lhistorique","title":"Filtrer l'historique","text":""},{"location":"_projects/_formation-git/git-chap03/#par-plage-de-dates","title":"Par plage de dates","text":"Bash<pre><code>git log --after=\"2025-01-01\" --before=\"2025-12-31\"\n</code></pre> <p>Cette syntaxe limite l'affichage aux commits cr\u00e9\u00e9s dans la p\u00e9riode sp\u00e9cifi\u00e9e. Plusieurs formats de date sont accept\u00e9s : \"2025-01-01\", \"january 1 2025\", \"1 january 2025\", etc.</p>"},{"location":"_projects/_formation-git/git-chap03/#par-auteur","title":"Par auteur","text":"Bash<pre><code>git log --author=\"Alice\"\n</code></pre> <p>Affiche uniquement les commits r\u00e9alis\u00e9s par l'auteur sp\u00e9cifi\u00e9. La recherche utilise des expressions r\u00e9guli\u00e8res, permettant des requ\u00eates plus complexes :</p> Bash<pre><code>git log --author=\"Alice\\|Bob\"\n</code></pre> <p>Cette commande affiche les commits de deux auteurs diff\u00e9rents.</p>"},{"location":"_projects/_formation-git/git-chap03/#par-message-de-commit","title":"Par message de commit","text":"Bash<pre><code>git log --grep=\"bug\"\n</code></pre> <p>Recherche dans les messages des commits pour trouver ceux contenant le terme sp\u00e9cifi\u00e9. L'option <code>--grep</code> accepte \u00e9galement les expressions r\u00e9guli\u00e8res :</p> Bash<pre><code>git log --grep=\"^Correction\" --grep=\"authentification\"\n</code></pre>"},{"location":"_projects/_formation-git/git-chap03/#par-contenu-modifie","title":"Par contenu modifi\u00e9","text":"Bash<pre><code>git log -S \"fonction_specifique\"\n</code></pre> <p>Affiche les commits qui ont ajout\u00e9 ou supprim\u00e9 les lignes contenant \"fonction_specifique\". Cette technique s'av\u00e8re extr\u00eamement utile pour tracer l'\u00e9volution d'une partie de code sp\u00e9cifique.</p>"},{"location":"_projects/_formation-git/git-chap03/#par-fichier-specifique","title":"Par fichier sp\u00e9cifique","text":"Bash<pre><code>git log -- src/auth.js\n</code></pre> <p>Affiche uniquement les commits ayant modifi\u00e9 le fichier sp\u00e9cifi\u00e9. L'option <code>--</code> indique que les param\u00e8tres suivants sont des chemins de fichier, non des r\u00e9f\u00e9rences de commit.</p>"},{"location":"_projects/_formation-git/git-chap03/#statistiques-et-analyse","title":"Statistiques et analyse","text":""},{"location":"_projects/_formation-git/git-chap03/#affichage-des-statistiques-de-modification","title":"Affichage des statistiques de modification","text":"Bash<pre><code>git log --stat\n</code></pre> <p>Ajoute une statistique \u00e0 chaque commit, indiquant le nombre de lignes ajout\u00e9es et supprim\u00e9es par fichier modifi\u00e9.</p> <p>Exemple de sortie : Text Only<pre><code>commit a1b2c3d\nAuthor: Alice &lt;alice@example.com&gt;\nDate:   Wed Dec 03 2025 10:30:00\n\n    Ajout du module de validation\n\n src/validators.js | 45 ++++++++++++++++++++++\n tests/validators.test.js | 30 ++++++++++++++\n 2 files changed, 75 insertions(+)\n</code></pre></p>"},{"location":"_projects/_formation-git/git-chap03/#affichage-detaille-des-modifications","title":"Affichage d\u00e9taill\u00e9 des modifications","text":"Bash<pre><code>git log -p\n</code></pre> <p>Affiche non seulement les m\u00e9tadonn\u00e9es du commit, mais \u00e9galement les diff\u00e9rences (patch) introduites par chaque commit. Cette option s'av\u00e8re particuli\u00e8rement pr\u00e9cieuse pour comprendre exactement quels changements ont \u00e9t\u00e9 apport\u00e9s.</p>"},{"location":"_projects/_formation-git/git-chap03/#compter-les-commits-par-auteur","title":"Compter les commits par auteur","text":"Bash<pre><code>git log --shortstat --format=\"%an\" | grep -E \"^[a-zA-Z]\" | sort | uniq -c | sort -rn\n</code></pre> <p>Cette commande combine plusieurs utilitaires pour compter le nombre de commits par auteur, r\u00e9v\u00e9lant la contribution relative de chaque membre de l'\u00e9quipe.</p>"},{"location":"_projects/_formation-git/git-chap03/#cas-dusage-pratiques","title":"Cas d'usage pratiques","text":""},{"location":"_projects/_formation-git/git-chap03/#examiner-les-commits-dune-branche","title":"Examiner les commits d'une branche","text":"Bash<pre><code>git log main..feature/nouvelle-fonction\n</code></pre> <p>Affiche les commits pr\u00e9sents dans <code>feature/nouvelle-fonction</code> mais absents de <code>main</code>. Cette comparaison s'av\u00e8re utile avant de fusionner une branche.</p>"},{"location":"_projects/_formation-git/git-chap03/#afficher-les-commits-en-ordre-inverse","title":"Afficher les commits en ordre inverse","text":"Bash<pre><code>git log --reverse\n</code></pre> <p>Commence par les commits les plus anciens et progresse vers les plus r\u00e9cents, offrant une perspective historique du d\u00e9veloppement du projet.</p>"},{"location":"_projects/_formation-git/git-chap03/#limiter-le-nombre-de-commits-affiches","title":"Limiter le nombre de commits affich\u00e9s","text":"Bash<pre><code>git log -n 10\n</code></pre> <p>Affiche uniquement les 10 commits les plus r\u00e9cents, r\u00e9duisant la charge cognitive lors de l'exploration de l'historique.</p>"},{"location":"_projects/_formation-git/git-chap03/#visualiser-lhistorique-dun-fichier-avec-git-blame","title":"\ud83d\udd0d Visualiser l'historique d'un fichier avec git blame","text":""},{"location":"_projects/_formation-git/git-chap03/#concept-fondamental-de-git-blame","title":"Concept fondamental de git blame","text":"<p>La commande <code>git blame</code> offre une perspective enti\u00e8rement diff\u00e9rente sur l'historique Git. Plut\u00f4t que d'afficher les commits chronologiquement, elle annote chaque ligne d'un fichier avec l'information du dernier commit qui l'a modifi\u00e9e. Cette technique s'av\u00e8re invaluable pour comprendre pourquoi une ligne de code existe, qui l'a \u00e9crite et quand.[1][3]</p>"},{"location":"_projects/_formation-git/git-chap03/#syntaxe-de-base","title":"Syntaxe de base","text":"Bash<pre><code>git blame nom_fichier\n</code></pre> <p>Cette commande affiche le fichier ligne par ligne, avec pour chaque ligne : le hash du commit (partiellement affich\u00e9), l'auteur, la date et l'heure de modification, suivis du contenu de la ligne.[1]</p> <p>Exemple de sortie : Text Only<pre><code>6f5b4d3d (Alice 2024-12-10 10:32:14 -0800) def fetch_data():\n74e2c4e9 (Bob 2024-12-11 14:01:02 -0800)     return api.get_data()\na3c8d2e1 (Alice 2024-12-12 09:15:45 -0800)     except Exception as e:\n</code></pre></p>"},{"location":"_projects/_formation-git/git-chap03/#cibler-une-plage-de-lignes-specifique","title":"Cibler une plage de lignes sp\u00e9cifique","text":""},{"location":"_projects/_formation-git/git-chap03/#syntaxe-avec-loption-l","title":"Syntaxe avec l'option -L","text":"<p>L'option <code>-L</code> permet de limiter l'analyse \u00e0 une plage pr\u00e9cise de lignes, optimisant le temps de traitement et la lisibilit\u00e9.[2][4]</p> Bash<pre><code>git blame -L 10,20 nom_fichier\n</code></pre> <p>Cette commande affiche uniquement les lignes 10 \u00e0 20, inclusivement.</p>"},{"location":"_projects/_formation-git/git-chap03/#variantes-de-la-plage","title":"Variantes de la plage","text":"Bash<pre><code>git blame -L 10,+5 nom_fichier\n</code></pre> <p>Cette syntaxe affiche 5 lignes \u00e0 partir de la ligne 10 (lignes 10 \u00e0 14).</p> Bash<pre><code>git blame -L 20, nom_fichier\n</code></pre> <p>Affiche de la ligne 20 jusqu'\u00e0 la fin du fichier.</p>"},{"location":"_projects/_formation-git/git-chap03/#exemple-pratique-concret","title":"Exemple pratique concret","text":"<p>Pour analyser les modifications apport\u00e9es aux lignes 45 \u00e0 50 du fichier <code>server/routes.js</code> :[2]</p> Bash<pre><code>git blame -L 45,50 server/routes.js\n</code></pre> <p>Sortie attendue : Text Only<pre><code>b5c8d9f1 (Dev Team     2023-05-15 10:20:30 +0100 45) router.post('/users', addNewUser);\nc3d4e5f6 (Senior Dev   2021-11-30 08:45:12 -0500 46) router.get('/users/:id', getUser);\nb5c8d9f1 (Dev Team     2023-05-15 10:20:30 +0100 47) router.put('/users/:id', updateUser);\nd7e8f9a0 (Maintenance  2024-01-20 14:22:18 +0200 48) router.delete('/users/:id', deleteUser);\n</code></pre></p>"},{"location":"_projects/_formation-git/git-chap03/#formats-et-options-avancees","title":"Formats et options avanc\u00e9es","text":""},{"location":"_projects/_formation-git/git-chap03/#format-relatif-des-dates","title":"Format relatif des dates","text":"Bash<pre><code>git blame --date=relative nom_fichier\n</code></pre> <p>Affiche les dates sous forme relative (par exemple \"2 weeks ago\", \"3 days ago\"), facilitant la compr\u00e9hension du d\u00e9lai \u00e9coul\u00e9.[1]</p> <p>Exemple de sortie : Text Only<pre><code>6f5b4d3d (Alice 2 weeks ago)    def fetch_data():\n74e2c4e9 (Bob 3 days ago)       return api.get_data()\na3c8d2e1 (Alice 1 day ago)      except Exception as e:\n</code></pre></p>"},{"location":"_projects/_formation-git/git-chap03/#format-porcelain","title":"Format porcelain","text":"Bash<pre><code>git blame --porcelain -L 5,10 README.md\n</code></pre> <p>Le format porcelain produit une sortie structur\u00e9e optimis\u00e9e pour la parsing par d'autres programmes, plut\u00f4t que pour la lecture humaine.[2]</p>"},{"location":"_projects/_formation-git/git-chap03/#suivi-du-code-deplace-avec-c","title":"Suivi du code d\u00e9plac\u00e9 avec -C","text":"Bash<pre><code>git blame -C -L 15,20 main.py\n</code></pre> <p>L'option <code>-C</code> d\u00e9tecte lorsqu'une ligne de code a \u00e9t\u00e9 copi\u00e9e ou d\u00e9plac\u00e9e d'un autre fichier, retra\u00e7ant l'origine r\u00e9elle du code.[2]</p>"},{"location":"_projects/_formation-git/git-chap03/#ignorer-les-changements-de-format-avec-w","title":"Ignorer les changements de format avec -w","text":"Bash<pre><code>git blame -w -L 10,15 styles.css\n</code></pre> <p>L'option <code>-w</code> ignore les modifications mineures d'espacement blanc, concentrant l'attention sur les vrais changements de contenu.[2]</p>"},{"location":"_projects/_formation-git/git-chap03/#cas-dusage-dinvestigation-avances","title":"Cas d'usage d'investigation avanc\u00e9s","text":""},{"location":"_projects/_formation-git/git-chap03/#localiser-quand-une-fonction-a-disparu","title":"Localiser quand une fonction a disparu","text":"<p>Le flux de travail suivant combine <code>git grep</code>, <code>git blame</code> et <code>git log</code> pour tracer la disparition d'une fonction :[2]</p> Bash<pre><code># \u00c9tape 1 : Localiser o\u00f9 la fonction se trouvait\ngit grep -n \"validateAuthToken\"\n# Sortie : src/auth.js:30: validateAuthToken(token);\n\n# \u00c9tape 2 : V\u00e9rifier le dernier commit qui a touch\u00e9 cette ligne\ngit blame -L 30,30 src/auth.js\n# Sortie : ^a1b2c3d (Security Team 2023-01-10 09:00:00 +0000 30) validateAuthToken(token);\n\n# \u00c9tape 3 : Afficher tous les commits ayant modifi\u00e9 cette ligne\ngit log -L 30,30:src/auth.js\n</code></pre>"},{"location":"_projects/_formation-git/git-chap03/#tracer-lintroduction-dune-nouvelle-route","title":"Tracer l'introduction d'une nouvelle route","text":"<p>Pour identifier quand et par qui une route API a \u00e9t\u00e9 ajout\u00e9e :[2]</p> Bash<pre><code># Trouver la ligne contenant la nouvelle route\ngrep -n \"addNewUser\" server/routes.js\n# Sortie : 45:router.post('/users', addNewUser);\n\n# Voir quand elle a \u00e9t\u00e9 introduite\ngit blame -L 45,45 server/routes.js\n# Sortie : b5c8d9f1 (Dev Team 2023-05-15 10:20:30 +0100 45) router.post('/users', addNewUser);\n\n# Inspecter le commit pour obtenir plus de contexte\ngit show b5c8d9f1\n</code></pre>"},{"location":"_projects/_formation-git/git-chap03/#analyser-lhistorique-dun-test","title":"Analyser l'historique d'un test","text":"<p>Pour comprendre l'\u00e9volution d'un test sp\u00e9cifique :[2]</p> Bash<pre><code># Localiser le test dans le fichier\ngrep -n \"shouldHandleConcurrentRequests\" tests/api.test.js\n# Sortie : 112: it('shouldHandleConcurrentRequests', async () =&gt; {\n\n# V\u00e9rifier quand il a \u00e9t\u00e9 modifi\u00e9 pour la derni\u00e8re fois\ngit blame -L 112,112 tests/api.test.js\n# Sortie : c3d4e5f6 (Senior Dev 2021-11-30 08:45:12 -0500 112) it('shouldHandleConcurrentRequests', async () =&gt; {\n</code></pre>"},{"location":"_projects/_formation-git/git-chap03/#consulter-git-blame-a-un-commit-specifique","title":"Consulter git blame \u00e0 un commit sp\u00e9cifique","text":"Bash<pre><code>git blame abc123 -L 25,30 app.js\n</code></pre> <p>Affiche le blame du fichier <code>app.js</code> tel qu'il \u00e9tait au moment du commit <code>abc123</code>, permettant d'explorer l'historique \u00e0 diff\u00e9rents points dans le temps.[2]</p>"},{"location":"_projects/_formation-git/git-chap03/#differences-entre-git-blame-et-git-log","title":"Diff\u00e9rences entre git blame et git log","text":"Aspect git log git blame Perspective Chronologique, par commit Par ligne, dans le contexte du fichier Cas d'usage Comprendre l'historique global Comprendre l'origine d'une ligne sp\u00e9cifique R\u00e9solution Au niveau du commit entier Au niveau de la ligne individuelle Recherche Par date, auteur, message Par num\u00e9ro de ligne, fichier sp\u00e9cifique Performance Rapide sur l'ensemble du d\u00e9p\u00f4t Plus rapide sur un fichier sp\u00e9cifique"},{"location":"_projects/_formation-git/git-chap03/#longlet-source-control-de-vs-code","title":"\ud83c\udfa8 L'onglet Source Control de VS Code","text":""},{"location":"_projects/_formation-git/git-chap03/#integration-native-de-git-dans-vs-code","title":"Int\u00e9gration native de Git dans VS Code","text":"<p>Visual Studio Code offre une int\u00e9gration compl\u00e8te de Git directement dans l'interface utilisateur, sans n\u00e9cessiter l'installation de d\u00e9pendances suppl\u00e9mentaires. L'onglet Source Control, accessible via la barre lat\u00e9rale, centralise toutes les op\u00e9rations Git courantes.</p>"},{"location":"_projects/_formation-git/git-chap03/#acceder-a-longlet-source-control","title":"Acc\u00e9der \u00e0 l'onglet Source Control","text":"<p>L'onglet Source Control appara\u00eet dans la barre lat\u00e9rale gauche, identifiable par l'ic\u00f4ne de branche (ressemblant \u00e0 un Y). Pour y acc\u00e9der :</p> <ol> <li>Cliquer sur l'ic\u00f4ne de branche dans la barre lat\u00e9rale gauche</li> <li>Utiliser le raccourci clavier <code>Ctrl+Shift+G</code> (Windows/Linux) ou <code>Cmd+Shift+G</code> (macOS)</li> </ol>"},{"location":"_projects/_formation-git/git-chap03/#structure-de-linterface","title":"Structure de l'interface","text":"<p>L'onglet Source Control organise les fichiers en plusieurs sections :</p>"},{"location":"_projects/_formation-git/git-chap03/#changes-modifications-non-mises-en-scene","title":"Changes (Modifications non mises en sc\u00e8ne)","text":"<p>Cette section affiche tous les fichiers modifi\u00e9s mais non encore ajout\u00e9s \u00e0 l'index. Les ic\u00f4nes \u00e0 c\u00f4t\u00e9 de chaque fichier indiquent le type de modification :</p> <ul> <li>M (jaune) : Fichier modifi\u00e9</li> <li>A (vert) : Fichier ajout\u00e9</li> <li>D (rouge) : Fichier supprim\u00e9</li> <li>? (blanc) : Fichier non suivi</li> </ul> <p>Cliquer sur un fichier dans cette section ouvre un diff visual, affichant les modifications ligne par ligne. Le diff utilise des couleurs pour identifier facilement les ajouts (vert) et les suppressions (rouge).</p>"},{"location":"_projects/_formation-git/git-chap03/#staged-changes-modifications-mises-en-scene","title":"Staged Changes (Modifications mises en sc\u00e8ne)","text":"<p>Apr\u00e8s avoir mis en sc\u00e8ne des modifications avec <code>git add</code>, celles-ci apparaissent dans cette section. Les fichiers ici sont pr\u00eats \u00e0 \u00eatre valid\u00e9s.</p>"},{"location":"_projects/_formation-git/git-chap03/#operations-courantes","title":"Op\u00e9rations courantes","text":""},{"location":"_projects/_formation-git/git-chap03/#ajouter-des-fichiers-a-lindex","title":"Ajouter des fichiers \u00e0 l'index","text":"<p>Plusieurs approches existent :</p> <ul> <li>Ajouter un fichier sp\u00e9cifique : Cliquer sur le symbole '+' \u00e0 c\u00f4t\u00e9 du nom du fichier dans la section Changes</li> <li>Ajouter tous les fichiers : Cliquer sur le symbole '+' au-dessus de la section Changes</li> <li>Retirer de l'index : Cliquer sur le symbole '-' \u00e0 c\u00f4t\u00e9 d'un fichier dans Staged Changes</li> </ul>"},{"location":"_projects/_formation-git/git-chap03/#creer-un-commit","title":"Cr\u00e9er un commit","text":"<p>Un champ de texte en haut de l'onglet permet de saisir le message du commit. Apr\u00e8s avoir \u00e9crit le message et mis\u00e9 en sc\u00e8ne les fichiers d\u00e9sir\u00e9s :</p> <ol> <li>Saisir le message dans le champ pr\u00e9vu</li> <li>Appuyer sur <code>Ctrl+Entr\u00e9e</code> (ou cliquer le bouton de validation)</li> <li>Le commit est cr\u00e9\u00e9 et l'index est r\u00e9initialis\u00e9</li> </ol>"},{"location":"_projects/_formation-git/git-chap03/#visualiser-lhistorique","title":"Visualiser l'historique","text":""},{"location":"_projects/_formation-git/git-chap03/#timeline-chronologie","title":"Timeline (Chronologie)","text":"<p>VS Code affiche une chronologie des commits dans l'explorateur de fichiers. Cliquer sur un commit dans cette timeline affiche les modifications introduites par ce commit sp\u00e9cifique.</p>"},{"location":"_projects/_formation-git/git-chap03/#afficher-les-commits-avec-ctrlk-ctrl0","title":"Afficher les commits avec Ctrl+K Ctrl+0","text":"<p>Combinaison de touches qui ouvre la vue de l'historique avec les commits et les branches.</p>"},{"location":"_projects/_formation-git/git-chap03/#integration-avec-les-branches","title":"Int\u00e9gration avec les branches","text":"<p>L'onglet Source Control affiche la branche courante \u00e0 c\u00f4t\u00e9 du nom du d\u00e9p\u00f4t. Cliquer sur le nom de la branche ouvre une palette de commandes permettant de :</p> <ul> <li>Cr\u00e9er une nouvelle branche</li> <li>Basculer vers une branche existante</li> <li>Supprimer une branche</li> <li>Fusionner une branche</li> </ul>"},{"location":"_projects/_formation-git/git-chap03/#conflits-de-fusion","title":"Conflits de fusion","text":"<p>Lors d'une fusion g\u00e9n\u00e9rant des conflits, VS Code les signale visuellement dans l'onglet Source Control. Des boutons permettent de r\u00e9soudre automatiquement les conflits en acceptant les changements actuels, les changements entrants, ou une combinaison des deux.</p>"},{"location":"_projects/_formation-git/git-chap03/#lextension-gitlens","title":"\ud83d\udd0c L'extension GitLens","text":""},{"location":"_projects/_formation-git/git-chap03/#vue-densemble-de-gitlens","title":"Vue d'ensemble de GitLens","text":"<p>GitLens, d\u00e9velopp\u00e9e par Eric Amodio, enrichit consid\u00e9rablement les capacit\u00e9s Git int\u00e9gr\u00e9es de VS Code. Cette extension superpose des informations contextuelles directement sur le code, r\u00e9v\u00e9lant l'auteur, la date et le message du commit pour chaque ligne.[5]</p>"},{"location":"_projects/_formation-git/git-chap03/#installation-et-activation","title":"Installation et activation","text":"<p>GitLens s'installe comme n'importe quelle extension VS Code :</p> <ol> <li>Ouvrir la palette de commandes avec <code>Ctrl+Shift+P</code></li> <li>Taper \"Extensions : Install Extensions\"</li> <li>Chercher \"GitLens\"</li> <li>Cliquer le bouton d'installation \u00e0 c\u00f4t\u00e9 de \"GitLens \u2014 Git supercharged\"</li> <li>Recharger VS Code apr\u00e8s l'installation</li> </ol>"},{"location":"_projects/_formation-git/git-chap03/#fonctionnalites-principales","title":"Fonctionnalit\u00e9s principales","text":""},{"location":"_projects/_formation-git/git-chap03/#git-blame-annotation-des-lignes","title":"Git Blame - Annotation des lignes","text":"<p>La fonctionnalit\u00e9 la plus visible de GitLens est l'affichage du blame en temps r\u00e9el. Pour chaque ligne de code, une annotation discr\u00e8te appara\u00eet affichant :</p> <ul> <li>Le hash court du commit</li> <li>L'auteur</li> <li>La date relative (par exemple \"2 weeks ago\")</li> <li>Le message du commit</li> </ul> <p>Exemple d'annotation : Text Only<pre><code>a1b2c3d (Alice, 2 weeks ago): def fetch_data():\n</code></pre></p>"},{"location":"_projects/_formation-git/git-chap03/#lens-de-code-code-lens","title":"Lens de code (Code Lens)","text":"<p>Au-dessus de chaque fonction et classe, GitLens affiche une ligne suppl\u00e9mentaire (Code Lens) indiquant le nombre de modifications r\u00e9centes, avec la possibilit\u00e9 de cliquer pour explorer l'historique.</p> <p>Exemple : Text Only<pre><code>\ud83d\udcdd 3 contributors, last change by Bob (1 day ago)\ndef calculate_total(items):\n</code></pre></p>"},{"location":"_projects/_formation-git/git-chap03/#commandes-integrees","title":"Commandes int\u00e9gr\u00e9es","text":"<p>GitLens ajoute plusieurs commandes accessibles en cliquant sur le code ou via la palette de commandes :</p> <ul> <li>View Blame : Affiche le blame du fichier courant</li> <li>Toggle Blame : Active/d\u00e9sactive l'affichage du blame</li> <li>Show Commit Details : Affiche les d\u00e9tails complets du commit</li> <li>Copy Commit Hash : Copie le hash du commit</li> <li>Open Commit in Remote : Ouvre le commit sur la plateforme distante (GitHub, GitLab, etc.)</li> </ul>"},{"location":"_projects/_formation-git/git-chap03/#navigation-et-exploration","title":"Navigation et exploration","text":""},{"location":"_projects/_formation-git/git-chap03/#explorer-des-branches","title":"Explorer des branches","text":"<p>L'arborescence des branches dans la barre lat\u00e9rale permet de visualiser rapidement :</p> <ul> <li>La branche courante</li> <li>Les branches locales</li> <li>Les branches distantes</li> <li>Les tags</li> </ul> <p>Cliquer sur une branche la rend courante, tandis qu'un clic droit ouvre un menu contextuel permettant de renommer, supprimer ou cr\u00e9er des branches.</p>"},{"location":"_projects/_formation-git/git-chap03/#historique-des-fichiers","title":"Historique des fichiers","text":"<p>L'onglet \"File History\" de GitLens affiche chronologiquement tous les commits ayant modifi\u00e9 le fichier courant, avec pour chacun :</p> <ul> <li>Le hash du commit</li> <li>L'auteur</li> <li>La date</li> <li>Le message</li> </ul>"},{"location":"_projects/_formation-git/git-chap03/#historique-des-lignes","title":"Historique des lignes","text":"<p>En positionnant le curseur sur une ligne, puis en utilisant la commande \"GitLens: View File Revision from Line\", l'historique complet de cette ligne s'affiche, r\u00e9v\u00e9lant toutes les modifications qu'elle a subies.</p>"},{"location":"_projects/_formation-git/git-chap03/#comparaison-visuelle-avancee","title":"Comparaison visuelle avanc\u00e9e","text":""},{"location":"_projects/_formation-git/git-chap03/#diff-pour-chaque-commit","title":"Diff pour chaque commit","text":"<p>En cliquant sur un commit dans l'historique, GitLens affiche le diff complet introduit par ce commit. Les additions sont mises en \u00e9vidence en vert, les suppressions en rouge.</p>"},{"location":"_projects/_formation-git/git-chap03/#blame-differentiel","title":"Blame diff\u00e9rentiel","text":"<p>GitLens peut comparer le blame entre deux commits, r\u00e9v\u00e9lant exactement ce qui a chang\u00e9 entre deux points du temps.</p>"},{"location":"_projects/_formation-git/git-chap03/#integration-avec-les-plateformes-distantes","title":"Int\u00e9gration avec les plateformes distantes","text":"<p>GitLens reconna\u00eet automatiquement la plateforme de destination (GitHub, GitLab, Bitbucket, etc.) et propose des commandes sp\u00e9cifiques :</p> <ul> <li>View on Remote : Ouvre le fichier sur la plateforme distante</li> <li>Copy Remote URL : Copie le lien vers le fichier distant</li> <li>Open Blame on Remote : Ouvre la vue blame sur la plateforme distante</li> </ul>"},{"location":"_projects/_formation-git/git-chap03/#configuration-et-personnalisation","title":"Configuration et personnalisation","text":""},{"location":"_projects/_formation-git/git-chap03/#fichier-settingsjson","title":"Fichier settings.json","text":"<p>Les pr\u00e9f\u00e9rences de GitLens se configurent dans <code>settings.json</code> :</p> JSON<pre><code>{\n  \"gitlens.blame.toggleMode\": \"file\",\n  \"gitlens.codeLens.enabled\": true,\n  \"gitlens.codeLens.recentChange.enabled\": true,\n  \"gitlens.currentLine.enabled\": false,\n  \"gitlens.hovers.enabled\": true,\n  \"gitlens.statusBar.enabled\": true\n}\n</code></pre>"},{"location":"_projects/_formation-git/git-chap03/#options-de-visibilite","title":"Options de visibilit\u00e9","text":"<ul> <li><code>toggleMode</code> : \"inline\" (direct sur le code), \"file\" (pour tout le fichier) ou \"window\" (pour la fen\u00eatre)</li> <li><code>enabled</code> : Chaque type d'information peut \u00eatre activ\u00e9/d\u00e9sactiv\u00e9 ind\u00e9pendamment</li> <li><code>format</code> : Personnaliser le format d'affichage des annotations</li> </ul>"},{"location":"_projects/_formation-git/git-chap03/#commandes-cles","title":"Commandes cl\u00e9s","text":"Commande Action <code>GitLens: Show File Blame</code> Affiche le blame du fichier entier <code>GitLens: Toggle File Blame</code> Active/d\u00e9sactive l'affichage du blame <code>GitLens: Show Commit Details</code> Affiche les d\u00e9tails du commit courant <code>GitLens: Show File History</code> Affiche l'historique complet du fichier <code>GitLens: View File Revision from Line</code> Affiche l'historique d'une ligne sp\u00e9cifique <code>GitLens: Copy Remote URL</code> Copie le lien vers le fichier distant"},{"location":"_projects/_formation-git/git-chap03/#synthese-comparative-des-outils","title":"\ud83d\udcca Synth\u00e8se comparative des outils","text":"Outil Cas d'usage principal Avantages Limitations git log Historique global du projet Flexible, puissant en CLI, id\u00e9al pour scripts N\u00e9cessite connaissance des options git blame Tracer l'origine de chaque ligne Pr\u00e9cision ligne par ligne, d\u00e9tails auteur/date Moins intuitif sans interface visuelle VS Code Source Control Gestion quotidienne des commits Int\u00e9gration native, simple, pas d'extension Fonctionnalit\u00e9s limit\u00e9es compar\u00e9 \u00e0 GitLens GitLens Exploration d\u00e9taill\u00e9e du code Annotations contextuelles, navigation riche Peut surcharger l'interface"},{"location":"_projects/_formation-git/git-chap03/#progression-dapprentissage-recommandee","title":"\ud83c\udf93 Progression d'apprentissage recommand\u00e9e","text":""},{"location":"_projects/_formation-git/git-chap03/#phase-1-fondamentaux-semaine-1","title":"Phase 1 : Fondamentaux (Semaine 1)","text":"<p>L'apprentissage commence par les commandes en ligne de commande, fondement de toute ma\u00eetrise de Git. Cette phase \u00e9tablit la compr\u00e9hension conceptuelle n\u00e9cessaire.</p> <p>Objectifs : - Ex\u00e9cuter <code>git log</code> dans diverses configurations - Comprendre le format de sortie et les m\u00e9tadonn\u00e9es - Filtrer par auteur, date et message</p> <p>Exercices pratiques : 1. Explorer le historique d'un d\u00e9p\u00f4t existant avec diff\u00e9rentes options 2. Identifier les commits d'un auteur sp\u00e9cifique 3. Utiliser le format graphique pour visualiser les branches</p>"},{"location":"_projects/_formation-git/git-chap03/#phase-2-analyse-detaillee-semaine-2","title":"Phase 2 : Analyse d\u00e9taill\u00e9e (Semaine 2)","text":"<p>La deuxi\u00e8me phase approfondit la compr\u00e9hension avec <code>git blame</code>, permettant une inspection au niveau de la ligne.</p> <p>Objectifs : - Utiliser <code>git blame</code> pour tracer l'origine de code - Combiner <code>git blame</code> avec d'autres commandes (grep, log) - Interpr\u00e9ter les r\u00e9sultats pour comprendre les d\u00e9cisions de codage</p> <p>Exercices pratiques : 1. Localiser qui a \u00e9crit une fonction sp\u00e9cifique 2. Tracer les modifications apport\u00e9es \u00e0 une ligne au fil du temps 3. Identifier les patterns de contribution d'auteurs</p>"},{"location":"_projects/_formation-git/git-chap03/#phase-3-integration-visuelle-semaine-3","title":"Phase 3 : Int\u00e9gration visuelle (Semaine 3)","text":"<p>L'interface visuelle de VS Code consolidate les connaissances acquises, offrant une exp\u00e9rience plus intuitive.</p> <p>Objectifs : - Naviguer dans l'onglet Source Control - Effectuer des commits via l'interface - Comprendre le workflow visuel</p> <p>Exercices pratiques : 1. Effectuer des commits r\u00e9guliers via VS Code 2. Visualiser les modifications avant de les valider 3. G\u00e9rer les branches avec l'interface visuelle</p>"},{"location":"_projects/_formation-git/git-chap03/#phase-4-maitrise-avancee-semaine-4","title":"Phase 4 : Ma\u00eetrise avanc\u00e9e (Semaine 4)","text":"<p>GitLens transforme l'exp\u00e9rience en ajoutant des capacit\u00e9s contextuelles riches directement dans l'\u00e9diteur.</p> <p>Objectifs : - Utiliser GitLens pour explorer le code interactivement - Naviguer vers les commits distants - Configurer GitLens pour les pr\u00e9f\u00e9rences personnelles</p> <p>Exercices pratiques : 1. Utiliser les annotations de GitLens pour comprendre le code 2. Acc\u00e9der directement \u00e0 GitHub/GitLab depuis l'\u00e9diteur 3. Param\u00e9trer l'affichage selon les pr\u00e9f\u00e9rences de travail</p>"},{"location":"_projects/_formation-git/git-chap03/#integration-pratique","title":"Int\u00e9gration pratique","text":"<p>La compr\u00e9hension compl\u00e8te s'acquiert en combinant les approches :</p> <p>Exemple de workflow r\u00e9el :</p> <ol> <li>Question initiale : Pourquoi ce bug existe-t-il ?</li> <li>Git log : <code>git log --grep=\"bug\" --oneline</code> pour identifier les commits pertinents</li> <li>Git blame : <code>git blame -L ligne_debut,ligne_fin fichier.js</code> pour tracer la ligne</li> <li>GitLens : Cliquer sur l'annotation pour acc\u00e9der aux d\u00e9tails du commit</li> <li>Diff visuel : Examiner le changement dans VS Code</li> <li>Action : Comprendre la d\u00e9cision et d\u00e9cider de corriger ou de documenter</li> </ol>"},{"location":"_projects/_formation-git/git-chap03/#points-cles-a-retenir","title":"\u2705 Points cl\u00e9s \u00e0 retenir","text":"<p>L'inspection efficace d'un r\u00e9pertoire Git n\u00e9cessite la ma\u00eetrise combin\u00e9e de plusieurs outils, chacun offrant des perspectives compl\u00e9mentaires :</p> <ul> <li>git log fournit la vue globale, l'historique chronologique du projet</li> <li>git blame offre la pr\u00e9cision, tra\u00e7ant l'origine exacte de chaque ligne</li> <li>VS Code Source Control facilite les op\u00e9rations quotidiennes de mani\u00e8re intuitif</li> <li>GitLens enrichit l'exp\u00e9rience en contextualisant les informations directement dans le code</li> </ul> <p>Cette progression logique, du conceptuel au pratique, du global au d\u00e9taill\u00e9, \u00e9tablit une base solide pour une utilisation productive de Git dans un environnement de d\u00e9veloppement professionnel.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-git/git-chap04/","title":"Citations","text":"<ul> <li>https://learn.microsoft.com/fr-fr/azure/devops/repos/git/undo?view=azure-devops</li> <li>https://www.tutkit.com/fr/tutoriels-texte/20151-git-revenir-sur-les-modifications-git-reset-et-git-checkout-expliques</li> <li>https://git-scm.com/book/fr/v2/Les-bases-de-Git-Annuler-des-actions</li> <li>https://www.nicelydev.com/git/tout-annuler-git</li> <li>https://labex.io/fr/tutorials/git-how-to-undo-git-commit-but-keep-changes-392512</li> <li>https://www.atlassian.com/fr/git/tutorials/undoing-changes/git-revert</li> <li>https://comprendre-git.com/fr/annuler-defaire-corriger/retirer-des-modifs-a-un-commit/</li> <li>https://www.datacamp.com/fr/tutorial/git-reset-revert-tutorial</li> <li>https://www.youtube.com/watch?v=UsCMD2CFobs</li> </ul>"},{"location":"_projects/_formation-git/git-chap04/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 241</li> <li>completion_tokens: 6608</li> <li>total_tokens: 6849</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.099, 'request_cost': 0.006, 'total_cost': 0.106}</li> </ul>"},{"location":"_projects/_formation-git/git-chap04/#content","title":"Content","text":""},{"location":"_projects/_formation-git/git-chap04/#chapitre-4-annuler-des-modifications","title":"Chapitre 4 : Annuler des modifications","text":""},{"location":"_projects/_formation-git/git-chap04/#introduction","title":"\ud83d\udcda Introduction","text":"<p>La gestion des modifications dans Git est une comp\u00e9tence fondamentale pour tout d\u00e9veloppeur. Le syst\u00e8me de contr\u00f4le de version Git offre plusieurs m\u00e9canismes permettant d'annuler, de corriger ou de modifier des changements \u00e0 diff\u00e9rents stades du workflow de d\u00e9veloppement. Ce chapitre explore en d\u00e9tail les commandes essentielles pour g\u00e9rer les modifications ind\u00e9sirables et maintenir un historique de commits propre et fiable.</p> <p>Les commandes pr\u00e9sent\u00e9es dans ce chapitre s'adressent \u00e0 des situations vari\u00e9es : annuler des modifications non commit\u00e9es, corriger un commit r\u00e9cent, supprimer des fichiers non versionn\u00e9s, ou encore inverser les changements introduits par un commit ancien sans r\u00e9\u00e9crire l'historique.</p>"},{"location":"_projects/_formation-git/git-chap04/#git-clean","title":"\ud83e\uddf9 git clean","text":""},{"location":"_projects/_formation-git/git-chap04/#concept-fondamental","title":"Concept fondamental","text":"<p><code>git clean</code> est une commande sp\u00e9cialis\u00e9e dans la suppression des fichiers non suivis par Git. Contrairement \u00e0 d'autres commandes qui modifient l'historique ou restaurent des fichiers d\u00e9j\u00e0 versionn\u00e9s, <code>git clean</code> \u00e9limine uniquement les fichiers qui n'ont jamais \u00e9t\u00e9 ajout\u00e9s \u00e0 l'index Git.[1]</p>"},{"location":"_projects/_formation-git/git-chap04/#cas-dusage-pratiques","title":"Cas d'usage pratiques","text":"<p>Cette commande s'av\u00e8re particuli\u00e8rement utile dans les sc\u00e9narios suivants : - Nettoyer le r\u00e9pertoire de travail apr\u00e8s la compilation de fichiers temporaires - Supprimer les fichiers de configuration locaux qui ne doivent pas \u00eatre versionn\u00e9s - Pr\u00e9parer l'espace de travail avant une op\u00e9ration fusion complexe - \u00c9liminer les fichiers de cache ou de log g\u00e9n\u00e9r\u00e9s accidentellement</p>"},{"location":"_projects/_formation-git/git-chap04/#utilisation-basique","title":"Utilisation basique","text":"<p>Pour afficher un aper\u00e7u des fichiers qui seraient supprim\u00e9s sans les effacer r\u00e9ellement :</p> Bash<pre><code>git clean -n\n</code></pre> <p>L'option <code>-n</code> (ou <code>--dry-run</code>) ex\u00e9cute la commande en mode simulation, permettant de v\u00e9rifier quels fichiers seraient supprim\u00e9s avant toute action irr\u00e9versible.</p>"},{"location":"_projects/_formation-git/git-chap04/#options-avancees","title":"Options avanc\u00e9es","text":"<p>Pour supprimer effectivement les fichiers non suivis :</p> Bash<pre><code>git clean -f\n</code></pre> <p>L'option <code>-f</code> (ou <code>--force</code>) ordonne la suppression des fichiers identifi\u00e9s.</p> <p>Pour inclure les r\u00e9pertoires vides dans la suppression :</p> Bash<pre><code>git clean -fd\n</code></pre> <p>L'option <code>-d</code> supprime \u00e9galement les r\u00e9pertoires vides qui ne contiennent que des fichiers non suivis.</p> <p>Pour supprimer aussi les fichiers list\u00e9s dans le fichier <code>.gitignore</code> :</p> Bash<pre><code>git clean -fX\n</code></pre> <p>Pour supprimer tous les fichiers non suivis, y compris ceux ignor\u00e9s :</p> Bash<pre><code>git clean -fdx\n</code></pre>"},{"location":"_projects/_formation-git/git-chap04/#exemple-pratique-complet","title":"Exemple pratique complet","text":"<p>Consid\u00e9rant un r\u00e9pertoire contenant les fichiers suivants :</p> Text Only<pre><code>mon-projet/\n\u251c\u2500\u2500 index.js (suivi par Git)\n\u251c\u2500\u2500 package.json (suivi par Git)\n\u251c\u2500\u2500 node_modules/ (ignor\u00e9 par .gitignore)\n\u251c\u2500\u2500 build/ (r\u00e9pertoire contenant des fichiers compil\u00e9s)\n\u2514\u2500\u2500 temp.txt (non suivi)\n</code></pre> <p>\u00c9tape 1 : V\u00e9rification pr\u00e9alable</p> Bash<pre><code>git clean -n\n</code></pre> <p>R\u00e9sultat attendu : Text Only<pre><code>Removing temp.txt\n</code></pre></p> <p>\u00c9tape 2 : Ex\u00e9cution avec suppression des r\u00e9pertoires</p> Bash<pre><code>git clean -fd\n</code></pre> <p>R\u00e9sultat : suppression de <code>temp.txt</code> et du r\u00e9pertoire <code>build/</code>.</p> <p>\u00c9tape 3 : Suppression incluant les fichiers ignor\u00e9s</p> <p>Si l'intention est de nettoyer \u00e9galement les fichiers du <code>.gitignore</code> :</p> Bash<pre><code>git clean -fdx\n</code></pre> <p>Cela supprimera \u00e9galement <code>node_modules/</code>.</p>"},{"location":"_projects/_formation-git/git-chap04/#considerations-importantes","title":"\u26a0\ufe0f Consid\u00e9rations importantes","text":"<p><code>git clean</code> constitue une op\u00e9ration irr\u00e9versible. Les fichiers supprim\u00e9s ne peuvent pas \u00eatre r\u00e9cup\u00e9r\u00e9s via Git. Il est donc imp\u00e9ratif d'utiliser syst\u00e9matiquement l'option <code>-n</code> avant d'appliquer une suppression effective.</p>"},{"location":"_projects/_formation-git/git-chap04/#git-revert","title":"\u21a9\ufe0f git revert","text":""},{"location":"_projects/_formation-git/git-chap04/#concept-fondamental_1","title":"Concept fondamental","text":"<p><code>git revert</code> est une commande d'annulation avant (forward-undo) qui cr\u00e9e un nouveau commit contenant les modifications inverses d'un commit sp\u00e9cifique, sans modifier l'historique existant.[1][6] Contrairement \u00e0 <code>git reset</code>, <code>git revert</code> pr\u00e9serve l'historique complet et est consid\u00e9r\u00e9e comme une approche plus s\u00fbre pour annuler les changements dans les branches partag\u00e9es.[6]</p>"},{"location":"_projects/_formation-git/git-chap04/#avantages-et-contexte-dutilisation","title":"Avantages et contexte d'utilisation","text":"<p>Avantages de <code>git revert</code> : - Pr\u00e9serve l'historique complet des commits - Convient id\u00e9alement pour les commits d\u00e9j\u00e0 pouss\u00e9s sur des branches partag\u00e9es - Cr\u00e9e une trace visible des annulations - Permet la collaboration sans risque de r\u00e9\u00e9criture d'historique conflictuelle</p> <p>Contextes d'utilisation optimaux : - Annuler les changements d'un commit dans une branche de production - Corriger une erreur commise par un autre d\u00e9veloppeur sans lui imposer une r\u00e9\u00e9criture d'historique - Maintenir une tra\u00e7abilit\u00e9 compl\u00e8te de toutes les modifications</p>"},{"location":"_projects/_formation-git/git-chap04/#syntaxe-de-base","title":"Syntaxe de base","text":"Bash<pre><code>git revert &lt;commit-id&gt;\n</code></pre> <p>O\u00f9 <code>&lt;commit-id&gt;</code> repr\u00e9sente l'identifiant du commit dont les modifications doivent \u00eatre invers\u00e9es.</p>"},{"location":"_projects/_formation-git/git-chap04/#processus-detaille-dun-revert","title":"Processus d\u00e9taill\u00e9 d'un revert","text":"<p>Lors de l'ex\u00e9cution de <code>git revert</code>, Git effectue les \u00e9tapes suivantes :</p> <ol> <li>Identifie les modifications introduites par le commit sp\u00e9cifi\u00e9</li> <li>Cr\u00e9e les modifications inverses (les changements qui annuleraient exactement ceux du commit original)</li> <li>Ouvre un \u00e9diteur pour permettre la modification du message de commit</li> <li>Cr\u00e9e un nouveau commit contenant ces modifications inverses</li> </ol>"},{"location":"_projects/_formation-git/git-chap04/#exemple-pratique-detaille","title":"Exemple pratique d\u00e9taill\u00e9","text":"<p>Supposant l'historique de commits suivant :</p> Text Only<pre><code>commit 3d4e5f6 (HEAD -&gt; main)\n\u2502   Message: Ajout de la fonctionnalit\u00e9 de paiement\n\u2502   Fichiers modifi\u00e9s: payment.js, checkout.js\n\ncommit 2c3d4e5\n\u2502   Message: Correction de bugs de validation\n\u2502   Fichiers modifi\u00e9s: validation.js\n\ncommit 1b2c3d4\n\u2502   Message: Configuration initiale\n\u2502   Fichiers modifi\u00e9s: config.js\n</code></pre> <p>Sc\u00e9nario : Il est d\u00e9couvert que la fonctionnalit\u00e9 de paiement introduit un bug critique en production.</p> <p>\u00c9tape 1 : Ex\u00e9cution du revert</p> Bash<pre><code>git revert 3d4e5f6\n</code></pre> <p>\u00c9tape 2 : Git ouvre l'\u00e9diteur par d\u00e9faut</p> <p>Le message de commit pr\u00e9rempli appara\u00eet :</p> Text Only<pre><code>Revert \"Ajout de la fonctionnalit\u00e9 de paiement\"\n\nThis reverts commit 3d4e5f6.\n</code></pre> <p>\u00c9tape 3 : Acceptation ou modification du message</p> <p>Si le message par d\u00e9faut convient, il suffit de sauvegarder et quitter l'\u00e9diteur (<code>:wq</code> dans vim).</p> <p>\u00c9tape 4 : R\u00e9sultat de l'op\u00e9ration</p> <p>Un nouveau commit est cr\u00e9\u00e9 :</p> Text Only<pre><code>commit 4e5f6a7 (HEAD -&gt; main)\n\u2502   Message: Revert \"Ajout de la fonctionnalit\u00e9 de paiement\"\n\u2502   \ncommit 3d4e5f6\n\u2502   Message: Ajout de la fonctionnalit\u00e9 de paiement\n\u2502   \ncommit 2c3d4e5\n\u2502   Message: Correction de bugs de validation\n</code></pre> <p>Les fichiers <code>payment.js</code> et <code>checkout.js</code> sont revenus \u00e0 leur \u00e9tat du commit <code>2c3d4e5</code>.</p>"},{"location":"_projects/_formation-git/git-chap04/#gestion-des-conflits-lors-dun-revert","title":"Gestion des conflits lors d'un revert","text":"<p>Si les modifications \u00e0 inverser entrent en conflit avec l'\u00e9tat actuel du code :</p> Bash<pre><code>git revert &lt;commit-id&gt;\n# Git signale des conflits de fusion\n</code></pre> <p>L'utilisateur doit alors :</p> <ol> <li>Ouvrir les fichiers en conflit et r\u00e9soudre manuellement les divergences</li> <li>Ajouter les fichiers r\u00e9solus \u00e0 l'index :</li> </ol> Bash<pre><code>git add &lt;fichier-r\u00e9solu&gt;\n</code></pre> <ol> <li>Poursuivre l'op\u00e9ration de revert :</li> </ol> Bash<pre><code>git revert --continue\n</code></pre> <p>Si l'op\u00e9ration devient trop complexe, il est possible d'abandonner :</p> Bash<pre><code>git revert --abort\n</code></pre>"},{"location":"_projects/_formation-git/git-chap04/#revert-de-plusieurs-commits","title":"Revert de plusieurs commits","text":"<p>Pour inverser les modifications de plusieurs commits cons\u00e9cutifs :</p> Bash<pre><code>git revert --no-edit 3d4e5f6 2c3d4e5\n</code></pre> <p>L'option <code>--no-edit</code> supprime la demande d'\u00e9dition du message de commit, utilisant le message par d\u00e9faut g\u00e9n\u00e9r\u00e9 par Git.</p>"},{"location":"_projects/_formation-git/git-chap04/#comparaison-visuelle-etat-avant-et-apres-revert","title":"Comparaison visuelle : \u00c9tat avant et apr\u00e8s revert","text":"Aspect Avant revert Apr\u00e8s revert Historique Commit contenant le bug Commit + commit d'annulation \u00c9tat du code Bug pr\u00e9sent Bug annul\u00e9 Fichiers modifi\u00e9s payment.js, checkout.js payment.js, checkout.js (invers\u00e9s) Tra\u00e7abilit\u00e9 \u274c Aucune trace de l'annulation \u2705 Trace visible du revert"},{"location":"_projects/_formation-git/git-chap04/#git-checkout","title":"\ud83d\udd04 git checkout","text":""},{"location":"_projects/_formation-git/git-chap04/#concept-fondamental_2","title":"Concept fondamental","text":"<p><code>git checkout</code> est une commande polyvalente permettant de naviguer entre les branches et de restaurer les fichiers \u00e0 un \u00e9tat ant\u00e9rieur.[1][2][3] Dans le contexte de l'annulation de modifications, elle s'utilise principalement pour abandonner les changements non commit\u00e9es d'un fichier, le restaurant \u00e0 sa derni\u00e8re version valid\u00e9e.[2]</p>"},{"location":"_projects/_formation-git/git-chap04/#champs-dapplication","title":"Champs d'application","text":"<p><code>git checkout</code> poss\u00e8de trois usages distincts :</p> <p>1. Changement de branche Bash<pre><code>git checkout &lt;nom-branche&gt;\n</code></pre></p> <p>2. Cr\u00e9ation et changement de branche Bash<pre><code>git checkout -b &lt;nom-nouvelle-branche&gt;\n</code></pre></p> <p>3. Restauration de fichiers (annulation de modifications) Bash<pre><code>git checkout -- &lt;fichier&gt;\n</code></pre></p>"},{"location":"_projects/_formation-git/git-chap04/#restauration-de-fichiers-non-commitees","title":"Restauration de fichiers non commit\u00e9es","text":"<p>La syntaxe compl\u00e8te pour annuler les modifications d'un fichier non encore committ\u00e9 est :</p> Bash<pre><code>git checkout -- &lt;nom-fichier&gt;\n</code></pre> <p>Cette op\u00e9ration restaure instantan\u00e9ment le fichier \u00e0 sa version dans le dernier commit, \u00e9liminant toutes les modifications locales non stag\u00e9es.</p>"},{"location":"_projects/_formation-git/git-chap04/#exemple-pratique-detaille_1","title":"Exemple pratique d\u00e9taill\u00e9","text":"<p>Sc\u00e9nario initial :</p> <p>Un fichier <code>app.js</code> a \u00e9t\u00e9 modifi\u00e9 mais non encore ajout\u00e9 \u00e0 l'index (staging area).</p> JavaScript<pre><code>// Contenu initial (dernier commit)\nfunction helloWorld() {\n  console.log(\"Hello\");\n}\n</code></pre> <p>Les modifications effectu\u00e9es :</p> JavaScript<pre><code>// Modifications apport\u00e9es mais non commit\u00e9es\nfunction helloWorld() {\n  console.log(\"Hello World\");\n  console.log(\"This is wrong\"); // Modification accidentelle\n  return undefined; // Erreur logique\n}\n</code></pre> <p>\u00c9tape 1 : V\u00e9rification du statut</p> Bash<pre><code>git status\n</code></pre> <p>Sortie : Text Only<pre><code>Sur la branche main\n\nModifications qui ne seront pas valid\u00e9es:\n  (utilisez \"git add &lt;fichier&gt;...\" pour mettre \u00e0 jour ce qui sera valid\u00e9)\n  (utilisez \"git checkout -- &lt;fichier&gt;...\" pour annuler les modifications dans la copie de travail)\n\n  modifi\u00e9 : app.js\n</code></pre></p> <p>\u00c9tape 2 : Annulation des modifications</p> Bash<pre><code>git checkout -- app.js\n</code></pre> <p>\u00c9tape 3 : V\u00e9rification du r\u00e9sultat</p> Bash<pre><code>git status\n</code></pre> <p>Sortie : Text Only<pre><code>Sur la branche main\nRien \u00e0 valider, r\u00e9pertoire de travail propre\n</code></pre></p> <p>Le fichier <code>app.js</code> contient maintenant sa version originale :</p> JavaScript<pre><code>function helloWorld() {\n  console.log(\"Hello\");\n}\n</code></pre>"},{"location":"_projects/_formation-git/git-chap04/#restauration-depuis-un-commit-specifique","title":"Restauration depuis un commit sp\u00e9cifique","text":"<p>Pour restaurer un fichier \u00e0 partir d'un commit ant\u00e9rieur sp\u00e9cifique (pas seulement le dernier commit) :</p> Bash<pre><code>git checkout &lt;commit-id&gt; -- &lt;nom-fichier&gt;\n</code></pre> <p>Exemple concret :</p> Bash<pre><code>git checkout abc1234 -- config.js\n</code></pre> <p>Cette commande restaure <code>config.js</code> \u00e0 son \u00e9tat tel qu'il existait dans le commit <code>abc1234</code>, et place cette version dans l'index et le r\u00e9pertoire de travail.</p>"},{"location":"_projects/_formation-git/git-chap04/#restauration-multiple-de-fichiers","title":"Restauration multiple de fichiers","text":"<p>Pour annuler les modifications de plusieurs fichiers simultan\u00e9ment :</p> Bash<pre><code>git checkout -- fichier1.js fichier2.js fichier3.js\n</code></pre> <p>Ou pour annuler tous les fichiers modifi\u00e9s non stag\u00e9s :</p> Bash<pre><code>git checkout -- .\n</code></pre>"},{"location":"_projects/_formation-git/git-chap04/#danger-et-irreversibilite","title":"\u26a0\ufe0f Danger et irr\u00e9versibilit\u00e9","text":"<p><code>git checkout</code> constitue une op\u00e9ration destructive et irr\u00e9versible pour le fichier restaur\u00e9. Une fois ex\u00e9cut\u00e9e, les modifications locales non commit\u00e9es sont perdues d\u00e9finitivement et ne peuvent pas \u00eatre r\u00e9cup\u00e9r\u00e9es via Git. Il est recommand\u00e9 de v\u00e9rifier les modifications avant restauration :</p> Bash<pre><code>git diff &lt;nom-fichier&gt;\n</code></pre>"},{"location":"_projects/_formation-git/git-chap04/#transition-vers-les-commandes-modernes","title":"Transition vers les commandes modernes","text":"<p>Depuis Git 2.23, la commande <code>git restore</code> est l'approche privil\u00e9gi\u00e9e pour restaurer les fichiers :[3]</p> Bash<pre><code>git restore &lt;nom-fichier&gt;\n</code></pre> <p>Bien que <code>git checkout</code> reste fonctionnelle, <code>git restore</code> offre une interface plus explicite et d\u00e9di\u00e9e \u00e0 cette op\u00e9ration.</p>"},{"location":"_projects/_formation-git/git-chap04/#branche-master-et-head","title":"\ud83c\udfaf Branche master et HEAD","text":""},{"location":"_projects/_formation-git/git-chap04/#concept-de-head","title":"Concept de HEAD","text":"<p>HEAD est un pointeur sp\u00e9cial dans Git qui indique toujours le commit actuellement actif dans le r\u00e9pertoire de travail.[1] Il agit comme une r\u00e9f\u00e9rence mobile marquant le point actuel dans l'historique de commits, permettant \u00e0 Git de savoir o\u00f9 se trouve l'utilisateur dans l'arborescence du projet.</p>"},{"location":"_projects/_formation-git/git-chap04/#structure-conceptuelle","title":"Structure conceptuelle","text":"Text Only<pre><code>Historique de commits :\n\ncommit 4f5e6g7 (main)\n\u251c\u2500\u2500 commit 3d4e5f6\n\u251c\u2500\u2500 commit 2c3d4e5\n\u2514\u2500\u2500 commit 1b2c3d4 (branche initiale)\n\nHEAD \u2192 pointe g\u00e9n\u00e9ralement vers le dernier commit de la branche active\n</code></pre>"},{"location":"_projects/_formation-git/git-chap04/#branche-master-vs-main","title":"Branche master vs main","text":"<p>Historiquement, Git cr\u00e9ait une branche par d\u00e9faut nomm\u00e9e master. Depuis 2020, cette convention a chang\u00e9, et la branche par d\u00e9faut s'appelle d\u00e9sormais main. Cette modification refl\u00e8te un choix dans le secteur technologique pour utiliser une terminologie plus inclusive.[1]</p>"},{"location":"_projects/_formation-git/git-chap04/#cas-dusage-pratiques_1","title":"Cas d'usage pratiques","text":"<p>Situation 1 : D\u00e9terminer la position actuelle</p> Bash<pre><code>git log -1 --oneline\n</code></pre> <p>Affiche le commit vers lequel HEAD pointe actuellement.</p> <p>Sortie exemple : Text Only<pre><code>3d4e5f6 (HEAD -&gt; main) Ajout de la fonctionnalit\u00e9 utilisateur\n</code></pre></p> <p>Situation 2 : D\u00e9tacher HEAD (detached HEAD state)</p> <p>Lorsqu'on bascule vers un commit sp\u00e9cifique plut\u00f4t qu'une branche :</p> Bash<pre><code>git checkout abc1234\n</code></pre> <p>HEAD se d\u00e9tache alors de la branche et pointe directement le commit <code>abc1234</code>. Cet \u00e9tat permet d'explorer l'historique mais rend les commits futurs inaccessibles s'ils ne sont pas int\u00e9gr\u00e9s \u00e0 une branche.</p> <p>Situation 3 : Retourner \u00e0 la branche</p> Bash<pre><code>git checkout main\n</code></pre> <p>HEAD redevient une branche au lieu de pointer directement un commit.</p>"},{"location":"_projects/_formation-git/git-chap04/#references-relatives-a-head","title":"R\u00e9f\u00e9rences relatives \u00e0 HEAD","text":"<p>Git permet d'utiliser des notations relatives pour r\u00e9f\u00e9rencer des commits par rapport \u00e0 HEAD :</p> Notation Signification Exemple <code>HEAD</code> Commit actuel <code>git reset HEAD</code> <code>HEAD^</code> Commit parent direct <code>git reset HEAD^</code> <code>HEAD~1</code> Commit parent (\u00e9quivalent \u00e0 HEAD^) <code>git reset HEAD~1</code> <code>HEAD~2</code> Grand-parent du commit <code>git reset HEAD~2</code> <code>HEAD~n</code> n commits avant HEAD <code>git reset HEAD~5</code>"},{"location":"_projects/_formation-git/git-chap04/#representation-visuelle","title":"Repr\u00e9sentation visuelle","text":"Text Only<pre><code>Timeline des commits :\n\nHEAD~3 : commit abc1234 (Initialisation du projet)\n         \u2193\nHEAD~2 : commit bcd2345 (Premier feature)\n         \u2193\nHEAD~1 : commit cde3456 (Correction bug)\n         \u2193\nHEAD   : commit def4567 (Derni\u00e8re modification)\n</code></pre>"},{"location":"_projects/_formation-git/git-chap04/#verification-de-la-position-de-head","title":"V\u00e9rification de la position de HEAD","text":"Bash<pre><code>cat .git/HEAD\n</code></pre> <p>Sortie si HEAD pointe vers une branche : Text Only<pre><code>ref: refs/heads/main\n</code></pre></p> <p>Sortie si HEAD est d\u00e9tach\u00e9 : Text Only<pre><code>abc1234567890def\n</code></pre></p>"},{"location":"_projects/_formation-git/git-chap04/#implication-pour-les-operations-dannulation","title":"Implication pour les op\u00e9rations d'annulation","text":"<p>Les commandes <code>git reset</code> et <code>git checkout</code> utilisent extensively les concepts de HEAD et de branche. Comprendre ces m\u00e9canismes est essentiel pour : - Annuler pr\u00e9cis\u00e9ment les commits d\u00e9sir\u00e9s - Naviguer dans l'historique - R\u00e9cup\u00e9rer des versions ant\u00e9rieures de fichiers</p>"},{"location":"_projects/_formation-git/git-chap04/#git-reset","title":"\ud83d\udd19 git reset","text":""},{"location":"_projects/_formation-git/git-chap04/#concept-fondamental_3","title":"Concept fondamental","text":"<p><code>git reset</code> est une commande puissante permettant de revenir \u00e0 un commit sp\u00e9cifique, tout en offrant diff\u00e9rentes options concernant le destin des modifications ult\u00e9rieures.[1][2][8] Contrairement \u00e0 <code>git revert</code>, <code>git reset</code> modifie directement l'historique, ce qui la rend potentiellement dangereuse dans les contextes de collaboration.[2]</p>"},{"location":"_projects/_formation-git/git-chap04/#trois-modes-de-fonctionnement","title":"Trois modes de fonctionnement","text":"<p><code>git reset</code> propose trois modes distincts, chacun modifiant diff\u00e9rentes zones du workflow Git :</p>"},{"location":"_projects/_formation-git/git-chap04/#1-mode-soft","title":"1. Mode --soft","text":"Bash<pre><code>git reset --soft &lt;commit-id&gt;\n</code></pre> <p>Effet : - HEAD pointe vers le commit sp\u00e9cifi\u00e9 - Les modifications des commits annul\u00e9s restent en staging area (index) - Le r\u00e9pertoire de travail n'est pas modifi\u00e9</p> <p>Cas d'usage : Regrouper plusieurs commits en un seul ou reorganiser les commits avant de cr\u00e9er une version finale.</p> <p>Exemple pratique :</p> <p>Supposant trois commits \u00e0 regrouper :</p> Text Only<pre><code>commit c : Ajout de fonction A\ncommit b : Ajout de fonction B\ncommit a : Initialisation\n</code></pre> Bash<pre><code>git reset --soft a\n</code></pre> <p>R\u00e9sultat : - HEAD pointe vers commit <code>a</code> - Les modifications de commits <code>b</code> et <code>c</code> se trouvent en staging area - Cr\u00e9er un nouveau commit regroup\u00e9 :</p> Bash<pre><code>git commit -m \"Ajout des fonctions A et B\"\n</code></pre>"},{"location":"_projects/_formation-git/git-chap04/#2-mode-mixed-par-defaut","title":"2. Mode --mixed (par d\u00e9faut)","text":"Bash<pre><code>git reset --mixed &lt;commit-id&gt;\n# \u00c9quivalent \u00e0 git reset &lt;commit-id&gt;\n</code></pre> <p>Effet : - HEAD pointe vers le commit sp\u00e9cifi\u00e9 - Les modifications des commits annul\u00e9s sont plac\u00e9es dans le r\u00e9pertoire de travail (non stag\u00e9es) - L'index est r\u00e9initialis\u00e9</p> <p>Cas d'usage : Annuler l'ajout de fichiers \u00e0 l'index tout en conservant les modifications en local pour r\u00e9vision.</p> <p>Exemple pratique :</p> Bash<pre><code># \u00c9tat actuel : fichier.txt modifi\u00e9 et stag\u00e9\ngit add fichier.txt\ngit status\n\n# Affiche :\n# Modifications qui seront valid\u00e9es:\n#   modifi\u00e9: fichier.txt\n</code></pre> <p>Ex\u00e9cution du reset en mode mixed :</p> Bash<pre><code>git reset HEAD fichier.txt\n</code></pre> <p>R\u00e9sultat :</p> Bash<pre><code>git status\n\n# Affiche :\n# Modifications qui ne seront pas valid\u00e9es:\n#   modifi\u00e9: fichier.txt\n</code></pre> <p>Le fichier reste modifi\u00e9 dans le r\u00e9pertoire de travail mais n'est plus stag\u00e9.</p>"},{"location":"_projects/_formation-git/git-chap04/#3-mode-hard","title":"3. Mode --hard","text":"Bash<pre><code>git reset --hard &lt;commit-id&gt;\n</code></pre> <p>Effet : - HEAD pointe vers le commit sp\u00e9cifi\u00e9 - L'index est r\u00e9initialis\u00e9 - Le r\u00e9pertoire de travail est enti\u00e8rement remplac\u00e9 par l'\u00e9tat du commit cible - Toutes les modifications locales non commit\u00e9es sont perdues irr\u00e9versiblement[2][4]</p> <p>Cas d'usage : Supprimer compl\u00e8tement tous les changements locaux et revenir \u00e0 un \u00e9tat stable connu.</p> <p>\u26a0\ufe0f Avertissement critique : C'est le mode le plus dangereux. Les modifications perdues ne peuvent pas \u00eatre r\u00e9cup\u00e9r\u00e9es via Git.</p>"},{"location":"_projects/_formation-git/git-chap04/#exemple-detaille-git-reset-hard","title":"Exemple d\u00e9taill\u00e9 : git reset --hard","text":"<p>Situation initiale :</p> JavaScript<pre><code>// index.js (derni\u00e8re version commit\u00e9e)\nvar nom = \"Henrique\";\nconsole.log(\"Salut, tout le monde\");\n</code></pre> <p>Modifications effectu\u00e9es (non commit\u00e9es) :</p> JavaScript<pre><code>// index.js (modifications en cours)\nvar nom = \"Henrique\";\nconsole.log(\"Salut, tout le monde\");\nconsole.log(\"Une ligne\");\n</code></pre> <p>V\u00e9rification pr\u00e9alable :</p> Bash<pre><code>git status\n</code></pre> <p>R\u00e9sultat : Text Only<pre><code>Modifications qui ne seront pas valid\u00e9es:\n  modifi\u00e9: index.js\n</code></pre></p> <p>Ex\u00e9cution du reset --hard :</p> Bash<pre><code>git reset --hard\n</code></pre> <p>R\u00e9sultat :</p> <p>Le fichier <code>index.js</code> revient instantan\u00e9ment \u00e0 son \u00e9tat du dernier commit :</p> JavaScript<pre><code>var nom = \"Henrique\";\nconsole.log(\"Salut, tout le monde\");\n// La ligne \"Une ligne\" a \u00e9t\u00e9 supprim\u00e9e d\u00e9finitivement\n</code></pre>"},{"location":"_projects/_formation-git/git-chap04/#comparaison-des-trois-modes","title":"Comparaison des trois modes","text":"Mode \u00c9tat de HEAD \u00c9tat de l'index \u00c9tat du r\u00e9pertoire Utilisation --soft Chang\u00e9 Inchang\u00e9 Inchang\u00e9 Regrouper des commits --mixed Chang\u00e9 R\u00e9initialis\u00e9 Inchang\u00e9 Destagner des fichiers --hard Chang\u00e9 R\u00e9initialis\u00e9 Remplac\u00e9 \u00c9liminer tous les changements"},{"location":"_projects/_formation-git/git-chap04/#annulation-de-commits-specifiques","title":"Annulation de commits sp\u00e9cifiques","text":"<p>Pour revenir \u00e0 un commit ant\u00e9rieur tout en conservant les modifications ult\u00e9rieures en tant que modifications locales :</p> Bash<pre><code>git reset &lt;commit-id&gt;\n</code></pre> <p>Exemple concret :</p> <p>L'historique actuel :</p> Text Only<pre><code>commit d : Derni\u00e8re modification (HEAD)\ncommit c : Modification interm\u00e9diaire\ncommit b : Modification ant\u00e9rieure\ncommit a : Initialisation\n</code></pre> <p>Pour revenir au commit <code>b</code> tout en conservant les modifications des commits <code>c</code> et <code>d</code> :</p> Bash<pre><code>git reset b\n</code></pre> <p>R\u00e9sultat : - HEAD pointe vers commit <code>b</code> - Les changements des commits <code>c</code> et <code>d</code> se trouvent dans le r\u00e9pertoire de travail en tant que modifications non stag\u00e9es - Ceci permet de retravailler et revalider ces modifications diff\u00e9remment</p>"},{"location":"_projects/_formation-git/git-chap04/#difference-cruciale-entre-reset-et-revert","title":"Diff\u00e9rence cruciale entre reset et revert","text":"Aspect git reset git revert Historique R\u00e9\u00e9criture (commits supprim\u00e9s) Pr\u00e9servation (nouveau commit ajout\u00e9) S\u00e9curit\u00e9 collaborative \u274c Dangereux \u2705 S\u00fbr Tra\u00e7abilit\u00e9 \u274c Perte d'information \u2705 Trace visible Cas d'usage Branches priv\u00e9es Branches partag\u00e9es, production"},{"location":"_projects/_formation-git/git-chap04/#recuperation-apres-un-reset-mal-place","title":"R\u00e9cup\u00e9ration apr\u00e8s un reset mal plac\u00e9","text":"<p>Si un <code>git reset --hard</code> a supprim\u00e9 des modifications importantes, il existe une possibilit\u00e9 de r\u00e9cup\u00e9ration via <code>git reflog</code> :</p> Bash<pre><code>git reflog\n</code></pre> <p>Cette commande affiche l'historique de tous les mouvements de HEAD, permettant potentiellement de retrouver les commits perdus.</p> <p>Exemple de reflog :</p> Text Only<pre><code>abc1234 HEAD@{0}: reset: moving to abc1234\ndef4567 HEAD@{1}: commit: Modification importante\nghi7890 HEAD@{2}: commit: Feature ajout\u00e9e\n</code></pre> <p>Pour restaurer un \u00e9tat ant\u00e9rieur :</p> Bash<pre><code>git reset --hard def4567\n</code></pre>"},{"location":"_projects/_formation-git/git-chap04/#interaction-entre-les-commandes","title":"\ud83d\uddc2\ufe0f Interaction entre les commandes","text":""},{"location":"_projects/_formation-git/git-chap04/#arbre-de-decision-pour-lannulation","title":"Arbre de d\u00e9cision pour l'annulation","text":"Text Only<pre><code>Besoin d'annulation ?\n\u2502\n\u251c\u2500 Fichiers non suivis \u00e0 supprimer ?\n\u2502  \u2514\u2500&gt; git clean\n\u2502\n\u251c\u2500 Modifications non commit\u00e9es \u00e0 annuler ?\n\u2502  \u251c\u2500 Pour un fichier sp\u00e9cifique ?\n\u2502  \u2502  \u2514\u2500&gt; git checkout -- &lt;fichier&gt;\n\u2502  \u2514\u2500 Pour tous les fichiers ?\n\u2502     \u2514\u2500&gt; git reset --hard\n\u2502\n\u251c\u2500 Commit \u00e0 annuler dans une branche partag\u00e9e ?\n\u2502  \u2514\u2500&gt; git revert &lt;commit-id&gt;\n\u2502\n\u2514\u2500 Commit \u00e0 annuler dans une branche priv\u00e9e ?\n   \u251c\u2500 Supprimer compl\u00e8tement le commit ?\n   \u2502  \u2514\u2500&gt; git reset --hard &lt;commit-id&gt;\n   \u2514\u2500 Garder les modifications localement ?\n      \u2514\u2500&gt; git reset &lt;commit-id&gt;\n</code></pre>"},{"location":"_projects/_formation-git/git-chap04/#scenario-complexe-correction-multi-etape","title":"Sc\u00e9nario complexe : Correction multi-\u00e9tape","text":"<p>Situation : Un d\u00e9veloppeur a effectu\u00e9 trois commits, r\u00e9alise que le deuxi\u00e8me commit contient une erreur, mais veut conserver les modifications du troisi\u00e8me.</p> <p>\u00c9tape 1 : Identifier l'historique</p> Bash<pre><code>git log --oneline -3\n</code></pre> <p>R\u00e9sultat : Text Only<pre><code>def4567 (HEAD) Commit 3 - Fonctionnalit\u00e9 finale\nabc1234 Commit 2 - Correction avec erreur\n789defg Commit 1 - Initialisation\n</code></pre></p> <p>\u00c9tape 2 : R\u00e9initialiser jusqu'au commit 1</p> Bash<pre><code>git reset 789defg\n</code></pre> <p>\u00c9tat apr\u00e8s reset : - HEAD pointe vers <code>789defg</code> - Modifications des commits 2 et 3 sont dans le r\u00e9pertoire de travail</p> <p>\u00c9tape 3 : Examiner et corriger les modifications</p> Bash<pre><code>git status\n</code></pre> <p>Affiche les fichiers modifi\u00e9s provenant des commits annul\u00e9s.</p> <p>Correction manuelle des fichiers : la modification erron\u00e9e est supprim\u00e9e, les modifications valides du commit 3 sont conserv\u00e9es.</p> <p>\u00c9tape 4 : Revalider proprement</p> Bash<pre><code>git add .\ngit commit -m \"Commit 2 - Correction (version corrig\u00e9e)\"\ngit commit -m \"Commit 3 - Fonctionnalit\u00e9 finale\"\n</code></pre> <p>R\u00e9sultat :</p> Text Only<pre><code>ghi8901 (HEAD) Commit 3 - Fonctionnalit\u00e9 finale (revalid\u00e9)\nhij9012 Commit 2 - Correction (version corrig\u00e9e)\n789defg Commit 1 - Initialisation\n</code></pre>"},{"location":"_projects/_formation-git/git-chap04/#tableau-recapitulatif-complet","title":"\ud83d\udccb Tableau r\u00e9capitulatif complet","text":"Commande Objectif Pr\u00e9serve l'historique S\u00fbre en collaboration R\u00e9cup\u00e9ration Cas d'usage git clean Supprimer fichiers non suivis N/A \u2705 \u274c Nettoyer le workspace git revert Annuler changements commit\u00e9es \u2705 \u2705 \u2705 Production, branches partag\u00e9es git checkout -- Annuler modifications non commit\u00e9es \u2705 \u2705 \u26a0\ufe0f Diff\u00e8re Fichier sp\u00e9cifique modifi\u00e9 git reset --soft Rejouer commits \u2705 \u26a0\ufe0f \u2705 Regrouper commits git reset --mixed Destagner, garder modifications \u2705 \u26a0\ufe0f \u2705 Retirer fichier de staging git reset --hard Revenir complet \u00e0 un commit \u274c \u274c \u26a0\ufe0f Via reflog Branche priv\u00e9e, nettoyage total"},{"location":"_projects/_formation-git/git-chap04/#synthese-du-parcours-dapprentissage","title":"\ud83c\udf93 Synth\u00e8se du parcours d'apprentissage","text":""},{"location":"_projects/_formation-git/git-chap04/#phase-1-fondamentaux-de-la-securite","title":"Phase 1 : Fondamentaux de la s\u00e9curit\u00e9","text":"<p>Commencer par git clean et git checkout -- pour comprendre comment annuler des modifications sans risque majeur. Ces commandes s'appliquent \u00e0 des modifications non commit\u00e9es, offrant un espace d'apprentissage s\u00fbr avant de modifier l'historique.</p>"},{"location":"_projects/_formation-git/git-chap04/#phase-2-comprehension-de-larchitecture","title":"Phase 2 : Compr\u00e9hension de l'architecture","text":"<p>\u00c9tudier HEAD et la structure des branches pour saisir comment Git organise les commits. Cette compr\u00e9hension conceptuelle est essentielle avant de manipuler l'historique.</p>"},{"location":"_projects/_formation-git/git-chap04/#phase-3-annulation-inverse-et-preservation","title":"Phase 3 : Annulation inverse et pr\u00e9servation","text":"<p>Ma\u00eetriser git revert pour apprendre l'approche recommand\u00e9e d'annulation des changements qui pr\u00e9serve compl\u00e8tement l'historique. C'est l'outil privil\u00e9gi\u00e9 pour la collaboration.</p>"},{"location":"_projects/_formation-git/git-chap04/#phase-4-manipulation-dhistorique-avancee","title":"Phase 4 : Manipulation d'historique avanc\u00e9e","text":"<p>Progresser vers git reset pour comprendre comment modifier v\u00e9ritablement l'historique. Apprendre les trois modes progressivement : soft, mixed, puis hard, en prenant conscience des risques croissants.</p>"},{"location":"_projects/_formation-git/git-chap04/#phase-5-integration-et-bonnes-pratiques","title":"Phase 5 : Int\u00e9gration et bonnes pratiques","text":"<p>Combiner les connaissances pour choisir l'outil appropri\u00e9 selon le contexte. D\u00e9velopper l'intuition sur quand utiliser chaque commande et comment r\u00e9cup\u00e9rer en cas d'erreur.</p> <p>Ce parcours progressif garantit une compr\u00e9hension solide des m\u00e9canismes d'annulation dans Git, des op\u00e9rations simples et s\u00fbres aux manipulations complexes d'historique, en passant par les nuances architecturales du syst\u00e8me de versioning.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-git/git-chap05/","title":"Citations","text":"<ul> <li>https://www.youtube.com/watch?v=iZ55m9ieSCo</li> <li>https://www.hostinger.com/fr/tutoriels/comment-utiliser-une-branche-git</li> <li>https://www.datacamp.com/fr/tutorial/git-branch</li> <li>https://www.varonis.com/fr/blog/git-branching</li> <li>https://git-scm.com/docs/git-branch/fr</li> <li>https://git-scm.com/book/fr/v2/Les-branches-avec-Git-Les-branches-en-bref</li> <li>https://lutece.paris.fr/support/wiki/git.html</li> <li>https://www.atlassian.com/fr/agile/software-development/branching</li> <li>https://git-scm.com/book/fr/v2/Les-branches-avec-Git-Branches-et-fusions%C2%A0:-les-bases</li> </ul>"},{"location":"_projects/_formation-git/git-chap05/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 279</li> <li>completion_tokens: 5181</li> <li>total_tokens: 5460</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.078, 'request_cost': 0.006, 'total_cost': 0.085}</li> </ul>"},{"location":"_projects/_formation-git/git-chap05/#content","title":"Content","text":""},{"location":"_projects/_formation-git/git-chap05/#chapitre-5-les-branches","title":"Chapitre 5 : Les branches \ud83c\udf33","text":""},{"location":"_projects/_formation-git/git-chap05/#introduction-aux-branches","title":"Introduction aux branches","text":"<p>Une branche dans Git repr\u00e9sente une ligne de d\u00e9veloppement ind\u00e9pendante permettant de travailler sur des fonctionnalit\u00e9s, des correctifs ou des exp\u00e9riences sans affecter le code principal. Contrairement aux syst\u00e8mes de contr\u00f4le de version plus anciens, les branches dans Git ne sont pas des dossiers s\u00e9par\u00e9s ni des copies compl\u00e8tes du code source[3]. Au lieu de cela, une branche Git n'est qu'un pointeur l\u00e9ger vers un commit particulier[3].</p> <p>Lorsqu'un commit est cr\u00e9\u00e9, Git identifie cet instantan\u00e9 de fichiers avec un hachage SHA-1 unique. Lors de la cr\u00e9ation d'une branche, Git cr\u00e9e simplement un nouveau pointeur vers le m\u00eame commit sur lequel la branche principale se trouve actuellement[4]. Cette architecture l\u00e9g\u00e8re rend les branches extr\u00eamement rapides et peu co\u00fbteuses \u00e0 cr\u00e9er, les rendant essentielles aux flux de travail quotidiens[3].</p>"},{"location":"_projects/_formation-git/git-chap05/#pourquoi-utiliser-des-branches","title":"Pourquoi utiliser des branches ?","text":"<p>Les branches permettent :</p> <ul> <li>De d\u00e9velopper des fonctionnalit\u00e9s en isolation sans perturber le code stable</li> <li>De corriger des bugs en parall\u00e8le du d\u00e9veloppement principal</li> <li>De collaborer efficacement en \u00e9quipe sur diff\u00e9rentes t\u00e2ches</li> <li>De tester des id\u00e9es nouvelles sans risque</li> <li>De maintenir plusieurs versions du projet simultan\u00e9ment</li> </ul>"},{"location":"_projects/_formation-git/git-chap05/#la-branche-principale","title":"La branche principale","text":"<p>La branche principale (appel\u00e9e main ou master) n'a rien de sp\u00e9cial dans la structure technique de Git[4]. C'est simplement la premi\u00e8re branche cr\u00e9\u00e9e lorsqu'un r\u00e9f\u00e9rentiel Git est initialis\u00e9 \u00e0 l'aide de la commande <code>git init</code>[4]. Par convention, cette branche contient le code stable et pr\u00eat pour la production.</p>"},{"location":"_projects/_formation-git/git-chap05/#lister-et-creer-des-branches-avec-git-branch","title":"Lister et cr\u00e9er des branches avec git branch","text":""},{"location":"_projects/_formation-git/git-chap05/#lister-les-branches-existantes","title":"Lister les branches existantes","text":"<p>Pour visualiser toutes les branches disponibles dans un projet Git, la commande suivante doit \u00eatre ex\u00e9cut\u00e9e[1][2] :</p> Bash<pre><code>git branch\n</code></pre> <p>Cette commande affiche la liste des branches locales. Git utilise un ast\u00e9risque (*) et une couleur diff\u00e9rente pour identifier la branche active, repr\u00e9sentant le pointeur HEAD indiquant quelle branche est actuellement active[4].</p> <p>Exemple de r\u00e9sultat terminal :</p> Text Only<pre><code>  develop\n* main\n  feature-login\n  bugfix-homepage\n</code></pre> <p>L'ast\u00e9risque indique que la branche main est la branche courante sur laquelle se trouvent les modifications.</p>"},{"location":"_projects/_formation-git/git-chap05/#creer-une-nouvelle-branche","title":"Cr\u00e9er une nouvelle branche","text":"<p>La cr\u00e9ation d'une branche est un processus simple. Pour cr\u00e9er une branche, la commande <code>git branch</code> doit \u00eatre utilis\u00e9e suivie du nom de la branche[1][2][4] :</p> Bash<pre><code>git branch nom-de-la-branche\n</code></pre> <p>Exemple pratique :</p> Bash<pre><code>git branch feature-authentification\n</code></pre> <p>Cette commande cr\u00e9e une nouvelle branche nomm\u00e9e <code>feature-authentification</code> \u00e0 partir du commit actuel. Cependant, cette op\u00e9ration ne bascule pas automatiquement vers la nouvelle branche[4]. La branche courante reste celle sur laquelle on se trouvait avant.</p>"},{"location":"_projects/_formation-git/git-chap05/#point-important-engagements-prealables","title":"Point important : Engagements pr\u00e9alables","text":"<p>Avant de cr\u00e9er des branches de d\u00e9veloppement, un commit doit d'abord \u00eatre effectu\u00e9 sur la branche principale pour que Git comprenne la structure de base du projet[2]. Sans au moins un commit initial, Git g\u00e9n\u00e8re une erreur lors de la tentative de cr\u00e9er une nouvelle branche.</p> <p>Processus recommand\u00e9 :</p> Bash<pre><code># 1. Initialiser le r\u00e9f\u00e9rentiel\ngit init\n\n# 2. Ajouter et committer des fichiers\ngit add .\ngit commit -m \"Commit initial\"\n\n# 3. Cr\u00e9er des branches\ngit branch feature-nouvelle-fonction\ngit branch bugfix-correctif\n</code></pre>"},{"location":"_projects/_formation-git/git-chap05/#creer-et-basculer-simultanement","title":"Cr\u00e9er et basculer simultan\u00e9ment","text":"<p>La cr\u00e9ation d'une branche peut \u00eatre combin\u00e9e avec le basculement vers celle-ci en une seule commande. Dans les versions r\u00e9centes de Git, la m\u00e9thode recommand\u00e9e est[3] :</p> Bash<pre><code>git switch -c nom-de-la-branche\n</code></pre> <p>Dans les versions plus anciennes de Git, la commande suivante \u00e9tait utilis\u00e9e :</p> Bash<pre><code>git checkout -b nom-de-la-branche\n</code></pre> <p>Exemple pratique :</p> Bash<pre><code>git switch -c feature-paiement\n</code></pre> <p>Cette op\u00e9ration cr\u00e9e la branche et y bascule imm\u00e9diatement, permettant de commencer \u00e0 travailler sans commandes suppl\u00e9mentaires.</p>"},{"location":"_projects/_formation-git/git-chap05/#creer-une-branche-a-partir-dune-autre-branche","title":"Cr\u00e9er une branche \u00e0 partir d'une autre branche","text":"<p>Pour cr\u00e9er une branche \u00e0 partir d'une autre branche (et non de la branche principale), il suffit de sp\u00e9cifier le nom de l'autre branche comme point de d\u00e9part[4] :</p> Bash<pre><code>git checkout -b feature4 develop\n</code></pre> <p>ou avec la syntaxe moderne :</p> Bash<pre><code>git switch -c feature4 develop\n</code></pre> <p>Cet exemple cr\u00e9e une branche feature4 bas\u00e9e sur la branche develop. Cette approche est particuli\u00e8rement utile pour les branches d\u00e9di\u00e9es aux correctifs de logiciel ou aux fonctionnalit\u00e9s construites sur d'autres branches.</p>"},{"location":"_projects/_formation-git/git-chap05/#basculer-entre-les-branches-avec-git-checkout","title":"Basculer entre les branches avec git checkout","text":""},{"location":"_projects/_formation-git/git-chap05/#comprendre-le-basculement-de-branche","title":"Comprendre le basculement de branche","text":"<p>Une fois plusieurs branches cr\u00e9\u00e9es, le basculement entre elles devient une op\u00e9ration courante. Git rend ce processus transparent et offre plusieurs fa\u00e7ons de l'accomplir[3].</p>"},{"location":"_projects/_formation-git/git-chap05/#basculer-vers-une-branche-existante","title":"Basculer vers une branche existante","text":"<p>Pour se d\u00e9placer vers une branche donn\u00e9e, la commande <code>git checkout</code> suivie du nom de la branche doit \u00eatre utilis\u00e9e[1] :</p> Bash<pre><code>git checkout nom-de-la-branche\n</code></pre> <p>Exemple pratique :</p> Bash<pre><code>git checkout develop\n</code></pre> <p>Cette commande bascule vers la branche develop. Le r\u00e9pertoire de travail se met \u00e0 jour pour refl\u00e9ter l'\u00e9tat du code sur cette branche.</p>"},{"location":"_projects/_formation-git/git-chap05/#verifier-la-branche-courante","title":"V\u00e9rifier la branche courante","text":"<p>Pour conna\u00eetre la branche active, la commande suivante peut \u00eatre ex\u00e9cut\u00e9e[1] :</p> Bash<pre><code>git status\n</code></pre> <p>La premi\u00e8re ligne de la sortie indique la branche courante :</p> Text Only<pre><code>On branch main\n</code></pre>"},{"location":"_projects/_formation-git/git-chap05/#basculer-et-creer-en-un-seul-geste","title":"Basculer et cr\u00e9er en un seul geste","text":"<p>Comme mentionn\u00e9 pr\u00e9c\u00e9demment, la cr\u00e9ation et le basculement peuvent \u00eatre combin\u00e9s[1][3] :</p> Bash<pre><code>git checkout -b nom-de-la-branche\n</code></pre> <p>ou avec la nouvelle syntaxe :</p> Bash<pre><code>git switch -c nom-de-la-branche\n</code></pre>"},{"location":"_projects/_formation-git/git-chap05/#differences-entre-checkout-et-switch","title":"Diff\u00e9rences entre checkout et switch","text":"Op\u00e9ration <code>git checkout</code> <code>git switch</code> Syntaxe moderne Ancienne approche Recommand\u00e9e Basculer vers une branche <code>git checkout branche</code> <code>git switch branche</code> Cr\u00e9er et basculer <code>git checkout -b branche</code> <code>git switch -c branche</code> Clart\u00e9 du but Multi-usage (d\u00e9fait aussi les fichiers) D\u00e9di\u00e9e au basculement <p>La commande <code>git switch</code> est plus intuitive car elle a un objectif unique : basculer entre les branches[3].</p>"},{"location":"_projects/_formation-git/git-chap05/#fusionner-des-branches-avec-git-merge","title":"Fusionner des branches avec git merge","text":""},{"location":"_projects/_formation-git/git-chap05/#concept-de-fusion","title":"Concept de fusion","text":"<p>La fusion (merge) est le processus qui combine les modifications de deux branches en une seule[1]. Apr\u00e8s avoir termin\u00e9 le travail sur une branche de fonctionnalit\u00e9 ou de correctif, ces changements doivent \u00eatre int\u00e9gr\u00e9s dans une autre branche, g\u00e9n\u00e9ralement la branche principale[3].</p>"},{"location":"_projects/_formation-git/git-chap05/#effectuer-une-fusion-simple","title":"Effectuer une fusion simple","text":"<p>Pour fusionner une branche dans la branche courante, la commande <code>git merge</code> doit \u00eatre utilis\u00e9e suivie du nom de la branche \u00e0 fusionner[1] :</p> Bash<pre><code>git merge nom-de-la-branche-a-fusionner\n</code></pre> <p>Exemple pratique complet :</p> Bash<pre><code># 1. V\u00e9rifier que l'on est sur la branche de destination\ngit checkout main\n\n# 2. Fusionner la branche feature\ngit merge feature-authentification\n</code></pre> <p>Cette s\u00e9quence r\u00e9cup\u00e8re tous les commits de la branche feature-authentification et les applique \u00e0 la branche main.</p>"},{"location":"_projects/_formation-git/git-chap05/#cas-de-fusion-simple-fast-forward","title":"Cas de fusion simple (Fast-forward)","text":"<p>Lorsque la branche cible n'a pas avanc\u00e9 depuis la cr\u00e9ation de la branche \u00e0 fusionner, Git effectue une fusion fast-forward. Dans ce cas, le pointeur de la branche est simplement d\u00e9plac\u00e9 vers le commit de la branche fusionn\u00e9e[9].</p> Bash<pre><code>git merge feature-simple\n</code></pre>"},{"location":"_projects/_formation-git/git-chap05/#fusion-avec-commits-multiples-merge-commit","title":"Fusion avec commits multiples (merge commit)","text":"<p>Lorsque les deux branches ont diverg\u00e9 (c'est-\u00e0-dire que la branche principale a re\u00e7u de nouveaux commits depuis la cr\u00e9ation de la branche \u00e0 fusionner), Git cr\u00e9e un commit de fusion combinant les modifications des deux branches[9].</p> Bash<pre><code>git merge feature-complexe\n</code></pre> <p>Git cr\u00e9e automatiquement un commit avec un message de fusion par d\u00e9faut. Ce commit de fusion a deux parents : le dernier commit de chaque branche.</p>"},{"location":"_projects/_formation-git/git-chap05/#resoudre-des-conflits-de-fusion","title":"R\u00e9soudre des conflits de fusion","text":""},{"location":"_projects/_formation-git/git-chap05/#quest-ce-quun-conflit-de-fusion","title":"Qu'est-ce qu'un conflit de fusion ?","text":"<p>Un conflit de fusion survient lorsque Git ne peut pas fusionner automatiquement deux branches parce que les m\u00eames lignes de code ont \u00e9t\u00e9 modifi\u00e9es diff\u00e9remment dans chaque branche. Git doit alors \u00eatre inform\u00e9 des modifications \u00e0 conserver[9].</p>"},{"location":"_projects/_formation-git/git-chap05/#identifier-les-conflits","title":"Identifier les conflits","text":"<p>Lors d'une tentative de fusion, si un conflit existe, Git affiche un message :</p> Text Only<pre><code>Auto-merging fichier.js\nCONFLICT (content): Merge conflict in fichier.js\nAutomatic merge failed; fix conflicts and then commit the result.\n</code></pre> <p>Pour voir les fichiers en conflit :</p> Bash<pre><code>git status\n</code></pre> <p>R\u00e9sultat :</p> Text Only<pre><code>On branch main\nYou have unmerged paths.\n  (use \"git add/rm &lt;file&gt;...\" as appropriate to mark resolution)\n  (use \"git merge --abort\" to abort the merge)\n\nUnmerged paths:\n  (use \"git add &lt;file&gt;...\" to mark as resolved)\n    both modified:   app.js\n</code></pre>"},{"location":"_projects/_formation-git/git-chap05/#resoudre-les-conflits-manuellement","title":"R\u00e9soudre les conflits manuellement","text":"<p>Les fichiers en conflit contiennent des marqueurs de conflit indiquant les sections conflictuelles :</p> JavaScript<pre><code>function login(username, password) {\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n  // Approche de la branche principale\n  return validateWithDatabase(username, password);\n=======\n  // Approche de la branche feature\n  return validateWithAPI(username, password);\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; feature-authentification\n}\n</code></pre> <p>Les marqueurs signifient :</p> <ul> <li><code>&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD</code> : D\u00e9but de la version de la branche courante</li> <li><code>=======</code> : S\u00e9parateur entre les deux versions</li> <li><code>&gt;&gt;&gt;&gt;&gt;&gt;&gt; nom-de-branche</code> : Fin de la version de la branche fusionn\u00e9e</li> </ul>"},{"location":"_projects/_formation-git/git-chap05/#strategies-de-resolution","title":"Strat\u00e9gies de r\u00e9solution","text":"<p>Strat\u00e9gie 1 : Conserver la version de la branche courante</p> JavaScript<pre><code>function login(username, password) {\n  return validateWithDatabase(username, password);\n}\n</code></pre> <p>Puis committer :</p> Bash<pre><code>git add app.js\ngit commit -m \"R\u00e9sout le conflit: utilise la validation base de donn\u00e9es\"\n</code></pre> <p>Strat\u00e9gie 2 : Conserver la version fusionn\u00e9e</p> JavaScript<pre><code>function login(username, password) {\n  return validateWithAPI(username, password);\n}\n</code></pre> <p>Strat\u00e9gie 3 : Combiner les deux approches</p> JavaScript<pre><code>function login(username, password) {\n  const dbValidation = validateWithDatabase(username, password);\n  const apiValidation = validateWithAPI(username, password);\n  return dbValidation &amp;&amp; apiValidation;\n}\n</code></pre>"},{"location":"_projects/_formation-git/git-chap05/#aborter-une-fusion","title":"Aborter une fusion","text":"<p>Si la r\u00e9solution de conflits devient trop complexe, la fusion peut \u00eatre annul\u00e9e :</p> Bash<pre><code>git merge --abort\n</code></pre> <p>Cette commande ram\u00e8ne le r\u00e9f\u00e9rentiel \u00e0 l'\u00e9tat avant la tentative de fusion.</p>"},{"location":"_projects/_formation-git/git-chap05/#utiliser-des-outils-visuels","title":"Utiliser des outils visuels","text":"<p>Pour les conflits complexes, les \u00e9diteurs modernes et les outils Git offrent des interfaces visuelles pour r\u00e9soudre les conflits plus facilement.</p>"},{"location":"_projects/_formation-git/git-chap05/#visualiser-les-branches","title":"Visualiser les branches","text":""},{"location":"_projects/_formation-git/git-chap05/#afficher-lhistorique-avec-branches","title":"Afficher l'historique avec branches","text":"<p>Pour visualiser l'historique des commits et comment les branches divergent, la commande suivante est utile :</p> Bash<pre><code>git log --oneline --graph --all\n</code></pre> <p>R\u00e9sultat typique :</p> Text Only<pre><code>*   3f7a9c2 (main) Merge branch 'feature-paiement'\n|\\\n| * 2e8b1d4 (feature-paiement) Ajoute int\u00e9gration Stripe\n| * 1c9a0e3 Pr\u00e9pare module paiement\n* | 4k2m8p1 Corrige bug authentification\n|/\n* 7j9l3k2 Commit initial\n</code></pre> <p>Ce graphique montre visuellement comment les branches se sont cr\u00e9\u00e9es, d\u00e9velopp\u00e9es et fusionn\u00e9es.</p>"},{"location":"_projects/_formation-git/git-chap05/#voir-les-branches-et-leurs-commits","title":"Voir les branches et leurs commits","text":"<p>Pour voir les branches avec les informations de commit :</p> Bash<pre><code>git branch -v\n</code></pre> <p>R\u00e9sultat :</p> Text Only<pre><code>  develop              2e8b1d4 Merge branch 'feature-api'\n* main                 3f7a9c2 Merge branch 'feature-paiement'\n  feature-api          5x6y7z8 Ajoute endpoints REST\n  hotfix-security      8a9b0c1 Corrige faille s\u00e9curit\u00e9\n</code></pre>"},{"location":"_projects/_formation-git/git-chap05/#afficher-les-branches-de-suivi-distant","title":"Afficher les branches de suivi distant","text":"<p>Pour voir \u00e0 la fois les branches locales et distantes :</p> Bash<pre><code>git branch -a\n</code></pre> <p>R\u00e9sultat :</p> Text Only<pre><code>  develop\n* main\n  feature-login\n  remotes/origin/main\n  remotes/origin/develop\n  remotes/origin/feature-api\n</code></pre> <p>Les branches pr\u00e9c\u00e9d\u00e9es de <code>remotes/</code> sont les branches sur le serveur distant (comme GitHub).</p>"},{"location":"_projects/_formation-git/git-chap05/#supprimer-des-branches","title":"Supprimer des branches","text":""},{"location":"_projects/_formation-git/git-chap05/#supprimer-une-branche-fusionnee","title":"Supprimer une branche fusionn\u00e9e","text":"<p>Une fois qu'une branche a \u00e9t\u00e9 fusionn\u00e9e, elle peut \u00eatre supprim\u00e9e pour maintenir la propret\u00e9 du r\u00e9f\u00e9rentiel[1] :</p> Bash<pre><code>git branch -d nom-de-la-branche\n</code></pre> <p>Exemple :</p> Bash<pre><code>git branch -d feature-authentification\n</code></pre> <p>Cette commande supprime seulement les branches qui ont \u00e9t\u00e9 compl\u00e8tement fusionn\u00e9es.</p>"},{"location":"_projects/_formation-git/git-chap05/#forcer-la-suppression-dune-branche","title":"Forcer la suppression d'une branche","text":"<p>Si une branche n'a pas \u00e9t\u00e9 fusionn\u00e9e mais doit \u00eatre supprim\u00e9e, l'option <code>-D</code> doit \u00eatre utilis\u00e9e[1] :</p> Bash<pre><code>git branch -D nom-de-la-branche\n</code></pre> <p>Exemple :</p> Bash<pre><code>git branch -D branche-experimentale\n</code></pre> <p>Cette commande supprime la branche sans v\u00e9rification, \u00e0 utiliser avec prudence car les commits non fusionn\u00e9s seront orphelins.</p>"},{"location":"_projects/_formation-git/git-chap05/#remiser-ses-changements-avec-git-stash","title":"Remiser ses changements avec git stash","text":""},{"location":"_projects/_formation-git/git-chap05/#concept-de-stash","title":"Concept de stash","text":"<p>Git stash permet de mettre de c\u00f4t\u00e9 temporairement les modifications non commit\u00e9es pour nettoyer l'espace de travail sans perdre le travail[1]. Cela s'av\u00e8re utile lors d'un basculement urgent vers une autre branche pour corriger un bug critique.</p>"},{"location":"_projects/_formation-git/git-chap05/#remiser-les-changements-actuels","title":"Remiser les changements actuels","text":"<p>Pour remiser les modifications actuelles :</p> Bash<pre><code>git stash\n</code></pre> <p>Le r\u00e9pertoire de travail revient \u00e0 l'\u00e9tat du dernier commit, et les modifications sont stock\u00e9es temporairement.</p>"},{"location":"_projects/_formation-git/git-chap05/#remiser-avec-un-message-descriptif","title":"Remiser avec un message descriptif","text":"<p>Pour faciliter l'identification ult\u00e9rieure :</p> Bash<pre><code>git stash save \"Description du travail en cours\"\n</code></pre> <p>ou avec la syntaxe moderne :</p> Bash<pre><code>git stash push -m \"Description du travail en cours\"\n</code></pre>"},{"location":"_projects/_formation-git/git-chap05/#lister-les-stashs","title":"Lister les stashs","text":"<p>Pour voir tous les stashs enregistr\u00e9s :</p> Bash<pre><code>git stash list\n</code></pre> <p>R\u00e9sultat :</p> Text Only<pre><code>stash@{0}: WIP on feature-paiement: 2e8b1d4 Ajoute int\u00e9gration Stripe\nstash@{1}: WIP on develop: 4k2m8p1 Corrige bug authentification\nstash@{2}: WIP on main: 7j9l3k2 Commit initial\n</code></pre>"},{"location":"_projects/_formation-git/git-chap05/#recuperer-un-stash","title":"R\u00e9cup\u00e9rer un stash","text":"<p>Pour appliquer \u00e0 nouveau les modifications remis\u00e9es :</p> Bash<pre><code>git stash pop\n</code></pre> <p>Cette commande applique le stash le plus r\u00e9cent (stash@{0}) et le supprime de la liste.</p> <p>Pour appliquer un stash sp\u00e9cifique sans le supprimer :</p> Bash<pre><code>git stash apply stash@{1}\n</code></pre>"},{"location":"_projects/_formation-git/git-chap05/#exemple-pratique-complet","title":"Exemple pratique complet","text":"<p>Sc\u00e9nario : En travaillant sur une nouvelle fonctionnalit\u00e9, un bug critique doit \u00eatre corrig\u00e9 imm\u00e9diatement sur la branche principale.</p> Bash<pre><code># 1. V\u00e9rifier les modifications actuelles\ngit status\n# On branch feature-paiement\n# Changes not staged for commit:\n#   modified:   app.js\n\n# 2. Remiser les modifications\ngit stash push -m \"WIP: int\u00e9gration paiement en cours\"\n\n# 3. V\u00e9rifier que l'espace de travail est propre\ngit status\n# On branch feature-paiement\n# nothing to commit, working tree clean\n\n# 4. Basculer vers main pour corriger le bug\ngit checkout main\n\n# 5. Cr\u00e9er une branche de correctif\ngit checkout -b hotfix-bug-critique\n\n# 6. Corriger et committer\n# ... effectuer les modifications ...\ngit add .\ngit commit -m \"Corrige bug critique\"\n\n# 7. Fusionner le correctif\ngit checkout main\ngit merge hotfix-bug-critique\n\n# 8. Retourner \u00e0 la branche de d\u00e9veloppement\ngit checkout feature-paiement\n\n# 9. R\u00e9cup\u00e9rer les modifications remis\u00e9es\ngit stash pop\n</code></pre> <p>Apr\u00e8s <code>git stash pop</code>, les modifications enregistr\u00e9es avant le basculement sont \u00e0 nouveau pr\u00e9sentes dans l'espace de travail.</p>"},{"location":"_projects/_formation-git/git-chap05/#nettoyer-les-stashs","title":"Nettoyer les stashs","text":"<p>Pour supprimer un stash sp\u00e9cifique :</p> Bash<pre><code>git stash drop stash@{0}\n</code></pre> <p>Pour supprimer tous les stashs :</p> Bash<pre><code>git stash clear\n</code></pre>"},{"location":"_projects/_formation-git/git-chap05/#strategies-de-branchement","title":"Strat\u00e9gies de branchement","text":""},{"location":"_projects/_formation-git/git-chap05/#gitflow","title":"GitFlow","text":"<p>GitFlow est un mod\u00e8le de branchement structur\u00e9 qui introduit des r\u00f4les sp\u00e9cifiques pour diff\u00e9rents types de branches[3] :</p> <ul> <li>main : Contient toujours du code pr\u00eat pour la production. Aucun commit direct n'est effectu\u00e9 sur cette branche.</li> <li>develop : Branche d'int\u00e9gration pour les fonctionnalit\u00e9s. C'est la branche dans laquelle sont faits tous les d\u00e9veloppements[7].</li> <li>feature/* : Branches temporaires pour les nouvelles fonctionnalit\u00e9s, cr\u00e9\u00e9es \u00e0 partir de <code>develop</code>.</li> <li>release/* : Branches pour la pr\u00e9paration des versions.</li> <li>hotfix/* : Branches pour les correctifs critiques en production.</li> </ul>"},{"location":"_projects/_formation-git/git-chap05/#workflow-recommande-avec-gitflow","title":"Workflow recommand\u00e9 avec GitFlow","text":"Bash<pre><code># 1. Commencer une nouvelle fonctionnalit\u00e9\ngit checkout develop\ngit checkout -b feature/authentification-oauth\n\n# 2. D\u00e9velopper et committer\ngit add .\ngit commit -m \"Ajoute authentification OAuth\"\n\n# 3. Terminer la fonctionnalit\u00e9\ngit checkout develop\ngit merge feature/authentification-oauth\ngit branch -d feature/authentification-oauth\n\n# 4. Pr\u00e9parer une version\ngit checkout -b release/1.2.0 develop\n\n# 5. Corriger les probl\u00e8mes de version\ngit add .\ngit commit -m \"Pr\u00e9pare version 1.2.0\"\n\n# 6. Terminer la version\ngit checkout main\ngit merge release/1.2.0\ngit tag -a v1.2.0 -m \"Version 1.2.0\"\n\n# 7. Retourner \u00e0 develop\ngit checkout develop\ngit merge release/1.2.0\ngit branch -d release/1.2.0\n</code></pre>"},{"location":"_projects/_formation-git/git-chap05/#bonnes-pratiques","title":"Bonnes pratiques","text":""},{"location":"_projects/_formation-git/git-chap05/#nommage-des-branches","title":"Nommage des branches","text":"<p>Adopter une convention coh\u00e9rente pour nommer les branches facilite la collaboration :</p> <ul> <li>feature/ pour les nouvelles fonctionnalit\u00e9s : <code>feature/login-page</code></li> <li>bugfix/ pour les correctifs : <code>bugfix/header-alignment</code></li> <li>hotfix/ pour les corrections critiques : <code>hotfix/security-patch</code></li> <li>docs/ pour la documentation : <code>docs/api-reference</code></li> <li>test/ pour les tests : <code>test/integration-tests</code></li> </ul>"},{"location":"_projects/_formation-git/git-chap05/#commits-atomiques","title":"Commits atomiques","text":"<p>Chaque commit doit repr\u00e9senter une unit\u00e9 logique de travail. Les commits de petite taille facilitent les revues de code et la r\u00e9solution de conflits.</p>"},{"location":"_projects/_formation-git/git-chap05/#messages-de-commit-descriptifs","title":"Messages de commit descriptifs","text":"<p>Les messages doivent \u00eatre clairs et d\u00e9tailler le changement effectu\u00e9 :</p> Bash<pre><code># \u2705 Bon\ngit commit -m \"Ajoute validation de formulaire\"\n\n# \u274c Mauvais\ngit commit -m \"Modifications\"\n</code></pre>"},{"location":"_projects/_formation-git/git-chap05/#maintenir-les-branches-a-jour","title":"Maintenir les branches \u00e0 jour","text":"<p>Avant de fusionner une branche, la maintenir \u00e0 jour par rapport \u00e0 la branche cible :</p> Bash<pre><code>git fetch origin\ngit rebase origin/develop\n</code></pre> <p>Ou :</p> Bash<pre><code>git pull origin develop\n</code></pre>"},{"location":"_projects/_formation-git/git-chap05/#resume-du-processus-dapprentissage","title":"R\u00e9sum\u00e9 du processus d'apprentissage","text":"<p>Le chemin d'apprentissage des branches dans Git suit une progression logique :</p> <p>\u00c9tape 1 : Comprendre le concept fondamental</p> <p>Comprendre qu'une branche est un simple pointeur vers un commit, et non une copie compl\u00e8te du code, est essentiel. Cette compr\u00e9hension permet de saisir pourquoi les branches sont l\u00e9g\u00e8res et rapides \u00e0 cr\u00e9er.</p> <p>\u00c9tape 2 : Ma\u00eetriser les op\u00e9rations de base</p> <p>Apprendre \u00e0 lister les branches avec <code>git branch</code>, cr\u00e9er de nouvelles branches avec <code>git branch</code> ou <code>git switch -c</code>, et basculer entre elles avec <code>git checkout</code> ou <code>git switch</code> fournit les fondamentaux pour toute op\u00e9ration future.</p> <p>\u00c9tape 3 : Fusionner et r\u00e9soudre les conflits</p> <p>Une fois \u00e0 l'aise avec la cr\u00e9ation et le basculement, l'apprentissage de la fusion avec <code>git merge</code> et la r\u00e9solution des conflits qui en d\u00e9coule pr\u00e9pare aux sc\u00e9narios r\u00e9els. Cette \u00e9tape est critique car les conflits sont in\u00e9vitables dans la collaboration.</p> <p>\u00c9tape 4 : Visualiser et g\u00e9rer les branches</p> <p>Utiliser <code>git log --graph</code> et <code>git branch -v</code> pour visualiser la structure des branches aide \u00e0 comprendre l'\u00e9tat du projet et \u00e0 identifier les branches \u00e0 supprimer ou fusionner.</p> <p>\u00c9tape 5 : Utiliser git stash pour la flexibilit\u00e9</p> <p>Apprendre \u00e0 remiser les changements permet de basculer rapidement entre les branches sans committer de travail incomplet, offrant une flexibilit\u00e9 essentielle pour les interruptions urgentes.</p> <p>\u00c9tape 6 : Impl\u00e9menter une strat\u00e9gie de branchement</p> <p>Enfin, adopter une strat\u00e9gie coh\u00e9rente comme GitFlow structure le flux de travail, facilite la collaboration en \u00e9quipe et maintient le projet organis\u00e9 \u00e0 mesure qu'il grandit.</p> <p>Chaque \u00e9tape s'appuie sur les pr\u00e9c\u00e9dentes, cr\u00e9ant une compr\u00e9hension globale des branches dans Git et comment les utiliser efficacement dans un projet r\u00e9el.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-git/git-chap06/","title":"Citations","text":"<ul> <li>https://www.datacamp.com/fr/tutorial/git-rebase</li> <li>https://www.atlassian.com/fr/git/tutorials/rewriting-history/git-rebase</li> <li>https://grafikart.fr/tutoriels/amend-rebase-588</li> <li>https://git-scm.com/docs/git-rebase/fr</li> <li>https://git-scm.com/book/fr/v2/Les-branches-avec-Git-Rebaser-Rebasing</li> <li>https://www.miximum.fr/blog/git-rebase/</li> <li>https://www.youtube.com/watch?v=BqMfUhl3nz8</li> <li>https://www.ionos.fr/digitalguide/sites-internet/developpement-web/git-rebase/</li> <li>https://docs.github.com/fr/get-started/using-git/about-git-rebase</li> <li>https://learn.microsoft.com/fr-fr/azure/devops/repos/git/rebase?view=azure-devops</li> </ul>"},{"location":"_projects/_formation-git/git-chap06/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 254</li> <li>completion_tokens: 1484</li> <li>total_tokens: 1738</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.022, 'request_cost': 0.006, 'total_cost': 0.029}</li> </ul>"},{"location":"_projects/_formation-git/git-chap06/#content","title":"Content","text":""},{"location":"_projects/_formation-git/git-chap06/#chapitre-6-modifier-des-commits","title":"Chapitre 6 : Modifier des commits","text":"<p>Ce chapitre explore les diff\u00e9rentes m\u00e9thodes pour modifier l\u2019historique des commits dans Git. Il aborde les commandes essentielles pour corriger, r\u00e9organiser ou simplifier l\u2019historique d\u2019un projet, en mettant l\u2019accent sur la ma\u00eetrise des outils avanc\u00e9s de Git.</p>"},{"location":"_projects/_formation-git/git-chap06/#introduction-et-git-commit-amend","title":"Introduction et <code>git commit --amend</code>","text":"<p>La commande <code>git commit --amend</code> permet de modifier le dernier commit effectu\u00e9. Elle est utile pour corriger une erreur dans le message du commit, ajouter des fichiers oubli\u00e9s ou modifier le contenu du commit.</p>"},{"location":"_projects/_formation-git/git-chap06/#fonctionnement","title":"Fonctionnement","text":"<ul> <li>Si le commit n\u2019a pas encore \u00e9t\u00e9 pouss\u00e9 sur un d\u00e9p\u00f4t distant, il est possible de le modifier sans risque.</li> <li>Si le commit a \u00e9t\u00e9 pouss\u00e9, il est d\u00e9conseill\u00e9 de l\u2019amender, car cela modifie l\u2019historique et peut causer des conflits pour les autres contributeurs.</li> </ul>"},{"location":"_projects/_formation-git/git-chap06/#exemple","title":"Exemple","text":"<p>Supposons qu\u2019un commit a \u00e9t\u00e9 effectu\u00e9 avec un message incorrect :</p> Bash<pre><code>git add fichier.txt\ngit commit -m \"Ajout du fichier\"\n</code></pre> <p>Pour corriger le message du dernier commit :</p> Bash<pre><code>git commit --amend -m \"Ajout du fichier important\"\n</code></pre> <p>Si des fichiers ont \u00e9t\u00e9 oubli\u00e9s, ils peuvent \u00eatre ajout\u00e9s avant d\u2019ex\u00e9cuter la commande :</p> Bash<pre><code>git add fichier_oublie.txt\ngit commit --amend\n</code></pre>"},{"location":"_projects/_formation-git/git-chap06/#schema","title":"Sch\u00e9ma","text":"Text Only<pre><code>Avant amend :\nA---B---C\n\nApr\u00e8s amend :\nA---B---C'\n</code></pre>"},{"location":"_projects/_formation-git/git-chap06/#le-reflog","title":"Le reflog","text":"<p>Le reflog (reference log) est un journal qui enregistre toutes les modifications apport\u00e9es \u00e0 la r\u00e9f\u00e9rence HEAD. Il permet de retrouver des commits perdus ou d\u2019annuler des erreurs.</p>"},{"location":"_projects/_formation-git/git-chap06/#fonctionnement_1","title":"Fonctionnement","text":"<ul> <li>Le reflog enregistre chaque changement de la branche courante, y compris les rebasages, les fusions et les resets.</li> <li>Il est utile pour r\u00e9cup\u00e9rer des commits supprim\u00e9s ou pour revenir \u00e0 un \u00e9tat ant\u00e9rieur.</li> </ul>"},{"location":"_projects/_formation-git/git-chap06/#exemple_1","title":"Exemple","text":"<p>Pour afficher le reflog :</p> Bash<pre><code>git reflog\n</code></pre> <p>Pour revenir \u00e0 un commit sp\u00e9cifique :</p> Bash<pre><code>git reset --hard HEAD@{2}\n</code></pre>"},{"location":"_projects/_formation-git/git-chap06/#schema_1","title":"Sch\u00e9ma","text":"Text Only<pre><code>reflog :\nHEAD@{0}: rebase: commit C\nHEAD@{1}: commit: commit B\nHEAD@{2}: checkout: commit A\n</code></pre>"},{"location":"_projects/_formation-git/git-chap06/#git-rebase","title":"<code>git rebase</code>","text":"<p>La commande <code>git rebase</code> permet de d\u00e9placer ou de r\u00e9appliquer des commits d\u2019une branche sur une autre. Elle est utilis\u00e9e pour obtenir un historique lin\u00e9aire et \u00e9viter les commits de fusion.</p>"},{"location":"_projects/_formation-git/git-chap06/#fonctionnement_2","title":"Fonctionnement","text":"<ul> <li>Le rebase prend les commits d\u2019une branche et les applique sur une autre branche.</li> <li>Il est important de comprendre que le rebase r\u00e9\u00e9crit l\u2019historique, ce qui peut causer des probl\u00e8mes si la branche a \u00e9t\u00e9 pouss\u00e9e sur un d\u00e9p\u00f4t distant.</li> </ul>"},{"location":"_projects/_formation-git/git-chap06/#exemple_2","title":"Exemple","text":"<p>Supposons que la branche <code>feature</code> a \u00e9t\u00e9 cr\u00e9\u00e9e \u00e0 partir de <code>main</code> :</p> Text Only<pre><code>main: A---B---C\nfeature:      D---E\n</code></pre> <p>Pour rebaser <code>feature</code> sur <code>main</code> :</p> Bash<pre><code>git checkout feature\ngit rebase main\n</code></pre> <p>R\u00e9sultat :</p> Text Only<pre><code>main: A---B---C\nfeature:          D'---E'\n</code></pre>"},{"location":"_projects/_formation-git/git-chap06/#schema_2","title":"Sch\u00e9ma","text":"Text Only<pre><code>Avant rebase :\nmain: A---B---C\nfeature:      D---E\n\nApr\u00e8s rebase :\nmain: A---B---C\nfeature:          D'---E'\n</code></pre>"},{"location":"_projects/_formation-git/git-chap06/#le-rebasage-interactif","title":"Le rebasage interactif","text":"<p>Le rebasage interactif (<code>git rebase -i</code>) permet de modifier, r\u00e9organiser ou supprimer des commits pendant le processus de rebase.</p>"},{"location":"_projects/_formation-git/git-chap06/#fonctionnement_3","title":"Fonctionnement","text":"<ul> <li>Le rebasage interactif ouvre un \u00e9diteur o\u00f9 il est possible de choisir les actions \u00e0 effectuer sur chaque commit.</li> <li>Les actions possibles incluent la modification du message, la suppression, la fusion ou la r\u00e9organisation des commits.</li> </ul>"},{"location":"_projects/_formation-git/git-chap06/#exemple_3","title":"Exemple","text":"<p>Pour lancer un rebasage interactif sur les 3 derniers commits :</p> Bash<pre><code>git rebase -i HEAD~3\n</code></pre> <p>Dans l\u2019\u00e9diteur, il est possible de modifier les lignes pour choisir les actions :</p> Text Only<pre><code>pick 1234567 Commit 1\npick 2345678 Commit 2\npick 3456789 Commit 3\n</code></pre> <p>Pour fusionner les deux premiers commits :</p> Text Only<pre><code>squash 1234567 Commit 1\npick 2345678 Commit 2\npick 3456789 Commit 3\n</code></pre>"},{"location":"_projects/_formation-git/git-chap06/#schema_3","title":"Sch\u00e9ma","text":"Text Only<pre><code>Avant rebasage interactif :\nA---B---C---D---E\n\nApr\u00e8s rebasage interactif :\nA---B---C'---D---E\n</code></pre>"},{"location":"_projects/_formation-git/git-chap06/#utilisation-de-git-merge-squash","title":"Utilisation de <code>git merge --squash</code>","text":"<p>La commande <code>git merge --squash</code> permet de fusionner une branche en cr\u00e9ant un seul commit qui regroupe toutes les modifications.</p>"},{"location":"_projects/_formation-git/git-chap06/#fonctionnement_4","title":"Fonctionnement","text":"<ul> <li>Le squash fusionne toutes les modifications d\u2019une branche en un seul commit, sans conserver l\u2019historique des commits individuels.</li> <li>Il est utile pour simplifier l\u2019historique lors de la fusion de branches de fonctionnalit\u00e9s.</li> </ul>"},{"location":"_projects/_formation-git/git-chap06/#exemple_4","title":"Exemple","text":"<p>Pour fusionner la branche <code>feature</code> en un seul commit :</p> Bash<pre><code>git checkout main\ngit merge --squash feature\ngit commit -m \"Fusion de la branche feature\"\n</code></pre>"},{"location":"_projects/_formation-git/git-chap06/#schema_4","title":"Sch\u00e9ma","text":"Text Only<pre><code>Avant merge --squash :\nmain: A---B---C\nfeature:      D---E---F\n\nApr\u00e8s merge --squash :\nmain: A---B---C---G\n</code></pre>"},{"location":"_projects/_formation-git/git-chap06/#conclusion","title":"Conclusion","text":"<p>La modification des commits dans Git est un outil puissant pour maintenir un historique propre et organis\u00e9. Les commandes pr\u00e9sent\u00e9es dans ce chapitre permettent de corriger, r\u00e9organiser ou simplifier l\u2019historique d\u2019un projet, en adaptant les outils \u00e0 chaque situation.</p>"},{"location":"_projects/_formation-git/git-chap06/#ressources-complementaires","title":"Ressources compl\u00e9mentaires","text":"<ul> <li>Documentation officielle Git</li> <li>Atlassian Git Tutorial</li> <li>DataCamp Git Rebase Guide</li> </ul> <p>Ce chapitre fournit une base solide pour ma\u00eetriser la modification des commits dans Git, en combinant th\u00e9orie, exemples pratiques et sch\u00e9mas explicatifs.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-git/git-chap07/","title":"Citations","text":"<ul> <li>https://git-scm.com/book/fr/v2/Git-sur-le-serveur-GitLab</li> <li>https://www.next-decision.fr/wiki/migration-dun-repertoire-git-sur-gitlab</li> <li>https://labex.io/fr/tutorials/git-step-by-step-instructions-for-linking-a-git-repository-to-a-remote-398369</li> <li>https://about.gitlab.com/fr-fr/blog/getting-started-with-gitlab-how-to-import-your-projects-to-gitlab/</li> <li>https://learninglab.gitlabpages.inria.fr/mooc-rr/mooc-rr-ressources/module2/ressources/gitlab_fr.html</li> <li>https://github.com/SocialGouv/tutoriel-gitlab</li> <li>https://inspe-sciedu.gricad-pages.univ-grenoble-alpes.fr/reflexpro/init-gitlab-rtd.html</li> <li>https://about.gitlab.com/fr-fr/blog/git-bash/</li> <li>https://irma.math.unistra.fr/~helluy/info/git-gitlab.pdf</li> <li>https://qualite-developpement-s2-1c0a85.gitpages.iut-orsay.fr/tp1</li> </ul>"},{"location":"_projects/_formation-git/git-chap07/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 324</li> <li>completion_tokens: 6278</li> <li>total_tokens: 6602</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.094, 'request_cost': 0.006, 'total_cost': 0.101}</li> </ul>"},{"location":"_projects/_formation-git/git-chap07/#content","title":"Content","text":""},{"location":"_projects/_formation-git/git-chap07/#chapitre-7-repertoire-distant-et-gitlab","title":"Chapitre 7 : R\u00e9pertoire distant et GitLab","text":""},{"location":"_projects/_formation-git/git-chap07/#introduction-aux-repertoires-distants-et-a-gitlab","title":"Introduction aux r\u00e9pertoires distants et \u00e0 GitLab","text":""},{"location":"_projects/_formation-git/git-chap07/#concept-fondamental-des-repertoires-distants","title":"Concept fondamental des r\u00e9pertoires distants","text":"<p>Un r\u00e9pertoire distant (remote repository) constitue une copie du projet Git h\u00e9berg\u00e9e sur un serveur, distinct de la copie locale pr\u00e9sente sur l'ordinateur. Cette architecture distribu\u00e9e permet \u00e0 plusieurs d\u00e9veloppeurs de collaborer sur un m\u00eame projet en synchronisant leurs modifications via ce point central.[1]</p> <p>GitLab est une plateforme web reposant sur une base de donn\u00e9es qui fournit un environnement complet pour h\u00e9berger et g\u00e9rer des r\u00e9pertoires Git.[1] Contrairement \u00e0 une simple structure de fichiers, GitLab offre une interface graphique pour la gestion de projets, l'int\u00e9gration continue/d\u00e9ploiement continu (CI/CD), les issues, et la collaboration d'\u00e9quipe.</p>"},{"location":"_projects/_formation-git/git-chap07/#architecture-client-serveur-dans-git","title":"Architecture client-serveur dans Git","text":"<p>La structure fondamentale fonctionne selon ce mod\u00e8le :</p> Text Only<pre><code>Ordinateur Local (D\u00e9p\u00f4t Local)\n    \u2193 \u2191\n    \u2502 \u2502 push/pull\n    \u2193 \u2191\nServeur GitLab (D\u00e9p\u00f4t Distant)\n</code></pre> <p>Le d\u00e9p\u00f4t local contient l'int\u00e9gralit\u00e9 de l'historique du projet, tandis que le d\u00e9p\u00f4t distant sert de point de synchronisation central. Cette approche conf\u00e8re \u00e0 Git sa nature distribu\u00e9e et sa robustesse.</p>"},{"location":"_projects/_formation-git/git-chap07/#configuration-initiale-dun-projet-gitlab","title":"Configuration initiale d'un projet GitLab","text":"<p>Pour d\u00e9buter avec GitLab, la cr\u00e9ation d'un projet n\u00e9cessite plusieurs \u00e9tapes. Dans l'interface GitLab, en cliquant sur <code>Create Project</code>, un formulaire s'affiche demandant le nom du projet, sa description, et le niveau de visibilit\u00e9 (public, interne ou priv\u00e9). La plupart de ces configurations ne sont pas permanentes et peuvent \u00eatre r\u00e9ajust\u00e9es ult\u00e9rieurement gr\u00e2ce \u00e0 l'interface de param\u00e9trage.[1]</p> <p>Une fois le projet cr\u00e9\u00e9, il est accessible via deux protocoles distincts :</p> <ul> <li>HTTPS : Authentification par nom d'utilisateur et mot de passe (ou token d'acc\u00e8s personnel)</li> <li>SSH : Authentification par paire de cl\u00e9s cryptographiques</li> </ul> <p>Les URLs correspondantes sont visibles en haut de la page du projet GitLab.[1]</p>"},{"location":"_projects/_formation-git/git-chap07/#cloner-et-gerer-un-repertoire-distant","title":"Cloner et g\u00e9rer un r\u00e9pertoire distant","text":""},{"location":"_projects/_formation-git/git-chap07/#operation-de-clonage","title":"Op\u00e9ration de clonage","text":"<p>Le clonage cr\u00e9e une copie locale compl\u00e8te du r\u00e9pertoire distant, incluant l'int\u00e9gralit\u00e9 de l'historique des commits, toutes les branches, et l'ensemble des fichiers du projet. Cette op\u00e9ration initialise automatiquement la connexion au r\u00e9pertoire distant.[3]</p> <p>Syntaxe g\u00e9n\u00e9rale du clonage :</p> Bash<pre><code>git clone &lt;url-du-depot-distant&gt;\n</code></pre> <p>Exemple avec HTTPS :</p> Bash<pre><code>git clone https://gitlab.com/utilisateur/mon-projet.git\n</code></pre> <p>Exemple avec SSH :</p> Bash<pre><code>git clone [email protected]:utilisateur/mon-projet.git\n</code></pre> <p>Exemple avec authentification HTTPS explicite :</p> Bash<pre><code>git clone https://nom_utilisateur@app-gitlab.exemple.com/utilisateur/mon-projet.git\n</code></pre> <p>Apr\u00e8s l'ex\u00e9cution de cette commande, un r\u00e9pertoire portant le nom du projet est cr\u00e9\u00e9 localement, contenant tous les fichiers et l'historique complet du projet.</p>"},{"location":"_projects/_formation-git/git-chap07/#lier-un-repertoire-local-existant-a-un-repertoire-distant","title":"Lier un r\u00e9pertoire local existant \u00e0 un r\u00e9pertoire distant","text":"<p>Lorsqu'un projet dispose d\u00e9j\u00e0 d'un dossier <code>.git</code> (contenant l'historique des modifications, les versions, et le syst\u00e8me de gestion du code), il est possible de le connecter \u00e0 un r\u00e9pertoire distant diff\u00e9rent sans perdre l'historique existant.[2]</p> <p>Ajouter un nouveau r\u00e9pertoire distant :</p> Bash<pre><code>git remote add gitlab https://serveur/espace_de_nom/projet.git\n</code></pre> <p>Cette commande cr\u00e9e une r\u00e9f\u00e9rence nomm\u00e9e <code>gitlab</code> pointant vers le serveur distant sp\u00e9cifi\u00e9.[1]</p> <p>Modifier un r\u00e9pertoire distant existant :</p> Bash<pre><code>git remote set-url origin &lt;url-du-nouveau-depot&gt;\n</code></pre> <p>Cette commande est fondamentale lors d'une migration : elle remplace l'URL du serveur distant sans r\u00e9initialiser la connexion, conservant ainsi l'historique local.[2]</p> <p>\u26a0\ufe0f Distinction critique : Il ne faut pas confondre <code>git remote add</code> (cr\u00e9ation d'une nouvelle connexion) avec <code>git remote set-url</code> (modification d'une connexion existante). Utiliser <code>add</code> sur un r\u00e9pertoire distant d\u00e9j\u00e0 configur\u00e9 g\u00e9n\u00e9rera une erreur.</p>"},{"location":"_projects/_formation-git/git-chap07/#gestion-des-repertoires-distants-multiples","title":"Gestion des r\u00e9pertoires distants multiples","text":"<p>Git permet de maintenir plusieurs connexions distantes simultan\u00e9ment. Par exemple, lors du travail avec des sous-traitants sur des plateformes diff\u00e9rentes ou lors de la mise \u00e0 disposition en open source d'un projet interne, il est possible de configurer plusieurs r\u00e9pertoires distants :[4]</p> Bash<pre><code>git remote add origin https://gitlab.com/mon-utilisateur/projet.git\ngit remote add github https://github.com/mon-utilisateur/projet.git\ngit remote add gitea https://gitea.exemple.com/mon-utilisateur/projet.git\n</code></pre> <p>Lister tous les r\u00e9pertoires distants configur\u00e9s :</p> Bash<pre><code>git remote -v\n</code></pre> <p>Cette commande affiche toutes les connexions distantes avec leurs URLs.</p>"},{"location":"_projects/_formation-git/git-chap07/#mise-a-jour-des-pointeurs-distants-avec-git-fetch","title":"Mise \u00e0 jour des pointeurs distants avec git fetch","text":""},{"location":"_projects/_formation-git/git-chap07/#concept-de-git-fetch","title":"Concept de git fetch","text":"<p>L'op\u00e9ration git fetch r\u00e9cup\u00e8re les modifications du serveur distant sans les int\u00e9grer automatiquement dans la branche locale courante. Cette commande met \u00e0 jour les r\u00e9f\u00e9rences distantes locales (les pointeurs qui trackent l'\u00e9tat des branches distantes) sans modifier le contenu local du r\u00e9pertoire de travail.[3]</p> Bash<pre><code>git fetch origin\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#mise-a-jour-des-references-de-suivi-distant","title":"Mise \u00e0 jour des r\u00e9f\u00e9rences de suivi distant","text":"<p>Lors de l'ex\u00e9cution de <code>git fetch</code>, Git t\u00e9l\u00e9charge les nouveaux commits depuis le serveur et met \u00e0 jour les r\u00e9f\u00e9rences de suivi distant. Ces r\u00e9f\u00e9rences, par convention nomm\u00e9es <code>origin/nom-branche</code>, pointent vers la derni\u00e8re position connue de chaque branche sur le serveur distant.</p> <p>Tableau des \u00e9tats avant et apr\u00e8s fetch :</p> \u00c9tat Branche locale R\u00e9f\u00e9rence distante (origin/branche) Description Avant fetch commit A commit A \u00c9tat initial synchronis\u00e9 Apr\u00e8s fetch (nouveau commit sur serveur) commit A commit B Fetch a mis \u00e0 jour la r\u00e9f\u00e9rence distante Avant merge commit A (HEAD) commit B (origin/main) Pr\u00eat pour int\u00e9gration"},{"location":"_projects/_formation-git/git-chap07/#syntaxes-de-fetch","title":"Syntaxes de fetch","text":"<p>R\u00e9cup\u00e9rer depuis tous les r\u00e9pertoires distants :</p> Bash<pre><code>git fetch --all\n</code></pre> <p>R\u00e9cup\u00e9rer depuis un r\u00e9pertoire distant sp\u00e9cifique :</p> Bash<pre><code>git fetch origin\n</code></pre> <p>R\u00e9cup\u00e9rer une branche sp\u00e9cifique :</p> Bash<pre><code>git fetch origin nom-branche\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#examen-des-branches-distantes-apres-fetch","title":"Examen des branches distantes apr\u00e8s fetch","text":"<p>Apr\u00e8s un fetch, les branches distantes peuvent \u00eatre consult\u00e9es :</p> Bash<pre><code>git branch -r\n</code></pre> <p>Cette commande liste toutes les branches de suivi distant, pr\u00e9fix\u00e9es par le nom du r\u00e9pertoire distant (par exemple <code>origin/main</code>, <code>origin/develop</code>).</p>"},{"location":"_projects/_formation-git/git-chap07/#difference-entre-fetch-et-pull","title":"Diff\u00e9rence entre fetch et pull","text":"<p>Bien que souvent confondues, ces deux op\u00e9rations comportent des diff\u00e9rences importantes :</p> <ul> <li>git fetch : R\u00e9cup\u00e8re les modifications du serveur sans les int\u00e9grer</li> <li>git pull : R\u00e9cup\u00e8re les modifications ET les int\u00e8gre dans la branche locale courante</li> </ul> <p>Cette distinction permet un contr\u00f4le plus granulaire du processus de mise \u00e0 jour.</p>"},{"location":"_projects/_formation-git/git-chap07/#le-raccourci-git-pull","title":"Le raccourci git pull","text":""},{"location":"_projects/_formation-git/git-chap07/#fonctionnement-de-git-pull","title":"Fonctionnement de git pull","text":"<p>L'op\u00e9ration git pull combine deux actions distinctes en une seule commande :[3]</p> <ol> <li>git fetch : R\u00e9cup\u00e9ration des modifications du serveur distant</li> <li>git merge (ou git rebase) : Int\u00e9gration des modifications dans la branche locale</li> </ol> Bash<pre><code>git pull origin main\n</code></pre> <p>Cette commande \u00e9quivaut \u00e0 :</p> Bash<pre><code>git fetch origin\ngit merge origin/main\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#strategies-dintegration-avec-git-pull","title":"Strat\u00e9gies d'int\u00e9gration avec git pull","text":"<p>Int\u00e9gration par fusion (merge) - comportement par d\u00e9faut :</p> Bash<pre><code>git pull origin main\n</code></pre> <p>Si la branche locale a avanc\u00e9 parall\u00e8lement \u00e0 la branche distante, Git cr\u00e9e un commit de fusion pour reconcilier les historiques.</p> <p>Int\u00e9gration par rebasage :</p> Bash<pre><code>git pull --rebase origin main\n</code></pre> <p>Le rebasage rejoue les commits locaux sur la base de la branche distante, produisant un historique lin\u00e9aire plus propre.</p>"},{"location":"_projects/_formation-git/git-chap07/#configuration-permanente-de-la-branche-de-suivi","title":"Configuration permanente de la branche de suivi","text":"<p>Pour que <code>git pull</code> fonctionne sans sp\u00e9cifier le r\u00e9pertoire distant et la branche, il est n\u00e9cessaire de configurer la branche de suivi :</p> Bash<pre><code>git branch --set-upstream-to=origin/main main\n</code></pre> <p>Ou de mani\u00e8re raccourcie :</p> Bash<pre><code>git branch -u origin/main main\n</code></pre> <p>Apr\u00e8s cette configuration, simplement taper <code>git pull</code> suffira.</p>"},{"location":"_projects/_formation-git/git-chap07/#depannage-des-operations-pull","title":"D\u00e9pannage des op\u00e9rations pull","text":"<p>Situation de divergence :</p> <p>Si la branche locale et la branche distante ont diverg\u00e9 (chacune contenant des commits non pr\u00e9sents dans l'autre), <code>git pull</code> cr\u00e9era un commit de fusion qui r\u00e9concilie les deux historiques.</p> Bash<pre><code># Avant pull : Local (A-B-C), Distant (A-B-D-E)\n# Apr\u00e8s pull : Local (A-B-C-M-D-E) o\u00f9 M est le commit de fusion\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#liens-entre-branches-locales-et-branches-distantes","title":"Liens entre branches locales et branches distantes","text":""},{"location":"_projects/_formation-git/git-chap07/#concept-de-branche-de-suivi-distant","title":"Concept de branche de suivi distant","text":"<p>Une branche de suivi distant (remote-tracking branch) est une r\u00e9f\u00e9rence locale qui repr\u00e9sente l'\u00e9tat d'une branche sur le serveur distant au moment du dernier fetch. Ces branches ont une nomenclature sp\u00e9cifique : <code>&lt;nom-distant&gt;/&lt;nom-branche&gt;</code>.</p> <p>Par exemple : - <code>origin/main</code> : l'\u00e9tat de <code>main</code> sur le serveur <code>origin</code> - <code>upstream/develop</code> : l'\u00e9tat de <code>develop</code> sur le serveur <code>upstream</code></p> <p>Ces branches ne peuvent pas \u00eatre modifi\u00e9es directement ; elles sont mises \u00e0 jour uniquement par les op\u00e9rations <code>fetch</code>.</p>"},{"location":"_projects/_formation-git/git-chap07/#liaison-explicite-entre-branche-locale-et-branche-distante","title":"Liaison explicite entre branche locale et branche distante","text":"<p>Lors de la cr\u00e9ation d'une branche locale, il est optimal de l'associer \u00e0 une branche de suivi distant. Cette liaison permet \u00e0 <code>git status</code> et <code>git pull</code> de fonctionner sans arguments suppl\u00e9mentaires.</p> <p>Cr\u00e9ation d'une branche locale associ\u00e9e \u00e0 une branche distante :</p> Bash<pre><code>git checkout --track origin/develop\n</code></pre> <p>Cette commande cr\u00e9e automatiquement une branche locale nomm\u00e9e <code>develop</code> et la configure pour suivre <code>origin/develop</code>.</p> <p>Cr\u00e9ation avec un nom personnalis\u00e9 :</p> Bash<pre><code>git checkout -b ma-branche origin/develop\ngit branch -u origin/develop ma-branche\n</code></pre> <p>Configuration apr\u00e8s cr\u00e9ation :</p> Bash<pre><code>git branch -u origin/develop\n</code></pre> <p>Ex\u00e9cut\u00e9e sans argument de branche sp\u00e9cifique, cette commande configure la branche courante.</p>"},{"location":"_projects/_formation-git/git-chap07/#tableau-de-suivi-des-branches","title":"Tableau de suivi des branches","text":"Branche locale Branche distante Command\u00e9e par \u00c9tat <code>main</code> <code>origin/main</code> Automatique au clonage Synchronis\u00e9e <code>develop</code> <code>origin/develop</code> <code>git checkout --track</code> Synchronis\u00e9e <code>feature-x</code> aucune Cr\u00e9ation manuelle D\u00e9tach\u00e9e <code>bugfix-y</code> <code>origin/bugfix-y</code> <code>git branch -u</code> Suivie"},{"location":"_projects/_formation-git/git-chap07/#affichage-du-suivi-des-branches","title":"Affichage du suivi des branches","text":"Bash<pre><code>git branch -vv\n</code></pre> <p>Cette commande affiche chaque branche locale avec sa branche de suivi associ\u00e9e et le statut de synchronisation (ahead/behind).</p> <p>Exemple de sortie :</p> Text Only<pre><code>  main                  abc1234 [origin/main] Derni\u00e8re version\n* develop               def5678 [origin/develop: ahead 2] Travail en cours\n  feature-authentif    ghi9012 [origin/feature-authentif: behind 3] En retard\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#mettre-a-jour-le-depot-distant-avec-git-push","title":"Mettre \u00e0 jour le d\u00e9p\u00f4t distant avec git push","text":""},{"location":"_projects/_formation-git/git-chap07/#concept-de-git-push","title":"Concept de git push","text":"<p>L'op\u00e9ration git push transmet les commits locaux vers le r\u00e9pertoire distant.[2] Contrairement \u00e0 <code>fetch</code> qui t\u00e9l\u00e9charge, <code>push</code> envoie les modifications du syst\u00e8me local vers le serveur.</p> Bash<pre><code>git push origin main\n</code></pre> <p>Cette commande pousse la branche <code>main</code> locale vers le r\u00e9pertoire distant nomm\u00e9 <code>origin</code>.</p>"},{"location":"_projects/_formation-git/git-chap07/#poussee-simple-vs-poussee-avec-suivi","title":"Pouss\u00e9e simple vs pouss\u00e9e avec suivi","text":"<p>Pouss\u00e9e basique (n\u00e9cessite de sp\u00e9cifier la branche cible) :</p> Bash<pre><code>git push origin develop\n</code></pre> <p>Pouss\u00e9e avec configuration de suivi :</p> Bash<pre><code>git push -u origin develop\n</code></pre> <p>Le flag <code>-u</code> (ou <code>--set-upstream</code>) configure simultaneement la pouss\u00e9e ET \u00e9tablit le lien de suivi. Apr\u00e8s cette commande, les futurs <code>git push</code> sur cette branche ne n\u00e9cessiteront plus d'arguments.</p>"},{"location":"_projects/_formation-git/git-chap07/#poussee-de-branches-multiples","title":"Pouss\u00e9e de branches multiples","text":"<p>Envoyer toutes les branches locales :</p> Bash<pre><code>git push --all\n</code></pre> <p>Selon le contexte d\u00e9crit dans les ressources, lors d'une migration compl\u00e8te de r\u00e9pertoire, cette commande transmet l'ensemble des branches et de leur historique :[2]</p> Bash<pre><code>git push -u origin --all\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#gestion-des-tags","title":"Gestion des tags","text":"<p>Les tags (\u00e9tiquettes) sont des rep\u00e8res pointant sur des commits sp\u00e9cifiques, g\u00e9n\u00e9ralement utilis\u00e9s pour marquer des versions. Par d\u00e9faut, <code>git push</code> n'envoie pas les tags.</p> <p>Envoyer les tags :</p> Bash<pre><code>git push origin --tags\n</code></pre> <p>Envoyer un tag sp\u00e9cifique :</p> Bash<pre><code>git push origin nom-du-tag\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#migration-complete-dun-repertoire","title":"Migration compl\u00e8te d'un r\u00e9pertoire","text":"<p>Lors du d\u00e9placement d'un projet d'une plateforme \u00e0 une autre (par exemple de GitHub vers GitLab), il est essentiel de pr\u00e9server l'int\u00e9grit\u00e9 compl\u00e8te du projet :[2]</p> Bash<pre><code># 1. Renommer le remote existant\ngit remote rename origin old-origin\n\n# 2. Ajouter le nouveau remote GitLab\ngit remote add origin https://gitlab.com/utilisateur/nouveau-projet.git\n\n# 3. Envoyer l'int\u00e9gralit\u00e9 des branches et tags\ngit push -u origin --all\ngit push origin --tags\n</code></pre> <p>Apr\u00e8s ces \u00e9tapes, l'int\u00e9gralit\u00e9 des fichiers, branches et tags du projet est pr\u00e9sente sur le nouveau serveur, et la collaboration peut d\u00e9buter.</p>"},{"location":"_projects/_formation-git/git-chap07/#gestion-des-conflits-lors-du-push","title":"Gestion des conflits lors du push","text":"<p>Si un push est rejet\u00e9 car la branche distante a avanc\u00e9, Git refuse l'op\u00e9ration pour pr\u00e9venir les pertes de donn\u00e9es.</p> <p>Sc\u00e9nario de rejet :</p> Text Only<pre><code>Local:    A-B-C (HEAD on main)\nDistant:  A-B-D\n\nTentative : git push origin main\nR\u00e9sultat : rejected (non-fast-forward)\n</code></pre> <p>Solution : Synchroniser d'abord avec le serveur</p> Bash<pre><code>git fetch origin\ngit merge origin/main\ngit push origin main\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#repertoire-distant-et-configurations","title":"R\u00e9pertoire distant et configurations","text":""},{"location":"_projects/_formation-git/git-chap07/#configuration-du-repertoire-distant-par-defaut","title":"Configuration du r\u00e9pertoire distant par d\u00e9faut","text":"<p>Lors du clonage d'un r\u00e9pertoire, Git cr\u00e9e automatiquement une configuration avec <code>origin</code> comme r\u00e9pertoire distant par d\u00e9faut et <code>main</code> comme branche par d\u00e9faut. Cette configuration peut \u00eatre consult\u00e9e dans le fichier <code>.git/config</code>.</p> <p>Afficher la configuration du remote :</p> Bash<pre><code>git remote -v\n</code></pre> <p>Exemple de sortie :</p> Text Only<pre><code>origin  https://gitlab.com/utilisateur/projet.git (fetch)\norigin  https://gitlab.com/utilisateur/projet.git (push)\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#configuration-avancee-des-repertoires-distants","title":"Configuration avanc\u00e9e des r\u00e9pertoires distants","text":"<p>Le fichier <code>.git/config</code> stocke la configuration compl\u00e8te. Pour les d\u00e9p\u00f4ts complexes, il peut ressembler \u00e0 :</p> INI<pre><code>[remote \"origin\"]\n    url = https://gitlab.com/utilisateur/projet.git\n    fetch = +refs/heads/*:refs/remotes/origin/*\n\n[remote \"upstream\"]\n    url = https://gitlab.com/projet-original/projet.git\n    fetch = +refs/heads/*:refs/remotes/upstream/*\n\n[branch \"main\"]\n    remote = origin\n    merge = refs/heads/main\n\n[branch \"develop\"]\n    remote = origin\n    merge = refs/heads/develop\n</code></pre> <p>Cette configuration peut \u00eatre \u00e9dit\u00e9e directement ou modifi\u00e9e via les commandes Git.</p>"},{"location":"_projects/_formation-git/git-chap07/#modification-de-la-configuration-des-repertoires-distants","title":"Modification de la configuration des r\u00e9pertoires distants","text":"<p>Ajouter une URL de push diff\u00e9rente :</p> Bash<pre><code>git remote set-url --push origin https://autre-url.git\n</code></pre> <p>Cette approche permet de r\u00e9cup\u00e9rer les modifications depuis une source tout en envoyant vers une autre destination.</p> <p>Supprimer un r\u00e9pertoire distant :</p> Bash<pre><code>git remote remove ancien-remote\n</code></pre> <p>Renommer un r\u00e9pertoire distant :</p> Bash<pre><code>git remote rename old-name new-name\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#depot-miroir-et-synchronisation-bidirectionnelle","title":"D\u00e9p\u00f4t miroir et synchronisation bidirectionnelle","text":"<p>Dans certains contextes, notamment lors de la gestion de projets open source, il est n\u00e9cessaire de maintenir deux copies du projet synchronis\u00e9es sur des plateformes diff\u00e9rentes. GitLab supporte la fonctionnalit\u00e9 de d\u00e9p\u00f4t miroir pour cela.[6]</p> <p>Configuration d'un miroir GitLab \u2192 GitHub :</p> <ol> <li>Dans les param\u00e8tres du projet GitLab, acc\u00e9der \u00e0 Param\u00e8tres \u2192 D\u00e9p\u00f4t \u2192 D\u00e9p\u00f4ts miroirs</li> <li>Ajouter l'URL du d\u00e9p\u00f4t GitHub</li> <li>Fournir le nom d'utilisateur GitHub et un token d'acc\u00e8s personnel</li> <li>Cocher l'option \"D\u00e9p\u00f4t miroir\"</li> </ol> <p>Apr\u00e8s cette configuration, chaque commit effectu\u00e9 sur GitLab est automatiquement pouss\u00e9 vers GitHub.[6]</p>"},{"location":"_projects/_formation-git/git-chap07/#liens-entre-branches-locales-et-branches-distantes-approfondissement","title":"Liens entre branches locales et branches distantes (approfondissement)","text":""},{"location":"_projects/_formation-git/git-chap07/#suivi-automatique-lors-du-checkout","title":"Suivi automatique lors du checkout","text":"<p>Lorsqu'une branche locale n'existe pas mais qu'une branche distante correspondante existe, Git cr\u00e9e automatiquement la branche locale avec le suivi configur\u00e9.</p> Bash<pre><code>git checkout develop\n# Si develop n'existe pas localement mais origin/develop existe,\n# Git cr\u00e9e automatiquement develop en local et la configure pour suivre origin/develop\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#affichage-detaille-des-branches-et-de-leur-suivi","title":"Affichage d\u00e9taill\u00e9 des branches et de leur suivi","text":"Bash<pre><code>git branch -vv\n</code></pre> <p>Interpr\u00e9tation de la sortie :</p> Text Only<pre><code>  main              a1b2c3d [origin/main] Commit message\n* develop           d4e5f6g [origin/develop: ahead 2, behind 1] Commit message\n  feature-x        h7i8j9k [origin/feature-x: gone] Commit message\n</code></pre> <ul> <li><code>ahead 2</code> : 2 commits locaux non envoy\u00e9s</li> <li><code>behind 1</code> : 1 commit distant non r\u00e9cup\u00e9r\u00e9</li> <li><code>gone</code> : La branche distante n'existe plus sur le serveur</li> </ul>"},{"location":"_projects/_formation-git/git-chap07/#gestion-des-branches-distantes-supprimees","title":"Gestion des branches distantes supprim\u00e9es","text":"<p>Lorsqu'une branche est supprim\u00e9e sur le serveur, la branche de suivi local persiste. Pour nettoyer ces r\u00e9f\u00e9rences obsol\u00e8tes :</p> Bash<pre><code>git remote prune origin\n</code></pre> <p>Ou lors d'un fetch :</p> Bash<pre><code>git fetch --prune origin\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#optimisation-et-nettoyage","title":"Optimisation et nettoyage","text":""},{"location":"_projects/_formation-git/git-chap07/#nettoyage-des-references-distantes-obsoletes","title":"Nettoyage des r\u00e9f\u00e9rences distantes obsol\u00e8tes","text":"<p>Au fil du temps, les branches sont cr\u00e9\u00e9es et supprim\u00e9es. Les r\u00e9f\u00e9rences locales vers les branches distantes supprim\u00e9es occupent de l'espace et cr\u00e9ent de la confusion.</p> <p>Supprimer les branches distantes supprim\u00e9es :</p> Bash<pre><code>git fetch --prune\n</code></pre> <p>Alias pour simplifier :</p> Bash<pre><code>git config --global alias.prune-local 'fetch --prune origin'\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#optimisation-de-la-base-de-donnees-git","title":"Optimisation de la base de donn\u00e9es Git","text":"<p>Git stocke l'historique dans une structure de fichiers. Au fil du temps, cette structure peut devenir fragment\u00e9e.</p> <p>Compacter la base de donn\u00e9es :</p> Bash<pre><code>git gc\n</code></pre> <p>Cette commande combine les objets Git fragment\u00e9s en fichiers packfile, r\u00e9duisant l'espace disque utilis\u00e9.</p> <p>Optimisation agressive (pour les r\u00e9pertoires volumineux) :</p> Bash<pre><code>git gc --aggressive\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#gestion-de-lespace-disque","title":"Gestion de l'espace disque","text":"<p>Afficher la taille du r\u00e9pertoire <code>.git</code> :</p> Bash<pre><code>du -sh .git\n</code></pre> <p>Identifier les fichiers volumineux :</p> Bash<pre><code>git rev-list --all --objects | sort -k2 | tail -20\n</code></pre> <p>Cette commande liste les 20 plus gros objets dans l'historique.</p>"},{"location":"_projects/_formation-git/git-chap07/#verification-de-lintegrite","title":"V\u00e9rification de l'int\u00e9grit\u00e9","text":"Bash<pre><code>git fsck --full\n</code></pre> <p>Cette commande v\u00e9rifie l'int\u00e9grit\u00e9 de tous les objets Git et identifie les probl\u00e8mes potentiels.</p>"},{"location":"_projects/_formation-git/git-chap07/#utiliser-le-protocole-ssh-avec-git-et-gitlab","title":"Utiliser le protocole SSH avec Git et GitLab","text":""},{"location":"_projects/_formation-git/git-chap07/#fondamentaux-de-ssh","title":"Fondamentaux de SSH","text":"<p>SSH (Secure Shell) est un protocole de communication s\u00e9curis\u00e9e bas\u00e9 sur le chiffrement asym\u00e9trique (paire de cl\u00e9s publique/priv\u00e9e). Pour l'authentification aupr\u00e8s de GitLab, il est n\u00e9cessaire de g\u00e9n\u00e9rer une paire de cl\u00e9s.[5]</p>"},{"location":"_projects/_formation-git/git-chap07/#architecture-ssh-pour-git","title":"Architecture SSH pour Git","text":"Text Only<pre><code>Ordinateur Local                    Serveur GitLab\n\u251c\u2500\u2500 Cl\u00e9 priv\u00e9e (secret)            \u251c\u2500\u2500 Cl\u00e9 publique (stock\u00e9e)\n\u2514\u2500\u2500 Client SSH          \u2190\u2192 SSH      \u251c\u2500\u2500 V\u00e9rification\n                     (chiffr\u00e9)      \u2514\u2500\u2500 D\u00e9verrouillage\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#generation-de-la-paire-de-cles-ssh","title":"G\u00e9n\u00e9ration de la paire de cl\u00e9s SSH","text":"<p>Cr\u00e9er une nouvelle paire de cl\u00e9s :</p> Bash<pre><code>ssh-keygen -t ed25519 -C \"email@exemple.com\"\n</code></pre> <p>Pour les syst\u00e8mes plus anciens (RSA) :</p> Bash<pre><code>ssh-keygen -t rsa -b 4096 -C \"email@exemple.com\"\n</code></pre> <p>Les prompts demandent : - Chemin de sauvegarde (par d\u00e9faut <code>~/.ssh/id_ed25519</code>) - Phrase de passe (optionnelle mais recommand\u00e9e)</p>"},{"location":"_projects/_formation-git/git-chap07/#structure-de-stockage-des-cles-ssh","title":"Structure de stockage des cl\u00e9s SSH","text":"Text Only<pre><code>~/.ssh/\n\u251c\u2500\u2500 id_ed25519           (cl\u00e9 priv\u00e9e - \u00c0 GARDER SECRET)\n\u251c\u2500\u2500 id_ed25519.pub       (cl\u00e9 publique - \u00c0 partager)\n\u251c\u2500\u2500 known_hosts          (serveurs connus)\n\u2514\u2500\u2500 config               (configuration SSH)\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#ajout-de-la-cle-publique-a-gitlab","title":"Ajout de la cl\u00e9 publique \u00e0 GitLab","text":"<ol> <li>Afficher le contenu de la cl\u00e9 publique :</li> </ol> Bash<pre><code>cat ~/.ssh/id_ed25519.pub\n</code></pre> <ol> <li> <p>Copier la sortie (commen\u00e7ant par <code>ssh-ed25519</code> ou <code>ssh-rsa</code>)</p> </li> <li> <p>Dans GitLab :</p> </li> <li>Cliquer sur l'avatar utilisateur \u2192 Pr\u00e9f\u00e9rences</li> <li>S\u00e9lectionner SSH Keys</li> <li>Coller la cl\u00e9 publique</li> <li>Cliquer sur Add key</li> </ol>"},{"location":"_projects/_formation-git/git-chap07/#test-de-la-connexion-ssh","title":"Test de la connexion SSH","text":"<p>V\u00e9rifier la connectivit\u00e9 :</p> Bash<pre><code>ssh -T [email protected]\n</code></pre> <p>R\u00e9ponse attendue :</p> Text Only<pre><code>Welcome to GitLab, @utilisateur!\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#utilisation-de-ssh-pour-les-operations-git","title":"Utilisation de SSH pour les op\u00e9rations Git","text":"<p>Cloner un r\u00e9pertoire via SSH :</p> Bash<pre><code>git clone [email protected]:utilisateur/mon-projet.git\n</code></pre> <p>Ajouter un r\u00e9pertoire distant via SSH :</p> Bash<pre><code>git remote add origin [email protected]:utilisateur/mon-projet.git\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#configuration-avancee-de-ssh","title":"Configuration avanc\u00e9e de SSH","text":"<p>Cr\u00e9er un alias SSH dans <code>~/.ssh/config</code> :</p> Text Only<pre><code>Host gitlab\n    HostName gitlab.com\n    User git\n    IdentityFile ~/.ssh/id_ed25519\n    PreferredAuthentications publickey\n</code></pre> <p>Apr\u00e8s cette configuration, les commandes Git peuvent utiliser <code>gitlab</code> :</p> Bash<pre><code>git clone gitlab:utilisateur/mon-projet.git\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#gestion-de-plusieurs-cles-ssh","title":"Gestion de plusieurs cl\u00e9s SSH","text":"<p>Pour les d\u00e9veloppeurs travaillant avec plusieurs serveurs Git ou plusieurs comptes :</p> <p>Configuration <code>~/.ssh/config</code> avanc\u00e9e :</p> Text Only<pre><code>Host gitlab-personnel\n    HostName gitlab.com\n    User git\n    IdentityFile ~/.ssh/id_ed25519_personnel\n\nHost gitlab-professionnel\n    HostName gitlab.com\n    User git\n    IdentityFile ~/.ssh/id_ed25519_professionnel\n\nHost github\n    HostName github.com\n    User git\n    IdentityFile ~/.ssh/id_ed25519_github\n</code></pre> <p>Utilisation avec les URLs correspondantes :</p> Bash<pre><code>git clone gitlab-personnel:utilisateur-personnel/projet.git\ngit clone gitlab-professionnel:utilisateur-pro/projet.git\ngit clone github:utilisateur-github/projet.git\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#securite-et-bonnes-pratiques-ssh","title":"S\u00e9curit\u00e9 et bonnes pratiques SSH","text":"<ul> <li>Phrase de passe : Toujours utiliser une phrase de passe pour prot\u00e9ger la cl\u00e9 priv\u00e9e</li> <li>Rotation : R\u00e9guli\u00e8rement g\u00e9n\u00e9rer de nouvelles cl\u00e9s et supprimer les anciennes</li> <li>Permissions : Le r\u00e9pertoire <code>~/.ssh/</code> doit avoir les permissions <code>700</code></li> </ul> Bash<pre><code>chmod 700 ~/.ssh\nchmod 600 ~/.ssh/id_ed25519\nchmod 644 ~/.ssh/id_ed25519.pub\n</code></pre> <ul> <li>Audits : R\u00e9guli\u00e8rement v\u00e9rifier les cl\u00e9s SSH enregistr\u00e9es sur GitLab</li> </ul>"},{"location":"_projects/_formation-git/git-chap07/#depannage-ssh","title":"D\u00e9pannage SSH","text":"<p>V\u00e9rifier les d\u00e9tails de la connexion :</p> Bash<pre><code>ssh -vvv [email protected]\n</code></pre> <p>Le verbose mode affiche les \u00e9tapes de connexion et aide \u00e0 identifier les probl\u00e8mes.</p> <p>Probl\u00e8me courant : Permission denied</p> Bash<pre><code># V\u00e9rifier les permissions\nls -la ~/.ssh/\n\n# R\u00e9initialiser si n\u00e9cessaire\nchmod 700 ~/.ssh\nchmod 600 ~/.ssh/id_ed25519\nchmod 644 ~/.ssh/id_ed25519.pub\n</code></pre>"},{"location":"_projects/_formation-git/git-chap07/#synthese-et-progression-pedagogique","title":"Synth\u00e8se et progression p\u00e9dagogique","text":"<p>L'apprentissage des r\u00e9pertoires distants et GitLab suit une progression logique :</p>"},{"location":"_projects/_formation-git/git-chap07/#phase-1-fondamentaux","title":"Phase 1 : Fondamentaux","text":"<p>La compr\u00e9hension d\u00e9bute par les concepts \u00e9l\u00e9mentaires : qu'est-ce qu'un r\u00e9pertoire distant, comment il se distingue du r\u00e9pertoire local, et les deux protocoles de communication (HTTPS et SSH).</p>"},{"location":"_projects/_formation-git/git-chap07/#phase-2-operations-essentielles","title":"Phase 2 : Op\u00e9rations essentielles","text":"<p>Apr\u00e8s avoir assimil\u00e9 les concepts, l'apprenant ma\u00eetrise les quatre op\u00e9rations fondamentales : cloner un r\u00e9pertoire, r\u00e9cup\u00e9rer les modifications avec fetch, envoyer les modifications avec push, et utiliser le raccourci pull.</p>"},{"location":"_projects/_formation-git/git-chap07/#phase-3-gestion-avancee","title":"Phase 3 : Gestion avanc\u00e9e","text":"<p>La compr\u00e9hension des branches distantes, du suivi des branches, et des configurations permet une utilisation plus efficace de Git dans les contextes collaboratifs r\u00e9els.</p>"},{"location":"_projects/_formation-git/git-chap07/#phase-4-authentification-securisee","title":"Phase 4 : Authentification s\u00e9curis\u00e9e","text":"<p>L'adoption de SSH comme protocole d'authentification repr\u00e9sente une \u00e9volution vers des pratiques de s\u00e9curit\u00e9 robustes, \u00e9liminant la n\u00e9cessit\u00e9 de stocker des mots de passe en clair.</p>"},{"location":"_projects/_formation-git/git-chap07/#phase-5-optimisation","title":"Phase 5 : Optimisation","text":"<p>Enfin, les techniques de nettoyage et d'optimisation permettent de maintenir des r\u00e9pertoires Git efficients et performants \u00e0 long terme.</p> <p>Cette progression du simple au complexe, du conceptuel au pratique, \u00e9tablit une base solide pour la collaboration efficace dans les projets Git.[2][3][4]</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-git/git-chap08/","title":"Citations","text":"<ul> <li>https://about.gitlab.com/fr-fr/blog/getting-started-with-gitlab-mastering-project-management/</li> <li>https://www.hostinger.com/fr/tutoriels/tutoriel-gitlab</li> <li>https://github.com/SocialGouv/tutoriel-gitlab</li> <li>https://pole-calcul-formation.gricad-pages.univ-grenoble-alpes.fr/outils-collaboratifs-gitlab/cours/pdf/outils_collab_gitlab.pdf</li> <li>https://www.youtube.com/watch?v=wX2j8On2U8w</li> <li>https://blog.stephane-robert.info/docs/pipeline-cicd/gitlab/</li> <li>https://about.gitlab.com/fr-fr/get-started/</li> <li>https://www.learnthings.fr/apprendre/informatique/devops/gitlab/</li> <li>https://rdes_dreal.gitlab.io/publication_guide/dev-gerer-gitlab.html</li> </ul>"},{"location":"_projects/_formation-git/git-chap08/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 281</li> <li>completion_tokens: 6263</li> <li>total_tokens: 6544</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.094, 'request_cost': 0.006, 'total_cost': 0.101}</li> </ul>"},{"location":"_projects/_formation-git/git-chap08/#content","title":"Content","text":""},{"location":"_projects/_formation-git/git-chap08/#chapitre-8-la-gestion-de-projets-avec-git-et-gitlab","title":"\ud83d\udcda Chapitre 8 : La gestion de projets avec Git et Gitlab","text":""},{"location":"_projects/_formation-git/git-chap08/#les-tickets-gitlab","title":"\ud83c\udfab Les tickets Gitlab","text":"<p>Les tickets, \u00e9galement appel\u00e9s issues dans la terminologie Gitlab, constituent l'\u00e9l\u00e9ment fondamental de la gestion de projets au sein de la plateforme. Ils permettent de centraliser les discussions, de documenter les bugs, les demandes de fonctionnalit\u00e9s et l'ensemble des t\u00e2ches li\u00e9es \u00e0 un projet.[1]</p>"},{"location":"_projects/_formation-git/git-chap08/#structure-et-creation-dun-ticket","title":"Structure et cr\u00e9ation d'un ticket","text":"<p>Un ticket Gitlab se compose de plusieurs \u00e9l\u00e9ments essentiels qui structurent le travail collaboratif. Chaque ticket poss\u00e8de un titre descriptif, une description d\u00e9taill\u00e9e du probl\u00e8me ou de la fonctionnalit\u00e9, et un ensemble de m\u00e9tadonn\u00e9es permettant son organisation.</p> <p>\u00c9l\u00e9ments fondamentaux d'un ticket :</p> <p>La cr\u00e9ation d'un ticket commence par la d\u00e9finition claire de son objectif. Le titre doit \u00eatre concis mais explicite, permettant une identification rapide du contenu. La description d\u00e9taill\u00e9e fournit le contexte n\u00e9cessaire pour que les membres de l'\u00e9quipe comprennent la nature du travail \u00e0 effectuer. Cette description peut inclure des \u00e9tapes de reproduction pour les bugs, des crit\u00e8res d'acceptation pour les fonctionnalit\u00e9s, ou des pr\u00e9cisions techniques.</p>"},{"location":"_projects/_formation-git/git-chap08/#systeme-de-categorisation-et-dorganisation","title":"Syst\u00e8me de cat\u00e9gorisation et d'organisation","text":"<p>Les tickets Gitlab peuvent \u00eatre organis\u00e9s selon plusieurs crit\u00e8res pour faciliter leur gestion et leur suivi.[1][3]</p> <p>Tags et \u00e9tiquettes : Les tags permettent de cat\u00e9goriser les tickets en les associant \u00e0 des th\u00e8mes sp\u00e9cifiques. Par exemple, un projet pourrait utiliser des tags comme \"bug\", \"feature\", \"documentation\", \"refactoring\" ou \"performance\". Cette cat\u00e9gorisation rend possible le filtrage rapide et l'identification des priorit\u00e9s de travail.</p> <p>Assignation des t\u00e2ches : Chaque ticket peut \u00eatre attribu\u00e9 \u00e0 un ou plusieurs membres de l'\u00e9quipe. L'assignation clarifie les responsabilit\u00e9s individuelles et garantit que chaque t\u00e2che est associ\u00e9e \u00e0 une personne responsable. Cette fonctionnalit\u00e9 facilite \u00e9galement le suivi du travail personnel de chaque contributeur.</p> <p>Estimation du travail : La pond\u00e9ration permet d'estimer l'effort requis pour chaque ticket. Un syst\u00e8me simple \u00e0 5 niveaux suffit g\u00e9n\u00e9ralement : une t\u00e2che simple re\u00e7oit un poids de 1, tandis qu'une t\u00e2che complexe peut obtenir un poids de 5. Cette estimation facilite la planification des sprints et la priorisation des efforts.[1]</p>"},{"location":"_projects/_formation-git/git-chap08/#sous-taches-et-decomposition-du-travail","title":"Sous-t\u00e2ches et d\u00e9composition du travail","text":"<p>Pour les t\u00e2ches complexes, Gitlab offre la possibilit\u00e9 de cr\u00e9er des sous-t\u00e2ches ou des checklist internes au ticket.[1] Cette fonctionnalit\u00e9 permet de d\u00e9composer un travail volumineux en \u00e9tapes plus g\u00e9rables.</p> <p>Exemple pratique de d\u00e9composition :</p> <p>Un ticket intitul\u00e9 \"Conception des wireframes de la page d'accueil\" pourrait \u00eatre d\u00e9compos\u00e9 en t\u00e2ches suivantes :</p> <ul> <li>Esquisser les concepts initiaux</li> <li>Cr\u00e9er les wireframes num\u00e9riques</li> <li>Valider avec le responsable design</li> <li>Recueillir les retours des parties prenantes</li> <li>It\u00e9rer sur les retours re\u00e7us</li> <li>Obtenir l'approbation finale</li> </ul> <p>Cette structuration permet au responsable du ticket de suivre la progression d\u00e9taill\u00e9e du travail et d'identifier rapidement les blocages.</p>"},{"location":"_projects/_formation-git/git-chap08/#collaboration-et-communication","title":"Collaboration et communication","text":"<p>Les tickets constituent un espace central de discussion autour des t\u00e2ches de projet.[1][3] Chaque ticket peut accumuler des commentaires permettant aux \u00e9quipes de discuter des approches, de partager des solutions et de documenter les d\u00e9cisions prises. Les mentions (@pseudo) permettent d'alerter rapidement les contributeurs pertinents. Cette capacit\u00e9 \u00e0 centraliser les discussions \u00e9vite la fragmentation des informations sur plusieurs outils et plateformes.</p>"},{"location":"_projects/_formation-git/git-chap08/#exemple-de-gitflow","title":"\ud83d\udd04 Exemple de GitFlow","text":""},{"location":"_projects/_formation-git/git-chap08/#comprehension-conceptuelle-du-workflow","title":"Compr\u00e9hension conceptuelle du workflow","text":"<p>Le GitFlow repr\u00e9sente une m\u00e9thodologie de branchement sophistiqu\u00e9e con\u00e7ue pour g\u00e9rer les releases, les d\u00e9veloppements parall\u00e8les et la maintenance des versions en production. Contrairement \u00e0 un mod\u00e8le simple de branchement lin\u00e9aire, le GitFlow introduit plusieurs branches permanentes et temporaires, chacune ayant un r\u00f4le sp\u00e9cifique dans le cycle de vie du d\u00e9veloppement.</p>"},{"location":"_projects/_formation-git/git-chap08/#architecture-des-branches-dans-gitflow","title":"Architecture des branches dans GitFlow","text":"<p>La branche principale (main/master) : Cette branche contient uniquement le code de production. Chaque commit sur cette branche repr\u00e9sente une version stable et valid\u00e9e pr\u00eate pour le d\u00e9ploiement. Aucun d\u00e9veloppement ne s'effectue directement sur cette branche ; elle re\u00e7oit uniquement des mises \u00e0 jour via des merge requests provenant de branches de release.</p> <p>La branche de d\u00e9veloppement (develop) : Cette branche sert de base pour le d\u00e9veloppement de nouvelles fonctionnalit\u00e9s. Elle contient le code en cours de d\u00e9veloppement et repr\u00e9sente l'\u00e9tat \"next-release\" du projet. C'est depuis cette branche que tous les feature branches sont cr\u00e9\u00e9s.</p>"},{"location":"_projects/_formation-git/git-chap08/#branches-temporaires","title":"Branches temporaires","text":"<p>Branches de fonctionnalit\u00e9s (feature branches) : Pour chaque nouvelle fonctionnalit\u00e9, un d\u00e9veloppeur cr\u00e9e une branche depuis <code>develop</code> suivant une convention de nommage sp\u00e9cifique, par exemple <code>feature/nom-de-la-fonctionnalit\u00e9</code>. Le d\u00e9veloppement s'effectue enti\u00e8rement sur cette branche isol\u00e9e. Une fois compl\u00e8te, une merge request est cr\u00e9\u00e9e pour int\u00e9grer la fonctionnalit\u00e9 dans <code>develop</code>.</p> <p>Branches de release (release branches) : Lorsqu'une version doit \u00eatre pr\u00e9par\u00e9e pour la production, une branche <code>release/X.Y.Z</code> est cr\u00e9\u00e9e depuis <code>develop</code>. Cette branche permet de finaliser les derniers ajustements, d'effectuer les tests de validation et de documenter les modifications. Les corrections de bugs critiques peuvent \u00eatre appliqu\u00e9es ici. Une fois valid\u00e9e, la release est fusionn\u00e9e dans <code>main</code> avec un tag de version et r\u00e9int\u00e9gr\u00e9e dans <code>develop</code>.</p> <p>Branches de correction (hotfix branches) : Lorsqu'un bug critique est d\u00e9couvert en production, une branche <code>hotfix/nom-du-fix</code> est cr\u00e9\u00e9e depuis <code>main</code>. Le correctif est appliqu\u00e9, test\u00e9, puis fusionn\u00e9 \u00e0 la fois dans <code>main</code> (avec un tag) et dans <code>develop</code> pour synchroniser les deux branches.</p>"},{"location":"_projects/_formation-git/git-chap08/#workflow-pratique-dun-exemple-gitflow","title":"Workflow pratique d'un exemple GitFlow","text":"<p>Consid\u00e9rons un projet de gestion de t\u00e2ches. L'\u00e9quipe re\u00e7oit la demande d'ajouter la fonctionnalit\u00e9 \"notifications par email\". Le processus suivrait ces \u00e9tapes :</p> <p>1. Cr\u00e9ation d'une feature branch : Un d\u00e9veloppeur cr\u00e9e la branche <code>feature/email-notifications</code> depuis <code>develop</code>. Durant cette phase, le code est r\u00e9guli\u00e8rement committ\u00e9 avec des messages explicites documenting les modifications.</p> <p>2. D\u00e9veloppement et commits r\u00e9guliers : Le d\u00e9veloppeur effectue plusieurs commits : \"Ajouter le module d'envoi d'email\", \"Impl\u00e9menter la logique de notifications\", \"Ajouter les tests unitaires\", etc.</p> <p>3. Cr\u00e9ation d'une merge request : Une fois le d\u00e9veloppement complet, une merge request est soumise. Cette demande d\u00e9clenche des v\u00e9rifications automatiques : linting du code, tests unitaires, construction du projet.</p> <p>4. R\u00e9vision et approbation : Les autres membres de l'\u00e9quipe examinent les modifications, posent des questions si n\u00e9cessaire, et approuvent ou demandent des ajustements.</p> <p>5. Fusion dans develop : Apr\u00e8s approbation, la feature branch est fusionn\u00e9e dans <code>develop</code>. La branche feature peut ensuite \u00eatre supprim\u00e9e.</p> <p>6. Pr\u00e9paration de la release : Quand plusieurs fonctionnalit\u00e9s sont int\u00e9gr\u00e9es et pr\u00eates, une branche <code>release/2.0.0</code> est cr\u00e9\u00e9e. Des tests d'int\u00e9gration complets sont effectu\u00e9s.</p> <p>7. Documentation et finalisation : Le fichier CHANGELOG est mis \u00e0 jour, les num\u00e9ros de version sont ajust\u00e9s, et les derni\u00e8res corrections sont appliqu\u00e9es.</p> <p>8. Fusion en production : Une merge request fusionne <code>release/2.0.0</code> dans <code>main</code> avec un tag <code>v2.0.0</code>. Le code est maintenant d\u00e9ploy\u00e9 en production.</p> <p>9. Synchronisation : La m\u00eame release est r\u00e9int\u00e9gr\u00e9e dans <code>develop</code> pour assurer la coh\u00e9rence.</p>"},{"location":"_projects/_formation-git/git-chap08/#avantages-de-cette-approche","title":"Avantages de cette approche","text":"<p>Ce mod\u00e8le offre plusieurs b\u00e9n\u00e9fices : une s\u00e9paration claire entre le d\u00e9veloppement et la production, la possibilit\u00e9 de maintenir plusieurs versions simultan\u00e9ment, une gestion efficace des correctifs d'urgence, et un workflow pr\u00e9visible facilitant la collaboration en \u00e9quipe.</p>"},{"location":"_projects/_formation-git/git-chap08/#introduction-aux-fonctionnalites-gitlab","title":"\ud83d\ude80 Introduction aux fonctionnalit\u00e9s Gitlab","text":""},{"location":"_projects/_formation-git/git-chap08/#la-plateforme-integree","title":"La plateforme int\u00e9gr\u00e9e","text":"<p>Gitlab transcende le simple gestionnaire de d\u00e9p\u00f4ts Git en offrant une suite compl\u00e8te d'outils pour la gestion de projets logiciels. Cette int\u00e9gration \u00e9limine la n\u00e9cessit\u00e9 de basculer entre plusieurs applications, centralisant toutes les fonctionnalit\u00e9s essentielles dans une plateforme unique.[1]</p>"},{"location":"_projects/_formation-git/git-chap08/#fonctionnalites-fondamentales","title":"Fonctionnalit\u00e9s fondamentales","text":"<p>Gestion de code avec Git : Gitlab fournit un contr\u00f4le de version complet bas\u00e9 sur Git, permettant le branchement, le merging et la gestion d'historique. Cette base technologique solide supporte les workflows complexes et la collaboration \u00e0 grande \u00e9chelle.</p> <p>Syst\u00e8me de tickets et issues : Comme explor\u00e9 pr\u00e9c\u00e9demment, les issues constituent l'\u00e9pine dorsale du suivi des t\u00e2ches et de la gestion des bugs. Gitlab Duo, la suite aliment\u00e9e par l'IA de Gitlab, peut g\u00e9n\u00e9rer automatiquement des descriptions d\u00e9taill\u00e9es de tickets en fournissant simplement quelques mots d\u00e9crivant l'objectif.[1]</p> <p>Tableaux Kanban : Gitlab offre des tableaux visuels de style Kanban permettant de visualiser le workflow sous forme de colonnes \"\u00c0 faire\", \"En cours\" et \"Termin\u00e9\". Les tickets peuvent \u00eatre gliss\u00e9s-d\u00e9pos\u00e9s entre les colonnes, fournissant une repr\u00e9sentation imm\u00e9diate de l'avancement du travail.[1]</p> <p>Planification avec les Epics : Pour les projets de grande envergure, les Epics permettent de regrouper plusieurs issues autour d'objectifs majeurs. Cette fonctionnalit\u00e9 offre une vue d'ensemble strat\u00e9gique du projet.</p>"},{"location":"_projects/_formation-git/git-chap08/#avantages-de-lintegration","title":"Avantages de l'int\u00e9gration","text":"<p>En centralisant code, suivi des t\u00e2ches, discussions et communication au sein d'une plateforme unique, Gitlab simplifie significativement le workflow des \u00e9quipes. Les informations ne se fragmentent pas entre email, chat, gestionnaires de tickets externes et d\u00e9p\u00f4ts Git. Cette centralisation r\u00e9duit le risque de perte d'informations et am\u00e9liore la continuit\u00e9 des discussions.[1]</p>"},{"location":"_projects/_formation-git/git-chap08/#les-demandes-de-fusion-merge-requests","title":"\ud83d\udce8 Les demandes de fusion (Merge Requests)","text":""},{"location":"_projects/_formation-git/git-chap08/#concept-fondamental","title":"Concept fondamental","text":"<p>Les demandes de fusion, connues sous le sigle MR (Merge Request), constituent le m\u00e9canisme central permettant l'int\u00e9gration du code collaboratif dans Gitlab. Une merge request repr\u00e9sente une proposition formelle d'int\u00e9gration de modifications cr\u00e9\u00e9es dans une branche vers une autre branche, g\u00e9n\u00e9ralement de la branche de feature vers la branche principale ou de d\u00e9veloppement.[2]</p>"},{"location":"_projects/_formation-git/git-chap08/#processus-de-creation-et-gestion","title":"Processus de cr\u00e9ation et gestion","text":"<p>Initiation d'une merge request : Apr\u00e8s avoir effectu\u00e9 les modifications sur une branche de feature et pouss\u00e9 les commits vers le d\u00e9p\u00f4t distant, le d\u00e9veloppeur cr\u00e9e une merge request. Cette action signale aux autres membres de l'\u00e9quipe qu'un nouveau code est pr\u00eat pour r\u00e9vision.</p> <p>Description et contexte : Chaque merge request doit inclure une description claire expliquant les modifications propos\u00e9es, les raisons de ces changements, et tout contexte pertinent. Cette documentation facilite la compr\u00e9hension rapide des modifications par les reviewers.</p> <p>Revue de code : C'est l'\u00e9tape critique o\u00f9 d'autres d\u00e9veloppeurs examinent le code propos\u00e9. Les reviewers peuvent commenter des lignes sp\u00e9cifiques, poser des questions, sugg\u00e9rer des am\u00e9liorations ou identifier des probl\u00e8mes potentiels. Cette revue assure la qualit\u00e9 du code et permet le partage des connaissances au sein de l'\u00e9quipe.</p> <p>V\u00e9rifications automatiques : Gitlab peut int\u00e9grer des pipelines CI/CD qui ex\u00e9cutent automatiquement des tests, des analyses de linting et des constructions. La merge request affiche le statut de ces v\u00e9rifications, permettant une \u00e9valuation imm\u00e9diate de la qualit\u00e9 du code.</p> <p>Approbation et fusion : Une fois que les reviewers approuvent la merge request et que toutes les v\u00e9rifications automatiques r\u00e9ussissent, le code peut \u00eatre fusionn\u00e9 dans la branche cible. Cette action int\u00e8gre d\u00e9finitivement les modifications.</p>"},{"location":"_projects/_formation-git/git-chap08/#bonnes-pratiques-pour-les-merge-requests","title":"Bonnes pratiques pour les merge requests","text":"<p>Les merge requests efficaces suivent certaines conventions. Les titres doivent \u00eatre concis et descriptifs. Les descriptions doivent expliquer le \"pourquoi\" en plus du \"quoi\", facilitant la compr\u00e9hension ult\u00e9rieure des d\u00e9cisions prises. Les demandes de fusion doivent rester relativement compactes ; des modifications trop volumineuses rendent la r\u00e9vision difficile et augmentent le risque d'erreurs.</p>"},{"location":"_projects/_formation-git/git-chap08/#introduction-au-gitflow","title":"\ud83c\udf93 Introduction au GitFlow","text":"<p>Le GitFlow repr\u00e9sente une m\u00e9thodologie \u00e9prouv\u00e9e de gestion des branches de code, particuli\u00e8rement efficace pour les projets suivant un mod\u00e8le de releases planifi\u00e9es. Contrairement \u00e0 des workflows plus simples, le GitFlow fournit une structure formelle et pr\u00e9visible pour g\u00e9rer les d\u00e9veloppements, les versions et les corrections.</p>"},{"location":"_projects/_formation-git/git-chap08/#principes-fondamentaux","title":"Principes fondamentaux","text":"<p>Le GitFlow repose sur la s\u00e9paration claire entre les branches de production, d\u00e9veloppement et travail temporaire. Cette s\u00e9paration offre plusieurs avantages : la production reste stable et test\u00e9e, le d\u00e9veloppement peut progresser rapidement avec plusieurs fonctionnalit\u00e9s en parall\u00e8le, et les corrections d'urgence peuvent \u00eatre isol\u00e9es sans perturber le d\u00e9veloppement normal.</p>"},{"location":"_projects/_formation-git/git-chap08/#conventions-de-nommage","title":"Conventions de nommage","text":"<p>Chaque type de branche suit une convention de nommage pr\u00e9cise :</p> <ul> <li>main ou master : la branche de production</li> <li>develop : la branche de d\u00e9veloppement principal</li> <li>feature/* : pour les nouvelles fonctionnalit\u00e9s</li> <li>release/* : pour les pr\u00e9parations de release</li> <li>hotfix/* : pour les correctifs critiques en production</li> </ul> <p>Cette convention claire facilite la navigation dans le d\u00e9p\u00f4t et rend les intentions explicites.</p>"},{"location":"_projects/_formation-git/git-chap08/#transitions-detats","title":"Transitions d'\u00e9tats","text":"<p>Le GitFlow g\u00e8re plusieurs transitions d'\u00e9tats dans le cycle de vie du code. Le code en d\u00e9veloppement r\u00e9siste dans la branche <code>develop</code>. Quand suffisamment de fonctionnalit\u00e9s sont pr\u00eates, une branche de release est cr\u00e9\u00e9e pour la finalisation. Apr\u00e8s validation, le code passe en production via la branche <code>main</code>. Les correctifs en production repassent par le circuit complet pour assurer la synchronisation.</p>"},{"location":"_projects/_formation-git/git-chap08/#les-milestones-gitlab","title":"\ud83c\udfc1 Les Milestones Gitlab","text":""},{"location":"_projects/_formation-git/git-chap08/#definition-et-utilite","title":"D\u00e9finition et utilit\u00e9","text":"<p>Les Milestones dans Gitlab constituent des marqueurs temporels majeurs qui structurent les objectifs et les jalons d'un projet. Contrairement aux issues individuelles, les Milestones repr\u00e9sentent des objectifs strat\u00e9giques plus larges, regroupant plusieurs issues autour d'une date limite ou d'un objectif commun.[1]</p>"},{"location":"_projects/_formation-git/git-chap08/#creation-et-configuration","title":"Cr\u00e9ation et configuration","text":"<p>Sp\u00e9cification des jalons : Les Milestones sont cr\u00e9\u00e9s avec un titre pr\u00e9cis d\u00e9crivant l'objectif atteint et une date d'\u00e9ch\u00e9ance. Par exemple, un projet pourrait avoir des Milestones comme \"Version 1.0\", \"MVP Launch\", ou \"Performance Sprint Q1 2026\".</p> <p>Association avec les issues : Chaque issue peut \u00eatre associ\u00e9e \u00e0 un ou plusieurs Milestones. Cette association establit le lien entre le travail d\u00e9taill\u00e9 et les objectifs strat\u00e9giques plus larges.</p> <p>Suivi de la progression : Gitlab fournit des vues permettant de visualiser le pourcentage de r\u00e9alisation de chaque Milestone. Ces statistiques montrent rapidement l'avancement vers les objectifs majeurs du projet.[1]</p>"},{"location":"_projects/_formation-git/git-chap08/#exemple-pratique-dutilisation","title":"Exemple pratique d'utilisation","text":"<p>Consid\u00e9rons un projet de d\u00e9veloppement d'une application de gestion de r\u00e9seau social. Les Milestones pourraient \u00eatre structur\u00e9s comme suit :</p> <ul> <li> <p>Milestone \"MVP (Minimum Viable Product)\" : Regroupant les issues essentielles comme \"Authentification utilisateur\", \"Publication de messages\", \"Syst\u00e8me de suivi\". Date limite : 31 mars 2026.</p> </li> <li> <p>Milestone \"Version 1.5\": Incluant les am\u00e9liorations comme \"Notifications en temps r\u00e9el\", \"Syst\u00e8me de recommandations\", \"Int\u00e9gration de pi\u00e8ces jointes\". Date limite : 31 mai 2026.</p> </li> <li> <p>Milestone \"Performance Optimization\": Rassemblant les t\u00e2ches comme \"Optimisation des requ\u00eates de base de donn\u00e9es\", \"Caching c\u00f4t\u00e9 client\", \"Compression des images\". Date limite : 30 juin 2026.</p> </li> </ul>"},{"location":"_projects/_formation-git/git-chap08/#integration-avec-les-roadmaps","title":"Int\u00e9gration avec les roadmaps","text":"<p>Les Milestones s'int\u00e8grent avec les Roadmaps Gitlab pour fournir une vue calendaire des objectifs \u00e0 long terme. Cette visualisation permet aux parties prenantes et \u00e0 l'\u00e9quipe de projet de comprendre rapidement la trajectoire du d\u00e9veloppement et les livraisons pr\u00e9vues.[1]</p>"},{"location":"_projects/_formation-git/git-chap08/#la-librairie-gitflow","title":"\ud83d\udcda La librairie GitFlow","text":""},{"location":"_projects/_formation-git/git-chap08/#contexte-et-motivation","title":"Contexte et motivation","text":"<p>GitFlow, bien qu'\u00e9tant une m\u00e9thodologie puissante, requiert une discipline rigoureuse pour \u00eatre impl\u00e9ment\u00e9e correctement. La gestion manuelle des branches, les conventions de nommage et les transitions d'\u00e9tat peuvent devenir sources d'erreurs. C'est dans ce contexte que la librairie GitFlow a \u00e9t\u00e9 d\u00e9velopp\u00e9e.</p>"},{"location":"_projects/_formation-git/git-chap08/#essentiellement-la-librairie-gitflow-est-un-ensemble-dextensions-git-qui-automatisent-et-standardisent-limplementation-du-workflow-gitflow2-au-lieu-de-memoriser-les-etapes-exactes-pour-creer-une-feature-branch-effectuer-un-merge-ou-preparer-une-release-les-developpeurs-peuvent-utiliser-des-commandes-simples","title":"Essentiellement, la librairie GitFlow est un ensemble d'extensions Git qui automatisent et standardisent l'impl\u00e9mentation du workflow GitFlow.[2] Au lieu de m\u00e9moriser les \u00e9tapes exactes pour cr\u00e9er une feature branch, effectuer un merge ou pr\u00e9parer une release, les d\u00e9veloppeurs peuvent utiliser des commandes simples.","text":""},{"location":"_projects/_formation-git/git-chap08/#commandes-principales","title":"Commandes principales","text":"<p>Initialisation du GitFlow :</p> Bash<pre><code>git flow init\n</code></pre> <p>Cette commande initialise le workflow GitFlow dans le d\u00e9p\u00f4t. Elle demande la confirmation des noms de branche par d\u00e9faut (main, develop, etc.).</p> <p>Gestion des features :</p> Bash<pre><code># Cr\u00e9er une nouvelle feature\ngit flow feature start nom-de-la-feature\n\n# Publier la feature (pousser vers le d\u00e9p\u00f4t distant)\ngit flow feature publish nom-de-la-feature\n\n# Terminer et fusionner la feature\ngit flow feature finish nom-de-la-feature\n</code></pre> <p>Gestion des releases :</p> Bash<pre><code># D\u00e9marrer une release\ngit flow release start 1.0.0\n\n# Terminer la release (cr\u00e9e un tag et fusionne dans main et develop)\ngit flow release finish 1.0.0\n</code></pre> <p>Gestion des hotfixes :</p> Bash<pre><code># D\u00e9marrer un hotfix\ngit flow hotfix start correction-critique\n\n# Terminer le hotfix\ngit flow hotfix finish correction-critique\n</code></pre>"},{"location":"_projects/_formation-git/git-chap08/#avantages-de-cette-approche_1","title":"Avantages de cette approche","text":"<p>L'utilisation de la librairie GitFlow r\u00e9duit consid\u00e9rablement le risque d'erreur lors de la manipulation des branches. Les d\u00e9veloppeurs n'ont pas besoin de retenir des s\u00e9quences complexes de commandes Git. La librairie applique automatiquement les conventions et effectue les fusions dans les branches appropri\u00e9es.</p>"},{"location":"_projects/_formation-git/git-chap08/#installation-et-setup","title":"Installation et setup","text":"<p>Bien que techniquement li\u00e9e \u00e0 GitFlow, la librairie GitFlow n'est pas int\u00e9gr\u00e9e directement \u00e0 Gitlab. Elle s'installe comme une extension Git suppl\u00e9mentaire et fonctionne en conjonction avec Gitlab. Les d\u00e9veloppeurs utilisant Gitlab peuvent b\u00e9n\u00e9ficier de la librairie GitFlow pour g\u00e9rer leurs branches locales tout en cr\u00e9ant des merge requests dans Gitlab pour le processus de r\u00e9vision.</p>"},{"location":"_projects/_formation-git/git-chap08/#les-tags","title":"\ud83c\udff7\ufe0f Les tags","text":""},{"location":"_projects/_formation-git/git-chap08/#concept-et-utilite","title":"Concept et utilit\u00e9","text":"<p>Les tags constituent des points de r\u00e9f\u00e9rence immuables dans l'historique Git, marquant des \u00e9tats sp\u00e9cifiques du code jug\u00e9s importants. Contrairement aux branches qui avancent avec chaque nouveau commit, les tags restent fixes \u00e0 un point pr\u00e9cis de l'historique, facilitant l'identification des versions de production ou des jalons importants.</p>"},{"location":"_projects/_formation-git/git-chap08/#types-de-tags","title":"Types de tags","text":"<p>Tags l\u00e9gers : Un tag l\u00e9ger est simplement un pointeur vers un commit sp\u00e9cifique. Il est cr\u00e9\u00e9 et stock\u00e9 dans le d\u00e9p\u00f4t Git avec un surco\u00fbt minimal.</p> Bash<pre><code>git tag v1.0.0\n</code></pre> <p>Tags annot\u00e9s : Un tag annot\u00e9 est un objet Git complet, contenant le nom du cr\u00e9ateur, la date, et un message. Cette approche est pr\u00e9f\u00e9r\u00e9e pour les releases officielles car elle fournit plus d'information et de tra\u00e7abilit\u00e9.</p> Bash<pre><code>git tag -a v1.0.0 -m \"Release version 1.0.0\"\n</code></pre>"},{"location":"_projects/_formation-git/git-chap08/#convention-de-versioning-semantique","title":"Convention de versioning s\u00e9mantique","text":"<p>Les tags de version suivent g\u00e9n\u00e9ralement la convention de versioning s\u00e9mantique : MAJOR.MINOR.PATCH</p> <ul> <li>MAJOR : incr\u00e9ment\u00e9 pour les changements incompatibles avec les versions ant\u00e9rieures</li> <li>MINOR : incr\u00e9ment\u00e9 pour les nouvelles fonctionnalit\u00e9s compatibles avec les versions ant\u00e9rieures</li> <li>PATCH : incr\u00e9ment\u00e9 pour les corrections de bugs</li> </ul> <p>Par exemple, la progression <code>1.0.0</code> \u2192 <code>1.1.0</code> \u2192 <code>1.1.1</code> \u2192 <code>2.0.0</code> suit cette convention.</p>"},{"location":"_projects/_formation-git/git-chap08/#utilisation-dans-le-workflow-de-release","title":"Utilisation dans le workflow de release","text":"<p>Dans le contexte du GitFlow, les tags jouent un r\u00f4le capital. Quand une branche de release est compl\u00e9t\u00e9e et fusionn\u00e9e dans la branche <code>main</code>, un tag annot\u00e9 est cr\u00e9\u00e9 marquant cette version. Cette pratique cr\u00e9e un enregistrement permanent et identifiable de chaque version livr\u00e9e.</p> Bash<pre><code># Afficher tous les tags\ngit tag\n\n# Afficher les d\u00e9tails d'un tag sp\u00e9cifique\ngit show v1.0.0\n\n# Cr\u00e9er un tag et le pousser vers le d\u00e9p\u00f4t distant\ngit push origin v1.0.0\n</code></pre>"},{"location":"_projects/_formation-git/git-chap08/#tags-dans-gitlab","title":"Tags dans Gitlab","text":"<p>Gitlab affiche les tags de mani\u00e8re visible dans l'interface utilisateur, facilitant l'identification des releases. Les tags peuvent \u00eatre utilis\u00e9s pour d\u00e9clencher des pipelines CI/CD sp\u00e9cifiques aux releases, automatisant le processus de d\u00e9ploiement.</p>"},{"location":"_projects/_formation-git/git-chap08/#exemple-de-workflow-complet-avec-tags","title":"Exemple de workflow complet avec tags","text":"<p>Consid\u00e9rons le cycle de vie complet d'une release dans un projet utilisant GitFlow et tags :</p> <p>1. D\u00e9veloppement : Les fonctionnalit\u00e9s sont d\u00e9velopp\u00e9es dans des branches feature qui mergent dans develop.</p> <p>2. Pr\u00e9paration de la release : Une branche <code>release/2.1.0</code> est cr\u00e9\u00e9e depuis develop pour finaliser la version.</p> <p>3. Validation : Tests et derni\u00e8res corrections sont appliqu\u00e9s sur la branche release.</p> <p>4. Cr\u00e9ation du tag : Une fois valid\u00e9e, la branche release est fusionn\u00e9e dans main et un tag annot\u00e9 <code>v2.1.0</code> est cr\u00e9\u00e9.</p> Bash<pre><code>git tag -a v2.1.0 -m \"Version 2.1.0 - Ajout des notifications et optimisations de performance\"\n</code></pre> <p>5. Synchronisation : La branche release est r\u00e9int\u00e9gr\u00e9e dans develop pour maintenir la coh\u00e9rence.</p> <p>6. D\u00e9ploiement : Le tag <code>v2.1.0</code> d\u00e9clenche un pipeline CI/CD automatisant le d\u00e9ploiement en production.</p>"},{"location":"_projects/_formation-git/git-chap08/#integration-complete-du-ticket-a-la-production","title":"\ud83d\udd17 Int\u00e9gration compl\u00e8te : Du ticket \u00e0 la production","text":""},{"location":"_projects/_formation-git/git-chap08/#orchestration-des-elements","title":"Orchestration des \u00e9l\u00e9ments","text":"<p>Ces diff\u00e9rents \u00e9l\u00e9ments - tickets, GitFlow, merge requests, Milestones et tags - s'int\u00e8grent pour former un syst\u00e8me complet de gestion de projet logiciel. La compr\u00e9hension de leur interaction mutuelle est essentielle pour ma\u00eetriser le d\u00e9veloppement collaboratif avec Gitlab.</p>"},{"location":"_projects/_formation-git/git-chap08/#flux-complet-dune-fonctionnalite","title":"Flux complet d'une fonctionnalit\u00e9","text":"<p>Phase 1 : Planification</p> <p>Une nouvelle fonctionnalit\u00e9 est identifi\u00e9e et cr\u00e9\u00e9e sous forme d'issue dans Gitlab. Cette issue est \u00e9tiquet\u00e9e \"feature\", assign\u00e9e \u00e0 un d\u00e9veloppeur, estim\u00e9e en termes d'effort, et associ\u00e9e \u00e0 un Milestone repr\u00e9sentant la version cible.</p> <p>Phase 2 : D\u00e9veloppement</p> <p>Le d\u00e9veloppeur cr\u00e9e une branche feature suivant les conventions GitFlow :</p> Bash<pre><code>git flow feature start tableau-de-bord-utilisateur\n</code></pre> <p>Cette action cr\u00e9e automatiquement une branche <code>feature/tableau-de-bord-utilisateur</code> bas\u00e9e sur develop. Le d\u00e9veloppeur effectue des commits r\u00e9guliers documentant sa progression.</p> <p>Phase 3 : R\u00e9vision</p> <p>Quand le d\u00e9veloppement est complet, une merge request est cr\u00e9\u00e9e. Cette MR r\u00e9f\u00e9rence l'issue originale, d\u00e9crivant les modifications et permettant aux autres d\u00e9veloppeurs de r\u00e9viser le code.</p> <p>Phase 4 : Int\u00e9gration</p> <p>Apr\u00e8s approbation et v\u00e9rifications automatiques r\u00e9ussies, le code est fusionn\u00e9 dans develop. La librairie GitFlow g\u00e8re automatiquement cette fusion :</p> Bash<pre><code>git flow feature finish tableau-de-bord-utilisateur\n</code></pre> <p>Phase 5 : Release</p> <p>Quand plusieurs fonctionnalit\u00e9s sont int\u00e9gr\u00e9es et pr\u00eates, une branche release est cr\u00e9\u00e9e :</p> Bash<pre><code>git flow release start 3.0.0\n</code></pre> <p>Des tests d'int\u00e9gration complets sont effectu\u00e9s. Une fois valid\u00e9e, la release est finalis\u00e9e :</p> Bash<pre><code>git flow release finish 3.0.0\n</code></pre> <p>Cette commande automatise plusieurs \u00e9tapes : la fusion dans main, la cr\u00e9ation d'un tag annot\u00e9, et la r\u00e9int\u00e9gration dans develop.</p> <p>Phase 6 : Production</p> <p>Le tag cr\u00e9\u00e9 d\u00e9clenche un pipeline CI/CD qui automatise les tests de production et le d\u00e9ploiement. L'issue originale est marqu\u00e9e comme r\u00e9solue et le Milestone progresse.</p>"},{"location":"_projects/_formation-git/git-chap08/#communication-et-collaboration","title":"Communication et collaboration","text":"<p>Tout au long de ce processus, la plateforme Gitlab maintient une trace compl\u00e8te. L'issue contient les commentaires de l'\u00e9quipe, les d\u00e9cisions prises et l'\u00e9volution de la compr\u00e9hension du probl\u00e8me. La merge request documente les choix d'impl\u00e9mentation. Les commits fournissent un historique d\u00e9taill\u00e9 des modifications.</p> <p>Cette documentation implicite constitue une ressource pr\u00e9cieuse pour les futurs mainteneurs du projet et pour les futurs contributeurs cherchant \u00e0 comprendre les d\u00e9cisions pass\u00e9es.</p>"},{"location":"_projects/_formation-git/git-chap08/#gestion-des-versions-multiples","title":"Gestion des versions multiples","text":"<p>Pour les projets devant maintenir plusieurs versions en production, ce workflow offre une flexibilit\u00e9 remarquable. Si un bug critique est d\u00e9couvert en production dans la version 2.x tandis que la version 3.0 est en d\u00e9veloppement, un hotfix branch peut \u00eatre cr\u00e9\u00e9 depuis le tag de la version 2.x :</p> Bash<pre><code>git flow hotfix start correction-securite-2.x\n</code></pre> <p>Ce correctif est appliqu\u00e9, test\u00e9, puis fusionn\u00e9 \u00e0 la fois dans main (production) et dans develop (prochaine version), assurant que le correctif de s\u00e9curit\u00e9 b\u00e9n\u00e9ficie \u00e0 toutes les branches.</p>"},{"location":"_projects/_formation-git/git-chap08/#conclusion-du-chemin-dapprentissage","title":"\ud83d\udcdd Conclusion du chemin d'apprentissage","text":"<p>Le passage de la gestion simple de code avec Git \u00e0 la gestion compl\u00e8te de projets collaboratifs avec Gitlab repr\u00e9sente une progression logique et structur\u00e9e. Les tickets offrent une structure pour organiser le travail. GitFlow fournit une discipline pour g\u00e9rer les branches et les releases. Les merge requests garantissent la qualit\u00e9 du code par r\u00e9vision. Les Milestones structurent les objectifs strat\u00e9giques. Les tags marquent les points de r\u00e9f\u00e9rence importants.</p> <p>La ma\u00eetrise progressive de ces \u00e9l\u00e9ments, de la cr\u00e9ation de tickets simples \u00e0 l'orchestration d'une release compl\u00e8te impliquant plusieurs branches, plusieurs revues et plusieurs d\u00e9ploiements, constitue le fondement de la gestion professionnelle de projets logiciels modernes. \ud83c\udfaf</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-git/git-chap09/","title":"Citations","text":"<ul> <li>https://graphite.com/guides/git-alias</li> <li>https://x-team.com/magazine/git-aliases-to-improve-your-workflow</li> <li>https://www.datacamp.com/tutorial/git-alias</li> <li>https://www.eficode.com/blog/10-levels-of-git-aliases-beginner-to-intermediate-concepts</li> <li>https://victorzhou.com/blog/git-aliases/</li> <li>https://git-scm.com/book/en/v2/Git-Basics-Git-Aliases</li> <li>https://opensource.com/article/20/11/git-aliases</li> <li>https://www.atlassian.com/git/tutorials/git-alias</li> <li>https://gist.github.com/johnpolacek/69604a1f6861129ef088</li> </ul>"},{"location":"_projects/_formation-git/git-chap09/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 253</li> <li>completion_tokens: 8932</li> <li>total_tokens: 9185</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.134, 'request_cost': 0.006, 'total_cost': 0.141}</li> </ul>"},{"location":"_projects/_formation-git/git-chap09/#content","title":"Content","text":""},{"location":"_projects/_formation-git/git-chap09/#chapitre-9-notions-avancees-git","title":"Chapitre 9 : Notions avanc\u00e9es Git","text":""},{"location":"_projects/_formation-git/git-chap09/#introduction-generale","title":"\ud83c\udfaf Introduction g\u00e9n\u00e9rale","text":"<p>Ce chapitre aborde les concepts avanc\u00e9s de Git qui permettent d'optimiser et de personnaliser le flux de travail. Les notions pr\u00e9sent\u00e9es ici constituent des outils puissants pour les d\u00e9veloppeurs cherchant \u00e0 automatiser des t\u00e2ches, organiser leur code de mani\u00e8re efficace et ma\u00eetriser les workflows complexes.</p>"},{"location":"_projects/_formation-git/git-chap09/#1-introduction-aux-hooks-git","title":"1\ufe0f\u20e3 Introduction aux hooks Git","text":""},{"location":"_projects/_formation-git/git-chap09/#definition-et-principes-fondamentaux","title":"D\u00e9finition et principes fondamentaux","text":"<p>Les hooks Git sont des scripts personnalis\u00e9s qui s'ex\u00e9cutent automatiquement lors d'\u00e9v\u00e9nements sp\u00e9cifiques du cycle de vie de Git. Ils permettent d'automatiser des t\u00e2ches, d'appliquer des r\u00e8gles de codage ou de d\u00e9clencher des actions sans intervention manuelle. Les hooks fonctionnent comme des points d'accroche dans le processus de gestion de version.</p>"},{"location":"_projects/_formation-git/git-chap09/#architecture-des-hooks","title":"Architecture des hooks","text":"<p>Le syst\u00e8me de hooks Git repose sur une structure en deux cat\u00e9gories principales :</p> <p>Hooks c\u00f4t\u00e9 client (Client-side hooks)</p> <p>Ces hooks s'ex\u00e9cutent sur la machine locale du d\u00e9veloppeur. Ils interviennent lors de commandes comme commit, merge ou push. Les hooks client incluent :</p> <ul> <li>Pre-commit : s'ex\u00e9cute avant la cr\u00e9ation d'un commit, permettant de v\u00e9rifier le code ou les fichiers</li> <li>Prepare-commit-msg : modifie le message de commit avant son \u00e9dition</li> <li>Commit-msg : valide le message de commit selon des r\u00e8gles d\u00e9finies</li> <li>Post-commit : s'ex\u00e9cute apr\u00e8s la cr\u00e9ation du commit</li> <li>Pre-rebase : s'ex\u00e9cute avant un rebasage</li> <li>Post-checkout : s'ex\u00e9cute apr\u00e8s un changement de branche</li> <li>Post-merge : s'ex\u00e9cute apr\u00e8s une fusion</li> </ul> <p>Hooks c\u00f4t\u00e9 serveur (Server-side hooks)</p> <p>Ces hooks s'ex\u00e9cutent sur le serveur Git lors des op\u00e9rations distantes. Ils incluent :</p> <ul> <li>Pre-receive : s'ex\u00e9cute avant d'accepter un push</li> <li>Update : s'ex\u00e9cute pour chaque branche lors d'un push</li> <li>Post-receive : s'ex\u00e9cute apr\u00e8s qu'un push soit complet</li> </ul>"},{"location":"_projects/_formation-git/git-chap09/#localisation-des-hooks","title":"Localisation des hooks","text":"<p>Les hooks Git sont stock\u00e9s dans le r\u00e9pertoire <code>.git/hooks</code> de chaque d\u00e9p\u00f4t. Ce r\u00e9pertoire contient des fichiers d'exemple avec l'extension <code>.sample</code>. Pour activer un hook, il faut renommer le fichier en supprimant l'extension <code>.sample</code>.</p> Bash<pre><code># Localisation des hooks\nls -la .git/hooks/\n\n# Exemple de structure\n.git/hooks/\n\u251c\u2500\u2500 applypatch-msg.sample\n\u251c\u2500\u2500 commit-msg.sample\n\u251c\u2500\u2500 post-update.sample\n\u251c\u2500\u2500 pre-commit.sample\n\u251c\u2500\u2500 pre-push.sample\n\u251c\u2500\u2500 pre-rebase.sample\n\u2514\u2500\u2500 update.sample\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#creation-et-execution-dun-hook","title":"Cr\u00e9ation et ex\u00e9cution d'un hook","text":"<p>Pour cr\u00e9er un hook, il faut cr\u00e9er un fichier ex\u00e9cutable dans le r\u00e9pertoire <code>.git/hooks</code>. Le fichier doit \u00eatre en lecture/ex\u00e9cution et contenir un script (bash, python, etc.).</p> <p>Exemple pratique : Hook pre-commit pour v\u00e9rifier la syntaxe</p> Bash<pre><code>#!/bin/bash\n# .git/hooks/pre-commit\n\n# R\u00e9cup\u00e8re les fichiers modifi\u00e9s\nSTAGED_FILES=$(git diff --cached --name-only)\n\n# V\u00e9rifie la pr\u00e9sence de fichiers Python\nfor FILE in $STAGED_FILES; do\n    if [[ $FILE == *.py ]]; then\n        # V\u00e9rifie la syntaxe Python\n        python3 -m py_compile \"$FILE\"\n        if [ $? -ne 0 ]; then\n            echo \"Erreur : Syntaxe Python invalide dans $FILE\"\n            exit 1\n        fi\n    fi\ndone\n\nexit 0\n</code></pre> <p>Pour rendre ce script ex\u00e9cutable :</p> Bash<pre><code>chmod +x .git/hooks/pre-commit\n</code></pre> <p>Exemple pratique : Hook commit-msg pour valider le format du message</p> Bash<pre><code>#!/bin/bash\n# .git/hooks/commit-msg\n\n# R\u00e9cup\u00e8re le fichier contenant le message\nCOMMIT_MSG_FILE=$1\n\n# Lit le message de commit\nCOMMIT_MSG=$(cat \"$COMMIT_MSG_FILE\")\n\n# V\u00e9rifie que le message commence par un pr\u00e9fixe valide\nif ! [[ $COMMIT_MSG =~ ^(feat|fix|docs|style|refactor|test|chore): ]]; then\n    echo \"Erreur : Le message de commit doit commencer par l'un des pr\u00e9fixes suivants :\"\n    echo \"feat: Pour une nouvelle fonctionnalit\u00e9\"\n    echo \"fix: Pour une correction de bug\"\n    echo \"docs: Pour une modification de documentation\"\n    echo \"style: Pour des modifications sans impact logique\"\n    echo \"refactor: Pour une refactorisation de code\"\n    echo \"test: Pour l'ajout de tests\"\n    echo \"chore: Pour des t\u00e2ches de maintenance\"\n    exit 1\nfi\n\nexit 0\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#gestion-des-permissions-et-partage","title":"Gestion des permissions et partage","text":"<p>Un d\u00e9fi majeur avec les hooks est leur partage entre d\u00e9veloppeurs. Comme le r\u00e9pertoire <code>.git/hooks</code> n'est pas versionn\u00e9 par d\u00e9faut, les hooks ne se propagent pas automatiquement lors d'un clone.</p> <p>Solution 1 : Cr\u00e9er un r\u00e9pertoire versionn\u00e9 pour les hooks</p> Bash<pre><code># Cr\u00e9er un r\u00e9pertoire hooks\nmkdir -p scripts/git-hooks\n\n# Cr\u00e9er un script d'installation\ncat &gt; scripts/install-hooks.sh &lt;&lt; 'EOF'\n#!/bin/bash\n# Script d'installation des hooks\n\ncp scripts/git-hooks/* .git/hooks/\nchmod +x .git/hooks/*\necho \"Hooks install\u00e9s avec succ\u00e8s\"\nEOF\n\nchmod +x scripts/install-hooks.sh\n</code></pre> <p>Solution 2 : Utiliser un hook d'initialisation</p> Bash<pre><code># .git/hooks/post-checkout\n#!/bin/bash\n\n# V\u00e9rifie si le fichier .git/hooks-config existe\nif [ -f \"scripts/hooks-config.sh\" ]; then\n    bash scripts/hooks-config.sh\nfi\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#2-librairies-pour-les-hooks","title":"2\ufe0f\u20e3 Librairies pour les hooks","text":""},{"location":"_projects/_formation-git/git-chap09/#frameworks-de-gestion-des-hooks","title":"Frameworks de gestion des hooks","text":"<p>Plusieurs outils et librairies facilitent la gestion des hooks Git en automatisant leur installation et en fournissant des fonctionnalit\u00e9s avanc\u00e9es.</p>"},{"location":"_projects/_formation-git/git-chap09/#husky","title":"Husky","text":"<p>Husky est une librairie Node.js populaire qui simplifie la gestion des hooks Git. Elle permet de d\u00e9finir les hooks dans le fichier <code>package.json</code> ou dans un fichier de configuration d\u00e9di\u00e9.</p> <p>Installation et configuration de Husky</p> Bash<pre><code># Installation via npm\nnpm install husky --save-dev\n\n# Initialisation de Husky\nnpx husky install\n\n# Cr\u00e9ation d'un hook pre-commit\nnpx husky add .husky/pre-commit \"npm run lint\"\n</code></pre> <p>Fichier <code>package.json</code> avec Husky</p> JSON<pre><code>{\n  \"name\": \"mon-projet\",\n  \"version\": \"1.0.0\",\n  \"scripts\": {\n    \"lint\": \"eslint src/\",\n    \"format\": \"prettier --write src/\",\n    \"test\": \"jest\"\n  },\n  \"devDependencies\": {\n    \"husky\": \"^8.0.0\",\n    \"eslint\": \"^8.0.0\",\n    \"prettier\": \"^3.0.0\",\n    \"jest\": \"^29.0.0\"\n  }\n}\n</code></pre> <p>Structure des fichiers Husky</p> Text Only<pre><code>.husky/\n\u251c\u2500\u2500 _/\n\u2502   \u251c\u2500\u2500 .gitignore\n\u2502   \u2514\u2500\u2500 husky.sh\n\u251c\u2500\u2500 pre-commit\n\u251c\u2500\u2500 commit-msg\n\u2514\u2500\u2500 pre-push\n</code></pre> <p>Exemple de hook pre-commit avec Husky</p> Bash<pre><code>#!/bin/sh\n. \"$(dirname \"$0\")/_/husky.sh\"\n\nnpm run lint\nnpm run test\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#pre-commit-framework-python","title":"Pre-commit (Framework Python)","text":"<p>Pre-commit est un framework multilangage qui g\u00e8re les hooks Git. Il est particuli\u00e8rement utile pour les projets polyglotes.</p> <p>Installation et configuration</p> Bash<pre><code># Installation via pip\npip install pre-commit\n\n# Cr\u00e9ation du fichier de configuration\ncat &gt; .pre-commit-config.yaml &lt;&lt; 'EOF'\nrepos:\n  - repo: https://github.com/pre-commit/pre-commit-hooks\n    rev: v4.4.0\n    hooks:\n      - id: trailing-whitespace\n      - id: end-of-file-fixer\n      - id: check-yaml\n      - id: check-added-large-files\n  - repo: https://github.com/psf/black\n    rev: 23.3.0\n    hooks:\n      - id: black\n  - repo: https://github.com/PyCQA/flake8\n    rev: 6.0.0\n    hooks:\n      - id: flake8\nEOF\n\n# Installation des hooks\npre-commit install\n\n# Ex\u00e9cution manuelle sur tous les fichiers\npre-commit run --all-files\n</code></pre> <p>Avantages du framework Pre-commit</p> Aspect D\u00e9tail Multilangage Support natif de Python, JavaScript, Go, Ruby, etc. Isolation Chaque hook s'ex\u00e9cute dans son propre environnement Versionnage Permet de fixer les versions des outils utilis\u00e9s Partage Le fichier <code>.pre-commit-config.yaml</code> se partage facilement Flexibilit\u00e9 Possibilit\u00e9 de cr\u00e9er des hooks personnalis\u00e9s"},{"location":"_projects/_formation-git/git-chap09/#lefthook","title":"Lefthook","text":"<p>Lefthook est un gestionnaire de hooks \u00e9crit en Go, reconnu pour sa rapidit\u00e9 et sa l\u00e9g\u00e8ret\u00e9.</p> <p>Installation et configuration</p> Bash<pre><code># Installation via npm\nnpm install lefthook --save-dev\n\n# Initialisation\nnpx lefthook install\n\n# Configuration dans lefthook.yml\ncat &gt; lefthook.yml &lt;&lt; 'EOF'\npre-commit:\n  commands:\n    lint:\n      glob: \"src/**/*.js\"\n      run: eslint {staged_files}\n    format:\n      glob: \"src/**/*.js\"\n      run: prettier --write {staged_files}\n\ncommit-msg:\n  commands:\n    commitlint:\n      run: commitlint --edit $1\nEOF\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#comparaison-des-frameworks","title":"Comparaison des frameworks","text":"Crit\u00e8re Husky Pre-commit Lefthook Langage JavaScript/Node Python Go Vitesse Mod\u00e9r\u00e9e Bonne Excellente Multilangage Non natif Oui Oui Installation npm pip npm/brew Courbe d'apprentissage Facile Mod\u00e9r\u00e9e Facile Configuration JSON/YAML YAML YAML"},{"location":"_projects/_formation-git/git-chap09/#3-les-alias-git","title":"3\ufe0f\u20e3 Les alias Git","text":""},{"location":"_projects/_formation-git/git-chap09/#concept-et-utilite","title":"Concept et utilit\u00e9","text":"<p>Les alias Git sont des raccourcis personnalis\u00e9s qui permettent de remplacer des commandes longues ou complexes par des versions plus courtes et faciles \u00e0 retenir. Ils r\u00e9duisent le temps de saisie et am\u00e9liorent la productivit\u00e9 en automatisant les commandes fr\u00e9quemment utilis\u00e9es.[1]</p>"},{"location":"_projects/_formation-git/git-chap09/#methodes-de-creation","title":"M\u00e9thodes de cr\u00e9ation","text":"<p>M\u00e9thode 1 : Utiliser <code>git config</code></p> <p>La commande <code>git config</code> modifie les fichiers de configuration Git et permet de cr\u00e9er des alias rapidement.[1][3]</p> Bash<pre><code># Syntaxe g\u00e9n\u00e9rale\ngit config [--global] alias.[alias_name] \"[command]\"\n\n# Exemple : cr\u00e9er un alias 'st' pour 'status'\ngit config --global alias.st \"status\"\n</code></pre> <p>M\u00e9thode 2 : \u00c9diter directement le fichier de configuration</p> <p>Le fichier <code>~/.gitconfig</code> (ou <code>.git/config</code> pour une configuration locale) contient la section <code>[alias]</code> o\u00f9 les raccourcis sont d\u00e9finis.[3][4]</p> Bash<pre><code># \u00c9diter le fichier de configuration global\nvim ~/.gitconfig\n</code></pre> <p>Fichier <code>~/.gitconfig</code> avec alias :</p> Text Only<pre><code>[user]\n    name = Jean Dupont\n    email = jean.dupont@exemple.com\n\n[alias]\n    st = status\n    di = diff\n    co = checkout\n    br = branch\n    cm = commit -m\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#alias-de-base-recommandes","title":"Alias de base recommand\u00e9s","text":"<p>Les alias les plus utiles pour d\u00e9buter incluent les commandes courantes du flux de travail Git.[5][6]</p> <p>Alias essentiels</p> Bash<pre><code># Status shorthand\ngit config --global alias.st status\ngit config --global alias.s 'status -sb'\n\n# Branch management\ngit config --global alias.br branch\ngit config --global alias.co checkout\ngit config --global alias.cb 'checkout -b'\n\n# Commit operations\ngit config --global alias.ci commit\ngit config --global alias.cm 'commit -m'\ngit config --global alias.amend 'commit --amend --no-edit'\n\n# Diff operations\ngit config --global alias.di diff\ngit config --global alias.dc 'diff --cached'\n\n# Log operations\ngit config --global alias.lg 'log --oneline --graph --decorate --all'\ngit config --global alias.ll 'log --oneline'\ngit config --global alias.last 'log -1 HEAD'\n</code></pre> <p>Collection compl\u00e8te pour fichier <code>.gitconfig</code>[5]</p> Text Only<pre><code>[alias]\n    s = status\n    d = diff\n    co = checkout\n    br = branch\n    last = log -1 HEAD\n    cane = commit --amend --no-edit\n    lo = log --oneline -n 10\n    pr = pull --rebase\n    st = status -sb\n    ll = log --oneline\n    lg = log --oneline --graph --decorate --all\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#alias-avances-avec-commandes-shell","title":"Alias avanc\u00e9s avec commandes shell","text":"<p>Pour les alias plus complexes, il est possible d'int\u00e9grer des commandes shell en utilisant le pr\u00e9fixe <code>!</code>.[7]</p> <p>Exemple : Alias pour afficher tous les alias existants</p> Bash<pre><code># Ajouter \u00e0 ~/.gitconfig\ngit config --global alias.aliases '!git config --get-regexp ^alias\\\\. | sed -e s/^alias\\\\.// -e s/\\\\ /\\\\ =\\\\ /'\n\n# Utilisation\ngit aliases\n</code></pre> <p>Exemple : Alias pour rechercher du code dans tout l'historique[7]</p> Bash<pre><code># Configuration\ngit config --global alias.se '!git rev-list --all | xargs git grep -F'\n\n# Utilisation : rechercher une cha\u00eene de caract\u00e8res\ngit se \"fonction_perdue\"\n</code></pre> <p>Exemple : Alias pour voir les branches supprim\u00e9es r\u00e9cemment</p> Bash<pre><code>git config --global alias.deleted '!git reflog | grep checkout | tail -20'\n</code></pre> <p>Exemple : Alias pour fusionner et supprimer la branche source</p> Bash<pre><code>git config --global alias.merge-clean '!git merge $1 &amp;&amp; git branch -d $1'\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#configuration-conditionnelle","title":"Configuration conditionnelle","text":"<p>Git permet d'utiliser des configurations diff\u00e9rentes selon le r\u00e9pertoire du projet, ce qui est particuli\u00e8rement utile pour maintenir des alias distincts pour des contextes diff\u00e9rents (travail, personnel, open source).[3]</p> <p>Configuration conditionnelle dans <code>~/.gitconfig</code></p> Text Only<pre><code>[includeIf \"gitdir:~/work/\"]\n    path = ~/.gitconfig-work\n\n[includeIf \"gitdir:~/personal/\"]\n    path = ~/.gitconfig-personal\n</code></pre> <p>Fichier <code>~/.gitconfig-work</code> pour les projets professionnels :</p> Text Only<pre><code>[alias]\n    st = status\n    lg = log --oneline --graph\n    pr = pull --rebase\n    deploys = tag -l 'v*' --sort=-v:refname | head -20\n</code></pre> <p>Fichier <code>~/.gitconfig-personal</code> pour les projets personnels :</p> Text Only<pre><code>[alias]\n    st = status -s\n    co = checkout\n    feature = checkout -b\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#gestion-et-maintenance-des-alias","title":"Gestion et maintenance des alias","text":"<p>Consulter les alias existants</p> Bash<pre><code># Lister tous les alias\ngit config --global -l | grep alias\n\n# Afficher les alias d\u00e9finis localement\ngit config --local -l | grep alias\n\n# Afficher un alias sp\u00e9cifique\ngit config --get alias.st\n</code></pre> <p>Modifier un alias existant</p> Bash<pre><code># Mettre \u00e0 jour un alias\ngit config --global alias.st 'status -sb'\n\n# V\u00e9rifier la modification\ngit config --get alias.st\n</code></pre> <p>Supprimer un alias</p> Bash<pre><code># Suppression via git config\ngit config --global --unset alias.st\n\n# Ou \u00e9diter directement le fichier ~/.gitconfig\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#bonnes-pratiques","title":"Bonnes pratiques","text":"Pratique Description Noms courts Utiliser 1-3 caract\u00e8res pour les alias fr\u00e9quents Coh\u00e9rence Adopter une convention de nommage uniforme Documentation Ajouter des commentaires dans ~/.gitconfig Partage Documenter les alias essentiels pour l'\u00e9quipe \u00c9viter les conflits Ne pas utiliser d'alias qui entre en conflit avec des commandes existantes"},{"location":"_projects/_formation-git/git-chap09/#4-git-lfs-large-file-storage","title":"4\ufe0f\u20e3 Git LFS (Large File Storage)","text":""},{"location":"_projects/_formation-git/git-chap09/#presentation-et-problematiques","title":"Pr\u00e9sentation et probl\u00e9matiques","text":"<p>Git LFS (Large File Storage) est une extension Git qui g\u00e8re les fichiers volumineux de mani\u00e8re efficace. Les syst\u00e8mes de contr\u00f4le de version traditionnels ne sont pas optimis\u00e9s pour les gros fichiers binaires (vid\u00e9os, images haute r\u00e9solution, archives, datasets), ce qui peut ralentir significativement le d\u00e9p\u00f4t et les op\u00e9rations Git.</p> <p>Probl\u00e8mes sans LFS</p> <ul> <li>Les fichiers volumineux augmentent la taille du clone de mani\u00e8re exponentielle</li> <li>Les op\u00e9rations push/pull deviennent tr\u00e8s lentes</li> <li>La bande passante utilis\u00e9e est importante</li> <li>Les op\u00e9rations locales (merge, rebase) consomment beaucoup de RAM</li> </ul>"},{"location":"_projects/_formation-git/git-chap09/#architecture-et-fonctionnement","title":"Architecture et fonctionnement","text":"<p>Git LFS remplace les fichiers volumineux par des pointeurs texte dans le d\u00e9p\u00f4t Git, tandis que le contenu r\u00e9el est stock\u00e9 sur un serveur s\u00e9par\u00e9.</p> <p>Structure d'un pointeur LFS</p> Text Only<pre><code>version https://git-lfs.github.com/spec/v1\noid sha256:2d26d5d1beed9b8e9e8b8e9e8e9e8e9e8e9e8e9e8e9e8e9e8e9e8e9e8\nsize 15728640\n</code></pre> <p>Ce pointeur remplace le fichier volumineux dans le d\u00e9p\u00f4t Git, ce qui permet des clones rapides. Le fichier r\u00e9el est t\u00e9l\u00e9charg\u00e9 lors d'un checkout.</p>"},{"location":"_projects/_formation-git/git-chap09/#installation-et-configuration","title":"Installation et configuration","text":"<p>Installation de Git LFS</p> Bash<pre><code># Sur macOS avec Homebrew\nbrew install git-lfs\n\n# Sur Linux (Ubuntu/Debian)\ncurl -s https://packagecloud.io/install/repositories/github/git-lfs/script.deb.sh | sudo bash\nsudo apt-get install git-lfs\n\n# Sur Windows\n# T\u00e9l\u00e9charger l'installateur depuis https://git-lfs.github.com/\n\n# Initialisation de Git LFS\ngit lfs install\n</code></pre> <p>V\u00e9rification de l'installation</p> Bash<pre><code># V\u00e9rifier que Git LFS est install\u00e9\ngit lfs --version\n\n# Afficher les configurations LFS\ngit lfs env\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#utilisation-basique","title":"Utilisation basique","text":"<p>Tracking de fichiers avec Git LFS</p> <p>Pour que Git LFS g\u00e8re un type de fichier, il faut le d\u00e9clarer dans le fichier <code>.gitattributes</code>.</p> Bash<pre><code># Ajouter un type de fichier \u00e0 LFS\ngit lfs track \"*.psd\"\ngit lfs track \"*.mp4\"\ngit lfs track \"*.zip\"\n\n# Cr\u00e9er le fichier .gitattributes\ncat &gt; .gitattributes &lt;&lt; 'EOF'\n# Images\n*.jpg filter=lfs diff=lfs merge=lfs -text\n*.png filter=lfs diff=lfs merge=lfs -text\n*.gif filter=lfs diff=lfs merge=lfs -text\n*.psd filter=lfs diff=lfs merge=lfs -text\n\n# Vid\u00e9os\n*.mp4 filter=lfs diff=lfs merge=lfs -text\n*.mkv filter=lfs diff=lfs merge=lfs -text\n*.mov filter=lfs diff=lfs merge=lfs -text\n\n# Archives\n*.zip filter=lfs diff=lfs merge=lfs -text\n*.tar filter=lfs diff=lfs merge=lfs -text\n*.rar filter=lfs diff=lfs merge=lfs -text\n\n# Datasets\n*.csv filter=lfs diff=lfs merge=lfs -text\n*.db filter=lfs diff=lfs merge=lfs -text\n\n# Mod\u00e8les machine learning\n*.h5 filter=lfs diff=lfs merge=lfs -text\n*.pkl filter=lfs diff=lfs merge=lfs -text\nEOF\n</code></pre> <p>Workflow avec LFS</p> Bash<pre><code># 1. Ajouter des fichiers volumineux\ncp /path/to/large_file.mp4 ./videos/\n\n# 2. V\u00e9rifier que LFS les g\u00e8re\ngit lfs ls-files\n\n# 3. Commit et push normalement\ngit add videos/large_file.mp4\ngit commit -m \"Ajouter vid\u00e9o de d\u00e9monstration\"\ngit push origin main\n\n# Le fichier volumineux est automatiquement g\u00e9r\u00e9 par LFS\n</code></pre> <p>V\u00e9rification de l'\u00e9tat de LFS</p> Bash<pre><code># Lister les fichiers g\u00e9r\u00e9s par LFS\ngit lfs ls-files\n\n# Afficher des d\u00e9tails sur les fichiers LFS\ngit lfs ls-files --long\n\n# Voir l'espace utilis\u00e9 par LFS\ndu -sh .git/lfs\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#configuration-avancee","title":"Configuration avanc\u00e9e","text":"<p>Utiliser un serveur LFS personnalis\u00e9</p> Bash<pre><code># Configurer le serveur LFS\ngit config --global lfs.url https://serveur-lfs.exemple.com\n\n# Pour un d\u00e9p\u00f4t sp\u00e9cifique\ngit config lfs.url https://serveur-lfs-projet.exemple.com\n</code></pre> <p>Configuration pour les performances</p> Bash<pre><code># Configurer le parall\u00e9lisme des t\u00e9l\u00e9chargements\ngit config lfs.concurrenttransfers 8\n\n# Configurer la taille des chunks\ngit config lfs.chunktransfersize 5242880\n</code></pre> <p>Ignorer les fichiers LFS pour le d\u00e9veloppement local</p> Bash<pre><code># Cr\u00e9er un fichier .git/info/exclude pour ignorer les fichiers LFS\necho \"*.mp4\" &gt;&gt; .git/info/exclude\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#commandes-utiles-de-lfs","title":"Commandes utiles de LFS","text":"Commande Description <code>git lfs track \"*.ext\"</code> Ajouter un type de fichier \u00e0 LFS <code>git lfs untrack \"*.ext\"</code> Arr\u00eater de tracker un type de fichier <code>git lfs ls-files</code> Lister les fichiers g\u00e9r\u00e9s par LFS <code>git lfs migrate</code> Migrer les fichiers volumineux existants vers LFS <code>git lfs prune</code> Nettoyer les fichiers LFS non r\u00e9f\u00e9renc\u00e9s <code>git lfs pull</code> T\u00e9l\u00e9charger les fichiers LFS manquants <code>git lfs fetch</code> R\u00e9cup\u00e9rer les fichiers LFS distants"},{"location":"_projects/_formation-git/git-chap09/#migration-de-fichiers-volumineux-existants","title":"Migration de fichiers volumineux existants","text":"<p>Si un projet contient d\u00e9j\u00e0 des fichiers volumineux dans l'historique, la commande <code>git lfs migrate</code> permet de les convertir.</p> Bash<pre><code># Migrer tous les fichiers .mp4 vers LFS\ngit lfs migrate import --include=\"*.mp4\"\n\n# Migrer plusieurs types\ngit lfs migrate import --include=\"*.mp4,*.psd,*.zip\"\n\n# R\u00e9\u00e9crire tout l'historique (attention : \u00e0 faire avec prudence)\ngit lfs migrate import --everything\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#limitations-et-considerations","title":"Limitations et consid\u00e9rations","text":"<ul> <li>Les serveurs LFS n\u00e9cessitent une configuration suppl\u00e9mentaire</li> <li>Certains services (GitHub, GitLab, Bitbucket) offrent du stockage LFS limit\u00e9</li> <li>La suppression de fichiers LFS de l'historique ne r\u00e9duit pas imm\u00e9diatement l'espace utilis\u00e9</li> </ul>"},{"location":"_projects/_formation-git/git-chap09/#5-utilisation-de-git-cherry-pick","title":"5\ufe0f\u20e3 Utilisation de git cherry-pick","text":""},{"location":"_projects/_formation-git/git-chap09/#concept-et-cas-dusage","title":"Concept et cas d'usage","text":"<p><code>git cherry-pick</code> permet de s\u00e9lectionner et d'appliquer des commits sp\u00e9cifiques d'une branche \u00e0 une autre sans fusionner l'ensemble de la branche. C'est particuli\u00e8rement utile pour appliquer des corrections de bugs ou des fonctionnalit\u00e9s sans faire de fusion compl\u00e8te.</p> <p>Cas d'usage courants</p> <ul> <li>Appliquer une correction d'urgence (hotfix) depuis une branche vers la production</li> <li>Copier des commits de fonctionnalit\u00e9s d'une branche \u00e0 une autre</li> <li>R\u00e9cup\u00e9rer un commit oubli\u00e9</li> <li>Refactoriser les commits d'une branche avant fusion</li> </ul>"},{"location":"_projects/_formation-git/git-chap09/#syntaxe-et-utilisation-basique","title":"Syntaxe et utilisation basique","text":"<p>Syntaxe g\u00e9n\u00e9rale de cherry-pick</p> Bash<pre><code>git cherry-pick &lt;commit-hash&gt;\n</code></pre> <p>Exemple pratique simple</p> Bash<pre><code># 1. Voir les commits disponibles dans une autre branche\ngit log origin/develop --oneline | head -10\n\n# 2. Identifier le hash du commit \u00e0 copier\n# Exemple : abc1234 Corriger bug de validation\n\n# 3. Se placer sur la branche de destination\ngit checkout main\n\n# 4. Appliquer le commit sp\u00e9cifique\ngit cherry-pick abc1234\n\n# 5. V\u00e9rifier que le commit a \u00e9t\u00e9 appliqu\u00e9\ngit log --oneline -1\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#cherry-picking-multiple","title":"Cherry-picking multiple","text":"<p>Pour appliquer plusieurs commits en m\u00eame temps, plusieurs approches sont possibles.</p> <p>Appliquer une s\u00e9rie de commits cons\u00e9cutifs</p> Bash<pre><code># Appliquer tous les commits entre deux points\ngit cherry-pick &lt;commit-debut&gt;..&lt;commit-fin&gt;\n\n# Exemple : appliquer les 3 derniers commits\ngit cherry-pick abc1234..def5678\n\n# Note : le commit de d\u00e9but n'est pas inclus, seul le intervalle entre les deux\n</code></pre> <p>Appliquer une plage inclusive</p> Bash<pre><code># Inclure le commit de d\u00e9but et de fin\ngit cherry-pick &lt;commit-debut&gt;^..&lt;commit-fin&gt;\n\n# Ou utiliser la notation avec trois points\ngit cherry-pick &lt;commit-debut&gt;~1..&lt;commit-fin&gt;\n</code></pre> <p>Appliquer plusieurs commits non-cons\u00e9cutifs</p> Bash<pre><code># Appliquer plusieurs commits sp\u00e9cifiques\ngit cherry-pick abc1234 def5678 ghi9012\n\n# Appliquer dans un ordre sp\u00e9cifique\ngit cherry-pick ghi9012 abc1234 def5678\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#gestion-des-conflits","title":"Gestion des conflits","text":"<p>Le cherry-picking peut g\u00e9n\u00e9rer des conflits si les modifications se chevauchent. Git fournit des m\u00e9canismes pour r\u00e9soudre ces situations.</p> <p>Sc\u00e9nario de conflit</p> Bash<pre><code># Tenter d'appliquer un commit qui cr\u00e9e un conflit\ngit cherry-pick abc1234\n\n# Output : CONFLICT (content): Merge conflict in fichier.js\n</code></pre> <p>R\u00e9solution des conflits</p> Bash<pre><code># 1. Voir le statut des conflits\ngit status\n\n# 2. \u00c9diter les fichiers en conflit et r\u00e9soudre manuellement\n# Les marqueurs de conflit :\n# &lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD\n# Code actuel\n# =======\n# Code \u00e0 cherry-picker\n# &gt;&gt;&gt;&gt;&gt;&gt;&gt; abc1234\n\n# 3. Marquer les fichiers comme r\u00e9solus\ngit add fichier.js\n\n# 4. Continuer le cherry-pick\ngit cherry-pick --continue\n\n# Ou annuler le cherry-pick compl\u00e8tement\ngit cherry-pick --abort\n</code></pre> <p>Strat\u00e9gies de r\u00e9solution</p> Bash<pre><code># Garder la version actuelle en cas de conflit\ngit cherry-pick --strategy-option=ours abc1234\n\n# Utiliser la version du commit \u00e0 cherry-picker\ngit cherry-pick --strategy-option=theirs abc1234\n\n# R\u00e9soudre automatiquement avec une strat\u00e9gie personnalis\u00e9e\ngit cherry-pick -X ours abc1234\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#options-avancees","title":"Options avanc\u00e9es","text":"<p>Cherry-pick avec message de commit personnalis\u00e9</p> Bash<pre><code># Appliquer le commit et modifier le message\ngit cherry-pick --edit abc1234\n\n# Appliquer sans \u00e9diter le message\ngit cherry-pick --no-edit abc1234\n\n# G\u00e9n\u00e9rer un nouveau commit avec le message original\ngit cherry-pick -n abc1234\ngit commit -m \"Appliquer depuis develop: $(git log --format=%B -n 1 abc1234)\"\n</code></pre> <p>Cherry-pick sans cr\u00e9er de commit</p> Bash<pre><code># Appliquer les changements du commit sans cr\u00e9er de commit\ngit cherry-pick --no-commit abc1234\n\n# Cette option permet de :\n# - Combiner plusieurs commits\n# - V\u00e9rifier les changements avant de commiter\n# - Modifier les changements avant de commiter\n\n# Apr\u00e8s modification, cr\u00e9er le commit\ngit commit -m \"Changements appliqu\u00e9s et modifi\u00e9s\"\n</code></pre> <p>Cherry-pick avec signoff</p> Bash<pre><code># Ajouter une ligne \"Signed-off-by\" au message\ngit cherry-pick --signoff abc1234\n\n# Cela ajoute au message :\n# Signed-off-by: Jean Dupont &lt;jean@exemple.com&gt;\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#workflow-avance-hotfix-avec-cherry-pick","title":"Workflow avanc\u00e9 : Hotfix avec cherry-pick","text":"<p>Un sc\u00e9nario courant combine cherry-pick avec un workflow de hotfix efficace.</p> <p>Sc\u00e9nario : Correction d'urgence en production</p> Bash<pre><code># 1. Cr\u00e9er une branche de hotfix depuis main\ngit checkout main\ngit pull origin main\ngit checkout -b hotfix/bug-critique\n\n# 2. Faire la correction\necho \"correction du bug\" &gt; fichier.js\ngit add fichier.js\ngit commit -m \"fix: r\u00e9soudre le bug critique\"\n# Commit hash : abc1234\n\n# 3. Merger la correction dans main (production)\ngit checkout main\ngit merge hotfix/bug-critique\ngit push origin main\n\n# 4. Appliquer la m\u00eame correction dans develop\ngit checkout develop\ngit pull origin develop\n\n# Plut\u00f4t que de refaire la correction ou de merger main dans develop,\n# cherry-picker le commit de hotfix\ngit cherry-pick abc1234\n\n# 5. G\u00e9rer les conflits potentiels et finir\ngit push origin develop\n\n# 6. Nettoyer\ngit branch -d hotfix/bug-critique\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#cherry-pick-en-boucle-avec-script","title":"Cherry-pick en boucle avec script","text":"<p>Pour les cas d'usage complexes impliquant de nombreux commits, un script peut automatiser le processus.</p> Bash<pre><code>#!/bin/bash\n# script-cherry-pick.sh\n# Appliquer une liste de commits avec gestion d'erreur\n\nCOMMITS=(\"abc1234\" \"def5678\" \"ghi9012\")\nBRANCH_DESTINATION=\"main\"\n\n# Basculer vers la branche de destination\ngit checkout \"$BRANCH_DESTINATION\"\n\n# Appliquer chaque commit\nfor COMMIT in \"${COMMITS[@]}\"; do\n    echo \"Application du commit : $COMMIT\"\n\n    if git cherry-pick \"$COMMIT\"; then\n        echo \"\u2713 Commit appliqu\u00e9 avec succ\u00e8s\"\n    else\n        echo \"\u2717 Conflit d\u00e9tect\u00e9 pour $COMMIT\"\n        echo \"Veuillez r\u00e9soudre les conflits et ex\u00e9cuter :\"\n        echo \"git add .\"\n        echo \"git cherry-pick --continue\"\n        exit 1\n    fi\ndone\n\necho \"Tous les commits ont \u00e9t\u00e9 appliqu\u00e9s avec succ\u00e8s\"\ngit log --oneline -n ${#COMMITS[@]}\n</code></pre> <p>Utilisation du script :</p> Bash<pre><code>chmod +x script-cherry-pick.sh\n./script-cherry-pick.sh\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#visualisation-et-verification","title":"Visualisation et v\u00e9rification","text":"<p>Visualiser les commits disponibles pour cherry-pick</p> Bash<pre><code># Voir les commits de la branche source\ngit log origin/develop --oneline -n 10\n\n# Comparer les commits entre deux branches\ngit log --oneline main..develop\n\n# Voir les commits non appliqu\u00e9s dans main qui existent dans develop\ngit log --graph --oneline --all --decorate\n</code></pre> <p>V\u00e9rifier les changements avant cherry-pick</p> Bash<pre><code># Voir quels changements apportera le cherry-pick\ngit show abc1234\n\n# Voir les fichiers affect\u00e9s\ngit show --name-status abc1234\n\n# Voir un diff d\u00e9taill\u00e9\ngit diff main abc1234\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#problemes-courants-et-solutions","title":"Probl\u00e8mes courants et solutions","text":"<p>Probl\u00e8me : Cherry-pick cr\u00e9e des doublons</p> Bash<pre><code># Sympt\u00f4me : Le m\u00eame changement appara\u00eet deux fois\n# Solution : Utiliser le rebase plut\u00f4t que cherry-pick\n\n# Ou \u00e9viter de cherry-picker des commits que vous allez merger\ngit cherry-pick --no-commit abc1234  # Permettre la modification\n</code></pre> <p>Probl\u00e8me : Conflits importants apr\u00e8s cherry-pick</p> Bash<pre><code># Si les conflits sont trop importants, annuler\ngit cherry-pick --abort\n\n# Puis utiliser une approche diff\u00e9rente\ngit rebase --interactive\n# ou\ngit merge branche-source\n</code></pre> <p>Probl\u00e8me : Cherry-pick de commits qui d\u00e9pendent les uns des autres</p> Bash<pre><code># Appliquer les commits dans le bon ordre\n# D\u00e9terminer les d\u00e9pendances\ngit log --oneline feature-branch --reverse\n\n# Appliquer dans l'ordre des d\u00e9pendances\ngit cherry-pick commit1\ngit cherry-pick commit2  # Si d\u00e9pend de commit1\ngit cherry-pick commit3  # Si d\u00e9pend de commit1 ou commit2\n</code></pre>"},{"location":"_projects/_formation-git/git-chap09/#bonnes-pratiques_1","title":"Bonnes pratiques","text":"Pratique Description Documenter l'origine Ajouter un commentaire indiquant d'o\u00f9 provient le commit V\u00e9rifier d'abord Toujours examiner un commit avant de le cherry-picker \u00c9viter l'abus Utiliser le cherry-pick avec mod\u00e9ration, pr\u00e9f\u00e9rer les merges normales Tester apr\u00e8s V\u00e9rifier que le code fonctionne correctement apr\u00e8s cherry-pick Notifier l'\u00e9quipe Indiquer aux autres d\u00e9veloppeurs les commits cherry-pick\u00e9s Limiter la profondeur Ne pas cherry-picker des commits qui ont d\u00e9j\u00e0 \u00e9t\u00e9 cherry-pick\u00e9s"},{"location":"_projects/_formation-git/git-chap09/#synthese-du-chemin-dapprentissage","title":"\ud83d\udcda Synth\u00e8se du chemin d'apprentissage","text":""},{"location":"_projects/_formation-git/git-chap09/#architecture-du-processus-dapprentissage","title":"Architecture du processus d'apprentissage","text":"<p>Le parcours propos\u00e9 suit une progression logique allant des concepts de base aux techniques avanc\u00e9es :</p> <p>1. Fondations : Hooks Git</p> <p>La compr\u00e9hension des hooks Git constitue la base. Les hooks permettent d'automatiser des t\u00e2ches et de mettre en place des processus reproductibles. C'est le point de d\u00e9part id\u00e9al car de nombreux workflows avanc \u00e9s en d\u00e9pendent. Un apprenant doit ma\u00eetriser : - La localisation et l'activation des hooks - La cr\u00e9ation de scripts simples (pre-commit, commit-msg) - Le debugging des hooks</p> <p>2. Outillage : Librairies pour les hooks</p> <p>Une fois les hooks compris, l'apprentissage des frameworks existants (Husky, Pre-commit, Lefthook) permet de b\u00e9n\u00e9ficier de solutions \u00e9prouv\u00e9es. Cette \u00e9tape \u00e9conomise du temps et \u00e9vite de r\u00e9inventer la roue. Les librairies fournissent : - Des abstractions simplifi\u00e9es - Des \u00e9cosyst\u00e8mes d'extensions - Des partages de configuration facilit\u00e9es</p> <p>3. Productivit\u00e9 : Alias Git</p> <p>Les alias constituent l'\u00e9tape la plus accessible mais tr\u00e8s impactante en termes de flux de travail quotidien. Contrairement aux hooks et aux librairies, les alias n'ont pas de pr\u00e9requis complexes et offrent un b\u00e9n\u00e9fice imm\u00e9diat. Cette \u00e9tape consolidide les bonnes habitudes avant d'aborder des sujets plus complexes.</p> <p>4. Scalabilit\u00e9 : Git LFS</p> <p>Git LFS s'adresse aux projets sp\u00e9cifiques manipulant des fichiers volumineux. Ce n'est pas une n\u00e9cessit\u00e9 pour tous les projets, mais c'est un \u00e9l\u00e9ment critique pour certains domaines (machine learning, design, m\u00e9dias). L'apprentissage de LFS doit intervenir apr\u00e8s avoir consolid\u00e9 les bases de Git.</p> <p>5. Expertise : Cherry-pick</p> <p>La ma\u00eetrise de <code>cherry-pick</code> repr\u00e9sente un niveau d'expertise interm\u00e9diaire. Elle suppose une bonne compr\u00e9hension du rebase, du merge et du mod\u00e8le de commits de Git. Cette technique avanc\u00e9e offre une granularit\u00e9 fine dans la gestion des commits et des branches.</p>"},{"location":"_projects/_formation-git/git-chap09/#points-de-connexion-entre-les-modules","title":"Points de connexion entre les modules","text":"<p>Les modules ne sont pas isol\u00e9s mais interagissent :</p> <ul> <li>Hooks + Aliases : Les hooks peuvent utiliser des alias Git</li> <li>Hooks + Librairies : Les librairies automatisent la gestion des hooks</li> <li>LFS + Alias : Un alias peut \u00eatre cr\u00e9\u00e9 pour les commandes LFS fr\u00e9quentes</li> <li>Cherry-pick + Hooks : Un hook peut v\u00e9rifier l'int\u00e9grit\u00e9 des commits cherry-pick\u00e9s</li> </ul>"},{"location":"_projects/_formation-git/git-chap09/#progression-en-spirale","title":"Progression en spirale","text":"<p>Le contenu suit une progression en spirale o\u00f9 chaque module revisit des concepts ant\u00e9rieurs \u00e0 un niveau plus approfondi :</p> <ol> <li>Premiers hooks \u2192 Comprendre l'automatisation</li> <li>Librairies \u2192 Organiser et partager l'automatisation</li> <li>Alias \u2192 Optimiser l'interaction avec l'automatisation</li> <li>LFS \u2192 Adapter l'automatisation \u00e0 des types de fichiers sp\u00e9cialis\u00e9s</li> <li>Cherry-pick \u2192 Automatiser la s\u00e9lection de commits avec pr\u00e9cision</li> </ol>"},{"location":"_projects/_formation-git/git-chap09/#pratiques-transversales","title":"Pratiques transversales","text":"<p>Certaines comp\u00e9tences s'appliquent \u00e0 tous les modules :</p> <ul> <li>\u00c9dition de fichiers de configuration : <code>.gitconfig</code>, <code>.pre-commit-config.yaml</code>, <code>.gitattributes</code>, <code>.git/hooks</code></li> <li>Ex\u00e9cution de scripts : Bash pour les hooks, Python pour Pre-commit</li> <li>Debugging : Inspection de l'\u00e9tat de Git \u00e0 chaque \u00e9tape</li> <li>Documentation : Enregistrer les configurations pour l'\u00e9quipe</li> <li>Test d'ex\u00e9cution : V\u00e9rifier que les changements produisent l'effet attendu</li> </ul>"},{"location":"_projects/_formation-git/git-chap09/#points-cles-de-maitrise-pour-chaque-module","title":"Points cl\u00e9s de ma\u00eetrise pour chaque module","text":"<p>Pour consolider l'apprentissage, un apprenant doit pouvoir :</p> <p>Hooks Git : - Cr\u00e9er et tester un hook pr\u00e9-commit fonctionnel - Diagnostiquer les probl\u00e8mes d'ex\u00e9cution de hooks - Partager les hooks avec une \u00e9quipe</p> <p>Librairies : - Installer et configurer Husky OU Pre-commit OU Lefthook - Int\u00e9grer au moins trois plugins/hooks existants - Adapter la configuration \u00e0 un projet r\u00e9el</p> <p>Alias Git : - Cr\u00e9er 10-15 alias couvrant les op\u00e9rations quotidiennes - Ma\u00eetriser la syntaxe des alias avanc\u00e9s avec <code>!</code> - Configurer les inclusions conditionnelles pour plusieurs contextes</p> <p>Git LFS : - Configurer LFS pour un projet avec fichiers volumineux - Migrer un projet existant vers LFS - Optimiser les performances de t\u00e9l\u00e9chargement</p> <p>Cherry-pick : - Appliquer un commit isol\u00e9 entre branches - R\u00e9soudre les conflits g\u00e9n\u00e9r\u00e9s par cherry-pick - Automatiser le cherry-pick de plusieurs commits</p>"},{"location":"_projects/_formation-git/git-chap09/#conclusion","title":"\u2705 Conclusion","text":"<p>Les notions avanc\u00e9es de Git pr\u00e9sent\u00e9es dans ce chapitre transforment l'utilisation de Git d'un simple outil de versioning \u00e0 un syst\u00e8me complet d'automatisation et d'optimisation du flux de travail. La progression propos\u00e9e guide l'apprenant du conceptuel (hooks) vers le pratique (alias), puis vers l'expert (cherry-pick), en passant par l'outillage (librairies) et la scalabilit\u00e9 (LFS).</p> <p>Chacun de ces domaines offre des b\u00e9n\u00e9fices imm\u00e9diats et durables pour l'efficacit\u00e9 et la fiabilit\u00e9 des processus de d\u00e9veloppement. L'apprentissage de ces concepts permet de ma\u00eetriser pleinement Git et d'adapter son utilisation \u00e0 des contextes et des \u00e9quipes vari\u00e9s.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/","title":"Citations","text":"<ul> <li>https://kinsta.com/fr/blog/configurer-pipeline-ci-cd/</li> <li>https://blog.stephane-robert.info/docs/pipeline-cicd/github/</li> <li>https://www.youtube.com/watch?v=vJkaJ6k54AQ</li> <li>https://www.youtube.com/watch?v=2l-uj4Q-MQM</li> <li>https://docs.github.com/fr/actions/get-started/understand-github-actions</li> <li>https://les-enovateurs.com/github-actions-construire-tester-et-deployer-sans-effort-ci-cd</li> <li>https://labex.io/fr/courses/github-actions-for-beginners</li> <li>https://www.dyma.fr/formations/github-actions</li> <li>https://docs.github.com/fr/actions/get-started/quickstart</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 274</li> <li>completion_tokens: 6287</li> <li>total_tokens: 6561</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.094, 'request_cost': 0.006, 'total_cost': 0.101}</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#content","title":"Content","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap01/#introduction-au-cicd-avec-github-actions","title":"Introduction au CI/CD avec GitHub Actions","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap01/#a-labordage","title":"\u00c0 l'abordage ! \ud83d\ude80","text":"<p>GitHub Actions repr\u00e9sente une plateforme r\u00e9volutionnaire pour l'automatisation des pipelines logiciels. Cette technologie, int\u00e9gr\u00e9e directement \u00e0 GitHub, permet aux d\u00e9veloppeurs de construire, tester et d\u00e9ployer leurs applications sans quitter leur environnement de travail habituel[5]. L'objectif de ce chapitre est de poser les fondations n\u00e9cessaires pour comprendre comment GitHub Actions s'inscrit dans une strat\u00e9gie d'int\u00e9gration continue et de livraison continue (CI/CD).</p> <p>La philosophie derri\u00e8re GitHub Actions repose sur l'automatisation intelligente des processus r\u00e9p\u00e9titifs. Plut\u00f4t que de g\u00e9rer manuellement les builds, les tests et les d\u00e9ploiements, les d\u00e9veloppeurs peuvent d\u00e9finir des workflows qui s'ex\u00e9cutent automatiquement en r\u00e9ponse \u00e0 des \u00e9v\u00e9nements sp\u00e9cifiques[1]. Cette automatisation lib\u00e8re du temps pr\u00e9cieux et r\u00e9duit consid\u00e9rablement les risques d'erreurs humaines dans le cycle de d\u00e9veloppement.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#introduction-au-devops","title":"Introduction au DevOps","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap01/#comprendre-lorigine-du-devops","title":"Comprendre l'origine du DevOps","text":"<p>Le DevOps \u00e9merge de la fusion de deux mondes traditionnellement s\u00e9par\u00e9s : le d\u00e9veloppement (Dev) et les op\u00e9rations (Ops). Historiquement, ces deux disciplines op\u00e9raient en silos distincts, cr\u00e9ant des frictions et des inefficacit\u00e9s dans la livraison de logiciels. Le DevOps brise cette barri\u00e8re en pr\u00f4nant une collaboration \u00e9troite entre les d\u00e9veloppeurs, les administrateurs syst\u00e8mes et les ing\u00e9nieurs de d\u00e9ploiement.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#les-principes-fondamentaux-du-devops","title":"Les principes fondamentaux du DevOps","text":"<p>Automation : Le principe central du DevOps consiste \u00e0 automatiser les t\u00e2ches r\u00e9p\u00e9titives. Cela inclut non seulement le code, mais aussi l'infrastructure, les tests et le d\u00e9ploiement. GitHub Actions s'inscrit directement dans cette philosophie en offrant un m\u00e9canisme d'automatisation puissant.</p> <p>Collaboration : Les barri\u00e8res traditionnelles entre les \u00e9quipes doivent s'estomper. Les d\u00e9veloppeurs comprennent les enjeux op\u00e9rationnels, tandis que les administrateurs syst\u00e8mes comprennent les contraintes du d\u00e9veloppement.</p> <p>Monitoring et feedback : L'observation continue des applications en production permet d'identifier rapidement les probl\u00e8mes et d'ajuster les strat\u00e9gies de d\u00e9veloppement et de d\u00e9ploiement.</p> <p>Infrastructure as Code : L'infrastructure est d\u00e9finie et g\u00e9r\u00e9e comme du code source, permettant une reproductibilit\u00e9 et une versioning compl\u00e8te.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#limpact-sur-le-cycle-de-developpement","title":"L'impact sur le cycle de d\u00e9veloppement","text":"<p>Dans un environnement DevOps, le cycle de d\u00e9veloppement s'acc\u00e9l\u00e8re drastiquement. Les d\u00e9ploiements, autrefois des \u00e9v\u00e9nements rares et stressants, deviennent des op\u00e9rations quotidiennes et automatis\u00e9es. Cette transformation permet aux organisations de r\u00e9agir plus rapidement aux besoins du march\u00e9 et de corriger les bugs bien plus rapidement.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#quest-ce-que-lintegration-et-la-livraison-continues","title":"Qu'est-ce que l'int\u00e9gration et la livraison continues ?","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap01/#integration-continue-ci","title":"Int\u00e9gration Continue (CI)","text":"<p>L'int\u00e9gration continue est une pratique de d\u00e9veloppement o\u00f9 les d\u00e9veloppeurs int\u00e8grent leur code dans un d\u00e9p\u00f4t central plusieurs fois par jour[1]. Chaque int\u00e9gration est v\u00e9rifi\u00e9e automatiquement par un build automatis\u00e9 et des tests automatis\u00e9s, permettant d'identifier les probl\u00e8mes d'int\u00e9gration le plus t\u00f4t possible.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#objectifs-de-lintegration-continue","title":"Objectifs de l'int\u00e9gration continue","text":"<ul> <li>D\u00e9tecter les bugs rapidement : Plut\u00f4t que d'attendre plusieurs mois avant une release majeure, les probl\u00e8mes sont identifi\u00e9s en heures ou en minutes.</li> <li>R\u00e9duire les efforts de d\u00e9ploiement : Avec une int\u00e9gration continue, le code est toujours dans un \u00e9tat potentiellement d\u00e9ployable.</li> <li>Am\u00e9liorer la confiance : L'automatisation compl\u00e8te des tests cr\u00e9e une base solide de confiance dans la qualit\u00e9 du code.</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#workflow-typique-dintegration-continue","title":"Workflow typique d'int\u00e9gration continue","text":"Text Only<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502          D\u00e9veloppeur pousse du code                  \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                     \u2502\n                     \u25bc\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502  Build automatique         \u2502\n         \u2502  (compilation, packaging)  \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502\n                      \u25bc\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502  Tests automatis\u00e9s         \u2502\n         \u2502  (unitaires, int\u00e9gration)  \u2502\n         \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n                      \u2502\n         \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n         \u2502                         \u2502\n    \u2705 Succ\u00e8s              \u274c \u00c9chec\n         \u2502                         \u2502\n         \u25bc                         \u25bc\n    Code int\u00e9gr\u00e9      Notification d'erreur\n                      Arr\u00eat du processus\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#livraison-continue-cd","title":"Livraison Continue (CD)","text":"<p>La livraison continue \u00e9tend l'int\u00e9gration continue en automatisant le d\u00e9ploiement du code dans les environnements de staging ou de production[1]. Une distinction importante : la livraison continue ne signifie pas qu'un d\u00e9ploiement en production se fait automatiquement \u00e0 chaque commit. Elle signifie que le code est pr\u00eat pour la production et peut \u00eatre d\u00e9ploy\u00e9 \u00e0 tout moment avec un simple clic.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#deploiement-continu-vs-livraison-continue","title":"D\u00e9ploiement continu vs Livraison continue","text":"Aspect Livraison Continue D\u00e9ploiement Continu Automatisation Tests et staging automatis\u00e9s Tout est automatis\u00e9, y compris la production D\u00e9ploiement en production Manuel (d\u00e9cision humaine) Automatique (si les tests passent) Fr\u00e9quence des releases R\u00e9guli\u00e8re (quelques fois par semaine) Tr\u00e8s fr\u00e9quente (plusieurs fois par jour) Risque Mod\u00e9r\u00e9 (contr\u00f4le humain sur la production) Plus \u00e9lev\u00e9 (moins de contr\u00f4le humain) Cas d'usage Id\u00e9al pour la plupart des applications Convient aux startups et services SaaS"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#benefices-de-la-livraison-continue","title":"B\u00e9n\u00e9fices de la livraison continue","text":"<ul> <li>Feedback utilisateur rapide : Les nouvelles fonctionnalit\u00e9s atteignent les utilisateurs rapidement.</li> <li>R\u00e9duction du time-to-market : Les organisations peuvent rivaliser plus efficacement sur le march\u00e9.</li> <li>Meilleure qualit\u00e9 : Les tests continus garantissent une qualit\u00e9 constante du code.</li> <li>R\u00e9duction des risques : Les d\u00e9ploiements plus fr\u00e9quents et plus petits r\u00e9duisent le risque d'erreurs catastrophiques.</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#comment-github-actions-supporte-cicd","title":"Comment GitHub Actions supporte CI/CD","text":"<p>GitHub Actions fournit les outils n\u00e9cessaires pour impl\u00e9menter \u00e0 la fois l'int\u00e9gration continue et la livraison continue. En utilisant des workflows (ensembles d'actions automatis\u00e9es), les d\u00e9veloppeurs d\u00e9finissent exactement ce qui doit se passer \u00e0 chaque \u00e9tape du processus[2].</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#exemple-concret-pipeline-cicd-simple","title":"Exemple concret : Pipeline CI/CD simple","text":"YAML<pre><code>name: Build, Test, and Deploy\n\non:\n  push:\n    branches: \"main\"\n  pull_request:\n    branches: \"main\"\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout du code\n        uses: actions/checkout@v4\n\n      - name: Installation des d\u00e9pendances\n        run: npm install\n\n      - name: Ex\u00e9cution des tests\n        run: npm test\n\n      - name: Build de l'application\n        run: npm run build\n\n      - name: D\u00e9ploiement en staging\n        if: github.ref == 'refs/heads/main'\n        run: npm run deploy:staging\n</code></pre> <p>Ce workflow s'active automatiquement \u00e0 chaque push ou pull request sur la branche <code>main</code>, ex\u00e9cute les tests, et d\u00e9ploie automatiquement en staging si tous les tests passent.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#le-langage-yaml","title":"Le langage YAML","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap01/#introduction-a-yaml","title":"Introduction \u00e0 YAML","text":"<p>YAML (YAML Ain't Markup Language) est un format de s\u00e9rialisation de donn\u00e9es con\u00e7u pour \u00eatre lisible par les humains[2]. Contrairement \u00e0 JSON ou XML, YAML minimise l'utilisation de symboles et privil\u00e9gie l'indentation pour repr\u00e9senter la structure hi\u00e9rarchique des donn\u00e9es. Dans GitHub Actions, tous les workflows sont d\u00e9finis en YAML.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#syntaxe-fondamentale-de-yaml","title":"Syntaxe fondamentale de YAML","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap01/#scalaires","title":"Scalaires","text":"<p>Les scalaires sont les \u00e9l\u00e9ments de base : strings, nombres, bool\u00e9ens, et null.</p> YAML<pre><code># Cha\u00eene de caract\u00e8res\nnom: GitHub Actions\n\n# Nombre\nversion: 1\nprix: 9.99\n\n# Bool\u00e9en\nactif: true\narchived: false\n\n# Null\nvaleur_vide: null\n# ou encore\nautre_null: ~\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#listes","title":"Listes","text":"<p>Les listes en YAML utilisent le tiret (<code>-</code>) pour d\u00e9noter chaque \u00e9l\u00e9ment.</p> YAML<pre><code># Liste simple\nfruits:\n  - pomme\n  - banane\n  - orange\n\n# Liste de nombres\nnombres: [1, 2, 3, 4, 5]\n\n# Liste imbriqu\u00e9e\nutilisateurs:\n  - nom: Alice\n    age: 30\n  - nom: Bob\n    age: 25\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#dictionnairesmaps","title":"Dictionnaires/Maps","text":"<p>Les dictionnaires structurent les donn\u00e9es en paires cl\u00e9-valeur.</p> YAML<pre><code># Dictionnaire simple\npersonne:\n  nom: Jean\n  age: 35\n  email: jean@example.com\n\n# Dictionnaire imbriqu\u00e9\nentreprise:\n  nom: TechCorp\n  localisation:\n    ville: Paris\n    pays: France\n  employes: 500\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#chaines-multilignes","title":"Cha\u00eenes multilignes","text":"<p>Quand il s'agit de texte plus long, YAML offre plusieurs options.</p> YAML<pre><code># Bloc litt\u00e9ral (pr\u00e9serve les retours \u00e0 la ligne)\ndescription: |\n  Ceci est une description\n  sur plusieurs lignes\n  avec pr\u00e9servation des sauts\n\n# Bloc pli\u00e9 (remplace les sauts de ligne par des espaces)\nresume: &gt;\n  Ceci est un r\u00e9sum\u00e9\n  qui sera sur une seule ligne\n  \u00e0 cause du pli\u00e9\n\n# Entre guillemets (avec \u00e9chappement)\ncommande: \"echo \\\"Bonjour\\\" &amp;&amp; echo \\\"Monde\\\"\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#structure-dun-workflow-github-actions-en-yaml","title":"Structure d'un workflow GitHub Actions en YAML","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap01/#niveau-1-metadonnees-du-workflow","title":"Niveau 1 : M\u00e9tadonn\u00e9es du workflow","text":"YAML<pre><code>name: Mon Premier Workflow\ndescription: Description du workflow\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#niveau-2-evenements-declencheurs","title":"Niveau 2 : \u00c9v\u00e9nements d\u00e9clencheurs","text":"YAML<pre><code>on:\n  push:\n    branches: [\"main\", \"develop\"]\n    paths:\n      - \"src/**\"\n      - \"tests/**\"\n  pull_request:\n    branches: [\"main\"]\n  schedule:\n    - cron: \"0 9 * * MON\"  # Chaque lundi \u00e0 9h\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#niveau-3-variables-denvironnement","title":"Niveau 3 : Variables d'environnement","text":"YAML<pre><code>env:\n  NODE_VERSION: \"18\"\n  DATABASE_URL: \"postgresql://localhost/mydb\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#niveau-4-jobs-et-steps","title":"Niveau 4 : Jobs et steps","text":"YAML<pre><code>jobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Setup Node\n        uses: actions/setup-node@v3\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n\n      - name: Run tests\n        run: npm test\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#exemple-complet-dun-workflow-yaml-pour-un-projet-nodejs","title":"Exemple complet d'un workflow YAML pour un projet Node.js","text":"YAML<pre><code>name: Node.js CI\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\nenv:\n  NODE_VERSION: '18.x'\n  NPM_REGISTRY: 'https://registry.npmjs.org'\n\njobs:\n  lint-and-test:\n    name: Lint &amp; Test\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [16.x, 18.x, 20.x]\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n\n      - name: Setup Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v3\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: 'npm'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run linter\n        run: npm run lint\n\n      - name: Run tests\n        run: npm test -- --coverage\n\n      - name: Upload coverage reports\n        uses: codecov/codecov-action@v3\n        if: matrix.node-version == '18.x'\n        with:\n          files: ./coverage/coverage-final.json\n\n  build:\n    name: Build Application\n    runs-on: ubuntu-latest\n    needs: lint-and-test\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Build application\n        run: npm run build\n\n      - name: Archive build artifacts\n        uses: actions/upload-artifact@v3\n        with:\n          name: dist\n          path: dist/\n          retention-days: 5\n\n  deploy:\n    name: Deploy to Staging\n    runs-on: ubuntu-latest\n    needs: build\n    if: github.ref == 'refs/heads/main'\n\n    steps:\n      - name: Download artifacts\n        uses: actions/download-artifact@v3\n        with:\n          name: dist\n\n      - name: Deploy to staging server\n        run: |\n          echo \"D\u00e9ploiement en cours...\"\n          # Commandes de d\u00e9ploiement r\u00e9elles ici\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#concepts-yaml-critiques-pour-github-actions","title":"Concepts YAML critiques pour GitHub Actions","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap01/#variables-et-interpolation","title":"Variables et interpolation","text":"YAML<pre><code>env:\n  APP_NAME: myapp\n  VERSION: 1.0.0\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Print version\n        run: echo \"D\u00e9ploiement de ${{ env.APP_NAME }} v${{ env.VERSION }}\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#conditions","title":"Conditions","text":"YAML<pre><code>jobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Deploy only on main branch\n        if: github.ref == 'refs/heads/main'\n        run: ./deploy.sh\n\n      - name: Run on pull request\n        if: github.event_name == 'pull_request'\n        run: npm test\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#matrice-de-build","title":"Matrice de build","text":"YAML<pre><code>jobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        python-version: [3.8, 3.9, '3.10', 3.11]\n        os: [ubuntu-latest, macos-latest, windows-latest]\n\n    steps:\n      - uses: actions/checkout@v4\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ matrix.python-version }}\n      - name: Run tests\n        run: pytest\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#mise-en-place-de-lenvironnement","title":"Mise en place de l'environnement","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap01/#prerequis-techniques","title":"Pr\u00e9requis techniques","text":"<p>Avant de commencer avec GitHub Actions, il est n\u00e9cessaire de disposer de certains outils et acc\u00e8s :</p> <p>Compte GitHub : Un compte GitHub actif avec la permission de cr\u00e9er et modifier des workflows. Les workflows publics sont gratuits pour tous les utilisateurs, tandis que les workflows priv\u00e9s b\u00e9n\u00e9ficient d'une allocation gratuite mensuelle g\u00e9n\u00e9reuse.</p> <p>Git install\u00e9 localement : Pour cloner et g\u00e9rer vos d\u00e9p\u00f4ts GitHub localement. Vous pouvez t\u00e9l\u00e9charger Git depuis git-scm.com.</p> <p>Un \u00e9diteur de code : VS Code, JetBrains IDEs, Sublime Text, ou tout autre \u00e9diteur supportant YAML est recommand\u00e9 pour \u00e9diter les fichiers de workflow.</p> <p>Connaissances en ligne de commande : Une familiarit\u00e9 basique avec le terminal ou PowerShell pour ex\u00e9cuter des commandes Git et tester les workflows localement.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#creer-un-depot-github","title":"Cr\u00e9er un d\u00e9p\u00f4t GitHub","text":"<p>La premi\u00e8re \u00e9tape concr\u00e8te consiste \u00e0 cr\u00e9er un d\u00e9p\u00f4t GitHub ou d'utiliser un d\u00e9p\u00f4t existant. GitHub Actions s'int\u00e8gre directement aux d\u00e9p\u00f4ts GitHub[1].</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#etapes-pour-creer-un-depot","title":"\u00c9tapes pour cr\u00e9er un d\u00e9p\u00f4t","text":"<ol> <li>Se connecter \u00e0 github.com</li> <li>Cliquer sur l'ic\u00f4ne <code>+</code> en haut \u00e0 droite</li> <li>S\u00e9lectionner \"New repository\"</li> <li>Remplir les informations :</li> <li>Repository name : Nom descriptif (exemple : <code>ci-cd-demo</code>)</li> <li>Description : Description br\u00e8ve du projet</li> <li>Public/Private : Choisir selon les besoins</li> <li>Initialize with : S\u00e9lectionner \"Add a README file\"</li> <li>Cliquer sur \"Create repository\"</li> </ol>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#structure-du-depot-pour-github-actions","title":"Structure du d\u00e9p\u00f4t pour GitHub Actions","text":"<p>GitHub Actions cherche automatiquement les fichiers de workflow dans le r\u00e9pertoire <code>.github/workflows/</code> \u00e0 la racine du d\u00e9p\u00f4t. La structure recommand\u00e9e est :</p> Text Only<pre><code>mon-projet/\n\u251c\u2500\u2500 .github/\n\u2502   \u2514\u2500\u2500 workflows/\n\u2502       \u251c\u2500\u2500 ci.yml\n\u2502       \u251c\u2500\u2500 deploy.yml\n\u2502       \u2514\u2500\u2500 tests.yml\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 app.js\n\u2502   \u2514\u2500\u2500 utils.js\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 app.test.js\n\u2502   \u2514\u2500\u2500 utils.test.js\n\u251c\u2500\u2500 package.json\n\u251c\u2500\u2500 README.md\n\u2514\u2500\u2500 .gitignore\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#creer-le-premier-workflow","title":"Cr\u00e9er le premier workflow","text":"<p>La cr\u00e9ation du premier workflow se fait en cr\u00e9ant un fichier YAML dans <code>.github/workflows/</code>.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#methode-1-via-linterface-github","title":"M\u00e9thode 1 : Via l'interface GitHub","text":"<ol> <li>Naviguer vers le d\u00e9p\u00f4t</li> <li>Cliquer sur \"Actions\" en haut</li> <li>Cliquer sur \"New workflow\"</li> <li>S\u00e9lectionner un template ou \"set up a workflow yourself\"</li> <li>\u00c9diter le fichier YAML</li> <li>Cliquer sur \"Start commit\"</li> </ol>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#methode-2-localement-via-git","title":"M\u00e9thode 2 : Localement via Git","text":"Bash<pre><code># Cloner le d\u00e9p\u00f4t\ngit clone https://github.com/votre-utilisateur/mon-projet.git\ncd mon-projet\n\n# Cr\u00e9er la structure des r\u00e9pertoires\nmkdir -p .github/workflows\n\n# Cr\u00e9er le fichier de workflow\ncat &gt; .github/workflows/hello.yml &lt;&lt; 'EOF'\nname: Hello World\n\non:\n  push:\n    branches: [main]\n\njobs:\n  hello:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Say hello\n        run: echo \"Bonjour GitHub Actions!\"\nEOF\n\n# Commit et push\ngit add .github/workflows/hello.yml\ngit commit -m \"Add hello world workflow\"\ngit push origin main\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#premier-workflow-hello-world","title":"Premier workflow : Hello World","text":"<p>Le workflow le plus simple permet de v\u00e9rifier que GitHub Actions fonctionne correctement dans votre environnement.</p> YAML<pre><code>name: Hello World\n\non:\n  push:\n    branches: [main]\n\njobs:\n  hello:\n    name: Say Hello\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Print greeting\n        run: echo \"\ud83d\ude80 Bonjour depuis GitHub Actions!\"\n\n      - name: Print environment info\n        run: |\n          echo \"Syst\u00e8me d'exploitation: $RUNNER_OS\"\n          echo \"Runner: $RUNNER_NAME\"\n          echo \"Branch: $GITHUB_REF_NAME\"\n\n      - name: Print timestamp\n        run: date\n</code></pre> <p>Ce workflow s'ex\u00e9cute automatiquement \u00e0 chaque push sur la branche <code>main</code> et effectue trois actions simples : un salut, l'affichage d'informations syst\u00e8mes, et l'affichage de la date/heure.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#acceder-aux-logs-du-workflow","title":"Acc\u00e9der aux logs du workflow","text":"<p>Pour v\u00e9rifier l'ex\u00e9cution de votre workflow :</p> <ol> <li>Naviguer vers le d\u00e9p\u00f4t GitHub</li> <li>Cliquer sur l'onglet \"Actions\"</li> <li>S\u00e9lectionner le workflow dans la liste</li> <li>Cliquer sur l'ex\u00e9cution sp\u00e9cifique</li> <li>Consulter les logs d\u00e9taill\u00e9s pour chaque \u00e9tape</li> </ol>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#concepts-cles-dun-workflow","title":"Concepts cl\u00e9s d'un workflow","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap01/#events-evenements","title":"Events (\u00c9v\u00e9nements)","text":"<p>Un \u00e9v\u00e9nement est ce qui d\u00e9clenche l'ex\u00e9cution d'un workflow[2]. Les \u00e9v\u00e9nements principaux incluent :</p> <ul> <li>push : Activation lors d'un push de commits</li> <li>pull_request : Activation lors de la cr\u00e9ation ou modification d'une PR</li> <li>schedule : Activation selon un calendrier (cron)</li> <li>workflow_dispatch : Activation manuelle depuis l'interface</li> <li>release : Activation lors de la cr\u00e9ation d'une release</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#jobs-taches","title":"Jobs (T\u00e2ches)","text":"<p>Un job est une unit\u00e9 d'ex\u00e9cution ind\u00e9pendante au sein d'un workflow. Plusieurs jobs peuvent s'ex\u00e9cuter en parall\u00e8le ou s\u00e9quentiellement (avec <code>needs</code>)[2].</p> YAML<pre><code>jobs:\n  job1:\n    runs-on: ubuntu-latest\n    steps:\n      - run: echo \"Job 1\"\n\n  job2:\n    runs-on: ubuntu-latest\n    needs: job1  # S'ex\u00e9cute seulement apr\u00e8s job1\n    steps:\n      - run: echo \"Job 2\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#runners-executeurs","title":"Runners (Ex\u00e9cuteurs)","text":"<p>Un runner est la machine qui ex\u00e9cute les jobs[2]. GitHub fournit des runners gratuits (ubuntu-latest, windows-latest, macos-latest) ou vous pouvez utiliser vos propres runners auto-h\u00e9berg\u00e9s.</p> YAML<pre><code>jobs:\n  multi-platform:\n    strategy:\n      matrix:\n        os: [ubuntu-latest, windows-latest, macos-latest]\n    runs-on: ${{ matrix.os }}\n    steps:\n      - run: echo \"Running on ${{ runner.os }}\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#actions-actions","title":"Actions (Actions)","text":"<p>Une action est une composante r\u00e9utilisable qui effectue une t\u00e2che sp\u00e9cifique[5]. Les actions peuvent \u00eatre officielles (fournies par GitHub), communautaires, ou cr\u00e9\u00e9es par l'utilisateur.</p> YAML<pre><code>steps:\n  - name: Checkout code\n    uses: actions/checkout@v4\n\n  - name: Setup Node.js\n    uses: actions/setup-node@v3\n    with:\n      node-version: 18\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#variables-denvironnement-et-secrets","title":"Variables d'environnement et secrets","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap01/#variables-denvironnement","title":"Variables d'environnement","text":"<p>Les variables d'environnement sont accessibles \u00e0 tous les jobs et steps du workflow.</p> YAML<pre><code>env:\n  LOG_LEVEL: debug\n  API_ENDPOINT: https://api.example.com\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Deploy\n        run: |\n          echo \"Log level: $LOG_LEVEL\"\n          echo \"API: $API_ENDPOINT\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#secrets","title":"Secrets","text":"<p>Pour les informations sensibles (tokens, passwords), GitHub fournit un m\u00e9canisme de secrets[1].</p> <p>Ajouter un secret dans GitHub : 1. Naviguer vers Settings \u2192 Secrets and variables \u2192 Actions 2. Cliquer sur \"New repository secret\" 3. Entrer le nom du secret (exemple : <code>DEPLOY_TOKEN</code>) 4. Entrer la valeur 5. Cliquer sur \"Add secret\"</p> <p>Utiliser un secret dans un workflow :</p> YAML<pre><code>jobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Deploy with token\n        run: |\n          curl -H \"Authorization: Bearer ${{ secrets.DEPLOY_TOKEN }}\" \\\n            https://api.example.com/deploy\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#depannage-et-logs","title":"D\u00e9pannage et logs","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap01/#verifier-les-logs-du-workflow","title":"V\u00e9rifier les logs du workflow","text":"<p>GitHub fournit des logs d\u00e9taill\u00e9s pour chaque ex\u00e9cution de workflow, incluant :</p> <ul> <li>Dur\u00e9e d'ex\u00e9cution : Combien de temps chaque step a pris</li> <li>Statuts : Succ\u00e8s ou \u00e9chec de chaque step</li> <li>Sortie : Les r\u00e9sultats imprim\u00e9s par <code>echo</code> ou <code>run</code></li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#exemple-de-logs-typiques","title":"Exemple de logs typiques","text":"Text Only<pre><code>Run: npm test\n&gt; npm test\n\n&gt; my-app@1.0.0 test\n&gt; jest\n\n PASS  src/app.test.js\n  \u2713 should render without crashing (45ms)\n  \u2713 should handle input correctly (32ms)\n\nTest Suites: 1 passed, 1 total\nTests:       2 passed, 2 total\nSnapshots:   0 total\nTime:        1.234 s\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#activer-le-debug","title":"Activer le debug","text":"<p>Pour plus de d\u00e9tails, il est possible d'activer le mode debug en ajoutant des secrets :</p> <ul> <li><code>ACTIONS_STEP_DEBUG</code> : Pour les logs d\u00e9taill\u00e9s des steps</li> <li><code>ACTIONS_RUNNER_DEBUG</code> : Pour les logs du runner</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#gestion-des-versions-des-actions","title":"Gestion des versions des actions","text":"<p>Les actions GitHub utilisent un syst\u00e8me de versioning. Les versions courantes :</p> <ul> <li>v1 : Version majeure (stable et recommand\u00e9e)</li> <li>v1.1 : Version mineure (corrections de bugs)</li> <li>v1.1.0 : Version patch (tr\u00e8s pr\u00e9cis)</li> <li>@main : Derni\u00e8re version (non recommand\u00e9 en production)</li> </ul> YAML<pre><code>steps:\n  # Recommand\u00e9 : version majeure sp\u00e9cifique\n  - uses: actions/checkout@v4\n\n  # Alternative : version mineure\n  - uses: actions/setup-node@v3.8\n\n  # \u00c0 \u00e9viter : version en d\u00e9veloppement\n  - uses: actions/deploy@main\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#permissions-et-securite","title":"Permissions et s\u00e9curit\u00e9","text":"<p>GitHub Actions b\u00e9n\u00e9ficie d'un syst\u00e8me de permissions granulaires. Par d\u00e9faut, les workflows ont des permissions limit\u00e9es :</p> YAML<pre><code>permissions:\n  contents: read        # Lecture du code\n  pull-requests: write  # \u00c9criture sur les PRs\n  deployments: write    # \u00c9criture des d\u00e9ploiements\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#tester-les-workflows-localement-avec-act","title":"Tester les workflows localement avec Act","text":"<p>Pour tester les workflows avant de les pousser sur GitHub, l'outil Act simule l'environnement GitHub Actions localement en utilisant Docker[2].</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#installation-dact","title":"Installation d'Act","text":"Bash<pre><code># Sur macOS avec Homebrew\nbrew install act\n\n# Sur Linux\ncurl https://raw.githubusercontent.com/nektos/act/master/install.sh | bash\n\n# Sur Windows\nchoco install act-cli\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#utiliser-act","title":"Utiliser Act","text":"Bash<pre><code># Lister tous les workflows\nact --list\n\n# Ex\u00e9cuter un workflow sp\u00e9cifique\nact --job hello\n\n# Ex\u00e9cuter avec des secrets locaux\nact --job build --secret DEPLOY_TOKEN=my-token\n\n# Utiliser un environnement personnalis\u00e9\nact -P ubuntu-latest=ghcr.io/catthehacker/ubuntu:full-latest\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#bonnes-pratiques-de-configuration","title":"Bonnes pratiques de configuration","text":"<p>Organisation des workflows : Utiliser un fichier par responsabilit\u00e9 (ci.yml, deploy.yml, security.yml)</p> <p>Nommage clair : Utiliser des noms explicites pour les jobs et steps</p> <p>Documentation : Ajouter des descriptions aux workflows et aux steps</p> <p>Versioning des actions : Sp\u00e9cifier toujours une version majeure stable</p> <p>Gestion des secrets : Ne jamais commiter les secrets, utiliser le syst\u00e8me de GitHub</p> <p>Timeout : D\u00e9finir des timeouts appropri\u00e9s pour \u00e9viter les hangups</p> YAML<pre><code>jobs:\n  build:\n    runs-on: ubuntu-latest\n    timeout-minutes: 30  # Timeout global du job\n\n    steps:\n      - name: Long-running task\n        timeout-minutes: 10  # Timeout sp\u00e9cifique du step\n        run: ./long-process.sh\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap01/#resume-du-chemin-dapprentissage","title":"R\u00e9sum\u00e9 du chemin d'apprentissage","text":"<p>Le chemin de formation couvre progressivement les \u00e9l\u00e9ments essentiels :</p> <ol> <li>Fondations conceptuelles : Comprendre DevOps, CI/CD et l'int\u00e9gration continue</li> <li>Fondamentaux YAML : Ma\u00eetriser la syntaxe pour \u00e9crire des workflows</li> <li>Mise en place pratique : Cr\u00e9er un d\u00e9p\u00f4t, initialiser GitHub Actions, cr\u00e9er des workflows simples</li> <li>D\u00e9ploiement : Passer de tests \u00e0 des d\u00e9ploiements r\u00e9els</li> <li>Optimisation : Utiliser des matrices de build, parall\u00e9liser les jobs, utiliser des caches</li> </ol> <p>Ce progression permet de passer d'une compr\u00e9hension th\u00e9orique \u00e0 une utilisation pratique de GitHub Actions dans des projets r\u00e9els, en commen\u00e7ant par des workflows simples pour progresser vers des pipelines complexes et sophistiqu\u00e9s.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/","title":"Citations","text":"<ul> <li>https://docs.github.com/articles/getting-started-with-github-actions</li> <li>https://notes.kodekloud.com/docs/GitHub-Actions/GitHub-Actions-Core-Concepts/GitHub-Action-Core-Components</li> <li>https://docs.github.com/en/actions/concepts/workflows-and-actions/workflows</li> <li>https://www.synacktiv.com/en/publications/github-actions-exploitation-introduction</li> <li>https://www.codecademy.com/article/how-to-use-github-actions</li> <li>https://learn.microsoft.com/en-us/training/paths/github-actions/</li> <li>https://docs.github.com/actions/quickstart</li> <li>https://docs.github.com/en/actions/tutorials/create-an-example-workflow</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 257</li> <li>completion_tokens: 7569</li> <li>total_tokens: 7826</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.114, 'request_cost': 0.006, 'total_cost': 0.12}</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#content","title":"Content","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap02/#chapitre-2-introduction-a-github-actions","title":"Chapitre 2 : Introduction \u00e0 Github Actions \ud83d\ude80","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap02/#vue-densemble-des-composants","title":"Vue d'ensemble des composants","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap02/#fondamentaux-de-lautomatisation-avec-github-actions","title":"Fondamentaux de l'automatisation avec GitHub Actions","text":"<p>GitHub Actions est une plateforme d'int\u00e9gration continue et de d\u00e9ploiement continu (CI/CD) int\u00e9gr\u00e9e nativement dans GitHub[7]. Elle permet d'automatiser enti\u00e8rement le cycle de vie du d\u00e9veloppement logiciel en cr\u00e9ant des processus configurables qui s'ex\u00e9cutent automatiquement en r\u00e9ponse \u00e0 des \u00e9v\u00e9nements sp\u00e9cifiques dans un r\u00e9f\u00e9rentiel[1].</p> <p>La compr\u00e9hension des composants fondamentaux constitue la base essentielle pour ma\u00eetriser GitHub Actions. Ces composants travaillent ensemble de mani\u00e8re hi\u00e9rarchique pour cr\u00e9er des automatisations robustes et maintenables[2][3].</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#les-trois-piliers-de-github-actions","title":"Les trois piliers de GitHub Actions","text":"<p>L'architecture de GitHub Actions repose sur trois composants principaux qui forment une hi\u00e9rarchie bien d\u00e9finie :</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#workflows-flux-de-travail","title":"Workflows (Flux de travail)","text":"<p>Un workflow repr\u00e9sente le niveau le plus \u00e9lev\u00e9 de l'automatisation. Il s'agit d'un processus automatis\u00e9 configurable d\u00e9fini au format YAML qui s'ex\u00e9cute en r\u00e9ponse \u00e0 un ou plusieurs \u00e9v\u00e9nements survenant dans le r\u00e9f\u00e9rentiel[1][2]. Les workflows constituent les orchestrateurs principaux de toute l'automatisation.</p> <p>Les workflows poss\u00e8dent plusieurs caract\u00e9ristiques essentielles :</p> <ul> <li>Localisation standardis\u00e9e : Tous les workflows doivent r\u00e9sider dans le r\u00e9pertoire <code>.github/workflows</code> du r\u00e9f\u00e9rentiel[2]</li> <li>Format : Les fichiers doivent utiliser l'extension <code>.yml</code> ou <code>.yaml</code> pour \u00eatre automatiquement d\u00e9tect\u00e9s par GitHub[2]</li> <li>D\u00e9clenchement : Ils s'activent automatiquement suite \u00e0 des \u00e9v\u00e9nements repository sp\u00e9cifiques</li> <li>Composition : Un workflow contient toujours un ou plusieurs jobs qui s'ex\u00e9cutent de mani\u00e8re s\u00e9quentielle ou parall\u00e8le</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#jobs-taches","title":"Jobs (T\u00e2ches)","text":"<p>Un job repr\u00e9sente l'ensemble des \u00e9tapes qui s'ex\u00e9cutent sur une m\u00eame machine runner[3]. Chaque job fonctionne de mani\u00e8re ind\u00e9pendante dans son propre environnement d'ex\u00e9cution, ce qui permet une isolation compl\u00e8te entre les diff\u00e9rentes t\u00e2ches[1].</p> <p>Les caract\u00e9ristiques principales des jobs incluent :</p> <ul> <li>Environnement d'ex\u00e9cution : Chaque job s'ex\u00e9cute sur sa propre machine virtuelle runner ou \u00e0 l'int\u00e9rieur d'un conteneur[1]</li> <li>Orchestration : Plusieurs jobs peuvent s'ex\u00e9cuter en parall\u00e8le ou dans un ordre s\u00e9quentiel d\u00e9fini</li> <li>Configuration d'ex\u00e9cution : Chaque job sp\u00e9cifie la plateforme sur laquelle il s'ex\u00e9cute via le champ <code>runs-on</code></li> <li>D\u00e9pendances : Les jobs peuvent \u00eatre configur\u00e9s pour d\u00e9pendre les uns des autres</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#steps-etapes","title":"Steps (\u00c9tapes)","text":"<p>Les steps (\u00e9tapes) constituent le niveau granulaire le plus fin de l'automatisation. Chaque \u00e9tape au sein d'un job ex\u00e9cute soit un script d\u00e9fini par l'utilisateur, soit une action r\u00e9utilisable[3]. Les steps s'ex\u00e9cutent toujours de mani\u00e8re s\u00e9quentielle dans le contexte du m\u00eame job[2].</p> Aspect Description Type Action Utilise une action pr\u00e9existante via le mot-cl\u00e9 <code>uses</code> Type Commande Ex\u00e9cute des commandes shell directement via le mot-cl\u00e9 <code>run</code> Ex\u00e9cution Toujours s\u00e9quentielle au sein du m\u00eame job Contexte Partage le m\u00eame environnement et les m\u00eames variables d'environnement"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#evenements-events","title":"\u00c9v\u00e9nements (Events)","text":"<p>Un \u00e9v\u00e9nement repr\u00e9sente une activit\u00e9 sp\u00e9cifique dans un r\u00e9f\u00e9rentiel qui d\u00e9clenche l'ex\u00e9cution du workflow[3][4]. GitHub Actions supporte une large gamme d'\u00e9v\u00e9nements natifs qui correspondent \u00e0 des actions courantes effectu\u00e9es au sein du flux de d\u00e9veloppement.</p> <p>Les \u00e9v\u00e9nements les plus courants incluent :</p> <ul> <li><code>push</code> : D\u00e9clench\u00e9 lorsqu'un commit est pouss\u00e9 vers le r\u00e9f\u00e9rentiel ou une branche sp\u00e9cifique[5]</li> <li><code>pull_request</code> : D\u00e9clench\u00e9 lorsqu'une pull request est ouverte, mise \u00e0 jour ou ferm\u00e9e[5]</li> <li><code>issues</code> : D\u00e9clench\u00e9 lors de la cr\u00e9ation, l'\u00e9dition ou la fermeture d'un probl\u00e8me[5]</li> <li><code>release</code> : D\u00e9clench\u00e9 lors de la cr\u00e9ation ou de la publication d'une version[5]</li> <li><code>schedule</code> : D\u00e9clench\u00e9 selon une planification de type cron</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#actions-reutilisables","title":"Actions (R\u00e9utilisables)","text":"<p>Une action repr\u00e9sente un bloc de code pr\u00e9d\u00e9fini et r\u00e9utilisable qui effectue des t\u00e2ches sp\u00e9cifiques au sein d'un workflow[1]. Les actions permettent d'encapsuler de la logique complexe et de la r\u00e9utiliser \u00e0 travers plusieurs workflows et projets, r\u00e9duisant ainsi la duplication de code[5].</p> <p>Il existe plusieurs sources d'actions :</p> <ul> <li>Actions officielles GitHub : Maintenues directement par GitHub et disponibles nativement</li> <li>GitHub Marketplace : Une place de march\u00e9 contenant des milliers d'actions cr\u00e9\u00e9es par la communaut\u00e9</li> <li>Actions personnalis\u00e9es : Les d\u00e9veloppeurs peuvent cr\u00e9er et maintenir leurs propres actions</li> </ul> <p>Les actions officielles couramment utilis\u00e9es incluent :</p> <ul> <li>Clonage du r\u00e9f\u00e9rentiel Git : <code>actions/checkout@v3</code></li> <li>Configuration d'une toolchain Node.js : <code>actions/setup-node@v3</code></li> <li>Configuration d'une toolchain Python : <code>actions/setup-python@v4</code></li> <li>Configuration de l'authentification aux fournisseurs cloud</li> <li>Construction et publication d'images Docker</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#runners-machines-dexecution","title":"Runners (Machines d'ex\u00e9cution)","text":"<p>Un runner repr\u00e9sente la machine physique ou virtuelle sur laquelle s'ex\u00e9cute le job[1][3]. GitHub fournit des runners h\u00e9berg\u00e9s gratuitement pour les utilisateurs publics et les plans payants pour les utilisateurs priv\u00e9s, mais les organisations peuvent \u00e9galement utiliser des runners auto-h\u00e9berg\u00e9s pour ex\u00e9cuter les jobs sur leur propre infrastructure[5].</p> <p>Les runners h\u00e9berg\u00e9s par GitHub supportent les environnements suivants :</p> <ul> <li>Ubuntu Linux (versions r\u00e9centes)</li> <li>Windows Server</li> <li>macOS</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#representation-hierarchique-des-composants","title":"Repr\u00e9sentation hi\u00e9rarchique des composants","text":"<p>La structure hi\u00e9rarchique de GitHub Actions peut \u00eatre visualis\u00e9e de la mani\u00e8re suivante :</p> Text Only<pre><code>\u00c9v\u00e9nement (Event)\n    \u2193\nWorkflow (.github/workflows/xxx.yml)\n    \u2193\nJob 1, Job 2, Job N (s\u00e9quentiels ou parall\u00e8les)\n    \u251c\u2500\u2500 Step 1 (action ou run)\n    \u251c\u2500\u2500 Step 2 (action ou run)\n    \u2514\u2500\u2500 Step N (action ou run)\n</code></pre> <p>Cette hi\u00e9rarchie d\u00e9montre comment un simple \u00e9v\u00e9nement d\u00e9clenche un workflow entier, qui orchestestre plusieurs jobs, chacun contenant une s\u00e9rie d'\u00e9tapes qui s'ex\u00e9cutent s\u00e9quentiellement.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#premier-exemple-de-workflow","title":"Premier exemple de workflow","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap02/#structure-de-base-dun-fichier-workflow","title":"Structure de base d'un fichier workflow","text":"<p>Un fichier workflow YAML minimal contient toujours les composants essentiels identifi\u00e9s par GitHub[3] :</p> <ol> <li>Un ou plusieurs \u00e9v\u00e9nements d\u00e9clencheurs</li> <li>Un ou plusieurs jobs</li> <li>Une s\u00e9rie d'une ou plusieurs \u00e9tapes au sein de chaque job</li> </ol>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#creation-du-repertoire-et-fichier-initial","title":"Cr\u00e9ation du r\u00e9pertoire et fichier initial","text":"<p>La premi\u00e8re \u00e9tape pour cr\u00e9er un workflow consiste \u00e0 initialiser la structure de r\u00e9pertoires appropri\u00e9e :</p> Bash<pre><code>mkdir -p .github/workflows\n</code></pre> <p>Cette commande cr\u00e9e le r\u00e9pertoire <code>.github/workflows</code> qui servira de conteneur pour tous les fichiers de workflow du projet[2].</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#exemple-de-workflow-simple","title":"Exemple de workflow simple","text":"<p>Voici un exemple complet d'un premier workflow fonctionnel[2] :</p> YAML<pre><code>name: CI Pipeline\n\non: [push]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - run: echo \"Hello, GitHub Actions!\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#analyse-detaillee-du-workflow","title":"Analyse d\u00e9taill\u00e9e du workflow","text":"<p>Champ <code>name</code></p> YAML<pre><code>name: CI Pipeline\n</code></pre> <p>Le champ <code>name</code> d\u00e9finit un nom convivial pour le workflow qui s'affichera dans l'onglet Actions de l'interface GitHub. Ce nom n'affecte pas le fonctionnement mais aide \u00e0 identifier rapidement le workflow parmi plusieurs autres[2].</p> <p>Champ <code>on</code></p> YAML<pre><code>on: [push]\n</code></pre> <p>Le champ <code>on</code> d\u00e9finit les \u00e9v\u00e9nements qui d\u00e9clenchent l'ex\u00e9cution du workflow. Dans cet exemple, le workflow s'ex\u00e9cute chaque fois qu'un commit est pouss\u00e9 vers n'importe quelle branche du r\u00e9f\u00e9rentiel[2]. Cette configuration simple est l'une des plus basiques.</p> <p>Section <code>jobs</code></p> YAML<pre><code>jobs:\n  build:\n    runs-on: ubuntu-latest\n</code></pre> <p>La section <code>jobs</code> contient une ou plusieurs t\u00e2ches qui s'ex\u00e9cuteront. Dans cet exemple, un job nomm\u00e9 <code>build</code> est d\u00e9fini. Le champ <code>runs-on: ubuntu-latest</code> sp\u00e9cifie que ce job s'ex\u00e9cutera sur une machine runner h\u00e9berg\u00e9e par GitHub avec le syst\u00e8me d'exploitation Ubuntu derni\u00e8re version[2].</p> <p>Section <code>steps</code></p> YAML<pre><code>steps:\n  - uses: actions/checkout@v3\n  - run: echo \"Hello, GitHub Actions!\"\n</code></pre> <p>La section <code>steps</code> d\u00e9finit les actions ou commandes qui s'ex\u00e9cutent s\u00e9quentiellement au sein du job. Dans cet exemple :</p> <ul> <li>La premi\u00e8re \u00e9tape utilise l'action officielle <code>actions/checkout@v3</code> pour cloner le code du r\u00e9f\u00e9rentiel dans l'environnement du runner[2]</li> <li>La deuxi\u00e8me \u00e9tape ex\u00e9cute une simple commande echo pour afficher un message</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#procedure-de-deploiement-du-workflow","title":"Proc\u00e9dure de d\u00e9ploiement du workflow","text":"<p>Pour mettre en place ce workflow dans un r\u00e9f\u00e9rentiel existant, voici les \u00e9tapes \u00e0 suivre :</p> <p>\u00c9tape 1 : Cr\u00e9ation du fichier</p> Bash<pre><code>cat &lt;&lt; 'EOF' &gt; .github/workflows/ci.yml\nname: CI Pipeline\n\non: [push]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - run: echo \"Hello, GitHub Actions!\"\nEOF\n</code></pre> <p>\u00c9tape 2 : Validation du contenu</p> Bash<pre><code>cat .github/workflows/ci.yml\n</code></pre> <p>Cette commande affiche le contenu du fichier pour v\u00e9rifier que la syntaxe est correcte.</p> <p>\u00c9tape 3 : Commit et push</p> Bash<pre><code>git add .github/workflows/ci.yml\ngit commit -m \"Add initial GitHub Actions workflow\"\ngit push origin main\n</code></pre> <p>Apr\u00e8s le commit et le push vers le r\u00e9f\u00e9rentiel distant, le workflow s'ex\u00e9cute automatiquement[2].</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#workflow-plus-complexe-avec-plusieurs-etapes","title":"Workflow plus complexe avec plusieurs \u00e9tapes","text":"<p>Voici un exemple de workflow plus r\u00e9aliste pour un projet Node.js :</p> YAML<pre><code>name: Node.js CI\n\non:\n  push:\n    branches: [ main, develop ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: Install dependencies\n        run: npm install\n\n      - name: Run linter\n        run: npm run lint\n\n      - name: Run tests\n        run: npm test\n\n      - name: Build application\n        run: npm run build\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#decortication-du-workflow-complexe","title":"D\u00e9cortication du workflow complexe","text":"<p>Ce workflow d\u00e9montre plusieurs concepts avanc\u00e9s :</p> <p>\u00c9v\u00e9nements multiples et filtrage par branche</p> YAML<pre><code>on:\n  push:\n    branches: [ main, develop ]\n  pull_request:\n    branches: [ main ]\n</code></pre> <p>Le workflow se d\u00e9clenche lors d'un push vers les branches <code>main</code> ou <code>develop</code>, et lors d'une pull request vers <code>main</code>. Cette configuration permet de cibler pr\u00e9cis\u00e9ment les sc\u00e9narios d'automatisation[5].</p> <p>Nommage explicite des \u00e9tapes</p> YAML<pre><code>- name: Set up Node.js\n  uses: actions/setup-node@v3\n  with:\n    node-version: '18'\n</code></pre> <p>Chaque \u00e9tape peut disposer d'un nom explicite via le champ <code>name</code>, ce qui am\u00e9liore consid\u00e9rablement la lisibilit\u00e9 des logs d'ex\u00e9cution. Le champ <code>with</code> permet de transmettre des param\u00e8tres \u00e0 l'action[5].</p> <p>Ex\u00e9cution s\u00e9quentielle des t\u00e2ches</p> <p>Toutes les \u00e9tapes s'ex\u00e9cutent s\u00e9quentiellement par d\u00e9faut. Si une \u00e9tape \u00e9choue (code de sortie non z\u00e9ro), le job s'arr\u00eate et les \u00e9tapes suivantes ne s'ex\u00e9cutent pas, sauf configuration contraire.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#acces-aux-logs-dexecution","title":"Acc\u00e8s aux logs d'ex\u00e9cution","text":"<p>Une fois le workflow d\u00e9clench\u00e9 par un push, les logs peuvent \u00eatre consult\u00e9s via l'interface GitHub[7] :</p> <ol> <li>Naviguer vers l'onglet Actions du r\u00e9f\u00e9rentiel</li> <li>S\u00e9lectionner le workflow ex\u00e9cut\u00e9</li> <li>Cliquer sur la run sp\u00e9cifique</li> <li>Explorer les logs d\u00e9taill\u00e9s pour chaque job et \u00e9tape</li> <li>D\u00e9velopper les \u00e9tapes individuelles pour afficher les d\u00e9tails complets</li> </ol>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#premiere-action","title":"Premi\u00e8re action","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap02/#quest-ce-quune-action-github","title":"Qu'est-ce qu'une action GitHub ?","text":"<p>Une action GitHub repr\u00e9sente un bloc de code r\u00e9utilisable qui encapsule une t\u00e2che sp\u00e9cifique ou une s\u00e9rie de t\u00e2ches connexes[1]. Les actions permettent de partager et de r\u00e9utiliser la logique m\u00e9tier \u00e0 travers plusieurs workflows, projets et m\u00eame au sein de l'\u00e9cosyst\u00e8me GitHub plus large via le GitHub Marketplace[5].</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#categories-principales-dactions","title":"Cat\u00e9gories principales d'actions","text":"<p>Les actions disponibles dans GitHub Actions se r\u00e9partissent en trois cat\u00e9gories principales :</p> <ul> <li>Actions officielles GitHub : Maintenues par GitHub et couvrant les sc\u00e9narios courants (checkout, setup de runtimes, d\u00e9ploiement, etc.)</li> <li>Actions communautaires : Cr\u00e9\u00e9es et maintenues par la communaut\u00e9, disponibles sur le GitHub Marketplace</li> <li>Actions personnalis\u00e9es : D\u00e9velopp\u00e9es localement par une organisation pour r\u00e9pondre \u00e0 des besoins sp\u00e9cifiques</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#utilisation-dune-action-officielle","title":"Utilisation d'une action officielle","text":"<p>L'une des actions les plus fondamentales est <code>actions/checkout</code>, qui clone le code du r\u00e9f\u00e9rentiel dans l'environnement du runner[1] :</p> YAML<pre><code>- uses: actions/checkout@v3\n</code></pre> <p>Cette action s'ex\u00e9cute g\u00e9n\u00e9ralement comme premi\u00e8re \u00e9tape de tout workflow pour permettre aux \u00e9tapes suivantes d'acc\u00e9der aux fichiers du projet.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#configuration-dactions-avec-parametres","title":"Configuration d'actions avec param\u00e8tres","text":"<p>Les actions acceptent souvent des param\u00e8tres de configuration via le champ <code>with</code>. Voici un exemple de configuration de l'action <code>actions/setup-node@v3</code> :</p> YAML<pre><code>- name: Set up Node.js environment\n  uses: actions/setup-node@v3\n  with:\n    node-version: '18'\n    cache: 'npm'\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#parametres-de-laction-setup-node","title":"Param\u00e8tres de l'action setup-node","text":"Param\u00e8tre Description Valeur par d\u00e9faut <code>node-version</code> Version de Node.js \u00e0 installer D\u00e9pend du runner <code>cache</code> Gestionnaire de cache \u00e0 utiliser (npm, yarn, pnpm) Non configur\u00e9 <code>registry-url</code> URL du registre npm personnalis\u00e9 registry.npmjs.org <code>scope</code> \u00c9tendue du registre pour les packages scoped Aucune"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#actions-courantes-pour-lintegration-continue","title":"Actions courantes pour l'int\u00e9gration continue","text":"<p>Voici les actions officielles les plus fr\u00e9quemment utilis\u00e9es dans les pipelines CI/CD :</p> <p>1. R\u00e9cup\u00e9ration du code</p> YAML<pre><code>- uses: actions/checkout@v3\n</code></pre> <p>R\u00e9cup\u00e8re le code source du r\u00e9f\u00e9rentiel pour le rendre disponible aux \u00e9tapes suivantes.</p> <p>2. Configuration de Python</p> YAML<pre><code>- uses: actions/setup-python@v4\n  with:\n    python-version: '3.11'\n</code></pre> <p>Configure un environnement Python avec la version sp\u00e9cifi\u00e9e.</p> <p>3. Configuration de Java</p> YAML<pre><code>- uses: actions/setup-java@v3\n  with:\n    java-version: '17'\n    distribution: 'temurin'\n</code></pre> <p>Configure un environnement Java avec le JDK sp\u00e9cifi\u00e9.</p> <p>4. Configuration de Docker</p> YAML<pre><code>- uses: docker/setup-buildx-action@v2\n</code></pre> <p>Configure Docker BuildX pour la construction d'images multi-plateforme.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#workflow-complet-utilisant-plusieurs-actions","title":"Workflow complet utilisant plusieurs actions","text":"<p>Voici un exemple de workflow qui orchestestre plusieurs actions pour tester une application Node.js :</p> YAML<pre><code>name: Comprehensive CI Workflow\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n\n    strategy:\n      matrix:\n        node-version: [16.x, 18.x, 20.x]\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v3\n\n      - name: Set up Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: 'npm'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run linter\n        run: npm run lint\n\n      - name: Run tests with coverage\n        run: npm run test -- --coverage\n\n      - name: Upload coverage reports\n        uses: codecov/codecov-action@v3\n        with:\n          files: ./coverage/coverage-final.json\n\n  security:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v3\n\n      - name: Run security audit\n        run: npm audit\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#decorticage-du-workflow-avance","title":"D\u00e9corticage du workflow avanc\u00e9","text":"<p>Matrix builds</p> YAML<pre><code>strategy:\n  matrix:\n    node-version: [16.x, 18.x, 20.x]\n</code></pre> <p>La strat\u00e9gie de matrice permet de cr\u00e9er plusieurs jobs \u00e0 partir d'une configuration unique, testant l'application sur diff\u00e9rentes versions de Node.js[5]. Cela optimise le temps de mise en place et am\u00e9liore la couverture des tests.</p> <p>Variables de contexte</p> YAML<pre><code>node-version: ${{ matrix.node-version }}\n</code></pre> <p>Les variables entre <code>${{ }}</code> repr\u00e9sentent des expressions qui sont \u00e9valu\u00e9es au moment de l'ex\u00e9cution. Dans cet exemple, la version de Node.js varie \u00e0 chaque it\u00e9ration de la matrice.</p> <p>Utilisation d'actions tierces</p> YAML<pre><code>- name: Upload coverage reports\n  uses: codecov/codecov-action@v3\n</code></pre> <p>Les actions provenant du GitHub Marketplace peuvent \u00eatre int\u00e9gr\u00e9es directement dans les workflows pour \u00e9tendre les capacit\u00e9s sans d\u00e9veloppement suppl\u00e9mentaire.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#decouverte-dactions-sur-le-github-marketplace","title":"D\u00e9couverte d'actions sur le GitHub Marketplace","text":"<p>Le GitHub Marketplace est accessible directement depuis la page de cr\u00e9ation de workflow dans l'interface GitHub. Voici comment naviguer :</p> <ol> <li>Acc\u00e9der \u00e0 l'onglet Actions d'un r\u00e9f\u00e9rentiel</li> <li>Cliquer sur New workflow</li> <li>Consulter les actions recommand\u00e9es ou utiliser la barre de recherche</li> <li>V\u00e9rifier l'\u00e9diteur (identifi\u00e9 par une v\u00e9rification officielle GitHub)</li> <li>Consulter la documentation et les exemples d'utilisation</li> <li>Int\u00e9grer l'action dans le workflow en copiant le bloc <code>uses</code></li> </ol>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#presentation-de-la-plateforme-github","title":"Pr\u00e9sentation de la plateforme GitHub","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap02/#github-ecosysteme-complet-du-developpement","title":"GitHub : \u00c9cosyst\u00e8me complet du d\u00e9veloppement","text":"<p>GitHub repr\u00e9sente bien plus qu'un simple syst\u00e8me de gestion de contr\u00f4le de version. C'est une plateforme int\u00e9gr\u00e9e offrant une suite compl\u00e8te d'outils couvrant l'ensemble du cycle de vie du d\u00e9veloppement logiciel, de la planification initiale \u00e0 la production[5].</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#github-actions-au-sein-de-lecosysteme","title":"GitHub Actions au sein de l'\u00e9cosyst\u00e8me","text":"<p>GitHub Actions s'int\u00e8gre naturellement dans l'\u00e9cosyst\u00e8me GitHub gr\u00e2ce \u00e0 plusieurs points de contact :</p> <p>Int\u00e9gration avec les \u00e9v\u00e9nements repository</p> <p>GitHub Actions se d\u00e9clenche automatiquement en r\u00e9ponse aux \u00e9v\u00e9nements natifs du syst\u00e8me de gestion de version. Cette int\u00e9gration native \u00e9limine le besoin d'outils externes pour les sc\u00e9narios d'automatisation courants[1]. Les \u00e9v\u00e9nements incluent :</p> <ul> <li>Pushes de code</li> <li>Pull requests</li> <li>Ouverture/fermeture de probl\u00e8mes</li> <li>Cr\u00e9ation de releases</li> <li>Et plus de 40 autres \u00e9v\u00e9nements disponibles</li> </ul> <p>Acc\u00e8s centralis\u00e9 via l'interface</p> <p>L'onglet Actions fournit une interface centralis\u00e9e pour :</p> <ul> <li>Consulter l'historique complet des ex\u00e9cutions de workflow</li> <li>Examiner les d\u00e9tails des logs pour chaque \u00e9tape</li> <li>Identifier les probl\u00e8mes et r\u00e9soudre les d\u00e9faillances</li> <li>Configurer les variables d'environnement et les secrets</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#avantages-de-lintegration-native","title":"Avantages de l'int\u00e9gration native","text":"<p>La nature int\u00e9gr\u00e9e de GitHub Actions offre plusieurs avantages distincts par rapport aux solutions CI/CD externes :</p> <p>Pas de configuration externe requise</p> <p>Les workflows fonctionnent imm\u00e9diatement sans n\u00e9cessiter d'authentification \u00e0 des services externes ou de configuration complexe. L'authentification aux autres services GitHub est automatique et s\u00e9curis\u00e9e[5].</p> <p>Transparence et tra\u00e7abilit\u00e9</p> <p>Tout ce qui concerne l'automatisation r\u00e9side dans le r\u00e9f\u00e9rentiel lui-m\u00eame, permettant aux \u00e9quipes de r\u00e9viser les modifications d'automatisation exactement comme elles le feraient pour le code source. Les workflows peuvent \u00eatre comment\u00e9s, r\u00e9vis\u00e9s via des pull requests et suivis dans l'historique git complet.</p> <p>\u00c9volutivit\u00e9</p> <p>Les workflows peuvent s'adapter automatiquement \u00e0 la croissance du projet. Les runners h\u00e9berg\u00e9s supportent des dizaines de configurations diff\u00e9rentes, et les runners auto-h\u00e9berg\u00e9s peuvent \u00eatre mis \u00e0 l'\u00e9chelle sur l'infrastructure de l'organisation[5].</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#strategies-dautomatisation-courantes","title":"Strat\u00e9gies d'automatisation courantes","text":"<p>GitHub Actions permet de mettre en \u0153uvre plusieurs strat\u00e9gies d'automatisation :</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#integration-continue-ci","title":"Int\u00e9gration continue (CI)","text":"<p>L'int\u00e9gration continue automatise le processus de test du code \u00e0 chaque push. Un workflow CI typique inclut :</p> <ul> <li>Clonage du code</li> <li>Installation des d\u00e9pendances</li> <li>Ex\u00e9cution des linters et des v\u00e9rificateurs de code</li> <li>Ex\u00e9cution des tests unitaires</li> <li>Ex\u00e9cution des tests d'int\u00e9gration</li> <li>G\u00e9n\u00e9ration des rapports de couverture</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#deploiement-continu-cd","title":"D\u00e9ploiement continu (CD)","text":"<p>Le d\u00e9ploiement continu automatise le d\u00e9ploiement du code vers les environnements de test et de production. Un workflow CD typique inclut :</p> <ul> <li>Tous les \u00e9tapes de CI</li> <li>Pr\u00e9paration des artefacts de build</li> <li>D\u00e9ploiement vers les environnements interm\u00e9diaires</li> <li>Ex\u00e9cution des tests de performance</li> <li>D\u00e9ploiement en production (selon les crit\u00e8res)</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#gestion-des-releases","title":"Gestion des releases","text":"<p>L'automatisation des releases g\u00e8re le versioning et la publication du code :</p> <ul> <li>Cr\u00e9ation de tags de version</li> <li>G\u00e9n\u00e9ration de changelogs automatiques</li> <li>Publication sur des registres (npm, PyPI, Docker Hub)</li> <li>Cr\u00e9ation de releases GitHub</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#securite-et-qualite","title":"S\u00e9curit\u00e9 et qualit\u00e9","text":"<p>L'automatisation peut enforcer les standards de qualit\u00e9 et de s\u00e9curit\u00e9 :</p> <ul> <li>Analyses de code statique</li> <li>Audits de s\u00e9curit\u00e9 des d\u00e9pendances</li> <li>Tests de vuln\u00e9rabilit\u00e9 de conteneurs</li> <li>V\u00e9rifications de conformit\u00e9</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#gestion-des-secrets-et-des-donnees-sensibles","title":"Gestion des secrets et des donn\u00e9es sensibles","text":"<p>GitHub Actions fournit un syst\u00e8me s\u00e9curis\u00e9 pour g\u00e9rer les donn\u00e9es sensibles :</p> <p>Secrets d'organisation et de r\u00e9f\u00e9rentiel</p> <p>Les secrets peuvent \u00eatre stock\u00e9s au niveau :</p> <ul> <li>De l'organisation (accessibles \u00e0 tous les r\u00e9f\u00e9rentiels autoris\u00e9s)</li> <li>Du r\u00e9f\u00e9rentiel (accessibles uniquement aux workflows de ce r\u00e9f\u00e9rentiel)</li> <li>De l'environnement (accessibles uniquement lors du d\u00e9ploiement vers cet environnement)</li> </ul> <p>Acc\u00e8s aux secrets dans les workflows</p> <p>Les secrets sont r\u00e9f\u00e9renc\u00e9s via la syntaxe <code>secrets</code> :</p> YAML<pre><code>- name: Deploy to production\n  env:\n    API_TOKEN: ${{ secrets.API_TOKEN }}\n    DATABASE_PASSWORD: ${{ secrets.DATABASE_PASSWORD }}\n  run: ./deploy.sh\n</code></pre> <p>Les secrets ne sont jamais affich\u00e9s dans les logs, m\u00eame s'ils \u00e9taient accidentellement utilis\u00e9s dans une commande d'affichage. GitHub les masque automatiquement avec <code>***</code>.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#variables-denvironnement-et-contextes","title":"Variables d'environnement et contextes","text":"<p>GitHub Actions fournit plusieurs variables d'environnement pr\u00e9d\u00e9finies pour acc\u00e9der aux informations contextuelles :</p> YAML<pre><code>steps:\n  - name: Display context information\n    run: |\n      echo \"Repository: ${{ github.repository }}\"\n      echo \"Branch: ${{ github.ref }}\"\n      echo \"Commit SHA: ${{ github.sha }}\"\n      echo \"Actor: ${{ github.actor }}\"\n      echo \"Event name: ${{ github.event_name }}\"\n</code></pre> <p>Ces variables permettent aux workflows d'adapter leur comportement en fonction du contexte d'ex\u00e9cution.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#monitoring-et-debogage","title":"Monitoring et d\u00e9bogage","text":"<p>GitHub Actions offre plusieurs outils pour monitorer et d\u00e9boguer les workflows :</p> <p>Logs d'ex\u00e9cution</p> <p>Les logs d\u00e9taill\u00e9s enregistrent chaque commande ex\u00e9cut\u00e9e et sa sortie. Les utilisateurs peuvent d\u00e9velopper les \u00e9tapes individuelles pour inspecter les d\u00e9tails.</p> <p>Annotations d'erreur</p> <p>Les erreurs d\u00e9tect\u00e9es par les outils de test ou d'analyse g\u00e9n\u00e8rent automatiquement des annotations visibles directement sur le code source via l'interface web.</p> <p>Notifications</p> <p>GitHub peut notifier les utilisateurs des r\u00e9sultats d'ex\u00e9cution via :</p> <ul> <li>Notifications in-app</li> <li>Emails</li> <li>Webhooks personnalis\u00e9s</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#matrice-de-compatibilite-des-runners","title":"Matrice de compatibilit\u00e9 des runners","text":"<p>GitHub fournit plusieurs environnements de runner pr\u00e9d\u00e9finis, chacun avec des caract\u00e9ristiques sp\u00e9cifiques :</p> Image Sp\u00e9cifications Utilisation <code>ubuntu-latest</code> Ubuntu LTS, Node.js, Python, Ruby, etc. D\u00e9veloppement Linux g\u00e9n\u00e9ral <code>windows-latest</code> Windows Server, Visual Studio, .NET Framework D\u00e9veloppement Windows <code>macos-latest</code> macOS, Xcode, Swift, Objective-C D\u00e9veloppement iOS/macOS <code>ubuntu-20.04</code> Ubuntu 20.04 LTS sp\u00e9cifique Compatibilit\u00e9 r\u00e9troactive <code>windows-2019</code> Windows Server 2019 Compatibilit\u00e9 r\u00e9troactive"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#runners-auto-heberges","title":"Runners auto-h\u00e9berg\u00e9s","text":"<p>Pour les organisations n\u00e9cessitant un contr\u00f4le complet de l'infrastructure :</p> YAML<pre><code>jobs:\n  build:\n    runs-on: [self-hosted, linux, x64]\n    steps:\n      - uses: actions/checkout@v3\n      - run: ./build.sh\n</code></pre> <p>Les runners auto-h\u00e9berg\u00e9s permettent d'utiliser des machines propri\u00e9taires, des configurations sp\u00e9cialis\u00e9es ou des ressources GPU pour les t\u00e2ches intensives en calcul.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#pricing-et-limites","title":"Pricing et limites","text":"<p>GitHub Actions offre une g\u00e9n\u00e9reuse allocation gratuite :</p> <ul> <li>Utilisateurs publics : Actions gratuites et illimit\u00e9es</li> <li>Utilisateurs priv\u00e9s : 2000 minutes par mois gratuites sur des runners h\u00e9berg\u00e9s</li> <li>Au-del\u00e0 : Facturation par minute selon le type de runner</li> </ul> <p>Les organisations avec des besoins \u00e9lev\u00e9s peuvent b\u00e9n\u00e9ficier de contrats entreprise avec des allocations personnalis\u00e9es.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#chemin-dapprentissage-complet","title":"Chemin d'apprentissage complet","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap02/#progression-pedagogique-proposee","title":"Progression p\u00e9dagogique propos\u00e9e","text":"<p>L'apprentissage de GitHub Actions suit une progression logique, \u00e9voluant des concepts fondamentaux vers des impl\u00e9mentations complexes.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#phase-1-fondamentaux-comprendre-les-bases","title":"Phase 1 : Fondamentaux (Comprendre les bases)","text":"<p>Objectifs d'apprentissage</p> <p>Au cours de cette phase initiale, l'apprenant doit acqu\u00e9rir une compr\u00e9hension claire des concepts de base qui sous-tendent GitHub Actions. Cette phase pose les fondations pour toute utilisation ult\u00e9rieure.</p> <ol> <li> <p>Compr\u00e9hension conceptuelle des workflows : Reconna\u00eetre comment un workflow repr\u00e9sente un processus automatis\u00e9 complet, de son d\u00e9clenchement par un \u00e9v\u00e9nement \u00e0 son ex\u00e9cution compl\u00e8te.</p> </li> <li> <p>Ma\u00eetrise de la hi\u00e9rarchie des composants : Comprendre les relations entre workflows, jobs, steps et actions, ainsi que la mani\u00e8re dont ces composants interagissent les uns avec les autres.</p> </li> <li> <p>Connaissance des \u00e9v\u00e9nements : Identifier les diff\u00e9rents \u00e9v\u00e9nements qui peuvent d\u00e9clencher des workflows et comment les configurer pour des sc\u00e9narios sp\u00e9cifiques.</p> </li> <li> <p>Initiation aux actions : Reconna\u00eetre le r\u00f4le des actions dans l'encapsulation de fonctionnalit\u00e9s r\u00e9utilisables et explorer les actions officielles courantes.</p> </li> </ol> <p>Ressources et activit\u00e9s</p> <ul> <li>Lecture de la documentation officielle sur les composants GitHub Actions</li> <li>Exploration de l'interface Actions dans plusieurs r\u00e9f\u00e9rentiels GitHub</li> <li>Examen des fichiers YAML de workflows existants</li> <li>Identification des composants dans des workflows r\u00e9els</li> </ul> <p>R\u00e9sultat attendu</p> <p>L'apprenant peut expliquer les composants de base de GitHub Actions, comprendre comment un workflow est d\u00e9clench\u00e9 et reconna\u00eetre les r\u00f4les des actions, jobs et steps.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#phase-2-creation-et-execution-mains-a-la-pate","title":"Phase 2 : Cr\u00e9ation et ex\u00e9cution (Mains \u00e0 la p\u00e2te)","text":"<p>Objectifs d'apprentissage</p> <p>Cette phase transition de la compr\u00e9hension th\u00e9orique \u00e0 l'impl\u00e9mentation pratique. L'apprenant acquiert l'exp\u00e9rience directe de cr\u00e9ation et d'ex\u00e9cution de workflows.</p> <ol> <li> <p>Cr\u00e9ation de workflows simples : Mettre en place un premier workflow qui s'ex\u00e9cute en r\u00e9ponse \u00e0 un \u00e9v\u00e9nement sp\u00e9cifique.</p> </li> <li> <p>Configuration de jobs multiples : Cr\u00e9er des workflows contenant plusieurs jobs orchestr\u00e9s de mani\u00e8re appropri\u00e9e.</p> </li> <li> <p>Utilisation d'actions : Int\u00e9grer des actions officielles et explorer comment les configurer avec des param\u00e8tres.</p> </li> <li> <p>D\u00e9bogage et monitoring : Consulter les logs d'ex\u00e9cution, identifier les erreurs et corriger les probl\u00e8mes.</p> </li> </ol> <p>Ressources et activit\u00e9s</p> <ul> <li>Cr\u00e9ation d'un premier workflow CI pour un r\u00e9f\u00e9rentiel test</li> <li>Configuration d'\u00e9v\u00e9nements sp\u00e9cifiques (push, pull_request)</li> <li>Utilisation de plusieurs actions dans un seul workflow</li> <li>Ajustement de la configuration d'actions et observation de l'impact</li> <li>Analyse des logs d'ex\u00e9cution et r\u00e9solution des probl\u00e8mes</li> </ul> <p>R\u00e9sultat attendu</p> <p>L'apprenant peut cr\u00e9er et ex\u00e9cuter des workflows simples \u00e0 mod\u00e9r\u00e9ment complexes, configurer des actions avec des param\u00e8tres et interpr\u00e9ter les logs d'ex\u00e9cution.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#phase-3-patterns-avances-optimisation-et-patterns","title":"Phase 3 : Patterns avanc\u00e9s (Optimisation et patterns)","text":"<p>Objectifs d'apprentissage</p> <p>Cette phase approfondit les comp\u00e9tences pour g\u00e9rer des sc\u00e9narios d'automatisation plus complexes et r\u00e9alistes.</p> <ol> <li> <p>Matrix builds : Mettre en place des strat\u00e9gies de matrice pour tester sur plusieurs configurations.</p> </li> <li> <p>Conditions et logique conditionnelle : Impl\u00e9menter des workflows qui s'adaptent selon les conditions d'ex\u00e9cution.</p> </li> <li> <p>Gestion des secrets : S\u00e9curiser les donn\u00e9es sensibles dans les workflows.</p> </li> <li> <p>Artifacts et caching : Optimiser les performances en g\u00e9rant les artifacts et le cache.</p> </li> <li> <p>Notifications et reporting : Configurer les notifications et g\u00e9n\u00e9rer des rapports.</p> </li> </ol> <p>Ressources et activit\u00e9s</p> <ul> <li>Configuration de matrix builds testant plusieurs versions de runtime</li> <li>Impl\u00e9mentation de conditions pour d\u00e9clencher des \u00e9tapes sp\u00e9cifiques</li> <li>Cr\u00e9ation et utilisation de secrets pour les donn\u00e9es sensibles</li> <li>Mise en cache des d\u00e9pendances pour acc\u00e9l\u00e9rer les ex\u00e9cutions</li> <li>Configuration de rapports de couverture</li> </ul> <p>R\u00e9sultat attendu</p> <p>L'apprenant peut cr\u00e9er des workflows sophistiqu\u00e9s avec des strat\u00e9gies de matrice, g\u00e9rer les donn\u00e9es sensibles de mani\u00e8re s\u00e9curis\u00e9e et optimiser les performances des workflows.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#phase-4-cas-dusage-reels-application-pratique","title":"Phase 4 : Cas d'usage r\u00e9els (Application pratique)","text":"<p>Objectifs d'apprentissage</p> <p>Cette phase applique les comp\u00e9tences acquises \u00e0 des sc\u00e9narios r\u00e9els d'int\u00e9gration et de d\u00e9ploiement continus.</p> <ol> <li> <p>Pipelines CI complets : Cr\u00e9er un pipeline d'int\u00e9gration continue complet incluant tests, analyses et builds.</p> </li> <li> <p>Pipelines CD : Impl\u00e9menter des d\u00e9ploiements automatis\u00e9s vers des environnements de staging et production.</p> </li> <li> <p>Automation de releases : Automatiser le versioning et la publication de nouvelles versions.</p> </li> <li> <p>Automation de s\u00e9curit\u00e9 : Mettre en place des v\u00e9rifications de s\u00e9curit\u00e9 et des audits automatiques.</p> </li> </ol> <p>Ressources et activit\u00e9s</p> <ul> <li>Cr\u00e9ation d'un pipeline CI pour un projet r\u00e9el</li> <li>Configuration d'un pipeline CD vers un environnement de d\u00e9ploiement</li> <li>Automation du processus de release</li> <li>Impl\u00e9mentation de v\u00e9rifications de s\u00e9curit\u00e9</li> </ul> <p>R\u00e9sultat attendu</p> <p>L'apprenant peut impl\u00e9menter des solutions GitHub Actions compl\u00e8tes couvrant l'int\u00e9gralit\u00e9 du cycle de d\u00e9veloppement dans un environnement de production.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap02/#conclusion-du-chapitre","title":"Conclusion du chapitre","text":"<p>Ce chapitre a pr\u00e9sent\u00e9 les fondamentaux de GitHub Actions, d\u00e9composant ses composants essentiels et d\u00e9montrant leur interaction harmonieuse. De la simple automatisation d'un workflow single-step \u00e0 des pipelines CI/CD sophistiqu\u00e9s, GitHub Actions offre une plateforme flexible et puissante int\u00e9gr\u00e9e nativement dans l'\u00e9cosyst\u00e8me GitHub[5].</p> <p>La ma\u00eetrise de ces concepts constitue le pr\u00e9alable \u00e0 toute utilisation efficace de GitHub Actions. Les chapitres suivants approfondiront ces concepts fondamentaux en explorant des patterns avanc\u00e9s, des strat\u00e9gies de d\u00e9ploiement complexes et des cas d'usage sp\u00e9cifiques \u00e0 diff\u00e9rents \u00e9cosyst\u00e8mes et langages de programmation.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/","title":"Citations","text":"<ul> <li>https://www.glukhov.org/fr/post/2025/07/github-actions-cheatsheet/</li> <li>https://blog.stephane-robert.info/docs/pipeline-cicd/github/</li> <li>https://apprendre-la-programmation.net/configurer-ci-github-actions/</li> <li>https://docs.github.com/fr/actions/get-started/understand-github-actions</li> <li>https://blog.eleven-labs.com/fr/et-si-on-passait-a-github-actions/</li> <li>https://docs.github.com/fr/actions</li> <li>https://docs.github.com/actions</li> <li>https://docs.github.com/fr/actions/reference/workflows-and-actions/workflow-syntax</li> <li>https://docs.github.com/fr/actions/get-started</li> <li>https://docs.github.com/articles/getting-started-with-github-actions</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 279</li> <li>completion_tokens: 9737</li> <li>total_tokens: 10016</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.146, 'request_cost': 0.006, 'total_cost': 0.153}</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#content","title":"Content","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap03/#chapitre-3-principales-notions-github-actions","title":"Chapitre 3 : Principales notions Github Actions","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap03/#introduction-aux-concepts-fondamentaux","title":"Introduction aux concepts fondamentaux","text":"<p>GitHub Actions repose sur plusieurs concepts interd\u00e9pendants qui permettent de construire des workflows automatis\u00e9s sophistiqu\u00e9s. Cette section explore en profondeur les m\u00e9canismes qui constituent l'\u00e9pine dorsale des pipelines CI/CD modernes, en fournissant des explications d\u00e9taill\u00e9es, des exemples concrets et des cas d'usage pratiques.[1][2]</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#utilisation-des-actions","title":"Utilisation des actions","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap03/#comprendre-les-actions-dans-github-actions","title":"Comprendre les actions dans GitHub Actions","text":"<p>Une action repr\u00e9sente une unit\u00e9 r\u00e9utilisable de code ou de travail qui effectue des t\u00e2ches sp\u00e9cifiques au sein d'un workflow.[4] Les actions encapsulent des processus complexes, r\u00e9duisant ainsi la n\u00e9cessit\u00e9 d'\u00e9crire du code r\u00e9p\u00e9titif dans les fichiers de workflow. Elles constituent les briques fondamentales permettant de construire des pipelines sophistiqu\u00e9s.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#categories-dactions","title":"Cat\u00e9gories d'actions","text":"<p>Les actions disponibles dans l'\u00e9cosyst\u00e8me GitHub se divisent en trois cat\u00e9gories principales :</p> <p>Actions officielles</p> <p>Les actions officielles sont maintenues par GitHub et offrent des fonctionnalit\u00e9s essentielles pour les workflows courants. Ces actions b\u00e9n\u00e9ficient du support complet de GitHub et sont r\u00e9guli\u00e8rement mises \u00e0 jour.[1]</p> <p>Voici les principales actions officielles :</p> Action Objectif Param\u00e8tres cl\u00e9s actions/checkout V\u00e9rifie le code du d\u00e9p\u00f4t ref, submodules actions/setup-node Configure Node.js node-version, cache actions/setup-python Configure Python python-version actions/cache Mettre en cache les d\u00e9pendances path, key, restore-keys actions/upload-artifact T\u00e9l\u00e9charger les artefacts de build name, path, if-no-files-found actions/download-artifact T\u00e9l\u00e9charger les artefacts name, path actions/create-release Cr\u00e9e une publication GitHub tag_name, release_name actions/labeler Applique automatiquement des \u00e9tiquettes repo-token, configuration-path <p>Actions communautaires</p> <p>La communaut\u00e9 GitHub d\u00e9veloppe des actions qui adressent des besoins sp\u00e9cifiques non couverts par les actions officielles. Ces actions sont souvent hautement sp\u00e9cialis\u00e9es et offrent des fonctionnalit\u00e9s innovantes.</p> <p>Actions tierces</p> <p>Les fournisseurs externes proposent des actions pour int\u00e9grer leurs services avec GitHub Actions, incluant des outils de d\u00e9ploiement, d'analyse de code et d'infrastructure.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#syntaxe-dutilisation-des-actions","title":"Syntaxe d'utilisation des actions","text":"<p>La syntaxe g\u00e9n\u00e9rale pour appeler une action suit un mod\u00e8le standardis\u00e9 :[1]</p> YAML<pre><code>- name: D\u00e9crire l'action\n  uses: owner/repo@ref\n  with:\n    param1: valeur1\n    param2: valeur2\n  env:\n    VAR_ENV: valeur\n  if: ${{ condition }}\n  continue-on-error: true\n</code></pre> <p>Param\u00e8tres d'action d\u00e9taill\u00e9s :</p> <ul> <li>uses : R\u00e9f\u00e9rence l'action \u00e0 utiliser au format <code>propri\u00e9taire/d\u00e9p\u00f4t@version</code></li> <li>with : Arguments sp\u00e9cifiques \u00e0 l'action (varient selon l'action)</li> <li>env : Variables d'environnement disponibles pour l'action</li> <li>if : Condition d'ex\u00e9cution (expression conditionnelle)</li> <li>continue-on-error : Continue l'ex\u00e9cution m\u00eame si l'\u00e9tape \u00e9choue</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#exemple-pratique-workflow-multi-actions","title":"Exemple pratique : Workflow multi-actions","text":"YAML<pre><code>name: Build et Test Application Node.js\n\non:\n  push:\n    branches: [ main, develop ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  build-and-test:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: R\u00e9cup\u00e9rer le code\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Configurer Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n          cache: 'npm'\n\n      - name: Installer les d\u00e9pendances\n        run: npm ci\n\n      - name: Ex\u00e9cuter les linters\n        run: npm run lint\n\n      - name: Ex\u00e9cuter les tests\n        run: npm run test:coverage\n\n      - name: T\u00e9l\u00e9charger le rapport de couverture\n        uses: actions/upload-artifact@v3\n        with:\n          name: coverage-report\n          path: coverage/\n          if-no-files-found: error\n\n      - name: Construire l'application\n        run: npm run build\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#exemple-approfondi-dune-action-checkout","title":"Exemple approfondi d'une action : Checkout","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap03/#presentation-de-laction-checkout","title":"Pr\u00e9sentation de l'action Checkout","text":"<p>L'action <code>actions/checkout</code> constitue l'une des actions les plus essentielles dans tout workflow GitHub Actions.[1] Elle effectue l'op\u00e9ration fondamentale de clonage du code du d\u00e9p\u00f4t dans l'environnement du runner, permettant au workflow d'acc\u00e9der et de manipuler le code source.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#fonctionnement-interne","title":"Fonctionnement interne","text":"<p>Lorsque <code>checkout</code> s'ex\u00e9cute, elle effectue les op\u00e9rations suivantes :</p> <ol> <li>Initialisation du d\u00e9p\u00f4t Git : Cr\u00e9e un d\u00e9p\u00f4t Git local sur le runner</li> <li>Configuration du remote : Configure l'URL du d\u00e9p\u00f4t distant</li> <li>R\u00e9cup\u00e9ration du code : T\u00e9l\u00e9charge les fichiers correspondant \u00e0 la r\u00e9f\u00e9rence sp\u00e9cifi\u00e9e</li> <li>Configuration de HEAD : Positionne HEAD sur le commit appropri\u00e9</li> </ol>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#parametres-de-laction-checkout","title":"Param\u00e8tres de l'action Checkout","text":"Param\u00e8tre Type D\u00e9faut Description repository string <code>${{ github.repository }}</code> D\u00e9p\u00f4t \u00e0 cloner au format <code>propri\u00e9taire/nom</code> ref string <code>${{ github.ref }}</code> Branche, tag ou SHA du commit \u00e0 v\u00e9rifier token string <code>${{ github.token }}</code> Token pour cloner les d\u00e9p\u00f4ts priv\u00e9s fetch-depth number <code>1</code> Nombre de commits \u00e0 r\u00e9cup\u00e9rer (0 = tous) clean boolean <code>true</code> Nettoie les fichiers non suivis apr\u00e8s le checkout submodules string <code>false</code> G\u00e8re les sous-modules Git (false, true, recursive) lfs boolean <code>false</code> Active Git LFS (Large File Storage) persist-credentials boolean <code>true</code> Configure les identifiants Git pour les commits ult\u00e9rieurs"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#cas-dusage-pratiques","title":"Cas d'usage pratiques","text":"<p>Cas 1 : Checkout simple sur la branche actuelle</p> YAML<pre><code>- name: Checkout du code\n  uses: actions/checkout@v4\n</code></pre> <p>Ce sc\u00e9nario minimal clone le d\u00e9p\u00f4t actuel sur la branche actuelle avec une profondeur de 1 commit.</p> <p>Cas 2 : R\u00e9cup\u00e9ration de tout l'historique Git</p> YAML<pre><code>- name: Checkout avec historique complet\n  uses: actions/checkout@v4\n  with:\n    fetch-depth: 0\n</code></pre> <p>Cette configuration permet d'acc\u00e9der \u00e0 l'int\u00e9gralit\u00e9 de l'historique Git, n\u00e9cessaire pour des outils comme SonarQube ou des analyses d'impact de changement.</p> <p>Cas 3 : Gestion des sous-modules</p> YAML<pre><code>- name: Checkout avec sous-modules\n  uses: actions/checkout@v4\n  with:\n    submodules: recursive\n    token: ${{ secrets.GITHUB_TOKEN }}\n</code></pre> <p>Lors du travail avec des d\u00e9p\u00f4ts contenant des sous-modules Git, cette configuration les r\u00e9cup\u00e8re r\u00e9cursivement.</p> <p>Cas 4 : Checkout d'une branche sp\u00e9cifique</p> YAML<pre><code>- name: Checkout d'une branche particuli\u00e8re\n  uses: actions/checkout@v4\n  with:\n    ref: refs/heads/release-v2.0\n    fetch-depth: 0\n</code></pre> <p>Permet de v\u00e9rifier un code provenant d'une branche diff\u00e9rente que la branche actuelle.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#workflow-complet-utilisant-checkout","title":"Workflow complet utilisant Checkout","text":"YAML<pre><code>name: Analyse de d\u00e9p\u00f4t multi-branche\n\non:\n  push:\n    branches: [ main, develop ]\n  pull_request:\n  workflow_dispatch:\n\njobs:\n  analyze:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        branch: [ main, develop ]\n\n    steps:\n      - name: Checkout de la branche ${{ matrix.branch }}\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ matrix.branch }}\n          fetch-depth: 0\n          clean: true\n\n      - name: Obtenir les informations du commit\n        run: |\n          echo \"Branche: ${{ matrix.branch }}\"\n          echo \"Dernier commit: $(git log -1 --oneline)\"\n          echo \"Nombre de commits: $(git rev-list --count HEAD)\"\n          echo \"Auteur du dernier commit: $(git log -1 --format='%an')\"\n\n      - name: Lister les fichiers modifi\u00e9s\n        run: |\n          if [ \"${{ github.event_name }}\" == \"pull_request\" ]; then\n            echo \"Fichiers modifi\u00e9s dans la PR:\"\n            git diff --name-only origin/main\n          fi\n\n      - name: Configuration Git pour les commits ult\u00e9rieurs\n        uses: actions/checkout@v4\n        with:\n          ref: ${{ matrix.branch }}\n          persist-credentials: true\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#enjeux-de-performance-avec-checkout","title":"Enjeux de performance avec Checkout","text":"<p>La profondeur de r\u00e9cup\u00e9ration (<code>fetch-depth</code>) impacte significativement les performances :</p> <ul> <li>fetch-depth: 1 (par d\u00e9faut) : Tr\u00e8s rapide, appropri\u00e9 pour les builds simples</li> <li>fetch-depth: 0 : Plus lent, mais n\u00e9cessaire pour les analyses compl\u00e8tes du d\u00e9p\u00f4t</li> </ul> <p>Pour les repositories volumineux, l'utilisation de <code>fetch-depth: 1</code> est recommand\u00e9e sauf si l'historique complet s'av\u00e8re n\u00e9cessaire.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#les-variables-et-les-secrets","title":"Les variables et les secrets","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap03/#systeme-de-variables-dans-github-actions","title":"Syst\u00e8me de variables dans GitHub Actions","text":"<p>GitHub Actions fournit plusieurs m\u00e9canismes pour g\u00e9rer les donn\u00e9es variables n\u00e9cessaires aux workflows. Ces m\u00e9canismes se divisent en trois cat\u00e9gories principales : les variables d'environnement, les variables personnalis\u00e9es et les secrets.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#variables-denvironnement-par-defaut","title":"Variables d'environnement par d\u00e9faut","text":"<p>GitHub fournit automatiquement un ensemble de variables d'environnement dans chaque step :</p> Variable Description Exemple GITHUB_WORKSPACE Chemin du r\u00e9pertoire de travail <code>/home/runner/work/repo-name/repo-name</code> GITHUB_ACTION Identifiant unique de l'action <code>__run</code> GITHUB_ACTIONS Indique que le code s'ex\u00e9cute dans GitHub Actions <code>true</code> GITHUB_ACTOR Nom de la personne qui a d\u00e9clench\u00e9 le workflow <code>username</code> GITHUB_EVENT_NAME Type d'\u00e9v\u00e9nement qui a d\u00e9clench\u00e9 le workflow <code>push</code>, <code>pull_request</code> GITHUB_REF Branche ou tag de r\u00e9f\u00e9rence <code>refs/heads/main</code> GITHUB_SHA SHA du commit <code>abc1234567890def</code> RUNNER_OS Syst\u00e8me d'exploitation du runner <code>Linux</code>, <code>Windows</code>, <code>macOS</code>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#definition-de-variables-personnalisees","title":"D\u00e9finition de variables personnalis\u00e9es","text":"<p>Variables au niveau du workflow</p> YAML<pre><code>name: Utilisation de variables\n\nenv:\n  NODE_VERSION: '18'\n  REGISTRY: ghcr.io\n  IMAGE_NAME: mon-app\n\non: push\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Configurer Node.js ${{ env.NODE_VERSION }}\n        uses: actions/setup-node@v3\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n\n      - name: Afficher les variables\n        run: |\n          echo \"Registry: ${{ env.REGISTRY }}\"\n          echo \"Image: ${{ env.IMAGE_NAME }}\"\n</code></pre> <p>Variables au niveau du job</p> YAML<pre><code>jobs:\n  build:\n    runs-on: ubuntu-latest\n    env:\n      BUILD_ENV: production\n      LOG_LEVEL: debug\n\n    steps:\n      - name: Utiliser les variables du job\n        run: |\n          echo \"Environnement: $BUILD_ENV\"\n          echo \"Niveau de log: $LOG_LEVEL\"\n</code></pre> <p>Variables au niveau du step</p> YAML<pre><code>steps:\n  - name: \u00c9tape sp\u00e9cifique\n    env:\n      TEMP_VAR: valeur-temporaire\n    run: |\n      echo \"Variable temporaire: $TEMP_VAR\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#gestion-des-secrets","title":"Gestion des secrets","text":"<p>Les secrets constituent le m\u00e9canisme s\u00e9curis\u00e9 pour stocker les informations sensibles comme les tokens d'authentification, les cl\u00e9s API et les identifiants.</p> <p>Cr\u00e9ation de secrets au niveau du d\u00e9p\u00f4t</p> <p>Les secrets doivent \u00eatre d\u00e9finis dans les param\u00e8tres du d\u00e9p\u00f4t GitHub (Settings &gt; Secrets and variables &gt; Actions). Ils ne peuvent pas \u00eatre cr\u00e9\u00e9s directement dans le workflow.</p> <p>Utilisation des secrets dans les workflows</p> YAML<pre><code>name: D\u00e9ploiement s\u00e9curis\u00e9\n\non:\n  push:\n    branches: [ main ]\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Configuration d'authentification\n        env:\n          API_KEY: ${{ secrets.API_KEY }}\n          DATABASE_URL: ${{ secrets.DATABASE_URL }}\n          DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}\n          DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}\n        run: |\n          # Les secrets sont masqu\u00e9s dans les logs\n          echo \"Configuration en cours...\"\n          # Le secret ne s'affichera pas : *** au lieu de la valeur\n          echo \"Database: $DATABASE_URL\"\n\n      - name: Authentification Docker\n        env:\n          REGISTRY_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}\n        run: |\n          echo \"$REGISTRY_PASSWORD\" | docker login -u ${{ secrets.DOCKER_USERNAME }} --password-stdin\n</code></pre> <p>Masquage des secrets dans les logs</p> <p>GitHub Actions masque automatiquement les secrets affich\u00e9s dans les logs. Toute valeur correspondant \u00e0 un secret sera remplac\u00e9e par <code>***</code>.</p> YAML<pre><code>- name: D\u00e9monstration du masquage\n  env:\n    SECRET_TOKEN: ${{ secrets.API_TOKEN }}\n  run: |\n    echo \"Token: $SECRET_TOKEN\"  # Affichera: Token: ***\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#secrets-au-niveau-de-lorganisation","title":"Secrets au niveau de l'organisation","text":"<p>Pour les workflows d'\u00e9quipes importantes, les secrets peuvent \u00eatre d\u00e9finis au niveau de l'organisation et r\u00e9utilis\u00e9s dans tous les d\u00e9p\u00f4ts.</p> YAML<pre><code>- name: Utiliser un secret d'organisation\n  env:\n    ORG_SECRET: ${{ secrets.ORG_SIGNING_KEY }}\n  run: |\n    echo \"Utilisation du secret d'organisation\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#workflow-complet-avec-variables-et-secrets","title":"Workflow complet avec variables et secrets","text":"YAML<pre><code>name: Pipeline CI/CD complet\n\non:\n  push:\n    branches: [ main, develop ]\n  pull_request:\n    branches: [ main ]\n\nenv:\n  REGISTRY: ghcr.io\n  VERSION: v1.0.0\n\njobs:\n  build-and-deploy:\n    runs-on: ubuntu-latest\n\n    env:\n      BUILD_TYPE: ${{ github.ref == 'refs/heads/main' &amp;&amp; 'production' || 'staging' }}\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Configurer les variables de build\n        run: |\n          echo \"BUILD_TYPE=${{ env.BUILD_TYPE }}\" &gt;&gt; $GITHUB_ENV\n          echo \"IMAGE_TAG=${{ env.REGISTRY }}/app:${{ env.VERSION }}-${{ github.run_number }}\" &gt;&gt; $GITHUB_ENV\n\n      - name: Construire l'image Docker\n        env:\n          IMAGE_NAME: ${{ env.IMAGE_TAG }}\n        run: |\n          docker build -t $IMAGE_NAME .\n          echo \"Image construite: $IMAGE_NAME\"\n\n      - name: Pousser vers le registre\n        env:\n          REGISTRY_TOKEN: ${{ secrets.REGISTRY_TOKEN }}\n        run: |\n          echo \"$REGISTRY_TOKEN\" | docker login -u ${{ secrets.REGISTRY_USER }} --password-stdin ${{ env.REGISTRY }}\n          docker push ${{ env.IMAGE_TAG }}\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#les-contextes","title":"Les contextes","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap03/#comprehension-des-contextes-dans-github-actions","title":"Compr\u00e9hension des contextes dans GitHub Actions","text":"<p>Un contexte est un objet contenant des informations sur le workflow, l'\u00e9v\u00e9nement d\u00e9clencheur, le runner et les actions en cours d'ex\u00e9cution.[4] Les contextes permettent d'acc\u00e9der \u00e0 ces informations dynamiques et de les utiliser dans les expressions du workflow.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#contextes-principaux-disponibles","title":"Contextes principaux disponibles","text":"<p>Contexte github</p> <p>Le contexte <code>github</code> contient des informations sur le workflow, le d\u00e9p\u00f4t et l'\u00e9v\u00e9nement d\u00e9clencheur.</p> YAML<pre><code>${{ github.workflow }}        # Nom du workflow\n${{ github.run_id }}          # ID unique de l'ex\u00e9cution\n${{ github.run_number }}      # Num\u00e9ro s\u00e9quentiel de l'ex\u00e9cution\n${{ github.job }}             # ID du job actuel\n${{ github.action }}          # ID unique de l'action\n${{ github.actor }}           # Nom de l'utilisateur qui a d\u00e9clench\u00e9 le workflow\n${{ github.repository }}      # Propri\u00e9taire/nom du d\u00e9p\u00f4t\n${{ github.repository_owner }} # Propri\u00e9taire du d\u00e9p\u00f4t\n${{ github.ref }}             # Branche ou tag de r\u00e9f\u00e9rence compl\u00e8te\n${{ github.ref_name }}        # Nom de la branche ou du tag sans le pr\u00e9fixe\n${{ github.sha }}             # SHA du commit\n${{ github.head_ref }}        # Branche head (pour les pull requests)\n${{ github.base_ref }}        # Branche base (pour les pull requests)\n${{ github.event_name }}      # Type d'\u00e9v\u00e9nement d\u00e9clencheur\n${{ github.workspace }}       # Chemin du r\u00e9pertoire de travail\n${{ github.server_url }}      # URL du serveur GitHub\n${{ github.api_url }}         # URL de l'API GitHub\n</code></pre> <p>Contexte env</p> <p>Le contexte <code>env</code> contient les variables d'environnement d\u00e9finies au niveau du workflow, du job ou du step.</p> YAML<pre><code>${{ env.NODE_VERSION }}       # Acc\u00e8s aux variables d\u00e9finies avec env:\n${{ env.CUSTOM_VAR }}         # Acc\u00e8s aux variables personnalis\u00e9es\n</code></pre> <p>Contexte secrets</p> <p>Le contexte <code>secrets</code> fournit l'acc\u00e8s \u00e0 tous les secrets d\u00e9finis pour le d\u00e9p\u00f4t, l'organisation ou la branche.</p> YAML<pre><code>${{ secrets.API_TOKEN }}      # Acc\u00e8s s\u00e9curis\u00e9 aux secrets\n${{ secrets.DEPLOY_KEY }}     # Cl\u00e9s de d\u00e9ploiement\n</code></pre> <p>Contexte runner</p> <p>Le contexte <code>runner</code> contient des informations sur le runner ex\u00e9cutant le job.</p> YAML<pre><code>${{ runner.os }}              # Syst\u00e8me d'exploitation (Linux, Windows, macOS)\n${{ runner.arch }}            # Architecture du processeur (x86, ARM, etc.)\n${{ runner.name }}            # Nom du runner\n${{ runner.tool_cache }}      # Chemin vers le cache des outils\n${{ runner.temp }}            # R\u00e9pertoire temporaire\n${{ runner.workspace }}       # Espace de travail du runner\n</code></pre> <p>Contexte strategy</p> <p>Le contexte <code>strategy</code> contient les informations sur la strat\u00e9gie d'ex\u00e9cution (notamment pour les matrices).</p> YAML<pre><code>${{ strategy.job-index }}     # Index du job dans la matrice\n${{ strategy.job-total }}     # Nombre total de jobs dans la matrice\n${{ strategy.max-parallel }}  # Nombre maximum de jobs parall\u00e8les\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#exemple-pratique-utilisation-complete-des-contextes","title":"Exemple pratique : Utilisation compl\u00e8te des contextes","text":"YAML<pre><code>name: D\u00e9monstration des contextes\n\non:\n  push:\n    branches: [ main, develop ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  context-demo:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ ubuntu-latest, windows-latest ]\n        node-version: [ 16, 18, 20 ]\n      max-parallel: 2\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Afficher les informations du contexte github\n        run: |\n          echo \"=== CONTEXTE GITHUB ===\"\n          echo \"Workflow: ${{ github.workflow }}\"\n          echo \"Run ID: ${{ github.run_id }}\"\n          echo \"Run Number: ${{ github.run_number }}\"\n          echo \"Job: ${{ github.job }}\"\n          echo \"Actor: ${{ github.actor }}\"\n          echo \"D\u00e9p\u00f4t: ${{ github.repository }}\"\n          echo \"Branche/Tag: ${{ github.ref }}\"\n          echo \"Ref name: ${{ github.ref_name }}\"\n          echo \"SHA: ${{ github.sha }}\"\n          echo \"Event: ${{ github.event_name }}\"\n\n      - name: Afficher les informations du contexte runner\n        run: |\n          echo \"=== CONTEXTE RUNNER ===\"\n          echo \"OS: ${{ runner.os }}\"\n          echo \"Architecture: ${{ runner.arch }}\"\n          echo \"Workspace: ${{ runner.workspace }}\"\n          echo \"Temp directory: ${{ runner.temp }}\"\n\n      - name: Afficher les informations de la strat\u00e9gie\n        run: |\n          echo \"=== CONTEXTE STRAT\u00c9GIE ===\"\n          echo \"Job Index: ${{ strategy.job-index }}\"\n          echo \"Job Total: ${{ strategy.job-total }}\"\n          echo \"Max Parallel: ${{ strategy.max-parallel }}\"\n          echo \"OS actuel: ${{ matrix.os }}\"\n          echo \"Node version: ${{ matrix.node-version }}\"\n\n      - name: D\u00e9terminer le type de d\u00e9ploiement\n        run: |\n          if [ \"${{ github.ref }}\" == \"refs/heads/main\" ]; then\n            echo \"DEPLOY_ENV=production\" &gt;&gt; $GITHUB_ENV\n          elif [ \"${{ github.ref }}\" == \"refs/heads/develop\" ]; then\n            echo \"DEPLOY_ENV=staging\" &gt;&gt; $GITHUB_ENV\n          else\n            echo \"DEPLOY_ENV=development\" &gt;&gt; $GITHUB_ENV\n          fi\n\n      - name: Afficher l'environnement d\u00e9termin\u00e9\n        run: |\n          echo \"Environnement de d\u00e9ploiement: ${{ env.DEPLOY_ENV }}\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#acces-aux-donnees-de-levenement","title":"Acc\u00e8s aux donn\u00e9es de l'\u00e9v\u00e9nement","text":"<p>Le contexte <code>github.event</code> contient les donn\u00e9es compl\u00e8tes de l'\u00e9v\u00e9nement qui a d\u00e9clench\u00e9 le workflow :</p> YAML<pre><code>- name: Informations de pull request\n  if: github.event_name == 'pull_request'\n  run: |\n    echo \"PR Number: ${{ github.event.pull_request.number }}\"\n    echo \"PR Title: ${{ github.event.pull_request.title }}\"\n    echo \"PR Author: ${{ github.event.pull_request.user.login }}\"\n    echo \"PR Base: ${{ github.event.pull_request.base.ref }}\"\n    echo \"PR Head: ${{ github.event.pull_request.head.ref }}\"\n    echo \"PR Additions: ${{ github.event.pull_request.additions }}\"\n    echo \"PR Deletions: ${{ github.event.pull_request.deletions }}\"\n\n- name: Informations de push\n  if: github.event_name == 'push'\n  run: |\n    echo \"Commits: ${{ github.event.head_commit.message }}\"\n    echo \"Author: ${{ github.event.head_commit.author.name }}\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#les-expressions-et-la-propriete-if","title":"Les expressions et la propri\u00e9t\u00e9 if","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap03/#concepts-des-expressions","title":"Concepts des expressions","text":"<p>Une expression dans GitHub Actions permet d'\u00e9valuer des conditions et de produire des valeurs dynamiques au sein des workflows.[1] Les expressions combinent des variables, des contextes, des op\u00e9rateurs et des fonctions pour cr\u00e9er une logique conditionnelle sophistiqu\u00e9e.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#syntaxe-des-expressions","title":"Syntaxe des expressions","text":"<p>Les expressions doivent \u00eatre encapsul\u00e9es dans la syntaxe <code>${{ }}</code> :</p> YAML<pre><code># Expression simple\nname: Build\nrun: echo \"Repository: ${{ github.repository }}\"\n\n# Expression avec condition\nif: ${{ github.event_name == 'push' }}\n\n# Expression avec fonction\nenv:\n  VERSION: ${{ format('v{0}.{1}', 1, 0) }}\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#operateurs-disponibles","title":"Op\u00e9rateurs disponibles","text":"Op\u00e9rateur Description Exemple == \u00c9galit\u00e9 <code>${{ github.event_name == 'push' }}</code> != In\u00e9galit\u00e9 <code>${{ github.ref != 'refs/heads/main' }}</code> &lt; Inf\u00e9rieur \u00e0 <code>${{ github.run_number &lt; 100 }}</code> &lt;= Inf\u00e9rieur ou \u00e9gal <code>${{ github.run_number &lt;= 100 }}</code> &gt; Sup\u00e9rieur \u00e0 <code>${{ github.run_number &gt; 100 }}</code> &gt;= Sup\u00e9rieur ou \u00e9gal <code>${{ github.run_number &gt;= 100 }}</code> &amp;&amp; ET logique <code>${{ condition1 &amp;&amp; condition2 }}</code> || OU logique <code>${{ condition1 \\|\\| condition2 }}</code> ! NON logique <code>${{ !condition }}</code>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#fonctions-disponibles-dans-les-expressions","title":"Fonctions disponibles dans les expressions","text":"<p>GitHub Actions fournit un ensemble de fonctions pr\u00e9d\u00e9finies pour manipuler les donn\u00e9es au sein des expressions :</p> <p>Fonction contains()</p> <p>V\u00e9rifie si une cha\u00eene en contient une autre :</p> YAML<pre><code>if: ${{ contains(github.event.head_commit.message, 'hotfix') }}\n  # D\u00e9clenche si le message de commit contient \"hotfix\"\n\nif: ${{ contains(github.repository, 'test') }}\n  # D\u00e9clenche si le nom du d\u00e9p\u00f4t contient \"test\"\n</code></pre> <p>Fonction startsWith()</p> <p>V\u00e9rifie le d\u00e9but d'une cha\u00eene :</p> YAML<pre><code>if: ${{ startsWith(github.ref_name, 'release-') }}\n  # D\u00e9clenche pour les branches commen\u00e7ant par \"release-\"\n\nif: ${{ startsWith(github.event.head_commit.message, '[SKIP]') }}\n  # Ignore le build si le commit commence par [SKIP]\n</code></pre> <p>Fonction endsWith()</p> <p>V\u00e9rifie la fin d'une cha\u00eene :</p> YAML<pre><code>if: ${{ endsWith(github.repository, '-api') }}\n  # D\u00e9clenche pour les d\u00e9p\u00f4ts terminant par \"-api\"\n</code></pre> <p>Fonction format()</p> <p>Formate les cha\u00eenes avec des param\u00e8tres :</p> YAML<pre><code>env:\n  BUILD_TAG: ${{ format('v{0}.{1}.{2}', github.run_number, 0, 0) }}\n\nrun: echo \"Version: ${{ format('{0}-{1}', github.ref_name, github.sha) }}\"\n</code></pre> <p>Fonction join()</p> <p>Joint les \u00e9l\u00e9ments d'un tableau :</p> YAML<pre><code>env:\n  PATHS: ${{ join(array('src/', 'build/', 'dist/'), ',') }}\n</code></pre> <p>Fonction hashFiles()</p> <p>Cr\u00e9e un hash pour une ou plusieurs fichiers :</p> YAML<pre><code>- uses: actions/cache@v3\n  with:\n    path: ~/.npm\n    key: npm-${{ hashFiles('**/package-lock.json') }}\n    # Le cache est invalide si package-lock.json change\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#la-propriete-if-pour-les-conditions","title":"La propri\u00e9t\u00e9 if pour les conditions","text":"<p>La propri\u00e9t\u00e9 <code>if</code> permet de contr\u00f4ler l'ex\u00e9cution conditionnelle des jobs et des steps.</p> <p>Conditions au niveau du step</p> YAML<pre><code>steps:\n  - uses: actions/checkout@v4\n\n  - name: \u00c9tape conditionnelle\n    if: ${{ github.event_name == 'push' }}\n    run: echo \"Ceci s'ex\u00e9cute uniquement sur les push\"\n\n  - name: \u00c9tape sur pull request\n    if: ${{ github.event_name == 'pull_request' }}\n    run: echo \"Ceci s'ex\u00e9cute uniquement sur les PR\"\n\n  - name: \u00c9tape sur branche main\n    if: ${{ github.ref == 'refs/heads/main' }}\n    run: echo \"Ceci s'ex\u00e9cute uniquement sur main\"\n\n  - name: \u00c9tape si le commit contient [deploy]\n    if: ${{ contains(github.event.head_commit.message, '[deploy]') }}\n    run: echo \"D\u00e9ploiement d\u00e9clench\u00e9\"\n</code></pre> <p>Conditions au niveau du job</p> YAML<pre><code>jobs:\n  build:\n    runs-on: ubuntu-latest\n    if: ${{ github.event_name != 'pull_request' }}\n    steps:\n      - uses: actions/checkout@v4\n\n  deploy:\n    runs-on: ubuntu-latest\n    needs: build\n    if: ${{ github.ref == 'refs/heads/main' &amp;&amp; github.event_name == 'push' }}\n    steps:\n      - name: D\u00e9ployer\n        run: echo \"D\u00e9ploiement en production\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#workflow-complet-avec-expressions-et-conditions","title":"Workflow complet avec expressions et conditions","text":"YAML<pre><code>name: CI/CD avec logique conditionnelle\n\non:\n  push:\n    branches: [ main, develop, release/* ]\n  pull_request:\n    branches: [ main, develop ]\n\njobs:\n  analyze:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: D\u00e9terminer le contexte d'ex\u00e9cution\n        run: |\n          if [[ \"${{ github.event_name }}\" == \"push\" ]]; then\n            echo \"MODE=production\" &gt;&gt; $GITHUB_ENV\n            echo \"SHOULD_DEPLOY=true\" &gt;&gt; $GITHUB_ENV\n          elif [[ \"${{ github.event_name }}\" == \"pull_request\" ]]; then\n            echo \"MODE=testing\" &gt;&gt; $GITHUB_ENV\n            echo \"SHOULD_DEPLOY=false\" &gt;&gt; $GITHUB_ENV\n          fi\n\n      - name: Afficher le mode d'ex\u00e9cution\n        run: echo \"Mode actuel: ${{ env.MODE }}\"\n\n  build:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ ubuntu-latest ]\n        node-version: [ 18 ]\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: actions/setup-node@v3\n        with:\n          node-version: ${{ matrix.node-version }}\n          cache: npm\n\n      - name: Installer les d\u00e9pendances\n        run: npm ci\n\n      - name: Ex\u00e9cuter les tests\n        run: npm test\n\n      - name: Construire le projet\n        run: npm run build\n\n  deploy:\n    needs: build\n    runs-on: ubuntu-latest\n    if: ${{ \n      github.event_name == 'push' &amp;&amp; \n      (github.ref == 'refs/heads/main' || startsWith(github.ref, 'refs/heads/release/'))\n    }}\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: D\u00e9terminer l'environnement de d\u00e9ploiement\n        run: |\n          if [[ \"${{ github.ref }}\" == \"refs/heads/main\" ]]; then\n            echo \"DEPLOY_ENV=production\" &gt;&gt; $GITHUB_ENV\n          elif [[ \"${{ github.ref }}\" =~ ^refs/heads/release/ ]]; then\n            echo \"DEPLOY_ENV=staging\" &gt;&gt; $GITHUB_ENV\n          fi\n\n      - name: Afficher l'environnement\n        run: echo \"D\u00e9ploiement vers: ${{ env.DEPLOY_ENV }}\"\n\n      - name: D\u00e9ployer\n        if: ${{ !cancelled() }}\n        run: |\n          echo \"D\u00e9ploiement en cours...\"\n          echo \"Branch: ${{ github.ref_name }}\"\n          echo \"Commit: ${{ github.sha }}\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#needs-outputs-et-les-contextes-steps-et-needs","title":"Needs, outputs et les contextes steps et needs","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap03/#le-systeme-de-dependances-entre-jobs-avec-needs","title":"Le syst\u00e8me de d\u00e9pendances entre jobs avec needs","text":"<p>La propri\u00e9t\u00e9 <code>needs</code> \u00e9tablit les d\u00e9pendances explicites entre jobs et permet la transmission de donn\u00e9es entre eux.</p> <p>D\u00e9finition des d\u00e9pendances</p> YAML<pre><code>jobs:\n  job1:\n    runs-on: ubuntu-latest\n    steps:\n      - run: echo \"Job 1 ex\u00e9cut\u00e9\"\n\n  job2:\n    needs: job1\n    runs-on: ubuntu-latest\n    steps:\n      - run: echo \"Job 2 s'ex\u00e9cute apr\u00e8s job1\"\n\n  job3:\n    needs: [ job1, job2 ]\n    runs-on: ubuntu-latest\n    steps:\n      - run: echo \"Job 3 s'ex\u00e9cute apr\u00e8s job1 et job2\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#sortie-des-jobs-avec-outputs","title":"Sortie des jobs avec outputs","text":"<p>Les outputs permettent de passer des donn\u00e9es d'un job \u00e0 un autre.</p> <p>D\u00e9finition des outputs au niveau du step</p> YAML<pre><code>jobs:\n  generate-data:\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.version.outputs.number }}\n      build-id: ${{ steps.build.outputs.id }}\n\n    steps:\n      - name: G\u00e9n\u00e9rer la version\n        id: version\n        run: |\n          echo \"number=v1.0.0-build.${{ github.run_number }}\" &gt;&gt; $GITHUB_OUTPUT\n\n      - name: G\u00e9n\u00e9rer l'ID de build\n        id: build\n        run: |\n          echo \"id=${{ github.run_id }}\" &gt;&gt; $GITHUB_OUTPUT\n</code></pre> <p>Consommation des outputs</p> YAML<pre><code>jobs:\n  generate-data:\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.version.outputs.number }}\n      commit-sha: ${{ steps.metadata.outputs.sha }}\n\n    steps:\n      - name: G\u00e9n\u00e9rer la version\n        id: version\n        run: echo \"number=v1.2.3\" &gt;&gt; $GITHUB_OUTPUT\n\n      - name: Capturer le SHA du commit\n        id: metadata\n        run: echo \"sha=${{ github.sha }}\" &gt;&gt; $GITHUB_OUTPUT\n\n  deploy:\n    needs: generate-data\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Utiliser les donn\u00e9es du job pr\u00e9c\u00e9dent\n        run: |\n          echo \"Version: ${{ needs.generate-data.outputs.version }}\"\n          echo \"Commit SHA: ${{ needs.generate-data.outputs.commit-sha }}\"\n\n      - name: D\u00e9ployer avec la version\n        run: |\n          VERSION=\"${{ needs.generate-data.outputs.version }}\"\n          echo \"D\u00e9ploiement de la version: $VERSION\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#le-contexte-steps","title":"Le contexte steps","text":"<p>Le contexte <code>steps</code> fournit l'acc\u00e8s aux informations sur les steps ex\u00e9cut\u00e9es au sein du job actuel.</p> YAML<pre><code>steps:\n  - name: Premi\u00e8re \u00e9tape\n    id: step1\n    run: |\n      echo \"output1=valeur1\" &gt;&gt; $GITHUB_OUTPUT\n      echo \"output2=valeur2\" &gt;&gt; $GITHUB_OUTPUT\n\n  - name: Deuxi\u00e8me \u00e9tape\n    run: |\n      echo \"R\u00e9sultat du step 1: ${{ steps.step1.outputs.output1 }}\"\n      echo \"R\u00e9sultat du step 1: ${{ steps.step1.outputs.output2 }}\"\n\n  - name: V\u00e9rifier le statut du step 1\n    if: ${{ success() }}\n    run: echo \"Le step pr\u00e9c\u00e9dent a r\u00e9ussi\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#le-contexte-needs","title":"Le contexte needs","text":"<p>Le contexte <code>needs</code> contient les informations sur les jobs dont d\u00e9pend le job actuel.</p> YAML<pre><code>jobs:\n  prepare:\n    runs-on: ubuntu-latest\n    outputs:\n      config: ${{ steps.config.outputs.data }}\n\n    steps:\n      - name: Pr\u00e9parer la configuration\n        id: config\n        run: echo \"data={\\\"env\\\":\\\"prod\\\"}\" &gt;&gt; $GITHUB_OUTPUT\n\n  validate:\n    needs: prepare\n    runs-on: ubuntu-latest\n    outputs:\n      status: success\n\n    steps:\n      - name: Acc\u00e9der aux outputs de prepare\n        run: |\n          echo \"Configuration: ${{ needs.prepare.outputs.config }}\"\n\n  deploy:\n    needs: [ prepare, validate ]\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: V\u00e9rifier tous les pr\u00e9alables\n        run: |\n          echo \"Config: ${{ needs.prepare.outputs.config }}\"\n          echo \"Status: ${{ needs.validate.outputs.status }}\"\n\n      - name: D\u00e9ployer si tous les pr\u00e9alables sont OK\n        if: ${{ needs.validate.outputs.status == 'success' }}\n        run: echo \"D\u00e9ploiement autoris\u00e9\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#workflow-complet-avec-needs-outputs-et-contextes","title":"Workflow complet avec needs, outputs et contextes","text":"YAML<pre><code>name: Pipeline multi-job avec d\u00e9pendances\n\non:\n  push:\n    branches: [ main ]\n\njobs:\n  setup:\n    name: Configuration initiale\n    runs-on: ubuntu-latest\n    outputs:\n      build-version: ${{ steps.version.outputs.number }}\n      docker-registry: ${{ steps.registry.outputs.url }}\n      deploy-env: ${{ steps.env.outputs.name }}\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: G\u00e9n\u00e9rer la version\n        id: version\n        run: |\n          VERSION=\"v${{ github.run_number }}-${{ github.sha }}\"\n          echo \"number=$VERSION\" &gt;&gt; $GITHUB_OUTPUT\n          echo \"Version g\u00e9n\u00e9r\u00e9e: $VERSION\"\n\n      - name: D\u00e9terminer le registre Docker\n        id: registry\n        run: |\n          echo \"url=ghcr.io/${{ github.repository_owner }}\" &gt;&gt; $GITHUB_OUTPUT\n\n      - name: D\u00e9terminer l'environnement\n        id: env\n        run: echo \"name=production\" &gt;&gt; $GITHUB_OUTPUT\n\n  lint:\n    name: Linter le code\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: actions/setup-node@v3\n        with:\n          node-version: 18\n          cache: npm\n\n      - name: Installer les d\u00e9pendances\n        run: npm ci\n\n      - name: Ex\u00e9cuter le linter\n        run: npm run lint\n\n  test:\n    name: Ex\u00e9cuter les tests\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - uses: actions/setup-node@v3\n        with:\n          node-version: 18\n          cache: npm\n\n      - name: Installer les d\u00e9pendances\n        run: npm ci\n\n      - name: Ex\u00e9cuter les tests\n        run: npm test\n\n      - name: G\u00e9n\u00e9rer le rapport de couverture\n        id: coverage\n        run: |\n          COVERAGE=$(npm run coverage:report)\n          echo \"report=$COVERAGE\" &gt;&gt; $GITHUB_OUTPUT\n\n  build:\n    name: Construire l'image Docker\n    runs-on: ubuntu-latest\n    needs: [ lint, test ]\n    outputs:\n      image-id: ${{ steps.build.outputs.digest }}\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Construire l'image Docker\n        id: build\n        run: |\n          IMAGE_ID=\"sha256:${{ github.sha }}\"\n          echo \"digest=$IMAGE_ID\" &gt;&gt; $GITHUB_OUTPUT\n          echo \"Image construite: $IMAGE_ID\"\n\n  security-scan:\n    name: Scanner de s\u00e9curit\u00e9\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Scanner la s\u00e9curit\u00e9\n        run: |\n          echo \"Scanning image: ${{ needs.build.outputs.image-id }}\"\n          echo \"Scan de s\u00e9curit\u00e9 compl\u00e9t\u00e9\"\n\n  deploy:\n    name: D\u00e9ployer l'application\n    runs-on: ubuntu-latest\n    needs: [ setup, build, security-scan ]\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Afficher les informations de d\u00e9ploiement\n        run: |\n          echo \"=== INFORMATIONS DE D\u00c9PLOIEMENT ===\"\n          echo \"Version: ${{ needs.setup.outputs.build-version }}\"\n          echo \"Registre: ${{ needs.setup.outputs.docker-registry }}\"\n          echo \"Environnement: ${{ needs.setup.outputs.deploy-env }}\"\n          echo \"Image ID: ${{ needs.build.outputs.image-id }}\"\n\n      - name: Pr\u00e9parer le d\u00e9ploiement\n        env:\n          REGISTRY: ${{ needs.setup.outputs.docker-registry }}\n          VERSION: ${{ needs.setup.outputs.build-version }}\n          IMAGE_ID: ${{ needs.build.outputs.image-id }}\n        run: |\n          echo \"D\u00e9ploiement vers: $REGISTRY\"\n          echo \"Version: $VERSION\"\n          echo \"Image: $IMAGE_ID\"\n\n      - name: D\u00e9ployer en production\n        run: |\n          echo \"D\u00e9ploiement en cours...\"\n          echo \"Acteur: ${{ github.actor }}\"\n          echo \"Timestamp: ${{ github.event.head_commit.timestamp }}\"\n\n      - name: V\u00e9rifier le d\u00e9ploiement\n        if: ${{ success() }}\n        run: echo \"\u2705 D\u00e9ploiement compl\u00e9t\u00e9 avec succ\u00e8s\"\n\n  notify:\n    name: Notifier du r\u00e9sultat\n    runs-on: ubuntu-latest\n    needs: [ setup, deploy ]\n    if: ${{ always() }}\n\n    steps:\n      - name: Notifier le succ\u00e8s\n        if: ${{ needs.deploy.result == 'success' }}\n        run: |\n          echo \"\u2705 Pipeline compl\u00e9t\u00e9 avec succ\u00e8s\"\n          echo \"Version d\u00e9ploy\u00e9e: ${{ needs.setup.outputs.build-version }}\"\n\n      - name: Notifier l'\u00e9chec\n        if: ${{ needs.deploy.result == 'failure' }}\n        run: |\n          echo \"\u274c Le pipeline a \u00e9chou\u00e9\"\n          echo \"V\u00e9rifier les logs pour plus de d\u00e9tails\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#statuts-et-resultats-des-jobs","title":"Statuts et r\u00e9sultats des jobs","text":"<p>Les jobs fournissent des informations sur leur r\u00e9sultat d'ex\u00e9cution :</p> YAML<pre><code>deploy:\n  needs: build\n  if: ${{ needs.build.result == 'success' }}\n  steps:\n    - run: echo \"Le job build a r\u00e9ussi\"\n\ncleanup:\n  needs: [ build, test, deploy ]\n  if: ${{ always() }}  # S'ex\u00e9cute ind\u00e9pendamment du r\u00e9sultat des autres jobs\n  steps:\n    - run: echo \"Nettoyage des ressources\"\n\nnotify-failure:\n  needs: deploy\n  if: ${{ failure() }}  # S'ex\u00e9cute si le job pr\u00e9c\u00e9dent a \u00e9chou\u00e9\n  steps:\n    - run: echo \"Notifier de l'\u00e9chec du d\u00e9ploiement\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#synthese-et-progression-pedagogique","title":"Synth\u00e8se et progression p\u00e9dagogique","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap03/#chemin-dapprentissage-recommande","title":"Chemin d'apprentissage recommand\u00e9","text":"<p>La progression \u00e0 travers ces concepts fondamentaux suit une logique d'accumulation croissante :</p> <p>Phase 1 : Fondations (Actions et Checkout)</p> <p>L'apprentissage d\u00e9bute par la compr\u00e9hension des actions comme briques r\u00e9utilisables des workflows. La ma\u00eetrise de l'action <code>checkout</code> fournit les bases pratiques de l'interaction avec les d\u00e9p\u00f4ts Git. Cette phase \u00e9tablit la compr\u00e9hension des patterns fondamentaux de r\u00e9utilisabilit\u00e9.</p> <p>Phase 2 : Gestion des donn\u00e9es (Variables et Secrets)</p> <p>Apr\u00e8s avoir compris les actions, l'apprentissage porte sur la gestion des donn\u00e9es au sein des workflows. Les variables d'environnement et les secrets introduisent les concepts de s\u00e9curit\u00e9 et de flexibilit\u00e9 de configuration. Cette phase pr\u00e9pare \u00e0 la manipulation dynamique des donn\u00e9es.</p> <p>Phase 3 : Acc\u00e8s \u00e0 l'information (Contextes)</p> <p>Les contextes permettent d'acc\u00e9der \u00e0 l'information dynamique g\u00e9n\u00e9r\u00e9e pendant l'ex\u00e9cution. Cette phase transforme les connaissances abstraites en pratique concr\u00e8te d'acc\u00e8s aux m\u00e9tadonn\u00e9es du workflow.</p> <p>Phase 4 : Logique conditionnelle (Expressions et if)</p> <p>Les expressions et les conditions permettent de cr\u00e9er une logique conditionnelle sophistiqu\u00e9e. Cette phase transforme les workflows statiques en pipelines dynamiques capables de s'adapter \u00e0 diff\u00e9rents sc\u00e9narios.</p> <p>Phase 5 : Orchestration avanc\u00e9e (Needs, Outputs, Contextes)</p> <p>La derni\u00e8re phase couvre l'orchestration multi-job avec transmission de donn\u00e9es et d\u00e9pendances explicites. Cette ma\u00eetrise permet la cr\u00e9ation de pipelines complexes et modulaires.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap03/#interactions-entre-les-concepts","title":"Interactions entre les concepts","text":"<p>Ces concepts ne fonctionnent pas isol\u00e9ment mais forment un \u00e9cosyst\u00e8me coh\u00e9rent :</p> <ul> <li>Les actions utilisent des contextes pour acc\u00e9der aux informations dynamiques</li> <li>Les variables et secrets sont manipul\u00e9s via des expressions</li> <li>Les conditions s'appliquent aux jobs et aux steps via la propri\u00e9t\u00e9 if</li> <li>Les outputs combinent les contextes steps et needs pour la transmission de donn\u00e9es</li> <li>Les expressions \u00e9valuent les conditions bas\u00e9es sur les contextes et les variables</li> </ul> <p>Cette interconnexion cr\u00e9e une synergie qui permet de construire des pipelines CI/CD sophistiqu\u00e9s et adaptables \u00e0 des cas d'usage complexes.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/","title":"Citations","text":"<ul> <li>https://dev.to/cicube/understanding-working-directory-in-github-actions-234j</li> <li>https://docs.github.com/actions/writing-workflows/choosing-what-your-workflow-does/setting-a-default-shell-and-working-directory</li> <li>https://dev.to/jajera/understanding-github-actions-working-directory-550o</li> <li>https://github.com/orgs/community/discussions/38360</li> <li>https://github.com/orgs/community/discussions/40526</li> <li>https://docs.github.com/actions/using-workflows/workflow-syntax-for-github-actions</li> <li>https://docs.github.com/actions/writing-workflows/choosing-what-your-workflow-does/adding-scripts-to-your-workflow</li> <li>https://docs.github.com/en/actions/reference/workflows-and-actions/workflow-commands</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 272</li> <li>completion_tokens: 5307</li> <li>total_tokens: 5579</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.08, 'request_cost': 0.006, 'total_cost': 0.086}</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#content","title":"Content","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap04/#github-actions-declenchement-evenements-et-commandes-des-workflows","title":"\ud83d\ude80 GitHub Actions : D\u00e9clenchement, \u00c9v\u00e9nements et Commandes des Workflows","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap04/#introduction","title":"\ud83d\udccb Introduction","text":"<p>GitHub Actions permet d'automatiser les t\u00e2ches de d\u00e9veloppement directement dans les r\u00e9f\u00e9rentiels. Pour ma\u00eetriser cette plateforme, il est essentiel de comprendre comment les workflows sont d\u00e9clench\u00e9s, quels \u00e9v\u00e9nements peuvent les activer, et comment configurer pr\u00e9cis\u00e9ment l'ex\u00e9cution des commandes. Ce guide approfondit ces concepts fondamentaux.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#declenchement-des-workflows-en-detail","title":"\ud83c\udfaf D\u00e9clenchement des Workflows en D\u00e9tail","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap04/#comprendre-le-mecanisme-de-declenchement","title":"Comprendre le M\u00e9canisme de D\u00e9clenchement","text":"<p>Le d\u00e9clenchement d'un workflow repr\u00e9sente le moment exact o\u00f9 GitHub Actions commence l'ex\u00e9cution d'un processus automatis\u00e9. Cela se fait par le biais d'\u00e9v\u00e9nements sp\u00e9cifiques qui surviennent dans le r\u00e9f\u00e9rentiel ou dans l'environnement GitHub. Le syst\u00e8me de d\u00e9clenchement fonctionne selon une architecture \u00e9v\u00e9nementielle o\u00f9 chaque action dans le r\u00e9f\u00e9rentiel g\u00e9n\u00e8re un signal que GitHub Actions peut intercepter et utiliser pour d\u00e9clencher des workflows pr\u00e9configur\u00e9s.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#niveaux-de-declenchement","title":"Niveaux de D\u00e9clenchement","text":"<p>Les workflows peuvent \u00eatre d\u00e9clench\u00e9s \u00e0 plusieurs niveaux :</p> <p>Niveau du r\u00e9f\u00e9rentiel : Les \u00e9v\u00e9nements li\u00e9s directement aux actions sur le code (push, pull request, cr\u00e9ation de release).</p> <p>Niveau des probl\u00e8mes : Les \u00e9v\u00e9nements relatifs aux issues et discussions.</p> <p>Niveau des discussions : Les interactions dans les discussions du projet.</p> <p>Niveau des planifications : Les d\u00e9clenches selon un calendrier pr\u00e9d\u00e9fini.</p> <p>Niveau manuel : Les activations manuelles via l'interface ou l'API.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#configuration-du-declenchement","title":"Configuration du D\u00e9clenchement","text":"<p>La configuration du d\u00e9clenchement s'effectue dans le fichier YAML du workflow \u00e0 l'aide de la cl\u00e9 <code>on</code>. Cette cl\u00e9 accepte soit une cha\u00eene de caract\u00e8res pour un \u00e9v\u00e9nement simple, soit un objet pour des configurations plus complexes.</p> YAML<pre><code># Configuration simple\non: push\n\n# Configuration avec filtrage\non:\n  push:\n    branches:\n      - main\n      - develop\n    paths:\n      - 'src/**'\n      - 'package.json'\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#liste-complete-des-evenements","title":"\ud83d\udcda Liste Compl\u00e8te des \u00c9v\u00e9nements","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap04/#evenements-de-push-et-de-branche","title":"\u00c9v\u00e9nements de Push et de Branche","text":"<p>push : S'active lors d'un push vers le r\u00e9f\u00e9rentiel ou une branche. Permet de filtrer par branche, chemins de fichiers ou balises.</p> YAML<pre><code>on:\n  push:\n    branches:\n      - main\n      - 'release/**'\n    tags:\n      - 'v*'\n    paths:\n      - 'src/**'\n      - '!src/tests/**'\n</code></pre> <p>pull_request : S'active lors de la cr\u00e9ation ou de la modification d'une pull request. Les filtres incluent les branches cibles et les chemins.</p> YAML<pre><code>on:\n  pull_request:\n    types: [opened, synchronize, reopened]\n    branches:\n      - main\n    paths:\n      - 'src/**'\n      - 'docs/**'\n</code></pre> <p>branch_protection_rule : S'active lors de modifications des r\u00e8gles de protection de branche.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#evenements-de-publication-et-releases","title":"\u00c9v\u00e9nements de Publication et Releases","text":"<p>release : S'active lors de la cr\u00e9ation, publication ou modification d'une release.</p> YAML<pre><code>on:\n  release:\n    types: [published, created, edited]\n</code></pre> <p>push (avec tags) : Peut aussi \u00eatre configur\u00e9 pour r\u00e9agir uniquement aux pushes de balises.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#evenements-de-discussion-et-gestion-denjeux","title":"\u00c9v\u00e9nements de Discussion et Gestion d'Enjeux","text":"<p>issues : S'active lors de la cr\u00e9ation, modification ou suppression d'une issue.</p> YAML<pre><code>on:\n  issues:\n    types: [opened, edited, closed, labeled]\n</code></pre> <p>discussion : S'active lors de modifications dans les discussions.</p> <p>issue_comment : S'active lors de commentaires sur les issues.</p> YAML<pre><code>on:\n  issue_comment:\n    types: [created, edited, deleted]\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#evenements-de-programmation","title":"\u00c9v\u00e9nements de Programmation","text":"<p>schedule : S'active selon une planification cron. Peut avoir plusieurs planifications.</p> YAML<pre><code>on:\n  schedule:\n    - cron: '0 9 * * MON-FRI'  # 9h chaque jour ouvrable\n    - cron: '0 0 * * 0'        # Minuit chaque dimanche\n</code></pre> <p>workflow_dispatch : Permet le d\u00e9clenchement manuel depuis l'interface GitHub.</p> YAML<pre><code>on:\n  workflow_dispatch:\n    inputs:\n      environment:\n        description: 'Environment to deploy to'\n        required: true\n        default: 'staging'\n        type: choice\n        options:\n          - staging\n          - production\n      debug_enabled:\n        description: 'Run in debug mode'\n        required: false\n        type: boolean\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#evenements-de-modification-des-workflows","title":"\u00c9v\u00e9nements de Modification des Workflows","text":"<p>workflow_run : S'active lors de l'ex\u00e9cution d'un autre workflow. Utile pour les workflows d\u00e9pendants.</p> YAML<pre><code>on:\n  workflow_run:\n    workflows: ['CI']\n    types: [completed]\n    branches:\n      - main\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#evenements-de-forking-et-fetch","title":"\u00c9v\u00e9nements de Forking et Fetch","text":"<p>fork : S'active lors de la cr\u00e9ation d'un fork du r\u00e9f\u00e9rentiel.</p> <p>pull_request_target : Semblable \u00e0 <code>pull_request</code> mais s'ex\u00e9cute dans le contexte de la branche de base avec acc\u00e8s aux secrets. \u00c0 utiliser avec prudence pour les s\u00e9curit\u00e9.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#evenements-de-gestion-des-references","title":"\u00c9v\u00e9nements de Gestion des R\u00e9f\u00e9rences","text":"<p>workflow_call : Permet aux workflows d'\u00eatre appel\u00e9s par d'autres workflows (workflows r\u00e9utilisables).</p> YAML<pre><code>on:\n  workflow_call:\n    inputs:\n      version:\n        required: true\n        type: string\n    secrets:\n      NPM_TOKEN:\n        required: true\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#tableau-recapitulatif-des-evenements-principaux","title":"Tableau R\u00e9capitulatif des \u00c9v\u00e9nements Principaux","text":"\u00c9v\u00e9nement D\u00e9clenchement Cas d'Usage push Commit pouss\u00e9 vers le r\u00e9f\u00e9rentiel Tests apr\u00e8s chaque commit pull_request PR cr\u00e9\u00e9e ou mise \u00e0 jour V\u00e9rifications avant fusion schedule Selon planification cron T\u00e2ches p\u00e9riodiques, sauvegardes workflow_dispatch Activation manuelle D\u00e9ploiements contr\u00f4l\u00e9s release Release publi\u00e9e Distribution de versions issues Issue cr\u00e9\u00e9e/modifi\u00e9e Automatisation de triage workflow_call Appel\u00e9 par un autre workflow R\u00e9utilisation de workflows"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#commandes-de-workflow-et-workflow-commands","title":"\u2699\ufe0f Commandes de Workflow et Workflow Commands","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap04/#comprendre-les-workflow-commands","title":"Comprendre les Workflow Commands","text":"<p>Les commandes de workflow constituent un syst\u00e8me de communication entre les scripts en ex\u00e9cution et le runner GitHub Actions. Elles utilisent la syntaxe sp\u00e9ciale <code>::</code> pour transmettre des instructions \u00e0 GitHub Actions via la sortie standard (stdout).</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#syntaxe-generale","title":"Syntaxe G\u00e9n\u00e9rale","text":"Text Only<pre><code>::{command} {parameters}::{value}\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#definir-des-variables-denvironnement","title":"D\u00e9finir des Variables d'Environnement","text":"<p>La commande <code>set-env</code> permet de cr\u00e9er ou de modifier des variables d'environnement qui seront disponibles dans les \u00e9tapes suivantes.</p> YAML<pre><code>- name: Set environment variable\n  run: echo \"ACTION_REF=${{ github.ref }}\" &gt;&gt; $GITHUB_ENV\n\n- name: Use the variable\n  run: echo \"The ref is $ACTION_REF\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#ajouter-des-chemins-au-path","title":"Ajouter des Chemins au PATH","text":"<p>La commande <code>add-path</code> ajoute un r\u00e9pertoire au PATH du syst\u00e8me, rendant ses ex\u00e9cutables accessibles directement.</p> YAML<pre><code>- name: Add custom bin to PATH\n  run: echo \"/opt/custom/bin\" &gt;&gt; $GITHUB_PATH\n\n- name: Use custom executable\n  run: custom-command --help\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#definir-des-sorties-de-workflow","title":"D\u00e9finir des Sorties de Workflow","text":"<p>La commande <code>set-output</code> d\u00e9finit des sorties qui peuvent \u00eatre utilis\u00e9es par d'autres \u00e9tapes ou jobs.</p> YAML<pre><code>- name: Generate version\n  id: version\n  run: echo \"version=1.0.0\" &gt;&gt; $GITHUB_OUTPUT\n\n- name: Use output\n  run: echo \"Version is ${{ steps.version.outputs.version }}\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#signaler-des-erreurs-et-avertissements","title":"Signaler des Erreurs et Avertissements","text":"<p>error : Marque une erreur d'ex\u00e9cution.</p> YAML<pre><code>- name: Check configuration\n  run: |\n    if [ ! -f \"config.yml\" ]; then\n      echo \"::error::Configuration file not found\"\n      exit 1\n    fi\n</code></pre> <p>warning : Signale un avertissement sans arr\u00eater l'ex\u00e9cution.</p> YAML<pre><code>- name: Validate dependencies\n  run: |\n    if [ ! -z \"$DEPRECATED_VAR\" ]; then\n      echo \"::warning::DEPRECATED_VAR is deprecated, use NEW_VAR instead\"\n    fi\n</code></pre> <p>notice : Affiche une notification informative.</p> YAML<pre><code>- name: Build info\n  run: echo \"::notice::Build started at $(date)\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#grouper-les-sorties","title":"Grouper les Sorties","text":"<p>La commande <code>group</code> cr\u00e9e des sections repliables dans les logs pour am\u00e9liorer la lisibilit\u00e9.</p> YAML<pre><code>- name: Run tests\n  run: |\n    echo \"::group::Unit Tests\"\n    npm run test:unit\n    echo \"::endgroup::\"\n\n    echo \"::group::Integration Tests\"\n    npm run test:integration\n    echo \"::endgroup::\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#masquer-les-donnees-sensibles","title":"Masquer les Donn\u00e9es Sensibles","text":"<p>La commande <code>add-mask</code> cache les valeurs sensibles dans les logs.</p> YAML<pre><code>- name: Get secret and add to mask\n  run: |\n    SECRET_VALUE=$(aws secretsmanager get-secret-value --secret-id my-secret --query SecretString --output text)\n    echo \"::add-mask::${SECRET_VALUE}\"\n    echo \"SECRET=$SECRET_VALUE\" &gt;&gt; $GITHUB_ENV\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#controler-lexecution-du-job","title":"Contr\u00f4ler l'Ex\u00e9cution du Job","text":"<p>stop-commands et resume-commands : D\u00e9sactivent ou r\u00e9activent le traitement des commandes de workflow.</p> YAML<pre><code>- name: Disable workflow commands\n  run: |\n    echo \"::stop-commands::pause-token\"\n    echo \"::error::This error will be ignored\"\n    echo \"::resume-commands::pause-token\"\n    echo \"::error::This error will be processed\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#configuration-detaillee-run-shell-working-directory-et-defaults","title":"\ud83d\udd27 Configuration D\u00e9taill\u00e9e : run, shell, working-directory et defaults","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap04/#parametre-run-execution-de-commandes","title":"Param\u00e8tre <code>run</code> : Ex\u00e9cution de Commandes","text":"<p>Le param\u00e8tre <code>run</code> sp\u00e9cifie la commande ou le script \u00e0 ex\u00e9cuter dans une \u00e9tape. Il repr\u00e9sente le c\u0153ur de l'ex\u00e9cution des t\u00e2ches automatis\u00e9es.</p> <p>Commandes simples :</p> YAML<pre><code>steps:\n  - name: Run simple command\n    run: echo \"Hello, GitHub Actions!\"\n</code></pre> <p>Commandes multilignes :</p> YAML<pre><code>steps:\n  - name: Run multiple commands\n    run: |\n      npm install\n      npm run build\n      npm run test\n</code></pre> <p>Commandes avec conditions :</p> YAML<pre><code>steps:\n  - name: Conditional execution\n    run: |\n      if [ \"${{ github.event_name }}\" == \"push\" ]; then\n        echo \"This is a push event\"\n        npm run build\n      else\n        echo \"This is not a push event\"\n      fi\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#parametre-shell-choix-de-linterpreteur","title":"Param\u00e8tre <code>shell</code> : Choix de l'Interpr\u00e9teur","text":"<p>Le param\u00e8tre <code>shell</code> d\u00e9termine quel interpr\u00e9teur ex\u00e9cute la commande. Les options varient selon le syst\u00e8me d'exploitation du runner.</p> <p>Sur Linux et macOS :</p> <ul> <li><code>bash</code> (par d\u00e9faut)</li> <li><code>sh</code></li> <li><code>pwsh</code> (PowerShell)</li> </ul> <p>Sur Windows :</p> <ul> <li><code>pwsh</code> (PowerShell Core)</li> <li><code>cmd</code> (Command Prompt)</li> <li><code>bash</code> (si Git Bash est disponible)</li> </ul> YAML<pre><code>steps:\n  - name: Run with bash\n    shell: bash\n    run: echo \"Using bash\"\n\n  - name: Run with PowerShell\n    shell: pwsh\n    run: Write-Host \"Using PowerShell\"\n\n  - name: Run with cmd (Windows)\n    shell: cmd\n    run: echo Using Command Prompt\n</code></pre> <p>Options de shell avanc\u00e9es :</p> YAML<pre><code>steps:\n  - name: Run with custom shell options\n    shell: bash -e -o pipefail {0}\n    run: |\n      # Script with enhanced error handling\n      set -u\n      undefined_var  # Will cause error\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#parametre-working-directory-repertoire-dexecution","title":"Param\u00e8tre <code>working-directory</code> : R\u00e9pertoire d'Ex\u00e9cution","text":"<p>Le param\u00e8tre <code>working-directory</code> sp\u00e9cifie le r\u00e9pertoire dans lequel la commande s'ex\u00e9cute. Par d\u00e9faut, les commandes s'ex\u00e9cutent \u00e0 la racine du r\u00e9f\u00e9rentiel.[1]</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#configuration-au-niveau-de-letape","title":"Configuration au Niveau de l'\u00c9tape","text":"YAML<pre><code>steps:\n  - name: Run build in scripts directory\n    run: npm run build\n    working-directory: ./scripts\n</code></pre> <p>Ici, la commande <code>npm run build</code> s'ex\u00e9cute depuis le r\u00e9pertoire <code>./scripts</code> au lieu de la racine.[1]</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#configuration-au-niveau-du-job","title":"Configuration au Niveau du Job","text":"YAML<pre><code>jobs:\n  build:\n    runs-on: ubuntu-latest\n    defaults:\n      run:\n        shell: bash\n        working-directory: ./scripts\n    steps:\n      - name: Install dependencies\n        run: npm install\n      - name: Run tests\n        run: npm test\n</code></pre> <p>Tous les <code>run</code> steps dans ce job s'ex\u00e9cutent dans <code>./scripts</code>.[1][2]</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#configuration-au-niveau-du-workflow","title":"Configuration au Niveau du Workflow","text":"YAML<pre><code>defaults:\n  run:\n    shell: bash\n    working-directory: ./src\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Install dependencies\n        run: npm install\n      - name: Build project\n        run: npm run build\n</code></pre> <p>Tous les jobs du workflow ex\u00e9cutent leurs t\u00e2ches depuis <code>./src</code>.[1]</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#surcharge-de-la-configuration-au-niveau-de-letape","title":"Surcharge de la Configuration au Niveau de l'\u00c9tape","text":"YAML<pre><code>jobs:\n  deploy:\n    runs-on: ubuntu-latest\n    defaults:\n      run:\n        shell: bash\n        working-directory: ./scripts\n    steps:\n      - name: Install dependencies\n        run: npm install\n\n      - name: Run cleanup in different directory\n        run: rm -rf *\n        working-directory: ./temp\n</code></pre> <p>L'\u00e9tape de nettoyage surcharge le r\u00e9pertoire d\u00e9fini au niveau du job et s'ex\u00e9cute dans <code>./temp</code>.[1]</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#parametre-defaults-configurations-par-defaut","title":"Param\u00e8tre <code>defaults</code> : Configurations Par D\u00e9faut","text":"<p>Le param\u00e8tre <code>defaults</code> \u00e9tablit des configurations par d\u00e9faut applicables \u00e0 plusieurs niveaux hi\u00e9rarchiques du workflow.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#hierarchie-des-defaults","title":"Hi\u00e9rarchie des Defaults","text":"<ol> <li>Niveau workflow : S'applique \u00e0 tous les jobs</li> <li>Niveau job : S'applique \u00e0 toutes les \u00e9tapes d'un job (surcharge le level workflow)</li> <li>Niveau \u00e9tape : S'applique uniquement \u00e0 une \u00e9tape (surcharge les niveaux pr\u00e9c\u00e9dents)</li> </ol>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#exemple-complet-de-hierarchie","title":"Exemple Complet de Hi\u00e9rarchie","text":"YAML<pre><code>name: Workflow with Multiple Defaults\n\ndefaults:\n  run:\n    shell: bash\n    working-directory: ./root-dir\n\non: push\n\njobs:\n  job1:\n    runs-on: ubuntu-latest\n    # H\u00e9rite du workflow level\n    steps:\n      - name: Step in job1\n        run: pwd  # S'ex\u00e9cute dans ./root-dir\n\n  job2:\n    runs-on: ubuntu-latest\n    defaults:\n      run:\n        shell: pwsh\n        working-directory: ./job2-dir\n    # Surcharge le workflow level\n    steps:\n      - name: Step in job2\n        run: Get-Location  # S'ex\u00e9cute dans ./job2-dir avec PowerShell\n\n      - name: Override at step level\n        run: pwd\n        working-directory: ./override-dir\n        shell: bash  # S'ex\u00e9cute dans ./override-dir avec bash\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#resolution-de-priorite","title":"R\u00e9solution de Priorit\u00e9","text":"<p>Lorsque plusieurs defaults sont d\u00e9finis avec le m\u00eame nom, GitHub utilise le param\u00e8tre le plus sp\u00e9cifique.[2]</p> Niveau Priorit\u00e9 Port\u00e9e \u00c9tape 1 (Plus haute) \u00c9tape unique Job 2 Toutes les \u00e9tapes du job Workflow 3 (Plus basse) Tous les jobs"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#utilisation-pratique-des-defaults","title":"Utilisation Pratique des Defaults","text":"YAML<pre><code>name: Node.js Project Build\n\ndefaults:\n  run:\n    shell: bash\n    working-directory: ./app\n\non:\n  push:\n    branches: [main, develop]\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Install linter\n        run: npm install eslint\n      - name: Run linter\n        run: npm run lint\n\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - name: Install dependencies\n        run: npm install\n      - name: Run tests\n        run: npm test\n\n  build:\n    runs-on: ubuntu-latest\n    defaults:\n      run:\n        working-directory: ./app/dist\n    steps:\n      - uses: actions/checkout@v4\n      - name: Prepare build directory\n        working-directory: ./app\n        run: npm run build\n      - name: Verify output\n        run: ls -la\n        # S'ex\u00e9cute dans ./app/dist pour v\u00e9rifier les fichiers g\u00e9n\u00e9r\u00e9s\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#tableau-comparatif-des-niveaux-de-configuration","title":"Tableau Comparatif des Niveaux de Configuration","text":"Aspect \u00c9tape Job Workflow Syntaxe <code>run: cmd</code> / <code>shell: bash</code> <code>defaults.run</code> <code>defaults.run</code> Port\u00e9e 1 \u00e9tape unique Toutes les \u00e9tapes du job Tous les jobs Priorit\u00e9 \u2b50\u2b50\u2b50 Haute \u2b50\u2b50 Moyenne \u2b50 Basse Cas d'usage Exception, override Coh\u00e9rence intra-job Coh\u00e9rence globale Surcharge Oui, de tout Oui, du workflow Non"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#integration-complete-exemple-pratique","title":"\ud83d\udd04 Int\u00e9gration Compl\u00e8te : Exemple Pratique","text":"<p>Voici un workflow complet int\u00e9grant tous les concepts :</p> YAML<pre><code>name: Complete CI/CD Pipeline\n\non:\n  push:\n    branches: [main, develop]\n    paths:\n      - 'src/**'\n      - 'package.json'\n      - '.github/workflows/**'\n  pull_request:\n    branches: [main]\n  schedule:\n    - cron: '0 0 * * 0'\n  workflow_dispatch:\n    inputs:\n      environment:\n        description: 'Target environment'\n        required: true\n        type: choice\n        options: [staging, production]\n\ndefaults:\n  run:\n    shell: bash\n    working-directory: ./application\n\nenv:\n  NODE_VERSION: '18'\n\njobs:\n  validate:\n    name: Code Validation\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run linter\n        run: npm run lint\n        continue-on-error: true\n\n      - name: Log validation status\n        run: |\n          echo \"::notice::Validation completed\"\n          echo \"Timestamp: $(date)\" &gt;&gt; $GITHUB_ENV\n\n  test:\n    name: Run Tests\n    runs-on: ubuntu-latest\n    needs: validate\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run unit tests\n        run: |\n          echo \"::group::Unit Tests Execution\"\n          npm run test:unit\n          echo \"::endgroup::\"\n\n      - name: Run integration tests\n        run: |\n          echo \"::group::Integration Tests Execution\"\n          npm run test:integration\n          echo \"::endgroup::\"\n\n      - name: Generate coverage\n        run: npm run test:coverage\n        working-directory: ./coverage  # Override du default\n        continue-on-error: true\n\n  build:\n    name: Build Application\n    runs-on: ubuntu-latest\n    needs: validate\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n\n      - name: Build application\n        run: npm run build\n\n      - name: Verify build output\n        run: |\n          if [ ! -d \"dist\" ]; then\n            echo \"::error::Build failed - dist directory not found\"\n            exit 1\n          fi\n          echo \"::notice::Build artifacts created successfully\"\n\n  deploy:\n    name: Deploy\n    runs-on: ubuntu-latest\n    needs: [test, build]\n    if: github.ref == 'refs/heads/main' || github.event_name == 'workflow_dispatch'\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Determine target environment\n        id: env\n        run: |\n          if [ \"${{ github.event_name }}\" == \"workflow_dispatch\" ]; then\n            ENV=\"${{ github.event.inputs.environment }}\"\n          else\n            ENV=\"staging\"\n          fi\n          echo \"target=$ENV\" &gt;&gt; $GITHUB_OUTPUT\n\n      - name: Deploy to ${{ steps.env.outputs.target }}\n        run: |\n          echo \"Deploying to ${{ steps.env.outputs.target }}\"\n          npm run deploy -- --env=${{ steps.env.outputs.target }}\n\n      - name: Verify deployment\n        run: curl -f https://app-${{ steps.env.outputs.target }}.example.com/health || exit 1\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#synthese-et-progression-dapprentissage","title":"\ud83d\udcca Synth\u00e8se et Progression d'Apprentissage","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap04/#chemin-dapprentissage-structure","title":"Chemin d'Apprentissage Structur\u00e9","text":"<p>\u00c9tape 1 : Fondamentaux des D\u00e9clencheurs (30 minutes) - Comprendre l'architecture \u00e9v\u00e9nementielle - Ma\u00eetriser les \u00e9v\u00e9nements simples (push, pull_request) - Exp\u00e9rimenter les configurations basiques</p> <p>\u00c9tape 2 : \u00c9v\u00e9nements Avanc\u00e9s (1 heure) - Explorer les filtres (branches, paths, tags) - Utiliser les \u00e9v\u00e9nements conditionnels - Cha\u00eener les workflows avec workflow_run</p> <p>\u00c9tape 3 : Commandes de Workflow (45 minutes) - Ma\u00eetriser les variables d'environnement - Impl\u00e9menter la gestion des erreurs - Utiliser les sorties et les regroupements</p> <p>\u00c9tape 4 : Ex\u00e9cution Pr\u00e9cise (1 heure) - Configurer les r\u00e9pertoires de travail - G\u00e9rer les interpr\u00e9teurs shell - \u00c9tablir les configurations par d\u00e9faut</p> <p>\u00c9tape 5 : Int\u00e9gration Compl\u00e8te (1-2 heures) - Construire des workflows multi-jobs - G\u00e9rer les d\u00e9pendances entre jobs - Optimiser la r\u00e9utilisabilit\u00e9</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap04/#points-cles-a-retenir","title":"Points Cl\u00e9s \u00e0 Retenir","text":"<p>L'architecture de GitHub Actions repose sur une hi\u00e9rarchie claire : les \u00e9v\u00e9nements d\u00e9clenchent les workflows, qui contiennent des jobs, qui contiennent des \u00e9tapes. Chaque niveau accepte des configurations que les niveaux inf\u00e9rieurs peuvent surcharger. Les commandes de workflow permettent une communication dynamique entre les scripts et le syst\u00e8me, tandis que les configurations de r\u00e9pertoire et de shell offrent une flexibilit\u00e9 d'ex\u00e9cution.</p> <p>La ma\u00eetrise progressive de ces concepts permet de passer de workflows simples \u00e0 des pipelines sophistiqu\u00e9s de CI/CD, tout en maintenant la clart\u00e9 et la maintenabilit\u00e9 du code d'automatisation.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/","title":"Citations","text":"<ul> <li>https://dev.to/tejastn10/mastering-github-actions-strategy-matrix-deploy-smarter-not-harder-28po</li> <li>https://codefresh.io/learn/github-actions/github-actions-matrix/</li> <li>https://www.blacksmith.sh/blog/matrix-builds-with-github-actions</li> <li>https://www.youtube.com/watch?v=FSQDtRMtSHo</li> <li>https://www.edwardthomson.com/blog/github_actions_6_fail_fast_matrix_workflows.html</li> <li>https://docs.github.com/actions/writing-workflows/choosing-what-your-workflow-does/running-variations-of-jobs-in-a-workflow</li> <li>https://github.com/orgs/community/discussions/45546</li> <li>https://docs.github.com/actions/using-workflows/workflow-syntax-for-github-actions</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 272</li> <li>completion_tokens: 8565</li> <li>total_tokens: 8837</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.128, 'request_cost': 0.006, 'total_cost': 0.135}</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#content","title":"Content","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap05/#chapitre-5-github-actions-executions-optimisations-et-permissions-des-workflows","title":"Chapitre 5 : GitHub Actions - Ex\u00e9cutions, Optimisations et Permissions des Workflows","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap05/#introduction","title":"\ud83c\udfaf Introduction","text":"<p>Ce chapitre approfondit les aspects techniques essentiels pour ma\u00eetriser GitHub Actions en production. Il couvre l'optimisation des workflows \u00e0 travers la gestion des caches et des matrices, la s\u00e9curisation via les permissions, et la structuration des d\u00e9ploiements avec les environnements et la gestion de la concurrence.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#1-gestion-des-caches","title":"1\ufe0f\u20e3 Gestion des Caches","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap05/#concept-fondamental","title":"Concept Fondamental","text":"<p>La gestion des caches dans GitHub Actions repr\u00e9sente une strat\u00e9gie d'optimisation critique pour r\u00e9duire les temps d'ex\u00e9cution des workflows. Le cache stocke les fichiers fr\u00e9quemment utilis\u00e9s entre les ex\u00e9cutions, \u00e9liminant le besoin de t\u00e9l\u00e9charger ou reconstruire les m\u00eames ressources \u00e0 chaque lancement.[1]</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#principes-de-base","title":"Principes de Base","text":"<p>Le cache fonctionne selon un syst\u00e8me cl\u00e9-valeur. Lors d'une premi\u00e8re ex\u00e9cution, les fichiers sp\u00e9cifi\u00e9s sont compress\u00e9s et stock\u00e9s. Lors des ex\u00e9cutions ult\u00e9rieures, si la cl\u00e9 de cache correspond, les fichiers sont restaur\u00e9s directement sans traitement suppl\u00e9mentaire.</p> <p>Points cl\u00e9s \u00e0 retenir :</p> <ul> <li>Les caches sont sp\u00e9cifiques au d\u00e9p\u00f4t et \u00e0 la branche</li> <li>Chaque cache dispose d'une capacit\u00e9 de stockage limit\u00e9e</li> <li>Un cache inutilis\u00e9 pendant 7 jours est automatiquement supprim\u00e9</li> <li>L'acc\u00e8s aux caches respecte les limites de s\u00e9curit\u00e9 entre branches</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#implementation-pratique","title":"Impl\u00e9mentation Pratique","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap05/#configuration-basique","title":"Configuration Basique","text":"YAML<pre><code>name: Node.js Caching Example\non:\n  push:\n    branches: [main]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '18'\n          cache: 'npm'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Build\n        run: npm run build\n</code></pre> <p>Dans cette configuration, l'action <code>setup-node</code> g\u00e8re automatiquement le cache des d\u00e9pendances npm. La premi\u00e8re ex\u00e9cution t\u00e9l\u00e9charge et installe les paquets, tandis que les ex\u00e9cutions suivantes r\u00e9utilisent le cache si le fichier <code>package-lock.json</code> n'a pas chang\u00e9.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#cache-personnalise-avance","title":"Cache Personnalis\u00e9 Avanc\u00e9","text":"YAML<pre><code>name: Advanced Caching Strategy\non:\n  push:\n    branches: [main, develop]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        os: [ubuntu-latest, windows-latest]\n        node-version: [16, 18, 20]\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n\n      - name: Cache dependencies with OS-specific key\n        uses: actions/cache@v3\n        with:\n          path: ~/.npm\n          key: ${{ runner.os }}-node-${{ matrix.node-version }}-${{ hashFiles('**/package-lock.json') }}\n          restore-keys: |\n            ${{ runner.os }}-node-${{ matrix.node-version }}-\n            ${{ runner.os }}-node-\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run tests\n        run: npm test\n</code></pre> <p>Cet exemple d\u00e9montre une strat\u00e9gie avanc\u00e9e o\u00f9 le cache est segment\u00e9 par syst\u00e8me d'exploitation et version de Node.js. Les cl\u00e9s de restauration en cascade permettent une r\u00e9cup\u00e9ration partielle du cache si une correspondance exacte n'existe pas.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#optimisation-multi-environnements","title":"Optimisation Multi-Environnements","text":"YAML<pre><code>name: Multi-Environment Caching\non:\n  push:\n\njobs:\n  build:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        python-version: ['3.9', '3.10', '3.11']\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Set up Python\n        uses: actions/setup-python@v4\n        with:\n          python-version: ${{ matrix.python-version }}\n          cache: 'pip'\n\n      - name: Cache pip packages\n        uses: actions/cache@v3\n        with:\n          path: |\n            ~/.cache/pip\n            ~/Library/Caches/pip\n            ~\\AppData\\Local\\pip\\Cache\n          key: ${{ runner.os }}-pip-${{ matrix.python-version }}-${{ hashFiles('**/requirements.txt') }}\n          restore-keys: |\n            ${{ runner.os }}-pip-${{ matrix.python-version }}-\n            ${{ runner.os }}-pip-\n\n      - name: Install dependencies\n        run: pip install -r requirements.txt\n\n      - name: Run tests\n        run: pytest\n</code></pre> <p>Cette configuration g\u00e8re les caches de mani\u00e8re intelligente sur diff\u00e9rentes architectures (Windows, macOS, Linux), tenant compte des chemins de cache sp\u00e9cifiques \u00e0 chaque syst\u00e8me d'exploitation.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#strategies-de-nettoyage-et-maintenance","title":"Strat\u00e9gies de Nettoyage et Maintenance","text":"YAML<pre><code>name: Cache Maintenance\non:\n  schedule:\n    - cron: '0 0 * * 0'  # Weekly cleanup\n\njobs:\n  cleanup:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: List all caches\n        run: |\n          gh actions-cache list -R ${{ github.repository }} --sort created-at --order desc\n        env:\n          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Delete old caches\n        run: |\n          gh actions-cache delete-all -R ${{ github.repository }} --branch ${{ github.ref_name }}\n        env:\n          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#2-matrices-fail-fast-et-strategies-de-build","title":"2\ufe0f\u20e3 Matrices, Fail-Fast et Strat\u00e9gies de Build","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap05/#concept-de-matrice","title":"Concept de Matrice","text":"<p>La strat\u00e9gie de matrice dans GitHub Actions permet d'ex\u00e9cuter automatiquement plusieurs variations d'un job avec diff\u00e9rentes configurations. Plut\u00f4t que de cr\u00e9er manuellement plusieurs jobs similaires, une matrice g\u00e9n\u00e8re dynamiquement ces variations \u00e0 partir de combinaisons de variables.[1][2]</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#utilite-pratique","title":"Utilit\u00e9 Pratique","text":"<p>La matrice s'av\u00e8re particuli\u00e8rement utile pour :</p> <ul> <li>Tester sur plusieurs syst\u00e8mes d'exploitation : v\u00e9rifier la compatibilit\u00e9 sur Ubuntu, macOS et Windows</li> <li>V\u00e9rifier plusieurs versions de runtime : tester un projet Node.js sur les versions 16, 18 et 20</li> <li>D\u00e9ployer plusieurs services : lancer simultan\u00e9ment le d\u00e9ploiement de plusieurs microservices</li> <li>Tests multi-navigateurs : valider le code dans diff\u00e9rents navigateurs et versions</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#structure-basique-dune-matrice","title":"Structure Basique d'une Matrice","text":"YAML<pre><code>name: Matrix Test Strategy\non:\n  push:\n    branches: [main]\n\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        node-version: [16, 18, 20]\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run tests\n        run: npm test\n</code></pre> <p>Cette matrice g\u00e9n\u00e8re 9 jobs (3 syst\u00e8mes d'exploitation \u00d7 3 versions de Node.js), tous ex\u00e9cut\u00e9s en parall\u00e8le.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#cas-dusage-reel-deploiement-multi-services","title":"Cas d'Usage R\u00e9el : D\u00e9ploiement Multi-Services","text":"YAML<pre><code>name: Release all services\non:\n  push:\n    branches:\n      - master\n\njobs:\n  deploy:\n    strategy:\n      matrix:\n        service: [\"proctor\", \"screenshot\", \"stitch\", \"canvas-snap\", \"canvas-fuse\"]\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v4\n\n      - name: Build Docker image for ${{ matrix.service }}\n        run: docker build -t ${{ matrix.service }}:latest ./services/${{ matrix.service }}\n\n      - name: Deploy ${{ matrix.service }}\n        run: |\n          echo \"Deploying ${{ matrix.service }} to production\"\n          docker push ${{ matrix.service }}:latest\n</code></pre> <p>Avec cette configuration, chaque service est construit et d\u00e9ploy\u00e9 dans un job s\u00e9par\u00e9, maximisant le parall\u00e9lisme et r\u00e9duisant le temps global d'ex\u00e9cution.[1]</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#comportement-fail-fast","title":"Comportement Fail-Fast","text":"<p>Le fail-fast repr\u00e9sente un m\u00e9canisme de s\u00e9curit\u00e9 et d'efficacit\u00e9 dans les matrices. Par d\u00e9faut, ce comportement est activ\u00e9.[2][3]</p> <p>Avec fail-fast activ\u00e9 (comportement par d\u00e9faut) :</p> <p>Si l'un des 9 jobs \u00e9choue, GitHub Actions annule imm\u00e9diatement tous les jobs en attente. Cela \u00e9conomise les ressources de calcul et \u00e9vite de gaspiller du temps sur des ex\u00e9cutions destin\u00e9es \u00e0 \u00e9chouer pour la m\u00eame raison.</p> <p>Avec fail-fast d\u00e9sactiv\u00e9 :</p> <p>Tous les jobs s'ex\u00e9cutent jusqu'\u00e0 leur completion, m\u00eame si certains \u00e9chouent. Cette approche s'av\u00e8re utile pour : - Collecter des informations de d\u00e9bogage compl\u00e8tes - Identifier si le probl\u00e8me est isol\u00e9 ou syst\u00e9matique - G\u00e9n\u00e9rer des rapports complets de compatibilit\u00e9</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#configuration-du-fail-fast","title":"Configuration du Fail-Fast","text":"YAML<pre><code>name: Fail-Fast Control Example\non:\n  push:\n    branches: [main]\n\njobs:\n  comprehensive-test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      fail-fast: false\n      matrix:\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        node-version: [14, 16, 18, 20]\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run comprehensive tests\n        run: npm test -- --verbose\n</code></pre> <p>Ici, <code>fail-fast: false</code> garantit que tous les 12 jobs (3 OS \u00d7 4 versions de Node) s'ex\u00e9cutent compl\u00e8tement, m\u00eame en cas d'\u00e9chec.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#limitation-du-parallelisme","title":"Limitation du Parall\u00e9lisme","text":"<p>Pour \u00e9viter de surcharger l'infrastructure ou les limites de quota, il est possible de contr\u00f4ler le nombre de jobs parall\u00e8les :</p> YAML<pre><code>name: Limited Parallel Execution\non:\n  push:\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    strategy:\n      max-parallel: 2\n      matrix:\n        database: [postgres, mysql, mongodb, redis]\n        cache: [memcached, redis]\n\n    steps:\n      - uses: actions/checkout@v4\n      - name: Test with ${{ matrix.database }} and ${{ matrix.cache }}\n        run: npm test\n</code></pre> <p>Avec <code>max-parallel: 2</code>, m\u00eame si la matrice g\u00e9n\u00e8re 8 combinaisons, seuls 2 jobs s'ex\u00e9cutent simultan\u00e9ment.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#inclusion-et-exclusion-selective","title":"Inclusion et Exclusion S\u00e9lective","text":"<p>Les matrices peuvent \u00eatre affin\u00e9es avec des r\u00e8gles d'inclusion et d'exclusion :</p> YAML<pre><code>name: Selective Matrix Execution\non:\n  push:\n\njobs:\n  test:\n    runs-on: ${{ matrix.os }}\n    strategy:\n      matrix:\n        os: [ubuntu-latest, macos-latest, windows-latest]\n        node-version: [16, 18, 20]\n        exclude:\n          - os: macos-latest\n            node-version: 16\n          - os: windows-latest\n            node-version: 20\n        include:\n          - os: ubuntu-latest\n            node-version: 21\n            experimental: true\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n\n      - name: Run tests\n        run: npm test\n        continue-on-error: ${{ matrix.experimental || false }}\n</code></pre> <p>Cette configuration : - Exclut certaines combinaisons incompatibles ou non pertinentes - Ajoute une version exp\u00e9rimentale de Node.js - Continue l'ex\u00e9cution m\u00eame si la version exp\u00e9rimentale \u00e9choue</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#gestion-avancee-des-erreurs","title":"Gestion Avanc\u00e9e des Erreurs","text":"YAML<pre><code>name: Advanced Error Handling\non:\n  push:\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      fail-fast: true\n      matrix:\n        version: [9, 10, 11]\n        experimental: [false]\n        include:\n          - version: 12\n            experimental: true\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.version }}\n\n      - name: Run tests\n        run: npm test\n        continue-on-error: ${{ matrix.experimental }}\n\n      - name: Post results\n        if: always()\n        run: echo \"Test completed for version ${{ matrix.version }}\"\n</code></pre> <p>Les jobs avec <code>experimental: false</code> respectent le fail-fast, tandis que ceux avec <code>experimental: true</code> s'ex\u00e9cutent sans bloquer les autres.[2]</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#table-comparative-strategies-de-build","title":"Table Comparative : Strat\u00e9gies de Build","text":"Strat\u00e9gie Fail-Fast Max-Parallel Cas d'Usage Rapide (Production) true D\u00e9faut Validation rapide avant merge Exhaustive (Debugging) false D\u00e9faut Identification compl\u00e8te des probl\u00e8mes \u00c9conome (Ressources) false 2-3 Environnements avec quota limit\u00e9 Exp\u00e9rimentale false D\u00e9faut Tests de nouvelles configurations"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#3-les-permissions","title":"3\ufe0f\u20e3 Les Permissions","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap05/#importance-de-la-securite","title":"Importance de la S\u00e9curit\u00e9","text":"<p>Les permissions dans GitHub Actions contr\u00f4lent le niveau d'acc\u00e8s des workflows aux ressources du d\u00e9p\u00f4t et aux services externes. Une gestion rigoureuse des permissions suit le principe du moindre privil\u00e8ge, accordant uniquement les droits n\u00e9cessaires pour l'ex\u00e9cution.[4]</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#portee-des-permissions","title":"Port\u00e9e des Permissions","text":"<p>Les permissions s'appliquent \u00e0 plusieurs niveaux :</p> <ul> <li>Au niveau du workflow : d\u00e9fini dans <code>permissions:</code> au sommet du fichier YAML</li> <li>Au niveau du job : sp\u00e9cifique \u00e0 chaque job</li> <li>Au niveau global : param\u00e8tres par d\u00e9faut du d\u00e9p\u00f4t</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#configuration-basique_1","title":"Configuration Basique","text":"YAML<pre><code>name: Secure Workflow\non:\n  push:\n    branches: [main]\n\npermissions:\n  contents: read\n  packages: read\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      pull-requests: read\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Build application\n        run: npm run build\n</code></pre> <p>La configuration <code>permissions: contents: read</code> signifie que le workflow peut lire le contenu du d\u00e9p\u00f4t mais ne peut pas le modifier.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#permissions-granulaires","title":"Permissions Granulaires","text":"<p>GitHub Actions propose des permissions sp\u00e9cifiques pour diff\u00e9rentes ressources :</p> Permission Description <code>contents</code> Acc\u00e8s aux fichiers du d\u00e9p\u00f4t (read/write) <code>pull-requests</code> Modification des pull requests (read/write) <code>issues</code> Gestion des issues (read/write) <code>packages</code> Acc\u00e8s aux packages (read/write) <code>deployments</code> Gestion des d\u00e9ploiements (read/write) <code>statuses</code> Modification du statut des commits (write) <code>checks</code> Lecture des r\u00e9sultats de v\u00e9rification (read) <code>actions</code> Gestion des workflows GitHub Actions (read/write)"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#workflow-avec-permissions-completes","title":"Workflow avec Permissions Compl\u00e8tes","text":"YAML<pre><code>name: Full-Featured Workflow\non:\n  pull_request:\n    types: [opened, synchronize]\n\npermissions:\n  contents: read\n  pull-requests: write\n  issues: write\n  statuses: write\n  checks: read\n\njobs:\n  analyze-and-comment:\n    runs-on: ubuntu-latest\n    permissions:\n      pull-requests: write\n      contents: read\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run analysis\n        id: analysis\n        run: |\n          # Code analysis\n          echo \"quality_score=95\" &gt;&gt; $GITHUB_OUTPUT\n\n      - name: Comment on PR\n        if: github.event_name == 'pull_request'\n        uses: actions/github-script@v7\n        with:\n          script: |\n            github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: '\u2705 Quality score: ${{ steps.analysis.outputs.quality_score }}/100'\n            })\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#bonnes-pratiques-de-securite","title":"Bonnes Pratiques de S\u00e9curit\u00e9","text":"YAML<pre><code>name: Security-First Workflow\non:\n  push:\n    branches: [main]\n\npermissions:\n  contents: read\n\njobs:\n  # Job 1 : Lecture seule\n  security-scan:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      security-events: write\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Run security scanner\n        run: npm audit --audit-level=moderate\n\n  # Job 2 : Restriction maximum\n  build:\n    runs-on: ubuntu-latest\n    permissions: {}\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Build\n        run: npm run build\n\n  # Job 3 : Permissions sp\u00e9cifiques uniquement si n\u00e9cessaire\n  deploy:\n    runs-on: ubuntu-latest\n    needs: [security-scan, build]\n    permissions:\n      contents: read\n      deployments: write\n    if: github.ref == 'refs/heads/main'\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Deploy to production\n        run: echo \"Deploying with limited permissions\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#utilisation-de-tokens-personnalises","title":"Utilisation de Tokens Personnalis\u00e9s","text":"<p>Pour des besoins sp\u00e9cifiques, les tokens personnalis\u00e9s avec permissions restreintes am\u00e9liorent la s\u00e9curit\u00e9 :</p> YAML<pre><code>name: Custom Token Workflow\non:\n  push:\n    branches: [main]\n\npermissions:\n  contents: read\n\njobs:\n  publish:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '18'\n          registry-url: 'https://npm.pkg.github.com'\n\n      - name: Install and publish\n        run: |\n          npm ci\n          npm publish\n        env:\n          NODE_AUTH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#4-environnements-et-deploiements","title":"4\ufe0f\u20e3 Environnements et D\u00e9ploiements","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap05/#concept-denvironnement","title":"Concept d'Environnement","text":"<p>Les environnements dans GitHub Actions fournissent un m\u00e9canisme structur\u00e9 pour d\u00e9ployer du code dans diff\u00e9rents contextes (d\u00e9veloppement, staging, production) avec des configurations, des secrets et des approbations sp\u00e9cifiques.[4]</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#architecture-des-environnements","title":"Architecture des Environnements","text":"Text Only<pre><code>\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502         GitHub Actions Workflow         \u2502\n\u251c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2524\n\u2502                                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Environment: Development        \u2502  \u2502\n\u2502  \u2502  - Variables: DEV_API_URL        \u2502  \u2502\n\u2502  \u2502  - Secrets: DEV_API_KEY          \u2502  \u2502\n\u2502  \u2502  - Reviewers: None               \u2502  \u2502\n\u2502  \u2502  - Deployment Branch: any        \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Environment: Staging            \u2502  \u2502\n\u2502  \u2502  - Variables: STAGING_API_URL    \u2502  \u2502\n\u2502  \u2502  - Secrets: STAGING_API_KEY      \u2502  \u2502\n\u2502  \u2502  - Reviewers: senior-dev         \u2502  \u2502\n\u2502  \u2502  - Deployment Branch: main only  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                         \u2502\n\u2502  \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510  \u2502\n\u2502  \u2502  Environment: Production         \u2502  \u2502\n\u2502  \u2502  - Variables: PROD_API_URL       \u2502  \u2502\n\u2502  \u2502  - Secrets: PROD_API_KEY         \u2502  \u2502\n\u2502  \u2502  - Reviewers: tech-lead, manager \u2502  \u2502\n\u2502  \u2502  - Deployment Branch: main only  \u2502  \u2502\n\u2502  \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518  \u2502\n\u2502                                         \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#configuration-des-environnements","title":"Configuration des Environnements","text":"YAML<pre><code>name: Multi-Environment Deployment\non:\n  push:\n    branches:\n      - develop\n      - main\n      - production\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '18'\n\n      - name: Run tests\n        run: npm test\n\n  deploy-dev:\n    runs-on: ubuntu-latest\n    needs: test\n    environment:\n      name: Development\n      url: https://dev.example.com\n    if: github.ref == 'refs/heads/develop'\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Deploy to Development\n        run: |\n          echo \"Deploying to ${{ vars.DEV_API_URL }}\"\n          npm run deploy:dev\n        env:\n          API_URL: ${{ vars.DEV_API_URL }}\n          API_KEY: ${{ secrets.DEV_API_KEY }}\n\n  deploy-staging:\n    runs-on: ubuntu-latest\n    needs: test\n    environment:\n      name: Staging\n      url: https://staging.example.com\n    if: github.ref == 'refs/heads/main'\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Deploy to Staging\n        run: npm run deploy:staging\n        env:\n          API_URL: ${{ vars.STAGING_API_URL }}\n          API_KEY: ${{ secrets.STAGING_API_KEY }}\n\n  deploy-prod:\n    runs-on: ubuntu-latest\n    needs: test\n    environment:\n      name: Production\n      url: https://example.com\n    if: github.ref == 'refs/heads/production'\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Deploy to Production\n        run: npm run deploy:prod\n        env:\n          API_URL: ${{ vars.PROD_API_URL }}\n          API_KEY: ${{ secrets.PROD_API_KEY }}\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#approbations-et-revisions","title":"Approbations et R\u00e9visions","text":"<p>Les environnements peuvent exiger une approbation avant l'ex\u00e9cution :</p> YAML<pre><code>name: Deployment with Approvals\non:\n  push:\n    tags:\n      - 'v*'\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n      - name: Build\n        run: npm run build\n\n  production-deployment:\n    runs-on: ubuntu-latest\n    needs: build\n    environment:\n      name: Production\n      url: https://example.com\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Deploy to Production\n        run: |\n          echo \"Production deployment started\"\n          npm run deploy:prod\n\n      - name: Notify deployment\n        uses: actions/github-script@v7\n        with:\n          script: |\n            github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: '\ud83d\ude80 Deployment to Production completed!'\n            })\n</code></pre> <p>Lors de la configuration de l'environnement dans l'interface GitHub, les administrateurs sp\u00e9cifient les reviewers requis. Le workflow pause avant le job <code>production-deployment</code> jusqu'\u00e0 approbation.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#variables-denvironnement-vs-secrets","title":"Variables d'Environnement vs Secrets","text":"YAML<pre><code>name: Environment Variables Management\non:\n  push:\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    environment:\n      name: Staging\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Use environment configuration\n        run: |\n          # Variables (non-sensibles, visibles dans les logs)\n          echo \"API URL: ${{ vars.STAGING_API_URL }}\"\n          echo \"Log Level: ${{ vars.LOG_LEVEL }}\"\n\n          # Secrets (masqu\u00e9s dans les logs)\n          echo \"Using API key: ${{ secrets.STAGING_API_KEY }}\"\n          echo \"Using DB password: ${{ secrets.DB_PASSWORD }}\"\n</code></pre> <p>Diff\u00e9rences cl\u00e9s :</p> Aspect Variables Secrets Visibilit\u00e9 Affich\u00e9es dans les logs Masqu\u00e9es/\u00e9chapp\u00e9es dans les logs Sensibilit\u00e9 Donn\u00e9es non-sensibles Donn\u00e9es sensibles Valeur par d\u00e9faut Oui, au niveau du d\u00e9p\u00f4t Oui, au niveau du d\u00e9p\u00f4t Priorit\u00e9 Environnement &gt; D\u00e9p\u00f4t Environnement &gt; D\u00e9p\u00f4t"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#deploiement-progressif","title":"D\u00e9ploiement Progressif","text":"YAML<pre><code>name: Progressive Deployment\non:\n  push:\n    branches: [main]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    outputs:\n      image-tag: ${{ steps.image.outputs.tag }}\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Build image\n        id: image\n        run: |\n          TAG=\"v-${{ github.sha }}\"\n          echo \"tag=$TAG\" &gt;&gt; $GITHUB_OUTPUT\n\n  deploy-canary:\n    runs-on: ubuntu-latest\n    needs: build\n    environment:\n      name: Production-Canary\n      url: https://canary.example.com\n\n    steps:\n      - name: Deploy canary (5% traffic)\n        run: |\n          echo \"Deploying canary with image: ${{ needs.build.outputs.image-tag }}\"\n          # Deployment logic for 5% of users\n\n  validate-canary:\n    runs-on: ubuntu-latest\n    needs: deploy-canary\n\n    steps:\n      - name: Monitor metrics\n        run: |\n          echo \"Validating canary deployment metrics...\"\n          # Health checks and metrics validation\n\n  deploy-full:\n    runs-on: ubuntu-latest\n    needs: validate-canary\n    environment:\n      name: Production-Full\n      url: https://example.com\n\n    steps:\n      - name: Deploy to full production (100% traffic)\n        run: |\n          echo \"Full production deployment\"\n          # Complete rollout\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#5-concurrence","title":"5\ufe0f\u20e3 Concurrence","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap05/#concept-de-concurrence","title":"Concept de Concurrence","text":"<p>La concurrence dans GitHub Actions g\u00e8re l'ex\u00e9cution simultan\u00e9e des workflows pour \u00e9viter les conflits, les conditions de course (race conditions) et les d\u00e9ploiements concurrents vers les m\u00eames environnements.[4]</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#problemes-resultant-de-labsence-de-gestion","title":"Probl\u00e8mes R\u00e9sultant de l'Absence de Gestion","text":"<p>Sans gestion appropri\u00e9e de la concurrence, plusieurs sc\u00e9narios probl\u00e9matiques peuvent survenir :</p> <ul> <li>D\u00e9ploiements concurrents : deux d\u00e9ploiements modifient simultan\u00e9ment les m\u00eames ressources</li> <li>Conditions de course : les \u00e9tapes s'ex\u00e9cutent dans un ordre impr\u00e9visible</li> <li>Consommation excessive de ressources : trop de jobs s'ex\u00e9cutent simultan\u00e9ment</li> <li>Incoh\u00e9rence d'\u00e9tat : le syst\u00e8me se retrouve dans un \u00e9tat ind\u00e9fini</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#configuration-basique_2","title":"Configuration Basique","text":"YAML<pre><code>name: Concurrency Control Example\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\nconcurrency:\n  group: ${{ github.workflow }}-${{ github.ref }}\n  cancel-in-progress: false\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Build\n        run: npm run build\n</code></pre> <p>Ici : - <code>group</code> identifie de mani\u00e8re unique la concurrence. Tous les workflows avec le m\u00eame groupe ne s'ex\u00e9cutent pas simultan\u00e9ment - <code>cancel-in-progress: false</code> signifie que les workflows pr\u00e9c\u00e9dents terminent leur ex\u00e9cution avant le d\u00e9marrage du nouveau</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#concurrence-par-environnement","title":"Concurrence Par Environnement","text":"YAML<pre><code>name: Environment-Based Concurrency\non:\n  push:\n    branches: [main]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    concurrency:\n      group: testing-${{ github.ref }}\n      cancel-in-progress: true\n\n    steps:\n      - uses: actions/checkout@v4\n      - run: npm test\n\n  deploy-dev:\n    runs-on: ubuntu-latest\n    needs: test\n    concurrency:\n      group: deployment-dev\n      cancel-in-progress: true\n    environment: Development\n\n    steps:\n      - uses: actions/checkout@v4\n      - run: npm run deploy:dev\n\n  deploy-prod:\n    runs-on: ubuntu-latest\n    needs: test\n    concurrency:\n      group: deployment-prod\n      cancel-in-progress: false\n    environment: Production\n\n    steps:\n      - uses: actions/checkout@v4\n      - run: npm run deploy:prod\n</code></pre> <p>Configuration d\u00e9taill\u00e9e : - Les tests utilisent <code>cancel-in-progress: true</code> car les r\u00e9sultats de test pr\u00e9c\u00e9dents deviennent obsol\u00e8tes rapidement - Le d\u00e9ploiement dev utilise <code>cancel-in-progress: true</code> pour \u00e9conomiser les ressources - Le d\u00e9ploiement production utilise <code>cancel-in-progress: false</code> pour garantir que tous les d\u00e9ploiements compl\u00e8tent, \u00e9vitant les \u00e9tats partiels</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#strategies-avancees-de-concurrence","title":"Strat\u00e9gies Avanc\u00e9es de Concurrence","text":"YAML<pre><code>name: Advanced Concurrency Patterns\non:\n  push:\n  pull_request:\n\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    concurrency:\n      group: lint-${{ github.head_ref || github.ref }}\n      cancel-in-progress: true\n\n    steps:\n      - uses: actions/checkout@v4\n      - run: npm run lint\n\n  unit-tests:\n    runs-on: ubuntu-latest\n    concurrency:\n      group: unit-tests-${{ github.head_ref || github.ref }}\n      cancel-in-progress: true\n\n    steps:\n      - uses: actions/checkout@v4\n      - run: npm run test:unit\n\n  integration-tests:\n    runs-on: ubuntu-latest\n    concurrency:\n      group: integration-tests-${{ github.head_ref || github.ref }}\n      cancel-in-progress: true\n    needs: [lint, unit-tests]\n\n    steps:\n      - uses: actions/checkout@v4\n      - run: npm run test:integration\n\n  build:\n    runs-on: ubuntu-latest\n    concurrency:\n      group: build-${{ github.head_ref || github.ref }}\n      cancel-in-progress: true\n    needs: [integration-tests]\n\n    steps:\n      - uses: actions/checkout@v4\n      - run: npm run build\n\n  deploy:\n    runs-on: ubuntu-latest\n    concurrency:\n      group: deploy-${{ github.ref }}\n      cancel-in-progress: false\n    environment: Production\n    needs: build\n    if: github.ref == 'refs/heads/main' &amp;&amp; github.event_name == 'push'\n\n    steps:\n      - uses: actions/checkout@v4\n      - run: npm run deploy\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#gestion-de-la-concurrence-avec-matrix","title":"Gestion de la Concurrence avec Matrix","text":"YAML<pre><code>name: Matrix with Concurrency Control\non:\n  push:\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    strategy:\n      matrix:\n        node-version: [16, 18, 20]\n        database: [postgres, mysql]\n    concurrency:\n      group: test-${{ matrix.node-version }}-${{ matrix.database }}\n      cancel-in-progress: true\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Setup Node.js ${{ matrix.node-version }}\n        uses: actions/setup-node@v4\n        with:\n          node-version: ${{ matrix.node-version }}\n\n      - name: Test with ${{ matrix.database }}\n        run: npm test -- --database=${{ matrix.database }}\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#table-comparative-strategies-de-concurrence","title":"Table Comparative : Strat\u00e9gies de Concurrence","text":"Strat\u00e9gie Groupe Cancel-in-Progress Cas d'Usage D\u00e9veloppement rapide Par PR true Linting, tests unitaires D\u00e9ploiement principal Par environnement false Production, staging Ressources limit\u00e9es Par workflow true \u00c9conomiser les ressources Haute fiabilit\u00e9 Par environnement false D\u00e9ploiements critiques"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#concurrence-et-etat-partage","title":"Concurrence et \u00c9tat Partag\u00e9","text":"YAML<pre><code>name: Concurrency with State Management\non:\n  push:\n    branches: [main]\n\nconcurrency:\n  group: release-${{ github.ref }}\n  cancel-in-progress: false\n\njobs:\n  prepare:\n    runs-on: ubuntu-latest\n    outputs:\n      version: ${{ steps.version.outputs.new-version }}\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Calculate new version\n        id: version\n        run: |\n          NEW_VERSION=\"1.2.$((${{ github.run_number }}))\"\n          echo \"new-version=$NEW_VERSION\" &gt;&gt; $GITHUB_OUTPUT\n\n  build-and-push:\n    runs-on: ubuntu-latest\n    needs: prepare\n\n    steps:\n      - uses: actions/checkout@v4\n\n      - name: Build with version ${{ needs.prepare.outputs.version }}\n        run: |\n          echo \"Building version ${{ needs.prepare.outputs.version }}\"\n          # Build logic\n\n  deploy:\n    runs-on: ubuntu-latest\n    needs: build-and-push\n    environment:\n      name: Production\n      url: https://example.com\n\n    steps:\n      - name: Deploy\n        run: echo \"Deployment completed\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#cheminement-dapprentissage-integre","title":"\ud83c\udf93 Cheminement d'Apprentissage Int\u00e9gr\u00e9","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap05/#phase-1-fondamentaux-1-2-jours","title":"Phase 1 : Fondamentaux (1-2 jours)","text":"<p>D\u00e9buter par la gestion des caches permet de comprendre comment GitHub Actions optimise les ex\u00e9cutions. Les caches constituent un concept simple avec des b\u00e9n\u00e9fices imm\u00e9diats visibles dans les temps d'ex\u00e9cution. Cette fondation facilite la compr\u00e9hension des performances futures.</p> <p>Ensuite, explorer les matrices de base cr\u00e9e une compr\u00e9hension du parall\u00e9lisme. Construire un workflow simple testant une application sur 3 versions de Node.js d\u00e9montre la puissance de l'automatisation sans accaparement d'administration.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#phase-2-optimisation-avancee-2-3-jours","title":"Phase 2 : Optimisation Avanc\u00e9e (2-3 jours)","text":"<p>Une fois familiaris\u00e9 avec les caches et matrices simples, approfondir le fail-fast et les strat\u00e9gies avanc\u00e9es r\u00e9v\u00e8le comment contr\u00f4ler l'efficacit\u00e9 des workflows. Comprendre quand annuler versus continuer l'ex\u00e9cution pr\u00e9pare \u00e0 des d\u00e9cisions productives sur des pipelines r\u00e9alistes.</p> <p>La limitation du parall\u00e9lisme et les r\u00e8gles d'inclusion/exclusion ajoutent des contr\u00f4les granulaires sur la consommation de ressources.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#phase-3-securite-et-gouvernance-2-3-jours","title":"Phase 3 : S\u00e9curit\u00e9 et Gouvernance (2-3 jours)","text":"<p>Les permissions s'apprennent naturellement apr\u00e8s les matrices, car elles compl\u00e8tent les workflows en ajoutant des barri\u00e8res de s\u00e9curit\u00e9. Impl\u00e9menter le principe du moindre privil\u00e8ge devient une habitude constante.</p> <p>Les environnements et d\u00e9ploiements structurent les workflows pour refl\u00e9ter les processus m\u00e9tier r\u00e9els (dev/staging/prod). Cette phase transforme les workflows techniques en outils professionnels avec approbations et validations.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#phase-4-orchestration-avancee-2-3-jours","title":"Phase 4 : Orchestration Avanc\u00e9e (2-3 jours)","text":"<p>La concurrence repr\u00e9sente le concept le plus complexe, orchestrant plusieurs workflows pour \u00e9viter les conflits. Apr\u00e8s comprendre les caches, matrices, permissions et environnements, la concurrence devient l'outil final pour orchestrer syst\u00e8mes complexes.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#progression-typique-dun-projet-realiste","title":"Progression Typique d'un Projet R\u00e9aliste","text":"<p>Semaine 1 : Configuration d'un workflow de test basique avec cache npm et matrice de 2 versions de Node.js</p> <p>Semaine 2 : Ajout d'un environnement staging, permissions limit\u00e9es, et fail-fast d\u00e9sactiv\u00e9 pour debugging</p> <p>Semaine 3 : Impl\u00e9mentation d'un d\u00e9ploiement multi-environnements (dev/staging/prod) avec approbations</p> <p>Semaine 4 : Optimisation via concurrence par environnement, inclusion/exclusion de configurations, et gestion avanc\u00e9e des caches</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#ressources-de-reference","title":"\ud83d\udcda Ressources de R\u00e9f\u00e9rence","text":"<p>La documentation officielle de GitHub sur les workflows fournit les d\u00e9tails complets pour chaque concept. Les guides incluent des exemples pratiques pour chaque configuration avanc\u00e9e. Pour les caches, consulter la documentation sp\u00e9cifique aux actions <code>setup-node</code>, <code>setup-python</code> etc. pour comprendre les caches g\u00e9r\u00e9s automatiquement.</p> <p>Les configurations YAML pr\u00e9sent\u00e9es ci-dessus couvrent l'ensemble des sc\u00e9narios courants, des plus simples aux plus complexes. Adapter ces exemples \u00e0 des contextes sp\u00e9cifiques facilite l'adoption dans des projets r\u00e9els.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap05/#points-cles-a-retenir","title":"\u2728 Points Cl\u00e9s \u00e0 Retenir","text":"<p>Caches : R\u00e9duisent drastiquement les temps d'ex\u00e9cution en r\u00e9utilisant les installations et compilations pr\u00e9c\u00e9dentes, avec une gestion intelligente par cl\u00e9 et restauration en cascade.</p> <p>Matrices : \u00c9liminent la duplication en g\u00e9n\u00e9rant dynamiquement plusieurs variations de jobs, avec contr\u00f4le du fail-fast pour \u00e9quilibrer rapidit\u00e9 et fiabilit\u00e9.</p> <p>Permissions : Appliquent le moindre privil\u00e8ge, limitant l'acc\u00e8s des workflows aux ressources minimales n\u00e9cessaires.</p> <p>Environnements : Structurent les d\u00e9ploiements avec variables, secrets et approbations sp\u00e9cifiques \u00e0 chaque \u00e9tape (dev/staging/prod).</p> <p>Concurrence : Orchestrent les workflows parall\u00e8les pour \u00e9viter les conflits et les \u00e9tats incoh\u00e9rents, garantissant la s\u00e9curit\u00e9 et la pr\u00e9visibilit\u00e9 des ex\u00e9cutions complexes.</p> <p>Ces cinq domaines forment un \u00e9cosyst\u00e8me complet pour produire des workflows sophistiqu\u00e9s, s\u00e9curis\u00e9s et performants en production.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/","title":"Citations","text":"<ul> <li>https://shipyard.build/blog/gha-recipes-build-and-push-container-registry/</li> <li>https://runcloud.io/blog/setup-docker-github-actions-ci-cd</li> <li>https://docs.github.com/actions/creating-actions/creating-a-docker-container-action</li> <li>https://docs.github.com/actions/using-jobs/running-jobs-in-a-container</li> <li>https://docs.github.com/actions/tutorials/communicating-with-docker-service-containers</li> <li>https://docs.github.com/actions/hosting-your-own-runners/customizing-the-containers-used-by-jobs</li> <li>https://aschmelyun.com/blog/using-docker-run-inside-of-github-actions/</li> <li>https://docs.docker.com/guides/reactjs/configure-github-actions/</li> <li>https://github.com/docker/build-push-action/discussions/1020</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 273</li> <li>completion_tokens: 6875</li> <li>total_tokens: 7148</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.103, 'request_cost': 0.006, 'total_cost': 0.11}</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#content","title":"Content","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap06/#chapitre-6-github-actions-notions-avancees","title":"Chapitre 6 : Github Actions - Notions Avanc\u00e9es","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap06/#utiliser-des-conteneurs-docker","title":"\ud83d\udc33 Utiliser des Conteneurs Docker","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap06/#concepts-fondamentaux","title":"Concepts Fondamentaux","text":"<p>Les conteneurs Docker offrent un environnement d'ex\u00e9cution isol\u00e9 et reproductible pour les workflows GitHub Actions. Cette approche garantit que les jobs s'ex\u00e9cutent dans des conditions identiques, ind\u00e9pendamment de la machine h\u00f4te. L'int\u00e9gration entre Docker et GitHub Actions permet de d\u00e9finir pr\u00e9cis\u00e9ment l'environnement d'ex\u00e9cution et d'am\u00e9liorer la coh\u00e9rence des pipelines CI/CD.[4]</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#execution-dun-job-dans-un-conteneur","title":"Ex\u00e9cution d'un Job dans un Conteneur","text":"<p>La syntaxe fondamentale pour ex\u00e9cuter un job dans un conteneur Docker utilise la directive <code>container:</code> dans le fichier de workflow.[4] Voici un exemple complet :</p> YAML<pre><code>name: CI\non:\n  push:\n    branches: [ main ]\njobs:\n  container-test-job:\n    runs-on: ubuntu-latest\n    container:\n      image: node:18\n      env:\n        NODE_ENV: development\n      ports:\n        - 80\n      volumes:\n        - my_docker_volume:/volume_mount\n      options: --cpus 1\n    steps:\n      - name: Check for dockerenv file\n        run: (ls /.dockerenv &amp;&amp; echo Found dockerenv) || (echo No dockerenv)\n</code></pre> <p>Ce workflow d\u00e9montre plusieurs configurations essentielles :</p> <ul> <li>image : Sp\u00e9cifie l'image Docker \u00e0 utiliser (ici Node.js 18)</li> <li>env : D\u00e9finit les variables d'environnement au sein du conteneur</li> <li>ports : Expose les ports n\u00e9cessaires</li> <li>volumes : Monte des volumes Docker pour la persistance de donn\u00e9es</li> <li>options : Ajoute des options de ressources comme les limitations CPU</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#gestion-des-volumes","title":"Gestion des Volumes","text":"<p>Les volumes permettent de monter des r\u00e9pertoires ou des donn\u00e9es entre l'h\u00f4te et le conteneur.[4] La syntaxe g\u00e9n\u00e9rale suit le format <code>&lt;source&gt;:&lt;destinationPath&gt;</code> :</p> YAML<pre><code>volumes:\n  - my_docker_volume:/volume_mount\n  - /data/my_data\n  - /source/directory:/destination/directory\n</code></pre> <p>La source peut \u00eatre soit un nom de volume Docker, soit un chemin absolu sur la machine h\u00f4te. Le chemin de destination doit \u00eatre un chemin absolu \u00e0 l'int\u00e9rieur du conteneur.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#acces-a-lespace-de-travail","title":"Acc\u00e8s \u00e0 l'Espace de Travail","text":"<p>GitHub mappe automatiquement le r\u00e9pertoire de travail du runner avec <code>/github/workspace</code> dans le conteneur.[3] Cela signifie que tout fichier cr\u00e9\u00e9 ou modifi\u00e9 dans cette location sur le conteneur sera accessible aux \u00e9tapes suivantes du job. Cette fonctionnalit\u00e9 s'av\u00e8re particuli\u00e8rement utile pour les actions qui g\u00e9n\u00e9raient des artefacts de build.</p> YAML<pre><code>workflow.yml:\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout\n        uses: actions/checkout@v5\n\n      - name: Containerized Build\n        uses: ./.github/actions/my-container-action\n\n      - name: Upload Build Artifacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: workspace_artifacts\n          path: ${{ github.workspace }}\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#creation-dactions-docker-personnalisees","title":"Cr\u00e9ation d'Actions Docker Personnalis\u00e9es","text":"<p>Pour cr\u00e9er une action Docker personnalis\u00e9e, il est n\u00e9cessaire de d\u00e9finir un fichier <code>Dockerfile</code> et un fichier de m\u00e9tadonn\u00e9es <code>action.yml</code>.[3]</p> <p>Voici un exemple minimal de Dockerfile :</p> Docker<pre><code>FROM alpine:3.10\n\nCOPY entrypoint.sh /entrypoint.sh\n\nENTRYPOINT [\"/entrypoint.sh\"]\n</code></pre> <p>Ce Dockerfile utilise Alpine Linux comme image de base (l\u00e9g\u00e8re et optimis\u00e9e), copie le script d'entr\u00e9e, et le d\u00e9finit comme point d'entr\u00e9e du conteneur.</p> <p>Le fichier <code>action.yml</code> accompagnant d\u00e9finit les entr\u00e9es et sorties de l'action :</p> YAML<pre><code>name: 'Hello world action'\ndescription: 'Greet someone'\ninputs:\n  who-to-greet:\n    description: 'Who to greet'\n    required: true\n    default: 'World'\noutputs:\n  time:\n    description: 'The time we greeted you'\nruns:\n  using: 'docker'\n  image: 'Dockerfile'\n  args:\n    - ${{ inputs.who-to-greet }}\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#construction-et-publication-dimages-docker","title":"Construction et Publication d'Images Docker","text":"<p>La construction et la publication d'images Docker via GitHub Actions requiert une authentification appropri\u00e9e.[1] Voici le processus complet pour publier vers GitHub Container Registry (GHCR) :</p> YAML<pre><code>- name: Log in to ghcr.io\n  run: echo \"${{ secrets.GHCR_TOKEN }}\" | docker login ghcr.io -u ${{ github.actor }} --password-stdin\n\n- name: Build and tag image\n  run: |\n    COMMIT_SHA=$(echo $GITHUB_SHA | cut -c1-7)\n    docker build -t ghcr.io/${{ github.repository_owner }}/${{ github.repository }}:$COMMIT_SHA -f path/to/Dockerfile .\n\n- name: Push image to GHCR\n  run: docker push ghcr.io/${{ github.repository_owner }}/${{ github.repository }}:$COMMIT_SHA\n</code></pre> <p>Pour Docker Hub, la d\u00e9marche est similaire mais requiert l'enregistrement de secrets sp\u00e9cifiques :[1]</p> YAML<pre><code>- name: Log in to Docker Hub\n  run: echo \"${{ secrets.DOCKERHUB_PASSWORD }}\" | docker login -u ${{ secrets.DOCKERHUB_USERNAME }} --password-stdin\n\n- name: Build and tag image\n  run: |\n    COMMIT_SHA=$(echo $GITHUB_SHA | cut -c1-7)\n    docker build -t ${{ secrets.DOCKERHUB_USERNAME }}/my-image:$COMMIT_SHA .\n\n- name: Push to Docker Hub\n  run: docker push ${{ secrets.DOCKERHUB_USERNAME }}/my-image:$COMMIT_SHA\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#limitations-de-ressources","title":"Limitations de Ressources","text":"<p>Les options Docker permettent de limiter les ressources allou\u00e9es \u00e0 un conteneur. L'option <code>--cpus</code> contr\u00f4le le nombre de CPUs accessibles :[4]</p> YAML<pre><code>container:\n  image: ubuntu:latest\n  options: --cpus 1\n</code></pre> <p>Cette configuration limite le conteneur \u00e0 utiliser au maximum 1 CPU, ce qui s'av\u00e8re utile pour tester le comportement de l'application dans des environnements \u00e0 ressources limit\u00e9es.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#les-services","title":"\ud83d\udd17 Les Services","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap06/#architecture-des-conteneurs-de-service","title":"Architecture des Conteneurs de Service","text":"<p>GitHub Actions permet de configurer des conteneurs de service qui fonctionnent en parall\u00e8le avec le job principal.[5] Chaque conteneur de service s'ex\u00e9cute dans une instance fra\u00eeche et s'arr\u00eate automatiquement une fois le job termin\u00e9. Cette architecture permet aux \u00e9tapes du job de communiquer avec tous les conteneurs de service du m\u00eame job.</p> <p>Les cas d'usage courants incluent :</p> <ul> <li>Les bases de donn\u00e9es (PostgreSQL, MySQL, MongoDB)</li> <li>Les syst\u00e8mes de cache (Redis)</li> <li>Les services tiers (Elasticsearch, RabbitMQ)</li> <li>Les serveurs web locaux</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#configuration-des-conteneurs-de-service","title":"Configuration des Conteneurs de Service","text":"<p>La syntaxe pour configurer un service repose sur la cl\u00e9 <code>services:</code> au niveau du job :[5]</p> YAML<pre><code>name: Testing with Services\non:\n  push:\n    branches: [ main ]\n\njobs:\n  test-job:\n    runs-on: ubuntu-latest\n    services:\n      postgres:\n        image: postgres:13\n        env:\n          POSTGRES_PASSWORD: postgres\n          POSTGRES_DB: testdb\n        options: &gt;-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n        ports:\n          - 5432:5432\n\n      redis:\n        image: redis:6\n        options: &gt;-\n          --health-cmd \"redis-cli ping\"\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n        ports:\n          - 6379:6379\n\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Run tests against services\n        run: npm test\n        env:\n          DATABASE_URL: postgresql://postgres:postgres@postgres:5432/testdb\n          REDIS_URL: redis://redis:6379\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#communication-entre-conteneurs","title":"Communication entre Conteneurs","text":"<p>Les conteneurs de service sont accessibles via leurs noms de service d\u00e9finis comme h\u00f4tes DNS.[5] Dans l'exemple pr\u00e9c\u00e9dent, PostgreSQL est accessible via <code>postgres:5432</code> et Redis via <code>redis:6379</code>. Cette r\u00e9solution DNS automatique facilite la communication sans n\u00e9cessiter la connaissance des adresses IP.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#verifications-de-sante","title":"V\u00e9rifications de Sant\u00e9","text":"<p>Les options de v\u00e9rification de sant\u00e9 garantissent que le service est pr\u00eat avant l'ex\u00e9cution des \u00e9tapes du job. Voici un exemple pour MongoDB :</p> YAML<pre><code>mongodb:\n  image: mongo:4.4\n  options: &gt;-\n    --health-cmd \"mongo --eval 'db.adminCommand(\\\"ping\\\")'\\\"\n    --health-interval 10s\n    --health-timeout 5s\n    --health-retries 5\n  ports:\n    - 27017:27017\n</code></pre> <p>L'option <code>--health-cmd</code> d\u00e9finit la commande de v\u00e9rification, tandis que les autres param\u00e8tres contr\u00f4lent la fr\u00e9quence et le nombre de tentatives.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#docker-compose-dans-github-actions","title":"Docker Compose dans GitHub Actions","text":"<p>Docker Compose s'int\u00e8gre efficacement dans GitHub Actions pour g\u00e9rer les configurations multi-conteneurs.[2] Voici un exemple utilisant Docker Compose :</p> YAML<pre><code>name: CI with Docker Compose\non:\n  push:\n    branches: [ main ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Start services with Docker Compose\n        run: docker-compose up -d\n\n      - name: Wait for services to be ready\n        run: sleep 10\n\n      - name: Run application tests\n        run: npm test\n\n      - name: Stop services\n        run: docker-compose down\n</code></pre> <p>Le fichier <code>docker-compose.yml</code> correspondant :</p> YAML<pre><code>version: '3.8'\nservices:\n  app:\n    build: .\n    ports:\n      - \"3000:3000\"\n    depends_on:\n      - db\n      - cache\n\n  db:\n    image: postgres:13\n    environment:\n      POSTGRES_PASSWORD: postgres\n      POSTGRES_DB: testdb\n    ports:\n      - \"5432:5432\"\n\n  cache:\n    image: redis:6\n    ports:\n      - \"6379:6379\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#les-artefacts","title":"\ud83d\udce6 Les Artefacts","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap06/#concept-et-utilite-des-artefacts","title":"Concept et Utilit\u00e9 des Artefacts","text":"<p>Les artefacts sont des fichiers g\u00e9n\u00e9r\u00e9s au cours de l'ex\u00e9cution d'un workflow GitHub Actions qui doivent \u00eatre conserv\u00e9s et rendus accessibles apr\u00e8s la fin du job.[3] Contrairement aux fichiers stock\u00e9s dans le workspace qui sont supprim\u00e9s apr\u00e8s l'ex\u00e9cution, les artefacts sont stock\u00e9s dans le stockage des artefacts de GitHub et demeurent accessibles pour une p\u00e9riode d\u00e9finie.</p> <p>Les types d'artefacts courants incluent :</p> <ul> <li>Les binaires compil\u00e9s</li> <li>Les distributions packag\u00e9es</li> <li>Les rapports de test et de couverture de code</li> <li>Les logs d'ex\u00e9cution</li> <li>Les fichiers de configuration g\u00e9n\u00e9r\u00e9s</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#upload-dartefacts","title":"Upload d'Artefacts","text":"<p>L'action <code>actions/upload-artifact</code> permet de sauvegarder des fichiers ou des r\u00e9pertoires.[3] Voici un exemple complet :</p> YAML<pre><code>name: Build and Upload Artifacts\non:\n  push:\n    branches: [ main ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Build project\n        run: |\n          mkdir -p build\n          npm run build\n          cp -r dist build/\n\n      - name: Create test report\n        run: npm test -- --coverage\n\n      - name: Upload build artifacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: build-output\n          path: build/\n          retention-days: 30\n\n      - name: Upload coverage report\n        uses: actions/upload-artifact@v4\n        with:\n          name: coverage-report\n          path: coverage/\n          retention-days: 7\n</code></pre> <p>Les param\u00e8tres essentiels sont :</p> <ul> <li>name : Identifiant unique de l'artefact</li> <li>path : Chemin vers les fichiers ou r\u00e9pertoires \u00e0 t\u00e9l\u00e9charger</li> <li>retention-days : Nombre de jours de conservation (par d\u00e9faut 90)</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#stockage-et-telechargement-des-artefacts","title":"Stockage et T\u00e9l\u00e9chargement des Artefacts","text":"<p>Les artefacts sont accessibles via l'interface web de GitHub ou t\u00e9l\u00e9chargeables via l'API. Les param\u00e8tres de r\u00e9tention peuvent \u00eatre g\u00e9r\u00e9s au niveau du d\u00e9p\u00f4t ou du workflow.</p> YAML<pre><code>- name: Upload multiple artifacts\n  uses: actions/upload-artifact@v4\n  with:\n    name: all-artifacts\n    path: |\n      build/\n      dist/\n      reports/\n    retention-days: 14\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#telechargement-dartefacts-dans-dautres-jobs","title":"T\u00e9l\u00e9chargement d'Artefacts dans d'autres Jobs","text":"<p>L'action <code>actions/download-artifact</code> r\u00e9cup\u00e8re les artefacts g\u00e9n\u00e9r\u00e9s par d'autres jobs du m\u00eame workflow :[3]</p> YAML<pre><code>name: Build and Deploy\non:\n  push:\n    branches: [ main ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Build application\n        run: npm run build\n\n      - name: Upload artifacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: application-build\n          path: dist/\n\n  deploy:\n    runs-on: ubuntu-latest\n    needs: build\n    steps:\n      - name: Download artifacts\n        uses: actions/download-artifact@v4\n        with:\n          name: application-build\n          path: ./downloaded-app\n\n      - name: Deploy to production\n        run: ./deploy.sh ./downloaded-app\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#gestion-des-espaces-de-travail-avec-conteneurs","title":"Gestion des Espaces de Travail avec Conteneurs","text":"<p>Lorsque les jobs s'ex\u00e9cutent dans des conteneurs, les fichiers cr\u00e9\u00e9s dans <code>/github/workspace</code> sont automatiquement accessibles aux \u00e9tapes suivantes et peuvent \u00eatre t\u00e9l\u00e9charg\u00e9s comme artefacts.[3] Cette synchronisation automatique \u00e9limine la n\u00e9cessit\u00e9 de g\u00e9rer explicitement la copie des fichiers entre le conteneur et l'h\u00f4te.</p> YAML<pre><code>jobs:\n  containerized-build:\n    runs-on: ubuntu-latest\n    container:\n      image: node:18\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Build in container\n        run: |\n          npm install\n          npm run build\n          # Les fichiers dans /github/workspace seront accessibles apr\u00e8s le job\n\n      - name: Upload build from container\n        uses: actions/upload-artifact@v4\n        with:\n          name: container-build\n          path: /github/workspace/dist/\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#les-resumes-de-jobs","title":"\ud83d\udccb Les R\u00e9sum\u00e9s de Jobs","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap06/#concept-des-resumes-de-jobs","title":"Concept des R\u00e9sum\u00e9s de Jobs","text":"<p>Les r\u00e9sum\u00e9s de jobs (job summaries) permettent de g\u00e9n\u00e9rer des rapports format\u00e9s en Markdown qui s'affichent dans l'interface GitHub apr\u00e8s l'ex\u00e9cution du workflow. Ces r\u00e9sum\u00e9s offrent une visibilit\u00e9 imm\u00e9diate sur les r\u00e9sultats cl\u00e9s sans n\u00e9cessiter d'acc\u00e9der aux logs complets.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#generation-de-resumes-simples","title":"G\u00e9n\u00e9ration de R\u00e9sum\u00e9s Simples","text":"<p>Les r\u00e9sum\u00e9s sont g\u00e9n\u00e9r\u00e9s en \u00e9crivant du contenu Markdown dans la variable d'environnement <code>GITHUB_STEP_SUMMARY</code> :[4]</p> Bash<pre><code>echo \"# Test Results\" &gt;&gt; $GITHUB_STEP_SUMMARY\necho \"## Summary\" &gt;&gt; $GITHUB_STEP_SUMMARY\necho \"- Tests passed: 156\" &gt;&gt; $GITHUB_STEP_SUMMARY\necho \"- Tests failed: 2\" &gt;&gt; $GITHUB_STEP_SUMMARY\necho \"- Coverage: 89%\" &gt;&gt; $GITHUB_STEP_SUMMARY\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#integration-dans-les-workflows","title":"Int\u00e9gration dans les Workflows","text":"<p>Voici un exemple complet int\u00e9grant les r\u00e9sum\u00e9s dans un workflow de test :</p> YAML<pre><code>name: Test with Summary\non:\n  push:\n    branches: [ main ]\n\njobs:\n  test:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run tests and generate report\n        run: |\n          npm test -- --json --outputFile=test-results.json || true\n\n      - name: Generate job summary\n        run: |\n          echo \"# \ud83e\uddea Test Results Summary\" &gt;&gt; $GITHUB_STEP_SUMMARY\n          echo \"\" &gt;&gt; $GITHUB_STEP_SUMMARY\n          echo \"| Metric | Value |\" &gt;&gt; $GITHUB_STEP_SUMMARY\n          echo \"|--------|-------|\" &gt;&gt; $GITHUB_STEP_SUMMARY\n          echo \"| Total Tests | 156 |\" &gt;&gt; $GITHUB_STEP_SUMMARY\n          echo \"| Passed | 154 |\" &gt;&gt; $GITHUB_STEP_SUMMARY\n          echo \"| Failed | 2 |\" &gt;&gt; $GITHUB_STEP_SUMMARY\n          echo \"| Success Rate | 98.7% |\" &gt;&gt; $GITHUB_STEP_SUMMARY\n          echo \"\" &gt;&gt; $GITHUB_STEP_SUMMARY\n          echo \"## Failed Tests\" &gt;&gt; $GITHUB_STEP_SUMMARY\n          echo \"- UserService::should create user with valid data\" &gt;&gt; $GITHUB_STEP_SUMMARY\n          echo \"- AuthService::should refresh token within 1 hour\" &gt;&gt; $GITHUB_STEP_SUMMARY\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#resumes-avec-tableaux-formates","title":"R\u00e9sum\u00e9s avec Tableaux Format\u00e9s","text":"<p>Les r\u00e9sum\u00e9s deviennent particuli\u00e8rement utiles pour pr\u00e9senter des donn\u00e9es complexes via des tableaux Markdown :</p> YAML<pre><code>- name: Generate deployment summary\n  run: |\n    echo \"# \ud83d\ude80 Deployment Report\" &gt;&gt; $GITHUB_STEP_SUMMARY\n    echo \"\" &gt;&gt; $GITHUB_STEP_SUMMARY\n    echo \"| Environment | Status | Version | Time |\" &gt;&gt; $GITHUB_STEP_SUMMARY\n    echo \"|-------------|--------|---------|------|\" &gt;&gt; $GITHUB_STEP_SUMMARY\n    echo \"| Staging | \u2705 Success | v1.2.3 | 2m 34s |\" &gt;&gt; $GITHUB_STEP_SUMMARY\n    echo \"| Production | \u2705 Success | v1.2.3 | 3m 12s |\" &gt;&gt; $GITHUB_STEP_SUMMARY\n    echo \"\" &gt;&gt; $GITHUB_STEP_SUMMARY\n    echo \"### Changes Deployed\" &gt;&gt; $GITHUB_STEP_SUMMARY\n    echo \"- Feature: User authentication with OAuth2\" &gt;&gt; $GITHUB_STEP_SUMMARY\n    echo \"- Fix: Memory leak in cache manager\" &gt;&gt; $GITHUB_STEP_SUMMARY\n    echo \"- Docs: Updated API documentation\" &gt;&gt; $GITHUB_STEP_SUMMARY\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#resumes-conditionnels","title":"R\u00e9sum\u00e9s Conditionnels","text":"<p>Les r\u00e9sum\u00e9s peuvent \u00eatre g\u00e9n\u00e9r\u00e9s conditionnellement en fonction du r\u00e9sultat des \u00e9tapes pr\u00e9c\u00e9dentes :</p> YAML<pre><code>- name: Run integration tests\n  id: integration-tests\n  continue-on-error: true\n  run: npm run test:integration\n\n- name: Generate conditional summary\n  if: always()\n  run: |\n    if [ \"${{ steps.integration-tests.outcome }}\" == \"success\" ]; then\n      echo \"# \u2705 Integration Tests Passed\" &gt;&gt; $GITHUB_STEP_SUMMARY\n    else\n      echo \"# \u274c Integration Tests Failed\" &gt;&gt; $GITHUB_STEP_SUMMARY\n      echo \"\" &gt;&gt; $GITHUB_STEP_SUMMARY\n      echo \"Please review the detailed logs for error information.\" &gt;&gt; $GITHUB_STEP_SUMMARY\n    fi\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#resumes-avec-statistiques-de-couverture","title":"R\u00e9sum\u00e9s avec Statistiques de Couverture","text":"<p>Pour les workflows de test avec mesure de couverture de code :</p> YAML<pre><code>- name: Generate coverage summary\n  run: |\n    COVERAGE=$(cat coverage/coverage-summary.json | grep '\"lines\"' | head -1 | grep -oP '\\d+\\.\\d+')\n    echo \"# \ud83d\udcca Code Coverage Report\" &gt;&gt; $GITHUB_STEP_SUMMARY\n    echo \"\" &gt;&gt; $GITHUB_STEP_SUMMARY\n    echo \"- **Overall Coverage**: $COVERAGE%\" &gt;&gt; $GITHUB_STEP_SUMMARY\n    echo \"- **Lines Covered**: 1,245 / 1,400\" &gt;&gt; $GITHUB_STEP_SUMMARY\n    echo \"- **Branches Covered**: 892 / 1,000\" &gt;&gt; $GITHUB_STEP_SUMMARY\n    echo \"- **Functions Covered**: 156 / 175\" &gt;&gt; $GITHUB_STEP_SUMMARY\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#securite-injection-de-scripts-et-utilisation-dactions-tierces","title":"\ud83d\udd10 S\u00e9curit\u00e9 : Injection de Scripts et Utilisation d'Actions Tierces","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap06/#risques-dinjection-de-scripts","title":"Risques d'Injection de Scripts","text":"<p>L'injection de scripts repr\u00e9sente une vuln\u00e9rabilit\u00e9 critique dans les workflows GitHub Actions. Elle survient lorsque des entr\u00e9es non valid\u00e9es sont directement ins\u00e9r\u00e9es dans des commandes shell ou des expressions GitHub Actions. Une acteur malveillant peut injecter du code arbitraire qui s'ex\u00e9cute avec les permissions du workflow.</p> <p>Voici un exemple vuln\u00e9rable :</p> YAML<pre><code>name: Vulnerable Workflow\non:\n  pull_request:\n    types: [opened, synchronize]\n\njobs:\n  vulnerable-job:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Dangerous use of PR title\n        run: echo \"Processing PR: ${{ github.event.pull_request.title }}\"\n        # \u26a0\ufe0f DANGER : Si le titre est `; rm -rf /`, cela supprime des fichiers\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#protection-contre-linjection-de-scripts","title":"Protection contre l'Injection de Scripts","text":"<p>La premi\u00e8re ligne de d\u00e9fense consiste \u00e0 utiliser des variables d'environnement plut\u00f4t que des interpolations directes dans les commandes shell :[2]</p> YAML<pre><code>name: Secure Workflow\non:\n  pull_request:\n    types: [opened, synchronize]\n\njobs:\n  secure-job:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Safe handling of PR data\n        env:\n          PR_TITLE: ${{ github.event.pull_request.title }}\n          PR_BODY: ${{ github.event.pull_request.body }}\n          PR_AUTHOR: ${{ github.event.pull_request.user.login }}\n        run: |\n          echo \"Processing PR: $PR_TITLE\"\n          echo \"Author: $PR_AUTHOR\"\n          # Les variables d'environnement sont \u00e9chapp\u00e9es automatiquement\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#gestion-securisee-des-secrets","title":"Gestion S\u00e9curis\u00e9e des Secrets","text":"<p>GitHub Actions stocke les secrets de mani\u00e8re chiffr\u00e9e et les r\u00e9v\u00e8le uniquement aux workflows autoris\u00e9s. Cependant, il faut \u00e9viter de les afficher accidentellement :[2]</p> YAML<pre><code>jobs:\n  secure-deployment:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Deploy with credentials\n        env:\n          API_TOKEN: ${{ secrets.DEPLOYMENT_TOKEN }}\n          DATABASE_PASSWORD: ${{ secrets.DB_PASSWORD }}\n        run: |\n          # Les secrets sont automatiquement masqu\u00e9s dans les logs\n          ./deploy.sh\n          # \u26a0\ufe0f DANGER : Ceci afficherait le secret dans les logs\n          # echo \"Token: $API_TOKEN\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#mise-en-uvre-de-controles-dacces","title":"Mise en \u0152uvre de Contr\u00f4les d'Acc\u00e8s","text":"<p>Pour les actions tierces, il convient de limiter les permissions via la cl\u00e9 <code>permissions:</code> :[1]</p> YAML<pre><code>name: Limited Permissions Workflow\non:\n  push:\n    branches: [ main ]\n\npermissions:\n  contents: read\n  packages: write\n  pull-requests: read\n\njobs:\n  build-and-push:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Build image\n        run: docker build -t myapp:latest .\n\n      - name: Push to registry\n        uses: docker/build-push-action@v5\n        with:\n          push: true\n          tags: ghcr.io/${{ github.repository }}:latest\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#evaluation-des-actions-tierces","title":"\u00c9valuation des Actions Tierces","text":"<p>Avant d'utiliser une action tierce, il faut examiner :</p> <ul> <li>La source : Pr\u00e9f\u00e9rer les actions officielles de GitHub ou celles d'organisations reconnues</li> <li>La maintenance : V\u00e9rifier que l'action est r\u00e9guli\u00e8rement mise \u00e0 jour</li> <li>Les d\u00e9pendances : Examiner les d\u00e9pendances transitives pour identifier les vuln\u00e9rabilit\u00e9s</li> <li>Les permissions requises : Comprendre exactement ce que l'action peut faire</li> </ul> YAML<pre><code>jobs:\n  third-party-safe:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      packages: write\n    steps:\n      - uses: actions/checkout@v3\n\n      # \u2705 Action officielle de GitHub\n      - uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      # \u2705 Action d'une organisation connue avec contr\u00f4le de version strict\n      - uses: docker/login-action@v2\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      # \u26a0\ufe0f Action tierce : \u00e0 \u00e9valuer attentivement\n      # - uses: unknown-org/risky-action@latest  # \u00c0 \u00e9viter\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#utilisation-de-sha-pour-la-securite-des-actions","title":"Utilisation de SHA pour la S\u00e9curit\u00e9 des Actions","text":"<p>Pour les actions tierces, il est recommand\u00e9 de r\u00e9f\u00e9rencer des versions pr\u00e9cises plut\u00f4t que des tags flexibles :[1]</p> YAML<pre><code>jobs:\n  production-build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n        # \u2705 Bonne pratique : utiliser un SHA sp\u00e9cifique\n        # with:\n        #   ref: abc123def456...\n\n      # \u2705 R\u00e9f\u00e9rence par version majeure\n      - uses: actions/setup-node@v3\n\n      # \u26a0\ufe0f \u00c0 \u00e9viter : utiliser 'latest' car l'action peut changer\n      # - uses: actions/setup-node@latest\n\n      # \u2705 Meilleure s\u00e9curit\u00e9 : utiliser un SHA complet\n      - uses: docker/login-action@27aaf59b1031d4b0f4eed3c3cc2345dfaa9a306d\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#audit-et-analyse-des-actions-tierces","title":"Audit et Analyse des Actions Tierces","text":"<p>Pour s\u00e9curiser l'utilisation d'actions tierces, mettre en place un processus d'audit :</p> YAML<pre><code>name: Security Audit Workflow\non:\n  schedule:\n    - cron: '0 0 * * 0'  # Chaque dimanche\n\njobs:\n  audit:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Scan dependencies\n        run: |\n          npm audit\n          # Ou tout autre outil d'audit pertinent\n\n      - name: Generate security report\n        run: |\n          echo \"# \ud83d\udd10 Security Audit Report\" &gt;&gt; $GITHUB_STEP_SUMMARY\n          echo \"Audit completed successfully\" &gt;&gt; $GITHUB_STEP_SUMMARY\n\n      - name: Notify if vulnerabilities found\n        if: failure()\n        run: |\n          echo \"Security vulnerabilities detected!\"\n          exit 1\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#pratiques-recommandees-pour-les-workflows-securises","title":"Pratiques Recommand\u00e9es pour les Workflows S\u00e9curis\u00e9s","text":"<p>Voici un exemple de workflow suivant les meilleures pratiques de s\u00e9curit\u00e9 :</p> YAML<pre><code>name: Secure CI/CD Pipeline\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\npermissions:\n  contents: read\n  packages: write\n\njobs:\n  security-checks:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      security-events: write\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Run security scanner\n        run: npm audit --audit-level=moderate\n\n  build-and-test:\n    runs-on: ubuntu-latest\n    needs: security-checks\n    permissions:\n      contents: read\n      packages: write\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Set up Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: Install dependencies\n        run: npm ci\n\n      - name: Run tests\n        run: npm test\n\n      - name: Build application\n        run: npm run build\n\n      - name: Upload build artifacts\n        uses: actions/upload-artifact@v4\n        with:\n          name: build-artifacts\n          path: dist/\n          retention-days: 7\n\n  publish-artifacts:\n    runs-on: ubuntu-latest\n    needs: build-and-test\n    if: github.ref == 'refs/heads/main'\n    permissions:\n      packages: write\n      contents: read\n    steps:\n      - uses: actions/checkout@v3\n\n      - name: Download artifacts\n        uses: actions/download-artifact@v4\n        with:\n          name: build-artifacts\n\n      - name: Authenticate with registry\n        uses: docker/login-action@v2\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Publish artifacts\n        run: |\n          echo \"Publishing build artifacts...\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#synthese-et-progression-pedagogique","title":"\ud83c\udfaf Synth\u00e8se et Progression P\u00e9dagogique","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap06/#parcours-dapprentissage-progressif","title":"Parcours d'Apprentissage Progressif","text":"<p>L'apprentissage de ces notions avanc\u00e9es suivre un ordre logique de progression :</p> <p>\u00c9tape 1 : Conteneurs Docker (Fondations) La compr\u00e9hension des conteneurs Docker dans GitHub Actions constitue la base de toutes les notions avanc\u00e9es. Elle permet de ma\u00eetriser l'isolation des environnements et la reproductibilit\u00e9 des ex\u00e9cutions.</p> <p>\u00c9tape 2 : Services (Extension) Une fois les conteneurs ma\u00eetris\u00e9s, les services repr\u00e9sentent l'\u00e9tape logique suivante, montrant comment orchestrer plusieurs conteneurs qui collaborent.</p> <p>\u00c9tape 3 : Artefacts (Stockage et Tra\u00e7abilit\u00e9) Les artefacts introduisent la notion de persistance et de transfert de donn\u00e9es entre jobs, essentielle pour les pipelines multi-jobs.</p> <p>\u00c9tape 4 : R\u00e9sum\u00e9s de Jobs (Visibilit\u00e9) Les r\u00e9sum\u00e9s de jobs apportent une meilleure visibilit\u00e9 sur les r\u00e9sultats, crucial pour les workflows complexes.</p> <p>\u00c9tape 5 : S\u00e9curit\u00e9 (Protection) La s\u00e9curit\u00e9 constituant le dernier niveau, elle s'appuie sur la compr\u00e9hension des \u00e9tapes pr\u00e9c\u00e9dentes pour prot\u00e9ger efficacement les workflows.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap06/#points-cles-a-retenir","title":"Points Cl\u00e9s \u00e0 Retenir","text":"<ul> <li>Les conteneurs Docker offrent une isolation compl\u00e8te et une reproductibilit\u00e9 garantie</li> <li>Les services permettent d'orchestrer des environnements multi-conteneurs pour les tests int\u00e9gr\u00e9s</li> <li>Les artefacts assurent la persistence des donn\u00e9es entre jobs et leurs versions</li> <li>Les r\u00e9sum\u00e9s de jobs am\u00e9liorent la visibilit\u00e9 des r\u00e9sultats pour les utilisateurs</li> <li>La s\u00e9curit\u00e9 requiert une vigilance constante sur l'injection de scripts et la gestion des actions tierces</li> </ul> <p> Partager sur X</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/","title":"Citations","text":"<ul> <li>https://dev.to/sarveshk76/streamline-your-workflow-automate-frontend-deployment-with-github-actions-271f</li> <li>https://github.com/helmuthdu/automated-frontend-workflow</li> <li>https://www.youtube.com/watch?v=2p1D29zJdBI</li> <li>https://docs.github.com/articles/getting-started-with-github-actions</li> <li>https://blog.maximeheckel.com/posts/building-perfect-github-action-frontend-teams/</li> <li>https://github.com/sdras/awesome-actions</li> <li>https://github.com/Azure/actions-workflow-samples</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 306</li> <li>completion_tokens: 8663</li> <li>total_tokens: 8969</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.13, 'request_cost': 0.006, 'total_cost': 0.137}</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#content","title":"Content","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap07/#projet-1-github-actions-guide-complet-dimplementation","title":"Projet 1 - GitHub Actions : Guide Complet d'Impl\u00e9mentation","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap07/#presentation-du-projet","title":"\ud83c\udfaf Pr\u00e9sentation du Projet","text":"<p>GitHub Actions constitue une plateforme d'int\u00e9gration continue et de d\u00e9ploiement continu (CI/CD) int\u00e9gr\u00e9e directement dans GitHub. Ce projet vise \u00e0 d\u00e9montrer l'impl\u00e9mentation compl\u00e8te d'un pipeline automatis\u00e9 pour une application fullstack, combinant des tests backend, des tests frontend et des tests end-to-end (E2E) avec couverture de code et d\u00e9ploiement automatis\u00e9[1][4].</p> <p>L'objectif principal consiste \u00e0 automatiser l'ensemble du cycle de vie d'une application, des tests unitaires jusqu'au d\u00e9ploiement en passant par les tests d'int\u00e9gration et de performance. Cette approche \u00e9limine les erreurs manuelles et garantit une coh\u00e9rence dans le processus de d\u00e9ploiement[1].</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#composants-fondamentaux-de-github-actions","title":"\ud83d\udccb Composants Fondamentaux de GitHub Actions","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap07/#architecture-de-base","title":"Architecture de Base","text":"<p>GitHub Actions repose sur quatre \u00e9l\u00e9ments essentiels qui fonctionnent ensemble pour cr\u00e9er un syst\u00e8me d'automatisation puissant[4]:</p> <p>Workflows - Fichiers YAML d\u00e9finissant l'ensemble du processus d'automatisation. Ils contiennent la logique d'ex\u00e9cution et s'activent en r\u00e9ponse \u00e0 des \u00e9v\u00e9nements sp\u00e9cifiques du repository.</p> <p>Events - \u00c9v\u00e9nements d\u00e9clencheurs tels que les push vers une branche, l'ouverture d'une pull request, ou l'ex\u00e9cution manuelle via workflow_dispatch[4].</p> <p>Jobs - Unit\u00e9s d'ex\u00e9cution au sein d'un workflow. Plusieurs jobs peuvent s'ex\u00e9cuter s\u00e9quentiellement ou en parall\u00e8le selon la configuration[5].</p> <p>Steps - T\u00e2ches individuelles composant chaque job. Un step peut ex\u00e9cuter un script personnalis\u00e9 ou utiliser une action r\u00e9utilisable[4].</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#concepts-avances","title":"Concepts Avanc\u00e9s","text":"<p>Runners - Serveurs ex\u00e9cutant les workflows lorsqu'ils sont d\u00e9clench\u00e9s. Chaque runner traite un seul job \u00e0 la fois[2]. GitHub propose des runners h\u00e9berg\u00e9s (ubuntu-latest, windows-latest) ou des self-hosted runners pour plus de contr\u00f4le[1].</p> <p>Actions - Applications r\u00e9utilisables effectuant des t\u00e2ches complexes et r\u00e9p\u00e9titives. La communaut\u00e9 maintient un \u00e9cosyst\u00e8me riche d'actions disponibles[2][6].</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#presentation-du-code-et-creation-du-repertoire-github","title":"\ud83d\uddc2\ufe0f Pr\u00e9sentation du Code et Cr\u00e9ation du R\u00e9pertoire GitHub","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap07/#structure-recommandee","title":"Structure Recommand\u00e9e","text":"<p>La structure d'un projet utilisant GitHub Actions doit respecter une organisation logique permettant une maintenance et une \u00e9volution ais\u00e9es.</p> Text Only<pre><code>mon-projet/\n\u251c\u2500\u2500 .github/\n\u2502   \u251c\u2500\u2500 workflows/\n\u2502   \u2502   \u251c\u2500\u2500 backend.yml\n\u2502   \u2502   \u251c\u2500\u2500 frontend.yml\n\u2502   \u2502   \u251c\u2500\u2500 e2e-tests.yml\n\u2502   \u2502   \u2514\u2500\u2500 deploy.yml\n\u2502   \u2514\u2500\u2500 workflows-configs/\n\u251c\u2500\u2500 backend/\n\u2502   \u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 package.json\n\u2502   \u2514\u2500\u2500 jest.config.js\n\u251c\u2500\u2500 frontend/\n\u2502   \u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 package.json\n\u2502   \u2514\u2500\u2500 vitest.config.js\n\u251c\u2500\u2500 e2e/\n\u2502   \u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 package.json\n\u2502   \u2514\u2500\u2500 playwright.config.js\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#initialisation-du-repository","title":"Initialisation du Repository","text":"<p>L'initialisation d'un repository GitHub Actions commence par cr\u00e9er le r\u00e9pertoire <code>.github/workflows</code>[1]. Ce r\u00e9pertoire centralise l'ensemble des fichiers de configuration des workflows.</p> Bash<pre><code># Cr\u00e9ation de la structure de base\nmkdir -p .github/workflows\ntouch .github/workflows/backend.yml\ntouch .github/workflows/frontend.yml\ntouch .github/workflows/e2e-tests.yml\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#fichier-de-configuration-principal","title":"Fichier de Configuration Principal","text":"<p>Chaque workflow d\u00e9marre par une structure YAML de base d\u00e9finissant le nom, les \u00e9v\u00e9nements d\u00e9clencheurs et les jobs[2]:</p> YAML<pre><code>name: Workflow Principal\n\non:\n  push:\n    branches:\n      - main\n      - develop\n  pull_request:\n    branches:\n      - main\n  workflow_dispatch:\n\njobs:\n  # Les jobs sont d\u00e9finis ici\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#mise-en-place-ssh-pour-le-runner-github","title":"\ud83d\udd10 Mise en Place SSH pour le Runner GitHub","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap07/#configuration-dun-self-hosted-runner","title":"Configuration d'un Self-Hosted Runner","text":"<p>Pour les d\u00e9ploiements vers des serveurs personnels (EC2, VPS, etc.), la configuration d'un self-hosted runner sur une instance EC2 s'av\u00e8re n\u00e9cessaire[1].</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#etapes-de-configuration","title":"\u00c9tapes de Configuration","text":"<p>\u00c9tape 1: G\u00e9n\u00e9rer les Cl\u00e9s SSH</p> Bash<pre><code># Sur la machine locale\nssh-keygen -t rsa -b 4096 -f github-runner-key -N \"\"\n\n# Cela cr\u00e9e deux fichiers:\n# - github-runner-key (cl\u00e9 priv\u00e9e)\n# - github-runner-key.pub (cl\u00e9 publique)\n</code></pre> <p>\u00c9tape 2: Configurer l'Instance EC2</p> Bash<pre><code># Sur l'instance EC2\n# Ajouter la cl\u00e9 publique au fichier authorized_keys\ncat github-runner-key.pub &gt;&gt; ~/.ssh/authorized_keys\nchmod 600 ~/.ssh/authorized_keys\n</code></pre> <p>\u00c9tape 3: Ajouter les Secrets GitHub</p> <p>Dans les param\u00e8tres du repository (Settings \u2192 Secrets and variables \u2192 Actions), ajouter:</p> <ul> <li><code>SSH_PRIVATE_KEY</code>: Contenu de la cl\u00e9 priv\u00e9e</li> <li><code>EC2_HOST</code>: Adresse IP ou hostname de l'instance</li> <li><code>EC2_USER</code>: Nom d'utilisateur (g\u00e9n\u00e9ralement <code>ec2-user</code> ou <code>ubuntu</code>)</li> <li><code>EC2_PORT</code>: Port SSH (g\u00e9n\u00e9ralement 22)</li> </ul> <p>\u00c9tape 4: Enregistrer le Self-Hosted Runner</p> Bash<pre><code># Sur l'instance EC2\n# T\u00e9l\u00e9charger et extraire le runner\nmkdir actions-runner &amp;&amp; cd actions-runner\ncurl -o actions-runner-linux-x64-2.311.0.tar.gz -L \\\n  https://github.com/actions/runner/releases/download/v2.311.0/actions-runner-linux-x64-2.311.0.tar.gz\ntar xzf ./actions-runner-linux-x64-2.311.0.tar.gz\n\n# Configurer le runner\n./config.sh --url https://github.com/USERNAME/REPO --token TOKEN_FOURNI_PAR_GITHUB\n\n# Installer et d\u00e9marrer comme service\nsudo ./svc.sh install\nsudo ./svc.sh start\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#utilisation-du-self-hosted-runner","title":"Utilisation du Self-Hosted Runner","text":"<p>Dans le fichier de workflow, sp\u00e9cifier le runner personnalis\u00e9[1]:</p> YAML<pre><code>jobs:\n  deploy:\n    runs-on: self-hosted\n    steps:\n      - name: V\u00e9rifier le code\n        uses: actions/checkout@v3\n\n      - name: D\u00e9ployer vers EC2\n        run: |\n          # Les commandes s'ex\u00e9cutent sur le self-hosted runner\n          ./deploy.sh\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#configuration-ssh-avancee","title":"Configuration SSH Avanc\u00e9e","text":"<p>Pour une s\u00e9curit\u00e9 renforc\u00e9e, cr\u00e9er un fichier de configuration SSH local[1]:</p> YAML<pre><code>name: D\u00e9ploiement S\u00e9curis\u00e9\n\non:\n  push:\n    branches:\n      - main\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: V\u00e9rifier le code\n        uses: actions/checkout@v3\n\n      - name: Configurer SSH\n        run: |\n          mkdir -p ~/.ssh\n          echo \"${{ secrets.SSH_PRIVATE_KEY }}\" &gt; ~/.ssh/id_rsa\n          chmod 600 ~/.ssh/id_rsa\n          ssh-keyscan -H ${{ secrets.EC2_HOST }} &gt;&gt; ~/.ssh/known_hosts\n\n      - name: D\u00e9ployer via SSH\n        run: |\n          ssh -i ~/.ssh/id_rsa ${{ secrets.EC2_USER }}@${{ secrets.EC2_HOST }} \\\n            'cd /app &amp;&amp; ./deploy.sh'\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#workflow-pour-le-backend","title":"\u2699\ufe0f Workflow pour le Backend","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap07/#structure-complete-dun-workflow-backend","title":"Structure Compl\u00e8te d'un Workflow Backend","text":"<p>Le workflow backend automatise les tests, la couverture de code et la validation de la qualit\u00e9[1][2].</p> YAML<pre><code>name: Backend CI/CD\n\non:\n  push:\n    branches:\n      - main\n      - develop\n    paths:\n      - 'backend/**'\n      - '.github/workflows/backend.yml'\n  pull_request:\n    branches:\n      - main\n    paths:\n      - 'backend/**'\n  workflow_dispatch:\n\nenv:\n  NODE_VERSION: '18'\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}/backend\n\njobs:\n  test:\n    name: Tests et Linting\n    runs-on: ubuntu-latest\n\n    services:\n      postgres:\n        image: postgres:15-alpine\n        env:\n          POSTGRES_PASSWORD: postgres\n          POSTGRES_DB: test_db\n        options: &gt;-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n        ports:\n          - 5432:5432\n\n      redis:\n        image: redis:7-alpine\n        options: &gt;-\n          --health-cmd \"redis-cli ping\"\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n        ports:\n          - 6379:6379\n\n    steps:\n      - name: V\u00e9rifier le code\n        uses: actions/checkout@v3\n\n      - name: Configurer Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: backend/package-lock.json\n\n      - name: Installer les d\u00e9pendances\n        run: |\n          cd backend\n          npm ci\n\n      - name: Ex\u00e9cuter ESLint\n        run: |\n          cd backend\n          npm run lint:report\n        continue-on-error: true\n\n      - name: Ex\u00e9cuter les tests unitaires\n        env:\n          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db\n          REDIS_URL: redis://localhost:6379\n          NODE_ENV: test\n        run: |\n          cd backend\n          npm run test:unit -- --coverage\n\n      - name: Ex\u00e9cuter les tests d'int\u00e9gration\n        env:\n          DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db\n          REDIS_URL: redis://localhost:6379\n          NODE_ENV: test\n        run: |\n          cd backend\n          npm run test:integration -- --coverage\n\n      - name: G\u00e9n\u00e9rer le rapport SARIF ESLint\n        if: always()\n        run: |\n          cd backend\n          npm run lint:sarif\n\n      - name: Charger les r\u00e9sultats ESLint\n        uses: github/codeql-action/upload-sarif@v2\n        if: always()\n        with:\n          sarif_file: backend/eslint-results.sarif\n          category: eslint\n\n      - name: T\u00e9l\u00e9charger l'artifact de couverture\n        uses: actions/upload-artifact@v3\n        if: always()\n        with:\n          name: backend-coverage\n          path: backend/coverage\n          retention-days: 30\n\n  build:\n    name: Construction de l'Image Docker\n    runs-on: ubuntu-latest\n    needs: test\n    if: success()\n\n    permissions:\n      contents: read\n      packages: write\n\n    steps:\n      - name: V\u00e9rifier le code\n        uses: actions/checkout@v3\n\n      - name: Configurer Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - name: Se connecter au registre\n        uses: docker/login-action@v2\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Extraire les m\u00e9tadonn\u00e9es\n        id: meta\n        uses: docker/metadata-action@v4\n        with:\n          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n          tags: |\n            type=ref,event=branch\n            type=semver,pattern={{version}}\n            type=sha\n\n      - name: Construire et pousser l'image\n        uses: docker/build-push-action@v4\n        with:\n          context: ./backend\n          push: ${{ github.event_name != 'pull_request' }}\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#configuration-du-backend","title":"Configuration du Backend","text":"<p>Le fichier <code>backend/package.json</code> doit contenir les scripts n\u00e9cessaires:</p> JSON<pre><code>{\n  \"name\": \"backend\",\n  \"version\": \"1.0.0\",\n  \"scripts\": {\n    \"test:unit\": \"jest --testPathPattern=unit\",\n    \"test:integration\": \"jest --testPathPattern=integration\",\n    \"lint\": \"eslint src/**/*.js\",\n    \"lint:report\": \"eslint src/**/*.js --format json --output-file eslint-results.json || true\",\n    \"lint:sarif\": \"node scripts/convert-eslint-to-sarif.js\"\n  },\n  \"devDependencies\": {\n    \"jest\": \"^29.0.0\",\n    \"eslint\": \"^8.0.0\"\n  }\n}\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#couverture-du-code-et-badges","title":"\ud83d\udcca Couverture du Code et Badges","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap07/#configuration-de-jest-pour-la-couverture","title":"Configuration de Jest pour la Couverture","text":"JavaScript<pre><code>// backend/jest.config.js\nmodule.exports = {\n  testEnvironment: 'node',\n  collectCoverage: true,\n  collectCoverageFrom: [\n    'src/**/*.js',\n    '!src/**/*.test.js',\n    '!src/index.js'\n  ],\n  coverageThreshold: {\n    global: {\n      branches: 80,\n      functions: 80,\n      lines: 80,\n      statements: 80\n    }\n  },\n  coverageReporters: [\n    'text',\n    'text-summary',\n    'html',\n    'lcov',\n    'json'\n  ]\n};\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#generation-des-badges-de-couverture","title":"G\u00e9n\u00e9ration des Badges de Couverture","text":"<p>Utiliser l'action <code>romeovs/lcov-reporter-action</code> pour g\u00e9n\u00e9rer automatiquement les badges:</p> YAML<pre><code>- name: G\u00e9n\u00e9rer le badge de couverture\n  uses: romeovs/lcov-reporter-action@v0.3.1\n  with:\n    lcov-file: ./backend/coverage/lcov.info\n    github-token: ${{ secrets.GITHUB_TOKEN }}\n  if: always()\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#badges-dans-le-readme","title":"Badges dans le README","text":"<p>Ajouter les badges au fichier <code>README.md</code>:</p> Markdown<pre><code># Mon Projet\n\n![Coverage Backend](https://img.shields.io/badge/coverage-85%25-brightgreen)\n![Build Status](https://github.com/USERNAME/REPO/workflows/Backend%20CI%2FCD/badge.svg)\n![Tests](https://img.shields.io/badge/tests-156%20passed-brightgreen)\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#workflow-pour-le-frontend","title":"\ud83c\udfa8 Workflow pour le Frontend","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap07/#structure-complete-dun-workflow-frontend","title":"Structure Compl\u00e8te d'un Workflow Frontend","text":"<p>Le workflow frontend valide le code, ex\u00e9cute les tests et g\u00e9n\u00e8re les assets de production[1][2].</p> YAML<pre><code>name: Frontend CI/CD\n\non:\n  push:\n    branches:\n      - main\n      - develop\n    paths:\n      - 'frontend/**'\n      - '.github/workflows/frontend.yml'\n  pull_request:\n    branches:\n      - main\n    paths:\n      - 'frontend/**'\n  workflow_dispatch:\n\nenv:\n  NODE_VERSION: '18'\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}/frontend\n\njobs:\n  lint:\n    name: Linting et Formatage\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: V\u00e9rifier le code\n        uses: actions/checkout@v3\n\n      - name: Configurer Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: frontend/package-lock.json\n\n      - name: Installer les d\u00e9pendances\n        run: |\n          cd frontend\n          npm ci\n\n      - name: Ex\u00e9cuter Prettier\n        run: |\n          cd frontend\n          npm run format:check\n        continue-on-error: true\n\n      - name: Ex\u00e9cuter ESLint\n        run: |\n          cd frontend\n          npm run lint\n        continue-on-error: true\n\n  test:\n    name: Tests Unitaires et Int\u00e9gration\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: V\u00e9rifier le code\n        uses: actions/checkout@v3\n\n      - name: Configurer Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: frontend/package-lock.json\n\n      - name: Installer les d\u00e9pendances\n        run: |\n          cd frontend\n          npm ci\n\n      - name: Ex\u00e9cuter les tests\n        run: |\n          cd frontend\n          npm run test -- --coverage\n\n      - name: T\u00e9l\u00e9charger l'artifact de couverture\n        uses: actions/upload-artifact@v3\n        if: always()\n        with:\n          name: frontend-coverage\n          path: frontend/coverage\n          retention-days: 30\n\n  build:\n    name: Construction du Build Production\n    runs-on: ubuntu-latest\n    needs: [lint, test]\n    if: success()\n\n    permissions:\n      contents: read\n      packages: write\n\n    steps:\n      - name: V\u00e9rifier le code\n        uses: actions/checkout@v3\n\n      - name: Configurer Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: frontend/package-lock.json\n\n      - name: Installer les d\u00e9pendances\n        run: |\n          cd frontend\n          npm ci\n\n      - name: Construire l'application\n        run: |\n          cd frontend\n          npm run build\n\n      - name: V\u00e9rifier les performances de build\n        run: |\n          cd frontend\n          npm run build:analyze\n\n      - name: T\u00e9l\u00e9charger l'artifact de build\n        uses: actions/upload-artifact@v3\n        with:\n          name: frontend-build\n          path: frontend/dist\n          retention-days: 5\n\n      - name: Configurer Docker Buildx\n        uses: docker/setup-buildx-action@v2\n\n      - name: Se connecter au registre\n        uses: docker/login-action@v2\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Construire et pousser l'image\n        uses: docker/build-push-action@v4\n        with:\n          context: ./frontend\n          push: ${{ github.event_name != 'pull_request' }}\n          tags: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}:${{ github.sha }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n\n  storybook:\n    name: Construire et Publier Storybook\n    runs-on: ubuntu-latest\n    needs: test\n    if: success() &amp;&amp; github.ref == 'refs/heads/main'\n\n    steps:\n      - name: V\u00e9rifier le code\n        uses: actions/checkout@v3\n\n      - name: Configurer Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: ${{ env.NODE_VERSION }}\n          cache: 'npm'\n          cache-dependency-path: frontend/package-lock.json\n\n      - name: Installer les d\u00e9pendances\n        run: |\n          cd frontend\n          npm ci\n\n      - name: Construire Storybook\n        run: |\n          cd frontend\n          npm run storybook:build\n\n      - name: Configurer GitHub Pages\n        uses: actions/configure-pages@v3\n\n      - name: T\u00e9l\u00e9charger l'artifact\n        uses: actions/upload-pages-artifact@v2\n        with:\n          path: 'frontend/storybook-static'\n\n      - name: D\u00e9ployer vers GitHub Pages\n        id: deployment\n        uses: actions/deploy-pages@v2\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#configuration-du-frontend","title":"Configuration du Frontend","text":"JSON<pre><code>{\n  \"name\": \"frontend\",\n  \"version\": \"1.0.0\",\n  \"scripts\": {\n    \"test\": \"vitest\",\n    \"lint\": \"eslint src --fix\",\n    \"format:check\": \"prettier --check src\",\n    \"build\": \"vite build\",\n    \"build:analyze\": \"vite build --report\",\n    \"storybook\": \"storybook dev -p 6006\",\n    \"storybook:build\": \"storybook build\"\n  },\n  \"devDependencies\": {\n    \"vitest\": \"^0.34.0\",\n    \"eslint\": \"^8.0.0\",\n    \"prettier\": \"^3.0.0\",\n    \"storybook\": \"^7.0.0\"\n  }\n}\n</code></pre> JavaScript<pre><code>// frontend/vitest.config.js\nimport { defineConfig } from 'vitest/config';\n\nexport default defineConfig({\n  test: {\n    environment: 'jsdom',\n    coverage: {\n      provider: 'v8',\n      reporter: ['text', 'json', 'html', 'lcov'],\n      exclude: [\n        'node_modules/',\n        'dist/',\n        'src/**/*.stories.jsx'\n      ],\n      all: true,\n      lines: 80,\n      functions: 80,\n      branches: 80,\n      statements: 80\n    }\n  }\n});\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#tests-e2e","title":"\ud83e\uddea Tests E2E","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap07/#configuration-de-playwright","title":"Configuration de Playwright","text":"<p>Les tests E2E valident l'int\u00e9gration compl\u00e8te de l'application en simulant les actions utilisateur[2][3]:</p> YAML<pre><code>name: Tests E2E\n\non:\n  push:\n    branches:\n      - main\n      - develop\n  pull_request:\n    branches:\n      - main\n  schedule:\n    - cron: '0 2 * * *'  # Ex\u00e9cution quotidienne \u00e0 2h du matin\n  workflow_dispatch:\n\njobs:\n  e2e:\n    name: Tests E2E Playwright\n    runs-on: ubuntu-latest\n    timeout-minutes: 60\n\n    services:\n      backend:\n        image: ghcr.io/${{ github.repository }}/backend:${{ github.sha }}\n        ports:\n          - 3000:3000\n        env:\n          DATABASE_URL: postgresql://postgres:postgres@postgres:5432/test_db\n          REDIS_URL: redis://redis:6379\n          NODE_ENV: test\n\n      postgres:\n        image: postgres:15-alpine\n        env:\n          POSTGRES_PASSWORD: postgres\n          POSTGRES_DB: test_db\n        options: &gt;-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n\n      redis:\n        image: redis:7-alpine\n        options: &gt;-\n          --health-cmd \"redis-cli ping\"\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n\n    strategy:\n      fail-fast: false\n      matrix:\n        browser:\n          - chromium\n          - firefox\n          - webkit\n        shardIndex: [1, 2, 3]\n        shardTotal: [3]\n\n    steps:\n      - name: V\u00e9rifier le code\n        uses: actions/checkout@v3\n\n      - name: Configurer Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n          cache: 'npm'\n          cache-dependency-path: e2e/package-lock.json\n\n      - name: Installer les d\u00e9pendances\n        run: |\n          cd e2e\n          npm ci\n\n      - name: Installer les navigateurs Playwright\n        run: |\n          cd e2e\n          npx playwright install ${{ matrix.browser }}\n\n      - name: Attendre que le backend soit pr\u00eat\n        run: |\n          until curl -s http://localhost:3000/health; do\n            echo 'Backend en d\u00e9marrage...'\n            sleep 1\n          done\n\n      - name: Ex\u00e9cuter les tests E2E\n        run: |\n          cd e2e\n          npx playwright test \\\n            --project=${{ matrix.browser }} \\\n            --shard=${{ matrix.shardIndex }}/${{ matrix.shardTotal }}\n\n      - name: T\u00e9l\u00e9charger les r\u00e9sultats\n        if: always()\n        uses: actions/upload-artifact@v3\n        with:\n          name: playwright-report-${{ matrix.browser }}-${{ matrix.shardIndex }}\n          path: e2e/playwright-report/\n          retention-days: 30\n\n      - name: T\u00e9l\u00e9charger les vid\u00e9os de test\n        if: failure()\n        uses: actions/upload-artifact@v3\n        with:\n          name: e2e-videos-${{ matrix.browser }}-${{ matrix.shardIndex }}\n          path: e2e/test-results/\n          retention-days: 7\n\n  merge-reports:\n    name: Fusionner les Rapports E2E\n    if: always()\n    needs: e2e\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: V\u00e9rifier le code\n        uses: actions/checkout@v3\n\n      - name: Configurer Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n          cache: 'npm'\n          cache-dependency-path: e2e/package-lock.json\n\n      - name: Installer les d\u00e9pendances\n        run: |\n          cd e2e\n          npm ci\n\n      - name: T\u00e9l\u00e9charger les artifacts\n        uses: actions/download-artifact@v3\n        with:\n          path: e2e/all-reports\n          pattern: playwright-report-*\n\n      - name: Fusionner les rapports\n        run: |\n          cd e2e\n          npx playwright merge-reports --reporter html ./all-reports\n\n      - name: T\u00e9l\u00e9charger le rapport fusionn\u00e9\n        uses: actions/upload-artifact@v3\n        with:\n          name: playwright-report-merged\n          path: e2e/playwright-report/\n          retention-days: 30\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#configuration-playwright","title":"Configuration Playwright","text":"JavaScript<pre><code>// e2e/playwright.config.js\nimport { defineConfig, devices } from '@playwright/test';\n\nexport default defineConfig({\n  testDir: './tests',\n  fullyParallel: true,\n  forbidOnly: !!process.env.CI,\n  retries: process.env.CI ? 2 : 0,\n  workers: process.env.CI ? 1 : undefined,\n  reporter: [\n    ['html'],\n    ['json', { outputFile: 'test-results/results.json' }],\n    ['junit', { outputFile: 'test-results/junit.xml' }]\n  ],\n  use: {\n    baseURL: 'http://localhost:3000',\n    trace: 'on-first-retry',\n    screenshot: 'only-on-failure',\n    video: 'retain-on-failure'\n  },\n  projects: [\n    { name: 'chromium', use: { ...devices['Desktop Chrome'] } },\n    { name: 'firefox', use: { ...devices['Desktop Firefox'] } },\n    { name: 'webkit', use: { ...devices['Desktop Safari'] } }\n  ],\n  webServer: {\n    command: 'npm run dev',\n    url: 'http://localhost:3000',\n    reuseExistingServer: !process.env.CI,\n    timeout: 120000\n  }\n});\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#exemple-de-test-e2e","title":"Exemple de Test E2E","text":"JavaScript<pre><code>// e2e/tests/login.spec.js\nimport { test, expect } from '@playwright/test';\n\ntest.describe('Authentification', () =&gt; {\n  test('Login avec des identifiants valides', async ({ page }) =&gt; {\n    await page.goto('/login');\n\n    await page.fill('input[name=\"email\"]', 'user@example.com');\n    await page.fill('input[name=\"password\"]', 'password123');\n    await page.click('button[type=\"submit\"]');\n\n    await expect(page).toHaveURL('/dashboard');\n    await expect(page.locator('text=Bienvenue')).toBeVisible();\n  });\n\n  test('Login avec identifiants invalides', async ({ page }) =&gt; {\n    await page.goto('/login');\n\n    await page.fill('input[name=\"email\"]', 'invalid@example.com');\n    await page.fill('input[name=\"password\"]', 'wrongpassword');\n    await page.click('button[type=\"submit\"]');\n\n    await expect(page.locator('text=Identifiants invalides')).toBeVisible();\n  });\n});\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#couverture-du-code-e2e","title":"\ud83d\udcc8 Couverture du Code E2E","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap07/#configuration-de-la-couverture-e2e","title":"Configuration de la Couverture E2E","text":"<p>Int\u00e9grer la couverture de code E2E dans le processus CI/CD:</p> YAML<pre><code>name: Couverture E2E\n\non:\n  push:\n    branches:\n      - main\n  workflow_run:\n    workflows: [\"Tests E2E\"]\n    types: [completed]\n\njobs:\n  coverage:\n    name: Rapport de Couverture E2E\n    runs-on: ubuntu-latest\n    if: ${{ github.event.workflow_run.conclusion == 'success' }}\n\n    steps:\n      - name: V\u00e9rifier le code\n        uses: actions/checkout@v3\n\n      - name: Configurer Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n          cache: 'npm'\n          cache-dependency-path: e2e/package-lock.json\n\n      - name: T\u00e9l\u00e9charger les r\u00e9sultats E2E\n        uses: actions/download-artifact@v3\n        with:\n          name: e2e-coverage\n          path: e2e/coverage\n\n      - name: G\u00e9n\u00e9rer le rapport de couverture\n        run: |\n          cd e2e\n          npm run coverage:report\n\n      - name: T\u00e9l\u00e9charger le rapport\n        uses: actions/upload-artifact@v3\n        with:\n          name: e2e-coverage-report\n          path: e2e/coverage/index.html\n\n      - name: Commenter la PR avec les r\u00e9sultats\n        uses: actions/github-script@v6\n        if: github.event_name == 'pull_request'\n        with:\n          script: |\n            const fs = require('fs');\n            const coverage = JSON.parse(fs.readFileSync('e2e/coverage/coverage-summary.json', 'utf8'));\n            const comment = `## \ud83d\udcca Couverture E2E\n\n            - **Lignes**: ${coverage.total.lines.pct}%\n            - **Branches**: ${coverage.total.branches.pct}%\n            - **Fonctions**: ${coverage.total.functions.pct}%\n            - **D\u00e9clarations**: ${coverage.total.statements.pct}%\n            `;\n            github.rest.issues.createComment({\n              issue_number: context.issue.number,\n              owner: context.repo.owner,\n              repo: context.repo.repo,\n              body: comment\n            });\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#execution-multi-navigateurs","title":"\ud83c\udf10 Ex\u00e9cution Multi-Navigateurs","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap07/#configuration-multi-navigateurs-avancee","title":"Configuration Multi-Navigateurs Avanc\u00e9e","text":"<p>L'ex\u00e9cution des tests sur plusieurs navigateurs garantit la compatibilit\u00e9 cross-browser:</p> YAML<pre><code>name: Tests Multi-Navigateurs\n\non:\n  push:\n    branches:\n      - main\n      - develop\n  pull_request:\n    branches:\n      - main\n  schedule:\n    - cron: '0 0 * * 1'  # Ex\u00e9cution hebdomadaire le lundi\n\njobs:\n  setup:\n    name: Pr\u00e9parer les Tests\n    runs-on: ubuntu-latest\n    outputs:\n      matrix: ${{ steps.set-matrix.outputs.matrix }}\n\n    steps:\n      - name: D\u00e9finir la matrice de test\n        id: set-matrix\n        run: |\n          if [[ \"${{ github.event_name }}\" == \"schedule\" ]]; then\n            echo \"matrix={\\\"browser\\\":[\\\"chromium\\\",\\\"firefox\\\",\\\"webkit\\\",\\\"edge\\\"]}\" &gt;&gt; $GITHUB_OUTPUT\n          else\n            echo \"matrix={\\\"browser\\\":[\\\"chromium\\\",\\\"firefox\\\",\\\"webkit\\\"]}\" &gt;&gt; $GITHUB_OUTPUT\n          fi\n\n  test:\n    name: Test ${{ matrix.browser }}\n    needs: setup\n    runs-on: ${{ matrix.os }}\n    timeout-minutes: 30\n\n    strategy:\n      fail-fast: false\n      matrix:\n        include:\n          - browser: chromium\n            os: ubuntu-latest\n          - browser: firefox\n            os: ubuntu-latest\n          - browser: webkit\n            os: ubuntu-latest\n          - browser: edge\n            os: windows-latest\n\n    steps:\n      - name: V\u00e9rifier le code\n        uses: actions/checkout@v3\n\n      - name: Configurer Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n          cache: 'npm'\n          cache-dependency-path: e2e/package-lock.json\n\n      - name: Installer les d\u00e9pendances\n        run: |\n          cd e2e\n          npm ci\n\n      - name: Installer le navigateur ${{ matrix.browser }}\n        run: |\n          cd e2e\n          npx playwright install ${{ matrix.browser }}\n\n      - name: Ex\u00e9cuter les tests sur ${{ matrix.browser }}\n        run: |\n          cd e2e\n          npx playwright test --project=${{ matrix.browser }}\n        env:\n          BROWSER: ${{ matrix.browser }}\n\n      - name: T\u00e9l\u00e9charger le rapport\n        if: always()\n        uses: actions/upload-artifact@v3\n        with:\n          name: report-${{ matrix.browser }}-${{ matrix.os }}\n          path: e2e/playwright-report/\n          retention-days: 30\n\n      - name: Publier les r\u00e9sultats de test\n        uses: EnricoMi/publish-unit-test-result-action@v2\n        if: always()\n        with:\n          files: e2e/test-results/junit.xml\n          check_name: Tests ${{ matrix.browser }}\n\n  compatibility-report:\n    name: G\u00e9n\u00e9rer un Rapport de Compatibilit\u00e9\n    if: always()\n    needs: test\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: V\u00e9rifier le code\n        uses: actions/checkout@v3\n\n      - name: Configurer Node.js\n        uses: actions/setup-node@v3\n        with:\n          node-version: '18'\n\n      - name: T\u00e9l\u00e9charger tous les rapports\n        uses: actions/download-artifact@v3\n\n      - name: G\u00e9n\u00e9rer le rapport de compatibilit\u00e9\n        run: |\n          node scripts/generate-compatibility-report.js\n\n      - name: T\u00e9l\u00e9charger le rapport final\n        uses: actions/upload-artifact@v3\n        with:\n          name: compatibility-report\n          path: compatibility-report.html\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#script-de-generation-de-rapport","title":"Script de G\u00e9n\u00e9ration de Rapport","text":"JavaScript<pre><code>// scripts/generate-compatibility-report.js\nconst fs = require('fs');\nconst path = require('path');\n\nconst browsers = ['chromium', 'firefox', 'webkit', 'edge'];\nconst results = {};\n\nbrowsers.forEach(browser =&gt; {\n  const resultFile = path.join(__dirname, `../report-${browser}-*/results.json`);\n  // Logique de lecture et agr\u00e9gation des r\u00e9sultats\n  results[browser] = {\n    passed: 0,\n    failed: 0,\n    skipped: 0\n  };\n});\n\nconst html = `\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n  &lt;title&gt;Rapport de Compatibilit\u00e9&lt;/title&gt;\n  &lt;style&gt;\n    body { font-family: Arial, sans-serif; padding: 20px; }\n    table { border-collapse: collapse; width: 100%; }\n    th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }\n    th { background-color: #4CAF50; color: white; }\n    .pass { color: green; }\n    .fail { color: red; }\n  &lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n  &lt;h1&gt;Rapport de Compatibilit\u00e9 Multi-Navigateurs&lt;/h1&gt;\n  &lt;table&gt;\n    &lt;tr&gt;\n      &lt;th&gt;Navigateur&lt;/th&gt;\n      &lt;th&gt;Tests R\u00e9ussis&lt;/th&gt;\n      &lt;th&gt;Tests \u00c9chou\u00e9s&lt;/th&gt;\n      &lt;th&gt;Tests Ignor\u00e9s&lt;/th&gt;\n      &lt;th&gt;Taux de R\u00e9ussite&lt;/th&gt;\n    &lt;/tr&gt;\n    ${Object.entries(results).map(([browser, data]) =&gt; {\n      const total = data.passed + data.failed + data.skipped;\n      const passRate = ((data.passed / total) * 100).toFixed(2);\n      return `\n        &lt;tr&gt;\n          &lt;td&gt;${browser}&lt;/td&gt;\n          &lt;td class=\"pass\"&gt;${data.passed}&lt;/td&gt;\n          &lt;td class=\"fail\"&gt;${data.failed}&lt;/td&gt;\n          &lt;td&gt;${data.skipped}&lt;/td&gt;\n          &lt;td&gt;${passRate}%&lt;/td&gt;\n        &lt;/tr&gt;\n      `;\n    }).join('')}\n  &lt;/table&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n`;\n\nfs.writeFileSync(path.join(__dirname, '../compatibility-report.html'), html);\nconsole.log('Rapport g\u00e9n\u00e9r\u00e9: compatibility-report.html');\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#pipeline-complet-et-integration","title":"\ud83d\udd04 Pipeline Complet et Int\u00e9gration","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap07/#orchestration-des-workflows","title":"Orchestration des Workflows","text":"<p>Pour une application fullstack compl\u00e8te, orchestrer tous les workflows:</p> YAML<pre><code>name: Pipeline Complet\n\non:\n  push:\n    branches:\n      - main\n      - develop\n  pull_request:\n    branches:\n      - main\n  workflow_dispatch:\n\njobs:\n  backend:\n    uses: ./.github/workflows/backend.yml\n    secrets: inherit\n\n  frontend:\n    uses: ./.github/workflows/frontend.yml\n    secrets: inherit\n\n  e2e:\n    needs: [backend, frontend]\n    uses: ./.github/workflows/e2e-tests.yml\n    secrets: inherit\n\n  multi-browser:\n    needs: [backend, frontend]\n    uses: ./.github/workflows/multi-browser-tests.yml\n    secrets: inherit\n\n  deploy:\n    if: github.ref == 'refs/heads/main' &amp;&amp; success()\n    needs: [backend, frontend, e2e, multi-browser]\n    uses: ./.github/workflows/deploy.yml\n    secrets: inherit\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap07/#notifications-et-rapports","title":"Notifications et Rapports","text":"<p>Ajouter des notifications pour suivre l'\u00e9tat du pipeline:</p> YAML<pre><code>  notify:\n    name: Notifier les R\u00e9sultats\n    if: always()\n    needs: [backend, frontend, e2e, multi-browser]\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: D\u00e9terminer le statut global\n        id: status\n        run: |\n          if [[ \"${{ needs.backend.result }}\" == \"failure\" ]] || \\\n             [[ \"${{ needs.frontend.result }}\" == \"failure\" ]] || \\\n             [[ \"${{ needs.e2e.result }}\" == \"failure\" ]]; then\n            echo \"status=failure\" &gt;&gt; $GITHUB_OUTPUT\n          else\n            echo \"status=success\" &gt;&gt; $GITHUB_OUTPUT\n          fi\n\n      - name: Envoyer une notification Slack\n        uses: slackapi/slack-github-action@v1\n        if: always()\n        with:\n          webhook-url: ${{ secrets.SLACK_WEBHOOK }}\n          payload: |\n            {\n              \"text\": \"Pipeline CI/CD - Statut: ${{ steps.status.outputs.status }}\",\n              \"blocks\": [\n                {\n                  \"type\": \"section\",\n                  \"text\": {\n                    \"type\": \"mrkdwn\",\n                    \"text\": \"*Pipeline CI/CD*\\nR\u00e9f\u00e9rence: ${{ github.ref }}\\nAuteur: ${{ github.actor }}\\nStatut: ${{ steps.status.outputs.status }}\"\n                  }\n                }\n              ]\n            }\n</code></pre> <p>Cette structure compl\u00e8te d'impl\u00e9mentation de GitHub Actions pour un projet fullstack fournit une fondation robuste pour l'automatisation, la qualit\u00e9 et le d\u00e9ploiement continu. L'adoption progressive de ces patterns garantit une fiabilit\u00e9 accrue du processus de d\u00e9veloppement et une meilleure exp\u00e9rience utilisateur[1][4][5][6].</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/","title":"Citations","text":"<ul> <li>https://docs.docker.com/build/ci/github-actions/test-before-push/</li> <li>https://event-driven.io/en/how_to_buid_and_push_docker_image_with_github_actions/</li> <li>https://github.com/docker/build-push-action</li> <li>https://docs.docker.com/build/ci/github-actions/</li> <li>https://runcloud.io/blog/setup-docker-github-actions-ci-cd</li> <li>https://docs.github.com/actions/creating-actions/creating-a-docker-container-action</li> <li>https://dev.to/sahanonp/setup-docker-for-integration-testing-in-github-action-39fn</li> <li>https://docs.github.com/actions/using-jobs/running-jobs-in-a-container</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 309</li> <li>completion_tokens: 9714</li> <li>total_tokens: 10023</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.146, 'request_cost': 0.006, 'total_cost': 0.153}</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#content","title":"Content","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap08/#projet-2-github-actions-formation-complete","title":"Projet 2 - GitHub Actions : Formation Compl\u00e8te","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap08/#presentation-du-projet-et-github-container-registry","title":"Pr\u00e9sentation du projet et GitHub Container Registry","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap08/#vue-densemble-du-projet","title":"Vue d'ensemble du projet","text":"<p>GitHub Actions constitue une plateforme CI/CD (Int\u00e9gration Continue / D\u00e9ploiement Continu) native int\u00e9gr\u00e9e directement dans GitHub, permettant d'automatiser les workflows de build, test et d\u00e9ploiement. Ce projet s'articule autour de la containerisation d'applications avec Docker et leur orchestration via GitHub Actions, incluant le stockage des images dans GitHub Container Registry (GHCR).[1][4]</p> <p>GitHub Container Registry repr\u00e9sente un service de registre de conteneurs propos\u00e9 par GitHub dans le cadre de son \u00e9cosyst\u00e8me Packages. Contrairement \u00e0 Docker Hub, GHCR offre des avantages significatifs pour les projets commerciaux : support natif des images publiques et priv\u00e9es, int\u00e9gration transparente avec GitHub, pas de limitations de d\u00e9bit pour les utilisateurs authentifi\u00e9s, et stockage des artefacts directement li\u00e9s au r\u00e9f\u00e9rentiel.[2]</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#architecture-et-flux-de-travail","title":"Architecture et flux de travail","text":"<p>L'approche g\u00e9n\u00e9ralement adopt\u00e9e dans ce projet suit un processus structur\u00e9 :</p> <ul> <li>D\u00e9finition des workflows : Cr\u00e9ation de fichiers YAML dans le r\u00e9pertoire <code>.github/workflows/</code></li> <li>Triggers d'ex\u00e9cution : D\u00e9clenchement automatique lors de commits, pull requests ou \u00e9v\u00e9nements planifi\u00e9s</li> <li>Construction d'images : Compilation du Dockerfile avec Docker Buildx</li> <li>Validation : Ex\u00e9cution de tests avant publication</li> <li>Publication : Pouss\u00e9e vers GHCR et/ou Docker Hub</li> <li>D\u00e9ploiement : Orchestration avec Docker Compose en environnements multiples</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#configuration-initiale-de-github-container-registry","title":"Configuration initiale de GitHub Container Registry","text":"<p>Avant de publier des images, une configuration pr\u00e9alable est n\u00e9cessaire :[2]</p> <ol> <li>Acc\u00e8s aux param\u00e8tres de secrets GitHub : <code>Settings =&gt; Secrets and variables =&gt; Actions</code></li> <li>Cr\u00e9ation des secrets n\u00e9cessaires pour l'authentification :</li> <li><code>GHCR_TOKEN</code> : Token d'authentification GitHub</li> <li> <p><code>DOCKERHUB_USERNAME</code> et <code>DOCKERHUB_TOKEN</code> : Identifiants Docker Hub (optionnel)</p> </li> <li> <p>Activation des permissions du workflow dans <code>Settings =&gt; Actions =&gt; General</code>, en veillant \u00e0 accorder les droits <code>write:packages</code> pour permettre \u00e0 GitHub Actions de publier des images.</p> </li> </ol>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#creation-des-images-et-push-manuel","title":"Cr\u00e9ation des images et push manuel","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap08/#processus-de-creation-manuelle","title":"Processus de cr\u00e9ation manuelle","text":"<p>La cr\u00e9ation manuelle d'images Docker constitue l'\u00e9tape pr\u00e9alable \u00e0 l'automatisation par GitHub Actions. Cette approche didactique permet de comprendre les m\u00e9canismes sous-jacents avant leur orchestration.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#structure-dun-dockerfile-optimal","title":"Structure d'un Dockerfile optimal","text":"<p>Un Dockerfile bien con\u00e7u doit privil\u00e9gier la l\u00e9g\u00e8ret\u00e9 et les meilleures pratiques de s\u00e9curit\u00e9 :</p> Docker<pre><code># \u00c9tape de construction\nFROM node:18-alpine AS builder\n\nWORKDIR /app\n\nCOPY package*.json ./\nRUN npm ci --only=production\n\n# \u00c9tape finale (multi-stage build)\nFROM node:18-alpine\n\nWORKDIR /app\n\n# Cr\u00e9er un utilisateur non-root\nRUN addgroup -g 1001 -S nodejs &amp;&amp; adduser -S nodejs -u 1001\n\n# Copier uniquement les d\u00e9pendances du builder\nCOPY --from=builder --chown=nodejs:nodejs /app/node_modules ./node_modules\nCOPY --chown=nodejs:nodejs . .\n\nUSER nodejs\n\nEXPOSE 3000\n\nCMD [\"node\", \"server.js\"]\n</code></pre> <p>Cet exemple illustre plusieurs principes essentiels :</p> <ul> <li>Multi-stage builds : R\u00e9duction de la taille finale en n'incluant que les artefacts n\u00e9cessaires</li> <li>Utilisateur non-root : Am\u00e9lioration de la s\u00e9curit\u00e9 en \u00e9vitant l'ex\u00e9cution en tant que root</li> <li>Alpine Linux : Base minimale r\u00e9duisant significativement la taille de l'image</li> <li>Gestion des d\u00e9pendances : Installation en \u00e9tape s\u00e9par\u00e9e pour optimiser le cache Docker</li> </ul>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#commandes-de-push-manuel","title":"Commandes de push manuel","text":"<p>Le push manuel s'effectue via des commandes CLI Docker :</p> Bash<pre><code># Authentification aupr\u00e8s de GitHub Container Registry\necho $GHCR_TOKEN | docker login ghcr.io -u USERNAME --password-stdin\n\n# Construction de l'image locale\ndocker build -t ghcr.io/username/project-name:v1.0.0 .\n\n# Tagging suppl\u00e9mentaires\ndocker tag ghcr.io/username/project-name:v1.0.0 ghcr.io/username/project-name:latest\n\n# Push de l'image\ndocker push ghcr.io/username/project-name:v1.0.0\ndocker push ghcr.io/username/project-name:latest\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#verification-et-gestion-des-images","title":"V\u00e9rification et gestion des images","text":"<p>Apr\u00e8s le push, il est important de v\u00e9rifier que l'image est correctement stock\u00e9e et accessible :</p> Bash<pre><code># Lister les images locales\ndocker images | grep ghcr.io\n\n# Tirer l'image du registre pour v\u00e9rification\ndocker pull ghcr.io/username/project-name:latest\n\n# Inspecter les m\u00e9tadonn\u00e9es de l'image\ndocker inspect ghcr.io/username/project-name:latest\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#construction-et-push-des-images-dans-le-workflow","title":"Construction et push des images dans le workflow","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap08/#architecture-dun-workflow-github-actions","title":"Architecture d'un workflow GitHub Actions","text":"<p>Les workflows GitHub Actions s'articulent autour de fichiers YAML d\u00e9finissant les \u00e9tapes d'ex\u00e9cution. La structure g\u00e9n\u00e9rale comprend :[1][3]</p> YAML<pre><code>name: Build and Publish Docker Image\n\non:\n  push:\n    branches:\n      - main\n      - develop\n  pull_request:\n    branches:\n      - main\n\njobs:\n  build-and-push:\n    runs-on: ubuntu-latest\n\n    permissions:\n      contents: read\n      packages: write\n\n    steps:\n      # \u00c9tapes d'ex\u00e9cution\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#detail-des-etapes-du-workflow","title":"D\u00e9tail des \u00e9tapes du workflow","text":"<p>\u00c9tape 1 : Checkout du code</p> YAML<pre><code>- name: Checkout repository\n  uses: actions/checkout@v4\n</code></pre> <p>Cette \u00e9tape clone le code du r\u00e9f\u00e9rentiel dans l'environnement d'ex\u00e9cution, rendant accessibles le Dockerfile et les sources.</p> <p>\u00c9tape 2 : Configuration de Docker Buildx</p> YAML<pre><code>- name: Set up Docker Buildx\n  uses: docker/setup-buildx-action@v3\n  with:\n    version: latest\n    buildkitd-flags: --allow-insecure-entitlement security.insecure\n</code></pre> <p>Docker Buildx \u00e9tend les capacit\u00e9s de Docker build en int\u00e9grant BuildKit, permettant les builds multi-plateforme et des optimisations avanc\u00e9es.[3]</p> <p>\u00c9tape 3 : Configuration QEMU (pour builds multi-plateforme)</p> YAML<pre><code>- name: Set up QEMU\n  uses: docker/setup-qemu-action@v3\n</code></pre> <p>QEMU permet l'\u00e9mulation d'architectures diff\u00e9rentes (arm64, arm/v7, etc.), essentiel pour construire des images compatibles avec divers environnements.</p> <p>\u00c9tape 4 : Extraction des m\u00e9tadonn\u00e9es</p> YAML<pre><code>- name: Extract metadata\n  id: meta\n  uses: docker/metadata-action@v5\n  with:\n    images: ghcr.io/${{ github.repository }}\n    tags: |\n      type=ref,event=branch\n      type=semver,pattern={{version}}\n      type=semver,pattern={{major}}.{{minor}}\n      type=sha,prefix={{branch}}-\n</code></pre> <p>Cette action g\u00e9n\u00e8re automatiquement des tags coh\u00e9rents bas\u00e9s sur les \u00e9v\u00e9nements Git (branches, tags, commits).</p> <p>\u00c9tape 5 : Authentification aupr\u00e8s des registres</p> YAML<pre><code>- name: Login to GitHub Container Registry\n  uses: docker/login-action@v3\n  with:\n    registry: ghcr.io\n    username: ${{ github.actor }}\n    password: ${{ secrets.GITHUB_TOKEN }}\n\n- name: Login to Docker Hub\n  uses: docker/login-action@v3\n  with:\n    username: ${{ secrets.DOCKERHUB_USERNAME }}\n    password: ${{ secrets.DOCKERHUB_TOKEN }}\n</code></pre> <p>L'authentification utilise les secrets configur\u00e9s dans les param\u00e8tres du r\u00e9f\u00e9rentiel, assurant la s\u00e9curit\u00e9 des credentials.</p> <p>\u00c9tape 6 : Build et push vers les registres</p> YAML<pre><code>- name: Build and push Docker images\n  uses: docker/build-push-action@v6\n  with:\n    context: .\n    file: ./Dockerfile\n    push: ${{ github.ref == 'refs/heads/main' }}\n    tags: ${{ steps.meta.outputs.tags }}\n    labels: ${{ steps.meta.outputs.labels }}\n    cache-from: type=gha\n    cache-to: type=gha,mode=max\n    platforms: linux/amd64,linux/arm64\n</code></pre> <p>Param\u00e8tres cl\u00e9s :[3]</p> Param\u00e8tre Description Valeur typique <code>context</code> R\u00e9pertoire contenant les sources et Dockerfile <code>.</code> ou <code>./src</code> <code>file</code> Chemin vers le Dockerfile <code>./Dockerfile</code> <code>push</code> Activation conditionnelle du push <code>${{ github.ref == 'refs/heads/main' }}</code> <code>tags</code> Liste des tags \u00e0 appliquer G\u00e9n\u00e9r\u00e9s par m\u00e9tadonn\u00e9es <code>platforms</code> Architectures cibles <code>linux/amd64,linux/arm64</code> <code>cache-from</code> Source du cache de build <code>type=gha</code> pour GitHub Actions"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#workflow-complet-avec-multi-registres","title":"Workflow complet avec multi-registres","text":"YAML<pre><code>name: Build, Test and Publish\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\nenv:\n  REGISTRY_GHCR: ghcr.io\n  REGISTRY_DOCKERHUB: docker.io\n  IMAGE_NAME: ${{ github.repository }}\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    permissions:\n      contents: read\n      packages: write\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n        with:\n          fetch-depth: 0\n\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v3\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n\n      - name: Log in to GHCR\n        uses: docker/login-action@v3\n        with:\n          registry: ${{ env.REGISTRY_GHCR }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Log in to Docker Hub\n        uses: docker/login-action@v3\n        with:\n          registry: ${{ env.REGISTRY_DOCKERHUB }}\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n\n      - name: Extract Docker metadata\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: |\n            ${{ env.REGISTRY_GHCR }}/${{ env.IMAGE_NAME }}\n            ${{ env.REGISTRY_DOCKERHUB }}/organisation/${{ github.event.repository.name }}\n          tags: |\n            type=ref,event=branch\n            type=semver,pattern={{version}}\n            type=sha\n\n      - name: Build and push\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          push: ${{ github.event_name != 'pull_request' }}\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          platforms: linux/amd64,linux/arm64,linux/arm/v7\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#tests-des-images-avant-le-push","title":"Tests des images avant le push","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap08/#importance-et-strategie-des-tests-pre-push","title":"Importance et strat\u00e9gie des tests pr\u00e9-push","text":"<p>La validation des images avant leur publication constitue une pratique critique pour assurer la qualit\u00e9 et la s\u00e9curit\u00e9.[1] Cette approche pr\u00e9vient la distribution d'images d\u00e9fectueuses ou vuln\u00e9rables dans les registres publics.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#export-de-limage-pour-test-local","title":"Export de l'image pour test local","text":"YAML<pre><code>- name: Build image (without push)\n  uses: docker/build-push-action@v6\n  with:\n    context: .\n    load: true\n    tags: app:test\n\n- name: Run image tests\n  run: |\n    docker run --rm app:test npm test\n    docker run --rm app:test npm run lint\n</code></pre> <p>L'option <code>load: true</code> exporte l'image dans le d\u00e9mon Docker local, permettant l'ex\u00e9cution de tests sans la publier.[1]</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#tests-de-sante-et-de-fonctionnalite","title":"Tests de sant\u00e9 et de fonctionnalit\u00e9","text":"YAML<pre><code>- name: Test image healthcheck\n  run: |\n    CONTAINER_ID=$(docker run -d --health-cmd='curl -f http://localhost:3000/health || exit 1' \\\n      --health-interval=10s \\\n      --health-timeout=5s \\\n      --health-retries=3 \\\n      app:test)\n\n    # Attendre la stabilit\u00e9 du conteneur\n    sleep 15\n\n    # V\u00e9rifier le statut\n    docker inspect --format='{{.State.Health.Status}}' $CONTAINER_ID\n\n    docker stop $CONTAINER_ID\n</code></pre> <p>Les healthchecks permettent de valider que le service d\u00e9marre correctement et r\u00e9pond aux requ\u00eates.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#scan-de-securite-et-vulnerabilites","title":"Scan de s\u00e9curit\u00e9 et vuln\u00e9rabilit\u00e9s","text":"YAML<pre><code>- name: Scan image for vulnerabilities\n  uses: aquasecurity/trivy-action@master\n  with:\n    image-ref: app:test\n    format: 'sarif'\n    output: 'trivy-results.sarif'\n    severity: 'CRITICAL,HIGH'\n\n- name: Upload Trivy results to GitHub Security tab\n  uses: github/codeql-action/upload-sarif@v2\n  with:\n    sarif_file: 'trivy-results.sarif'\n</code></pre> <p>Trivy analyse l'image pour d\u00e9tecter les vuln\u00e9rabilit\u00e9s connues, am\u00e9liorant la posture de s\u00e9curit\u00e9 avant la publication.[5]</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#workflow-complet-avec-tests-integres","title":"Workflow complet avec tests int\u00e9gr\u00e9s","text":"YAML<pre><code>name: Build, Test and Publish with Security Scan\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  test-and-build:\n    runs-on: ubuntu-latest\n\n    permissions:\n      contents: read\n      packages: write\n      security-events: write\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n\n      - name: Build image for testing\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          load: true\n          tags: myapp:test\n          cache-from: type=gha\n\n      - name: Run unit tests\n        run: |\n          docker run --rm \\\n            -v ${{ github.workspace }}/coverage:/app/coverage \\\n            myapp:test \\\n            npm run test:unit\n\n      - name: Run integration tests\n        run: |\n          docker run --rm \\\n            --network host \\\n            myapp:test \\\n            npm run test:integration\n\n      - name: Scan for vulnerabilities\n        uses: aquasecurity/trivy-action@master\n        with:\n          image-ref: myapp:test\n          format: 'table'\n          exit-code: '1'\n          ignore-unfixed: true\n          vuln-type: 'os,library'\n          severity: 'CRITICAL,HIGH'\n\n      - name: Set up QEMU\n        uses: docker/setup-qemu-action@v3\n\n      - name: Login to GHCR\n        if: github.event_name != 'pull_request'\n        uses: docker/login-action@v3\n        with:\n          registry: ghcr.io\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Build and push\n        if: github.event_name != 'pull_request'\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          push: true\n          tags: ghcr.io/${{ github.repository }}:latest\n          platforms: linux/amd64,linux/arm64\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#tests-e2e-end-to-end","title":"Tests E2E (End-to-End)","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap08/#architecture-des-tests-e2e-dans-github-actions","title":"Architecture des tests E2E dans GitHub Actions","text":"<p>Les tests E2E valident le fonctionnement complet de l'application en environnement proche de la production. Leur int\u00e9gration dans GitHub Actions garantit la qualit\u00e9 globale du d\u00e9ploiement.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#configuration-de-lenvironnement-de-test","title":"Configuration de l'environnement de test","text":"YAML<pre><code>- name: Start application stack\n  run: |\n    docker-compose \\\n      -f docker-compose.test.yml \\\n      -p test-stack \\\n      up -d\n\n- name: Wait for services to be healthy\n  run: |\n    timeout 60 bash -c 'until \\\n      docker inspect test-stack_app_1 | \\\n      grep -q \"\\\"Status\\\": \\\"healthy\\\"\"; do \\\n      sleep 5; done'\n</code></pre> <p>Docker Compose orchestre la cr\u00e9ation d'un stack complet avec l'application, les bases de donn\u00e9es et les d\u00e9pendances externes.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#execution-de-tests-playwrightcypress","title":"Ex\u00e9cution de tests Playwright/Cypress","text":"YAML<pre><code>- name: Run E2E tests with Playwright\n  uses: docker://mcr.microsoft.com/playwright:v1.40.1-jammy\n  with:\n    args: npx playwright test --project=chromium --project=firefox\n\n- name: Upload test artifacts\n  if: always()\n  uses: actions/upload-artifact@v3\n  with:\n    name: playwright-report\n    path: playwright-report/\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#gestion-des-donnees-de-test","title":"Gestion des donn\u00e9es de test","text":"YAML<pre><code>- name: Seed test database\n  run: |\n    docker-compose \\\n      -f docker-compose.test.yml \\\n      exec -T database \\\n      psql -U testuser -d testdb \\\n      -f /docker-entrypoint-initdb.d/seed.sql\n\n- name: Run E2E tests\n  run: |\n    docker-compose \\\n      -f docker-compose.test.yml \\\n      exec -T app \\\n      npm run test:e2e\n\n- name: Collect logs on failure\n  if: failure()\n  run: |\n    docker-compose \\\n      -f docker-compose.test.yml \\\n      logs &gt; test-logs.txt\n\n    docker-compose \\\n      -f docker-compose.test.yml \\\n      down\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#workflow-e2e-complet","title":"Workflow E2E complet","text":"YAML<pre><code>name: E2E Tests\n\non:\n  push:\n    branches: [main]\n  pull_request:\n    branches: [main]\n\njobs:\n  e2e-tests:\n    runs-on: ubuntu-latest\n\n    services:\n      postgres:\n        image: postgres:15-alpine\n        env:\n          POSTGRES_USER: testuser\n          POSTGRES_PASSWORD: testpass\n          POSTGRES_DB: testdb\n        options: &gt;-\n          --health-cmd pg_isready\n          --health-interval 10s\n          --health-timeout 5s\n          --health-retries 5\n        ports:\n          - 5432:5432\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Build application image\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          load: true\n          tags: app:e2e\n          cache-from: type=gha\n\n      - name: Start application\n        run: |\n          docker run -d \\\n            --name app-e2e \\\n            --network host \\\n            -e DATABASE_URL=postgresql://testuser:testpass@localhost/testdb \\\n            app:e2e\n\n      - name: Wait for application startup\n        run: |\n          timeout 30 bash -c 'until curl -f http://localhost:3000/health; do \\\n            sleep 2; done'\n\n      - name: Setup Node.js\n        uses: actions/setup-node@v4\n        with:\n          node-version: '18'\n\n      - name: Install Playwright dependencies\n        run: npx playwright install --with-deps\n\n      - name: Run E2E tests\n        run: npm run test:e2e\n        env:\n          BASE_URL: http://localhost:3000\n\n      - name: Upload test results\n        if: always()\n        uses: actions/upload-artifact@v3\n        with:\n          name: e2e-test-results\n          path: |\n            test-results/\n            playwright-report/\n\n      - name: Cleanup\n        if: always()\n        run: docker stop app-e2e &amp;&amp; docker rm app-e2e\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#deploiement-avec-docker-compose","title":"D\u00e9ploiement avec Docker Compose","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap08/#integration-docker-compose-dans-les-workflows","title":"Int\u00e9gration Docker Compose dans les workflows","text":"<p>Docker Compose simplifie l'orchestration de stacks multi-conteneurs, facilitant les d\u00e9ploiements reproductibles en environnements pr\u00e9-prod et production.</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#fichier-docker-composeyml-pour-production","title":"Fichier docker-compose.yml pour production","text":"YAML<pre><code>version: '3.9'\n\nservices:\n  app:\n    image: ghcr.io/organisation/app:${APP_VERSION}\n    container_name: app-prod\n    restart: unless-stopped\n    environment:\n      - NODE_ENV=production\n      - DATABASE_URL=postgresql://${DB_USER}:${DB_PASSWORD}@postgres:5432/${DB_NAME}\n      - REDIS_URL=redis://cache:6379\n    ports:\n      - \"3000:3000\"\n    depends_on:\n      postgres:\n        condition: service_healthy\n      cache:\n        condition: service_started\n    networks:\n      - app-network\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 40s\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n    volumes:\n      - app-logs:/app/logs\n\n  postgres:\n    image: postgres:15-alpine\n    container_name: postgres-prod\n    restart: unless-stopped\n    environment:\n      - POSTGRES_USER=${DB_USER}\n      - POSTGRES_PASSWORD=${DB_PASSWORD}\n      - POSTGRES_DB=${DB_NAME}\n    volumes:\n      - postgres-data:/var/lib/postgresql/data\n      - ./init-db.sql:/docker-entrypoint-initdb.d/init.sql\n    networks:\n      - app-network\n    healthcheck:\n      test: [\"CMD-SHELL\", \"pg_isready -U ${DB_USER}\"]\n      interval: 10s\n      timeout: 5s\n      retries: 5\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n\n  cache:\n    image: redis:7-alpine\n    container_name: redis-prod\n    restart: unless-stopped\n    command: redis-server --appendonly yes\n    volumes:\n      - redis-data:/data\n    networks:\n      - app-network\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n\n  nginx:\n    image: nginx:alpine\n    container_name: nginx-prod\n    restart: unless-stopped\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf:ro\n      - ./ssl:/etc/nginx/ssl:ro\n    depends_on:\n      - app\n    networks:\n      - app-network\n    logging:\n      driver: \"json-file\"\n      options:\n        max-size: \"10m\"\n\nvolumes:\n  postgres-data:\n  redis-data:\n  app-logs:\n\nnetworks:\n  app-network:\n    driver: bridge\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#workflow-de-deploiement-avec-docker-compose","title":"Workflow de d\u00e9ploiement avec Docker Compose","text":"YAML<pre><code>name: Deploy to Production\n\non:\n  push:\n    branches: [main]\n    tags:\n      - 'v*.*.*'\n  workflow_dispatch:\n    inputs:\n      environment:\n        description: 'Environment to deploy to'\n        required: true\n        default: 'production'\n        type: choice\n        options:\n          - staging\n          - production\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n\n    environment:\n      name: ${{ github.event.inputs.environment || 'production' }}\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Configure SSH\n        run: |\n          mkdir -p ~/.ssh\n          echo \"${{ secrets.DEPLOY_KEY }}\" &gt; ~/.ssh/deploy_key\n          chmod 600 ~/.ssh/deploy_key\n          ssh-keyscan -H ${{ secrets.DEPLOY_HOST }} &gt;&gt; ~/.ssh/known_hosts\n\n      - name: Extract version\n        id: version\n        run: |\n          if [[ \"${{ github.ref }}\" == refs/tags/* ]]; then\n            VERSION=${GITHUB_REF#refs/tags/}\n          else\n            VERSION=\"latest\"\n          fi\n          echo \"version=$VERSION\" &gt;&gt; $GITHUB_OUTPUT\n\n      - name: Deploy application\n        run: |\n          ssh -i ~/.ssh/deploy_key ${{ secrets.DEPLOY_USER }}@${{ secrets.DEPLOY_HOST }} &lt;&lt; 'EOF'\n          cd /opt/app\n\n          # T\u00e9l\u00e9charger les nouveaux fichiers de configuration\n          git pull origin main\n\n          # D\u00e9finir la version de l'image\n          export APP_VERSION=${{ steps.version.outputs.version }}\n          export DB_USER=${{ secrets.DB_USER }}\n          export DB_PASSWORD=${{ secrets.DB_PASSWORD }}\n          export DB_NAME=${{ secrets.DB_NAME }}\n\n          # Arr\u00eater les services actuels\n          docker-compose -f docker-compose.yml down\n\n          # Tirer les derni\u00e8res images\n          docker-compose -f docker-compose.yml pull\n\n          # D\u00e9marrer les services\n          docker-compose -f docker-compose.yml up -d\n\n          # V\u00e9rifier la sant\u00e9 de l'application\n          sleep 10\n          if ! curl -f http://localhost:3000/health; then\n            echo \"Health check failed\"\n            docker-compose -f docker-compose.yml logs\n            exit 1\n          fi\n\n          echo \"Deployment successful\"\n          EOF\n\n      - name: Notify deployment status\n        if: always()\n        uses: 8398a7/action-slack@v3\n        with:\n          status: ${{ job.status }}\n          text: 'Deployment to ${{ github.event.inputs.environment || \"production\" }} - Version: ${{ steps.version.outputs.version }}'\n          webhook_url: ${{ secrets.SLACK_WEBHOOK }}\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#environnements-multiples-pre-prod-production","title":"Environnements multiples : pr\u00e9-prod / production","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap08/#concept-et-implementation-des-environnements","title":"Concept et impl\u00e9mentation des environnements","text":"<p>GitHub Actions supporte nativement la gestion d'environnements distincts, permettant des configurations et des approbations diff\u00e9renci\u00e9es selon la cible de d\u00e9ploiement.[4]</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#configuration-des-environnements-dans-github","title":"Configuration des environnements dans GitHub","text":"<ol> <li>Acc\u00e9der \u00e0 <code>Settings =&gt; Environments</code></li> <li>Cr\u00e9er deux environnements : <code>staging</code> et <code>production</code></li> <li>Configurer pour chacun :</li> <li>Variables d'environnement sp\u00e9cifiques</li> <li>Reviewers obligatoires pour les d\u00e9ploiements en production</li> <li>D\u00e9lais d'attente de confirmation</li> <li>Secrets prot\u00e9g\u00e9s</li> </ol>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#workflow-multi-environnement","title":"Workflow multi-environnement","text":"YAML<pre><code>name: Build, Test and Deploy to Multiple Environments\n\non:\n  push:\n    branches: [main, develop]\n  pull_request:\n    branches: [main]\n\nenv:\n  REGISTRY: ghcr.io\n  IMAGE_NAME: ${{ github.repository }}\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n    outputs:\n      image-tag: ${{ steps.meta.outputs.version }}\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v3\n\n      - name: Log in to GHCR\n        uses: docker/login-action@v3\n        with:\n          registry: ${{ env.REGISTRY }}\n          username: ${{ github.actor }}\n          password: ${{ secrets.GITHUB_TOKEN }}\n\n      - name: Extract metadata\n        id: meta\n        uses: docker/metadata-action@v5\n        with:\n          images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}\n          tags: |\n            type=ref,event=branch\n            type=semver,pattern={{version}}\n            type=sha\n\n      - name: Build and push Docker image\n        uses: docker/build-push-action@v6\n        with:\n          context: .\n          push: true\n          tags: ${{ steps.meta.outputs.tags }}\n          labels: ${{ steps.meta.outputs.labels }}\n          cache-from: type=gha\n          cache-to: type=gha,mode=max\n\n  test:\n    runs-on: ubuntu-latest\n    needs: build\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Run tests\n        run: npm test\n\n  deploy-staging:\n    runs-on: ubuntu-latest\n    needs: [build, test]\n    if: github.ref == 'refs/heads/develop'\n    environment:\n      name: staging\n      url: https://staging.example.com\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Deploy to staging\n        env:\n          DEPLOY_HOST: ${{ secrets.STAGING_HOST }}\n          DEPLOY_USER: ${{ secrets.STAGING_USER }}\n          DEPLOY_KEY: ${{ secrets.STAGING_KEY }}\n          APP_VERSION: ${{ needs.build.outputs.image-tag }}\n        run: |\n          mkdir -p ~/.ssh\n          echo \"$DEPLOY_KEY\" &gt; ~/.ssh/deploy_key\n          chmod 600 ~/.ssh/deploy_key\n          ssh-keyscan -H $DEPLOY_HOST &gt;&gt; ~/.ssh/known_hosts\n\n          ssh -i ~/.ssh/deploy_key $DEPLOY_USER@$DEPLOY_HOST &lt;&lt; 'EOF'\n          cd /opt/app-staging\n          export IMAGE_TAG=$APP_VERSION\n          docker-compose pull\n          docker-compose up -d\n          EOF\n\n  deploy-production:\n    runs-on: ubuntu-latest\n    needs: [build, test]\n    if: github.ref == 'refs/heads/main'\n    environment:\n      name: production\n      url: https://app.example.com\n\n    steps:\n      - name: Checkout code\n        uses: actions/checkout@v4\n\n      - name: Request approval\n        run: echo \"Waiting for approval to deploy to production\"\n\n      - name: Deploy to production\n        env:\n          DEPLOY_HOST: ${{ secrets.PROD_HOST }}\n          DEPLOY_USER: ${{ secrets.PROD_USER }}\n          DEPLOY_KEY: ${{ secrets.PROD_KEY }}\n          APP_VERSION: ${{ needs.build.outputs.image-tag }}\n        run: |\n          mkdir -p ~/.ssh\n          echo \"$DEPLOY_KEY\" &gt; ~/.ssh/deploy_key\n          chmod 600 ~/.ssh/deploy_key\n          ssh-keyscan -H $DEPLOY_HOST &gt;&gt; ~/.ssh/known_hosts\n\n          ssh -i ~/.ssh/deploy_key $DEPLOY_USER@$DEPLOY_HOST &lt;&lt; 'EOF'\n          cd /opt/app\n          export IMAGE_TAG=$APP_VERSION\n\n          # Backup de l'\u00e9tat actuel\n          docker-compose ps &gt; /var/backups/compose-state-$(date +%s).txt\n\n          # Mise \u00e0 jour et red\u00e9ploiement\n          docker-compose pull\n          docker-compose up -d\n\n          # V\u00e9rification de sant\u00e9\n          sleep 15\n          if ! curl -f https://app.example.com/health; then\n            echo \"Health check failed, initiating rollback\"\n            git checkout HEAD~1 docker-compose.yml\n            docker-compose up -d\n            exit 1\n          fi\n          EOF\n\n      - name: Notify deployment\n        if: always()\n        uses: 8398a7/action-slack@v3\n        with:\n          status: ${{ job.status }}\n          text: 'Production deployment completed'\n          webhook_url: ${{ secrets.SLACK_WEBHOOK }}\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#gestion-des-secrets-par-environnement","title":"Gestion des secrets par environnement","text":"Environnement Secrets requis Utilisation Staging <code>STAGING_HOST</code>, <code>STAGING_USER</code>, <code>STAGING_KEY</code>, <code>STAGING_DB_*</code> D\u00e9ploiement en pr\u00e9-production Production <code>PROD_HOST</code>, <code>PROD_USER</code>, <code>PROD_KEY</code>, <code>PROD_DB_*</code> D\u00e9ploiement en production avec approbation"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#creer-une-action-personnalisee","title":"Cr\u00e9er une action personnalis\u00e9e","text":""},{"location":"_projects/_formation-github-actions/github-actions-chap08/#concepts-fondamentaux-des-actions-personnalisees","title":"Concepts fondamentaux des actions personnalis\u00e9es","text":"<p>Les actions personnalis\u00e9es permettent de packager de la logique r\u00e9utilisable et de la partager au sein des workflows. GitHub Actions supporte trois types d'actions : JavaScript, Docker container, et composite.[4][6]</p>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#type-1-action-docker-container","title":"Type 1 : Action Docker Container","text":"<p>Les actions Docker container offrent l'avantage de l'isolation et de la reproductibilit\u00e9 en ex\u00e9cutant du code dans un conteneur d\u00e9di\u00e9.</p> <p>Structure du r\u00e9pertoire</p> Text Only<pre><code>my-custom-action/\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 action.yml\n\u251c\u2500\u2500 entrypoint.sh\n\u2514\u2500\u2500 README.md\n</code></pre> <p>Fichier action.yml</p> YAML<pre><code>name: 'Build and Push Docker Image'\ndescription: 'Construire et pousser une image Docker avec tests pr\u00e9alables'\n\ninputs:\n  dockerfile:\n    description: 'Chemin vers le Dockerfile'\n    required: false\n    default: './Dockerfile'\n\n  registry:\n    description: 'Registre Docker cible'\n    required: true\n\n  image-name:\n    description: 'Nom de l''image Docker'\n    required: true\n\n  tags:\n    description: 'Tags de l''image (s\u00e9par\u00e9s par virgule)'\n    required: true\n\n  context:\n    description: 'Contexte de build'\n    required: false\n    default: '.'\n\n  platforms:\n    description: 'Plateformes cibles (ex: linux/amd64,linux/arm64)'\n    required: false\n    default: 'linux/amd64'\n\n  registry-username:\n    description: 'Utilisateur du registre'\n    required: true\n\n  registry-password:\n    description: 'Mot de passe du registre'\n    required: true\n\noutputs:\n  image-digest:\n    description: 'Digest de l''image construite'\n\n  image-size:\n    description: 'Taille de l''image en MB'\n\nruns:\n  using: 'docker'\n  image: 'docker://docker:latest'\n  entrypoint: '/entrypoint.sh'\n  env:\n    DOCKERFILE: ${{ inputs.dockerfile }}\n    REGISTRY: ${{ inputs.registry }}\n    IMAGE_NAME: ${{ inputs.image-name }}\n    TAGS: ${{ inputs.tags }}\n    CONTEXT: ${{ inputs.context }}\n    PLATFORMS: ${{ inputs.platforms }}\n    REGISTRY_USERNAME: ${{ inputs.registry-username }}\n    REGISTRY_PASSWORD: ${{ inputs.registry-password }}\n</code></pre> <p>Fichier Dockerfile pour l'action</p> Docker<pre><code>FROM docker:latest\n\nRUN apk add --no-cache \\\n    bash \\\n    curl \\\n    jq\n\nCOPY entrypoint.sh /entrypoint.sh\nRUN chmod +x /entrypoint.sh\n\nENTRYPOINT [\"/entrypoint.sh\"]\n</code></pre> <p>Fichier entrypoint.sh</p> Bash<pre><code>#!/bin/bash\nset -e\n\necho \"\ud83d\udd10 Authentification aupr\u00e8s du registre...\"\necho \"${REGISTRY_PASSWORD}\" | docker login -u \"${REGISTRY_USERNAME}\" --password-stdin \"${REGISTRY}\"\n\necho \"\ud83d\udd28 Construction de l'image Docker...\"\ndocker build \\\n  -f \"${DOCKERFILE}\" \\\n  -t temp-image:build \\\n  \"${CONTEXT}\"\n\necho \"\ud83d\udce6 Tagging de l'image...\"\nIFS=',' read -ra TAG_ARRAY &lt;&lt;&lt; \"$TAGS\"\nfor tag in \"${TAG_ARRAY[@]}\"; do\n  docker tag temp-image:build \"${REGISTRY}/${IMAGE_NAME}:${tag}\"\ndone\n\necho \"\ud83d\udce4 Pouss\u00e9e de l'image...\"\nfor tag in \"${TAG_ARRAY[@]}\"; do\n  docker push \"${REGISTRY}/${IMAGE_NAME}:${tag}\"\ndone\n\necho \"\ud83d\udcca Calcul de l'information de l'image...\"\nDIGEST=$(docker inspect --format='{{.RepoDigests}}' \"${REGISTRY}/${IMAGE_NAME}:${TAG_ARRAY[0]}\" | jq -r '.[0]')\nSIZE=$(docker inspect --format='{{.Size}}' temp-image:build | awk '{printf \"%.2f\", $1/1048576}')\n\necho \"image-digest=${DIGEST}\" &gt;&gt; $GITHUB_OUTPUT\necho \"image-size=${SIZE}\" &gt;&gt; $GITHUB_OUTPUT\n\necho \"\u2705 Action compl\u00e9t\u00e9e avec succ\u00e8s\"\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#utilisation-de-laction-personnalisee-docker","title":"Utilisation de l'action personnalis\u00e9e Docker","text":"YAML<pre><code>- name: Build and Push Docker Image\n  uses: ./my-custom-action\n  with:\n    dockerfile: './Dockerfile'\n    registry: 'ghcr.io'\n    image-name: 'organisation/app'\n    tags: 'v1.0.0,latest'\n    context: '.'\n    platforms: 'linux/amd64,linux/arm64'\n    registry-username: ${{ github.actor }}\n    registry-password: ${{ secrets.GITHUB_TOKEN }}\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#type-2-action-composite","title":"Type 2 : Action Composite","text":"<p>Les actions composite permettent de combiner plusieurs actions existantes pour cr\u00e9er un workflow r\u00e9utilisable sans surcharge de conteneur.</p> <p>Structure action.yml pour composite</p> YAML<pre><code>name: 'Test and Publish Composite Action'\ndescription: 'Tester l''application et publier en cas de succ\u00e8s'\n\ninputs:\n  node-version:\n    description: 'Version de Node.js'\n    required: false\n    default: '18'\n\n  registry:\n    description: 'Registre Docker'\n    required: true\n\n  image-name:\n    description: 'Nom de l''image'\n    required: true\n\n  github-token:\n    description: 'Token GitHub'\n    required: true\n\noutputs:\n  test-results:\n    description: 'R\u00e9sultats des tests'\n    value: ${{ steps.test.outputs.results }}\n\n  image-published:\n    description: 'Indicateur de publication'\n    value: ${{ steps.publish.outputs.published }}\n\nruns:\n  using: 'composite'\n\n  steps:\n    - name: Setup Node.js\n      uses: actions/setup-node@v4\n      with:\n        node-version: ${{ inputs.node-version }}\n\n    - name: Install dependencies\n      run: npm ci\n      shell: bash\n\n    - name: Run tests\n      id: test\n      run: |\n        npm test\n        echo \"results=success\" &gt;&gt; $GITHUB_OUTPUT\n      shell: bash\n\n    - name: Set up Docker Buildx\n      uses: docker/setup-buildx-action@v3\n\n    - name: Login to registry\n      uses: docker/login-action@v3\n      with:\n        registry: ${{ inputs.registry }}\n        username: ${{ github.actor }}\n        password: ${{ inputs.github-token }}\n\n    - name: Build and push\n      id: publish\n      uses: docker/build-push-action@v6\n      with:\n        context: .\n        push: true\n        tags: ${{ inputs.registry }}/${{ inputs.image-name }}:latest\n\n    - name: Output publication result\n      run: echo \"published=true\" &gt;&gt; $GITHUB_OUTPUT\n      shell: bash\n</code></pre> <p>Utilisation de l'action composite</p> YAML<pre><code>- name: Test and Publish\n  uses: ./test-and-publish-action\n  with:\n    node-version: '18'\n    registry: 'ghcr.io'\n    image-name: ${{ github.repository }}\n    github-token: ${{ secrets.GITHUB_TOKEN }}\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#type-3-action-javascript","title":"Type 3 : Action JavaScript","text":"<p>Les actions JavaScript s'ex\u00e9cutent directement sans conteneur, offrant une performance sup\u00e9rieure.</p> <p>Structure du r\u00e9pertoire</p> Text Only<pre><code>js-action/\n\u251c\u2500\u2500 action.yml\n\u251c\u2500\u2500 index.js\n\u251c\u2500\u2500 package.json\n\u2514\u2500\u2500 README.md\n</code></pre> <p>Fichier package.json</p> JSON<pre><code>{\n  \"name\": \"scan-image-action\",\n  \"version\": \"1.0.0\",\n  \"description\": \"Scanner une image Docker pour les vuln\u00e9rabilit\u00e9s\",\n  \"main\": \"index.js\",\n  \"dependencies\": {\n    \"@actions/core\": \"^1.10.0\",\n    \"@actions/exec\": \"^1.1.1\",\n    \"axios\": \"^1.6.0\"\n  }\n}\n</code></pre> <p>Fichier index.js</p> JavaScript<pre><code>const core = require('@actions/core');\nconst exec = require('@actions/exec');\nconst axios = require('axios');\n\nasync function run() {\n  try {\n    const imageRef = core.getInput('image-ref');\n    const severity = core.getInput('severity');\n    const failOnVulnerabilities = core.getInput('fail-on-vulnerabilities');\n\n    core.info(`\ud83d\udd0d Scanning image: ${imageRef}`);\n\n    // Ex\u00e9cuter Trivy pour scanner l'image\n    let vulnerabilityCount = 0;\n    const options = {\n      listeners: {\n        stdout: (data) =&gt; {\n          const output = data.toString();\n          // Parser la sortie et compter les vuln\u00e9rabilit\u00e9s\n          if (output.includes(severity)) {\n            vulnerabilityCount++;\n          }\n        }\n      }\n    };\n\n    await exec.exec('trivy', ['image', '--severity', severity, imageRef], options);\n\n    core.setOutput('vulnerability-count', vulnerabilityCount.toString());\n\n    if (failOnVulnerabilities === 'true' &amp;&amp; vulnerabilityCount &gt; 0) {\n      core.setFailed(`Found ${vulnerabilityCount} vulnerabilities with severity ${severity}`);\n      return;\n    }\n\n    core.info(`\u2705 Scan completed: Found ${vulnerabilityCount} vulnerabilities`);\n\n  } catch (error) {\n    core.setFailed(`\u274c Scan failed: ${error.message}`);\n  }\n}\n\nrun();\n</code></pre> <p>Fichier action.yml pour JavaScript</p> YAML<pre><code>name: 'Scan Docker Image for Vulnerabilities'\ndescription: 'Scanner une image Docker avec Trivy'\n\ninputs:\n  image-ref:\n    description: 'R\u00e9f\u00e9rence de l''image \u00e0 scanner'\n    required: true\n\n  severity:\n    description: 'Niveaux de s\u00e9v\u00e9rit\u00e9 \u00e0 rapporter (ex: CRITICAL,HIGH)'\n    required: false\n    default: 'CRITICAL,HIGH'\n\n  fail-on-vulnerabilities:\n    description: '\u00c9chouer si des vuln\u00e9rabilit\u00e9s sont trouv\u00e9es'\n    required: false\n    default: 'true'\n\noutputs:\n  vulnerability-count:\n    description: 'Nombre de vuln\u00e9rabilit\u00e9s trouv\u00e9es'\n\nruns:\n  using: 'node20'\n  main: 'index.js'\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#publication-et-partage-dune-action-personnalisee","title":"Publication et partage d'une action personnalis\u00e9e","text":"<p>Les actions personnalis\u00e9es peuvent \u00eatre publi\u00e9es sur GitHub Marketplace pour partage public :</p> <ol> <li>Cr\u00e9er un nouveau r\u00e9f\u00e9rentiel public avec le nom <code>actions/action-name</code></li> <li>Ajouter des tags s\u00e9mantiques : <code>git tag -a v1 -m \"v1 release\"</code> et <code>git push origin v1</code></li> <li>Compl\u00e9ter le fichier <code>action.yml</code> avec des m\u00e9tadonn\u00e9es exhaustives</li> <li>Ajouter une documentation compl\u00e8te dans <code>README.md</code></li> <li>Publier sur le Marketplace via les param\u00e8tres du r\u00e9f\u00e9rentiel</li> </ol> <p>Utilisation d'une action du Marketplace</p> YAML<pre><code>- name: Use published action\n  uses: organisation/action-name@v1\n  with:\n    parameter1: value1\n    parameter2: value2\n</code></pre>"},{"location":"_projects/_formation-github-actions/github-actions-chap08/#synthese-du-parcours-dapprentissage","title":"Synth\u00e8se du parcours d'apprentissage","text":"<p>La ma\u00eetrise de GitHub Actions pour la containerisation et le d\u00e9ploiement s'acquiert progressivement selon le chemin suivant :</p> <p>Phase 1 : Fondations - Configuration initiale de GHCR et authentification - Cr\u00e9ation manuelle d'images Docker optimis\u00e9es - Apprentissage de la syntaxe YAML pour workflows</p> <p>Phase 2 : Automatisation Progressive - Construction et push automatis\u00e9s d'images - Int\u00e9gration des tests unitaires et d'int\u00e9gration - Scans de s\u00e9curit\u00e9 et gestion des vuln\u00e9rabilit\u00e9s</p> <p>Phase 3 : Validation et Qualit\u00e9 - Tests E2E en environnement proche production - Export local d'images pour validation pr\u00e9-push - Mise en place d'healthchecks et v\u00e9rifications</p> <p>Phase 4 : D\u00e9ploiement Orchestr\u00e9 - Docker Compose pour environnements complexes - Gestion multi-environnements (staging/production) - Approval workflows et gestion des secrets</p> <p>Phase 5 : R\u00e9utilisabilit\u00e9 et Scalabilit\u00e9 - Cr\u00e9ation d'actions personnalis\u00e9es (Docker, composite, JavaScript) - Partage et publication sur Marketplace - Architecture modulaire pour \u00e9quipes</p> <p>Cette progression assure une compr\u00e9hension profonde de chaque couche technologique avant d'aborder les niveaux sup\u00e9rieurs de complexit\u00e9.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/","title":"Citations","text":"<ul> <li>https://www.winside.fr/blog/introduction-a-la-ci-cd-avec-gitlab-pour-les-developpeurs</li> <li>https://about.gitlab.com/fr-fr/blog/getting-started-with-gitlab-understanding-ci-cd/</li> <li>https://about.gitlab.com/fr-fr/blog/ultimate-guide-to-ci-cd-fundamentals-to-advanced-implementation/</li> <li>https://blog.eleven-labs.com/fr/introduction-gitlab-ci/</li> <li>https://blog.stephane-robert.info/docs/pipeline-cicd/gitlab/</li> <li>https://www.youtube.com/watch?v=UkUF827CGJY</li> <li>https://openclassrooms.com/fr/courses/2035736-mettez-en-place-l-integration-et-la-livraison-continues-avec-la-demarche-devops</li> <li>https://documentation.univ-lyon1.fr/gitlab/ci/</li> <li>https://about.gitlab.com/fr-fr/blog/basics-of-gitlab-ci-updated/</li> <li>https://www.youtube.com/watch?v=017CQCh3ogY</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 284</li> <li>completion_tokens: 5771</li> <li>total_tokens: 6055</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.087, 'request_cost': 0.006, 'total_cost': 0.093}</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#content","title":"Content","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#chapitre-1-introduction-au-cicd","title":"\ud83d\udcda Chapitre 1 : Introduction au CI/CD","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#a-labordage","title":"A l'abordage ! \ud83d\ude80","text":"<p>GitLab CI/CD repr\u00e9sente une r\u00e9volution dans les pratiques de d\u00e9veloppement logiciel moderne. Cette plateforme int\u00e9gr\u00e9e automatise enti\u00e8rement le cycle de d\u00e9veloppement, de la compilation du code jusqu'au d\u00e9ploiement en production. L'adoption de CI/CD ne constitue plus une option mais une n\u00e9cessit\u00e9 pour les \u00e9quipes de d\u00e9veloppement contemporaines qui souhaitent livrer des logiciels de qualit\u00e9 \u00e0 un rythme rapide et soutenu.[1][2]</p> <p>Le c\u0153ur de cette automatisation repose sur un processus simple mais puissant : chaque modification de code d\u00e9clench\u00e9e par un d\u00e9veloppeur initie automatiquement une s\u00e9quence d'\u00e9tapes pr\u00e9d\u00e9finies. Ces \u00e9tapes englobent la compilation du code source, l'ex\u00e9cution des tests automatis\u00e9s, l'analyse de la qualit\u00e9 du code, et finalement le d\u00e9ploiement vers l'environnement cible.[1][2] Cette cha\u00eene d'automatisation garantit que seul du code valid\u00e9 et test\u00e9 atteint les utilisateurs finaux.</p> <p>GitLab propose une solution CI/CD int\u00e9gr\u00e9e directement dans sa plateforme DevOps, \u00e9liminant le besoin d'outils externes fragment\u00e9s. Les d\u00e9veloppeurs b\u00e9n\u00e9ficient d'une interface unifi\u00e9e pour g\u00e9rer leurs d\u00e9p\u00f4ts de code, configurer les pipelines, surveiller les performances et analyser les r\u00e9sultats, tout au sein d'un seul et m\u00eame \u00e9cosyst\u00e8me.[1]</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#introduction-au-devops","title":"Introduction au DevOps \ud83d\udd27","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#fondamentaux-du-devops","title":"Fondamentaux du DevOps","text":"<p>DevOps repr\u00e9sente une philosophie et un ensemble de pratiques qui fusionnent le d\u00e9veloppement logiciel (Dev) et les op\u00e9rations informatiques (Ops). Cette approche vise \u00e0 raccourcir le cycle de vie du d\u00e9veloppement et \u00e0 am\u00e9liorer la qualit\u00e9 et la fiabilit\u00e9 des applications en production.</p> <p>Historiquement, les \u00e9quipes de d\u00e9veloppement et d'op\u00e9rations fonctionnaient de mani\u00e8re isol\u00e9e. Les d\u00e9veloppeurs cr\u00e9aient du code, puis le transmettaient aux op\u00e9rations qui s'occupaient du d\u00e9ploiement et de la maintenance. Cette s\u00e9paration engendrait des frictions, des malentendus et des d\u00e9lais consid\u00e9rables entre la cr\u00e9ation du code et sa mise en production.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#les-piliers-du-devops","title":"Les piliers du DevOps","text":"<p>Le DevOps repose sur plusieurs piliers fondamentaux :</p> <p>Automatisation : Chaque t\u00e2che r\u00e9p\u00e9titive du cycle de vie logiciel (compilation, tests, d\u00e9ploiement) est automatis\u00e9e afin d'\u00e9liminer les erreurs manuelles et d'acc\u00e9l\u00e9rer les processus.[2]</p> <p>Int\u00e9gration continue : Les d\u00e9veloppeurs int\u00e8grent leur code dans un d\u00e9p\u00f4t central plusieurs fois par jour. Chaque int\u00e9gration d\u00e9clenche automatiquement une s\u00e9rie de v\u00e9rifications et de tests.</p> <p>Livraison continue : Les applications demeurent constamment dans un \u00e9tat d\u00e9ployable. L'infrastructure et les processus permettent de d\u00e9ployer vers un environnement quelconque (pr\u00e9production, production) en un seul clic ou automatiquement.</p> <p>D\u00e9ploiement continu : Chaque compilation r\u00e9ussie est automatiquement pouss\u00e9e en production sans intervention manuelle, n\u00e9cessitant une confiance absolue dans les tests automatis\u00e9s.[2]</p> <p>Collaboration : Les barri\u00e8res entre les \u00e9quipes se dissolvent. D\u00e9veloppeurs et op\u00e9rations travaillent ensemble vers des objectifs communs.</p> <p>Monitoring et feedback : Les applications en production sont constamment surveill\u00e9es. Les m\u00e9triques et les alertes permettent une d\u00e9tection rapide des probl\u00e8mes et une r\u00e9action imm\u00e9diate.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#avantages-du-devops","title":"Avantages du DevOps","text":"<p>L'adoption de pratiques DevOps apporte des b\u00e9n\u00e9fices tangibles :</p> <ul> <li>D\u00e9ploiements plus rapides : Les cycles de lib\u00e9ration passent de mois \u00e0 jours ou heures</li> <li>Am\u00e9lioration de la stabilit\u00e9 : Les tests automatis\u00e9s et les v\u00e9rifications continues r\u00e9duisent les d\u00e9fauts</li> <li>R\u00e9duction du temps d'arr\u00eat : Les probl\u00e8mes sont d\u00e9tect\u00e9s et corrig\u00e9s rapidement</li> <li>Meilleure collaboration : Les \u00e9quipes travaillent ensemble plut\u00f4t que de se bloquer mutuellement</li> <li>Am\u00e9lioration continue : Les m\u00e9triques et le feedback permettent une optimisation constante</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#quest-ce-que-lintegration-et-la-livraison-continues","title":"Qu'est-ce que l'int\u00e9gration et la livraison continues ? \ud83d\udd04","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#definition-de-lintegration-continue-ci","title":"D\u00e9finition de l'int\u00e9gration continue (CI)","text":"<p>L'int\u00e9gration continue consiste \u00e0 automatiser la compilation et les tests du code \u00e0 chaque modification.[1][2] D\u00e8s qu'un d\u00e9veloppeur pousse ses modifications vers le d\u00e9p\u00f4t central (via un commit), une s\u00e9rie de v\u00e9rifications s'amorce automatiquement.</p> <p>Le processus d'int\u00e9gration continue fonctionne selon ce flux :</p> <ol> <li>Un d\u00e9veloppeur fait un commit et pousse le code vers le d\u00e9p\u00f4t</li> <li>GitLab d\u00e9tecte cette modification</li> <li>Un pipeline CI se d\u00e9clenche automatiquement</li> <li>Le code est compil\u00e9</li> <li>Des tests automatis\u00e9s s'ex\u00e9cutent</li> <li>Des analyses de qualit\u00e9 et de s\u00e9curit\u00e9 sont conduites</li> <li>Les r\u00e9sultats sont communiqu\u00e9s au d\u00e9veloppeur</li> </ol> <p>Cette approche pr\u00e9sente plusieurs avantages cruciaux. Premi\u00e8rement, elle d\u00e9tecte les bogues \u00e0 un stade pr\u00e9coce, bien avant qu'ils n'atteignent l'environnement de production.[2] Un probl\u00e8me identifi\u00e9 d\u00e8s la phase de compilation est bien moins co\u00fbteux \u00e0 corriger qu'un bug d\u00e9couvert apr\u00e8s le d\u00e9ploiement.</p> <p>Deuxi\u00e8mement, l'int\u00e9gration continue force les d\u00e9veloppeurs \u00e0 int\u00e9grer leur code fr\u00e9quemment, r\u00e9duisant ainsi la complexit\u00e9 des fusions (merges) ult\u00e9rieures et minimisant les conflits de code.</p> <p>Troisi\u00e8mement, elle garantit la maintenabilit\u00e9 du codebase. Un code continuellement test\u00e9 et v\u00e9rifi\u00e9 reste propre, lisible et facile \u00e0 maintenir.[1]</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#definition-de-la-livraison-continue-cd","title":"D\u00e9finition de la livraison continue (CD)","text":"<p>La livraison continue compl\u00e8te l'int\u00e9gration continue en automatisant le pipeline jusqu'au d\u00e9ploiement.[2] Elle repr\u00e9sente une extension naturelle de la CI.</p> <p>Avec la livraison continue, d\u00e8s que le code passe tous les tests et les v\u00e9rifications d'int\u00e9gration continue, il est automatiquement pr\u00e9par\u00e9 pour \u00eatre d\u00e9ploy\u00e9. L'application demeure constamment dans un \u00e9tat d\u00e9ployable. Un administrateur ou un responsable peut d\u00e9ployer vers un environnement cible (pr\u00e9production, production) en un seul clic ou via un d\u00e9clenchement manuel.</p> <p>La livraison continue ne pousse pas automatiquement les modifications en production. Elle les pr\u00e9pare et les rend disponibles, mais c'est un humain qui d\u00e9cide du moment du d\u00e9ploiement r\u00e9el. Cette distinction est cruciale pour les environnements sensibles o\u00f9 des d\u00e9ploiements non contr\u00f4l\u00e9s pourraient causer des interruptions de service.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#differenciation-livraison-continue-vs-deploiement-continu","title":"Diff\u00e9renciation : Livraison continue vs D\u00e9ploiement continu","text":"<p>Il existe une distinction importante entre la livraison continue (CD) et le d\u00e9ploiement continu.</p> <p>Livraison continue : L'application est constamment pr\u00eate \u00e0 \u00eatre d\u00e9ploy\u00e9e, mais le d\u00e9ploiement en production n\u00e9cessite une approbation manuelle.[2]</p> <p>D\u00e9ploiement continu : Pousse la logique d'automatisation encore plus loin. Chaque compilation r\u00e9ussie est directement mise en production sans validation manuelle. Ce niveau d'automatisation requiert une confiance totale dans les tests automatis\u00e9s et les processus de d\u00e9ploiement.[2]</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#benefices-concrets-du-cicd","title":"B\u00e9n\u00e9fices concrets du CI/CD","text":"<p>L'impl\u00e9mentation de CI/CD offre des avantages tangibles :</p> <p>D\u00e9tection pr\u00e9coce des d\u00e9fauts : Les probl\u00e8mes sont identifi\u00e9s et corrig\u00e9s bien avant d'atteindre l'environnement de production.[2]</p> <p>Automatisation compl\u00e8te : Compilation, tests et d\u00e9ploiement sont orchestr\u00e9s sans intervention manuelle.[2]</p> <p>Livraison plus rapide : Les logiciels sont livr\u00e9s plus rapidement et plus fr\u00e9quemment, permettant une r\u00e9activit\u00e9 accrue aux besoins des utilisateurs.[2]</p> <p>R\u00e9duction des risques : Les processus standardis\u00e9s et test\u00e9s r\u00e9duisent les erreurs humaines et les d\u00e9ploiements non contr\u00f4l\u00e9s.</p> <p>Feedback imm\u00e9diat : Les d\u00e9veloppeurs re\u00e7oivent un retour imm\u00e9diat sur la qualit\u00e9 de leur code.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#cycle-de-developpement-transforme","title":"Cycle de d\u00e9veloppement transform\u00e9","text":"<p>Le cycle de d\u00e9veloppement logiciel se transforme compl\u00e8tement avec CI/CD. Imaginez un cycle dans lequel chaque modification de code est automatiquement compil\u00e9e, test\u00e9e, puis pr\u00e9par\u00e9e pour le d\u00e9ploiement.[2] Cette vision, autrefois utopique, devient r\u00e9alit\u00e9 avec les outils appropri\u00e9s.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#le-langage-yaml","title":"Le langage YAML \ud83d\udcdd","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#quest-ce-que-yaml","title":"Qu'est-ce que YAML ?","text":"<p>YAML signifie \"YAML Ain't Markup Language\". Il s'agit d'un langage de s\u00e9rialisation de donn\u00e9es con\u00e7u pour \u00eatre lisible par les humains. YAML utilise une syntaxe bas\u00e9e sur l'indentation et des structures simples pour repr\u00e9senter des donn\u00e9es complexes.</p> <p>Contrairement \u00e0 JSON ou XML, YAML privil\u00e9gie la lisibilit\u00e9. Le code YAML ressemble presque \u00e0 du texte naturel, ce qui le rend accessible m\u00eame aux personnes n'ayant pas d'exp\u00e9rience en programmation.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#syntaxe-fondamentale-de-yaml","title":"Syntaxe fondamentale de YAML","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#structures-de-base","title":"Structures de base","text":"<p>YAML fonctionne autour de trois structures principales : les cl\u00e9s-valeurs, les listes et les commentaires.</p> <p>Cl\u00e9s-valeurs :</p> YAML<pre><code>nom: Jean\nage: 30\nville: Paris\n</code></pre> <p>Les cl\u00e9s et les valeurs sont s\u00e9par\u00e9es par deux points. Chaque paire cl\u00e9-valeur est sur sa propre ligne. L'indentation d\u00e9finit la hi\u00e9rarchie.</p> <p>Imbrication d'objets :</p> YAML<pre><code>personne:\n  nom: Marie\n  age: 28\n  adresse:\n    rue: Rue de la Paix\n    ville: Lyon\n    codepostal: 69000\n</code></pre> <p>Les objets imbriqu\u00e9s sont indent\u00e9s de 2 espaces suppl\u00e9mentaires. Cette imbrication cr\u00e9e une structure hi\u00e9rarchique.</p> <p>Listes :</p> YAML<pre><code>fruits:\n  - pomme\n  - banane\n  - orange\n  - raisin\n</code></pre> <p>Les listes sont d\u00e9finies avec un trait d'union suivi d'un espace. Chaque \u00e9l\u00e9ment de la liste est sur sa propre ligne avec la m\u00eame indentation.</p> <p>Listes de dictionnaires :</p> YAML<pre><code>employes:\n  - nom: Alice\n    poste: D\u00e9veloppeur\n    salaire: 45000\n  - nom: Bob\n    poste: Manager\n    salaire: 55000\n  - nom: Charlie\n    poste: Testeur\n    salaire: 40000\n</code></pre> <p>Cette structure combine listes et dictionnaires, utile pour repr\u00e9senter des collections d'objets complexes.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#types-de-donnees","title":"Types de donn\u00e9es","text":"<p>YAML supporte plusieurs types de donn\u00e9es :</p> <p>Cha\u00eenes de caract\u00e8res :</p> YAML<pre><code>description: \"Ceci est une cha\u00eene de caract\u00e8res\"\nautre_description: Ceci aussi est une cha\u00eene\nmulti_ligne: |\n  Ceci est une cha\u00eene\n  sur plusieurs lignes\n  maintenant\n</code></pre> <p>Les cha\u00eenes peuvent \u00eatre entre guillemets ou sans. Le caract\u00e8re <code>|</code> permet les cha\u00eenes multi-lignes.</p> <p>Nombres :</p> YAML<pre><code>entier: 42\ndecimal: 3.14\nnotation_scientifique: 1.23e-4\n</code></pre> <p>Bool\u00e9ens :</p> YAML<pre><code>actif: true\ntermine: false\noption1: yes\noption2: no\n</code></pre> <p>Les bool\u00e9ens acceptent plusieurs repr\u00e9sentations : <code>true</code>/<code>false</code>, <code>yes</code>/<code>no</code>, <code>on</code>/<code>off</code>.</p> <p>Valeurs nulles :</p> YAML<pre><code>valeur_nulle: null\nautre_vide: ~\n</code></pre> <p>Commentaires :</p> YAML<pre><code># Ceci est un commentaire\nnom: Jean  # Commentaire en fin de ligne\n# age: 30  # Cette ligne est comment\u00e9e\n</code></pre> <p>Les commentaires commencent par le caract\u00e8re <code>#</code>.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#contexte-gitlab-cicd","title":"Contexte GitLab CI/CD","text":"<p>Dans GitLab CI/CD, YAML est le langage de configuration exclusif. Le fichier <code>.gitlab-ci.yml</code> \u00e0 la racine du projet d\u00e9finit enti\u00e8rement le comportement du pipeline.[1][2][3][4]</p> <p>Ce fichier YAML d\u00e9crit :</p> <ul> <li>Les \u00e9tapes du pipeline (stages)</li> <li>Les jobs associ\u00e9s \u00e0 chaque \u00e9tape</li> <li>Les scripts \u00e0 ex\u00e9cuter pour chaque job</li> <li>Les runners \u00e0 utiliser</li> <li>Les variables d'environnement</li> <li>Les conditions d'ex\u00e9cution</li> <li>Les artefacts \u00e0 g\u00e9n\u00e9rer</li> <li>Les d\u00e9pendances entre jobs</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#exemple-de-fichier-gitlab-ciyml-simple","title":"Exemple de fichier <code>.gitlab-ci.yml</code> simple","text":"YAML<pre><code>stages:\n  - build\n  - test\n  - deploy\n\nbuild_job:\n  stage: build\n  script:\n    - echo \"Compilation de l'application...\"\n    - npm install\n\ntest_job:\n  stage: test\n  script:\n    - echo \"Ex\u00e9cution des tests...\"\n    - npm test\n\ndeploy_job:\n  stage: deploy\n  script:\n    - echo \"D\u00e9ploiement en production...\"\n    - npm run deploy\n  environment:\n    name: production\n</code></pre> <p>Cette configuration illustre les concepts cl\u00e9s :</p> <ul> <li>stages : Les trois \u00e9tapes du pipeline (build, test, deploy)</li> <li>build_job, test_job, deploy_job : Les trois jobs, chacun assign\u00e9 \u00e0 une \u00e9tape</li> <li>script : Les commandes \u00e0 ex\u00e9cuter pour chaque job</li> <li>environment : La configuration de l'environnement de d\u00e9ploiement</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#pourquoi-yaml-pour-gitlab-cicd","title":"Pourquoi YAML pour GitLab CI/CD ?","text":"<p>YAML a \u00e9t\u00e9 choisi pour GitLab CI/CD pour plusieurs raisons :</p> <p>Simplicit\u00e9 : La syntaxe YAML est intuitive et ne n\u00e9cessite pas de connaissances approfondies en programmation.[4]</p> <p>Lisibilit\u00e9 : Un fichier <code>.gitlab-ci.yml</code> bien structur\u00e9 se lit comme de la documentation.[4]</p> <p>Flexibilit\u00e9 : YAML permet d'exprimer des configurations complexes tout en restant accessible.</p> <p>Standardisation : YAML est devenu le standard pour de nombreux outils DevOps (Docker Compose, Kubernetes, Ansible, etc.), facilitant la coh\u00e9rence entre les outils.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#mise-en-place-de-lenvironnement","title":"Mise en place de l'environnement \u2699\ufe0f","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#architecture-globale-de-gitlab-cicd","title":"Architecture globale de GitLab CI/CD","text":"<p>Avant de configurer l'environnement, il est essentiel de comprendre l'architecture sous-jacente de GitLab CI/CD.</p> <p>L'architecture repose sur plusieurs composants interconnect\u00e9s :</p> <p>GitLab Server : Le serveur central h\u00e9bergeant les d\u00e9p\u00f4ts Git, les configurations de pipeline et les historiques d'ex\u00e9cution.</p> <p>GitLab Runner : Un agent charg\u00e9 d'ex\u00e9cuter les jobs d\u00e9finis dans le pipeline.[2][4] Les runners peuvent \u00eatre install\u00e9s sur n'importe quelle infrastructure (machines physiques, machines virtuelles, conteneurs Docker, clusters Kubernetes).</p> <p>Pipeline : L'ensemble des \u00e9tapes et des jobs configur\u00e9s pour transformer le code source en application d\u00e9ploy\u00e9e.</p> <p>Jobs : Les unit\u00e9s individuelles de travail ex\u00e9cut\u00e9es lors d'une \u00e9tape donn\u00e9e (par exemple, compiler du code, ex\u00e9cuter des tests ou d\u00e9ployer dans un environnement).[2]</p> <p>\u00c9tapes (Stages) : Elles d\u00e9finissent l'ordre d'ex\u00e9cution des jobs.[2] Les jobs d'une m\u00eame \u00e9tape s'ex\u00e9cutent en parall\u00e8le, tandis que les \u00e9tapes s'ex\u00e9cutent s\u00e9quentiellement.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#conditions-prealables","title":"Conditions pr\u00e9alables","text":"<p>Pour mettre en place GitLab CI/CD, certaines conditions doivent \u00eatre remplies :</p> <p>Acc\u00e8s \u00e0 GitLab : Un compte GitLab actif avec au moins un projet cr\u00e9\u00e9.</p> <p>D\u00e9p\u00f4t Git : Un d\u00e9p\u00f4t git configur\u00e9 et synchronis\u00e9 avec GitLab.</p> <p>Permissions : Les droits d'\u00e9criture sur le projet pour cr\u00e9er et modifier le fichier <code>.gitlab-ci.yml</code>.</p> <p>Runners disponibles : GitLab fournit des runners partag\u00e9s par d\u00e9faut accessibles imm\u00e9diatement sans configuration suppl\u00e9mentaire.[1] Ces runners sont pr\u00e9configur\u00e9s pour ex\u00e9cuter les jobs CI/CD.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#creation-du-fichier-gitlab-ciyml","title":"Cr\u00e9ation du fichier <code>.gitlab-ci.yml</code>","text":"<p>La premi\u00e8re \u00e9tape consiste \u00e0 cr\u00e9er le fichier <code>.gitlab-ci.yml</code> \u00e0 la racine du projet.[1][3][8]</p> <p>Pour cr\u00e9er ce fichier :</p> <ol> <li>Se connecter \u00e0 GitLab et acc\u00e9der au projet</li> <li>Cliquer sur le bouton \"+\" pour ajouter un nouveau fichier</li> <li>Nommer le fichier <code>.gitlab-ci.yml</code></li> <li>Ajouter le contenu YAML du pipeline</li> <li>Valider la cr\u00e9ation du fichier</li> </ol> <p>Alternativement, en ligne de commande :</p> Bash<pre><code>cd /chemin/vers/projet\ncat &gt; .gitlab-ci.yml &lt;&lt; 'EOF'\nstages:\n  - build\n  - test\n  - deploy\n\nbuild_job:\n  stage: build\n  script:\n    - echo \"Compilation...\"\nEOF\ngit add .gitlab-ci.yml\ngit commit -m \"Ajout de la configuration CI/CD\"\ngit push origin main\n</code></pre> <p>Une fois le fichier commit\u00e9 et pouss\u00e9, GitLab d\u00e9tecte automatiquement ce fichier et commence \u00e0 ex\u00e9cuter le pipeline \u00e0 chaque modification ult\u00e9rieure.[3]</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#configuration-des-runners","title":"Configuration des runners","text":"<p>GitLab propose deux approches concernant les runners :</p> <p>Runners partag\u00e9s : GitLab fournit des runners partag\u00e9s par d\u00e9faut. Ces runners sont maintenu par GitLab et accessibles sans configuration. Ils conviennent pour la majorit\u00e9 des projets.[1]</p> <p>Runners personnalis\u00e9s : Pour des besoins sp\u00e9cifiques (infrastructure propri\u00e9taire, environnements isol\u00e9s, outils sp\u00e9cialis\u00e9s), des runners personnalis\u00e9s peuvent \u00eatre configur\u00e9s.[1]</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#pipeline-basique","title":"Pipeline basique","text":"<p>Un pipeline basique typique se structure comme suit :</p> YAML<pre><code>stages:\n  - Compilation\n  - Test\n  - D\u00e9ploiement\n\njob_compilation:\n  stage: Compilation\n  script:\n    - echo \"Compilation du code...\"\n    - # Commandes de compilation sp\u00e9cifiques\n\njob_test_unitaires:\n  stage: Test\n  script:\n    - echo \"Ex\u00e9cution des tests unitaires...\"\n    - # Commandes de test\n\njob_test_integration:\n  stage: Test\n  script:\n    - echo \"Ex\u00e9cution des tests d'int\u00e9gration...\"\n    - # Commandes de test d'int\u00e9gration\n\njob_deploiement:\n  stage: D\u00e9ploiement\n  script:\n    - echo \"D\u00e9ploiement en production...\"\n    - # Commandes de d\u00e9ploiement\n</code></pre> <p>Cette structure comprend :</p> <ul> <li>Une \u00e9tape de compilation o\u00f9 le code source est compil\u00e9 et des artefacts sont g\u00e9n\u00e9r\u00e9s</li> <li>Une \u00e9tape de test o\u00f9 les tests unitaires et d'int\u00e9gration s'ex\u00e9cutent</li> <li>Une \u00e9tape de d\u00e9ploiement o\u00f9 l'application est d\u00e9ploy\u00e9e</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#suivi-de-lexecution-des-pipelines","title":"Suivi de l'ex\u00e9cution des pipelines","text":"<p>Une fois le fichier <code>.gitlab-ci.yml</code> cr\u00e9\u00e9 et le code pouss\u00e9, le pipeline s'ex\u00e9cute automatiquement.[5] Pour suivre son ex\u00e9cution :</p> <ol> <li>Acc\u00e9der \u00e0 la page du projet GitLab</li> <li>Cliquer sur \"CI/CD\" dans le menu lat\u00e9ral</li> <li>S\u00e9lectionner \"Pipelines\" pour voir la liste des ex\u00e9cutions</li> <li>Cliquer sur une ex\u00e9cution pour voir les d\u00e9tails</li> <li>Consulter les logs de chaque job pour diagnostiquer les probl\u00e8mes</li> </ol>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#variables-denvironnement","title":"Variables d'environnement","text":"<p>GitLab CI/CD supporte les variables d'environnement, essentielles pour g\u00e9rer les informations sensibles et les configurations sp\u00e9cifiques \u00e0 chaque environnement.</p> YAML<pre><code>variables:\n  NODE_ENV: \"production\"\n  LOG_LEVEL: \"debug\"\n  DATABASE_URL: $DATABASE_URL  # Variable prot\u00e9g\u00e9e d\u00e9finie dans les param\u00e8tres du projet\n\nbuild_job:\n  stage: build\n  script:\n    - echo \"Environnement: $NODE_ENV\"\n    - echo \"Niveau de log: $LOG_LEVEL\"\n</code></pre> <p>Les variables d\u00e9finies au niveau du projet (via les param\u00e8tres GitLab) sont inject\u00e9es automatiquement dans les jobs. Cela permet de stocker des informations sensibles (identifiants, tokens API) de mani\u00e8re s\u00e9curis\u00e9e sans les inclure dans le code.[2]</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#exemple-pratique-pour-une-application-nodejs","title":"Exemple pratique pour une application Node.js","text":"<p>Voici un exemple concret de pipeline pour une application Node.js :</p> YAML<pre><code>image: node:16\n\nstages:\n  - build\n  - test\n  - deploy\n\nvariables:\n  NPM_REGISTRY: \"https://registry.npmjs.org\"\n\nbuild_job:\n  stage: build\n  script:\n    - npm install\n    - npm run build\n  artifacts:\n    paths:\n      - dist/\n    expire_in: 1 hour\n\ntest_job:\n  stage: test\n  script:\n    - npm install\n    - npm test\n  coverage: '/Coverage: \\d+\\.\\d+%/'\n\ndeploy_job:\n  stage: deploy\n  script:\n    - npm install --production\n    - npm start\n  environment:\n    name: production\n    url: https://monapp.com\n  only:\n    - main\n</code></pre> <p>Ce pipeline :</p> <ul> <li>Utilise l'image Docker <code>node:16</code> pour tous les jobs</li> <li>Compile l'application et g\u00e9n\u00e8re des artefacts dans l'\u00e9tape build</li> <li>Ex\u00e9cute les tests dans l'\u00e9tape test</li> <li>D\u00e9ploie en production dans l'\u00e9tape deploy, uniquement si la branche est <code>main</code></li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#artefacts-et-dependances","title":"Artefacts et d\u00e9pendances","text":"<p>Les artefacts permettent de transmettre des fichiers entre les jobs d'un pipeline.[1]</p> YAML<pre><code>build_job:\n  stage: build\n  script:\n    - npm run build\n  artifacts:\n    paths:\n      - dist/\n    expire_in: 1 day\n\ntest_job:\n  stage: test\n  dependencies:\n    - build_job\n  script:\n    - npm test\n</code></pre> <p>Le job <code>build_job</code> g\u00e9n\u00e8re des artefacts dans le r\u00e9pertoire <code>dist/</code>. Le job <code>test_job</code> d\u00e9clare une d\u00e9pendance envers <code>build_job</code>, ce qui signifie que les artefacts seront automatiquement t\u00e9l\u00e9charg\u00e9s avant l'ex\u00e9cution des tests.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#etapes-predefinies","title":"\u00c9tapes pr\u00e9d\u00e9finies","text":"<p>GitLab CI/CD fournit deux \u00e9tapes pr\u00e9d\u00e9finies sp\u00e9ciales :[5]</p> <p>.pre : Cette \u00e9tape s'ex\u00e9cute toujours au d\u00e9but du pipeline, avant toutes les autres \u00e9tapes. Utile pour des v\u00e9rifications pr\u00e9alables ou de l'initialisation.</p> <p>.post : Cette \u00e9tape s'ex\u00e9cute toujours \u00e0 la fin du pipeline, apr\u00e8s toutes les autres \u00e9tapes, m\u00eame en cas d'erreur. Utile pour du nettoyage ou des notifications.</p> YAML<pre><code>.pre:\n  stage: .pre\n  script:\n    - echo \"Initialisation du pipeline...\"\n\nbuild_job:\n  stage: build\n  script:\n    - echo \"Compilation...\"\n\n.post:\n  stage: .post\n  script:\n    - echo \"Nettoyage et fin du pipeline...\"\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#environnements-et-deploiements-multiples","title":"Environnements et d\u00e9ploiements multiples","text":"<p>GitLab permet de d\u00e9ployer vers diff\u00e9rents environnements avec un contr\u00f4le granulaire.[2]</p> YAML<pre><code>stages:\n  - build\n  - test\n  - deploy_staging\n  - deploy_production\n\nbuild_job:\n  stage: build\n  script:\n    - npm run build\n\ntest_job:\n  stage: test\n  script:\n    - npm test\n\ndeploy_staging:\n  stage: deploy_staging\n  script:\n    - echo \"D\u00e9ploiement en pr\u00e9production...\"\n    - ./deploy.sh staging\n  environment:\n    name: staging\n    url: https://staging.monapp.com\n  only:\n    - develop\n\ndeploy_production:\n  stage: deploy_production\n  script:\n    - echo \"D\u00e9ploiement en production...\"\n    - ./deploy.sh production\n  environment:\n    name: production\n    url: https://monapp.com\n  when: manual\n  only:\n    - main\n</code></pre> <p>Dans cet exemple :</p> <ul> <li>Le d\u00e9ploiement en staging (pr\u00e9production) s'ex\u00e9cute automatiquement sur la branche <code>develop</code></li> <li>Le d\u00e9ploiement en production s'ex\u00e9cute uniquement sur la branche <code>main</code> et n\u00e9cessite une approbation manuelle (<code>when: manual</code>)</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#verification-et-diagnostic","title":"V\u00e9rification et diagnostic","text":"<p>Lorsque l'ex\u00e9cution d'un pipeline rencontre des probl\u00e8mes, plusieurs outils de diagnostic sont disponibles :</p> <p>Logs des jobs : Chaque job affiche des logs d\u00e9taill\u00e9s montrant l'ex\u00e9cution de chaque commande du script.</p> <p>Statut du pipeline : Le statut global (succ\u00e8s, \u00e9chec, arr\u00eat\u00e9) est visible imm\u00e9diatement.</p> <p>Artefacts g\u00e9n\u00e9r\u00e9s : Les artefacts cr\u00e9\u00e9s par les jobs peuvent \u00eatre t\u00e9l\u00e9charg\u00e9s pour examen.</p> <p>Historique des pipelines : Un historique complet de toutes les ex\u00e9cutions est conserv\u00e9, permettant d'identifier les patterns d'erreurs.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap01/#conclusion-du-chapitre-1","title":"Conclusion du chapitre 1","text":"<p>Ce premier chapitre a \u00e9tabli les fondations essentielles pour comprendre GitLab CI/CD. De l'introduction g\u00e9n\u00e9rale aux concepts DevOps, en passant par les principes de CI/CD et la syntaxe YAML, jusqu'\u00e0 la mise en place concr\u00e8te de l'environnement, les \u00e9l\u00e9ments cl\u00e9s ont \u00e9t\u00e9 pr\u00e9sent\u00e9s.</p> <p>La compr\u00e9hension de ces concepts fondamentaux est cruciale avant d'explorer les configurations plus avanc\u00e9es. L'automatisation des processus de d\u00e9veloppement, r\u00e9alis\u00e9e via GitLab CI/CD, transforme profond\u00e9ment les workflows et am\u00e9liore significativement la qualit\u00e9 et la vitesse de livraison des applications.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/","title":"Citations","text":"<ul> <li>https://www.winside.fr/blog/introduction-a-la-ci-cd-avec-gitlab-pour-les-developpeurs</li> <li>https://about.gitlab.com/fr-fr/blog/getting-started-with-gitlab-understanding-ci-cd/</li> <li>https://about.gitlab.com/fr-fr/blog/ultimate-guide-to-ci-cd-fundamentals-to-advanced-implementation/</li> <li>https://blog.eleven-labs.com/fr/introduction-gitlab-ci/</li> <li>https://blog.stephane-robert.info/docs/pipeline-cicd/gitlab/</li> <li>https://www.youtube.com/watch?v=UkUF827CGJY</li> <li>https://openclassrooms.com/fr/courses/2035736-mettez-en-place-l-integration-et-la-livraison-continues-avec-la-demarche-devops</li> <li>https://documentation.univ-lyon1.fr/gitlab/ci/</li> <li>https://about.gitlab.com/fr-fr/blog/basics-of-gitlab-ci-updated/</li> <li>https://www.youtube.com/watch?v=017CQCh3ogY</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 277</li> <li>completion_tokens: 4023</li> <li>total_tokens: 4300</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.06, 'request_cost': 0.006, 'total_cost': 0.067}</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#content","title":"Content","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#chapitre-2-introduction-a-gitlab-cicd","title":"Chapitre 2 : Introduction \u00e0 Gitlab CI/CD","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#introduction-a-gitlab","title":"Introduction \u00e0 Gitlab","text":"<p>GitLab est une plateforme DevOps int\u00e9gr\u00e9e qui fournit un ensemble complet d'outils pour g\u00e9rer le cycle de vie du d\u00e9veloppement logiciel. Contrairement \u00e0 des solutions fragment\u00e9es, GitLab offre une interface unifi\u00e9e permettant de g\u00e9rer les d\u00e9p\u00f4ts de code, de configurer des pipelines d'int\u00e9gration et de d\u00e9ploiement continus, et de surveiller les performances des applications dans un seul \u00e9cosyst\u00e8me[1].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#quest-ce-que-gitlab-cicd","title":"Qu'est-ce que GitLab CI/CD ?","text":"<p>GitLab CI/CD (Int\u00e9gration Continue/Livraison Continue) est une solution int\u00e9gr\u00e9e dans la plateforme GitLab qui automatise les processus d'int\u00e9gration continue et de d\u00e9ploiement continu[1]. Cette approche transforme le cycle de d\u00e9veloppement logiciel en \u00e9liminant les t\u00e2ches manuelles r\u00e9p\u00e9titives et en garantissant que chaque modification de code est automatiquement compil\u00e9e, test\u00e9e et valid\u00e9e[2].</p> <p>L'int\u00e9gration continue (CI) signifie que chaque modification apport\u00e9e au code est imm\u00e9diatement int\u00e9gr\u00e9e au d\u00e9p\u00f4t principal et soumise \u00e0 une s\u00e9rie de tests automatiques. Cela permet de d\u00e9tecter les bogues et les probl\u00e8mes d'int\u00e9gration \u00e0 un stade pr\u00e9coce du d\u00e9veloppement, plut\u00f4t que de les d\u00e9couvrir tardivement en production[2].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#les-avantages-cles-de-gitlab-cicd","title":"Les avantages cl\u00e9s de GitLab CI/CD","text":"<p>L'adoption de GitLab CI/CD offre plusieurs avantages majeurs aux \u00e9quipes de d\u00e9veloppement :</p> <p>Automatisation compl\u00e8te du cycle de d\u00e9veloppement : La compilation, les tests et le d\u00e9ploiement peuvent \u00eatre enti\u00e8rement orchestr\u00e9s via le pipeline CI/CD, \u00e9liminant ainsi les \u00e9tapes manuelles sujettes aux erreurs[2].</p> <p>D\u00e9tection pr\u00e9coce des bogues : Les probl\u00e8mes sont identifi\u00e9s et corrig\u00e9s bien avant d'atteindre l'environnement de production, r\u00e9duisant les co\u00fbts de correction et am\u00e9liorant la qualit\u00e9 globale du logiciel[2].</p> <p>Livraison plus rapide : En automatisant les processus, les \u00e9quipes peuvent livrer des logiciels plus fr\u00e9quemment et plus rapidement, permettant une mise en march\u00e9 plus agile[2].</p> <p>Qualit\u00e9 du code garantie : GitLab fournit une int\u00e9gration avec des outils de qualit\u00e9 de code comme Code Climate pour analyser le code et g\u00e9n\u00e9rer des rapports, assurant un codebase sain et maintenable[1].</p> <p>S\u00e9curit\u00e9 renforc\u00e9e : Les fonctionnalit\u00e9s d'analyse des conteneurs, d'analyse des d\u00e9pendances et de scanning de s\u00e9curit\u00e9 peuvent \u00eatre configur\u00e9es pour s'ex\u00e9cuter automatiquement \u00e0 chaque modification de code[3].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#debuter-avec-gitlab-cicd","title":"D\u00e9buter avec Gitlab CI/CD","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#architecture-et-composants-principaux","title":"Architecture et composants principaux","text":"<p>Avant de mettre en place une pipeline CI/CD, il est essentiel de comprendre les composants cl\u00e9s qui forment l'architecture de GitLab CI/CD[2].</p> <p>GitLab Runner : Cet agent ex\u00e9cute les jobs CI/CD sur l'infrastructure de choix. Les runners peuvent fonctionner sur des machines physiques, des machines virtuelles, des conteneurs Docker ou des clusters Kubernetes. GitLab fournit par d\u00e9faut des runners partag\u00e9s qui peuvent \u00eatre utilis\u00e9s imm\u00e9diatement sans configuration suppl\u00e9mentaire[1][2].</p> <p>\u00c9tapes (Stages) : Elles d\u00e9finissent l'ordre d'ex\u00e9cution logique des jobs au sein du pipeline. Par exemple, un pipeline typique peut contenir les \u00e9tapes suivantes : build, test, et deploy. Ces \u00e9tapes s'ex\u00e9cutent dans l'ordre sp\u00e9cifi\u00e9, et l'\u00e9tape suivante commence seulement une fois que tous les jobs de l'\u00e9tape pr\u00e9c\u00e9dente sont termin\u00e9s[2].</p> <p>Jobs : Chaque job repr\u00e9sente une unit\u00e9 de travail sp\u00e9cifique ex\u00e9cut\u00e9e lors de l'\u00e9tape correspondante. Un job peut compiler du code, ex\u00e9cuter des tests, d\u00e9ployer dans un environnement de pr\u00e9production, ou effectuer n'importe quelle autre t\u00e2che automatisable[2].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#le-fichier-gitlab-ciyml","title":"Le fichier <code>.gitlab-ci.yml</code>","text":"<p>Le c\u0153ur de la configuration CI/CD dans GitLab est le fichier <code>.gitlab-ci.yml</code>, qui doit \u00eatre plac\u00e9 \u00e0 la racine du projet[1][3]. Ce fichier YAML d\u00e9finit la structure compl\u00e8te du pipeline, les \u00e9tapes, les jobs et les actions \u00e0 automatiser.</p> <p>GitLab d\u00e9tecte automatiquement ce fichier et commence \u00e0 ex\u00e9cuter le pipeline \u00e0 chaque fois que des modifications sont transmises via un push vers le d\u00e9p\u00f4t[3]. Le fichier <code>.gitlab-ci.yml</code> offre une flexibilit\u00e9 et une personnalisation \u00e9lev\u00e9es, permettant de d\u00e9finir exactement ce qui doit \u00eatre ex\u00e9cut\u00e9 et comment[1].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#le-modele-de-livraison-continue","title":"Le mod\u00e8le de livraison continue","text":"<p>Pour bien comprendre le cycle CI/CD, il est important de distinguer trois concepts :</p> <p>Int\u00e9gration Continue (CI) : Le code est automatiquement compil\u00e9 et test\u00e9 \u00e0 chaque modification. Cela signifie que les changements sont valid\u00e9s imm\u00e9diatement apr\u00e8s leur soumission[2].</p> <p>Livraison Continue (CD) : Cette approche compl\u00e8te l'int\u00e9gration continue en automatisant le pipeline pour la sortie de nouvelles versions. \u00c0 tout moment, l'application reste d\u00e9ployable vers un environnement donn\u00e9 (par exemple, pr\u00e9production, production), en un seul clic ou par le biais d'un d\u00e9clenchement automatique[2].</p> <p>D\u00e9ploiement Continu : Cet niveau pousse encore plus loin la logique d'automatisation. Chaque compilation r\u00e9ussie est directement mise en production, sans validation manuelle. Ce niveau d'automatisation requiert une confiance totale dans les tests automatis\u00e9s et les processus de d\u00e9ploiement[2].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#premier-pipeline","title":"Premier pipeline","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#configuration-de-base","title":"Configuration de base","text":"<p>La cr\u00e9ation d'une premi\u00e8re pipeline CI/CD avec GitLab commence par l'ajout du fichier <code>.gitlab-ci.yml</code> \u00e0 la racine du projet. Ce fichier d\u00e9finit les \u00e9tapes de base et les jobs[3].</p> <p>Voici un exemple \u00e9l\u00e9mentaire de pipeline :</p> YAML<pre><code>stages:\n  - build\n  - test\n  - deploy\n\nbuild_job:\n  stage: build\n  script:\n    - echo \"Building the application...\"\n\ntest_job:\n  stage: test\n  script:\n    - echo \"Running tests...\"\n\ndeploy_job:\n  stage: deploy\n  script:\n    - echo \"Deploying to production...\"\n  environment:\n    name: production\n</code></pre> <p>Cette configuration d\u00e9finit trois \u00e9tapes cl\u00e9s : compilation, test et d\u00e9ploiement[2]. Chaque \u00e9tape contient un job qui ex\u00e9cute un script simple. L'\u00e9l\u00e9ment <code>stages</code> \u00e9num\u00e8re l'ordre d'ex\u00e9cution des \u00e9tapes, tandis que chaque job d\u00e9finit le travail \u00e0 effectuer dans l'\u00e9tape correspondante.</p> <p>Le mot-cl\u00e9 <code>script</code> contient les commandes shell \u00e0 ex\u00e9cuter. L'\u00e9l\u00e9ment <code>environment</code> permet de d\u00e9finir l'environnement de destination pour le d\u00e9ploiement[2].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#etapes-predefinies","title":"\u00c9tapes pr\u00e9d\u00e9finies","text":"<p>GitLab propose deux stages pr\u00e9d\u00e9finis qui sont toujours lanc\u00e9s automatiquement[5] :</p> <ul> <li><code>.pre</code> : S'ex\u00e9cute au d\u00e9but du pipeline, avant tous les autres stages</li> <li><code>.post</code> : S'ex\u00e9cute \u00e0 la fin du pipeline, apr\u00e8s tous les autres stages</li> </ul> <p>Ces stages peuvent \u00eatre utilis\u00e9s pour des t\u00e2ches de pr\u00e9paration ou de nettoyage globales sans modifier la structure principale du pipeline.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#declenchement-automatique","title":"D\u00e9clenchement automatique","text":"<p>Une fonctionnalit\u00e9 fondamentale de GitLab CI/CD est le d\u00e9clenchement automatique des pipelines[1]. \u00c0 chaque push ou merge request, le pipeline est automatiquement lanc\u00e9, garantissant que chaque modification est test\u00e9e et valid\u00e9e avant d'\u00eatre fusionn\u00e9e dans la branche principale.</p> <p>Cette automatisation \u00e9limine le risque oubli d'ex\u00e9cuter manuellement les tests, assurant une coh\u00e9rence et une fiabilit\u00e9 accrues dans le processus de d\u00e9veloppement.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#onglets-code-et-build","title":"Onglets Code et Build","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#navigation-dans-linterface-gitlab","title":"Navigation dans l'interface GitLab","text":"<p>Une fois le fichier <code>.gitlab-ci.yml</code> commit\u00e9 et push\u00e9, GitLab commence automatiquement \u00e0 ex\u00e9cuter le pipeline[3]. Les r\u00e9sultats peuvent \u00eatre suivis via l'interface web de GitLab.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#onglet-build-cicd","title":"Onglet Build (CI/CD)","text":"<p>L'onglet CI/CD dans GitLab permet de suivre l'ex\u00e9cution du pipeline en temps r\u00e9el[5]. Cet onglet fournit une vue d\u00e9taill\u00e9e de chaque \u00e9tape et de chaque job du pipeline.</p> <p>Visualisation des \u00e9tapes : Chaque \u00e9tape du pipeline est affich\u00e9e horizontalement, montrant son statut actuel (en cours, r\u00e9ussi, \u00e9chou\u00e9). Les jobs contenus dans chaque \u00e9tape sont visibles individuellement.</p> <p>D\u00e9tails des jobs : En cliquant sur un job, les utilisateurs peuvent voir les d\u00e9tails complets de son ex\u00e9cution, y compris les logs en temps r\u00e9el de la sortie du script. Ces logs sont essentiels pour diagnostiquer les probl\u00e8mes ou comprendre le flux d'ex\u00e9cution[5].</p> <p>Runners utilis\u00e9s : GitLab affiche le runner Docker utilis\u00e9 pour ex\u00e9cuter les jobs. Par d\u00e9faut, <code>gitlab.com</code> utilise un runner Docker avec une image pr\u00e9d\u00e9finie. Dans l'exemple suivant, le runner utilise l'image <code>ruby:2.5</code> pour ex\u00e9cuter un job Ruby[5].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#onglet-code","title":"Onglet Code","text":"<p>L'onglet Code fournit une vue sur la structure du d\u00e9p\u00f4t, permettant de visualiser et d'acc\u00e9der aux fichiers du projet[2]. C'est ici que le fichier <code>.gitlab-ci.yml</code> doit \u00eatre plac\u00e9 et commit\u00e9 pour que GitLab d\u00e9tecte et ex\u00e9cute la pipeline.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#plus-de-details-sur-les-pipelines","title":"Plus de d\u00e9tails sur les pipelines","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#structure-avancee-des-pipelines","title":"Structure avanc\u00e9e des pipelines","text":"<p>Au-del\u00e0 de la configuration de base, GitLab CI/CD offre des capacit\u00e9s avanc\u00e9es pour structurer et optimiser les pipelines[3].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#compilation-dune-application-nodejs","title":"Compilation d'une application Node.js","text":"<p>Un exemple concret d'une pipeline plus sophistiqu\u00e9e pourrait \u00eatre la compilation et le d\u00e9ploiement d'une application Node.js :</p> YAML<pre><code>stages:\n  - build\n  - test\n  - deploy\n\nbuild_job:\n  stage: build\n  image: node:14\n  script:\n    - npm install\n    - npm run build\n  artifacts:\n    paths:\n      - dist/\n    expire_in: 1 hour\n\ntest_job:\n  stage: test\n  image: node:14\n  script:\n    - npm install\n    - npm test\n  coverage: '/Coverage: \\d+\\.\\d+%/'\n\ndeploy_job:\n  stage: deploy\n  image: ruby:latest\n  script:\n    - apt-get update &amp;&amp; apt-get install -y dpl\n    - dpl --provider=heroku --app=$HEROKU_APP --api-key=$HEROKU_API_KEY\n  environment:\n    name: production\n    url: https://my-app.herokuapp.com\n  only:\n    - main\n</code></pre> <p>Cette pipeline illustre plusieurs concepts avanc\u00e9s[2] :</p> <ul> <li>Images Docker : Chaque job peut utiliser une image Docker diff\u00e9rente adapt\u00e9e \u00e0 ses besoins</li> <li>Artefacts : Les fichiers de sortie (comme <code>dist/</code>) peuvent \u00eatre conserv\u00e9s et transmis aux jobs suivants</li> <li>Variables d'environnement : Des variables sensibles comme <code>$HEROKU_API_KEY</code> sont stock\u00e9es de mani\u00e8re s\u00e9curis\u00e9e</li> <li>Conditions d'ex\u00e9cution : Le job de d\u00e9ploiement s'ex\u00e9cute uniquement sur la branche <code>main</code></li> <li>Couverture de code : Les m\u00e9triques de couverture peuvent \u00eatre extraites des logs</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#deploiement-vers-plusieurs-environnements","title":"D\u00e9ploiement vers plusieurs environnements","text":"<p>Une capacit\u00e9 essentielle des pipelines modernes est la gestion des d\u00e9ploiements vers diff\u00e9rents environnements[2]. GitLab propose des fonctionnalit\u00e9s natives pour g\u00e9rer cela :</p> YAML<pre><code>stages:\n  - build\n  - test\n  - deploy_staging\n  - deploy_production\n\nbuild_job:\n  stage: build\n  script:\n    - echo \"Building application...\"\n\ntest_job:\n  stage: test\n  script:\n    - echo \"Running tests...\"\n\ndeploy_staging:\n  stage: deploy_staging\n  script:\n    - echo \"Deploying to staging environment...\"\n  environment:\n    name: staging\n    url: https://staging.example.com\n  only:\n    - develop\n\ndeploy_production:\n  stage: deploy_production\n  script:\n    - echo \"Deploying to production...\"\n  environment:\n    name: production\n    url: https://example.com\n  when: manual\n  only:\n    - main\n</code></pre> <p>Dans cet exemple, la configuration diff\u00e8re selon l'environnement[2] :</p> <ul> <li>Staging : Le d\u00e9ploiement s'effectue automatiquement sur la branche <code>develop</code></li> <li>Production : Le d\u00e9ploiement requiert une approbation manuelle (<code>when: manual</code>) pour \u00e9viter tout d\u00e9ploiement accidentel, et n'est disponible que sur la branche <code>main</code></li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#gestion-des-runners","title":"Gestion des runners","text":"<p>GitLab fournit des runners partag\u00e9s par d\u00e9faut qui peuvent \u00eatre utilis\u00e9s imm\u00e9diatement sans configuration suppl\u00e9mentaire[1]. Ces runners sont pr\u00e9configur\u00e9s pour ex\u00e9cuter les jobs CI/CD. Cependant, si des besoins sp\u00e9cifiques existent, il est possible de configurer des runners personnalis\u00e9s pour un contr\u00f4le plus granulaire[1].</p> <p>GitLab Runner, un projet open source \u00e9crit en Go, fonctionne sur des machines physiques, virtuelles ou dans des conteneurs pour ex\u00e9cuter les jobs d\u00e9finis dans le fichier <code>.gitlab-ci.yml</code>[4].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#reutilisation-et-optimisation-des-pipelines","title":"R\u00e9utilisation et optimisation des pipelines","text":"<p>GitLab r\u00e9volutionne la gestion des pipelines CI/CD en introduisant deux innovations majeures[3] :</p> <p>Le catalogue CI/CD : Une plateforme centralis\u00e9e o\u00f9 les \u00e9quipes peuvent d\u00e9couvrir, r\u00e9utiliser et optimiser les diff\u00e9rents composants CI/CD. Cela \u00e9vite la duplication de code et standardise les bonnes pratiques au sein de l'organisation[3].</p> <p>CI/CD Steps : Un nouveau langage de programmation exp\u00e9rimental d\u00e9di\u00e9 \u00e0 l'automatisation DevSecOps, permettant une personnalisation encore plus pouss\u00e9e des pipelines[3].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#securite-dans-les-pipelines","title":"S\u00e9curit\u00e9 dans les pipelines","text":"<p>La s\u00e9curit\u00e9 est int\u00e9gr\u00e9e dans la pipeline CI/CD d\u00e8s le d\u00e9part. Le fichier <code>.gitlab-ci.yml</code> peut \u00eatre configur\u00e9 pour d\u00e9clencher automatiquement des scans de s\u00e9curit\u00e9 \u00e0 plusieurs \u00e9tapes[3] :</p> <ul> <li>Validation initiale du code</li> <li>Analyse des conteneurs</li> <li>Analyse des d\u00e9pendances</li> <li>Scanning de s\u00e9curit\u00e9 dynamique et statique (SAST)</li> </ul> <p>Ces fonctionnalit\u00e9s s'ex\u00e9cutent automatiquement \u00e0 chaque modification de code pour rechercher les vuln\u00e9rabilit\u00e9s, les violations des exigences de conformit\u00e9 et les erreurs de configuration de s\u00e9curit\u00e9[3].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#variables-denvironnement-et-secrets","title":"Variables d'environnement et secrets","text":"<p>Les variables d'environnement jouent un r\u00f4le crucial dans les pipelines[2]. Elles permettent de stocker des informations sensibles (identifiants de connexion, cl\u00e9s d'API, tokens) et de les utiliser en toute s\u00e9curit\u00e9 dans les processus CI/CD sans les exposer dans le code source.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#logs-et-debogage","title":"Logs et d\u00e9bogage","text":"<p>La visualisation des logs de pipeline est essentielle pour comprendre les d\u00e9faillances ou le comportement des jobs. Chaque job g\u00e9n\u00e8re des logs d\u00e9taill\u00e9s que les d\u00e9veloppeurs peuvent consulter pour diagnostiquer les probl\u00e8mes. Ces logs affichent la sortie compl\u00e8te des scripts ex\u00e9cut\u00e9s, permettant une analyse approfondie des erreurs[5].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#conditions-dexecution-avancees","title":"Conditions d'ex\u00e9cution avanc\u00e9es","text":"<p>GitLab permet de d\u00e9finir des conditions complexes pour contr\u00f4ler quand les jobs s'ex\u00e9cutent[2] :</p> <ul> <li>only : Le job n'ex\u00e9cute que si certaines conditions sont remplies (branches, tags, \u00e9v\u00e9nements)</li> <li>except : Le job s'ex\u00e9cute sauf si certaines conditions sont remplies</li> <li>when : Permet de sp\u00e9cifier si le job s'ex\u00e9cute automatiquement ou manuellement</li> <li>rules : Un syst\u00e8me plus puissant et flexible pour contr\u00f4ler l'ex\u00e9cution des jobs</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#artefacts-et-dependances","title":"Artefacts et d\u00e9pendances","text":"<p>Les artefacts permettent de conserver les fichiers g\u00e9n\u00e9r\u00e9s lors de l'ex\u00e9cution d'un job et de les transmettre aux jobs suivants[2]. Cela est essentiel pour les pipelines multi-\u00e9tapes o\u00f9 le r\u00e9sultat d'une \u00e9tape est n\u00e9cessaire pour la suivante. Par exemple, une phase de build g\u00e9n\u00e8re des binaires qui doivent \u00eatre test\u00e9s dans la phase de test.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#metriques-de-qualite-et-rapports","title":"M\u00e9triques de qualit\u00e9 et rapports","text":"<p>GitLab int\u00e8gre nativement la g\u00e9n\u00e9ration de rapports sur la qualit\u00e9 du code, la couverture des tests, les performances et la s\u00e9curit\u00e9. Ces m\u00e9triques peuvent \u00eatre extraites automatiquement des logs ou g\u00e9n\u00e9r\u00e9s explicitement par des outils sp\u00e9cialis\u00e9s, fournissant une visibilit\u00e9 compl\u00e8te sur la sant\u00e9 du projet.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap02/#integration-avec-dautres-outils","title":"Int\u00e9gration avec d'autres outils","text":"<p>GitLab CI/CD peut \u00eatre int\u00e9gr\u00e9 avec d'autres outils populaires du DevOps comme Code Climate pour l'analyse de qualit\u00e9, des services de d\u00e9ploiement comme Heroku, ou des syst\u00e8mes de notification pour alerter les d\u00e9veloppeurs des d\u00e9faillances de pipeline.</p> <p>Ce chapitre constitue une fondation solide pour comprendre GitLab CI/CD. Le cheminement d'apprentissage commence par la compr\u00e9hension des concepts fondamentaux de l'int\u00e9gration et de la livraison continues, puis progresse vers la configuration pratique d'une premi\u00e8re pipeline simple. Les utilisateurs acqui\u00e8rent ensuite la capacit\u00e9 \u00e0 lire et interpr\u00e9ter l'interface de GitLab, avant de se familiariser avec des configurations plus complexes incluant plusieurs environnements, des scans de s\u00e9curit\u00e9 et des optimisations avanc\u00e9es. Cette progression logique permet une mont\u00e9e en comp\u00e9tence graduelle et une ma\u00eetrise progressive de GitLab CI/CD.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/","title":"Citations","text":"<ul> <li>https://mink-agency.com/comment-utiliser-gitlab-ci-cd-pour-ameliorer-votre-flow-de-developpement/</li> <li>https://about.gitlab.com/fr-fr/blog/getting-started-with-gitlab-understanding-ci-cd/</li> <li>https://code-garage.com/blog/utiliser-gitlab-et-github-pour-construire-son-pipeline-de-ci-cd</li> <li>https://galadrim.fr/blog/comment-utiliser-gitlab-ci-cd-pour-ameliorer-votre-flow-de-developpement/</li> <li>https://devops.isc.heia-fr.ch/lecture/gitlab-cicd/advanced/</li> <li>https://share.gitlab-pages.din.developpement-durable.gouv.fr/devops/formation/competences-livraison-continue/3-build/tp-workflow-git-2.html</li> <li>https://blog.stephane-robert.info/docs/pipeline-cicd/gitlab/conditions/</li> <li>https://docs.gitlab.com/ci/steps/</li> <li>https://cto-externe.fr/actualites-developpement/deploiement-php-gitlab-ci-cd/</li> <li>https://blog.antoinemayer.fr/2022/06/21/a-la-decouverte-de-gitlab-ci/</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 287</li> <li>completion_tokens: 7477</li> <li>total_tokens: 7764</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.112, 'request_cost': 0.006, 'total_cost': 0.119}</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#content","title":"Content","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#chapitre-3-principales-notions-gitlab-cicd","title":"Chapitre 3 : Principales notions GitLab CI/CD","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#les-etapes-stages","title":"Les \u00e9tapes (Stages)","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#definition-et-concept-fondamental","title":"D\u00e9finition et concept fondamental","text":"<p>Les stages constituent les briques \u00e9l\u00e9mentaires de l'architecture d'une pipeline GitLab CI/CD[1][4]. Un stage repr\u00e9sente une phase logique d'ex\u00e9cution au sein du pipeline, regroupant un ensemble de t\u00e2ches (jobs) qui doivent s'accomplir dans un ordre d\u00e9fini. La structure hi\u00e9rarchique s'organise ainsi : pipeline &gt; stages &gt; jobs.</p> <p>La puissance des stages r\u00e9side dans leur ex\u00e9cution s\u00e9quentielle et garantie[4]. Chaque stage ne commence son ex\u00e9cution que lorsque tous les jobs du stage pr\u00e9c\u00e9dent se sont achev\u00e9s avec succ\u00e8s. En revanche, au sein d'un m\u00eame stage, les diff\u00e9rents jobs s'ex\u00e9cutent en parall\u00e8le par d\u00e9faut, ce qui optimise les temps de traitement et les ressources disponibles[4].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#architecture-classique-dune-pipeline","title":"Architecture classique d'une pipeline","text":"<p>Une pipeline CI/CD bien structur\u00e9e suit g\u00e9n\u00e9ralement ce mod\u00e8le organisationnel[1][3]:</p> <p>Phase d'int\u00e9gration continue : - Build : compilation du code source et packaging du logiciel - Test : ex\u00e9cution des tests unitaires, d'int\u00e9gration et de non-r\u00e9gression - Lint : v\u00e9rification de la qualit\u00e9 de code et conformit\u00e9 aux standards</p> <p>Phase de d\u00e9ploiement continu : - Review : d\u00e9ploiement de la solution dans un environnement isol\u00e9 pour validation - Staging : d\u00e9ploiement en environnement de pr\u00e9production - Production : d\u00e9ploiement du software dans son environnement final de production</p> <p>Cette segmentation logique permet \u00e0 une \u00e9quipe de d\u00e9veloppement d'automatiser le cycle complet : un simple commit d\u00e9clenche la pipeline qui g\u00e9n\u00e8re un build, lance la suite de tests, et d\u00e9ploie la nouvelle version en staging ou production[4].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#configuration-des-stages-dans-gitlab-ciyml","title":"Configuration des stages dans <code>.gitlab-ci.yml</code>","text":"<p>La d\u00e9finition des stages s'effectue en d\u00e9but de fichier <code>.gitlab-ci.yml</code> \u00e0 la racine du projet. Cette d\u00e9claration \u00e9tablit l'ordre d'ex\u00e9cution global de la pipeline :</p> YAML<pre><code>stages:\n  - build\n  - test\n  - deploy\n</code></pre> <p>La pr\u00e9sence du mot-cl\u00e9 <code>stages</code> au niveau racine du fichier de configuration structure l'ensemble du workflow[1]. L'ordre listage d\u00e9termine directement l'ordre d'ex\u00e9cution s\u00e9quentielle de la pipeline.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#exemple-concret-avec-trois-stages","title":"Exemple concret avec trois stages","text":"YAML<pre><code>stages:\n  - build\n  - test\n  - deploy\n\nbuild_job:\n  stage: build\n  script:\n    - echo \"Building the application...\"\n    - npm install\n    - npm run build\n\ntest_job:\n  stage: test\n  script:\n    - echo \"Running tests...\"\n    - npm run test\n\ndeploy_job:\n  stage: deploy\n  script:\n    - echo \"Deploying to production...\"\n    - ./deploy.sh\n</code></pre> <p>Dans cet exemple[2], la pipeline s'ex\u00e9cute en trois temps distincts : 1. Le stage <code>build</code> compile l'application 2. Une fois le build r\u00e9ussi, le stage <code>test</code> lance la suite de tests 3. Si tous les tests passent, le stage <code>deploy</code> ex\u00e9cute le d\u00e9ploiement</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#stages-avec-jobs-paralleles","title":"Stages avec jobs parall\u00e8les","text":"<p>Pour optimiser les temps de traitement, plusieurs jobs peuvent s'ex\u00e9cuter au sein d'un m\u00eame stage[4] :</p> YAML<pre><code>stages:\n  - build\n  - test\n  - deploy\n\nbuild:\n  stage: build\n  script:\n    - npm install\n    - npm run build\n\ntest_unit:\n  stage: test\n  script:\n    - npm run test:unit\n\ntest_integration:\n  stage: test\n  script:\n    - npm run test:integration\n\ntest_lint:\n  stage: test\n  script:\n    - npm run lint\n\ndeploy:\n  stage: deploy\n  script:\n    - ./deploy.sh\n</code></pre> <p>Dans cette configuration, les trois jobs du stage <code>test</code> (<code>test_unit</code>, <code>test_integration</code>, <code>test_lint</code>) s'ex\u00e9cutent en parall\u00e8le une fois le stage <code>build</code> termin\u00e9. Cette parall\u00e9lisation r\u00e9duit consid\u00e9rablement le temps total d'ex\u00e9cution de la pipeline.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#les-scripts","title":"Les scripts","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#fondamentaux-des-scripts","title":"Fondamentaux des scripts","text":"<p>Les scripts constituent le c\u0153ur ex\u00e9cutoire des jobs dans GitLab CI/CD[1]. Le mot-cl\u00e9 <code>script</code> d\u00e9finit une s\u00e9rie de commandes shell qui s'ex\u00e9cutent s\u00e9quentiellement lorsque le job est d\u00e9clench\u00e9. Les scripts s'ex\u00e9cutent sur le GitLab Runner (agent d'ex\u00e9cution) avec les permissions et l'environnement d\u00e9finis par la configuration du runner.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#structure-de-base","title":"Structure de base","text":"YAML<pre><code>job_name:\n  stage: build\n  script:\n    - command_1\n    - command_2\n    - command_3\n</code></pre> <p>Chaque ligne du script s'ex\u00e9cute successivement. Si une commande \u00e9choue (code de sortie non-z\u00e9ro), le job entier est marqu\u00e9 comme \u00e9chou\u00e9 par d\u00e9faut, et les commandes suivantes ne s'ex\u00e9cutent pas[1]. Cette comportement assure l'int\u00e9grit\u00e9 du processus de build.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#exemple-concret-avec-npm","title":"Exemple concret avec npm","text":"YAML<pre><code>build_job:\n  stage: build\n  script:\n    - echo \"Building the application...\"\n    - npm install\n    - npm run build\n</code></pre> <p>L'ex\u00e9cution suit cette s\u00e9quence : 1. Affichage du message \"Building the application...\" 2. Installation des d\u00e9pendances npm 3. Ex\u00e9cution du script build d\u00e9fini dans <code>package.json</code></p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#scripts-multilignes-et-variables-denvironnement","title":"Scripts multilignes et variables d'environnement","text":"<p>Les scripts peuvent utiliser les variables d'environnement standard et celles d\u00e9finies dans GitLab[1] :</p> YAML<pre><code>deploy_job:\n  stage: deploy\n  script:\n    - echo \"Deploying to $DEPLOY_SERVER\"\n    - export APP_NAME=\"my-application\"\n    - ./scripts/deploy.sh\n    - echo \"Deployment completed for $APP_NAME\"\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#gestion-des-erreurs-et-continue_on_failure","title":"Gestion des erreurs et continue_on_failure","text":"<p>Par d\u00e9faut, si une commande \u00e9choue, le job s'arr\u00eate. Il est possible de modifier ce comportement[4] :</p> YAML<pre><code>test_job:\n  stage: test\n  script:\n    - npm run test\n    - npm run lint\n    - npm run security-check\n  allow_failure: true\n</code></pre> <p>Le param\u00e8tre <code>allow_failure: true</code> indique \u00e0 GitLab que l'\u00e9chec de ce job ne devrait pas bloquer l'ex\u00e9cution des stages suivants. Le job est marqu\u00e9 comme \u00e9chou\u00e9, mais le pipeline continue.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#scripts-avec-conditions-et-boucles","title":"Scripts avec conditions et boucles","text":"<p>Les scripts supportent la syntaxe shell compl\u00e8te, incluant structures conditionnelles et boucles[1] :</p> YAML<pre><code>deployment_job:\n  stage: deploy\n  script:\n    - |\n      if [ \"$CI_COMMIT_BRANCH\" == \"main\" ]; then\n        echo \"Deploying to production\"\n        ./deploy.sh production\n      elif [ \"$CI_COMMIT_BRANCH\" == \"develop\" ]; then\n        echo \"Deploying to staging\"\n        ./deploy.sh staging\n      else\n        echo \"No deployment for this branch\"\n      fi\n</code></pre> <p>L'utilisation du pipe <code>|</code> permet d'\u00e9crire des scripts multilignes avec support complet de la syntaxe shell.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#scripts-avec-images-docker","title":"Scripts avec images Docker","text":"YAML<pre><code>build_java:\n  stage: build\n  image: maven:3.8-openjdk-11\n  script:\n    - mvn clean package\n\nbuild_node:\n  stage: build\n  image: node:16\n  script:\n    - npm install\n    - npm run build\n</code></pre> <p>Chaque job peut sp\u00e9cifier son propre environnement Docker, adaptant les outils disponibles \u00e0 la nature du travail.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#les-environnements","title":"Les environnements","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#concept-denvironnement-dans-gitlab-cicd","title":"Concept d'environnement dans GitLab CI/CD","text":"<p>Les environnements repr\u00e9sentent les cibles d'infrastructure vers lesquelles les applications sont d\u00e9ploy\u00e9es[2]. GitLab propose une gestion int\u00e9gr\u00e9e des environnements permettant de suivre les d\u00e9ploiements, de maintenir l'historique des versions et de contr\u00f4ler les approbations manuelles selon l'environnement cible.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#types-denvironnements-courants","title":"Types d'environnements courants","text":"<p>Une application traverse g\u00e9n\u00e9ralement plusieurs environnements avant d'atteindre les utilisateurs finaux[2] :</p> <ul> <li>D\u00e9veloppement (development) : environnement local ou de d\u00e9veloppement</li> <li>Int\u00e9gration (integration) : tests d'int\u00e9gration continue</li> <li>Pr\u00e9production (staging) : environnement de test proche de la production</li> <li>Production (production) : environnement accessible aux utilisateurs finaux</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#configuration-basique-dun-environnement","title":"Configuration basique d'un environnement","text":"YAML<pre><code>deploy_staging:\n  stage: deploy_staging\n  script:\n    - echo \"Deploying to staging...\"\n  environment:\n    name: staging\n    url: https://staging.example.com\n\ndeploy_production:\n  stage: deploy_production\n  script:\n    - echo \"Deploying to production...\"\n  environment:\n    name: production\n    url: https://example.com\n</code></pre> <p>Le bloc <code>environment</code> contient : - name : identifiant unique de l'environnement - url : adresse accessible pour v\u00e9rifier le d\u00e9ploiement</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#deploiement-avec-approbation-manuelle","title":"D\u00e9ploiement avec approbation manuelle","text":"<p>Pour \u00e9viter les d\u00e9ploiements accidentels en production, une approbation manuelle peut \u00eatre requise[2] :</p> YAML<pre><code>stages:\n  - build\n  - test\n  - deploy_staging\n  - deploy_production\n\nbuild:\n  stage: build\n  script:\n    - npm install\n    - npm run build\n\ntest:\n  stage: test\n  script:\n    - npm run test\n\ndeploy_staging:\n  stage: deploy_staging\n  script:\n    - echo \"Deploying to staging...\"\n  environment:\n    name: staging\n    url: https://staging.example.com\n\ndeploy_production:\n  stage: deploy_production\n  script:\n    - echo \"Deploying to production...\"\n  environment:\n    name: production\n    url: https://example.com\n  when: manual\n</code></pre> <p>Le param\u00e8tre <code>when: manual</code>[2] transforme le d\u00e9ploiement en production en action manuelle. Cette approbation explicite pr\u00e9vient les d\u00e9ploiements accidentels sur l'environnement critique.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#suivi-de-lhistorique-des-deploiements","title":"Suivi de l'historique des d\u00e9ploiements","text":"<p>GitLab maintient automatiquement un historique complet des d\u00e9ploiements vers chaque environnement. Cet historique affiche[2] : - Date et heure du d\u00e9ploiement - Branche ou tag d'o\u00f9 provient le d\u00e9ploiement - Auteur du d\u00e9ploiement - Statut du d\u00e9ploiement (r\u00e9ussi/\u00e9chou\u00e9) - Commit associ\u00e9</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#configuration-denvironnements-dynamiques","title":"Configuration d'environnements dynamiques","text":"<p>Pour les applications avec plusieurs instances ou environnements variables[2] :</p> YAML<pre><code>deploy_preview:\n  stage: deploy\n  script:\n    - ./deploy.sh $PREVIEW_ENV\n  environment:\n    name: preview-$CI_MERGE_REQUEST_IID\n    url: https://preview-$CI_MERGE_REQUEST_IID.example.com\n    auto_stop_in: 1 week\n  only:\n    - merge_requests\n</code></pre> <p>Cette configuration cr\u00e9e un environnement de review temporaire pour chaque merge request, accessible pendant une semaine avant suppression automatique.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#gestion-des-variables","title":"Gestion des variables","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#principe-des-variables-cicd","title":"Principe des variables CI/CD","text":"<p>Les variables constituent le m\u00e9canisme fondamental pour param\u00e9trer les pipelines sans modifier le code source[1]. GitLab fournit deux cat\u00e9gories de variables :</p> <ul> <li>Variables pr\u00e9d\u00e9finies (built-in) : fournies automatiquement par GitLab (ex: CI_COMMIT_SHA, CI_PROJECT_NAME)</li> <li>Variables personnalis\u00e9es : d\u00e9finies par l'utilisateur au niveau projet ou pipeline</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#variables-predefinies-essentielles","title":"Variables pr\u00e9d\u00e9finies essentielles","text":"<p>GitLab expose automatiquement un ensemble riche de variables contextuelles :</p> Variable Description <code>$CI_COMMIT_SHA</code> Hash complet du commit (40 caract\u00e8res) <code>$CI_COMMIT_SHORT_SHA</code> Hash court du commit (8 caract\u00e8res) <code>$CI_COMMIT_BRANCH</code> Branche depuis laquelle le pipeline s'ex\u00e9cute <code>$CI_COMMIT_TAG</code> Tag Git si le pipeline est d\u00e9clench\u00e9 par un tag <code>$CI_COMMIT_MESSAGE</code> Message du commit <code>$CI_PROJECT_NAME</code> Nom du projet GitLab <code>$CI_PROJECT_PATH</code> Chemin complet du projet (groupe/projet) <code>$CI_BUILD_ID</code> Identifiant unique du job <code>$CI_PIPELINE_ID</code> Identifiant unique de la pipeline <code>$CI_MERGE_REQUEST_IID</code> Identifiant de la merge request (si applicable)"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#utilisation-des-variables-predefinies","title":"Utilisation des variables pr\u00e9d\u00e9finies","text":"YAML<pre><code>logging_job:\n  stage: build\n  script:\n    - echo \"Commit SHA: $CI_COMMIT_SHA\"\n    - echo \"Branch: $CI_COMMIT_BRANCH\"\n    - echo \"Project: $CI_PROJECT_NAME\"\n    - echo \"Pipeline ID: $CI_PIPELINE_ID\"\n    - echo \"Message du commit: $CI_COMMIT_MESSAGE\"\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#definition-de-variables-personnalisees-au-niveau-projet","title":"D\u00e9finition de variables personnalis\u00e9es au niveau projet","text":"<p>Les variables au niveau projet s'appliquent \u00e0 toutes les pipelines du projet[1] :</p> YAML<pre><code>job_name:\n  stage: build\n  script:\n    - echo \"Database URL: $DATABASE_URL\"\n    - echo \"API Token: $API_TOKEN\"\n</code></pre> <p>Ces variables se configurent dans l'interface GitLab via Param\u00e8tres du projet &gt; CI/CD &gt; Variables.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#variables-au-niveau-pipeline","title":"Variables au niveau pipeline","text":"<p>Les variables d\u00e9finies dans le fichier <code>.gitlab-ci.yml</code> s'appliquent \u00e0 la pipeline courante :</p> YAML<pre><code>variables:\n  DATABASE_HOST: \"localhost\"\n  DATABASE_PORT: \"5432\"\n  NODE_ENV: \"production\"\n  LOG_LEVEL: \"info\"\n\nbuild_job:\n  stage: build\n  script:\n    - echo \"Environment: $NODE_ENV\"\n    - echo \"Database: $DATABASE_HOST:$DATABASE_PORT\"\n    - echo \"Log Level: $LOG_LEVEL\"\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#variables-au-niveau-job","title":"Variables au niveau job","text":"<p>Les variables d\u00e9finies dans un job sp\u00e9cifique surpassent les variables globales :</p> YAML<pre><code>variables:\n  APP_ENV: \"production\"\n\nbuild_dev:\n  stage: build\n  variables:\n    APP_ENV: \"development\"\n  script:\n    - echo \"Running in $APP_ENV environment\"\n\nbuild_prod:\n  stage: build\n  script:\n    - echo \"Running in $APP_ENV environment\"\n</code></pre> <p>Dans cet exemple, <code>build_dev</code> ex\u00e9cute avec <code>APP_ENV=development</code>, tandis que <code>build_prod</code> utilise <code>APP_ENV=production</code>.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#variables-protegees-et-masquees","title":"Variables prot\u00e9g\u00e9es et masqu\u00e9es","text":"<p>Pour les donn\u00e9es sensibles (tokens, cl\u00e9s API, mots de passe) :</p> YAML<pre><code>deploy_job:\n  stage: deploy\n  variables:\n    # Cette variable n'est disponible que sur branches prot\u00e9g\u00e9es\n    PROD_API_KEY:\n      value: \"sk-1234567890abcdef\"\n      protected: true\n    # Cette variable est masqu\u00e9e dans les logs\n    SECRET_TOKEN:\n      value: \"secret-12345\"\n      protected: true\n  script:\n    - curl -H \"Authorization: Bearer $PROD_API_KEY\" https://api.example.com/deploy\n</code></pre> <p>Les variables prot\u00e9g\u00e9es ne s'ex\u00e9cutent que sur les branches prot\u00e9g\u00e9es (main, develop) et les tags prot\u00e9g\u00e9s, offrant une couche de s\u00e9curit\u00e9 suppl\u00e9mentaire.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#interpolation-et-concatenation-de-variables","title":"Interpolation et concat\u00e9nation de variables","text":"YAML<pre><code>variables:\n  REGISTRY: \"registry.example.com\"\n  IMAGE_NAME: \"my-app\"\n  IMAGE_TAG: \"latest\"\n\nbuild_image:\n  stage: build\n  script:\n    - docker build -t $REGISTRY/$IMAGE_NAME:$IMAGE_TAG .\n    - docker push $REGISTRY/$IMAGE_NAME:$IMAGE_TAG\n    - echo \"Image pushed: $REGISTRY/$IMAGE_NAME:$IMAGE_TAG\"\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#variables-issues-dartefacts","title":"Variables issues d'artefacts","text":"<p>GitLab permet d'extraire des variables depuis les fichiers d'artefacts[1] :</p> YAML<pre><code>build_job:\n  stage: build\n  script:\n    - npm run build\n    - echo \"BUILD_VERSION=1.2.3\" &gt;&gt; build.env\n  artifacts:\n    reports:\n      dotenv: build.env\n\ndeploy_job:\n  stage: deploy\n  dependencies:\n    - build_job\n  script:\n    - echo \"Deploying version: $BUILD_VERSION\"\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#controle-du-flux-dexecution","title":"Contr\u00f4le du flux d'ex\u00e9cution","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#concept-de-controle-du-flux","title":"Concept de contr\u00f4le du flux","text":"<p>Le contr\u00f4le du flux d\u00e9termine quand et comment les jobs s'ex\u00e9cutent au sein d'une pipeline. GitLab propose plusieurs m\u00e9canismes pour orchestrer l'ex\u00e9cution conditionnelle, permettant une fine granularit\u00e9 dans la d\u00e9finition des workflows[7].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#parametre-when-pour-lexecution-conditionnelle","title":"Param\u00e8tre <code>when</code> pour l'ex\u00e9cution conditionnelle","text":"<p>Le mot-cl\u00e9 <code>when</code> offre quatre options fondamentales[2] :</p> Valeur Comportement <code>always</code> Le job s'ex\u00e9cute toujours, ind\u00e9pendamment de l'\u00e9tat du job pr\u00e9c\u00e9dent <code>on_success</code> Le job s'ex\u00e9cute uniquement si tous les jobs du stage pr\u00e9c\u00e9dent ont r\u00e9ussi (d\u00e9faut) <code>on_failure</code> Le job s'ex\u00e9cute uniquement si au moins un job du stage pr\u00e9c\u00e9dent a \u00e9chou\u00e9 <code>manual</code> Le job n\u00e9cessite une approbation manuelle pour s'ex\u00e9cuter <code>delayed</code> Le job est d\u00e9cal\u00e9 d'une dur\u00e9e donn\u00e9e avant son ex\u00e9cution"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#utilisation-du-parametre-when-manual","title":"Utilisation du param\u00e8tre <code>when: manual</code>","text":"YAML<pre><code>stages:\n  - build\n  - test\n  - deploy\n\nbuild:\n  stage: build\n  script:\n    - npm install\n    - npm run build\n\ntest:\n  stage: test\n  script:\n    - npm run test\n\ndeploy_production:\n  stage: deploy\n  script:\n    - ./deploy.sh production\n  when: manual\n</code></pre> <p>Le d\u00e9ploiement en production n\u00e9cessite une action manuelle depuis l'interface GitLab, pr\u00e9venant les d\u00e9ploiements accidentels[2].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#utilisation-du-parametre-when-on_failure","title":"Utilisation du param\u00e8tre <code>when: on_failure</code>","text":"YAML<pre><code>notify_failure:\n  stage: deploy\n  script:\n    - curl -X POST https://hooks.slack.com/services/... -d '{\"text\":\"Pipeline failed\"}'\n  when: on_failure\n</code></pre> <p>La notification Slack s'envoie uniquement si un job du stage pr\u00e9c\u00e9dent a \u00e9chou\u00e9.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#utilisation-du-parametre-when-always","title":"Utilisation du param\u00e8tre <code>when: always</code>","text":"YAML<pre><code>cleanup:\n  stage: test\n  script:\n    - rm -rf /tmp/build-*\n    - echo \"Cleanup completed\"\n  when: always\n</code></pre> <p>Le nettoyage s'ex\u00e9cute toujours, m\u00eame si les jobs de test ont \u00e9chou\u00e9, assurant la lib\u00e9ration des ressources temporaires.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#utilisation-du-parametre-when-delayed","title":"Utilisation du param\u00e8tre <code>when: delayed</code>","text":"YAML<pre><code>smoke_tests:\n  stage: deploy\n  script:\n    - ./run-smoke-tests.sh\n  when: delayed\n  start_in: 5 minutes\n</code></pre> <p>Les tests smoke commencent 5 minutes apr\u00e8s le d\u00e9clenchement du job, laissant le temps \u00e0 l'infrastructure de se stabiliser suite au d\u00e9ploiement.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#parametre-allow_failure","title":"Param\u00e8tre <code>allow_failure</code>","text":"YAML<pre><code>experimental_feature:\n  stage: test\n  script:\n    - npm run test:experimental\n  allow_failure: true\n</code></pre> <p>L'\u00e9chec de ce job ne bloque pas l'ex\u00e9cution des stages suivants. Le job est marqu\u00e9 comme \u00e9chou\u00e9, mais la pipeline continue[4].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#combinaison-de-controles","title":"Combinaison de contr\u00f4les","text":"YAML<pre><code>stages:\n  - build\n  - test\n  - deploy\n  - rollback\n\nbuild:\n  stage: build\n  script:\n    - npm run build\n\ntest_unit:\n  stage: test\n  script:\n    - npm run test:unit\n\ntest_integration:\n  stage: test\n  script:\n    - npm run test:integration\n  allow_failure: true\n\ndeploy_staging:\n  stage: deploy\n  script:\n    - ./deploy.sh staging\n  when: on_success\n\ndeploy_production:\n  stage: deploy\n  script:\n    - ./deploy.sh production\n  when: manual\n\nrollback:\n  stage: rollback\n  script:\n    - ./rollback.sh\n  when: on_failure\n</code></pre> <p>Cette pipeline sophistiqu\u00e9e illustre : - Tests int\u00e9gr\u00e9s non-bloquants (<code>allow_failure: true</code>) - D\u00e9ploiement staging automatique apr\u00e8s r\u00e9ussite (<code>when: on_success</code>) - D\u00e9ploiement production manuel (<code>when: manual</code>) - Rollback automatique en cas d'\u00e9chec (<code>when: on_failure</code>)</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#filtrage-et-conditions","title":"Filtrage et conditions","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#concepts-de-filtrage-avance","title":"Concepts de filtrage avanc\u00e9","text":"<p>Le filtrage granulaire permet de cibler pr\u00e9cis\u00e9ment les contextes d'ex\u00e9cution des jobs : branches sp\u00e9cifiques, tags, merge requests, ou combinaisons complexes[5][7]. GitLab offre plusieurs syst\u00e8mes pour d\u00e9finir ces conditions.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#mot-cle-only-et-except","title":"Mot-cl\u00e9 <code>only</code> et <code>except</code>","text":"<p>Les param\u00e8tres <code>only</code> et <code>except</code> contr\u00f4lent l'ex\u00e9cution selon le type d'\u00e9v\u00e9nement[5] :</p> YAML<pre><code>deploy_main:\n  stage: deploy\n  script:\n    - echo \"Deploying from main branch\"\n  only:\n    - main\n\nfeature_branch:\n  stage: build\n  script:\n    - echo \"Building feature branch\"\n  except:\n    - main\n    - develop\n</code></pre> <p>Le job <code>deploy_main</code> ne s'ex\u00e9cute que lors d'un push sur la branche <code>main</code>. Le job <code>feature_branch</code> s'ex\u00e9cute sur toute branche sauf <code>main</code> et <code>develop</code>.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#ciblage-par-type-devenement","title":"Ciblage par type d'\u00e9v\u00e9nement","text":"YAML<pre><code>on_merge_request:\n  stage: test\n  script:\n    - npm run test\n  only:\n    - merge_requests\n\non_tag:\n  stage: deploy\n  script:\n    - echo \"Deploying version $CI_COMMIT_TAG\"\n  only:\n    - tags\n\non_schedule:\n  stage: maintenance\n  script:\n    - ./daily-maintenance.sh\n  only:\n    - schedules\n</code></pre> <p>Ces jobs s'ex\u00e9cutent dans des contextes sp\u00e9cifiques : merge requests, tags Git, ou ex\u00e9cutions programm\u00e9es.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#filtrage-par-branche-avec-expressions-regulieres","title":"Filtrage par branche avec expressions r\u00e9guli\u00e8res","text":"YAML<pre><code>release_candidate:\n  stage: deploy\n  script:\n    - ./build-release.sh\n  only:\n    - /^release-\\d+\\.\\d+\\.\\d+$/\n\nhotfix:\n  stage: deploy\n  script:\n    - ./apply-hotfix.sh\n  only:\n    - /^hotfix\\//\n</code></pre> <p>Les expressions r\u00e9guli\u00e8res permettent de matcher des patterns de branche dynamiquement.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#mot-cle-rules-approche-moderne-et-flexible","title":"Mot-cl\u00e9 <code>rules</code> : approche moderne et flexible","text":"<p>GitLab recommande l'utilisation de <code>rules</code> pour une plus grande flexibilit\u00e9[7] :</p> YAML<pre><code>deploy_job:\n  stage: deploy\n  script:\n    - ./deploy.sh\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"main\"'\n      when: always\n    - if: '$CI_COMMIT_BRANCH == \"develop\"'\n      when: manual\n    - if: '$CI_COMMIT_TAG'\n      when: always\n    - when: never\n</code></pre> <p>Cette configuration : - D\u00e9ploie automatiquement sur <code>main</code> - Permet d\u00e9ploiement manuel sur <code>develop</code> - D\u00e9ploie automatiquement sur tags - Bloque les autres branches</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#conditions-avancees-avec-rules","title":"Conditions avanc\u00e9es avec <code>rules</code>","text":"YAML<pre><code>complex_pipeline:\n  stage: deploy\n  script:\n    - ./deploy.sh\n  rules:\n    # R\u00e8gle 1 : branche main + variables d\u00e9finis\n    - if: '$CI_COMMIT_BRANCH == \"main\" &amp;&amp; $ENABLE_DEPLOY == \"true\"'\n      when: always\n\n    # R\u00e8gle 2 : merge request vers main\n    - if: '$CI_MERGE_REQUEST_TARGET_BRANCH_NAME == \"main\"'\n      when: manual\n\n    # R\u00e8gle 3 : tags de version\n    - if: '$CI_COMMIT_TAG =~ /^v\\d+\\.\\d+\\.\\d+$/'\n      when: always\n\n    # R\u00e8gle 4 : par d\u00e9faut, ne rien faire\n    - when: never\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#filtrage-par-variables-denvironnement","title":"Filtrage par variables d'environnement","text":"YAML<pre><code>security_scan:\n  stage: test\n  script:\n    - ./security-scan.sh\n  rules:\n    - if: '$SECURITY_ENABLED == \"true\"'\n      when: always\n    - when: never\n</code></pre> <p>Le scan de s\u00e9curit\u00e9 ne s'ex\u00e9cute que si la variable <code>SECURITY_ENABLED</code> vaut <code>true</code>.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#condition-sur-le-message-de-commit","title":"Condition sur le message de commit","text":"YAML<pre><code>skip_ci:\n  stage: build\n  script:\n    - echo \"This job is skipped\"\n  rules:\n    - if: '$CI_COMMIT_MESSAGE =~ /\\[skip-ci\\]/'\n      when: never\n    - when: always\n</code></pre> <p>Les commits comportant <code>[skip-ci]</code> dans leur message bypassent cette \u00e9tape.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#utiliser-des-images","title":"Utiliser des images","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#concept-des-images-docker-dans-gitlab-cicd","title":"Concept des images Docker dans GitLab CI/CD","text":"<p>Les images Docker constituent l'environnement d'ex\u00e9cution pour chaque job GitLab CI/CD[2]. Une image Docker encapsule tous les outils, libraires et runtime n\u00e9cessaires \u00e0 l'ex\u00e9cution du job, garantissant une reproductibilit\u00e9 compl\u00e8te et isolant les d\u00e9pendances d'un job \u00e0 l'autre.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#image-par-defaut-au-niveau-projet","title":"Image par d\u00e9faut au niveau projet","text":"YAML<pre><code>image: node:16-alpine\n\nbuild:\n  stage: build\n  script:\n    - npm install\n    - npm run build\n\ntest:\n  stage: test\n  script:\n    - npm run test\n</code></pre> <p>Tous les jobs utilisent l'image <code>node:16-alpine</code> par d\u00e9faut, sauf surcharge au niveau individuel.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#image-specifique-au-niveau-job","title":"Image sp\u00e9cifique au niveau job","text":"YAML<pre><code>build_node:\n  stage: build\n  image: node:16\n  script:\n    - npm install\n    - npm run build\n\nbuild_python:\n  stage: build\n  image: python:3.9\n  script:\n    - pip install -r requirements.txt\n    - python setup.py build\n\nbuild_java:\n  stage: build\n  image: maven:3.8-openjdk-11\n  script:\n    - mvn clean package\n</code></pre> <p>Chaque job poss\u00e8de son image adapt\u00e9e \u00e0 son langage de programmation[2].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#images-multi-framework","title":"Images multi-framework","text":"YAML<pre><code>stages:\n  - build\n  - test\n  - deploy\n\nbuild_frontend:\n  stage: build\n  image: node:16-alpine\n  script:\n    - cd frontend\n    - npm install\n    - npm run build\n\nbuild_backend:\n  stage: build\n  image: python:3.9-slim\n  script:\n    - cd backend\n    - pip install -r requirements.txt\n    - python manage.py collectstatic\n\ntest_frontend:\n  stage: test\n  image: node:16-alpine\n  script:\n    - npm run test:frontend\n\ntest_backend:\n  stage: test\n  image: python:3.9-slim\n  script:\n    - pytest backend/\n\ndeploy:\n  stage: deploy\n  image: ubuntu:20.04\n  script:\n    - apt-get update\n    - apt-get install -y curl\n    - ./deploy.sh\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#registre-prive-dimages-docker","title":"Registre priv\u00e9 d'images Docker","text":"<p>Pour utiliser des images provenant d'un registre priv\u00e9 :</p> YAML<pre><code>image: registry.example.com/my-org/my-image:latest\n\nbuild:\n  stage: build\n  script:\n    - echo \"Building with private image\"\n</code></pre> <p>L'acc\u00e8s au registre priv\u00e9 s'authentifie via les variables prot\u00e9g\u00e9es du projet GitLab.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#images-avec-variables","title":"Images avec variables","text":"YAML<pre><code>variables:\n  REGISTRY: \"registry.example.com\"\n  IMAGE_TAG: \"latest\"\n\nbuild:\n  stage: build\n  image: $REGISTRY/build-tools:$IMAGE_TAG\n  script:\n    - npm run build\n</code></pre> <p>Les variables dynamiques permettent de modifier l'image selon le contexte.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#configuration-dimage-au-niveau-global","title":"Configuration d'image au niveau global","text":"YAML<pre><code>default:\n  image: node:16-alpine\n\nvariables:\n  APP_ENV: \"production\"\n\nbuild:\n  stage: build\n  script:\n    - npm install\n    - npm run build\n\ntest:\n  stage: test\n  script:\n    - npm run test\n\ndeploy:\n  stage: deploy\n  image: docker:latest\n  script:\n    - docker build -t my-app:latest .\n</code></pre> <p>Le bloc <code>default</code> d\u00e9finit la configuration par d\u00e9faut pour tous les jobs, incluant l'image par d\u00e9faut[1]. Le job <code>deploy</code> surcharge avec sa propre image <code>docker:latest</code>.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#commandes-avant-et-apres-dans-limage","title":"Commandes avant et apr\u00e8s dans l'image","text":"YAML<pre><code>build:\n  stage: build\n  image: node:16-alpine\n  before_script:\n    - echo \"Installing additional packages...\"\n    - apk add --no-cache curl\n    - echo \"Environment setup completed\"\n  script:\n    - npm install\n    - npm run build\n  after_script:\n    - echo \"Build completed at $(date)\"\n    - df -h\n</code></pre> <ul> <li><code>before_script</code> : s'ex\u00e9cute avant le script principal</li> <li><code>after_script</code> : s'ex\u00e9cute apr\u00e8s, m\u00eame en cas d'erreur[4]</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#images-avec-authentification","title":"Images avec authentification","text":"YAML<pre><code>image: \n  name: registry.example.com/private-image:latest\n  entrypoint: [\"\"]\n\nbuild:\n  stage: build\n  before_script:\n    - echo $REGISTRY_PASSWORD | docker login -u $REGISTRY_USER --password-stdin registry.example.com\n  script:\n    - npm install\n    - npm run build\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#selection-dimage-selon-la-branche","title":"S\u00e9lection d'image selon la branche","text":"YAML<pre><code>build:\n  stage: build\n  image: \n    name: node:16\n  rules:\n    - if: '$CI_COMMIT_BRANCH == \"main\"'\n      variables:\n        IMAGE_TAG: \"node:16-slim\"\n    - if: '$CI_COMMIT_BRANCH == \"develop\"'\n      variables:\n        IMAGE_TAG: \"node:16-alpine\"\n  script:\n    - npm install\n    - npm run build\n</code></pre> <p>La s\u00e9lection d'image s'adapte selon la branche de destination, optimisant les ressources selon le contexte.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#synthese-integrative-du-parcours-dapprentissage","title":"Synth\u00e8se int\u00e9grative du parcours d'apprentissage","text":"<p>L'appropriation de GitLab CI/CD suit une progression logique et cumulative, o\u00f9 chaque concept s'appuie sur les fondations pr\u00e9c\u00e9dentes pour construire des workflows sophistiqu\u00e9s et efficaces.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#fondation-les-stages","title":"Fondation : les stages","text":"<p>Le parcours d\u00e9marre par la compr\u00e9hension de la structure fondamentale des pipelines via les stages. Cette \u00e9tape forme la colonne vert\u00e9brale de toute pipeline, \u00e9tablissant l'ordre s\u00e9quentiel d'ex\u00e9cution et l'architecture g\u00e9n\u00e9rale du workflow. Ma\u00eetriser les stages signifie comprendre comment organiser logiquement le processus d'int\u00e9gration et de d\u00e9ploiement en phases distinctes.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#premier-niveau-dexecution-les-scripts","title":"Premier niveau d'ex\u00e9cution : les scripts","text":"<p>Avec la structure en place, les scripts mat\u00e9rialisent l'action concr\u00e8te. Les scripts transforment les stages abstraits en ex\u00e9cution r\u00e9elle, d\u00e9finissant les commandes shell qui accomplissent le travail. Ce stade requiert une compr\u00e9hension claire de la syntaxe shell et de la gestion des erreurs d'ex\u00e9cution.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#parametrage-dynamique-les-variables","title":"Param\u00e9trage dynamique : les variables","text":"<p>Les variables introduisent la flexibilit\u00e9 et la r\u00e9utilisabilit\u00e9. Plut\u00f4t que de coder en dur les valeurs dans les scripts, les variables permettent d'adapter le comportement selon le contexte sans modification du code source. Cette approche \u00e9l\u00e8ve le niveau d'abstraction et facilite la maintenance.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#orchestration-intelligente-controle-du-flux-et-filtrage","title":"Orchestration intelligente : contr\u00f4le du flux et filtrage","text":"<p>Une fois les structures et param\u00e8tres en place, le contr\u00f4le du flux et les conditions de filtrage offrent la granularit\u00e9 n\u00e9cessaire pour orchestrer des workflows complexes. Ces concepts permettent de d\u00e9cider dynamiquement quand et comment les jobs s'ex\u00e9cutent, selon des crit\u00e8res sophistiqu\u00e9s.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#isolation-et-portabilite-les-images","title":"Isolation et portabilit\u00e9 : les images","text":"<p>Enfin, les images Docker encapsulent l'environnement d'ex\u00e9cution, garantissant la reproductibilit\u00e9 et l'isolement des d\u00e9pendances. Les images compl\u00e8tent la configuration en fournissant un environnement contr\u00f4l\u00e9 et portable.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#dimension-transversale-les-environnements","title":"Dimension transversale : les environnements","text":"<p>Les environnements transcendent les autres concepts, apportant une dimension de tra\u00e7abilit\u00e9 et de gouvernance au processus. Ils permettent de suivre les d\u00e9ploiements, de g\u00e9rer les approbations, et de maintenir un historique clair des versions en production.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap03/#progression-recommandee","title":"Progression recommand\u00e9e","text":"<ol> <li>Phase 1 - Mise en place : D\u00e9finir les stages de base (build, test, deploy), impl\u00e9menter les scripts simples</li> <li>Phase 2 - Param\u00e9trage : Introduire les variables pour adapter le comportement selon le contexte</li> <li>Phase 3 - Sophistication : Ajouter le contr\u00f4le du flux (when, allow_failure) pour orchestrer l'ex\u00e9cution</li> <li>Phase 4 - Finesse : Impl\u00e9menter le filtrage avanc\u00e9 (rules) pour cibler pr\u00e9cis\u00e9ment les contextes</li> <li>Phase 5 - Portabilit\u00e9 : S\u00e9lectionner les images Docker appropri\u00e9es et configurer les environnements de d\u00e9ploiement</li> <li>Phase 6 - Production : Combiner tous les concepts pour construire des pipelines d'entreprise compl\u00e8tes avec approbations, notifications et rollback</li> </ol> <p>Cette progression assure une mont\u00e9e en comp\u00e9tence graduelle, chaque \u00e9tape s'appuyant sur les concepts pr\u00e9c\u00e9dents pour construire une expertise compl\u00e8te en CI/CD sous GitLab.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/","title":"Citations","text":"<ul> <li>https://www.youtube.com/watch?v=9VTGW1pCTC8</li> <li>https://www.youtube.com/watch?v=TiWo_eTOkbs</li> <li>https://docs.gitlab.com/ci/quick_start/</li> <li>https://university.gitlab.com/pages/advanced-cicd</li> <li>https://www.youtube.com/watch?v=jR1HFox1BMg</li> <li>https://www.youtube.com/watch?v=R236CKpurwA</li> <li>https://adictosaltrabajo.com/2018/04/10/primeros-pasos-con-gitlab-ci/</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 322</li> <li>completion_tokens: 6819</li> <li>total_tokens: 7141</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.102, 'request_cost': 0.006, 'total_cost': 0.109}</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#content","title":"Content","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#chapitre-4-notions-avancees-sur-gitlab-cicd","title":"Chapitre 4 : Notions avanc\u00e9es sur GitLab CI/CD","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#comprendre-la-notion-de-default","title":"Comprendre la notion de default","text":"<p>La section <code>default</code> dans GitLab CI/CD repr\u00e9sente un m\u00e9canisme fondamental de configuration qui permet de d\u00e9finir des param\u00e8tres applicables \u00e0 l'ensemble des jobs d'un pipeline[1]. Cette approche r\u00e9duit consid\u00e9rablement la redondance de code et facilite la maintenance des pipelines complexes.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#principes-fondamentaux","title":"Principes fondamentaux","text":"<p>La section <code>default</code> s'applique automatiquement \u00e0 tous les jobs, sauf si ces derniers surcharger explicitement les param\u00e8tres h\u00e9rit\u00e9s. Cette hi\u00e9rarchie de configuration suit un ordre de priorit\u00e9 clair : les param\u00e8tres d\u00e9finis au niveau du job prennent toujours pr\u00e9c\u00e9dence sur ceux d\u00e9finis dans <code>default</code>.</p> YAML<pre><code>default:\n  stage: test\n  tags:\n    - docker\n  timeout: 1 hour\n  retry:\n    max: 2\n    when:\n      - runner_system_failure\n      - stuck_or_timeout_failure\n\nbuild-job:\n  stage: build\n  script:\n    - echo \"Ce job utilise build stage, pas test\"\n\ntest-job:\n  script:\n    - echo \"Ce job utilise le stage test de default\"\n    - echo \"Il dispose \u00e9galement du timeout de 1 heure\"\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#parametres-heritables","title":"Param\u00e8tres h\u00e9ritables","text":"<p>Les param\u00e8tres configurables dans la section <code>default</code> incluent :</p> <ul> <li><code>stage</code> : L'\u00e9tape d'ex\u00e9cution du pipeline</li> <li><code>image</code> : L'image Docker utilis\u00e9e</li> <li><code>tags</code> : Les \u00e9tiquettes pour s\u00e9lectionner les runners</li> <li><code>cache</code> : Configuration du cache entre jobs</li> <li><code>artifacts</code> : Configuration des artefacts</li> <li><code>retry</code> : Strat\u00e9gie de relance en cas d'\u00e9chec</li> <li><code>timeout</code> : Dur\u00e9e maximale d'ex\u00e9cution</li> <li><code>before_script</code> : Scripts ex\u00e9cut\u00e9s avant le job</li> <li><code>after_script</code> : Scripts ex\u00e9cut\u00e9s apr\u00e8s le job</li> <li><code>interruptible</code> : Possibilit\u00e9 d'interrompre le job</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#cas-dusage-avances","title":"Cas d'usage avanc\u00e9s","text":"YAML<pre><code>default:\n  retry:\n    max: 2\n    when: [runner_system_failure, api_failure]\n  tags:\n    - shared-runner\n  image: ubuntu:22.04\n\nbuild:\n  stage: build\n  script:\n    - apt-get update\n    - apt-get install -y build-essential\n\nunit-tests:\n  stage: test\n  image: ubuntu:22.04-python3.10\n  script:\n    - python -m pytest tests/\n\nintegration-tests:\n  stage: test\n  tags:\n    - docker\n  script:\n    - ./run_integration_tests.sh\n  retry:\n    max: 3\n    when: [runner_system_failure]\n\ndeploy:\n  stage: deploy\n  script:\n    - ./deploy.sh\n  retry:\n    max: 1\n</code></pre> <p>Dans cet exemple, les jobs <code>build</code> et <code>unit-tests</code> h\u00e9ritent automatiquement de la configuration <code>default</code>, tandis que le job <code>integration-tests</code> surcharge le param\u00e8tre <code>retry</code> pour une strat\u00e9gie plus agressive, et le job <code>deploy</code> limite le nombre de tentatives \u00e0 1.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#gestion-des-artifacts-et-dependencies","title":"Gestion des artifacts et dependencies","text":"<p>Les artefacts constituent un \u00e9l\u00e9ment central dans la transmission de donn\u00e9es entre les \u00e9tapes d'un pipeline. Contrairement aux donn\u00e9es temporaires, les artefacts sont conserv\u00e9s et peuvent \u00eatre t\u00e9l\u00e9charg\u00e9s ou transmis aux jobs suivants[1].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#concepts-fondamentaux-des-artifacts","title":"Concepts fondamentaux des artifacts","text":"<p>Un artefact repr\u00e9sente un fichier ou un ensemble de fichiers g\u00e9n\u00e9r\u00e9s par un job et destin\u00e9s \u00e0 \u00eatre :</p> <ul> <li>Conserv\u00e9s apr\u00e8s l'ex\u00e9cution du job</li> <li>T\u00e9l\u00e9charg\u00e9s manuellement via l'interface GitLab</li> <li>Transmis automatiquement aux jobs d\u00e9pendants</li> <li>Archiv\u00e9s pour audit ou analyse ult\u00e9rieure</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#configuration-basique-des-artifacts","title":"Configuration basique des artifacts","text":"YAML<pre><code>build-job:\n  stage: build\n  script:\n    - mkdir -p build\n    - gcc -o build/application main.c\n    - echo \"Version 1.0\" &gt; build/version.txt\n  artifacts:\n    paths:\n      - build/\n    expire_in: 1 week\n    name: \"application-build-$CI_COMMIT_SHORT_SHA\"\n\ntest-job:\n  stage: test\n  script:\n    - ./build/application --version\n    - ./build/application --test\n  dependencies:\n    - build-job\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#gestion-avancee-des-artefacts","title":"Gestion avanc\u00e9e des artefacts","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#selection-par-patterns","title":"S\u00e9lection par patterns","text":"YAML<pre><code>compile-backend:\n  stage: build\n  script:\n    - npm install\n    - npm run build\n    - npm run test\n  artifacts:\n    paths:\n      - dist/\n      - coverage/\n    exclude:\n      - dist/**/*.map\n    expire_in: 30 days\n\ncompile-frontend:\n  stage: build\n  script:\n    - yarn install\n    - yarn build\n  artifacts:\n    paths:\n      - public/\n    reports:\n      dependency_scanning: gl-dependency-scanning-report.json\n    expire_in: 1 week\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#rapports-specialises","title":"Rapports sp\u00e9cialis\u00e9s","text":"YAML<pre><code>testing:\n  stage: test\n  script:\n    - pytest --cov=src --cov-report=term --cov-report=html\n    - pylint src/ --exit-zero -f json &gt; pylint-report.json\n  artifacts:\n    paths:\n      - htmlcov/\n    reports:\n      coverage_report:\n        coverage_format: cobertura\n        path: coverage.xml\n      sast: sast-report.json\n    expire_in: 30 days\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#dependances-explicites","title":"D\u00e9pendances explicites","text":"<p>Les d\u00e9pendances permettent de contr\u00f4ler pr\u00e9cis\u00e9ment quels artefacts sont accessibles \u00e0 un job donn\u00e9 :</p> YAML<pre><code>stages:\n  - build\n  - test\n  - package\n  - deploy\n\nbuild-backend:\n  stage: build\n  artifacts:\n    paths:\n      - backend/dist/\n  script:\n    - cd backend &amp;&amp; npm run build\n\nbuild-frontend:\n  stage: build\n  artifacts:\n    paths:\n      - frontend/dist/\n  script:\n    - cd frontend &amp;&amp; npm run build\n\nunit-tests-backend:\n  stage: test\n  dependencies:\n    - build-backend\n  script:\n    - npm test\n\nunit-tests-frontend:\n  stage: test\n  dependencies:\n    - build-frontend\n  script:\n    - npm test\n\nintegration-tests:\n  stage: test\n  dependencies:\n    - build-backend\n    - build-frontend\n  script:\n    - ./test/integration.sh\n\npackage-app:\n  stage: package\n  dependencies:\n    - build-backend\n    - build-frontend\n  script:\n    - ./scripts/package.sh\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#optimisation-de-la-transmission-des-artefacts","title":"Optimisation de la transmission des artefacts","text":"YAML<pre><code>stages:\n  - build\n  - verify\n  - deploy\n\nbuild:\n  stage: build\n  script:\n    - echo \"Compilation en cours...\"\n    - tar czf application.tar.gz --exclude='*.o' src/\n  artifacts:\n    paths:\n      - application.tar.gz\n    expire_in: 2 hours\n\nverify-signature:\n  stage: verify\n  dependencies:\n    - build\n  script:\n    - tar xzf application.tar.gz\n    - ./verify.sh\n  artifacts:\n    paths:\n      - verification-report.txt\n    expire_in: 30 days\n\ndeploy-production:\n  stage: deploy\n  dependencies:\n    - verify-signature\n  script:\n    - ./deploy.sh\n  only:\n    - main\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#utilisation-du-cache","title":"Utilisation du cache","text":"<p>Le cache am\u00e9liore significativement les performances des pipelines en stockant des fichiers entre les ex\u00e9cutions. Contrairement aux artefacts qui sont conserv\u00e9s sur les serveurs GitLab, le cache est g\u00e9r\u00e9 localement par les runners[1].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#distinction-cache-vs-artifacts","title":"Distinction cache vs artifacts","text":"Aspect Cache Artifacts Stockage Syst\u00e8me de fichiers du runner Serveurs GitLab Dur\u00e9e de vie Entre les jobs/pipelines D\u00e9finie par <code>expire_in</code> Transmission Automatique si m\u00eame runner Explicite via <code>dependencies</code> Taille Optimis\u00e9e pour rapidit\u00e9 Moins de contraintes Cas d'usage D\u00e9pendances, modules npm R\u00e9sultats de build, rapports"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#configuration-basique-du-cache","title":"Configuration basique du cache","text":"YAML<pre><code>stages:\n  - build\n  - test\n  - deploy\n\ncache:\n  key: \"build-cache\"\n  paths:\n    - node_modules/\n    - .gradle/\n\ninstall-dependencies:\n  stage: build\n  script:\n    - npm install\n    - pip install -r requirements.txt\n\nrun-tests:\n  stage: test\n  script:\n    - npm test\n\nbuild-artifact:\n  stage: build\n  script:\n    - npm run build\n  artifacts:\n    paths:\n      - dist/\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#strategies-de-cache-avancees","title":"Strat\u00e9gies de cache avanc\u00e9es","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#cache-par-branche","title":"Cache par branche","text":"YAML<pre><code>stages:\n  - install\n  - build\n  - test\n\ncache:\n  key:\n    files:\n      - package-lock.json\n    prefix: ${CI_COMMIT_REF_SLUG}\n  paths:\n    - node_modules/\n    - .npm/\n\ninstall-npm:\n  stage: install\n  script:\n    - npm ci\n\nbuild-app:\n  stage: build\n  script:\n    - npm run build\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#caches-multiples","title":"Caches multiples","text":"YAML<pre><code>build-project:\n  stage: build\n  cache:\n    - key: \"npm-cache-${CI_COMMIT_REF_SLUG}\"\n      paths:\n        - node_modules/\n    - key: \"pip-cache-${CI_COMMIT_REF_SLUG}\"\n      paths:\n        - venv/\n        - .cache/pip/\n  script:\n    - npm install\n    - python -m venv venv\n    - pip install -r requirements.txt\n    - npm run build\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#controle-granulaire-du-cache","title":"Contr\u00f4le granulaire du cache","text":"YAML<pre><code>stages:\n  - dependencies\n  - build\n  - test\n  - cleanup\n\ninstall-dependencies:\n  stage: dependencies\n  cache:\n    key: \"dependencies-${CI_COMMIT_REF_SLUG}\"\n    paths:\n      - node_modules/\n      - vendor/\n    policy: pull-push\n  script:\n    - npm install\n    - composer install\n\nbuild-cached:\n  stage: build\n  cache:\n    key: \"dependencies-${CI_COMMIT_REF_SLUG}\"\n    paths:\n      - node_modules/\n      - vendor/\n    policy: pull\n  script:\n    - npm run build\n  dependencies:\n    - install-dependencies\n\ntest-cached:\n  stage: test\n  cache:\n    key: \"dependencies-${CI_COMMIT_REF_SLUG}\"\n    paths:\n      - node_modules/\n    policy: pull\n  script:\n    - npm test\n  dependencies:\n    - install-dependencies\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#gestion-du-cycle-de-vie-du-cache","title":"Gestion du cycle de vie du cache","text":"YAML<pre><code>default:\n  cache:\n    key:\n      files:\n        - package-lock.json\n      prefix: ${CI_COMMIT_REF_SLUG}\n    paths:\n      - node_modules/\n    policy: pull-push\n\nstages:\n  - setup\n  - build\n  - test\n  - cleanup\n\nsetup-environment:\n  stage: setup\n  cache:\n    policy: pull-push\n  script:\n    - npm ci\n    - npm cache verify\n\nbuild:\n  stage: build\n  cache:\n    policy: pull\n  script:\n    - npm run build\n    - npm run lint\n\ntest:\n  stage: test\n  cache:\n    policy: pull\n  script:\n    - npm test\n\nclear-cache:\n  stage: cleanup\n  cache:\n    policy: pull-push\n  script:\n    - npm cache clean --force\n  when: on_success\n  only:\n    - schedules\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#mesurer-le-coverage-du-code","title":"Mesurer le coverage du code","text":"<p>La couverture de code mesure le pourcentage du code source ex\u00e9cut\u00e9 lors des tests. Cette m\u00e9trique permet d'identifier les sections non test\u00e9es et d'am\u00e9liorer la qualit\u00e9 du code.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#configuration-basique-du-coverage","title":"Configuration basique du coverage","text":"YAML<pre><code>stages:\n  - test\n  - report\n\ntest-coverage:\n  stage: test\n  image: python:3.10\n  script:\n    - pip install pytest pytest-cov\n    - pytest --cov=src --cov-report=term --cov-report=xml\n  artifacts:\n    reports:\n      coverage_report:\n        coverage_format: cobertura\n        path: coverage.xml\n  coverage: '/TOTAL.*\\s+(\\d+%)$/'\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#extraction-du-coverage-par-format","title":"Extraction du coverage par format","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#format-cobertura-xml","title":"Format Cobertura (XML)","text":"YAML<pre><code>test-java:\n  stage: test\n  image: maven:3.8\n  script:\n    - mvn clean test jacoco:report\n  artifacts:\n    reports:\n      coverage_report:\n        coverage_format: cobertura\n        path: target/site/jacoco/jacoco.xml\n    expire_in: 30 days\n  coverage: '/Total.*?(\\d+%)/'\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#format-javascripttypescript","title":"Format JavaScript/TypeScript","text":"YAML<pre><code>test-javascript:\n  stage: test\n  image: node:18\n  script:\n    - npm install --save-dev jest @babel/preset-env babel-jest\n    - npm test -- --coverage --coverage-reporters=cobertura\n  artifacts:\n    reports:\n      coverage_report:\n        coverage_format: cobertura\n        path: coverage/cobertura-coverage.xml\n  coverage: '/Lines\\s*:\\s*(\\d+\\.\\d+)%/'\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#configurations-avancees-du-coverage","title":"Configurations avanc\u00e9es du coverage","text":"YAML<pre><code>stages:\n  - build\n  - test\n  - analysis\n\nbuild:\n  stage: build\n  script:\n    - npm install\n\nunit-tests:\n  stage: test\n  needs:\n    - build\n  script:\n    - npm run test:unit -- --coverage\n  artifacts:\n    reports:\n      coverage_report:\n        coverage_format: cobertura\n        path: coverage/unit/cobertura-coverage.xml\n    paths:\n      - coverage/unit/\n  coverage: '/Statements\\s*:\\s*(\\d+\\.\\d+)%/'\n\nintegration-tests:\n  stage: test\n  needs:\n    - build\n  script:\n    - npm run test:integration -- --coverage\n  artifacts:\n    reports:\n      coverage_report:\n        coverage_format: cobertura\n        path: coverage/integration/cobertura-coverage.xml\n    paths:\n      - coverage/integration/\n  coverage: '/Statements\\s*:\\s*(\\d+\\.\\d+)%/'\n\ncoverage-analysis:\n  stage: analysis\n  image: python:3.10\n  script:\n    - python scripts/analyze_coverage.py\n  artifacts:\n    paths:\n      - coverage-report.html\n  coverage: '/Coverage:\\s*(\\d+\\.\\d+)%/'\n  allow_failure: true\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#mise-en-place-de-seuils-de-coverage","title":"Mise en place de seuils de coverage","text":"YAML<pre><code>test-with-threshold:\n  stage: test\n  image: python:3.10\n  script:\n    - pip install pytest pytest-cov\n    - pytest --cov=src --cov-report=term --cov-report=xml --cov-fail-under=80\n  artifacts:\n    reports:\n      coverage_report:\n        coverage_format: cobertura\n        path: coverage.xml\n  coverage: '/TOTAL.*\\s+(\\d+%)$/'\n  allow_failure: false\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#optimiser-avec-lexecution-en-parallele","title":"Optimiser avec l'ex\u00e9cution en parall\u00e8le","text":"<p>L'ex\u00e9cution en parall\u00e8le des jobs repr\u00e9sente un \u00e9l\u00e9ment cl\u00e9 d'optimisation des pipelines. GitLab permet plusieurs approches pour exploiter le parall\u00e9lisme.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#parallelisme-au-niveau-des-stages","title":"Parall\u00e9lisme au niveau des stages","text":"YAML<pre><code>stages:\n  - build\n  - test\n  - deploy\n\nbuild-backend:\n  stage: build\n  script:\n    - echo \"Compilation backend\"\n    - sleep 30\n\nbuild-frontend:\n  stage: build\n  script:\n    - echo \"Compilation frontend\"\n    - sleep 30\n\ntest-backend:\n  stage: test\n  script:\n    - echo \"Tests backend\"\n  needs:\n    - build-backend\n\ntest-frontend:\n  stage: test\n  script:\n    - echo \"Tests frontend\"\n  needs:\n    - build-frontend\n\ndeploy:\n  stage: deploy\n  script:\n    - echo \"D\u00e9ploiement\"\n  needs:\n    - test-backend\n    - test-frontend\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#utilisation-de-dag-directed-acyclic-graph-avec-needs","title":"Utilisation de DAG (Directed Acyclic Graph) avec needs","text":"YAML<pre><code>stages:\n  - build\n  - unit-tests\n  - integration-tests\n  - package\n\ncompile-backend:\n  stage: build\n  script:\n    - mvn clean compile\n\ncompile-frontend:\n  stage: build\n  script:\n    - npm run build\n\nunit-tests-backend:\n  stage: unit-tests\n  needs:\n    - compile-backend\n  script:\n    - mvn test\n\nunit-tests-frontend:\n  stage: unit-tests\n  needs:\n    - compile-frontend\n  script:\n    - npm test\n\nintegration-tests:\n  stage: integration-tests\n  needs:\n    - unit-tests-backend\n    - unit-tests-frontend\n  script:\n    - ./test/run-integration.sh\n\npackage:\n  stage: package\n  needs:\n    - integration-tests\n  script:\n    - ./scripts/package.sh\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#partitionnement-des-tests","title":"Partitionnement des tests","text":"YAML<pre><code>stages:\n  - build\n  - test\n  - results\n\nbuild:\n  stage: build\n  script:\n    - npm install\n    - npm run build\n\ntest-1:\n  stage: test\n  parallel: 5\n  script:\n    - npm test -- --shard=$CI_NODE_INDEX/$CI_NODE_TOTAL\n  needs:\n    - build\n\ntest-2:\n  stage: test\n  parallel:\n    total: 3\n  script:\n    - pytest tests/ -k \"test_module_${CI_NODE_INDEX}\" --maxfail=3\n  needs:\n    - build\n\nmerge-results:\n  stage: results\n  script:\n    - ./scripts/merge_test_results.sh\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#optimisation-avec-matrix","title":"Optimisation avec matrix","text":"YAML<pre><code>stages:\n  - test\n  - deploy\n\ntest:\n  stage: test\n  parallel:\n    matrix:\n      - PYTHON_VERSION: [\"3.9\", \"3.10\", \"3.11\"]\n        DJANGO_VERSION: [\"3.2\", \"4.0\"]\n  image: python:${PYTHON_VERSION}\n  script:\n    - pip install Django==${DJANGO_VERSION}\n    - python manage.py test\n  needs: []\n\ndeploy:\n  stage: deploy\n  parallel:\n    matrix:\n      - ENVIRONMENT: [\"staging\", \"production\"]\n        REGION: [\"eu-west\", \"us-east\"]\n  script:\n    - ./deploy.sh ${ENVIRONMENT} ${REGION}\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#composition-avancee-include-et-template","title":"Composition avanc\u00e9e : include et template","text":"<p>La composition via <code>include</code> permet de r\u00e9utiliser des configurations de pipeline et de maintenir une coh\u00e9rence \u00e0 travers plusieurs projets.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#include-local","title":"Include local","text":"YAML<pre><code>stages:\n  - test\n  - build\n  - deploy\n\ninclude:\n  - local: '.gitlab/ci/test.yml'\n  - local: '.gitlab/ci/build.yml'\n  - local: '.gitlab/ci/deploy.yml'\n</code></pre> <p>Structure des fichiers :</p> Text Only<pre><code>.gitlab/\n\u251c\u2500\u2500 ci/\n\u2502   \u251c\u2500\u2500 test.yml\n\u2502   \u251c\u2500\u2500 build.yml\n\u2502   \u2514\u2500\u2500 deploy.yml\n</code></pre> <p>Contenu <code>.gitlab/ci/test.yml</code> :</p> YAML<pre><code>test-unit:\n  stage: test\n  image: node:18\n  script:\n    - npm install\n    - npm test\n\ntest-lint:\n  stage: test\n  image: node:18\n  script:\n    - npm install\n    - npm run lint\n</code></pre> <p>Contenu <code>.gitlab/ci/build.yml</code> :</p> YAML<pre><code>build:\n  stage: build\n  image: node:18\n  script:\n    - npm install\n    - npm run build\n  artifacts:\n    paths:\n      - dist/\n    expire_in: 1 week\n</code></pre> <p>Contenu <code>.gitlab/ci/deploy.yml</code> :</p> YAML<pre><code>deploy-staging:\n  stage: deploy\n  image: alpine:latest\n  script:\n    - ./deploy.sh staging\n  environment:\n    name: staging\n  only:\n    - develop\n\ndeploy-production:\n  stage: deploy\n  image: alpine:latest\n  script:\n    - ./deploy.sh production\n  environment:\n    name: production\n  only:\n    - main\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#include-depuis-un-registre-ou-url","title":"Include depuis un registre ou URL","text":"YAML<pre><code>include:\n  - remote: 'https://gitlab.com/shared-ci-pipelines/templates.yml'\n  - project: 'shared-templates/ci-components'\n    ref: main\n    file: 'common-jobs.yml'\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#include-avec-regles-conditionnelles","title":"Include avec r\u00e8gles conditionnelles","text":"YAML<pre><code>include:\n  - local: '.gitlab/ci/base.yml'\n  - local: '.gitlab/ci/docker.yml'\n    rules:\n      - if: $BUILD_DOCKER == \"true\"\n  - local: '.gitlab/ci/security.yml'\n    rules:\n      - if: $SECURITY_SCAN == \"true\"\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#composition-multi-niveaux","title":"Composition multi-niveaux","text":"YAML<pre><code># .gitlab-ci.yml principal\nstages:\n  - dependencies\n  - build\n  - test\n  - security\n  - deploy\n\ninclude:\n  - local: '.gitlab/ci/shared/default.yml'\n  - local: '.gitlab/ci/build/backend.yml'\n  - local: '.gitlab/ci/build/frontend.yml'\n  - local: '.gitlab/ci/test/unit.yml'\n  - local: '.gitlab/ci/test/integration.yml'\n  - local: '.gitlab/ci/security/sast.yml'\n  - local: '.gitlab/ci/security/dependency-check.yml'\n  - local: '.gitlab/ci/deploy/staging.yml'\n  - local: '.gitlab/ci/deploy/production.yml'\n\ninstall-dependencies:\n  stage: dependencies\n  script:\n    - npm install\n    - pip install -r requirements.txt\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#composition-jobs-caches-et-extends","title":"Composition : jobs cach\u00e9s, &lt;&lt;* et extends","text":"<p>La composition via l'h\u00e9ritage permet de d\u00e9finir des configurations r\u00e9utilisables et de maintenir une logique DRY (Don't Repeat Yourself).</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#jobs-caches-hidden-jobs","title":"Jobs cach\u00e9s (hidden jobs)","text":"YAML<pre><code>.base-job:\n  image: ubuntu:22.04\n  tags:\n    - docker\n  before_script:\n    - apt-get update -qq\n  after_script:\n    - echo \"Job finished\"\n\n.test-job:\n  extends: .base-job\n  stage: test\n  script:\n    - echo \"Running tests\"\n\n.deploy-job:\n  extends: .base-job\n  stage: deploy\n  script:\n    - echo \"Deploying\"\n  only:\n    - main\n\nunit-tests:\n  extends: .test-job\n  script:\n    - npm test\n\nintegration-tests:\n  extends: .test-job\n  script:\n    - ./test/integration.sh\n\ndeploy-production:\n  extends: .deploy-job\n  script:\n    - ./deploy.sh production\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#fusion-con-merge-keys","title":"Fusi\u00f3n con &lt;&lt;* (merge keys)","text":"YAML<pre><code>.defaults: &amp;defaults\n  tags:\n    - docker\n  timeout: 1h\n  retry: 2\n\n.python-defaults: &amp;python-defaults\n  image: python:3.10\n  before_script:\n    - pip install -r requirements.txt\n\ntest-unit:\n  &lt;&lt;: *defaults\n  &lt;&lt;: *python-defaults\n  stage: test\n  script:\n    - pytest tests/unit/\n\ntest-integration:\n  &lt;&lt;: *defaults\n  &lt;&lt;: *python-defaults\n  stage: test\n  script:\n    - pytest tests/integration/\n  timeout: 2h\n  retry: 3\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#extends-avance","title":"Extends avanc\u00e9","text":"YAML<pre><code>stages:\n  - build\n  - test\n  - deploy\n\n.docker-job:\n  image: docker:latest\n  services:\n    - docker:dind\n  before_script:\n    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n\n.test-job:\n  stage: test\n  retry:\n    max: 2\n    when: [runner_system_failure]\n\n.deploy-job:\n  stage: deploy\n  when: manual\n  environment:\n    name: $CI_COMMIT_REF_NAME\n  only:\n    - main\n    - develop\n\nbuild-docker:\n  extends: .docker-job\n  stage: build\n  script:\n    - docker build -t $CI_REGISTRY_IMAGE:latest .\n    - docker push $CI_REGISTRY_IMAGE:latest\n\ntest-docker:\n  extends:\n    - .docker-job\n    - .test-job\n  script:\n    - docker run $CI_REGISTRY_IMAGE:latest npm test\n\ndeploy-staging:\n  extends: .deploy-job\n  environment:\n    name: staging\n    url: https://staging.example.com\n  script:\n    - docker pull $CI_REGISTRY_IMAGE:latest\n    - docker run -d --name app $CI_REGISTRY_IMAGE:latest\n  only:\n    - develop\n\ndeploy-production:\n  extends: .deploy-job\n  environment:\n    name: production\n    url: https://example.com\n  script:\n    - docker pull $CI_REGISTRY_IMAGE:latest\n    - docker run -d --name app $CI_REGISTRY_IMAGE:latest\n  only:\n    - main\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#composition-complexe-avec-multiples-heritage","title":"Composition complexe avec multiples h\u00e9ritage","text":"YAML<pre><code>.base:\n  tags: [docker]\n  timeout: 30m\n\n.node:\n  image: node:18\n  cache:\n    paths: [node_modules/]\n\n.python:\n  image: python:3.10\n  cache:\n    paths: [.venv/]\n\n.test:\n  stage: test\n  coverage: '/Coverage: \\d+\\.\\d+%/'\n\n.deploy:\n  stage: deploy\n  environment:\n    name: $CI_COMMIT_REF_NAME\n  when: manual\n\ntest-node:\n  extends:\n    - .base\n    - .node\n    - .test\n  script:\n    - npm install\n    - npm test\n\ntest-python:\n  extends:\n    - .base\n    - .python\n    - .test\n  script:\n    - python -m venv .venv\n    - pip install -r requirements.txt\n    - pytest\n\ndeploy-node:\n  extends:\n    - .base\n    - .node\n    - .deploy\n  script:\n    - npm install\n    - npm run build\n    - npm run deploy\n\ndeploy-python:\n  extends:\n    - .base\n    - .python\n    - .deploy\n  script:\n    - python -m venv .venv\n    - pip install -r requirements.txt\n    - python deploy.py\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#controle-de-lheritage-avec-inherit","title":"Contr\u00f4le de l'h\u00e9ritage avec inherit","text":"<p>Le mot-cl\u00e9 <code>inherit</code> permet de contr\u00f4ler finement quels \u00e9l\u00e9ments sont h\u00e9rit\u00e9s d'une configuration parente.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#controle-basique-de-lheritage","title":"Contr\u00f4le basique de l'h\u00e9ritage","text":"YAML<pre><code>default:\n  image: ubuntu:22.04\n  tags: [docker]\n  retry: 2\n  timeout: 1h\n\njob-all-inherited:\n  stage: test\n  script:\n    - echo \"H\u00e9rite de tout\"\n\njob-partial-inheritance:\n  inherit:\n    default: true\n  stage: test\n  script:\n    - echo \"H\u00e9rite de default\"\n\njob-no-inheritance:\n  inherit:\n    default: false\n  stage: test\n  image: alpine:latest\n  script:\n    - echo \"N'h\u00e9rite pas de default\"\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#heritage-selectif","title":"H\u00e9ritage s\u00e9lectif","text":"YAML<pre><code>default:\n  image: ubuntu:22.04\n  tags: [docker]\n  cache:\n    paths: [vendor/]\n  artifacts:\n    paths: [build/]\n  retry: 2\n\njob-inherit-partial:\n  inherit:\n    default:\n      - image\n      - tags\n  stage: build\n  script:\n    - echo \"Utilise image et tags de default\"\n    - echo \"Ne pas h\u00e9riter cache et artifacts\"\n\njob-inherit-all:\n  inherit:\n    default: true\n  stage: test\n  script:\n    - echo \"H\u00e9rite de tous les param\u00e8tres\"\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#heritage-avec-extends-et-inherit-combines","title":"H\u00e9ritage avec extends et inherit combin\u00e9s","text":"YAML<pre><code>.base-configuration:\n  image: node:18\n  cache:\n    paths: [node_modules/]\n  retry: 2\n\n.test-configuration:\n  stage: test\n  coverage: '/Coverage: \\d+\\.\\d+%/'\n\ntest-with-full-inheritance:\n  extends:\n    - .base-configuration\n    - .test-configuration\n  inherit: true\n  script:\n    - npm install\n    - npm test\n\ntest-with-selective-inheritance:\n  extends:\n    - .base-configuration\n    - .test-configuration\n  inherit:\n    - image\n    - cache\n  stage: test\n  script:\n    - npm install\n    - npm test\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#patterns-avances-dheritage","title":"Patterns avanc\u00e9s d'h\u00e9ritage","text":"YAML<pre><code>.docker-service:\n  image: docker:latest\n  services:\n    - docker:dind\n  before_script:\n    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n\n.security-checks:\n  script:\n    - ./scripts/security-scan.sh\n  artifacts:\n    reports:\n      sast: sast-report.json\n\n.deployment-base:\n  stage: deploy\n  when: manual\n  environment:\n    name: $CI_ENVIRONMENT_NAME\n  retry:\n    max: 2\n\nbuild-image:\n  extends: .docker-service\n  inherit:\n    default:\n      - tags\n      - timeout\n  stage: build\n  script:\n    - docker build -t myapp:$CI_COMMIT_SHA .\n\nscan-security:\n  extends:\n    - .docker-service\n    - .security-checks\n  inherit:\n    default: true\n  stage: test\n\ndeploy-staging:\n  extends:\n    - .deployment-base\n  inherit:\n    default:\n      - tags\n      - retry\n  environment:\n    name: staging\n  script:\n    - ./deploy.sh staging\n\ndeploy-production:\n  extends:\n    - .deployment-base\n  inherit:\n    default: false\n  environment:\n    name: production\n  script:\n    - ./deploy.sh production\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap04/#progression-et-synthese-du-chapitre","title":"Progression et synth\u00e8se du chapitre","text":"<p>L'apprentissage de ces notions avanc\u00e9es suit une progression logique et hi\u00e9rarchique. Commencer par la compr\u00e9hension de <code>default</code> fournit les fondations n\u00e9cessaires pour exploiter efficacement l'h\u00e9ritage. Cette compr\u00e9hension pr\u00e9alable rend l'utilisation de <code>extends</code> et <code>inherit</code> beaucoup plus intuitive.</p> <p>Par la suite, ma\u00eetriser la gestion des artifacts et d\u00e9pendances permet de concevoir des pipelines robustes o\u00f9 les donn\u00e9es circulent correctement entre les \u00e9tapes. Le cache vient ensuite compl\u00e9ter cette compr\u00e9hension en fournissant une couche d'optimisation pour les op\u00e9rations r\u00e9p\u00e9titives.</p> <p>La mesure du coverage s'appuie sur ces m\u00e9canismes de base pour injecter des rapports dans le pipeline. L'optimisation avec l'ex\u00e9cution en parall\u00e8le repr\u00e9sente une \u00e9tape o\u00f9 la connaissance des d\u00e9pendances devient essentielle pour d\u00e9finir efficacement les graphes d'ex\u00e9cution.</p> <p>Enfin, les patterns avanc\u00e9s de composition via <code>include</code>, la fusion avec les merge keys et le contr\u00f4le fin de l'h\u00e9ritage avec <code>inherit</code> constituent les techniques les plus sophistiqu\u00e9es. Ces derni\u00e8res requi\u00e8rent une compr\u00e9hension solide de tous les \u00e9l\u00e9ments pr\u00e9c\u00e9dents pour \u00eatre utilis\u00e9es efficacement.</p> <p>Cette progression garantit une compr\u00e9hension progressive et une capacit\u00e9 croissante \u00e0 concevoir des pipelines complexes et maintenables dans des environnements d'entreprise vari\u00e9s.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/","title":"Citations","text":"<ul> <li>https://www.winside.fr/blog/introduction-a-la-ci-cd-avec-gitlab-pour-les-developpeurs</li> <li>https://about.gitlab.com/fr-fr/blog/getting-started-with-gitlab-understanding-ci-cd/</li> <li>https://about.gitlab.com/fr-fr/blog/ultimate-guide-to-ci-cd-fundamentals-to-advanced-implementation/</li> <li>https://blog.eleven-labs.com/fr/introduction-gitlab-ci/</li> <li>https://blog.stephane-robert.info/docs/pipeline-cicd/gitlab/</li> <li>https://www.youtube.com/watch?v=UkUF827CGJY</li> <li>https://openclassrooms.com/fr/courses/2035736-mettez-en-place-l-integration-et-la-livraison-continues-avec-la-demarche-devops</li> <li>https://documentation.univ-lyon1.fr/gitlab/ci/</li> <li>https://about.gitlab.com/fr-fr/blog/basics-of-gitlab-ci-updated/</li> <li>https://www.youtube.com/watch?v=017CQCh3ogY</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 340</li> <li>completion_tokens: 6006</li> <li>total_tokens: 6346</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.09, 'request_cost': 0.006, 'total_cost': 0.097}</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#content","title":"Content","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#chapitre-5-projet-1-gitlab-cicd","title":"Chapitre 5 : Projet 1 - GitLab CI/CD","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#introduction-au-projet","title":"Introduction au projet","text":"<p>GitLab CI/CD repr\u00e9sente une plateforme DevOps int\u00e9gr\u00e9e permettant d'automatiser l'ensemble du cycle de d\u00e9veloppement logiciel[1]. Ce projet vise \u00e0 mettre en \u0153uvre une pipeline CI/CD compl\u00e8te couvrant \u00e0 la fois les aspects d'int\u00e9gration continue (CI) et de d\u00e9ploiement continu (CD) pour une application compos\u00e9e d'un frontend et d'un backend.</p> <p>L'objectif fondamental consiste \u00e0 transformer le workflow de d\u00e9veloppement en automatisant chaque \u00e9tape : compilation, tests, analyse de la couverture de code, et d\u00e9ploiement vers les environnements de pr\u00e9production et production[2]. Cette automatisation garantit que chaque modification de code est imm\u00e9diatement valid\u00e9e, test\u00e9e et pr\u00eate pour la mise en production, tout en maintenant des standards de qualit\u00e9 \u00e9lev\u00e9s.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#presentation-du-frontend-et-du-backend","title":"Pr\u00e9sentation du frontend et du backend","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#architecture-generale","title":"Architecture g\u00e9n\u00e9rale","text":"<p>L'application se compose de deux composants distincts dont l'interaction s'effectue via des API REST :</p> <p>Backend \ud83d\udccb - Service REST API construite avec Spring Boot (Java) - Responsable de la logique m\u00e9tier et de la gestion des donn\u00e9es - Communication via endpoints HTTP RESTful - Base de donn\u00e9es relationnelle pour la persistance</p> <p>Frontend \ud83c\udfa8 - Application web d\u00e9velopp\u00e9e avec des technologies modernes (React, Angular ou Vue.js) - Interface utilisateur interactive - Communication avec le backend via appels API HTTP/HTTPS - Rendu client-side des contenus</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#interactions-entre-les-composants","title":"Interactions entre les composants","text":"Aspect Backend Frontend Langage Java/Spring Boot JavaScript/TypeScript Responsabilit\u00e9 Logique m\u00e9tier, donn\u00e9es Interface utilisateur Communication Endpoints REST Appels fetch/axios Tests Tests unitaires, tests d'int\u00e9gration Tests unitaires, tests e2e D\u00e9ploiement Serveur applicatif CDN ou serveur web statique"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#pipeline-globale","title":"Pipeline globale","text":"<p>La pipeline CI/CD doit g\u00e9rer les \u00e9tapes suivantes pour chaque composant :</p> <ul> <li>Build/Compilation : Construction des artefacts (JAR pour backend, bundle JS pour frontend)</li> <li>Tests unitaires : Validation des fonctionnalit\u00e9s individuelles</li> <li>Analyse de qualit\u00e9 : \u00c9valuation de la couverture de code et de la complexit\u00e9</li> <li>Tests d'int\u00e9grabilit\u00e9 : V\u00e9rification de la communication inter-composants</li> <li>Tests multi-navigateurs : Pour le frontend uniquement, validation sur diff\u00e9rents navigateurs</li> <li>D\u00e9ploiement : Mise en ligne des versions compil\u00e9es et test\u00e9es</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#mise-en-place-ssh-pour-le-runner-gitlab","title":"Mise en place SSH pour le runner GitLab","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#concept-fondamental-des-runners","title":"Concept fondamental des runners","text":"<p>Un GitLab Runner constitue un agent l\u00e9ger charg\u00e9 d'ex\u00e9cuter les jobs d\u00e9finis dans la pipeline CI/CD[2]. Cet agent peut fonctionner sur l'infrastructure de choix : machines physiques, machines virtuelles, conteneurs Docker ou clusters Kubernetes[2].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#configuration-ssh-avec-le-runner","title":"Configuration SSH avec le runner","text":"<p>La mise en place SSH pour le runner GitLab permet une communication s\u00e9curis\u00e9e avec les serveurs de d\u00e9ploiement. Cette approche implique plusieurs \u00e9tapes :</p> <p>\u00c9tape 1 : G\u00e9n\u00e9ration des cl\u00e9s SSH</p> Bash<pre><code># Sur la machine h\u00e9bergeant le runner\nssh-keygen -t rsa -b 4096 -f ~/.ssh/gitlab-runner -C \"gitlab-runner\"\n</code></pre> <p>Cette commande g\u00e9n\u00e8re une paire de cl\u00e9s : une cl\u00e9 priv\u00e9e (<code>gitlab-runner</code>) et une cl\u00e9 publique (<code>gitlab-runner.pub</code>).</p> <p>\u00c9tape 2 : D\u00e9ploiement de la cl\u00e9 publique</p> Bash<pre><code># Sur le serveur de d\u00e9ploiement cible\ncat ~/.ssh/gitlab-runner.pub &gt;&gt; ~/.ssh/authorized_keys\nchmod 600 ~/.ssh/authorized_keys\n</code></pre> <p>\u00c9tape 3 : Configuration du fichier de configuration SSH</p> <p>La cr\u00e9ation d'un fichier de configuration SSH simplifie les connexions :</p> Bash<pre><code># ~/.ssh/config\nHost deployment-server\n    HostName 192.168.1.100\n    User deploy\n    IdentityFile ~/.ssh/gitlab-runner\n    StrictHostKeyChecking no\n</code></pre> <p>\u00c9tape 4 : Stockage s\u00e9curis\u00e9 des cl\u00e9s dans GitLab</p> <p>Les cl\u00e9s SSH doivent \u00eatre stock\u00e9es en tant que variables CI/CD prot\u00e9g\u00e9es dans GitLab :</p> <ol> <li>Acc\u00e9der \u00e0 Settings \u2192 CI/CD \u2192 Variables</li> <li>Cr\u00e9er une variable <code>SSH_PRIVATE_KEY</code> avec la cl\u00e9 priv\u00e9e encod\u00e9e en base64</li> <li>Marquer la variable comme \u00ab Protected \u00bb et \u00ab Masked \u00bb</li> </ol> <p>\u00c9tape 5 : Utilisation dans le <code>.gitlab-ci.yml</code></p> YAML<pre><code>before_script:\n  - apt-get update &amp;&amp; apt-get install -y openssh-client\n  - eval $(ssh-agent -s)\n  - echo \"$SSH_PRIVATE_KEY\" | tr -d '\\r' | ssh-add -\n  - mkdir -p ~/.ssh\n  - chmod 700 ~/.ssh\n\ndeploy_job:\n  stage: deploy\n  script:\n    - ssh -o StrictHostKeyChecking=no deploy@deployment-server \"cd /var/www/app &amp;&amp; ./deploy.sh\"\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#verification-de-la-connectivite","title":"V\u00e9rification de la connectivit\u00e9","text":"Bash<pre><code># Test de connexion SSH\nssh -i ~/.ssh/gitlab-runner deploy@deployment-server \"echo 'SSH connection successful'\"\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#mise-en-place-des-jobs-ci-pour-le-backend","title":"Mise en place des jobs CI pour le backend","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#structure-du-fichier-gitlab-ciyml","title":"Structure du fichier <code>.gitlab-ci.yml</code>","text":"<p>Le fichier <code>.gitlab-ci.yml</code> constitue le c\u0153ur de la configuration CI/CD dans GitLab[1]. Sa structure d\u00e9finit les \u00e9tapes, les jobs et leur orchestration.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#stages-de-pipeline-pour-le-backend","title":"Stages de pipeline pour le backend","text":"YAML<pre><code>stages:\n  - build\n  - test\n  - analyze\n  - deploy\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#job-de-compilation-backend","title":"Job de compilation backend","text":"<p>Build Spring Boot</p> YAML<pre><code>build_backend:\n  stage: build\n  image: maven:3.8.1-openjdk-11\n  script:\n    - echo \"Building Spring Boot application...\"\n    - mvn clean package -DskipTests\n  artifacts:\n    paths:\n      - target/api-*.jar\n    expire_in: 1 day\n  cache:\n    paths:\n      - .m2/repository/\n  only:\n    - main\n    - develop\n</code></pre> <p>Ce job effectue les op\u00e9rations suivantes :</p> <ul> <li>Utilise l'image Docker <code>maven:3.8.1-openjdk-11</code> contenant Maven et OpenJDK 11</li> <li>Ex\u00e9cute une compilation Maven compl\u00e8te</li> <li>G\u00e9n\u00e8re un artefact (fichier JAR) stock\u00e9 pour une journ\u00e9e</li> <li>Met en cache les d\u00e9pendances Maven pour acc\u00e9l\u00e9rer les builds ult\u00e9rieurs</li> <li>S'ex\u00e9cute uniquement sur les branches <code>main</code> et <code>develop</code></li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#jobs-de-tests-unitaires-backend","title":"Jobs de tests unitaires backend","text":"<p>Tests unitaires et d'int\u00e9gration</p> YAML<pre><code>test_backend_unit:\n  stage: test\n  image: maven:3.8.1-openjdk-11\n  script:\n    - echo \"Running unit tests...\"\n    - mvn test\n    - echo \"Running integration tests...\"\n    - mvn verify\n  artifacts:\n    reports:\n      junit: target/surefire-reports/TEST-*.xml\n  cache:\n    paths:\n      - .m2/repository/\n  dependencies:\n    - build_backend\n  allow_failure: false\n</code></pre> <p>Les artifacts <code>junit</code> permettent \u00e0 GitLab d'afficher les r\u00e9sultats des tests directement dans l'interface.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#job-de-qualite-du-code-backend","title":"Job de qualit\u00e9 du code backend","text":"<p>Analyse SonarQube</p> YAML<pre><code>analyze_backend_sonarqube:\n  stage: analyze\n  image: maven:3.8.1-openjdk-11\n  script:\n    - echo \"Analyzing code quality with SonarQube...\"\n    - mvn sonar:sonar \n      -Dsonar.projectKey=backend-project\n      -Dsonar.sources=src\n      -Dsonar.host.url=$SONARQUBE_URL\n      -Dsonar.login=$SONARQUBE_TOKEN\n  allow_failure: true\n  only:\n    - merge_requests\n    - main\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#couverture-du-code-backend","title":"Couverture du code backend","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#generation-des-rapports-de-couverture","title":"G\u00e9n\u00e9ration des rapports de couverture","text":"<p>La couverture de code mesure le pourcentage de code ex\u00e9cut\u00e9 pendant les tests. Pour le backend Spring Boot, l'outil JaCoCo (Java Code Coverage) est couramment utilis\u00e9.</p> <p>Configuration Maven avec JaCoCo</p> XML<pre><code>&lt;!-- pom.xml --&gt;\n&lt;properties&gt;\n    &lt;sonar.coverage.exclusions&gt;\n        **/config/**,\n        **/entity/**,\n        **/dto/**\n    &lt;/sonar.coverage.exclusions&gt;\n&lt;/properties&gt;\n\n&lt;plugin&gt;\n    &lt;groupId&gt;org.jacoco&lt;/groupId&gt;\n    &lt;artifactId&gt;jacoco-maven-plugin&lt;/artifactId&gt;\n    &lt;version&gt;0.8.7&lt;/version&gt;\n    &lt;executions&gt;\n        &lt;execution&gt;\n            &lt;goals&gt;\n                &lt;goal&gt;prepare-agent&lt;/goal&gt;\n            &lt;/goals&gt;\n        &lt;/execution&gt;\n        &lt;execution&gt;\n            &lt;id&gt;report&lt;/id&gt;\n            &lt;phase&gt;test&lt;/phase&gt;\n            &lt;goals&gt;\n                &lt;goal&gt;report&lt;/goal&gt;\n            &lt;/goals&gt;\n        &lt;/execution&gt;\n    &lt;/executions&gt;\n&lt;/plugin&gt;\n</code></pre> <p>Job CI pour la couverture</p> YAML<pre><code>coverage_backend:\n  stage: analyze\n  image: maven:3.8.1-openjdk-11\n  script:\n    - mvn clean test jacoco:report\n    - cat target/site/jacoco/index.html\n  artifacts:\n    paths:\n      - target/site/jacoco/\n    expire_in: 30 days\n  coverage: '/Total.*?(\\d+)%/'\n  cache:\n    paths:\n      - .m2/repository/\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#seuils-de-couverture-et-qualite-gates","title":"Seuils de couverture et qualit\u00e9 gates","text":"YAML<pre><code>quality_gate_backend:\n  stage: analyze\n  image: maven:3.8.1-openjdk-11\n  script:\n    - |\n      COVERAGE=$(mvn jacoco:report | grep -oP 'Total.*?\\K\\d+(?=%)')\n      if [ \"$COVERAGE\" -lt 70 ]; then\n        echo \"Couverture insuffisante: $COVERAGE%\"\n        exit 1\n      fi\n  dependencies:\n    - coverage_backend\n  allow_failure: false\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#planification-des-jobs-frontend-et-refactorisation-du-cache","title":"Planification des jobs frontend et refactorisation du cache","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#stages-pour-le-frontend","title":"Stages pour le frontend","text":"YAML<pre><code>stages:\n  - build\n  - test\n  - lint\n  - e2e\n  - deploy\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#job-de-construction-frontend","title":"Job de construction frontend","text":"<p>Build avec npm/yarn</p> YAML<pre><code>build_frontend:\n  stage: build\n  image: node:16-alpine\n  script:\n    - echo \"Installing dependencies...\"\n    - npm ci\n    - echo \"Building application...\"\n    - npm run build\n  artifacts:\n    paths:\n      - dist/\n    expire_in: 1 day\n  cache:\n    key:\n      files:\n        - package-lock.json\n    paths:\n      - node_modules/\n  only:\n    - main\n    - develop\n</code></pre> <p>L'utilisation de <code>npm ci</code> (clean install) au lieu de <code>npm install</code> garantit l'installation exacte des versions sp\u00e9cifi\u00e9es.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#optimisation-du-cache-multi-etages","title":"Optimisation du cache multi-\u00e9tages","text":"<p>Refactorisation pour r\u00e9utiliser les d\u00e9pendances</p> YAML<pre><code>cache_dependencies:\n  stage: .pre\n  image: node:16-alpine\n  script:\n    - npm ci\n  cache:\n    key:\n      files:\n        - package-lock.json\n    paths:\n      - node_modules/\n  artifacts:\n    paths:\n      - node_modules/\n    expire_in: 1 day\n\nbuild_frontend:\n  stage: build\n  image: node:16-alpine\n  script:\n    - npm run build\n  dependencies:\n    - cache_dependencies\n  artifacts:\n    paths:\n      - dist/\n    expire_in: 1 day\n\ntest_frontend:\n  stage: test\n  image: node:16-alpine\n  script:\n    - npm run test\n  dependencies:\n    - cache_dependencies\n  coverage: '/Statements\\s*:\\s*(\\d+\\.\\d+)%/'\n\nlint_frontend:\n  stage: lint\n  image: node:16-alpine\n  script:\n    - npm run lint\n  dependencies:\n    - cache_dependencies\n  allow_failure: true\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#strategies-de-cache-avancees","title":"Strat\u00e9gies de cache avanc\u00e9es","text":"Strat\u00e9gie Utilisation Avantages Cache par fichier Quand les d\u00e9pendances changent rarement Rapidit\u00e9 maximale Cache par branche Pour des branches isol\u00e9es avec d\u00e9pendances sp\u00e9cifiques Isolation par branche Cache partage global Pour les t\u00e2ches communes Partage entre toutes les branches <p>Configuration cache avanc\u00e9e</p> YAML<pre><code>cache:\n  key:\n    prefix: ${CI_COMMIT_REF_SLUG}\n    files:\n      - package-lock.json\n  paths:\n    - node_modules/\n  policy: pull-push\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#couverture-du-code-frontend","title":"Couverture du code frontend","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#configuration-des-outils-de-couverture","title":"Configuration des outils de couverture","text":"<p>Installation et configuration de Jest avec couverture</p> JavaScript<pre><code>// jest.config.js\nmodule.exports = {\n  testEnvironment: 'jsdom',\n  coverageDirectory: 'coverage',\n  collectCoverageFrom: [\n    'src/**/*.{js,jsx}',\n    '!src/index.js',\n    '!src/**/*.spec.js',\n    '!src/config/**'\n  ],\n  coverageThreshold: {\n    global: {\n      branches: 70,\n      functions: 70,\n      lines: 70,\n      statements: 70\n    }\n  }\n};\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#job-de-couverture-frontend","title":"Job de couverture frontend","text":"YAML<pre><code>coverage_frontend:\n  stage: test\n  image: node:16-alpine\n  script:\n    - npm ci\n    - npm run test:coverage\n  artifacts:\n    paths:\n      - coverage/\n    reports:\n      coverage_report:\n        coverage_format: cobertura\n        path: coverage/cobertura-coverage.xml\n    expire_in: 30 days\n  coverage: '/Statements\\s*:\\s*(\\d+\\.\\d+)%/'\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#configuration-pour-istanbulnyc","title":"Configuration pour Istanbul/nyc","text":"JSON<pre><code>{\n  \"nyc\": {\n    \"reporter\": [\"text\", \"cobertura\", \"html\"],\n    \"temp-dir\": \".nyc_output\",\n    \"report-dir\": \"coverage\",\n    \"exclude\": [\n      \"node_modules/**\",\n      \"test/**\",\n      \"dist/**\"\n    ],\n    \"check-coverage\": true,\n    \"lines\": 70,\n    \"statements\": 70,\n    \"functions\": 70,\n    \"branches\": 70\n  }\n}\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#execution-multi-navigateurs","title":"Ex\u00e9cution multi-navigateurs","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#tests-e2e-avec-cypress","title":"Tests e2e avec Cypress","text":"<p>Configuration Cypress pour multi-navigateurs</p> JavaScript<pre><code>// cypress.config.js\nmodule.exports = {\n  e2e: {\n    baseUrl: 'http://localhost:3000',\n    viewportWidth: 1280,\n    viewportHeight: 720,\n    specPattern: 'cypress/e2e/**/*.cy.{js,jsx}',\n    supportFile: 'cypress/support/e2e.js'\n  }\n};\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#jobs-ci-pour-tests-multi-navigateurs","title":"Jobs CI pour tests multi-navigateurs","text":"YAML<pre><code>e2e_chrome:\n  stage: e2e\n  image: cypress/browsers:node16.13.0-chrome95\n  script:\n    - npm ci\n    - npm run build\n    - npx cypress run --browser chrome\n  artifacts:\n    when: always\n    paths:\n      - cypress/videos/\n      - cypress/screenshots/\n    expire_in: 7 days\n  only:\n    - main\n    - develop\n\ne2e_firefox:\n  stage: e2e\n  image: cypress/browsers:node16.13.0-firefox\n  script:\n    - npm ci\n    - npm run build\n    - npx cypress run --browser firefox\n  artifacts:\n    when: always\n    paths:\n      - cypress/videos/\n      - cypress/screenshots/\n    expire_in: 7 days\n  only:\n    - main\n    - develop\n\ne2e_edge:\n  stage: e2e\n  image: cypress/browsers:node16.13.0-edge\n  script:\n    - npm ci\n    - npm run build\n    - npx cypress run --browser edge\n  artifacts:\n    when: always\n    paths:\n      - cypress/videos/\n      - cypress/screenshots/\n    expire_in: 7 days\n  only:\n    - main\n    - develop\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#tests-parallelises","title":"Tests parall\u00e9lis\u00e9s","text":"YAML<pre><code>e2e_parallel:\n  stage: e2e\n  image: cypress/included:13.0.0\n  parallel:\n    matrix:\n      - BROWSER: [chrome, firefox, edge]\n        SPEC: [\n          \"cypress/e2e/auth/**\",\n          \"cypress/e2e/dashboard/**\",\n          \"cypress/e2e/profile/**\"\n        ]\n  script:\n    - npx cypress run --browser $BROWSER --spec \"$SPEC\"\n  artifacts:\n    when: always\n    paths:\n      - cypress/videos/\n      - cypress/screenshots/\n    expire_in: 7 days\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#mise-en-place-du-job-cd-pour-le-deploiement-backend","title":"Mise en place du job CD pour le d\u00e9ploiement backend","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#concept-du-deploiement-continu","title":"Concept du d\u00e9ploiement continu","text":"<p>Le d\u00e9ploiement continu (CD) automatise la mise en ligne des applications compil\u00e9es et test\u00e9es. Chaque build r\u00e9ussi passant tous les contr\u00f4les de qualit\u00e9 peut \u00eatre d\u00e9ploy\u00e9 automatiquement ou sur demande[2].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#job-de-deploiement-backend","title":"Job de d\u00e9ploiement backend","text":"<p>D\u00e9ploiement sur serveur applicatif</p> YAML<pre><code>deploy_backend_staging:\n  stage: deploy\n  image: alpine:latest\n  before_script:\n    - apk add --no-cache openssh-client\n    - eval $(ssh-agent -s)\n    - echo \"$SSH_PRIVATE_KEY\" | tr -d '\\r' | ssh-add -\n    - mkdir -p ~/.ssh\n    - chmod 700 ~/.ssh\n  script:\n    - |\n      ssh -o StrictHostKeyChecking=no deploy@staging-server &lt;&lt; 'EOF'\n      cd /var/www/backend\n      systemctl stop backend || true\n      cp target/api-*.jar ./api-latest.jar\n      systemctl start backend\n      systemctl status backend\n      EOF\n  environment:\n    name: staging\n    url: https://staging-api.example.com\n  dependencies:\n    - build_backend\n    - test_backend_unit\n    - coverage_backend\n  only:\n    - develop\n  when: on_success\n\ndeploy_backend_production:\n  stage: deploy\n  image: alpine:latest\n  before_script:\n    - apk add --no-cache openssh-client\n    - eval $(ssh-agent -s)\n    - echo \"$SSH_PRIVATE_KEY\" | tr -d '\\r' | ssh-add -\n    - mkdir -p ~/.ssh\n    - chmod 700 ~/.ssh\n  script:\n    - |\n      ssh -o StrictHostKeyChecking=no deploy@prod-server &lt;&lt; 'EOF'\n      cd /var/www/backend\n      # Backup de la version actuelle\n      cp api-latest.jar api-backup-$(date +%s).jar\n      systemctl stop backend\n      cp target/api-*.jar ./api-latest.jar\n      systemctl start backend\n      systemctl status backend\n      EOF\n  environment:\n    name: production\n    url: https://api.example.com\n  dependencies:\n    - build_backend\n    - test_backend_unit\n    - coverage_backend\n  only:\n    - main\n  when: manual\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#deploiement-avec-docker","title":"D\u00e9ploiement avec Docker","text":"<p>Utilisation d'images Docker pour le d\u00e9ploiement</p> YAML<pre><code>build_backend_docker:\n  stage: build\n  image: docker:latest\n  services:\n    - docker:dind\n  script:\n    - docker build -t registry.example.com/backend:$CI_COMMIT_SHA .\n    - docker tag registry.example.com/backend:$CI_COMMIT_SHA registry.example.com/backend:latest\n    - docker push registry.example.com/backend:$CI_COMMIT_SHA\n    - docker push registry.example.com/backend:latest\n  only:\n    - main\n\ndeploy_backend_docker:\n  stage: deploy\n  image: alpine:latest\n  script:\n    - |\n      ssh -o StrictHostKeyChecking=no deploy@prod-server &lt;&lt; 'EOF'\n      cd /var/www/backend\n      docker pull registry.example.com/backend:latest\n      docker stop backend-container || true\n      docker rm backend-container || true\n      docker run -d --name backend-container \\\n        -p 8080:8080 \\\n        -e DATABASE_URL=$DATABASE_URL \\\n        registry.example.com/backend:latest\n      EOF\n  environment:\n    name: production\n  only:\n    - main\n  when: manual\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#health-checks-post-deploiement","title":"Health checks post-d\u00e9ploiement","text":"YAML<pre><code>health_check_backend:\n  stage: deploy\n  image: curlimages/curl:latest\n  script:\n    - |\n      for i in {1..30}; do\n        if curl -f https://api.example.com/health; then\n          echo \"Backend is healthy\"\n          exit 0\n        fi\n        echo \"Attempt $i/30 - waiting for backend to be ready...\"\n        sleep 5\n      done\n      echo \"Backend failed to become healthy\"\n      exit 1\n  environment:\n    name: production\n  dependencies:\n    - deploy_backend_production\n  only:\n    - main\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#implementation-des-jobs-ci-client","title":"Impl\u00e9mentation des jobs CI client","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#jobs-specifiques-au-frontend","title":"Jobs sp\u00e9cifiques au frontend","text":"<p>Suite compl\u00e8te des jobs CI client</p> YAML<pre><code>lint_code:\n  stage: lint\n  image: node:16-alpine\n  script:\n    - npm ci\n    - npm run lint -- --format json --output-file lint-report.json || true\n    - npm run lint\n  artifacts:\n    reports:\n      codequality: lint-report.json\n  allow_failure: true\n\nformat_check:\n  stage: lint\n  image: node:16-alpine\n  script:\n    - npm ci\n    - npm run format:check\n  allow_failure: true\n\nsecurity_audit:\n  stage: test\n  image: node:16-alpine\n  script:\n    - npm ci\n    - npm audit --audit-level=moderate\n  allow_failure: true\n\nbuild_optimized:\n  stage: build\n  image: node:16-alpine\n  script:\n    - npm ci\n    - npm run build\n    - echo \"Build Size Analysis:\"\n    - du -sh dist/\n    - ls -lh dist/\n  artifacts:\n    paths:\n      - dist/\n    expire_in: 1 day\n\naccessibility_check:\n  stage: test\n  image: node:16-alpine\n  script:\n    - npm ci\n    - npm run test:a11y\n  allow_failure: true\n  artifacts:\n    reports:\n      junit: a11y-report.xml\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#tests-dintegration-client-backend","title":"Tests d'int\u00e9gration client-backend","text":"YAML<pre><code>integration_tests:\n  stage: test\n  image: node:16-alpine\n  services:\n    - name: registry.example.com/backend:latest\n      alias: backend\n  script:\n    - npm ci\n    - npm run test:integration\n      -- --baseUrl=http://backend:8080\n  environment:\n    name: integration-test\n  artifacts:\n    when: always\n    paths:\n      - integration-test-results/\n    reports:\n      junit: integration-test-results/junit.xml\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#deployment-frontend","title":"Deployment frontend","text":"YAML<pre><code>deploy_frontend_staging:\n  stage: deploy\n  image: node:16-alpine\n  before_script:\n    - apk add --no-cache openssh-client\n    - eval $(ssh-agent -s)\n    - echo \"$SSH_PRIVATE_KEY\" | tr -d '\\r' | ssh-add -\n    - mkdir -p ~/.ssh\n  script:\n    - npm ci\n    - npm run build\n    - |\n      ssh -o StrictHostKeyChecking=no deploy@staging-cdn &lt;&lt; 'EOF'\n      cd /var/www/frontend\n      rm -rf dist-old\n      mv dist dist-old || true\n      EOF\n    - scp -r dist/* deploy@staging-cdn:/var/www/frontend/dist/\n  environment:\n    name: staging\n    url: https://staging.example.com\n  only:\n    - develop\n  when: on_success\n\ndeploy_frontend_production:\n  stage: deploy\n  image: node:16-alpine\n  before_script:\n    - apk add --no-cache openssh-client\n    - eval $(ssh-agent -s)\n    - echo \"$SSH_PRIVATE_KEY\" | tr -d '\\r' | ssh-add -\n    - mkdir -p ~/.ssh\n  script:\n    - npm ci\n    - npm run build\n    - |\n      ssh -o StrictHostKeyChecking=no deploy@prod-cdn &lt;&lt; 'EOF'\n      cd /var/www/frontend\n      cp -r dist dist-backup-$(date +%s) || true\n      EOF\n    - scp -r dist/* deploy@prod-cdn:/var/www/frontend/dist/\n    - ssh deploy@prod-cdn \"chmod -R 755 /var/www/frontend/dist\"\n  environment:\n    name: production\n    url: https://example.com\n  only:\n    - main\n  when: manual\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap05/#pipeline-complete-consolidee","title":"Pipeline compl\u00e8te consolid\u00e9e","text":"YAML<pre><code>image: docker:latest\n\nstages:\n  - .pre\n  - build\n  - test\n  - lint\n  - analyze\n  - e2e\n  - deploy\n  - verify\n\nvariables:\n  DOCKER_DRIVER: overlay2\n  DOCKER_TLS_CERTDIR: \"/certs\"\n\n# Backend Jobs\nbuild_backend:\n  stage: build\n  image: maven:3.8.1-openjdk-11\n  script:\n    - mvn clean package -DskipTests\n  artifacts:\n    paths:\n      - target/api-*.jar\n    expire_in: 1 day\n  cache:\n    paths:\n      - .m2/repository/\n\ntest_backend:\n  stage: test\n  image: maven:3.8.1-openjdk-11\n  script:\n    - mvn test\n  cache:\n    paths:\n      - .m2/repository/\n\n# Frontend Jobs\nbuild_frontend:\n  stage: build\n  image: node:16-alpine\n  script:\n    - npm ci\n    - npm run build\n  artifacts:\n    paths:\n      - dist/\n    expire_in: 1 day\n  cache:\n    key:\n      files:\n        - package-lock.json\n    paths:\n      - node_modules/\n\ntest_frontend:\n  stage: test\n  image: node:16-alpine\n  script:\n    - npm ci\n    - npm run test:coverage\n  cache:\n    key:\n      files:\n        - package-lock.json\n    paths:\n      - node_modules/\n\ne2e_tests:\n  stage: e2e\n  image: cypress/included:13.0.0\n  script:\n    - npm ci\n    - npx cypress run\n  artifacts:\n    when: always\n    paths:\n      - cypress/videos/\n      - cypress/screenshots/\n\ndeploy:\n  stage: deploy\n  image: alpine:latest\n  script:\n    - echo \"Deploying application...\"\n  only:\n    - main\n  when: manual\n</code></pre> <p>Cette impl\u00e9mentation compl\u00e8te couvre l'ensemble du cycle de d\u00e9veloppement, de la compilation au d\u00e9ploiement, en passant par les tests unitaires, l'analyse de couverture, les tests multi-navigateurs et le d\u00e9ploiement continu[1][2][3]. La structure modulaire permet une adaptation facile selon les besoins sp\u00e9cifiques du projet et de l'infrastructure d'entreprise.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/","title":"Citations","text":"<ul> <li>https://spacelift.io/blog/docker-ci-cd</li> <li>https://docs.gitlab.com/ci/quick_start/tutorial/</li> <li>https://dev.to/arbythecoder/introduction-to-docker-integration-in-gitlab-cicd-pipelines-4lg6</li> <li>https://docs.gitlab.com/ci/quick_start/</li> <li>https://docs.gitlab.com/ci/docker/using_docker_images/</li> <li>https://www.youtube.com/watch?v=z7nLsJvEyMY</li> <li>https://octopus.com/devops/gitlab/gitlab-cicd-tutorial/</li> <li>https://docs.gitlab.com/ci/docker/using_docker_build/</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 306</li> <li>completion_tokens: 7010</li> <li>total_tokens: 7316</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.105, 'request_cost': 0.006, 'total_cost': 0.112}</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#content","title":"Content","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#chapitre-6-projet-2-gitlab-cicd-avec-docker","title":"\ud83d\udcda Chapitre 6 : Projet 2 - GitLab CI/CD avec Docker","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#presentation-du-projet-et-gitlab-container-registry","title":"\ud83c\udfaf Pr\u00e9sentation du projet et GitLab Container Registry","text":"<p>GitLab CI/CD repr\u00e9sente une plateforme compl\u00e8te d'int\u00e9gration et de d\u00e9ploiement continus permettant d'automatiser l'ensemble du cycle de vie applicatif, de la compilation au d\u00e9ploiement en production.[1] Lorsqu'on l'associe \u00e0 Docker, cette puissance s'accro\u00eet consid\u00e9rablement en offrant une isolation maximale des environnements et une coh\u00e9rence garantie entre le d\u00e9veloppement, les tests et la production.[3]</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#fondamentaux-de-gitlab-cicd-et-docker","title":"Fondamentaux de GitLab CI/CD et Docker","text":"<p>GitLab CI/CD fonctionne selon un mod\u00e8le d\u00e9claratif o\u00f9 chaque pipeline est d\u00e9fini dans un fichier <code>.gitlab-ci.yml</code> situ\u00e9 \u00e0 la racine du r\u00e9f\u00e9rentiel.[4] Ce fichier d\u00e9crit les \u00e9tapes, les jobs et les conditions d'ex\u00e9cution. Docker intervient \u00e0 deux niveaux :</p> <p>Premier niveau - Ex\u00e9cution des jobs : La plateforme GitLab cr\u00e9e un nouveau conteneur Docker pour chaque job du pipeline.[1] Le script du job s'ex\u00e9cute \u00e0 l'int\u00e9rieur du conteneur, fournissant une isolation par job qui pr\u00e9vient les effets secondaires ind\u00e9sirables et renforce la s\u00e9curit\u00e9.</p> <p>Deuxi\u00e8me niveau - Construction et d\u00e9ploiement : Un job du pipeline est utilis\u00e9 pour construire une image Docker mise \u00e0 jour suite aux modifications du code source, image qui peut ensuite \u00eatre d\u00e9ploy\u00e9e en production dans un job ult\u00e9rieur.[1]</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#gitlab-container-registry","title":"GitLab Container Registry","text":"<p>GitLab Container Registry est un registre int\u00e9gr\u00e9 natif fourni par GitLab permettant de stocker et de g\u00e9rer les images Docker sans configuration externe.[1] Ce registre pr\u00e9sente plusieurs avantages :</p> <ul> <li>Accessibilit\u00e9 : Directement accessible depuis l'interface web sous Deploy &gt; Container Registry</li> <li>Authentification int\u00e9gr\u00e9e : Utilise les credentials GitLab pour l'acc\u00e8s</li> <li>Versioning automatique : Les images sont tagu\u00e9es avec le SHA du commit, permettant une tra\u00e7abilit\u00e9 compl\u00e8te</li> <li>D\u00e9ploiement facilit\u00e9 : Les images peuvent \u00eatre directement d\u00e9ploy\u00e9es vers diff\u00e9rents environnements</li> </ul> <p>Le registre stocke les images avec une nomenclature standardis\u00e9e : <code>$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA</code>, o\u00f9 <code>$CI_REGISTRY_IMAGE</code> correspond \u00e0 l'URL du registre et du projet, tandis que <code>$CI_COMMIT_SHA</code> repr\u00e9sente l'identifiant unique du commit.[1]</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#creation-des-images-et-push-manuel","title":"\ud83c\udfd7\ufe0f Cr\u00e9ation des images et push manuel","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#preparation-de-lenvironnement-gitlab","title":"Pr\u00e9paration de l'environnement GitLab","text":"<p>Avant de commencer la cr\u00e9ation d'images Docker, plusieurs \u00e9tapes pr\u00e9alables sont n\u00e9cessaires[4] :</p> <ul> <li>V\u00e9rifier la disponibilit\u00e9 des runners : Si l'utilisation se fait sur GitLab.com, les instance runners sont fournis par d\u00e9faut. Pour une instance GitLab auto-h\u00e9berg\u00e9e, un GitLab Runner configur\u00e9 avec l'ex\u00e9cuteur Docker doit \u00eatre pr\u00e9alablement connect\u00e9.</li> <li>Cr\u00e9er un nouveau projet : Sur GitLab.com ou une instance locale</li> <li>Initialiser le r\u00e9f\u00e9rentiel : Cloner le projet localement pour commencer le d\u00e9veloppement</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#structure-du-projet-et-dockerfile","title":"Structure du projet et Dockerfile","text":"<p>La premi\u00e8re \u00e9tape concr\u00e8te consiste \u00e0 cr\u00e9er le fichier <code>Dockerfile</code> qui d\u00e9finit la configuration de l'image applicative. Voici un exemple simplifi\u00e9 :</p> Docker<pre><code>FROM httpd:alpine\n\nRUN echo \"&lt;h1&gt;Hello World&lt;/h1&gt;\" &gt; /usr/local/apache2/htdocs/index.html\n</code></pre> <p>Ce Dockerfile utilise l'image l\u00e9g\u00e8re <code>httpd:alpine</code> comme base et cr\u00e9e une page HTML de test. Apr\u00e8s cr\u00e9ation, le fichier doit \u00eatre commit\u00e9 et pouss\u00e9 vers le r\u00e9f\u00e9rentiel :</p> Bash<pre><code>$ git add Dockerfile\n$ git commit -m \"Add Dockerfile\"\n$ git push\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#variables-denvironnement-et-authentification","title":"Variables d'environnement et authentification","text":"<p>Pour permettre \u00e0 la pipeline de construire et pousser les images vers le GitLab Container Registry, des variables d'environnement doivent \u00eatre configur\u00e9es.[3] L'acc\u00e8s s'effectue via Settings &gt; CI/CD &gt; Variables dans l'interface GitLab :</p> Variable Description Source <code>CI_REGISTRY</code> URL du registre de conteneurs GitLab Automatiquement d\u00e9finie <code>CI_REGISTRY_USER</code> Nom d'utilisateur GitLab Automatiquement d\u00e9finie <code>CI_REGISTRY_PASSWORD</code> Token d'acc\u00e8s personnel GitLab \u00c0 g\u00e9n\u00e9rer dans les param\u00e8tres du profil <code>CI_REGISTRY_IMAGE</code> Chemin complet de l'image (registre + projet) Automatiquement d\u00e9finie"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#push-manuel-versus-automatise","title":"Push manuel versus automatis\u00e9","text":"<p>Le push manuel d'une image implique une intervention humaine \u00e0 chaque \u00e9tape. Bien que cela soit possible localement via Docker CLI, cette approche ne correspond pas au paradigme CI/CD. Le flux optimal automatise ce processus directement dans la pipeline, sans intervention manuelle.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#construction-des-images-dans-un-pipeline","title":"\ud83d\ude80 Construction des images dans un pipeline","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#configuration-de-la-pipeline-gitlab","title":"Configuration de la pipeline GitLab","text":"<p>La construction automatis\u00e9e des images s'effectue par la cr\u00e9ation d'un fichier <code>.gitlab-ci.yml</code> \u00e0 la racine du projet.[4] Ce fichier YAML orchestre l'ensemble des \u00e9tapes de la pipeline. Voici une configuration fondamentale :</p> YAML<pre><code>stages:\n  - build\n\nvariables:\n  DOCKER_IMAGE: $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n\nbuild:\n  image: docker:25.0\n  stage: build\n  services:\n    - docker:25.0-dind\n  script:\n    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n    - docker build -t $DOCKER_IMAGE .\n    - docker push $DOCKER_IMAGE\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#decomposition-de-la-configuration","title":"D\u00e9composition de la configuration","text":"<p>Section stages : D\u00e9finit les phases d'ex\u00e9cution de la pipeline. Dans cet exemple simple, une seule phase <code>build</code> existe.</p> <p>Section variables : D\u00e9clare les variables utilis\u00e9es dans l'ensemble de la pipeline. <code>DOCKER_IMAGE</code> combine le registre et le SHA du commit pour une identification unique.</p> <p>Section build : D\u00e9crit le job principal de construction : - <code>image: docker:25.0</code> : S\u00e9lectionne l'image Docker \u00e0 utiliser pour ex\u00e9cuter le job[5] - <code>services: docker:25.0-dind</code> : Active Docker-in-Docker (DinD), permettant au job Docker d'acc\u00e9der \u00e0 un daemon Docker[1] - <code>script</code> : Contient les commandes \u00e0 ex\u00e9cuter</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#mecanisme-docker-in-docker-dind","title":"M\u00e9canisme Docker-in-Docker (DinD)","text":"<p>Docker-in-Docker est une technique permettant d'ex\u00e9cuter Docker \u00e0 l'int\u00e9rieur d'un conteneur Docker.[1] Le job s'ex\u00e9cute dans un conteneur <code>docker:25.0</code>, et gr\u00e2ce au service DinD, le daemon Docker est accessible \u00e0 l'int\u00e9rieur. Les commandes suivantes s'ex\u00e9cutent donc :</p> Bash<pre><code>docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\ndocker build -t $DOCKER_IMAGE .\ndocker push $DOCKER_IMAGE\n</code></pre> <p>L'authentification d'abord \u00e9tablie, la construction de l'image proc\u00e8de \u00e0 partir du Dockerfile local, puis l'image est pouss\u00e9e vers le registre GitLab.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#pipeline-avancee-avec-plusieurs-stages","title":"Pipeline avanc\u00e9e avec plusieurs stages","text":"<p>Pour des projets plus complexes, une pipeline multi-\u00e9tapes s'av\u00e8re b\u00e9n\u00e9fique :</p> YAML<pre><code>stages:\n  - build\n  - push\n\nvariables:\n  DOCKER_DRIVER: overlay2\n  IMAGE_TAG: $CI_REGISTRY_IMAGE:$CI_COMMIT_REF_SLUG\n\nbuild_image:\n  stage: build\n  image: docker:latest\n  services:\n    - docker:dind\n  script:\n    - docker build -t $IMAGE_TAG .\n    - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $CI_REGISTRY\n    - docker tag $IMAGE_TAG $CI_REGISTRY_IMAGE:latest\n\npush_image:\n  stage: push\n  image: docker:latest\n  services:\n    - docker:dind\n  script:\n    - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $CI_REGISTRY\n    - docker push $IMAGE_TAG\n    - docker push $CI_REGISTRY_IMAGE:latest\n</code></pre> <p>Cette approche s\u00e9pare construction et push en deux jobs distincts, offrant une meilleure clart\u00e9 et permettant une r\u00e9utilisation du job build par plusieurs jobs push avec des destinations diff\u00e9rentes.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#tagging-intelligent-des-images","title":"Tagging intelligent des images","text":"<p>L'utilisation de <code>$CI_COMMIT_REF_SLUG</code> comme tag combine le nom de la branche avec un identifiant stable, facilitant le suivi des versions.[3] Simultan\u00e9ment, cr\u00e9er un tag <code>latest</code> pour la branche principale permet \u00e0 l'environnement de production de toujours d\u00e9ployer la version la plus r\u00e9cente.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#tests-des-images-avant-de-les-pousser","title":"\ud83e\uddea Tests des images avant de les pousser","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#strategie-de-validation-des-images","title":"Strat\u00e9gie de validation des images","text":"<p>Avant de pousser une image vers le registre de production, valider son int\u00e9grit\u00e9 et son fonctionnement s'av\u00e8re essentiel. Cette validation s'effectue dans la pipeline m\u00eame, avant l'\u00e9tape de push, r\u00e9duisant ainsi le risque de d\u00e9ploiement d'images d\u00e9fectueuses.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#tests-de-construction-de-limage","title":"Tests de construction de l'image","text":"<p>Le premier niveau de test v\u00e9rifie que la construction elle-m\u00eame r\u00e9ussit sans erreur :</p> YAML<pre><code>stages:\n  - build\n  - test\n  - push\n\nbuild_image:\n  stage: build\n  image: docker:25.0\n  services:\n    - docker:25.0-dind\n  script:\n    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .\n  artifacts:\n    reports:\n      dotenv: build.env\n  after_script:\n    - echo \"IMAGE_TAG=$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\" &gt;&gt; build.env\n</code></pre> <p>Ce job cr\u00e9e un artefact contenant le tag de l'image, permettant aux jobs ult\u00e9rieurs de le r\u00e9utiliser.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#tests-fonctionnels-de-limage","title":"Tests fonctionnels de l'image","text":"<p>Apr\u00e8s construction, ex\u00e9cuter des tests \u00e0 l'int\u00e9rieur de l'image elle-m\u00eame valide son fonctionnement :</p> YAML<pre><code>test_image:\n  stage: test\n  image: $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n  dependencies:\n    - build_image\n  script:\n    - echo \"Testing application inside the container...\"\n    - whoami\n    - pwd\n    - ls -la\n    - |\n      if [ -f \"/usr/local/apache2/htdocs/index.html\" ]; then\n        echo \"\u2713 Application files present\"\n      else\n        echo \"\u2717 Application files missing\"\n        exit 1\n      fi\n  only:\n    - merge_requests\n    - main\n</code></pre> <p>Ce job utilise l'image construite et ex\u00e9cute des commandes de validation \u00e0 l'int\u00e9rieur.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#tests-de-securite","title":"Tests de s\u00e9curit\u00e9","text":"<p>Analyser l'image pour d\u00e9tecter les vuln\u00e9rabilit\u00e9s connues renforce la qualit\u00e9 :</p> YAML<pre><code>security_scan:\n  stage: test\n  image: aquasec/trivy:latest\n  services:\n    - docker:dind\n  script:\n    - trivy image --severity HIGH,CRITICAL $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n  allow_failure: true\n</code></pre> <p>Trivy analyse les couches de l'image et identifie les CVE (Common Vulnerabilities and Exposures) connus.[3]</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#push-conditionnel","title":"Push conditionnel","text":"<p>Le push ne s'effectue que si tous les tests ont r\u00e9ussi :</p> YAML<pre><code>push_image:\n  stage: push\n  image: docker:25.0\n  services:\n    - docker:25.0-dind\n  script:\n    - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $CI_REGISTRY\n    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n    - docker push $CI_REGISTRY_IMAGE:latest\n  only:\n    - main\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#tests-e2e-end-to-end","title":"\ud83d\udd17 Tests e2e (End-to-End)","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#definition-et-objectifs-des-tests-e2e","title":"D\u00e9finition et objectifs des tests e2e","text":"<p>Les tests end-to-end v\u00e9rifient que l'application compl\u00e8te, d\u00e9ploy\u00e9e dans son environnement d'ex\u00e9cution r\u00e9el, fonctionne correctement du point de vue de l'utilisateur final.[2] Contrairement aux tests unitaires qui testent des composants isol\u00e9s, les tests e2e valident les flux m\u00e9tier complets en conditions de production.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#architecture-des-tests-e2e-dans-une-pipeline","title":"Architecture des tests e2e dans une pipeline","text":"<p>Les tests e2e n\u00e9cessitent que l'application soit ex\u00e9cut\u00e9e et accessible. Dans un contexte CI/CD, cela implique :</p> <ol> <li>Construction de l'image de l'application</li> <li>D\u00e9ploiement de l'image dans un conteneur de test</li> <li>Ex\u00e9cution des tests e2e contre l'application en cours d'ex\u00e9cution</li> <li>Collecte des r\u00e9sultats et cleanup</li> </ol>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#configuration-dune-etape-de-tests-e2e","title":"Configuration d'une \u00e9tape de tests e2e","text":"YAML<pre><code>stages:\n  - build\n  - test\n  - e2e\n  - push\n\nbuild_image:\n  stage: build\n  image: docker:25.0\n  services:\n    - docker:25.0-dind\n  script:\n    - docker build -t app:$CI_COMMIT_SHA .\n    - docker tag app:$CI_COMMIT_SHA app:latest\n  artifacts:\n    reports:\n      dotenv: build.env\n  after_script:\n    - echo \"APP_IMAGE=app:$CI_COMMIT_SHA\" &gt;&gt; build.env\n\ne2e_tests:\n  stage: e2e\n  image: docker:25.0\n  services:\n    - docker:25.0-dind\n  dependencies:\n    - build_image\n  script:\n    - apk add --no-cache curl\n    - docker run -d --name test-app -p 8080:80 app:latest\n    - sleep 5\n    - |\n      for i in {1..10}; do\n        if curl -f http://test-app:8080/ &gt; /dev/null; then\n          echo \"\u2713 Application is responding\"\n          break\n        else\n          echo \"Waiting for application... ($i/10)\"\n          sleep 2\n        fi\n      done\n    - |\n      if curl -f http://test-app:8080/ | grep -q \"Hello World\"; then\n        echo \"\u2713 Content validation passed\"\n      else\n        echo \"\u2717 Content validation failed\"\n        exit 1\n      fi\n  after_script:\n    - docker stop test-app || true\n    - docker rm test-app || true\n  only:\n    - merge_requests\n    - main\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#tests-avec-outils-specialises","title":"Tests avec outils sp\u00e9cialis\u00e9s","text":"<p>Pour des applications plus complexes, utiliser des outils de test e2e d\u00e9di\u00e9s :</p> YAML<pre><code>e2e_with_cypress:\n  stage: e2e\n  image: cypress:latest\n  services:\n    - docker:25.0-dind\n  script:\n    - npm ci\n    - npm run build\n    - npx cypress run --headless --browser chrome\n  artifacts:\n    when: always\n    paths:\n      - cypress/screenshots\n      - cypress/videos\n  only:\n    - merge_requests\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#orchestration-avec-docker-compose","title":"Orchestration avec Docker Compose","text":"<p>Pour des applications multi-conteneurs, Docker Compose simplifie l'orchestration :</p> YAML<pre><code>e2e_docker_compose:\n  stage: e2e\n  image: docker:25.0\n  services:\n    - docker:25.0-dind\n  before_script:\n    - apk add --no-cache docker-compose\n  script:\n    - docker-compose up -d\n    - sleep 10\n    - docker-compose ps\n    - docker-compose exec -T app npm run e2e:test\n  after_script:\n    - docker-compose down -v\n  only:\n    - merge_requests\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#rapports-et-artefacts","title":"Rapports et artefacts","text":"<p>Collecter les r\u00e9sultats des tests pour analyse ult\u00e9rieure :</p> YAML<pre><code>e2e_tests:\n  stage: e2e\n  artifacts:\n    when: always\n    reports:\n      junit: test-results/e2e-results.xml\n    paths:\n      - test-results/\n      - screenshots/\n  only:\n    - merge_requests\n    - main\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#deploiement-avec-docker-compose","title":"\ud83d\udc33 D\u00e9ploiement avec Docker Compose","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#principes-du-deploiement-orchestre","title":"Principes du d\u00e9ploiement orchestr\u00e9","text":"<p>Docker Compose automatise le d\u00e9ploiement d'applications multi-conteneurs en d\u00e9finissant tous les services, volumes et r\u00e9seaux dans un fichier <code>docker-compose.yml</code> unique.[1] Cette approche s'int\u00e8gre naturellement dans les pipelines GitLab pour d\u00e9ployer les images construites vers des environnements de staging ou production.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#structure-dun-fichier-docker-composeyml","title":"Structure d'un fichier docker-compose.yml","text":"YAML<pre><code>version: '3.9'\n\nservices:\n  app:\n    image: $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n    container_name: app-container\n    ports:\n      - \"80:80\"\n    environment:\n      - ENVIRONMENT=production\n      - DATABASE_URL=postgresql://user:password@db:5432/appdb\n    depends_on:\n      - db\n    networks:\n      - app-network\n    restart: unless-stopped\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n\n  db:\n    image: postgres:15-alpine\n    container_name: app-db\n    environment:\n      - POSTGRES_DB=appdb\n      - POSTGRES_USER=user\n      - POSTGRES_PASSWORD=password\n    volumes:\n      - db-data:/var/lib/postgresql/data\n    networks:\n      - app-network\n    restart: unless-stopped\n\n  nginx:\n    image: nginx:alpine\n    container_name: app-nginx\n    ports:\n      - \"443:443\"\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf:ro\n      - ./ssl:/etc/nginx/ssl:ro\n    depends_on:\n      - app\n    networks:\n      - app-network\n    restart: unless-stopped\n\nvolumes:\n  db-data:\n\nnetworks:\n  app-network:\n    driver: bridge\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#integration-dans-la-pipeline-de-deploiement","title":"Int\u00e9gration dans la pipeline de d\u00e9ploiement","text":"YAML<pre><code>stages:\n  - build\n  - test\n  - push\n  - deploy_staging\n\ndeploy_staging:\n  stage: deploy_staging\n  image: docker:25.0\n  services:\n    - docker:25.0-dind\n  environment:\n    name: staging\n    url: https://staging.example.com\n  script:\n    - apk add --no-cache docker-compose openssh-client\n    - eval $(ssh-agent -s)\n    - echo \"$SSH_PRIVATE_KEY\" | tr -d '\\r' | ssh-add -\n    - mkdir -p ~/.ssh\n    - chmod 700 ~/.ssh\n    - ssh-keyscan -H staging-server.example.com &gt;&gt; ~/.ssh/known_hosts\n    - scp docker-compose.yml user@staging-server.example.com:/opt/app/\n    - scp .env user@staging-server.example.com:/opt/app/\n    - |\n      ssh user@staging-server.example.com &lt;&lt; 'EOF'\n      cd /opt/app\n      export CI_REGISTRY_IMAGE=$CI_REGISTRY_IMAGE\n      export CI_COMMIT_SHA=$CI_COMMIT_SHA\n      docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n      docker-compose pull\n      docker-compose up -d\n      EOF\n  only:\n    - main\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#gestion-des-configurations-et-secrets","title":"Gestion des configurations et secrets","text":"<p>Utiliser des fichiers <code>.env</code> pour stocker les variables sensibles, sans les commiter au r\u00e9f\u00e9rentiel :</p> Text Only<pre><code>POSTGRES_USER=appuser\nPOSTGRES_PASSWORD=securepassword123\nDATABASE_URL=postgresql://appuser:securepassword123@db:5432/appdb\nREDIS_URL=redis://redis:6379\nAPI_KEY=secret_api_key_here\nJWT_SECRET=jwt_secret_key_here\n</code></pre> <p>Dans GitLab, stocker ces valeurs en tant que variables prot\u00e9g\u00e9es dans Settings &gt; CI/CD &gt; Variables :</p> YAML<pre><code>deploy_staging:\n  script:\n    - |\n      cat &gt; .env &lt;&lt; EOF\n      POSTGRES_USER=$DB_USER\n      POSTGRES_PASSWORD=$DB_PASSWORD\n      DATABASE_URL=$DATABASE_URL\n      API_KEY=$API_KEY\n      JWT_SECRET=$JWT_SECRET\n      EOF\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#sante-et-monitoring-du-deploiement","title":"Sant\u00e9 et monitoring du d\u00e9ploiement","text":"<p>Impl\u00e9menter des v\u00e9rifications de sant\u00e9 pour assurer le bon fonctionnement apr\u00e8s d\u00e9ploiement :</p> YAML<pre><code>deploy_staging:\n  script:\n    # ... d\u00e9ploiement ...\n    - sleep 30\n    - |\n      for i in {1..20}; do\n        if curl -f https://staging.example.com/health &gt; /dev/null 2&gt;&amp;1; then\n          echo \"\u2713 Application is healthy\"\n          exit 0\n        else\n          echo \"Waiting for application health check... ($i/20)\"\n          sleep 5\n        fi\n      done\n      echo \"\u2717 Application health check failed\"\n      exit 1\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#rollback-en-cas-dechec","title":"Rollback en cas d'\u00e9chec","text":"<p>Pr\u00e9voir un m\u00e9canisme de rollback pour revenir \u00e0 la version pr\u00e9c\u00e9dente en cas de probl\u00e8me :</p> YAML<pre><code>deploy_staging:\n  script:\n    - |\n      ssh user@staging-server.example.com &lt;&lt; 'EOF'\n      cd /opt/app\n      cp docker-compose.yml docker-compose.yml.new\n      if ! docker-compose -f docker-compose.yml.new up -d; then\n        echo \"Deployment failed, rolling back...\"\n        rm docker-compose.yml.new\n        exit 1\n      fi\n      EOF\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#environnement-de-staging","title":"\ud83c\udf0d Environnement de staging","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#concept-et-importance-du-staging","title":"Concept et importance du staging","text":"<p>L'environnement de staging reproduit aussi fid\u00e8lement que possible l'environnement de production, permettant de valider les d\u00e9ploiements avant leur mise en ligne r\u00e9elle.[3] Cet environnement interm\u00e9diaire capture les bugs et probl\u00e8mes de configuration sans impacter les utilisateurs finaux.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#architecture-multi-environnements","title":"Architecture multi-environnements","text":"YAML<pre><code>stages:\n  - build\n  - test\n  - push\n  - deploy_staging\n  - approve_production\n  - deploy_production\n\nvariables:\n  REGISTRY_URL: $CI_REGISTRY\n  STAGING_SERVER: staging.example.com\n  PRODUCTION_SERVER: prod.example.com\n\nbuild_image:\n  stage: build\n  image: docker:25.0\n  services:\n    - docker:25.0-dind\n  script:\n    - docker build -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA .\n    - docker tag $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA $CI_REGISTRY_IMAGE:staging\n    - docker login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY\n    - docker push $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n\ndeploy_staging:\n  stage: deploy_staging\n  image: alpine:latest\n  environment:\n    name: staging\n    url: https://staging.example.com\n    deployment_tier: staging\n  script:\n    - apk add --no-cache openssh-client docker-cli\n    - eval $(ssh-agent -s)\n    - echo \"$STAGING_DEPLOY_KEY\" | ssh-add -\n    - mkdir -p ~/.ssh &amp;&amp; chmod 700 ~/.ssh\n    - ssh-keyscan $STAGING_SERVER &gt;&gt; ~/.ssh/known_hosts\n    - |\n      ssh deploy@$STAGING_SERVER &lt;&lt; 'DEPLOY'\n      cd /opt/app-staging\n      export IMAGE_TAG=$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n      docker-compose -f docker-compose.staging.yml pull\n      docker-compose -f docker-compose.staging.yml up -d\n      DEPLOY\n  only:\n    - develop\n    - merge_requests\n\napprove_production:\n  stage: approve_production\n  environment:\n    name: production\n  script:\n    - echo \"Ready for production deployment\"\n  when: manual\n  only:\n    - main\n\ndeploy_production:\n  stage: deploy_production\n  image: alpine:latest\n  environment:\n    name: production\n    url: https://example.com\n    deployment_tier: production\n  script:\n    - apk add --no-cache openssh-client docker-cli\n    - eval $(ssh-agent -s)\n    - echo \"$PRODUCTION_DEPLOY_KEY\" | ssh-add -\n    - mkdir -p ~/.ssh &amp;&amp; chmod 700 ~/.ssh\n    - ssh-keyscan $PRODUCTION_SERVER &gt;&gt; ~/.ssh/known_hosts\n    - |\n      ssh deploy@$PRODUCTION_SERVER &lt;&lt; 'DEPLOY'\n      cd /opt/app\n      export IMAGE_TAG=$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n      docker-compose -f docker-compose.prod.yml pull\n      docker-compose -f docker-compose.prod.yml up -d\n      DEPLOY\n  only:\n    - main\n  when: manual\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#fichiers-docker-compose-distincts-par-environnement","title":"Fichiers docker-compose distincts par environnement","text":"<p>Maintenir des fichiers <code>docker-compose</code> sp\u00e9cifiques permet d'adapter les ressources et configurations \u00e0 chaque environnement.</p> <p>docker-compose.staging.yml :</p> YAML<pre><code>version: '3.9'\n\nservices:\n  app:\n    image: $IMAGE_TAG\n    environment:\n      - NODE_ENV=staging\n      - LOG_LEVEL=debug\n      - DATABASE_URL=postgresql://staging_user:pass@db:5432/staging_db\n    ports:\n      - \"8080:3000\"\n    resources:\n      limits:\n        cpus: '1'\n        memory: 512M\n    restart: unless-stopped\n\n  db:\n    image: postgres:15-alpine\n    environment:\n      - POSTGRES_USER=staging_user\n      - POSTGRES_PASSWORD=pass\n      - POSTGRES_DB=staging_db\n    volumes:\n      - staging-db-data:/var/lib/postgresql/data\n    resources:\n      limits:\n        cpus: '0.5'\n        memory: 256M\n\nvolumes:\n  staging-db-data:\n</code></pre> <p>docker-compose.prod.yml :</p> YAML<pre><code>version: '3.9'\n\nservices:\n  app:\n    image: $IMAGE_TAG\n    environment:\n      - NODE_ENV=production\n      - LOG_LEVEL=warn\n      - DATABASE_URL=postgresql://$PROD_DB_USER:$PROD_DB_PASSWORD@db:5432/prod_db\n    ports:\n      - \"3000:3000\"\n    deploy:\n      replicas: 3\n      resources:\n        limits:\n          cpus: '2'\n          memory: 2G\n    restart: always\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:3000/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 5\n\n  db:\n    image: postgres:15-alpine\n    environment:\n      - POSTGRES_USER=$PROD_DB_USER\n      - POSTGRES_PASSWORD=$PROD_DB_PASSWORD\n      - POSTGRES_DB=prod_db\n    volumes:\n      - prod-db-data:/var/lib/postgresql/data\n    deploy:\n      resources:\n        limits:\n          cpus: '1'\n          memory: 1G\n\n  nginx:\n    image: nginx:alpine\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx.conf:/etc/nginx/nginx.conf:ro\n      - ./ssl:/etc/nginx/ssl:ro\n    depends_on:\n      - app\n    restart: always\n\nvolumes:\n  prod-db-data:\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#gestion-des-donnees-et-migrations","title":"Gestion des donn\u00e9es et migrations","text":"<p>Impl\u00e9menter des migrations de base de donn\u00e9es automatis\u00e9es lors du d\u00e9ploiement :</p> YAML<pre><code>deploy_staging:\n  script:\n    - |\n      ssh deploy@$STAGING_SERVER &lt;&lt; 'DEPLOY'\n      cd /opt/app-staging\n      # D\u00e9marrer les services\n      docker-compose -f docker-compose.staging.yml up -d\n      # Attendre que la base soit pr\u00eate\n      sleep 5\n      # Ex\u00e9cuter les migrations\n      docker-compose -f docker-compose.staging.yml exec -T app npm run migrate:run\n      # Ex\u00e9cuter les seeds si n\u00e9cessaire\n      docker-compose -f docker-compose.staging.yml exec -T app npm run seed\n      DEPLOY\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#monitoring-et-logging-du-staging","title":"Monitoring et logging du staging","text":"<p>Configurer la collecte des logs pour surveillance du staging :</p> YAML<pre><code>version: '3.9'\n\nservices:\n  app:\n    image: $IMAGE_TAG\n    logging:\n      driver: json-file\n      options:\n        max-size: \"10m\"\n        max-file: \"3\"\n        labels: \"service=app,environment=staging\"\n    environment:\n      - LOG_FORMAT=json\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#tests-dacceptation-utilisateur-en-staging","title":"Tests d'acceptation utilisateur en staging","text":"<p>Avant production, valider le comportement m\u00e9tier en staging :</p> YAML<pre><code>test_staging:\n  stage: test\n  image: node:18-alpine\n  environment:\n    name: staging\n  script:\n    - npm ci\n    - npm run test:acceptance -- --base-url https://staging.example.com\n  only:\n    - merge_requests\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#promotion-vers-production","title":"Promotion vers production","text":"<p>La promotion du code de staging vers production doit \u00eatre d\u00e9lib\u00e9r\u00e9e et contr\u00f4l\u00e9e :</p> YAML<pre><code>approve_production:\n  stage: approve_production\n  script:\n    - |\n      echo \"Staging deployment passed all tests and validations.\"\n      echo \"Ready for manual promotion to production.\"\n  when: manual\n  only:\n    - main\n\ndeploy_production:\n  stage: deploy_production\n  script:\n    - |\n      ssh deploy@$PRODUCTION_SERVER &lt;&lt; 'DEPLOY'\n      cd /opt/app\n      export IMAGE_TAG=$CI_REGISTRY_IMAGE:$CI_COMMIT_SHA\n      docker-compose -f docker-compose.prod.yml pull\n      docker-compose -f docker-compose.prod.yml up -d --scale app=3\n      DEPLOY\n  when: manual\n  only:\n    - main\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#comparaison-des-trois-environnements","title":"Comparaison des trois environnements","text":"Aspect D\u00e9veloppement Staging Production Acc\u00e8s Local/\u00c9quipe \u00c9quipe interne Utilisateurs finaux Ressources Minimales Mod\u00e9r\u00e9es Maximales Donn\u00e9es Factices Repr\u00e9sentatives R\u00e9elles D\u00e9ploiements Fr\u00e9quents Occasionnels Rares et contr\u00f4l\u00e9s Rollback Instantan\u00e9 Rapide Planifi\u00e9 SLA Aucun 99% 99.99%"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#synthese-du-parcours-dapprentissage","title":"\ud83c\udf93 Synth\u00e8se du parcours d'apprentissage","text":"<p>Le parcours propos\u00e9 progresse du simple vers le complexe, en commen\u00e7ant par les fondamentaux de GitLab CI/CD et Docker, puis en construisant progressivement une infrastructure robuste de d\u00e9ploiement multi-environnements.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#phase-1-fondamentaux","title":"Phase 1 : Fondamentaux","text":"<p>La compr\u00e9hension initiale porte sur la fa\u00e7on dont GitLab CI/CD et Docker interagissent, en particulier le concept de Docker-in-Docker et l'utilisation du GitLab Container Registry. Cette phase \u00e9tablit les bases n\u00e9cessaires pour toutes les \u00e9tapes ult\u00e9rieures.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#phase-2-automatisation","title":"Phase 2 : Automatisation","text":"<p>La cr\u00e9ation et la construction automatis\u00e9es des images Docker au sein de pipelines repr\u00e9sentent le premier pas vers une v\u00e9ritable int\u00e9gration continue. Cette phase transforme les processus manuels en flux automatis\u00e9s.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#phase-3-assurance-qualite","title":"Phase 3 : Assurance qualit\u00e9","text":"<p>L'introduction de tests vari\u00e9s\u2014tests fonctionnels, tests de s\u00e9curit\u00e9, tests e2e\u2014\u00e9tablit un filet de s\u00e9curit\u00e9 garantissant que seules les images valid\u00e9es sont d\u00e9ploy\u00e9es.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#phase-4-orchestration-et-deploiement","title":"Phase 4 : Orchestration et d\u00e9ploiement","text":"<p>Docker Compose offre un m\u00e9canisme pour orchestrer les d\u00e9ploiements multi-conteneurs, tandis que l'int\u00e9gration dans les pipelines automatise les d\u00e9ploiements r\u00e9currents.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap06/#phase-5-gestion-multi-environnements","title":"Phase 5 : Gestion multi-environnements","text":"<p>La diff\u00e9renciation entre staging et production, avec approbation manuelle des d\u00e9ploiements de production, \u00e9tablit une gouvernance appropri\u00e9e et r\u00e9duit les risques.</p> <p>Cette progression structur\u00e9e permet de ma\u00eetriser progressivement chaque concept et de construire une compr\u00e9hension globale solide du pipeline CI/CD avec Docker dans GitLab.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/","title":"Citations","text":"<ul> <li>https://tutoriels.lws.fr/vps/configurer-une-ci-cd-avec-gitlab-auto-heberge-lws</li> <li>https://docs.gitlab.com/ci/runners/configure_runners/</li> <li>https://cours.brosseau.ovh/tp/ci/gitlab/runner.html</li> <li>https://www.misesurorbite.fr/aide/aide-gitlab/configurer-un-runner-dans-votre-gitlab/</li> <li>https://blog.stephane-robert.info/docs/services/devops/gitlab/runner/</li> <li>https://docs.gitlab.com/runner/configuration/</li> <li>https://www.youtube.com/watch?v=kMbXxoLriwo</li> <li>https://rdr-it.com/gitlab-ci-cd-comment-installer-et-utiliser-un-runner/</li> <li>https://docs.gitlab.com/runner/</li> <li>https://blent.ai/blog/a/gitlab-cicd-tout-savoir</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 286</li> <li>completion_tokens: 7058</li> <li>total_tokens: 7344</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.106, 'request_cost': 0.006, 'total_cost': 0.113}</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#content","title":"Content","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#chapitre-7-configurer-ses-runners-avec-gitlab-cicd","title":"Chapitre 7 : Configurer ses runners avec Gitlab CI/CD","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#introduction-aux-runners-gitlab","title":"Introduction aux Runners GitLab","text":"<p>Un runner GitLab est un agent logiciel qui ex\u00e9cute les jobs d\u00e9finis dans le fichier <code>.gitlab-ci.yml</code>[1][9]. Il s'agit d'un composant essentiel de l'infrastructure CI/CD, permettant d'automatiser les t\u00e2ches de tests, de compilation et de d\u00e9ploiement du code. Lorsqu'un d\u00e9veloppeur pousse du code sur GitLab, les pipelines CI/CD se d\u00e9clenchent automatiquement et les runners ex\u00e9cutent les jobs correspondants[9].</p> <p>Les runners sont au c\u0153ur de l'automatisation, car ils transforment les d\u00e9finitions de pipeline en actions concr\u00e8tes. Sans runner, les pipelines CI/CD ne pourraient pas fonctionner. La configuration des runners d\u00e9termine \u00e9galement la flexibilit\u00e9 et les capacit\u00e9s du syst\u00e8me CI/CD global.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#1-installer-gitlab-runner","title":"1. Installer GitLab Runner","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#prerequis-et-preparation","title":"Pr\u00e9requis et pr\u00e9paration","text":"<p>Avant d'installer GitLab Runner, il est n\u00e9cessaire de disposer de plusieurs \u00e9l\u00e9ments[1] :</p> <ul> <li>Une connexion Internet stable pour que le runner puisse communiquer avec l'instance GitLab</li> <li>Un projet actif sur GitLab (priv\u00e9 ou public)</li> <li>Les droits Maintainer sur le projet pour pouvoir configurer la CI/CD</li> <li>Des connaissances basiques en YAML, Bash ou Docker pour personnaliser les pipelines</li> <li>Une machine ou un serveur sur lequel installer le runner (VPS, machine locale, etc.)</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#processus-dinstallation","title":"Processus d'installation","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#etape-1-connexion-au-serveur","title":"\u00c9tape 1 : Connexion au serveur","text":"<p>La premi\u00e8re \u00e9tape consiste \u00e0 se connecter au serveur ou VPS o\u00f9 sera install\u00e9 le runner[1] :</p> Bash<pre><code>ssh root@votre-ip\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#etape-2-telechargement-et-installation-du-gitlab-runner","title":"\u00c9tape 2 : T\u00e9l\u00e9chargement et installation du GitLab Runner","text":"<p>Pour installer GitLab Runner sur une machine Debian/Ubuntu, les commandes suivantes doivent \u00eatre ex\u00e9cut\u00e9es[1] :</p> Bash<pre><code>curl -L https://packages.gitlab.com/install/repositories/runner/gitlab-runner/script.deb.sh | bash\napt install gitlab-runner\n</code></pre> <p>Ces commandes t\u00e9l\u00e9chargent le script d'installation officiel depuis les d\u00e9p\u00f4ts GitLab et installe le package <code>gitlab-runner</code> avec toutes ses d\u00e9pendances.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#enregistrement-du-runner","title":"Enregistrement du runner","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#lancement-de-lenregistrement","title":"Lancement de l'enregistrement","text":"<p>Une fois GitLab Runner install\u00e9, il faut l'enregistrer aupr\u00e8s de l'instance GitLab[1] :</p> Bash<pre><code>gitlab-runner register\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#questions-interactives-lors-de-lenregistrement","title":"Questions interactives lors de l'enregistrement","text":"<p>Le processus d'enregistrement pose plusieurs questions cruciales[1] :</p> Question Description Exemple URL de GitLab L'adresse de l'instance GitLab <code>https://gitlab.example.com</code> Jeton du runner Disponible dans GitLab &gt; Admin &gt; Runners Token fourni par GitLab Description Nom ou description du runner <code>Docker Runner Production</code> Tags \u00c9tiquettes pour identifier le runner <code>docker</code>, <code>production</code>, <code>python</code> Type d'ex\u00e9cution Executor \u00e0 utiliser <code>docker</code> ou <code>shell</code> Image par d\u00e9faut Image Docker si executor Docker est choisi <code>python:3.10</code>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#obtention-du-jeton-du-runner","title":"Obtention du jeton du runner","text":"<p>Le jeton d'enregistrement est disponible dans l'interface d'administration de GitLab[1][4] :</p> <ul> <li>Se connecter en tant qu'administrateur sur GitLab</li> <li>Acc\u00e9der \u00e0 la section Administration</li> <li>Naviguer vers CI/CD \u203a Runners</li> <li>Cliquer sur \"Nouvel ex\u00e9cuteur d'instance\" ou \"Create instance runner\"</li> <li>Le jeton appara\u00eet dans la page de cr\u00e9ation</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#verification-post-installation","title":"V\u00e9rification post-installation","text":"<p>Apr\u00e8s l'installation et la configuration, il est important de v\u00e9rifier que le runner est correctement enregistr\u00e9 et op\u00e9rationnel[5]. Cette v\u00e9rification s'effectue en acc\u00e9dant \u00e0 la section \"CI/CD\" du projet GitLab, puis en consultant la liste des runners disponibles. Si tout est correct, le runner nouvellement enregistr\u00e9 devrait appara\u00eetre dans cette liste, marqu\u00e9 comme \u00e9tant pr\u00eat \u00e0 ex\u00e9cuter les jobs[5].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#configuration-avancee","title":"Configuration avanc\u00e9e","text":"<p>GitLab Runner peut \u00eatre configur\u00e9 de mani\u00e8re tr\u00e8s d\u00e9taill\u00e9e gr\u00e2ce au fichier <code>config.toml</code>[6]. Ce fichier de configuration permet de personnaliser[6] :</p> <ul> <li>Les param\u00e8tres GPU (Graphics Processing Units) pour l'ex\u00e9cution de jobs</li> <li>Le syst\u00e8me d'initialisation (bas\u00e9 sur le syst\u00e8me d'exploitation)</li> <li>Les shells support\u00e9s pour g\u00e9n\u00e9rer les scripts de compilation</li> <li>Les consid\u00e9rations de s\u00e9curit\u00e9 lors de l'ex\u00e9cution des jobs</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#2-creation-dun-serveur-vps","title":"2. Cr\u00e9ation d'un serveur VPS","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#quest-ce-quun-vps","title":"Qu'est-ce qu'un VPS ?","text":"<p>Un VPS (Virtual Private Server) est un serveur virtuel d\u00e9di\u00e9 qui offre les ressources et l'isolation n\u00e9cessaires pour ex\u00e9cuter GitLab Runner de mani\u00e8re fiable[1]. Contrairement \u00e0 une machine locale, un VPS disponible 24/7 assure que les pipelines CI/CD s'ex\u00e9cutent continuellement sans interruption.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#deploiement-sur-un-vps","title":"D\u00e9ploiement sur un VPS","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#avantages-du-vps-pour-gitlab-runner","title":"Avantages du VPS pour GitLab Runner","text":"<ul> <li>Disponibilit\u00e9 continue : Le VPS reste actif 24/7, contrairement \u00e0 une machine locale</li> <li>Ressources d\u00e9di\u00e9es : Les ressources sont r\u00e9serv\u00e9es \u00e0 l'ex\u00e9cution des jobs CI/CD</li> <li>Isolation de l'environnement : Le VPS ne partage pas les ressources avec d'autres services</li> <li>Scalabilit\u00e9 : Possibilit\u00e9 d'ajouter plusieurs runners sur diff\u00e9rents VPS</li> <li>Performance stable : Les performances ne sont pas affect\u00e9es par d'autres processus</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#installation-sur-un-vps","title":"Installation sur un VPS","text":"<p>L'installation sur un VPS suit exactement le m\u00eame processus qu'une machine locale. Les \u00e9tapes sont identiques[1] :</p> <ol> <li>Connexion SSH au VPS</li> <li>Installation du package GitLab Runner</li> <li>Enregistrement du runner aupr\u00e8s de GitLab</li> <li>V\u00e9rification du statut</li> </ol>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#considerations-de-securite","title":"Consid\u00e9rations de s\u00e9curit\u00e9","text":"<p>Lors du d\u00e9ploiement sur un VPS, plusieurs aspects s\u00e9curitaires doivent \u00eatre pris en compte[1][6] :</p> <ul> <li>Pare-feu : Configurer les r\u00e8gles de pare-feu pour autoriser la communication GitLab \u2194 Runner</li> <li>Certificats SSL : Utiliser HTTPS pour la communication s\u00e9curis\u00e9e</li> <li>Acc\u00e8s SSH : Limiter l'acc\u00e8s SSH \u00e0 des adresses IP sp\u00e9cifiques</li> <li>Permissions : Assurer que GitLab Runner s'ex\u00e9cute avec les permissions minimales n\u00e9cessaires</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#configuration-dun-runner-docker-sur-vps","title":"Configuration d'un runner Docker sur VPS","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#installation-de-docker","title":"Installation de Docker","text":"<p>Pour utiliser un executor Docker sur le VPS, Docker doit d'abord \u00eatre install\u00e9 et actif[1] :</p> Bash<pre><code># Installation de Docker\ncurl -fsSL https://get.docker.com -o get-docker.sh\nsh get-docker.sh\n\n# D\u00e9marrage du service Docker\nsystemctl start docker\nsystemctl enable docker\n\n# V\u00e9rification de l'installation\ndocker --version\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#configuration-du-runner-avec-executor-docker","title":"Configuration du runner avec executor Docker","text":"<p>Une fois Docker install\u00e9, lors de l'enregistrement du runner, s\u00e9lectionner <code>docker</code> comme type d'ex\u00e9cution[1] :</p> Bash<pre><code>gitlab-runner register\n# ...r\u00e9pondre aux questions...\n# Type d'ex\u00e9cution : docker\n# Image par d\u00e9faut : python:3.10  (ou l'image appropri\u00e9e)\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#exemple-de-runner-docker-configure","title":"Exemple de runner Docker configur\u00e9","text":"<p>Apr\u00e8s l'enregistrement, le fichier <code>/etc/gitlab-runner/config.toml</code> contient la configuration du runner[6] :</p> TOML<pre><code>[[runners]]\n  name = \"Docker Runner VPS\"\n  url = \"https://gitlab.example.com\"\n  token = \"runner_token_xxxxx\"\n  executor = \"docker\"\n\n  [runners.docker]\n    image = \"python:3.10\"\n    privileged = false\n    disable_cache = false\n    volumes = [\"/cache\"]\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#3-introduction-aux-runners-auto-geres","title":"3. Introduction aux runners auto-g\u00e9r\u00e9s","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#concept-des-runners-auto-geres","title":"Concept des runners auto-g\u00e9r\u00e9s","text":"<p>Les runners auto-g\u00e9r\u00e9s (ou self-hosted runners) sont des runners d\u00e9ploy\u00e9s et g\u00e9r\u00e9s par l'organisation plut\u00f4t que par GitLab[1]. Ils offrent une flexibilit\u00e9 compl\u00e8te concernant l'environnement d'ex\u00e9cution, les ressources mat\u00e9rielles et les configurations logicielles.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#differences-avec-les-runners-partages","title":"Diff\u00e9rences avec les runners partag\u00e9s","text":"Aspect Runners partag\u00e9s Runners auto-g\u00e9r\u00e9s Gestion GitLab g\u00e8re l'infrastructure L'organisation g\u00e8re l'infrastructure Disponibilit\u00e9 Partag\u00e9s entre plusieurs utilisateurs D\u00e9di\u00e9s \u00e0 des projets sp\u00e9cifiques Co\u00fbts Gratuit ou payant selon le plan Co\u00fbts de serveur/mat\u00e9riel \u00e0 supporter Contr\u00f4le Limit\u00e9 aux configurations GitLab Contr\u00f4le total de l'environnement Performance Variable selon la charge partag\u00e9e Stable et pr\u00e9visible Personnalisation Peu flexible Tr\u00e8s flexible"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#architecture-des-runners-auto-geres","title":"Architecture des runners auto-g\u00e9r\u00e9s","text":"<p>Un runner auto-g\u00e9r\u00e9 communique directement avec l'instance GitLab via une connexion HTTP(S). Voici le flux d'ex\u00e9cution typique[1] :</p> Text Only<pre><code>GitLab Instance\n    \u2193\nCr\u00e9e un job dans le pipeline\n    \u2193\nEnvoie la d\u00e9finition du job au runner\n    \u2193\nRunner re\u00e7oit le job\n    \u2193\nRunner ex\u00e9cute les instructions dans l'executor appropri\u00e9\n    \u2193\nRunner renvoie les r\u00e9sultats et logs \u00e0 GitLab\n    \u2193\nGitLab affiche les r\u00e9sultats dans l'interface\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#enregistrement-dun-runner-auto-gere","title":"Enregistrement d'un runner auto-g\u00e9r\u00e9","text":"<p>Le processus d'enregistrement \u00e9tablit la relation de confiance entre GitLab et le runner[1] :</p> Bash<pre><code>gitlab-runner register \\\n  --url https://gitlab.example.com \\\n  --registration-token glrt_xxxxxxxxxxxxx \\\n  --executor docker \\\n  --description \"Mon runner auto-g\u00e9r\u00e9\" \\\n  --tag-list \"docker,production\" \\\n  --docker-image python:3.10\n</code></pre> <p>Chaque param\u00e8tre a une signification pr\u00e9cise[1] :</p> <ul> <li><code>--url</code> : L'adresse de l'instance GitLab</li> <li><code>--registration-token</code> : Le jeton d'enregistrement obtenu depuis GitLab</li> <li><code>--executor</code> : Le type d'executor (docker, shell, kubernetes, etc.)</li> <li><code>--description</code> : Une description identifiable du runner</li> <li><code>--tag-list</code> : Les tags permettant de s\u00e9lectionner ce runner</li> <li><code>--docker-image</code> : L'image Docker par d\u00e9faut (si executor Docker)</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#gestion-du-cycle-de-vie-des-runners-auto-geres","title":"Gestion du cycle de vie des runners auto-g\u00e9r\u00e9s","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#demarrage-du-runner","title":"D\u00e9marrage du runner","text":"<p>Une fois enregistr\u00e9, le runner doit \u00eatre d\u00e9marr\u00e9 comme service[1] :</p> Bash<pre><code># D\u00e9marrage du runner\ngitlab-runner start\n\n# V\u00e9rification du statut\ngitlab-runner status\n\n# Red\u00e9marrage du runner\ngitlab-runner restart\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#arret-et-suppression","title":"Arr\u00eat et suppression","text":"<p>Pour arr\u00eater ou supprimer un runner[1] :</p> Bash<pre><code># Arr\u00eat du runner\ngitlab-runner stop\n\n# Unregister (d\u00e9senregistrement) du runner\ngitlab-runner unregister --name \"Mon runner auto-g\u00e9r\u00e9\"\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#avantages-des-runners-auto-geres","title":"Avantages des runners auto-g\u00e9r\u00e9s","text":"<ul> <li>Flexibilit\u00e9 maximale : Installation de n'importe quelle d\u00e9pendance syst\u00e8me requise</li> <li>Confidentialit\u00e9 : Les donn\u00e9es sensibles restent dans l'infrastructure interne</li> <li>Performance optimis\u00e9e : Configuration adapt\u00e9e aux besoins sp\u00e9cifiques du projet</li> <li>Int\u00e9gration personnalis\u00e9e : Int\u00e9gration avec des syst\u00e8mes internes propri\u00e9taires</li> <li>Co\u00fbts ma\u00eetris\u00e9s : Infrastructure existante r\u00e9utilis\u00e9e</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#4-utilisation-des-tags","title":"4. Utilisation des tags","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#concept-des-tags-dans-gitlab-cicd","title":"Concept des tags dans GitLab CI/CD","text":"<p>Les tags constituent un m\u00e9canisme puissant pour contr\u00f4ler quels runners ex\u00e9cutent quels jobs[2]. Un tag est une \u00e9tiquette qui identifie les capacit\u00e9s ou la destination d'un runner. Les jobs demandent des tags sp\u00e9cifiques, et seuls les runners poss\u00e9dant ces tags peuvent ex\u00e9cuter le job[2].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#difference-entre-tags-git-et-tags-cicd","title":"Diff\u00e9rence entre tags Git et tags CI/CD","text":"<p>Il est important de ne pas confondre les deux types de tags[2] :</p> Type Utilisation Exemple Tags Git Marquent des commits sp\u00e9cifiques <code>v1.0.0</code>, <code>release-2023</code> Tags CI/CD S\u00e9lectionnent les runners pour les jobs <code>docker</code>, <code>production</code>, <code>gpu</code> <p>Les tags GitLab CI/CD sont associ\u00e9s \u00e0 des runners, tandis que les tags Git sont associ\u00e9s \u00e0 des commits.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#attribution-de-tags-aux-runners","title":"Attribution de tags aux runners","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#lors-de-lenregistrement","title":"Lors de l'enregistrement","text":"<p>Les tags peuvent \u00eatre assign\u00e9s lors de l'enregistrement du runner[1] :</p> Bash<pre><code>gitlab-runner register \\\n  --url https://gitlab.example.com \\\n  --registration-token glrt_xxxxxxxxxxxxx \\\n  --executor docker \\\n  --tag-list \"docker,python,backend,production\"\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#via-linterface-dadministration","title":"Via l'interface d'administration","text":"<p>Pour modifier les tags d'un runner existant, acc\u00e9der \u00e0 l'interface d'administration[2] :</p> <ul> <li>Acc\u00e9der \u00e0 Admin (bas de la barre lat\u00e9rale gauche)</li> <li>S\u00e9lectionner CI/CD \u203a Runners</li> <li>Cliquer sur le bouton Edit (\u270e) \u00e0 droite du runner</li> <li>Modifier le champ des tags</li> <li>Cliquer sur Save changes</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#utilisation-des-tags-dans-les-pipelines","title":"Utilisation des tags dans les pipelines","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#specification-des-tags-dans-le-fichier-gitlab-ciyml","title":"Sp\u00e9cification des tags dans le fichier <code>.gitlab-ci.yml</code>","text":"<p>Les jobs d\u00e9clarent les tags requis pour leur ex\u00e9cution[2] :</p> YAML<pre><code>stages:\n  - test\n  - build\n  - deploy\n\n# Job s'ex\u00e9cutant sur n'importe quel runner avec le tag \"docker\"\ntest_python:\n  stage: test\n  tags:\n    - docker\n    - python\n  script:\n    - python -m pytest tests/\n    - python -m coverage report\n\n# Job s'ex\u00e9cutant sur un runner \"production\"\ndeploy_production:\n  stage: deploy\n  tags:\n    - production\n    - high-performance\n  script:\n    - ./deploy.sh production\n  only:\n    - main\n\n# Job s'ex\u00e9cutant sur un runner avec GPU\nml_training:\n  stage: build\n  tags:\n    - gpu\n    - tensorflow\n  script:\n    - python train_model.py --gpu\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#cas-dusage-des-tags","title":"Cas d'usage des tags","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#1-separation-par-environnement","title":"1. S\u00e9paration par environnement","text":"<p>Les tags permettent de s\u00e9parer les ex\u00e9cutions selon l'environnement[2] :</p> YAML<pre><code>deploy_staging:\n  stage: deploy\n  tags:\n    - staging\n  script:\n    - ./deploy.sh staging\n  only:\n    - develop\n\ndeploy_production:\n  stage: deploy\n  tags:\n    - production\n  script:\n    - ./deploy.sh production\n  only:\n    - main\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#2-separation-par-technologies","title":"2. S\u00e9paration par technologies","text":"<p>Les runners peuvent \u00eatre tagu\u00e9s selon les technologies qu'ils supportent[2] :</p> YAML<pre><code>test_backend:\n  stage: test\n  tags:\n    - python\n    - docker\n  script:\n    - pip install -r requirements.txt\n    - pytest tests/\n\ntest_frontend:\n  stage: test\n  tags:\n    - nodejs\n    - docker\n  script:\n    - npm install\n    - npm run test\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#3-selection-par-performance","title":"3. S\u00e9lection par performance","text":"<p>Les tags permettent de diriger les jobs vers des runners appropri\u00e9s[2] :</p> YAML<pre><code>quick_test:\n  stage: test\n  tags:\n    - docker\n    - standard\n  script:\n    - pytest tests/ -k \"not slow\"\n\nfull_test:\n  stage: test\n  tags:\n    - docker\n    - high-performance\n  script:\n    - pytest tests/\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#variables-cicd-et-selection-dynamique-de-runners","title":"Variables CI/CD et s\u00e9lection dynamique de runners","text":"<p>GitLab CI/CD permet d'utiliser des variables pour une s\u00e9lection dynamique de runners[2] :</p> YAML<pre><code>variables:\n  KUBERNETES_RUNNER: kubernetes\n  DOCKER_RUNNER: docker\n\njob:\n  tags:\n    - $DOCKER_RUNNER\n    - $KUBERNETES_RUNNER\n  script:\n    - echo \"Ex\u00e9cution sur un runner s\u00e9lectionn\u00e9 dynamiquement\"\n</code></pre> <p>Cette approche offre une flexibilit\u00e9 accrue lors de la configuration de pipelines complexes.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#runners-proteges-et-tags","title":"Runners prot\u00e9g\u00e9s et tags","text":"<p>Pour renforcer la s\u00e9curit\u00e9, un runner peut \u00eatre marqu\u00e9 comme prot\u00e9g\u00e9[2]. Les runners prot\u00e9g\u00e9s ne peuvent ex\u00e9cuter que les jobs des branches prot\u00e9g\u00e9es :</p> <ul> <li>Acc\u00e9der \u00e0 Admin \u203a CI/CD \u203a Runners</li> <li>Cliquer sur Edit \u00e0 droite du runner</li> <li>Cocher la case Protected</li> <li>Cliquer sur Save changes</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#5-construire-des-images-dans-lexecuteur-docker","title":"5. Construire des images dans l'ex\u00e9cuteur Docker","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#comprendre-lexecuteur-docker","title":"Comprendre l'ex\u00e9cuteur Docker","text":"<p>L'ex\u00e9cuteur Docker est l'un des types d'executors les plus populaires[1]. Il utilise Docker pour cr\u00e9er un conteneur temporaire pour chaque job, dans lequel les scripts sont ex\u00e9cut\u00e9s. Cette approche offre une isolation compl\u00e8te et une reproductibilit\u00e9 garantie.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#avantages-de-lexecuteur-docker","title":"Avantages de l'ex\u00e9cuteur Docker","text":"<ul> <li>Isolation compl\u00e8te : Chaque job s'ex\u00e9cute dans un conteneur distinct</li> <li>Reproductibilit\u00e9 : Les m\u00eames images produisent les m\u00eames r\u00e9sultats</li> <li>D\u00e9pendances ma\u00eetris\u00e9es : Les d\u00e9pendances sont empaquet\u00e9es dans l'image</li> <li>Scalabilit\u00e9 : Plusieurs conteneurs peuvent s'ex\u00e9cuter en parall\u00e8le</li> <li>Flexibilit\u00e9 : Support de toute image Docker disponible</li> </ul>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#configuration-de-docker-pour-gitlab-runner","title":"Configuration de Docker pour GitLab Runner","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#installation-et-initialisation","title":"Installation et initialisation","text":"<p>Pour utiliser l'ex\u00e9cuteur Docker, il doit \u00eatre install\u00e9 et le runner enregistr\u00e9 avec l'executor Docker[1] :</p> Bash<pre><code># Docker doit \u00eatre install\u00e9 et actif\ndocker --version\n\n# Enregistrement du runner avec executor Docker\ngitlab-runner register \\\n  --url https://gitlab.example.com \\\n  --registration-token glrt_xxxxxxxxxxxxx \\\n  --executor docker \\\n  --docker-image python:3.10\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#configuration-avancee-du-runner-docker","title":"Configuration avanc\u00e9e du runner Docker","text":"<p>Le fichier <code>/etc/gitlab-runner/config.toml</code> permet de configurer Docker en d\u00e9tail[6] :</p> TOML<pre><code>[[runners]]\n  name = \"Docker Runner Avanc\u00e9\"\n  url = \"https://gitlab.example.com\"\n  token = \"runner_token_xxxxx\"\n  executor = \"docker\"\n\n  [runners.docker]\n    image = \"python:3.10\"\n    privileged = true  # Permet l'utilisation de Docker-in-Docker\n    disable_cache = false\n    volumes = [\"/cache\", \"/var/run/docker.sock:/var/run/docker.sock\"]\n    allowed_images = [\"python:*\", \"nodejs:*\", \"golang:*\"]\n    dns = [\"8.8.8.8\"]\n    network_mode = \"bridge\"\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#creation-dimages-docker-dans-les-pipelines","title":"Cr\u00e9ation d'images Docker dans les pipelines","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#pipeline-simple-de-construction-dimage-docker","title":"Pipeline simple de construction d'image Docker","text":"<p>Un pipeline classique pour construire une image Docker[1] :</p> YAML<pre><code>stages:\n  - build\n  - test\n  - push\n\nvariables:\n  DOCKER_IMAGE_NAME: myapp\n  DOCKER_REGISTRY: docker.io\n  DOCKER_IMAGE_TAG: $CI_COMMIT_SHA\n\nbuild_docker_image:\n  stage: build\n  tags:\n    - docker\n  image: docker:latest\n  services:\n    - docker:dind\n  script:\n    - docker build -t $DOCKER_IMAGE_NAME:$DOCKER_IMAGE_TAG .\n    - docker save $DOCKER_IMAGE_NAME:$DOCKER_IMAGE_TAG &gt; image.tar\n  artifacts:\n    paths:\n      - image.tar\n    expire_in: 1 hour\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#docker-in-docker-dind","title":"Docker-in-Docker (DinD)","text":"<p>Pour construire des images Docker \u00e0 l'int\u00e9rieur de jobs GitLab CI/CD, le mode Docker-in-Docker (DinD) est utilis\u00e9[1]. Cela n\u00e9cessite l'acc\u00e8s \u00e0 la socket Docker :</p> YAML<pre><code>build_and_push_image:\n  stage: build\n  tags:\n    - docker\n  image: docker:latest\n  services:\n    - docker:dind\n  before_script:\n    - echo $CI_REGISTRY_PASSWORD | docker login -u $CI_REGISTRY_USER --password-stdin $CI_REGISTRY\n  script:\n    - docker build -t $CI_REGISTRY_IMAGE:latest .\n    - docker push $CI_REGISTRY_IMAGE:latest\n  after_script:\n    - docker logout $CI_REGISTRY\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#creation-dun-dockerfile-optimise","title":"Cr\u00e9ation d'un Dockerfile optimis\u00e9","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#structure-de-base","title":"Structure de base","text":"<p>Un Dockerfile pour un projet Python typique[1] :</p> Docker<pre><code># Stage 1 : Construction\nFROM python:3.10-slim as builder\n\nWORKDIR /build\n\nCOPY requirements.txt .\nRUN pip install --user --no-cache-dir -r requirements.txt\n\n# Stage 2 : Runtime\nFROM python:3.10-slim\n\nWORKDIR /app\n\n# Copier les d\u00e9pendances du stage pr\u00e9c\u00e9dent\nCOPY --from=builder /root/.local /root/.local\n\n# Copier le code source\nCOPY . .\n\n# D\u00e9finir les variables d'environnement\nENV PATH=/root/.local/bin:$PATH \\\n    PYTHONUNBUFFERED=1\n\n# Commande par d\u00e9faut\nCMD [\"python\", \"app.py\"]\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#dockerfile-multistage","title":"Dockerfile multistage","text":"<p>Pour r\u00e9duire la taille des images, utiliser les builds multistages[1] :</p> Docker<pre><code># Stage 1 : Construction et tests\nFROM python:3.10 as builder\n\nWORKDIR /build\nCOPY requirements-dev.txt .\nRUN pip install -r requirements-dev.txt\n\nCOPY . .\nRUN pytest tests/\nRUN pylint app/\n\n# Stage 2 : Runtime uniquement\nFROM python:3.10-alpine\n\nWORKDIR /app\nCOPY --from=builder /build /app\n\nRUN pip install --no-cache-dir gunicorn\n\nCMD [\"gunicorn\", \"--bind\", \"0.0.0.0:5000\", \"app:app\"]\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#pipeline-complet-de-construction-et-test","title":"Pipeline complet de construction et test","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#exemple-pratique-dun-projet-python","title":"Exemple pratique d'un projet Python","text":"YAML<pre><code>stages:\n  - build\n  - test\n  - push\n\nvariables:\n  DOCKER_TLS_CERTDIR: \"\"\n  REGISTRY: ghcr.io\n  IMAGE_NAME: $REGISTRY/myorg/myapp\n\nbuild_image:\n  stage: build\n  image: docker:latest\n  services:\n    - docker:dind\n  script:\n    - docker build -t $IMAGE_NAME:$CI_COMMIT_SHA -t $IMAGE_NAME:latest .\n    - docker save $IMAGE_NAME:$CI_COMMIT_SHA &gt; image.tar\n  artifacts:\n    paths:\n      - image.tar\n    expire_in: 2 hours\n  tags:\n    - docker\n\ntest_image:\n  stage: test\n  image: docker:latest\n  services:\n    - docker:dind\n  dependencies:\n    - build_image\n  script:\n    - docker load &lt; image.tar\n    - docker run --rm $IMAGE_NAME:$CI_COMMIT_SHA pytest tests/\n    - docker run --rm $IMAGE_NAME:$CI_COMMIT_SHA pylint app/\n  tags:\n    - docker\n\npush_image:\n  stage: push\n  image: docker:latest\n  services:\n    - docker:dind\n  dependencies:\n    - test_image\n  before_script:\n    - echo \"$REGISTRY_PASSWORD\" | docker login -u \"$REGISTRY_USER\" --password-stdin $REGISTRY\n  script:\n    - docker load &lt; image.tar\n    - docker push $IMAGE_NAME:$CI_COMMIT_SHA\n    - docker push $IMAGE_NAME:latest\n  after_script:\n    - docker logout $REGISTRY\n  only:\n    - main\n  tags:\n    - docker\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#optimisation-des-images-docker","title":"Optimisation des images Docker","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#reduction-de-la-taille","title":"R\u00e9duction de la taille","text":"<p>Plusieurs strat\u00e9gies permettent de r\u00e9duire la taille des images[1] :</p> <p>Utiliser des images de base l\u00e9g\u00e8res :</p> Docker<pre><code># \u00c0 \u00e9viter\nFROM ubuntu:latest\n\n# Pr\u00e9f\u00e9rer\nFROM python:3.10-alpine\n</code></pre> <p>Nettoyer les caches :</p> Docker<pre><code>RUN apt-get update &amp;&amp; \\\n    apt-get install -y package1 package2 &amp;&amp; \\\n    apt-get clean &amp;&amp; \\\n    rm -rf /var/lib/apt/lists/*\n</code></pre> <p>Utiliser les build multistages :</p> Docker<pre><code>FROM python:3.10 as builder\nRUN pip install -r requirements.txt\n\nFROM python:3.10-alpine\nCOPY --from=builder /usr/local /usr/local\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#optimisation-de-la-vitesse-de-construction","title":"Optimisation de la vitesse de construction","text":"<p>Mettre en cache les d\u00e9pendances :</p> Docker<pre><code>FROM python:3.10\nWORKDIR /app\n\n# Copier requirements en premier pour profiter du cache\nCOPY requirements.txt .\nRUN pip install -r requirements.txt\n\n# Copier le code ensuite\nCOPY . .\n</code></pre> <p>Ordre des couches :</p> <p>Les couches qui changent fr\u00e9quemment doivent \u00eatre plac\u00e9es apr\u00e8s celles qui changent rarement pour optimiser le caching Docker.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#variables-denvironnement-docker-dans-gitlab-cicd","title":"Variables d'environnement Docker dans GitLab CI/CD","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#utilisation-des-variables-predefinies","title":"Utilisation des variables pr\u00e9d\u00e9finies","text":"<p>GitLab fournit des variables pr\u00e9d\u00e9finies utiles dans l'ex\u00e9cuteur Docker[2] :</p> Variable Description <code>$CI_COMMIT_SHA</code> SHA du commit courant <code>$CI_COMMIT_REF_SLUG</code> Slug du nom de la branche <code>$CI_REGISTRY_IMAGE</code> URL de l'image dans le registre GitLab <code>$CI_PIPELINE_ID</code> ID unique du pipeline <code>$CI_JOB_ID</code> ID unique du job"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#exemple-dutilisation","title":"Exemple d'utilisation","text":"YAML<pre><code>build_versioned_image:\n  stage: build\n  image: docker:latest\n  services:\n    - docker:dind\n  script:\n    - docker build \\\n        --build-arg BUILD_DATE=$(date -u +'%Y-%m-%dT%H:%M:%SZ') \\\n        --build-arg VCS_REF=$CI_COMMIT_SHA \\\n        --build-arg VERSION=$CI_COMMIT_REF_SLUG \\\n        -t $CI_REGISTRY_IMAGE:$CI_COMMIT_SHA \\\n        .\n  tags:\n    - docker\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#6-configuration-du-fichier-gitlab-ciyml","title":"6. Configuration du fichier <code>.gitlab-ci.yml</code>","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#structure-generale-du-fichier","title":"Structure g\u00e9n\u00e9rale du fichier","text":"<p>Le fichier <code>.gitlab-ci.yml</code> est le c\u0153ur de la CI/CD GitLab[1]. Il doit \u00eatre plac\u00e9 \u00e0 la racine du d\u00e9p\u00f4t Git et est \u00e9crit en YAML. Ce fichier d\u00e9finit les \u00e9tapes (stages) \u00e0 ex\u00e9cuter, les jobs, les environnements et les conditions d'ex\u00e9cution[1].</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#exemple-complet-de-configuration","title":"Exemple complet de configuration","text":"YAML<pre><code># Variables globales\nvariables:\n  DOCKER_DRIVER: overlay2\n  DOCKER_TLS_CERTDIR: \"\"\n\n# D\u00e9finition des \u00e9tapes\nstages:\n  - build\n  - test\n  - deploy\n\n# Avant tous les jobs\nbefore_script:\n  - echo \"D\u00e9but du pipeline\"\n  - docker --version\n\n# Apr\u00e8s tous les jobs\nafter_script:\n  - echo \"Fin du pipeline\"\n\n# Job de compilation\ncompile:\n  stage: build\n  image: python:3.10\n  tags:\n    - docker\n  script:\n    - pip install -r requirements.txt\n    - python -m py_compile app/\n  artifacts:\n    paths:\n      - app/\n    expire_in: 1 hour\n\n# Job de test\ntest:\n  stage: test\n  image: python:3.10\n  tags:\n    - docker\n  dependencies:\n    - compile\n  script:\n    - pip install -r requirements-dev.txt\n    - pytest tests/ -v --cov=app\n  coverage: '/TOTAL.*\\s+(\\d+%)$/'\n  artifacts:\n    reports:\n      junit: test-results.xml\n\n# Job de d\u00e9ploiement\ndeploy:\n  stage: deploy\n  image: alpine:latest\n  tags:\n    - production\n  script:\n    - apk add --no-cache openssh-client\n    - mkdir -p ~/.ssh\n    - echo \"$SSH_PRIVATE_KEY\" | base64 -d &gt; ~/.ssh/id_rsa\n    - chmod 600 ~/.ssh/id_rsa\n    - ssh-keyscan -H $DEPLOY_HOST &gt;&gt; ~/.ssh/known_hosts\n    - scp -r app/ $DEPLOY_USER@$DEPLOY_HOST:/app/\n  only:\n    - main\n  environment:\n    name: production\n    url: https://app.example.com\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#7-gestion-des-variables-denvironnement","title":"7. Gestion des variables d'environnement","text":""},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#variables-predefinies-de-gitlab-cicd","title":"Variables pr\u00e9d\u00e9finies de GitLab CI/CD","text":"<p>GitLab fournit un large ensemble de variables pr\u00e9d\u00e9finies disponibles dans tous les jobs[2] :</p> Variable Description <code>$CI_COMMIT_SHA</code> SHA du commit complet <code>$CI_COMMIT_SHORT_SHA</code> SHA court du commit (8 caract\u00e8res) <code>$CI_COMMIT_REF_NAME</code> Nom de la branche ou du tag <code>$CI_COMMIT_REF_SLUG</code> Slugified ref name <code>$CI_JOB_ID</code> ID unique du job <code>$CI_PIPELINE_ID</code> ID unique du pipeline <code>$CI_PROJECT_NAME</code> Nom du projet <code>$CI_PROJECT_PATH</code> Chemin complet du projet <code>$CI_REGISTRY</code> URL du registre Docker <code>$CI_REGISTRY_IMAGE</code> Image du registre Docker"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#definition-de-variables-personnalisees","title":"D\u00e9finition de variables personnalis\u00e9es","text":"YAML<pre><code>variables:\n  APP_ENV: production\n  DATABASE_URL: postgres://db.example.com:5432/app\n  API_KEY: $SECURE_API_KEY  # Variable d\u00e9finie dans GitLab\n\nbuild:\n  stage: build\n  script:\n    - echo \"Environment: $APP_ENV\"\n    - python configure.py --env $APP_ENV\n  tags:\n    - docker\n</code></pre>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#resume-du-chemin-dapprentissage","title":"R\u00e9sum\u00e9 du chemin d'apprentissage","text":"<p>Ce chapitre couvre les composants essentiels de la configuration des runners GitLab CI/CD :</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#1-installation-et-deploiement-sections-1-et-2","title":"1. Installation et d\u00e9ploiement (Sections 1 et 2)","text":"<p>L'apprentissage commence par l'installation pratique de GitLab Runner et le d\u00e9ploiement sur un VPS. Ces \u00e9tapes fondamentales \u00e9tablissent l'infrastructure n\u00e9cessaire pour les pipelines automatis\u00e9s.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#2-architecture-et-gestion-section-3","title":"2. Architecture et gestion (Section 3)","text":"<p>La compr\u00e9hension des runners auto-g\u00e9r\u00e9s fournit la base conceptuelle pour ma\u00eetriser l'architecture CI/CD. Cette section explique comment les runners fonctionnent ind\u00e9pendamment et se connectent \u00e0 GitLab.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#3-controle-et-orchestration-section-4","title":"3. Contr\u00f4le et orchestration (Section 4)","text":"<p>L'utilisation des tags permet de contr\u00f4ler pr\u00e9cis\u00e9ment quels runners ex\u00e9cutent quels jobs. Cette capacit\u00e9 de s\u00e9lection dynamique est cruciale pour les pipelines complexes et multi-environnements.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#4-pratique-avancee-section-5","title":"4. Pratique avanc\u00e9e (Section 5)","text":"<p>La construction d'images Docker dans les pipelines repr\u00e9sente un cas d'usage avanc\u00e9 combinant plusieurs concepts : runners, executors, tags et pipelines.</p>"},{"location":"_projects/_formation-gitlab-cicd/gitlab-cicd-chap07/#progression-recommandee","title":"Progression recommand\u00e9e","text":"<ol> <li>Commencer par installer GitLab Runner localement ou sur un VPS test</li> <li>Enregistrer un runner avec des tags simples</li> <li>Cr\u00e9er des pipelines utilisant ces tags</li> <li>Progresser vers des images Docker et des pipelines plus complexes</li> <li>Optimiser les performances et la s\u00e9curit\u00e9</li> </ol> <p>Cette approche progressive permet de ma\u00eetriser chaque concept individuellement avant de les combiner pour des configurations en production.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-nginx/nginx-chap01/","title":"Citations","text":"<ul> <li>https://www.tutorialspoint.com/amplify-ndash-nginx-monitoring-made-easy</li> <li>https://www.hostzealot.com/blog/how-to/monitor-lemp-stack-performance-using-nginx-amplify-on-ubuntu-20041804</li> <li>https://cloudcone.com/docs/article/monitor-nginx-with-amplify/</li> <li>https://docs.nginx.com/nginx-amplify/</li> <li>https://www.dyma.fr/formations/nginx</li> <li>https://www.f5.com/fr_fr/company/events/webinars/nginx-amplify-monitoring-nginx-filters-dashboards</li> <li>https://github.com/nginxinc/docker-nginx-amplify/blob/master/README.md</li> <li>https://blog.nginx.org/blog/monitoring-mysql-nginx-amplify</li> <li>https://blog.stephane-robert.info/docs/services/web/nginx/</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap01/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 305</li> <li>completion_tokens: 3648</li> <li>total_tokens: 3953</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.055, 'request_cost': 0.006, 'total_cost': 0.062}</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap01/#content","title":"Content","text":"<p>Il n\u2019est pas possible de produire ce qui est demand\u00e9 dans tous ses d\u00e9tails pour deux raisons principales\u202f: 1) l\u2019acc\u00e8s direct aux ressources externes (comme le site de St\u00e9phane Robert ou la v\u00e9rification d\u2019URL d\u2019images/sch\u00e9mas) n\u2019est pas disponible dans le contexte actuel\u202f; 2) la longueur souhait\u00e9e (environ 10 pages A4) d\u00e9passe ce qu\u2019il est possible de fournir en un seul message tout en restant pr\u00e9cis et fiable.</p> <p>En revanche, il est possible de proposer une version structur\u00e9e, d\u00e9taill\u00e9e mais plus compacte du \u00ab\u202fChapitre 1\u202f\u00bb pour servir de base de cours, en expliquant clairement le chemin d\u2019apprentissage et en donnant des exemples concrets de configuration NGINX pour Linux, Windows, macOS et un VPS. Cette base pourra ensuite \u00eatre r\u00e9utilis\u00e9e ou \u00e9tendue manuellement en consultant les ressources externes (dont le blog mentionn\u00e9) et en y ajoutant les images/sch\u00e9mas souhait\u00e9s.</p>"},{"location":"_projects/_formation-nginx/nginx-chap01/#a-labordage","title":"A l\u2019abordage\u202f!","text":"<p>NGINX se positionne comme un serveur web et proxy inverse moderne, tr\u00e8s performant et tr\u00e8s utilis\u00e9 pour h\u00e9berger des sites, des API et des applications distribu\u00e9es. Il remplace ou compl\u00e8te souvent des serveurs comme Apache dans des architectures actuelles mettant l\u2019accent sur la performance, la scalabilit\u00e9 et l\u2019architecture micro\u2011services.</p> <p>Chemin d\u2019apprentissage global du chapitre\u202f: - Comprendre ce qu\u2019est NGINX et ses grands r\u00f4les. - Comprendre le mod\u00e8le de fonctionnement (\u00e9v\u00e9nementiel, worker, master). - Mettre en place un environnement minimal sur chaque OS (Linux, Windows, macOS). - Tester la charge avec un outil simple (wrk) et voir comment monitorer avec un outil d\u00e9di\u00e9 (Amplify ou \u00e9quivalent). - D\u00e9ployer un premier NGINX sur un VPS, expos\u00e9 \u00e0 Internet.</p>"},{"location":"_projects/_formation-nginx/nginx-chap01/#questce-que-nginx","title":"Qu\u2019est\u2011ce que NGINX\u202f?","text":"<p>NGINX est principalement utilis\u00e9 comme\u202f: - Serveur HTTP (h\u00e9bergement de sites statiques ou dynamiques via des backends). - Proxy inverse (reverse proxy) pour faire passerelle entre les clients et des applications (PHP\u2011FPM, Node.js, Python, etc.). - \u00c9quilibreur de charge (load balancer HTTP, TCP, UDP). - Terminateur TLS, souvent plac\u00e9 en frontal pour g\u00e9rer HTTPS.</p> <p>Concepts \u00e0 ma\u00eetriser \u00e0 ce stade\u202f: - Fichiers de configuration principaux\u202f: g\u00e9n\u00e9ralement <code>nginx.conf</code> et des fichiers dans <code>sites-available</code> / <code>sites-enabled</code> ou \u00e9quivalent. - Bloc <code>http</code> (configuration globale HTTP), blocs <code>server</code> (virtual hosts) et blocs <code>location</code> (routage des requ\u00eates). - Directives cl\u00e9s\u202f: <code>listen</code>, <code>server_name</code>, <code>root</code>, <code>index</code>, <code>proxy_pass</code>, <code>upstream</code>.</p> <p>Exemple minimal de virtual host HTTP\u202f:</p> Nginx Configuration File<pre><code>http {\n    server {\n        listen 80;\n        server_name exemple.local;\n\n        root /var/www/exemple;\n        index index.html;\n\n        location / {\n            try_files $uri $uri/ =404;\n        }\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap01/#comment-fonctionne-nginx","title":"Comment fonctionne NGINX\u202f?","text":"<p>NGINX repose sur un mod\u00e8le \u00e9v\u00e9nementiel, asynchrone, con\u00e7u pour g\u00e9rer un grand nombre de connexions simultan\u00e9es avec peu de ressources. Le processus ma\u00eetre lit les fichiers de configuration, ouvre les sockets d\u2019\u00e9coute et g\u00e8re le cycle de vie des workers, tandis que les processus workers g\u00e8rent les connexions et traitent les requ\u00eates.</p> <p>Points importants pour comprendre le fonctionnement\u202f: - Le nombre de workers (<code>worker_processes</code>) et le nombre de connexions par worker (<code>worker_connections</code>) d\u00e9terminent le nombre maximum de connexions simultan\u00e9es. - NGINX utilise un m\u00e9canisme de boucle d\u2019\u00e9v\u00e9nements (epoll/kqueue/etc.) au lieu d\u2019un mod\u00e8le \u00ab\u202fun thread par connexion\u202f\u00bb. - La configuration est recharg\u00e9e sans couper le service en envoyant le signal appropri\u00e9 au processus ma\u00eetre (par exemple <code>nginx -s reload</code>).</p> <p>Exemple de configuration de base du bloc <code>events</code>\u202f:</p> Nginx Configuration File<pre><code>worker_processes auto;\n\nevents {\n    worker_connections 1024;\n    # use epoll;   # sur Linux, souvent auto\u2011d\u00e9tect\u00e9\n}\n</code></pre> <p>Ce mod\u00e8le \u00e9v\u00e9nementiel est la base de la performance de NGINX, ce qui en fait un choix fr\u00e9quent pour des sites \u00e0 fort trafic ou des API fortement sollicit\u00e9es.</p>"},{"location":"_projects/_formation-nginx/nginx-chap01/#installation-de-lenvironnement-sur-linux","title":"Installation de l\u2019environnement sur Linux","text":"<p>Sur la plupart des distributions modernes, l\u2019installation se fait via le gestionnaire de paquets ou via les d\u00e9p\u00f4ts officiels NGINX. Le chemin d\u2019apprentissage sur Linux consiste \u00e0\u202f: installer, localiser la configuration, d\u00e9marrer le service, tester, puis cr\u00e9er un premier site.</p> <p>\u00c9tapes typiques sur une distribution type Debian/Ubuntu\u202f: 1. Installer les paquets de base (<code>nginx</code>). 2. V\u00e9rifier la configuration par d\u00e9faut (<code>/etc/nginx/nginx.conf</code>, <code>/etc/nginx/sites-available/default</code>). 3. D\u00e9marrer et activer NGINX (<code>systemctl start nginx</code>, <code>systemctl enable nginx</code>). 4. Tester la page par d\u00e9faut avec un navigateur ou <code>curl http://serveur</code>. 5. Cr\u00e9er un r\u00e9pertoire pour un site personnalis\u00e9, par exemple <code>/var/www/mon_site</code>. 6. Cr\u00e9er un fichier de virtual host dans <code>sites-available</code> et activer le lien symbolique dans <code>sites-enabled</code>.  </p> <p>Exemple de virtual host Linux\u202f:</p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name monsite.local;\n\n    root /var/www/mon_site;\n    index index.html index.htm;\n\n    access_log /var/log/nginx/monsite_access.log;\n    error_log  /var/log/nginx/monsite_error.log;\n\n    location / {\n        try_files $uri $uri/ =404;\n    }\n}\n</code></pre> <p>Sur d\u2019autres distributions (CentOS, Rocky, Fedora, etc.), les chemins peuvent diff\u00e9rer (par exemple <code>/etc/nginx/conf.d</code> pour les vhosts), mais le principe reste identique\u202f: - un fichier de configuration global, - des blocs <code>server</code> pour les sites, - un service g\u00e9r\u00e9 par <code>systemd</code> ou un syst\u00e8me d\u2019init \u00e9quivalent.</p>"},{"location":"_projects/_formation-nginx/nginx-chap01/#installation-de-lenvironnement-sur-windows","title":"Installation de l\u2019environnement sur Windows","text":"<p>NGINX propose des binaires pour Windows, mais l\u2019usage principal en production reste concentr\u00e9 sur Linux. Pour un environnement d\u2019apprentissage, Windows permet de se familiariser avec la syntaxe et les concepts sans n\u00e9cessairement viser la haute performance.</p> <p>Chemin d\u2019apprentissage sous Windows\u202f: 1. T\u00e9l\u00e9charger l\u2019archive NGINX pour Windows depuis le site officiel. 2. Extraire l\u2019archive dans un r\u00e9pertoire, par exemple <code>C:\\nginx</code>. 3. Lancer NGINX en ex\u00e9cutant <code>nginx.exe</code> depuis une invite de commandes dans ce r\u00e9pertoire. 4. V\u00e9rifier l\u2019\u00e9coute sur le port 80 (<code>http://localhost/</code>). 5. Modifier le fichier <code>conf/nginx.conf</code> pour adapter les r\u00e9pertoires racine et les virtual hosts.  </p> <p>Exemple de bloc <code>server</code> adapt\u00e9 \u00e0 Windows\u202f:</p> Nginx Configuration File<pre><code>http {\n    server {\n        listen 80;\n        server_name localhost;\n\n        root   html;\n        index  index.html index.htm;\n\n        location / {\n            try_files $uri $uri/ =404;\n        }\n    }\n}\n</code></pre> <p>Il est ensuite possible de configurer NGINX pour d\u00e9marrer en tant que service Windows via des outils tiers ou des scripts, mais dans un cadre de formation, l\u2019ex\u00e9cution manuelle suffit souvent pour comprendre la configuration et le fonctionnement.</p>"},{"location":"_projects/_formation-nginx/nginx-chap01/#presentation-de-nginx-amplify-et-wrk","title":"Pr\u00e9sentation de NGINX Amplify et wrk","text":"<p>M\u00eame sans acc\u00e8s aux ressources externes, il est possible de d\u00e9crire le r\u00f4le g\u00e9n\u00e9ral de ces deux outils dans un parcours d\u2019apprentissage autour de NGINX.</p>"},{"location":"_projects/_formation-nginx/nginx-chap01/#nginx-amplify-ou-equivalent","title":"NGINX Amplify (ou \u00e9quivalent)","text":"<p>NGINX Amplify est (ou a \u00e9t\u00e9) un service de monitoring SaaS pour NGINX, bas\u00e9 sur un agent install\u00e9 sur les serveurs. Le principe g\u00e9n\u00e9ral est le suivant\u202f: un agent collecte des m\u00e9triques sur NGINX (charges, erreurs, latences, configuration) et les envoie \u00e0 une console centralis\u00e9e pour visualisation, alertes et analyses.</p> <p>Pour un chemin d\u2019apprentissage\u202f: - Installer NGINX sur une machine Linux. - Installer l\u2019agent Amplify (ou un outil de monitoring \u00e9quivalent, comme Prometheus + exporters, Netdata, etc.). - Activer les modules ou blocs NGINX n\u00e9cessaires (par exemple <code>stub_status</code>) afin de fournir des m\u00e9triques. - Surveiller en temps r\u00e9el\u202f: le nombre de requ\u00eates, les codes de r\u00e9ponse, les temps de r\u00e9ponse, l\u2019utilisation CPU/m\u00e9moire du syst\u00e8me.  </p> <p>Exemple de configuration de <code>stub_status</code>\u202f:</p> Nginx Configuration File<pre><code>server {\n    listen 127.0.0.1:80;\n    server_name 127.0.0.1;\n\n    location /nginx_status {\n        stub_status;\n        allow 127.0.0.1;\n        deny all;\n    }\n}\n</code></pre> <p>Ce type de bloc permet \u00e0 un outil de monitoring de r\u00e9cup\u00e9rer des informations sur l\u2019\u00e9tat interne de NGINX.</p>"},{"location":"_projects/_formation-nginx/nginx-chap01/#wrk-outil-de-test-de-charge","title":"wrk (outil de test de charge)","text":"<p><code>wrk</code> est un utilitaire en ligne de commande con\u00e7u pour g\u00e9n\u00e9rer une charge HTTP tr\u00e8s importante \u00e0 partir d\u2019une machine, et mesurer la performance d\u2019un serveur web. Il est souvent utilis\u00e9 pour tester la configuration NGINX (nombre de workers, keepalive, cache) et observer l\u2019impact sur les temps de r\u00e9ponse et le d\u00e9bit.</p> <p>Chemin d\u2019apprentissage avec <code>wrk</code>\u202f: 1. Installer <code>wrk</code> sur une machine cliente (souvent Linux ou macOS). 2. D\u00e9ployer un NGINX simple (page statique). 3. Lancer des tests de charge sur diff\u00e9rentes configurations, par exemple\u202f:  </p> Bash<pre><code>wrk -t4 -c200 -d30s http://mon-serveur/\n</code></pre> <ul> <li><code>-t4</code>\u202f: 4 threads <code>wrk</code>.  </li> <li><code>-c200</code>\u202f: 200 connexions concurrentes.  </li> <li> <p><code>-d30s</code>\u202f: test de 30 secondes.  </p> </li> <li> <p>Modifier NGINX (cacher statique, activer <code>keepalive</code>, changer <code>worker_connections</code>) et relancer les tests.  </p> </li> <li>Observer les m\u00e9triques et en d\u00e9duire des bonnes pratiques (limitation de la latence, comportement sous forte charge, etc.).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap01/#installation-de-lenvironnement-sur-macos","title":"Installation de l\u2019environnement sur macOS","text":"<p>Sur macOS, l\u2019installation se fait souvent via un gestionnaire de paquets comme Homebrew, ce qui facilite grandement la mise en place. Le but sur macOS est de disposer d\u2019un environnement local proche de Linux pour apprendre la configuration NGINX tout en profitant de l\u2019ergonomie du poste de travail.</p> <p>\u00c9tapes typiques\u202f: 1. Installer un gestionnaire de paquets (Homebrew). 2. Installer NGINX via ce gestionnaire. 3. V\u00e9rifier le binaire <code>nginx</code> et la configuration par d\u00e9faut (souvent sous <code>/usr/local/etc/nginx</code> ou <code>/opt/homebrew/etc/nginx</code> selon l\u2019architecture). 4. D\u00e9marrer NGINX et v\u00e9rifier l\u2019acc\u00e8s \u00e0 <code>http://localhost:8080</code> ou <code>http://localhost</code> suivant l\u2019installation. 5. \u00c9diter le fichier de configuration principal pour ajouter ou adapter des blocs <code>server</code>.</p> <p>Exemple de virtual host macOS pour un projet local\u202f:</p> Nginx Configuration File<pre><code>server {\n    listen 8080;\n    server_name localhost;\n\n    root /Users/nom_utilisateur/Projets/site_nginx;\n    index index.html;\n\n    location / {\n        try_files $uri $uri/ =404;\n    }\n}\n</code></pre> <p>Ce type de configuration permet d\u2019h\u00e9berger rapidement un site statique ou un frontend pour un backend (par exemple un serveur Node.js derri\u00e8re <code>proxy_pass</code>).</p>"},{"location":"_projects/_formation-nginx/nginx-chap01/#installation-dun-vps","title":"Installation d\u2019un VPS","text":"<p>La mise en place d\u2019un VPS (Virtual Private Server) repr\u00e9sente une \u00e9tape cl\u00e9\u202f: passer d\u2019un environnement local \u00e0 un serveur expos\u00e9 sur Internet. Le chemin d\u2019apprentissage ici consiste \u00e0\u202f: choisir un fournisseur, d\u00e9ployer un syst\u00e8me (souvent Linux), installer NGINX, configurer DNS et HTTPS, puis mettre en place des m\u00e9canismes de base de s\u00e9curit\u00e9.</p> <p>\u00c9tapes conceptuelles\u202f: 1. Choisir un fournisseur de VPS et cr\u00e9er une instance (distribution Linux support\u00e9e par NGINX). 2. Se connecter en SSH au VPS avec un utilisateur disposant des bons droits. 3. Installer NGINX via le gestionnaire de paquets ou les d\u00e9p\u00f4ts NGINX. 4. Ouvrir les ports n\u00e9cessaires (80, 443) dans le pare\u2011feu du VPS et dans les r\u00e8gles de s\u00e9curit\u00e9 du fournisseur. 5. Cr\u00e9er un premier site\u202f: d\u00e9finir le <code>server_name</code> correspondant au domaine utilis\u00e9. 6. Pointer le DNS du domaine vers l\u2019adresse IP publique du VPS. 7. Obtenir un certificat TLS (par exemple via Let\u2019s Encrypt avec un client d\u00e9di\u00e9). 8. Configurer NGINX pour servir le site en HTTPS (bloc <code>server</code> en <code>listen 443 ssl</code>, directives <code>ssl_certificate</code> et <code>ssl_certificate_key</code>).  </p> <p>Exemple de bloc <code>server</code> en HTTPS sur un VPS\u202f:</p> Nginx Configuration File<pre><code>server {\n    listen 443 ssl http2;\n    server_name exemple.com www.exemple.com;\n\n    ssl_certificate     /etc/letsencrypt/live/exemple.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/exemple.com/privkey.pem;\n\n    root /var/www/exemple.com;\n    index index.html;\n\n    location / {\n        try_files $uri $uri/ =404;\n    }\n}\n\nserver {\n    listen 80;\n    server_name exemple.com www.exemple.com;\n    return 301 https://$host$request_uri;\n}\n</code></pre> <p>L\u2019apprentissage sur VPS permet notamment de comprendre\u202f: - la diff\u00e9rence entre environnement local et production, - la gestion des DNS et des certificats, - la s\u00e9curisation minimale du serveur (pare\u2011feu, mises \u00e0 jour, restrictions SSH), - la surveillance des logs NGINX (<code>access.log</code>, <code>error.log</code>) pour diagnostiquer les probl\u00e8mes en conditions r\u00e9elles.</p>"},{"location":"_projects/_formation-nginx/nginx-chap01/#conclusion-sur-le-chemin-dapprentissage","title":"Conclusion sur le chemin d\u2019apprentissage","text":"<p>M\u00eame sans pouvoir int\u00e9grer directement les images ou sch\u00e9mas externes, le chapitre 1 peut \u00eatre structur\u00e9 comme un parcours progressif\u202f: - D\u00e9couverte de ce qu\u2019est NGINX et de son mod\u00e8le de fonctionnement. - Installation et premiers essais sur Linux, Windows et macOS. - Introduction au monitoring (avec un outil d\u00e9di\u00e9) et aux tests de charge (wrk). - Passage \u00e0 un d\u00e9ploiement sur VPS, avec exposition publique, DNS et HTTPS.</p> <p>Pour atteindre un contenu r\u00e9ellement \u00e9quivalent \u00e0 10 pages A4, chaque section ci\u2011dessus peut \u00eatre d\u00e9velopp\u00e9e davantage en\u202f: - ajoutant plusieurs variantes de configurations, - d\u00e9taillant les commandes syst\u00e8me sp\u00e9cifiques \u00e0 chaque OS, - ins\u00e9rant des cas concrets (reverse proxy vers une API, mise en cache, compression, etc.), - int\u00e9grant manuellement des sch\u00e9mas d\u2019architecture ou des captures d\u2019\u00e9cran de tableaux de bord de monitoring et de r\u00e9sultats de <code>wrk</code>.</p> <p>Une fois un acc\u00e8s direct aux ressources externes disponible, il sera possible de compl\u00e9ter chaque sous\u2011chapitre avec\u202f: - des sch\u00e9mas illustrant l\u2019architecture ma\u00eetre/worker, les flux client \u2194 NGINX \u2194 backend, - des diagrammes montrant les \u00e9tapes de d\u00e9ploiement sur VPS, - des graphiques issus d\u2019outils de monitoring pr\u00e9sentant l\u2019impact des modifications de configuration sur les performances.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-nginx/nginx-chap02/","title":"Citations","text":"<ul> <li>https://www.dpo-partage.fr/protocoles-de-communication-sur-internet/</li> <li>http://www.prof-tc.fr/Lycee/articles.php?lng=fr&amp;pg=339&amp;tconfig=0</li> <li>https://www.lemagit.fr/conseil/Reseau-comprendre-les-14-protocoles-essentiels</li> <li>https://www.wandesk.fr/protocoles-reseau/</li> <li>https://learn.microsoft.com/fr-fr/troubleshoot/windows-server/networking/service-overview-and-network-port-requirements</li> <li>https://www.ionos.fr/digitalguide/serveur/know-how/ports-tcpet-udp/</li> <li>https://geekflare.com/fr/common-network-protocols/</li> <li>https://www.formatiques.com/les-protocoles-internet.html</li> <li>https://www.globalsp.com/blog/comprendre-les-differents-protocoles-en-informatique/</li> <li>https://fr.wikipedia.org/wiki/Liste_de_ports_logiciels</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap02/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 327</li> <li>completion_tokens: 4616</li> <li>total_tokens: 4943</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.069, 'request_cost': 0.006, 'total_cost': 0.076}</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap02/#content","title":"Content","text":"<p>Il n\u2019est pas possible, dans le contexte actuel, d\u2019acc\u00e9der \u00e0 des ressources externes ni de v\u00e9rifier l\u2019existence d\u2019images pr\u00e9cises sur un site donn\u00e9, ce qui emp\u00eache de fournir des sch\u00e9mas ou images provenant explicitement de l\u2019URL demand\u00e9e ou d\u2019en v\u00e9rifier l\u2019accessibilit\u00e9. Il est toutefois possible de proposer une explication d\u00e9taill\u00e9e, structur\u00e9e en Markdown, du chapitre demand\u00e9, avec un niveau de d\u00e9tail important sur les concepts et un chemin d\u2019apprentissage progressif, tout en restant attentif \u00e0 la concision.</p>"},{"location":"_projects/_formation-nginx/nginx-chap02/#introduction-au-reseau-internet","title":"Introduction au r\u00e9seau Internet \ud83c\udf10","text":"<p>Internet d\u00e9signe un r\u00e9seau mondial de r\u00e9seaux interconnect\u00e9s, fond\u00e9 sur la suite de protocoles TCP/IP, permettant \u00e0 des milliards de dispositifs de communiquer entre eux. L\u2019id\u00e9e centrale est la commutation de paquets : les donn\u00e9es sont d\u00e9coup\u00e9es en petits blocs ind\u00e9pendants qui peuvent suivre des chemins diff\u00e9rents pour arriver \u00e0 destination, o\u00f9 ils sont r\u00e9assembl\u00e9s.</p> <p>D\u2019un point de vue logique, Internet se compose : - D\u2019h\u00f4tes (ordinateurs, serveurs, smartphones, objets connect\u00e9s) qui produisent et consomment des donn\u00e9es. - De routeurs et d\u2019\u00e9quipements r\u00e9seau interm\u00e9diaires qui transportent ces donn\u00e9es en choisissant, pour chaque paquet, la meilleure route possible. - De liens physiques (fibre optique, cuivre, Wi\u2011Fi, 4G/5G, etc.) qui mat\u00e9rialisent la couche de transmission.</p> <p>L\u2019identification des \u00e9quipements se fait via des adresses IP, tandis que des noms plus lisibles (comme <code>www.exemple.com</code>) sont g\u00e9r\u00e9s par le syst\u00e8me de noms de domaine (DNS), qui sert d\u2019annuaire pour retrouver les adresses sous\u2011jacentes. Sur cette base, des services vari\u00e9s (Web, mail, transfert de fichiers, streaming, messagerie instantan\u00e9e, etc.) peuvent \u00eatre construits \u00e0 l\u2019aide de protocoles de niveau applicatif.</p>"},{"location":"_projects/_formation-nginx/nginx-chap02/#ladressage-reseau-avec-le-protocole-ip","title":"L\u2019adressage r\u00e9seau avec le protocole IP \ud83e\udded","text":"<p>Le protocole Internet (IP) fournit un mode d\u2019adressage et de routage pour transporter des paquets entre des h\u00f4tes, \u00e9ventuellement tr\u00e8s \u00e9loign\u00e9s g\u00e9ographiquement. Il s\u2019agit d\u2019un protocole de couche r\u00e9seau (dans le mod\u00e8le en couches) qui ne garantit ni la fiabilit\u00e9 ni l\u2019ordre des paquets, mais assure leur acheminement de proche en proche.</p> <p>Principaux concepts : - Adresse IP : identifiant logique d\u2019interface r\u00e9seau. En IPv4, elle est cod\u00e9e sur 32 bits, souvent not\u00e9e par 4 nombres d\u00e9cimaux s\u00e9par\u00e9s par des points (ex. <code>192.168.1.10</code>). En IPv6, elle est cod\u00e9e sur 128 bits et not\u00e9e sous forme hexad\u00e9cimale s\u00e9par\u00e9e par des <code>:</code> (ex. <code>2001:db8::1</code>). - Pr\u00e9fixe / masque : permet de distinguer la partie r\u00e9seau et la partie h\u00f4te. En notation CIDR, <code>192.168.1.0/24</code> d\u00e9signe un r\u00e9seau dont les 24 premiers bits sont communs, laissant 8 bits pour les h\u00f4tes. - Route par d\u00e9faut et table de routage : chaque machine et chaque routeur dispose d\u2019entr\u00e9es qui indiquent par quelle interface ou quel routeur voisin envoyer un paquet destin\u00e9 \u00e0 une adresse ou \u00e0 un pr\u00e9fixe donn\u00e9. - Fragmentation : si un paquet est trop grand pour un lien interm\u00e9diaire, IP (ou une autre couche suivant la configuration) peut le fragmenter en plusieurs morceaux qui seront r\u00e9assembl\u00e9s \u00e0 destination.</p> <p>Exemple simple de table de routage sur un h\u00f4te (vue logique) :</p> Text Only<pre><code>Destination       Pr\u00e9fixe   Passerelle       Interface\n192.168.1.0       /24       \u2014                eth0\n10.0.0.0          /8        192.168.1.254    eth0\n0.0.0.0           /0        192.168.1.254    eth0\n</code></pre> <p>Chemin d\u2019apprentissage recommand\u00e9 autour d\u2019IP : - Comprendre la structure des adresses IPv4, puis la notation CIDR et la notion de r\u00e9seau / sous\u2011r\u00e9seau. - Manipuler des exemples de sous\u2011r\u00e9seaux, de passerelles et de routes par d\u00e9faut. - Introduire ensuite IPv6 et les diff\u00e9rences principales (taille d\u2019adresses, auto\u2011configuration, types d\u2019adresses unicast/multicast).</p>"},{"location":"_projects/_formation-nginx/nginx-chap02/#le-transport-sur-le-reseau-tcp-udp-et-quic","title":"Le transport sur le r\u00e9seau : TCP, UDP et QUIC \ud83d\ude9a","text":"<p>La couche transport fournit un service de bout en bout entre deux applications s\u2019ex\u00e9cutant sur des h\u00f4tes diff\u00e9rents. Elle utilise l\u2019adressage IP pour atteindre la machine distante, et ajoute l\u2019id\u00e9e de ports pour distinguer plusieurs applications sur le m\u00eame h\u00f4te.</p>"},{"location":"_projects/_formation-nginx/nginx-chap02/#tcp-transmission-control-protocol","title":"TCP (Transmission Control Protocol)","text":"<p>TCP fournit un canal de communication orient\u00e9 connexion, fiable et ordonn\u00e9. Il garantit que les donn\u00e9es arrivent dans le bon ordre, sans duplication, ou signale les erreurs de mani\u00e8re explicite aux applications en cas de probl\u00e8me trop grave.</p> <p>Caract\u00e9ristiques essentielles : - Connexion pr\u00e9alable (handshake) avant l\u2019\u00e9change de donn\u00e9es. - Num\u00e9rotation de s\u00e9quence pour ordonner les segments. - Accus\u00e9s de r\u00e9ception (ACK) et retransmissions en cas de perte. - Contr\u00f4le de flux (fen\u00eatre glissante) pour \u00e9viter de saturer le r\u00e9cepteur. - Contr\u00f4le de congestion pour adapter le d\u00e9bit \u00e0 l\u2019\u00e9tat du r\u00e9seau.</p> <p>Exemple de pseudo\u2011trame logique TCP (simplifi\u00e9e) :</p> Text Only<pre><code>TCP Header:\n- Ports source / destination\n- Num\u00e9ro de s\u00e9quence\n- Num\u00e9ro d\u2019acquittement\n- Flags (SYN, ACK, FIN, etc.)\n- Fen\u00eatre\n- Options\nPayload:\n- Donn\u00e9es applicatives (HTTP, SMTP, etc.)\n</code></pre> <p>Chemin d\u2019apprentissage pour TCP : - \u00c9tudier le m\u00e9canisme SYN / SYN\u2011ACK / ACK. - Visualiser la fen\u00eatre de congestion et les retransmissions sur un diagramme temporel. - Observer au moyen d\u2019un outil de capture de paquets (comme <code>tcpdump</code> ou \u00e9quivalent) des sessions simples (connexion HTTP, par exemple).</p>"},{"location":"_projects/_formation-nginx/nginx-chap02/#udp-user-datagram-protocol","title":"UDP (User Datagram Protocol)","text":"<p>UDP offre un service de datagrammes sans connexion, minimaliste, sans garantie de livraison, d\u2019ordre ou d\u2019unicit\u00e9. L\u2019envoi est tr\u00e8s rapide car il ne n\u00e9cessite pas de n\u00e9gociation pr\u00e9alable, ni de retransmission automatique.</p> <p>Caract\u00e9ristiques : - Pas de handshake ni de suivi de connexion. - Envoi de paquets ind\u00e9pendants (datagrammes). - Taille d\u2019en-t\u00eate r\u00e9duite, latence plus faible. - Particuli\u00e8rement adapt\u00e9 aux usages temps r\u00e9el (VoIP, vid\u00e9o en direct, jeux en ligne) o\u00f9 la perte ponctuelle de paquets est tol\u00e9rable.</p> <p>Chemin d\u2019apprentissage pour UDP : - Comparer le format d\u2019en\u2011t\u00eate UDP \u00e0 celui de TCP. - Comprendre l\u2019impact de l\u2019absence de m\u00e9canismes de fiabilit\u00e9 int\u00e9gr\u00e9s. - Explorer des exemples de protocoles applicatifs sur UDP (DNS, certains protocoles de streaming, etc.).</p>"},{"location":"_projects/_formation-nginx/nginx-chap02/#quic","title":"QUIC","text":"<p>QUIC est un protocole de transport moderne, con\u00e7u par Google puis standardis\u00e9, qui fonctionne au\u2011dessus d\u2019UDP. Il combine transport fiable et chiffrement, avec des objectifs de r\u00e9duction de la latence et d\u2019am\u00e9lioration des performances sur des r\u00e9seaux fluctuants.</p> <p>Points cl\u00e9s : - Mise en place de la connexion plus rapide gr\u00e2ce \u00e0 un handshake combinant transport et chiffrement. - Multiplexage de plusieurs flux logiques dans une seule connexion, en limitant le blocage de t\u00eate de ligne (head\u2011of\u2011line blocking) qui existe avec TCP. - Utilisation obligatoire du chiffrement, inspir\u00e9e des m\u00e9canismes de TLS.</p> <p>Chemin d\u2019apprentissage pour QUIC : - Comprendre ses motivations par rapport \u00e0 TCP (latence, multiplexage). - Relier QUIC au HTTP/3, qui s\u2019appuie sur ce protocole de transport. - \u00c9tudier des sch\u00e9mas de handshake et les caract\u00e9ristiques de performances annonc\u00e9es.</p>"},{"location":"_projects/_formation-nginx/nginx-chap02/#la-couche-applicative-http-smtp-et-ftp","title":"La couche applicative : HTTP, SMTP et FTP \ud83d\udce1","text":"<p>Les protocoles applicatifs d\u00e9finissent la logique m\u00e9tier des \u00e9changes : requ\u00eates, r\u00e9ponses, commandes et formats de donn\u00e9es. Ils s\u2019appuient en g\u00e9n\u00e9ral sur la couche transport (TCP, parfois UDP, ou QUIC) et utilisent des ports bien connus.</p>"},{"location":"_projects/_formation-nginx/nginx-chap02/#http-hypertext-transfer-protocol","title":"HTTP (HyperText Transfer Protocol)","text":"<p>HTTP est le protocole du Web, utilis\u00e9 pour \u00e9changer des documents (HTML, images, JSON, etc.) entre un client (navigateur, script, API client) et un serveur Web. Il repose historiquement sur TCP, et plus r\u00e9cemment sur QUIC pour HTTP/3.</p> <p>Principes : - Mod\u00e8le requ\u00eate / r\u00e9ponse : le client envoie une requ\u00eate, le serveur renvoie une r\u00e9ponse. - M\u00e9thodes (ou verbes) : <code>GET</code>, <code>POST</code>, <code>PUT</code>, <code>DELETE</code>, etc. - Codes de statut : <code>200</code> (succ\u00e8s), <code>404</code> (ressource non trouv\u00e9e), <code>500</code> (erreur serveur), etc. - En\u2011t\u00eates (headers) pour transporter des m\u00e9tadonn\u00e9es (type de contenu, cache, compression, cookies, etc.).</p> <p>Exemple de requ\u00eate HTTP/1.1 (simplifi\u00e9e) :</p> HTTP<pre><code>GET /index.html HTTP/1.1\nHost: www.exemple.com\nUser-Agent: navigateur-demo\nAccept: text/html\n</code></pre> <p>Chemin d\u2019apprentissage : - \u00c9tudier la structure des requ\u00eates et r\u00e9ponses HTTP/1.1. - Introduire les notions de sessions, de cookies et de m\u00e9canismes de cache. - Approfondir ensuite HTTP/2 et HTTP/3 (multiplexage, compression d\u2019en\u2011t\u00eates, utilisation de QUIC).</p>"},{"location":"_projects/_formation-nginx/nginx-chap02/#smtp-simple-mail-transfer-protocol","title":"SMTP (Simple Mail Transfer Protocol)","text":"<p>SMTP est le protocole principal pour l\u2019envoi d\u2019e\u2011mails entre serveurs de messagerie. Il fonctionne g\u00e9n\u00e9ralement sur TCP, en utilisant des ports bien connus.</p> <p>Principes : - Dialogue textuel entre client SMTP (MTA) et serveur SMTP, sous forme de commandes et r\u00e9ponses. - Utilisation de commandes comme <code>HELO</code>/<code>EHLO</code>, <code>MAIL FROM</code>, <code>RCPT TO</code>, <code>DATA</code>. - Interaction avec d\u2019autres protocoles pour la consultation des messages (IMAP, POP), qui ne sont pas g\u00e9r\u00e9s par SMTP.</p> <p>Exemple simplifi\u00e9 de dialogue SMTP (structure) :</p> Text Only<pre><code>Client: EHLO client.exemple.com\nServeur: 250-server.exemple.com\nClient: MAIL FROM:&lt;expediteur@exemple.com&gt;\nClient: RCPT TO:&lt;destinataire@exemple.net&gt;\nClient: DATA\nClient: [contenu du message]\nClient: .\nServeur: 250 Message accept\u00e9\n</code></pre> <p>Chemin d\u2019apprentissage : - Comprendre la s\u00e9paration entre l\u2019envoi (SMTP) et la r\u00e9ception/lecture (IMAP/POP). - \u00c9tudier les ports utilis\u00e9s (avec ou sans chiffrement). - Introduire des notions de s\u00e9curit\u00e9 comme SPF, DKIM et DMARC pour la lutte contre le spam et l\u2019usurpation d\u2019adresse.</p>"},{"location":"_projects/_formation-nginx/nginx-chap02/#ftp-file-transfer-protocol","title":"FTP (File Transfer Protocol)","text":"<p>FTP permet le transfert de fichiers entre client et serveur sur un r\u00e9seau TCP/IP. Historiquement tr\u00e8s utilis\u00e9 pour la mise en ligne de sites Web ou le partage de fichiers dans des contextes professionnels.</p> <p>Caract\u00e9ristiques : - Fonctionne en mode commande et mode donn\u00e9es, souvent sur des ports distincts. - Propose des op\u00e9rations telles que le listage de r\u00e9pertoires, l\u2019envoi et la r\u00e9cup\u00e9ration de fichiers, la suppression, etc. - N\u2019int\u00e8gre pas nativement le chiffrement, ce qui a conduit \u00e0 des variantes s\u00e9curis\u00e9es comme FTPS (FTP sur TLS) ou \u00e0 des alternatives comme SFTP (bas\u00e9 sur SSH).</p> <p>Chemin d\u2019apprentissage : - \u00c9tudier les modes actif et passif et leur impact sur les pare\u2011feu. - Observer la diff\u00e9rence entre FTP, FTPS et SFTP. - Comprendre les implications de s\u00e9curit\u00e9 li\u00e9es \u00e0 l\u2019absence de chiffrement dans FTP simple.</p>"},{"location":"_projects/_formation-nginx/nginx-chap02/#securisation-des-echanges-ssl-et-tls","title":"S\u00e9curisation des \u00e9changes : SSL et TLS \ud83d\udd10","text":"<p>SSL (Secure Sockets Layer) et surtout TLS (Transport Layer Security, successeur de SSL) ajoutent une couche de s\u00e9curit\u00e9 par\u2011dessus les protocoles de transport, en chiffrant les communications et en authentifiant les parties.</p> <p>Objectifs de TLS : - Confidentialit\u00e9 : le contenu \u00e9chang\u00e9 n\u2019est lisible que par les interlocuteurs l\u00e9gitimes. - Int\u00e9grit\u00e9 : les modifications non autoris\u00e9es sont d\u00e9tect\u00e9es. - Authentification : le serveur (et parfois le client) d\u00e9montre son identit\u00e9 via des certificats num\u00e9riques.</p> <p>M\u00e9canismes principaux : - N\u00e9gociation de versions et de suites cryptographiques (choix des algorithmes). - Utilisation de certificats X.509 sign\u00e9s par une autorit\u00e9 de certification. - \u00c9tablissement d\u2019une cl\u00e9 de session sym\u00e9trique, utilis\u00e9e ensuite pour chiffrer efficacement le flux de donn\u00e9es.</p> <p>Exemples d\u2019usages : - HTTPS : HTTP sur TLS, pour s\u00e9curiser la navigation Web. - SMTPS ou SMTP avec STARTTLS : chiffrement de l\u2019envoi de mail. - FTPS : FTP s\u00e9curis\u00e9 par TLS.</p> <p>Chemin d\u2019apprentissage : - Comprendre la notion de certificat, de cha\u00eene de confiance et d\u2019autorit\u00e9 de certification. - \u00c9tudier la diff\u00e9rence entre SSL (versions obsol\u00e8tes) et TLS (versions modernes). - Examiner le flux d\u2019un handshake TLS et l\u2019\u00e9tablissement de la cl\u00e9 de session.</p>"},{"location":"_projects/_formation-nginx/nginx-chap02/#presentation-du-modele-osi-et-introduction-a-tcpip","title":"Pr\u00e9sentation du mod\u00e8le OSI et introduction \u00e0 TCP/IP \ud83e\uddf1","text":"<p>Pour structurer la compr\u00e9hension des communications, deux mod\u00e8les sont souvent pr\u00e9sent\u00e9s : le mod\u00e8le OSI (th\u00e9orique) et le mod\u00e8le TCP/IP (plus proche d\u2019Internet r\u00e9el). Ils d\u00e9crivent les fonctions des diff\u00e9rentes couches d\u2019un syst\u00e8me de communication.</p>"},{"location":"_projects/_formation-nginx/nginx-chap02/#modele-osi-7-couches","title":"Mod\u00e8le OSI (7 couches)","text":"<p>Le mod\u00e8le OSI d\u00e9finit sept couches, de la plus basse (proche du support physique) \u00e0 la plus haute (proche de l\u2019application) : - Physique : transmission brute de bits sur le m\u00e9dia (c\u00e2ble, fibre, radio). - Liaison de donn\u00e9es : trames, adresses MAC, d\u00e9tection d\u2019erreurs locales. - R\u00e9seau : routage de paquets d\u2019un r\u00e9seau \u00e0 un autre (IP). - Transport : transport fiable ou non, de bout en bout (TCP, UDP, QUIC conceptualis\u00e9). - Session : gestion de sessions de communication, synchronisation. - Pr\u00e9sentation : traduction, chiffrement/d\u00e9chiffrement, compression. - Application : protocoles au service des applications (HTTP, SMTP, FTP, etc.).</p> <p>Ce mod\u00e8le est avant tout un outil p\u00e9dagogique pour s\u00e9parer logiquement les fonctions et comprendre \u00e0 quel niveau se situent les probl\u00e8mes ou les protocoles.</p>"},{"location":"_projects/_formation-nginx/nginx-chap02/#modele-tcpip","title":"Mod\u00e8le TCP/IP","text":"<p>Le mod\u00e8le TCP/IP, historiquement issu du d\u00e9veloppement d\u2019Internet, regroupe certaines couches OSI pour se focaliser sur ce qui est r\u00e9ellement impl\u00e9ment\u00e9 : - Acc\u00e8s r\u00e9seau (ou liaison + physique). - Internet (couche r\u00e9seau), avec IP. - Transport, avec TCP, UDP, QUIC. - Application, englobant les couches session, pr\u00e9sentation et application du mod\u00e8le OSI.</p> <p>Tableau de correspondance simplifi\u00e9 :</p> Mod\u00e8le OSI Mod\u00e8le TCP/IP Exemples de protocoles Application Application HTTP, SMTP, FTP Pr\u00e9sentation Application TLS (dans certains mod\u00e8les) Session Application Contr\u00f4le de session applicative Transport Transport TCP, UDP, QUIC R\u00e9seau Internet IP, ICMP Liaison de donn\u00e9es Acc\u00e8s r\u00e9seau Ethernet, Wi\u2011Fi Physique Acc\u00e8s r\u00e9seau C\u00e2ble cuivre, fibre, radio <p>Chemin d\u2019apprentissage : - Positionner chaque protocole d\u00e9j\u00e0 vu (IP, TCP, UDP, HTTP, SMTP, FTP, TLS) dans l\u2019un ou l\u2019autre mod\u00e8le. - Utiliser ces mod\u00e8les pour raisonner sur les probl\u00e8mes r\u00e9seau : \u00e0 quelle couche se situe une panne ou une configuration erron\u00e9e. - Relier cette vision \u00e0 la configuration concr\u00e8te d\u2019un h\u00f4te (interfaces, routes, pare\u2011feu, services).</p>"},{"location":"_projects/_formation-nginx/nginx-chap02/#le-protocole-dns-et-les-serveurs-dns","title":"Le protocole DNS et les serveurs DNS \ud83e\uddf1\u27a1\ufe0f\ud83d\udd24","text":"<p>DNS (Domain Name System) fournit un service de r\u00e9solution de noms, qui traduit des noms symboliques lisibles (comme <code>www.exemple.com</code>) en adresses IP utilisables par les machines. Sans DNS, il serait n\u00e9cessaire de retenir et saisir directement les adresses IP.</p> <p>Fonctionnement conceptuel : - Le client (r\u00e9solveur) envoie une requ\u00eate DNS, g\u00e9n\u00e9ralement via UDP (parfois TCP pour des r\u00e9ponses volumineuses ou des op\u00e9rations sp\u00e9cifiques). - La requ\u00eate transite d\u2019abord vers un r\u00e9solveur r\u00e9cursif (souvent fourni par le fournisseur d\u2019acc\u00e8s ou configur\u00e9 manuellement comme un service public). - Ce r\u00e9solveur interroge \u00e9ventuellement des serveurs faisant autorit\u00e9 pour les domaines concern\u00e9s, en commen\u00e7ant par la racine, puis les TLD (<code>.com</code>, <code>.org</code>, etc.), puis le domaine sp\u00e9cifique. - Une fois la r\u00e9ponse obtenue, elle est renvoy\u00e9e au client, qui peut la mettre en cache pour acc\u00e9l\u00e9rer les acc\u00e8s ult\u00e9rieurs.</p> <p>Enregistrements principaux : - <code>A</code> : nom de domaine vers adresse IPv4. - <code>AAAA</code> : nom de domaine vers adresse IPv6. - <code>CNAME</code> : alias vers un autre nom. - <code>MX</code> : serveurs de messagerie pour un domaine. - <code>NS</code> : serveurs de noms faisant autorit\u00e9 pour le domaine. - D\u2019autres types existent (TXT, SRV, etc.) pour diverses fonctions.</p> <p>Chemin d\u2019apprentissage : - Comprendre la diff\u00e9rence entre un r\u00e9solveur r\u00e9cursif, un serveur faisant autorit\u00e9 et un cache DNS local. - \u00c9tudier le format des enregistrements DNS courants (A, AAAA, MX, CNAME). - Observer une r\u00e9solution de nom \u00e9tape par \u00e9tape, du cache local aux serveurs de la racine.</p>"},{"location":"_projects/_formation-nginx/nginx-chap02/#integration-dans-un-chemin-dapprentissage-coherent","title":"Int\u00e9gration dans un chemin d\u2019apprentissage coh\u00e9rent \ud83e\udded","text":"<p>Pour un apprentissage progressif en lien avec Nginx et les services Web, un encha\u00eenement logique possible consiste \u00e0 : - Poser les bases avec l\u2019architecture d\u2019Internet, la notion de paquets, d\u2019adressage IP et de routage. - Approfondir les protocoles de transport (TCP, UDP, QUIC) pour comprendre comment les donn\u00e9es HTTP ou FTP sont effectivement livr\u00e9es. - \u00c9tudier ensuite les protocoles applicatifs importants (HTTP, SMTP, FTP), leur syntaxe, leurs codes de statut et leur usage dans des sc\u00e9narios r\u00e9els. - Introduire la s\u00e9curisation via TLS, en reliant directement ces notions \u00e0 HTTPS et aux configurations typiques de serveurs Web modernes. - Apprendre \u00e0 raisonner avec les mod\u00e8les OSI et TCP/IP pour localiser les concepts d\u00e9j\u00e0 abord\u00e9s et diagnostiquer des probl\u00e8mes. - Finalement, comprendre le r\u00f4le essentiel de DNS, qui relie les noms de services \u00e0 leurs adresses IP et conditionne l\u2019accessibilit\u00e9 des sites et services sous Nginx.</p> <p>Cette progression permet de relier chaque brique (adressage, transport, application, s\u00e9curit\u00e9, r\u00e9solution de noms) \u00e0 la mise en place concr\u00e8te de services Web, dont Nginx constitue un composant central.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-nginx/nginx-chap03/","title":"Citations","text":"<ul> <li>https://www.digitalocean.com/community/tutorials/understanding-the-nginx-configuration-file-structure-and-configuration-contexts</li> <li>https://dev.to/kabilan/understanding-nginx-core-contexts-52o8</li> <li>https://www.solo.io/topics/nginx/nginx-configuration</li> <li>https://docs.nginx.com/nginx/admin-guide/basic-functionality/managing-configuration-files/</li> <li>https://nginx.org/en/docs/beginners_guide.html</li> <li>https://docs.nginx.com/waf/policies/directives/</li> <li>https://wisdom.gitbook.io/gyan/nginx/deep-dive-on-nginx-directives</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap03/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 272</li> <li>completion_tokens: 5267</li> <li>total_tokens: 5539</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.079, 'request_cost': 0.006, 'total_cost': 0.086}</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap03/#content","title":"Content","text":"<p>Il n\u2019est actuellement pas possible d\u2019acc\u00e9der aux ressources externes (y compris le site de St\u00e9phane Robert) ni de v\u00e9rifier l\u2019existence des images demand\u00e9es, ce qui emp\u00eache de respecter la contrainte d\u2019utiliser pr\u00e9cis\u00e9ment ces sch\u00e9mas et de valider leurs URLs. Il est en revanche possible de proposer un cours d\u00e9taill\u00e9, structur\u00e9 comme un chapitre complet, avec exemples de configuration, tableaux comparatifs et indications sur les types de sch\u00e9mas \u00e0 rechercher ou \u00e0 r\u00e9aliser autour de NGINX, mais sans int\u00e9grer directement des images ni garantir qu\u2019elles proviennent d\u2019une ressource donn\u00e9e.</p> <p>La suite propose donc une pr\u00e9sentation tr\u00e8s d\u00e9taill\u00e9e des quatre th\u00e8mes demand\u00e9s (d\u00e9marrage/arr\u00eat/rechargement, directives et contextes, architecture, configuration de base) avec un chemin d\u2019apprentissage progressif, des exemples concrets et des formats proches de ce qui serait trouv\u00e9 dans une documentation approfondie. Le ton reste neutre, avec emploi de \u201con\u201d plut\u00f4t que \u201ctu\u201d ou \u201cvous\u201d.</p>"},{"location":"_projects/_formation-nginx/nginx-chap03/#demarrage-arret-et-rechargement-de-nginx","title":"D\u00e9marrage, arr\u00eat et rechargement de NGINX","text":"<p>Cette partie couvre la gestion du cycle de vie du service NGINX : lancement, arr\u00eat, red\u00e9marrage et rechargement de la configuration sans interruption de service.</p>"},{"location":"_projects/_formation-nginx/nginx-chap03/#localisation-des-fichiers-et-processus","title":"Localisation des fichiers et processus","text":"<p>En environnement Linux classique (Debian/Ubuntu, CentOS/RHEL, etc.), on rencontre en g\u00e9n\u00e9ral :</p> <ul> <li>Binaire principal : <code>/usr/sbin/nginx</code> </li> <li>Fichier de configuration principal : <code>/etc/nginx/nginx.conf</code> </li> <li>R\u00e9pertoire de configuration suppl\u00e9mentaire : <code>/etc/nginx/conf.d/</code> et souvent <code>/etc/nginx/sites-available/</code> + <code>/etc/nginx/sites-enabled/</code> </li> <li>PID du processus ma\u00eetre : <code>/run/nginx.pid</code> ou <code>/var/run/nginx.pid</code></li> </ul> <p>Un sch\u00e9ma typique \u00e0 repr\u00e9senter :</p> <ul> <li>Un bloc \u201cnginx master process\u201d qui lit <code>nginx.conf</code>.</li> <li>Des fl\u00e8ches vers plusieurs \u201cworker processes\u201d.</li> <li>Une fl\u00e8che depuis <code>nginx.conf</code> vers des fichiers inclus (<code>conf.d/*.conf</code>, <code>sites-enabled/*</code>).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap03/#commandes-de-base-binaire-nginx","title":"Commandes de base (binaire nginx)","text":"<p>Les commandes directes avec le binaire <code>nginx</code> permettent un contr\u00f4le fin, g\u00e9n\u00e9ralement ex\u00e9cut\u00e9es en tant que root ou via <code>sudo</code> :</p> Bash<pre><code># Lancer NGINX\nsudo nginx\n\n# Sp\u00e9cifier un autre fichier de configuration\nsudo nginx -c /chemin/vers/nginx.conf\n\n# Tester la configuration sans l\u2019appliquer\nsudo nginx -t\nsudo nginx -t -c /chemin/vers/nginx.conf\n\n# Recharger la configuration (gr\u00e2ce au PID)\nsudo nginx -s reload\n\n# Arr\u00eater proprement\nsudo nginx -s quit\n\n# Arr\u00eat imm\u00e9diat (peut interrompre des connexions)\nsudo nginx -s stop\n</code></pre> <p>Chemin d\u2019apprentissage possible \u00e0 ce stade :</p> <ol> <li>Lancer NGINX avec la configuration par d\u00e9faut.  </li> <li>Modifier l\u00e9g\u00e8rement <code>nginx.conf</code> (par exemple la page d\u2019index) et utiliser <code>nginx -t</code> pour valider le fichier.  </li> <li>Utiliser <code>nginx -s reload</code> pour appliquer les changements sans couper les connexions en cours.  </li> <li>Observer avec <code>ps aux | grep nginx</code> la diff\u00e9rence entre le processus ma\u00eetre et les workers.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap03/#gestion-via-systemd-service","title":"Gestion via systemd / service","text":"<p>Dans la plupart des distributions modernes, NGINX est g\u00e9r\u00e9 comme un service systemd :</p> Bash<pre><code># D\u00e9marrage et arr\u00eat\nsudo systemctl start nginx\nsudo systemctl stop nginx\n\n# Red\u00e9marrage complet\nsudo systemctl restart nginx\n\n# Rechargement de la configuration\nsudo systemctl reload nginx\n\n# Activer au d\u00e9marrage\nsudo systemctl enable nginx\n\n# V\u00e9rifier l\u2019\u00e9tat\nsudo systemctl status nginx\n</code></pre> <p>On peut repr\u00e9senter dans un tableau les diff\u00e9rences d\u2019usage :</p> Action Commande nginx directe Commande systemd D\u00e9marrer <code>nginx</code> <code>systemctl start nginx</code> Arr\u00eat propre <code>nginx -s quit</code> <code>systemctl stop nginx</code> Rechargement config <code>nginx -s reload</code> <code>systemctl reload nginx</code> Red\u00e9marrage complet (stop + start) <code>systemctl restart nginx</code> V\u00e9rifier configuration <code>nginx -t</code> (ind\u00e9pendant de systemd) Activer au boot (non applicable) <code>systemctl enable nginx</code> <p>Sch\u00e9ma conseill\u00e9 : - Un rectangle \u201csystemd\u201d qui envoie des signaux (start/stop/reload) au \u201cnginx master process\u201d. - Des fl\u00e8ches du master vers les workers.</p>"},{"location":"_projects/_formation-nginx/nginx-chap03/#bonnes-pratiques-de-manipulation","title":"Bonnes pratiques de manipulation","text":"<ul> <li>Toujours tester la configuration avant un rechargement : <code>nginx -t</code> puis seulement si OK, <code>systemctl reload nginx</code>.  </li> <li>Privil\u00e9gier <code>reload</code> \u00e0 <code>restart</code> pour \u00e9viter les coupures de service.  </li> <li>Utiliser <code>journalctl -u nginx</code> pour analyser les erreurs de d\u00e9marrage ou de configuration.  </li> <li>Conserver un acc\u00e8s shell de secours (par exemple via une seconde session SSH) lors des modifications de configuration, en cas d\u2019erreur qui ferait chuter le service.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap03/#introduction-aux-directives-et-aux-contextes","title":"Introduction aux directives et aux contextes","text":"<p>Un des concepts cl\u00e9s de NGINX repose sur les \u201cdirectives\u201d et les \u201ccontextes\u201d, qui forment une arborescence logique dans les fichiers de configuration.</p>"},{"location":"_projects/_formation-nginx/nginx-chap03/#directives-structure-et-types","title":"Directives : structure et types","text":"<p>Une directive est une instruction de configuration, g\u00e9n\u00e9ralement sous la forme :</p> Nginx Configuration File<pre><code>nom_directive valeur1 valeur2 ... ;\n</code></pre> <p>Exemples classiques :</p> Nginx Configuration File<pre><code>worker_processes auto;\nerror_log /var/log/nginx/error.log warn;\nlisten 80;\nserver_name exemple.com;\nroot /var/www/exemple;\n</code></pre> <p>Caract\u00e9ristiques importantes :</p> <ul> <li>La directive se termine toujours par un point-virgule <code>;</code>.  </li> <li>Selon la directive, il peut y avoir une ou plusieurs valeurs.  </li> <li>Certaines directives sont \u201cscalaires\u201d (une valeur simple), d\u2019autres sont de type \u201cliste\u201d (plusieurs \u00e9l\u00e9ments).</li> </ul> <p>La documentation officielle de NGINX liste pour chaque directive :</p> <ul> <li>Le contexte (ou les contextes) o\u00f9 elle est valide.  </li> <li>Sa syntaxe exacte.  </li> <li>Sa valeur par d\u00e9faut.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap03/#contextes-blocs-hierarchiques","title":"Contextes : blocs hi\u00e9rarchiques","text":"<p>Les contextes sont des blocs d\u00e9limit\u00e9s par des accolades <code>{ }</code>, qui peuvent contenir d\u2019autres directives et contextes.</p> <p>Exemple simplifi\u00e9 d\u2019arborescence :</p> Nginx Configuration File<pre><code># Contexte main (global)\nuser  nginx;\nworker_processes auto;\n\nevents {\n    # Contexte events\n    worker_connections 1024;\n}\n\nhttp {\n    # Contexte http\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    server {\n        # Contexte server (virtuel)\n        listen       80;\n        server_name  exemple.com;\n\n        location / {\n            # Contexte location\n            root   /var/www/exemple;\n            index  index.html index.htm;\n        }\n    }\n}\n</code></pre> <p>Contextes principaux courants :</p> <ul> <li>Contexte \u201cmain\u201d (global) : directives en dehors de tout bloc.  </li> <li><code>events</code> : gestion globale des connexions.  </li> <li><code>http</code> : configuration HTTP/HTTPS.  </li> <li><code>server</code> : virtual host HTTP.  </li> <li><code>location</code> : traitement d\u2019une partie d\u2019URI.  </li> <li><code>upstream</code>, <code>stream</code>, <code>mail</code>, etc. dans des cas plus avanc\u00e9s.</li> </ul> <p>Tableau r\u00e9capitulatif simple :</p> Contexte Parent direct R\u00f4le principal Exemples de directives main (aucun) Param\u00e8tres globaux du serveur <code>user</code>, <code>worker_processes</code> events main Gestion des connexions bas niveau <code>worker_connections</code> http main Configuration HTTP globale <code>include</code>, <code>log_format</code>, <code>sendfile</code> server http H\u00f4te virtuel HTTP <code>listen</code>, <code>server_name</code>, <code>root</code> location server R\u00e8gles par URI / chemin <code>proxy_pass</code>, <code>try_files</code>, <code>root</code> <p>Sch\u00e9ma \u00e0 produire : un diagramme \u201cen arbre\u201d montrant <code>main</code> au sommet, puis <code>events</code> et <code>http</code>, puis sous <code>http</code> plusieurs <code>server</code>, eux-m\u00eames contenant des <code>location</code>.</p>"},{"location":"_projects/_formation-nginx/nginx-chap03/#heritage-et-surcharge","title":"H\u00e9ritage et surcharge","text":"<p>Les contextes forment une hi\u00e9rarchie avec :</p> <ul> <li>H\u00e9ritage : certaines directives d\u00e9finies dans un contexte parent se propagent aux enfants.  </li> <li>Surcharge : si une directive peut \u00eatre red\u00e9finie dans un contexte enfant, la valeur la plus sp\u00e9cifique l\u2019emporte.</li> </ul> <p>Exemple :</p> Nginx Configuration File<pre><code>http {\n    # Active la compression gzip par d\u00e9faut\n    gzip on;\n\n    server {\n        # H\u00e9rite de gzip on;\n        server_name exemple1.com;\n\n        location /statique/ {\n            # D\u00e9sactivation ponctuelle\n            gzip off;\n        }\n    }\n\n    server {\n        # H\u00e9rite de gzip on;\n        server_name exemple2.com;\n    }\n}\n</code></pre> <p>Chemin d\u2019apprentissage recommand\u00e9 :</p> <ol> <li>Lire un <code>nginx.conf</code> complet et rep\u00e9rer tous les blocs <code>{}</code> et leur indentation.  </li> <li>Classer manuellement quelques directives dans un tableau indiquant leur contexte autoris\u00e9.  </li> <li>Exp\u00e9rimenter avec l\u2019h\u00e9ritage : d\u00e9finir une directive dans <code>http</code> puis la surcharger dans un <code>server</code>, voire un <code>location</code>.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap03/#larchitecture-de-nginx","title":"L\u2019architecture de NGINX","text":"<p>La compr\u00e9hension de l\u2019architecture interne de NGINX permet d\u2019expliquer ses performances et sa mani\u00e8re de g\u00e9rer les connexions.</p>"},{"location":"_projects/_formation-nginx/nginx-chap03/#processus-maitre-et-workers","title":"Processus ma\u00eetre et workers","text":"<p>NGINX utilise un mod\u00e8le multi-processus :</p> <ul> <li>Un processus ma\u00eetre (\u201cmaster process\u201d) :</li> <li>Lit les fichiers de configuration.</li> <li>Ouvre les sockets d\u2019\u00e9coute (ports).  </li> <li>Lance et surveille les workers.  </li> <li> <p>Traite les signaux (reload, stop, etc.).</p> </li> <li> <p>Un ou plusieurs processus travailleurs (\u201cworker processes\u201d) :</p> </li> <li>Acceptent les connexions des clients.</li> <li>Traitent les requ\u00eates HTTP.</li> <li>G\u00e8rent les op\u00e9rations r\u00e9seau (event-driven, non bloquant).</li> </ul> <p>Sch\u00e9ma typique :</p> <ul> <li>En haut : \u201cnginx master process (PID X)\u201d connect\u00e9 \u00e0 <code>nginx.conf</code>.  </li> <li>En bas : plusieurs bo\u00eetes \u201cworker process 1\u201d, \u201cworker process 2\u201d, etc.  </li> <li>Des fl\u00e8ches des clients (navigateurs) qui arrivent vers les workers via les ports 80/443.</li> </ul> <p>Configuration correspondante :</p> Nginx Configuration File<pre><code># Dans le contexte main\nuser  nginx;\nworker_processes  auto;\n\nevents {\n    worker_connections  1024;\n}\n</code></pre> <ul> <li><code>worker_processes auto;</code> demande \u00e0 NGINX de choisir un nombre de workers adapt\u00e9 (souvent \u00e9gal au nombre de c\u0153urs CPU).  </li> <li><code>worker_connections</code> d\u00e9finit le nombre de connexions simultan\u00e9es par worker.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap03/#modele-evenementiel-event-driven","title":"Mod\u00e8le \u00e9v\u00e9nementiel (event-driven)","text":"<p>NGINX est con\u00e7u autour d\u2019un mod\u00e8le \u00e9v\u00e9nementiel asynchrone :</p> <ul> <li>Chaque worker utilise un m\u00e9canisme comme <code>epoll</code> (Linux) ou <code>kqueue</code> (BSD) pour g\u00e9rer un grand nombre de connexions sans bloquer.  </li> <li>Un worker peut ainsi g\u00e9rer des milliers de connexions simultan\u00e9es.</li> </ul> <p>Dans <code>events</code> :</p> Nginx Configuration File<pre><code>events {\n    worker_connections 4096;\n    # event model automatique par d\u00e9faut (epoll, etc.)\n}\n</code></pre> <p>Un sch\u00e9ma utile : - Un worker process reli\u00e9 \u00e0 une file d\u2019\u00e9v\u00e9nements \u201cepoll\u201d avec plusieurs sockets client. - Des fl\u00e8ches montrant que tous les sockets sont g\u00e9r\u00e9s par une seule boucle d\u2019\u00e9v\u00e9nements.</p>"},{"location":"_projects/_formation-nginx/nginx-chap03/#modules-et-pipeline-de-traitement","title":"Modules et pipeline de traitement","text":"<p>NGINX est modulaire. Il existe plusieurs cat\u00e9gories de modules :</p> <ul> <li>Modules \u201ccore\u201d (g\u00e9r\u00e9s dans le code principal).  </li> <li>Modules HTTP (ex : <code>http_proxy</code>, <code>http_gzip_static</code>, <code>http_ssl</code>).  </li> <li>Modules stream, mail, etc.</li> </ul> <p>Dans une requ\u00eate HTTP typique :</p> <ol> <li>Le worker re\u00e7oit la requ\u00eate.  </li> <li>Une phase de \u201crewrite\u201d peut modifier l\u2019URI.  </li> <li>La phase de s\u00e9lection de <code>server</code>/<code>location</code> choisit le bloc appropri\u00e9.  </li> <li>Selon la configuration, la requ\u00eate peut :</li> <li>Servir un fichier statique (<code>root</code>, <code>try_files</code>).  </li> <li>\u00catre proxyfi\u00e9e vers un backend (<code>proxy_pass</code>).  </li> <li>\u00catre transmise \u00e0 FastCGI (<code>fastcgi_pass</code>), etc.  </li> <li>Les modules de logging et de filtres (compression, headers) interviennent avant la r\u00e9ponse.</li> </ol> <p>Exemple minimal de proxy :</p> Nginx Configuration File<pre><code>http {\n    upstream backend_app {\n        server 127.0.0.1:3000;\n        server 127.0.0.1:3001;\n    }\n\n    server {\n        listen 80;\n        server_name api.exemple.com;\n\n        location / {\n            proxy_pass http://backend_app;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n        }\n    }\n}\n</code></pre> <p>Sch\u00e9ma possible :</p> <ul> <li>\u00c0 gauche : clients.  </li> <li>Au centre : NGINX (workers).  </li> <li>\u00c0 droite : plusieurs serveurs backend (upstream).  </li> <li>Fl\u00e8ches montrant le routage des requ\u00eates.</li> </ul> <p>Chemin d\u2019apprentissage pour cette section :</p> <ol> <li>Lister les processus via <code>ps</code> pour voir le ma\u00eetre et les workers.  </li> <li>Modifier <code>worker_processes</code> et <code>worker_connections</code>, faire des tests de charge (avec un outil simple comme <code>ab</code> ou <code>wrk</code>).  </li> <li>Introduire un <code>upstream</code> et un <code>proxy_pass</code> et observer la r\u00e9partition de charge.  </li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap03/#la-configuration-de-base-de-nginx","title":"La configuration de base de NGINX","text":"<p>Cette section montre comment passer d\u2019une configuration par d\u00e9faut \u00e0 une configuration de base propre pour servir un site statique simple et introduire quelques notions essentielles.</p>"},{"location":"_projects/_formation-nginx/nginx-chap03/#structure-classique-des-fichiers","title":"Structure classique des fichiers","text":"<p>Sur Debian/Ubuntu, on rencontre g\u00e9n\u00e9ralement :</p> <ul> <li><code>/etc/nginx/nginx.conf</code> : fichier principal.  </li> <li><code>/etc/nginx/conf.d/*.conf</code> : configurations globales additionnelles.  </li> <li><code>/etc/nginx/sites-available/</code> : fichiers de configuration de sites (virtuel hosts).  </li> <li><code>/etc/nginx/sites-enabled/</code> : liens symboliques vers les sites actifs.</li> </ul> <p>Exemple de <code>nginx.conf</code> minimaliste :</p> Nginx Configuration File<pre><code>user  www-data;\nworker_processes auto;\npid /run/nginx.pid;\n\nevents {\n    worker_connections 1024;\n}\n\nhttp {\n    include       /etc/nginx/mime.types;\n    default_type  application/octet-stream;\n\n    sendfile        on;\n    keepalive_timeout 65;\n\n    include /etc/nginx/conf.d/*.conf;\n    include /etc/nginx/sites-enabled/*;\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap03/#configuration-dun-serveur-simple-site-statique","title":"Configuration d\u2019un serveur simple (site statique)","text":"<p>Un fichier <code>/etc/nginx/sites-available/mon_site</code> peut contenir :</p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name monsite.local;\n\n    root /var/www/monsite;\n    index index.html index.htm;\n\n    access_log /var/log/nginx/monsite.access.log;\n    error_log  /var/log/nginx/monsite.error.log;\n\n    location / {\n        try_files $uri $uri/ =404;\n    }\n}\n</code></pre> <p>\u00c9tapes concr\u00e8tes :</p> <ol> <li>Cr\u00e9er un r\u00e9pertoire <code>/var/www/monsite</code> et y placer un <code>index.html</code>.  </li> <li>Cr\u00e9er le fichier de configuration du site dans <code>sites-available</code>.  </li> <li>Cr\u00e9er un lien symbolique dans <code>sites-enabled</code> : <code>sudo ln -s /etc/nginx/sites-available/monsite /etc/nginx/sites-enabled/monsite</code> </li> <li>Tester la configuration : <code>sudo nginx -t</code>.  </li> <li>Recharger : <code>sudo systemctl reload nginx</code>.</li> </ol> <p>Tableau d\u2019explication des directives de ce <code>server</code> :</p> Directive R\u00f4le <code>listen</code> Port (et \u00e9ventuellement IP) d\u2019\u00e9coute. <code>server_name</code> Nom(s) de domaine correspondant \u00e0 ce virtual host. <code>root</code> R\u00e9pertoire racine des fichiers statiques. <code>index</code> Nom(s) des fichiers d\u2019index par d\u00e9faut. <code>access_log</code> Fichier de log des requ\u00eates trait\u00e9es. <code>error_log</code> Fichier de log des erreurs. <code>location /</code> Bloc d\u00e9finissant le comportement pour l\u2019URI racine. <code>try_files</code> Tentative de servir un fichier/chemin donn\u00e9, sinon retourner un code."},{"location":"_projects/_formation-nginx/nginx-chap03/#ajout-du-http-https-base","title":"Ajout du HTTP \u2192 HTTPS (base)","text":"<p>Une configuration de base pour activer HTTPS suppose des certificats valides (par exemple via Let\u2019s Encrypt) :</p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name monsite.exemple;\n\n    # Redirection HTTP -&gt; HTTPS\n    return 301 https://$host$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    server_name monsite.exemple;\n\n    ssl_certificate     /etc/letsencrypt/live/monsite.exemple/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/monsite.exemple/privkey.pem;\n\n    root /var/www/monsite;\n    index index.html;\n\n    location / {\n        try_files $uri $uri/ =404;\n    }\n}\n</code></pre> <p>Points importants \u00e0 assimiler :</p> <ul> <li>Le premier <code>server</code> \u00e9coute en HTTP et redirige tout vers HTTPS.  </li> <li>Le second <code>server</code> est en HTTPS, avec directives <code>ssl_certificate</code> et <code>ssl_certificate_key</code>.  </li> </ul> <p>Sch\u00e9ma recommand\u00e9 : - Un client qui interroge <code>http://</code> redirig\u00e9 vers <code>https://</code>. - Deux blocs <code>server</code> indiquant 80 et 443.</p>"},{"location":"_projects/_formation-nginx/nginx-chap03/#journalisation-logs-et-formats","title":"Journalisation (logs) et formats","text":"<p>NGINX permet de configurer les logs d\u2019acc\u00e8s et d\u2019erreur :</p> Nginx Configuration File<pre><code>http {\n    log_format main '$remote_addr - $remote_user [$time_local] \"$request\" '\n                    '$status $body_bytes_sent \"$http_referer\" '\n                    '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n\n    access_log /var/log/nginx/access.log main;\n\n    server {\n        # ...\n        access_log /var/log/nginx/monsite.access.log main;\n        error_log  /var/log/nginx/monsite.error.log warn;\n    }\n}\n</code></pre> <p>Chemin d\u2019apprentissage :</p> <ol> <li>Cr\u00e9er un premier site statique en HTTP.  </li> <li>Activer la redirection HTTP \u2192 HTTPS et d\u00e9ployer un certificat.  </li> <li>Configurer des logs d\u00e9di\u00e9s et analyser quelques entr\u00e9es (codes de statut, IP).  </li> <li>Varier <code>index</code>, <code>root</code> et <code>location</code> pour observer l\u2019impact sur la r\u00e9solution des fichiers.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap03/#chemin-dapprentissage-detaille-pour-lensemble-du-chapitre","title":"Chemin d\u2019apprentissage d\u00e9taill\u00e9 pour l\u2019ensemble du chapitre","text":"<p>M\u00eame si le contenu ci\u2011dessus est organis\u00e9 par th\u00e8mes, il est possible de les parcourir dans un ordre progressif pour construire une compr\u00e9hension solide.</p>"},{"location":"_projects/_formation-nginx/nginx-chap03/#etape-1-manipuler-le-service-nginx","title":"\u00c9tape 1 : Manipuler le service NGINX","text":"<p>Objectif : ma\u00eetriser les d\u00e9marrages, arr\u00eats et rechargements sans crainte.</p> <ul> <li>Identifier la distribution utilis\u00e9e et v\u00e9rifier si <code>systemctl</code> est disponible.  </li> <li>Apprendre par c\u0153ur les commandes :</li> <li><code>nginx -t</code>, <code>nginx -s reload</code>, <code>systemctl reload nginx</code>.  </li> <li>Faire de petits changements contr\u00f4l\u00e9s (modifier la page d\u2019index) et tester/recharger.  </li> <li>Observer les logs (<code>journalctl -u nginx</code>, <code>/var/log/nginx/error.log</code>) lors d\u2019erreurs de syntaxe.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap03/#etape-2-lire-et-comprendre-la-structure-de-nginxconf","title":"\u00c9tape 2 : Lire et comprendre la structure de <code>nginx.conf</code>","text":"<p>Objectif : \u00eatre capable d\u2019ouvrir n\u2019importe quel fichier de configuration et en comprendre les grands blocs.</p> <ul> <li>Ouvrir <code>/etc/nginx/nginx.conf</code> et rep\u00e9rer :</li> <li>Le contexte global (directives en haut).  </li> <li>Le bloc <code>events</code>.  </li> <li>Le bloc <code>http</code>, les includes (<code>conf.d</code>, <code>sites-enabled</code>).  </li> <li>Dessiner l\u2019arborescence des contextes sur papier (ou outil de diagramme).  </li> <li>Ajouter une directive simple dans <code>http</code> (par exemple un nouveau <code>log_format</code>) et observer son h\u00e9ritage dans les <code>server</code>.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap03/#etape-3-travailler-les-directives-et-contextes","title":"\u00c9tape 3 : Travailler les directives et contextes","text":"<p>Objectif : comprendre quelles directives peuvent \u00eatre utilis\u00e9es o\u00f9, et comment l\u2019h\u00e9ritage fonctionne.</p> <ul> <li>Choisir quelques directives clefs : <code>root</code>, <code>index</code>, <code>access_log</code>, <code>error_log</code>, <code>listen</code>, <code>server_name</code>, <code>try_files</code>, <code>proxy_pass</code>.  </li> <li>Pour chacune, noter :</li> <li>Contextes autoris\u00e9s (http, server, location, etc.).  </li> <li>Valeur par d\u00e9faut (si connue).  </li> <li>Faire des essais :</li> <li>D\u00e9finir <code>root</code> dans <code>http</code> et le red\u00e9finir dans un <code>server</code>.  </li> <li>D\u00e9finir <code>access_log</code> dans <code>http</code> puis le d\u00e9sactiver (<code>off</code>) dans un <code>location</code> pr\u00e9cis.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap03/#etape-4-decouvrir-larchitecture-interne","title":"\u00c9tape 4 : D\u00e9couvrir l\u2019architecture interne","text":"<p>Objectif : lier ce qui est dans la configuration \u00e0 ce qui tourne r\u00e9ellement sur la machine.</p> <ul> <li>Lancer NGINX puis utiliser <code>ps</code> ou <code>pgrep</code> pour voir le master et les workers.  </li> <li>Modifier <code>worker_processes</code> (par exemple <code>1</code>, <code>2</code>, <code>auto</code>) et observer le nombre de workers.  </li> <li>Ex\u00e9cuter une l\u00e9g\u00e8re charge (par exemple acc\u00e9der \u00e0 une page en boucle, ou utiliser un outil simple de test de charge) et observer la consommation CPU/m\u00e9moire par worker.  </li> <li>Lire une documentation de haut niveau sur le mod\u00e8le \u201cevent\u2011driven\u201d pour mieux comprendre la diff\u00e9rence avec un serveur multi\u2011thread classique.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap03/#etape-5-construire-une-configuration-de-base-solide","title":"\u00c9tape 5 : Construire une configuration de base solide","text":"<p>Objectif : poss\u00e9der un squelette de configuration r\u00e9utilisable.</p> <ul> <li>Partir d\u2019un <code>nginx.conf</code> minimal et le compl\u00e9ter avec :</li> <li><code>worker_processes auto;</code> </li> <li><code>events { worker_connections 1024; }</code> </li> <li><code>http { ... }</code> avec <code>sendfile on;</code>, <code>keepalive_timeout</code>, logs, includes.  </li> <li>Cr\u00e9er un fichier de site dans <code>sites-available</code> et le lier dans <code>sites-enabled</code>.  </li> <li>Tester le comportement pour diff\u00e9rents fichiers :</li> <li>Fichiers statiques (HTML, CSS, images).  </li> <li>Fichier inexistant pour voir la page 404.  </li> <li>Ajouter une redirection HTTPS et (facultatif) introduire un <code>upstream</code> vers une application.</li> </ul> <p>Ce chapitre pos\u00e9, l\u2019\u00e9tape suivante dans un cursus NGINX consisterait \u00e0 approfondir progressivement les modules HTTP (proxy, cache, rewrite), la s\u00e9curit\u00e9 (TLS, en-t\u00eates, rate limiting) et l\u2019observabilit\u00e9 (logs avanc\u00e9s, m\u00e9triques), en s\u2019appuyant sur les m\u00e9canismes vus ici : gestion du service, structure des contextes, architecture processeur/\u00e9v\u00e9nements et configuration de base r\u00e9utilisable.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-nginx/nginx-chap04/","title":"Citations","text":"<ul> <li>https://blog.stephane-robert.info/docs/services/web/nginx/</li> <li>https://blent.ai/blog/a/nginx-tout-savoir</li> <li>https://grafikart.fr/tutoriels/nginx-692</li> <li>https://datascientest.com/nginx-tout-savoir</li> <li>https://www.ionos.fr/digitalguide/serveur/configuration/tutoriel-nginx-premiers-pas-avec-nginxconf/</li> <li>https://experienceleague.adobe.com/fr/docs/commerce-operations/configuration-guide/multi-sites/ms-nginx</li> <li>https://www.it-connect.fr/cours-tutoriels/administration-systemes/serveur-web/tutoriels-nginx/</li> <li>https://www.serverion.com/fr/3cx-hosting-pbx/mastering-nginx-configurations-for-optimal-web-server-performance/</li> <li>https://openclassrooms.com/fr/courses/4425101-deployez-une-application-django/4688553-utilisez-le-serveur-http-nginx</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap04/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 289</li> <li>completion_tokens: 5289</li> <li>total_tokens: 5578</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.079, 'request_cost': 0.006, 'total_cost': 0.086}</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap04/#content","title":"Content","text":"<p>Nginx est con\u00e7u pour \u00eatre un serveur HTTP tr\u00e8s modulaire\u202f: la plupart des fonctionnalit\u00e9s utiles \u00e0 un \u201csimple\u201d serveur Web reposent sur quelques directives cl\u00e9s (server, location, root, index, try_files, return, rewrite, error_page, variables, etc.). L\u2019objectif ci\u2011dessous est de proposer un parcours d\u2019apprentissage progressif, en expliquant chaque notion en d\u00e9tail, avec des exemples concrets en configuration.  </p> <p>Les images ou sch\u00e9mas externes ne peuvent malheureusement pas \u00eatre import\u00e9s ou v\u00e9rifi\u00e9s ici ; en revanche, chaque bloc de configuration est pr\u00e9sent\u00e9 de fa\u00e7on \u00e0 pouvoir \u00eatre recopi\u00e9 et test\u00e9 directement dans un environnement Nginx.</p>"},{"location":"_projects/_formation-nginx/nginx-chap04/#preambule-structure-dun-serveur-web-nginx","title":"Pr\u00e9ambule : structure d\u2019un serveur web Nginx","text":"<p>Un serveur Web Nginx typique pour des fichiers statiques se d\u00e9finit dans un bloc <code>server</code> \u00e0 l\u2019int\u00e9rieur du bloc <code>http</code> de <code>nginx.conf</code> (ou d\u2019un fichier inclus, par exemple dans <code>sites-enabled</code>).  </p> <p>Exemple minimaliste\u202f:</p> Nginx Configuration File<pre><code>http {\n    server {\n        listen 80;\n        server_name exemple.local;\n\n        root /var/www/exemple;\n        index index.html index.htm;\n\n        location / {\n            try_files $uri $uri/ =404;\n        }\n    }\n}\n</code></pre> <p>Dans ce contexte, les notions suivantes seront d\u00e9taill\u00e9es\u202f:</p> <ul> <li>S\u00e9lection de serveurs (<code>server_name</code>, <code>listen</code>, ordre de s\u00e9lection).</li> <li><code>location</code> et le routage par URI.</li> <li><code>root</code> et son interaction avec <code>location</code>.</li> <li><code>index</code> pour les fichiers par d\u00e9faut.</li> <li><code>try_files</code> pour tester plusieurs chemins.</li> <li>Les variables (standards et personnalis\u00e9es).</li> <li><code>return</code> et les redirections.</li> <li>Les r\u00e9\u00e9critures d\u2019URI (<code>rewrite</code>).</li> <li>Les r\u00e9\u00e9critures de r\u00e9ponses HTTP (filtrage, headers, sous\u2011requ\u00eates).</li> <li><code>error_page</code> pour le traitement fin des erreurs.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap04/#la-selection-de-serveurs","title":"La s\u00e9lection de serveurs","text":"<p>Nginx choisit d\u2019abord un bloc <code>server</code> parmi tous ceux disponibles dans le bloc <code>http</code>, en fonction de\u202f:</p> <ul> <li>L\u2019adresse/port (<code>listen</code>).</li> <li>Le nom d\u2019h\u00f4te (<code>Host</code>) via <code>server_name</code>.</li> <li>Des r\u00e8gles de priorit\u00e9 (serveur par d\u00e9faut, correspondances exactes, jokers, regex, etc.).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap04/#directive-listen","title":"Directive listen","text":"Nginx Configuration File<pre><code>server {\n    listen 80;                # \u00e9coute sur 0.0.0.0:80 (toutes les IP IPv4)\n    server_name exemple.local;\n}\n</code></pre> <p>Points importants\u202f:</p> <ul> <li><code>listen 80;</code> signifie \u201ctoutes les interfaces IPv4 sur le port 80\u201d.</li> <li><code>listen 127.0.0.1:8080 default_server;</code> cr\u00e9e un serveur \u201cpar d\u00e9faut\u201d pour cette IP/port.</li> <li>Il est possible de combiner IPv4 et IPv6\u202f:</li> </ul> Nginx Configuration File<pre><code>server {\n    listen 80;\n    listen [::]:80;\n    server_name exemple.local;\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap04/#directive-server_name-et-ordre-de-selection","title":"Directive server_name et ordre de s\u00e9lection","text":"<p>Le <code>Host</code> de la requ\u00eate HTTP est compar\u00e9 \u00e0 <code>server_name</code> pour trouver le meilleur match\u202f:</p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name exemple.com www.exemple.com;\n    # ...\n}\n\nserver {\n    listen 80;\n    server_name api.exemple.com;\n    # ...\n}\n</code></pre> <p>S\u00e9lection\u202f:</p> <ul> <li>Une requ\u00eate avec <code>Host: exemple.com</code> atterrit dans le premier <code>server</code>.</li> <li>Une requ\u00eate avec <code>Host: api.exemple.com</code> va dans le deuxi\u00e8me.</li> <li>S\u2019il n\u2019y a pas de correspondance, Nginx utilise le <code>default_server</code> pour cette adresse/port.</li> </ul> <p>Exemple de serveur par d\u00e9faut\u202f:</p> Nginx Configuration File<pre><code>server {\n    listen 80 default_server;\n    server_name _;           # convention souvent utilis\u00e9e\n    return 444;\n}\n</code></pre> <p>Parcours d\u2019apprentissage recommand\u00e9 pour cette partie\u202f:</p> <ol> <li>Cr\u00e9er deux blocs <code>server</code> \u00e9coutant sur le m\u00eame port avec des <code>server_name</code> diff\u00e9rents.</li> <li>Tester avec <code>curl -H \"Host: ...\" http://127.0.0.1/</code> pour v\u00e9rifier quel bloc est utilis\u00e9.</li> <li>Ajouter ou retirer <code>default_server</code> pour voir le comportement en absence de correspondance.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap04/#configuration-des-emplacements-avec-location","title":"Configuration des emplacements avec location","text":"<p>Une fois le bloc <code>server</code> choisi, Nginx s\u00e9lectionne un bloc <code>location</code> en fonction de l\u2019URI. Chaque <code>location</code> d\u00e9crit comment traiter une portion d\u2019URI.</p>"},{"location":"_projects/_formation-nginx/nginx-chap04/#types-de-location","title":"Types de location","text":"<ol> <li>Pr\u00e9fixe simple\u202f: <code>location /images/ { ... }</code></li> <li>Pr\u00e9fixe exact\u202f: <code>location = / { ... }</code></li> <li>Regex\u202f:  </li> <li><code>location ~ \\.php$ { ... }</code> (sensible \u00e0 la casse)  </li> <li><code>location ~* \\.(jpg|jpeg|png)$ { ... }</code> (insensible \u00e0 la casse)</li> <li>Pr\u00e9fixe avec recherche \u201cla plus longue\u201d\u202f: <code>location /static/ { ... }</code></li> </ol> <p>Exemple complet\u202f:</p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name exemple.local;\n    root /var/www/exemple;\n\n    # URI exacte \"/\"\n    location = / {\n        index index.html;\n    }\n\n    # Toutes les URI commen\u00e7ant par /images/\n    location /images/ {\n        autoindex on;\n    }\n\n    # Fichiers .php\n    location ~ \\.php$ {\n        include fastcgi_params;\n        fastcgi_pass unix:/run/php/php-fpm.sock;\n        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n    }\n\n    # Fichier sp\u00e9cifique\n    location = /sante {\n        return 200 \"OK\";\n    }\n\n    # Default\n    location / {\n        try_files $uri $uri/ =404;\n    }\n}\n</code></pre> <p>Ordre de s\u00e9lection\u202f:</p> <ol> <li><code>location =</code> (exacte) si correspondance.</li> <li>Toutes les <code>location</code> pr\u00e9fixes, choisir la plus longue.</li> <li><code>location ~</code> / <code>~*</code> si aucune pr\u00e9fixe plus sp\u00e9cifique ne s\u2019applique, selon les r\u00e8gles de priorit\u00e9.</li> <li><code>location /</code> sert de \u201cfallback\u201d global.</li> </ol> <p>Chemin d\u2019apprentissage\u202f:</p> <ul> <li>D\u00e9finir une <code>location /</code> par d\u00e9faut, puis ajouter des <code>location /static/</code> et <code>location /images/</code>.</li> <li>Observer quelle <code>location</code> est choisie en consultant les logs (<code>access_log</code>) avec diff\u00e9rents chemins.</li> <li>Introduire une <code>location = /sante</code> et v\u00e9rifier qu\u2019elle prend le dessus sur <code>location /</code>.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap04/#la-directive-root","title":"La directive root","text":"<p><code>root</code> d\u00e9finit le r\u00e9pertoire racine du syst\u00e8me de fichiers \u00e0 partir duquel Nginx traduit une URI en chemin r\u00e9el.</p>"},{"location":"_projects/_formation-nginx/nginx-chap04/#portee-de-root","title":"Port\u00e9e de root","text":"<ul> <li><code>root</code> peut \u00eatre d\u00e9clar\u00e9 dans le bloc <code>http</code>, <code>server</code> ou <code>location</code>.</li> <li>Une d\u00e9finition dans un <code>location</code> \u00e9crase celle du <code>server</code> (pour ce <code>location</code>).</li> </ul> <p>Exemple\u202f:</p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name exemple.local;\n    root /var/www/exemple;\n\n    location / {\n        # root = /var/www/exemple\n    }\n\n    location /images/ {\n        root /data;   # diff\u00e9rent\n    }\n}\n</code></pre> <p>Traduction\u202f:</p> <ul> <li>Requ\u00eate\u202f: <code>GET /index.html</code>   \u2192 chemin\u202f: <code>/var/www/exemple/index.html</code></li> <li>Requ\u00eate\u202f: <code>GET /images/logo.png</code>   \u2192 chemin\u202f: <code>/data/images/logo.png</code></li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap04/#difference-root-alias","title":"Diff\u00e9rence root / alias","text":"<p>M\u00eame si <code>alias</code> ne fait pas partie explicite de la liste, il est crucial de comprendre sa diff\u00e9rence avec <code>root</code>\u202f:</p> Nginx Configuration File<pre><code>location /images/ {\n    root /data;\n    # /images/logo.png -&gt; /data/images/logo.png\n}\n\nlocation /photos/ {\n    alias /data/images/;\n    # /photos/logo.png -&gt; /data/images/logo.png\n}\n</code></pre> <ul> <li>Avec <code>root</code>, l\u2019URI compl\u00e8te est concat\u00e9n\u00e9e apr\u00e8s le chemin.</li> <li>Avec <code>alias</code>, la partie de l\u2019URI correspondant au pr\u00e9fixe <code>location</code> est remplac\u00e9e par le chemin fourni.</li> </ul> <p>Chemin d\u2019apprentissage\u202f:</p> <ol> <li>Cr\u00e9er un dossier <code>/var/www/exemple</code> avec <code>index.html</code> et <code>images/</code> \u00e0 l\u2019int\u00e9rieur.</li> <li>Modifier <code>root</code> au niveau du <code>server</code> puis au niveau de <code>location /images/</code> pour comprendre la traduction des chemins.</li> <li>Introduire <code>alias</code> pour voir la diff\u00e9rence avec <code>root</code>.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap04/#la-directive-index","title":"La directive index","text":"<p><code>index</code> d\u00e9finit la liste des fichiers que Nginx essaie automatiquement lorsqu\u2019une URI cible un r\u00e9pertoire (ou une URI se terminant par <code>/</code>).</p> <p>Exemple\u202f:</p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name exemple.local;\n    root /var/www/exemple;\n\n    index index.html index.htm index.php;\n\n    location / {\n        try_files $uri $uri/ =404;\n    }\n}\n</code></pre> <p>Comportement\u202f:</p> <ul> <li>Requ\u00eate\u202f: <code>GET /</code>   \u2192 Nginx teste successivement\u202f: <code>/var/www/exemple/index.html</code>, puis <code>index.htm</code>, puis <code>index.php</code>.</li> <li>Requ\u00eate\u202f: <code>GET /blog/</code>   \u2192 M\u00eame logique dans <code>/var/www/exemple/blog/</code>.</li> </ul> <p><code>index</code> peut \u00eatre sp\u00e9cifi\u00e9 par <code>location</code>\u202f:</p> Nginx Configuration File<pre><code>location /admin/ {\n    index admin.html;\n}\n</code></pre> <p>Chemin d\u2019apprentissage\u202f:</p> <ul> <li>Cr\u00e9er plusieurs fichiers d\u2019index (par exemple <code>index.html</code> et <code>index.htm</code>) et modifier l\u2019ordre dans la directive <code>index</code>.</li> <li>Supprimer tous les fichiers d\u2019index pour voir le comportement (en g\u00e9n\u00e9ral 403 si autoindex d\u00e9sactiv\u00e9, ou 404/403 selon la config).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap04/#la-directive-try_files","title":"La directive try_files","text":"<p><code>try_files</code> permet de tester plusieurs chemins (fichiers ou r\u00e9pertoires) dans un ordre donn\u00e9 et de choisir la premi\u00e8re correspondance r\u00e9elle, sinon de passer \u00e0 un fallback (URI, code, etc.). C\u2019est un outil cl\u00e9 pour les applications web (SPA, frameworks, etc.).</p> <p>Exemple typique pour un site statique ou une SPA\u202f:</p> Nginx Configuration File<pre><code>location / {\n    try_files $uri $uri/ /index.html;\n}\n</code></pre> <p>Explication\u202f:</p> <ul> <li><code>$uri</code> correspond au chemin demand\u00e9 (par exemple <code>/css/style.css</code>).</li> <li><code>$uri/</code> permet de tester le m\u00eame chemin comme r\u00e9pertoire.</li> <li>Si aucun fichier n\u2019existe, Nginx sert <code>/index.html</code>.</li> </ul> <p>Exemple pour un site dynamique en PHP\u202f:</p> Nginx Configuration File<pre><code>location / {\n    try_files $uri $uri/ /index.php$is_args$args;\n}\n</code></pre> <p>Ici, si le fichier ou le r\u00e9pertoire n\u2019existe pas, la requ\u00eate est finalement rout\u00e9e vers <code>/index.php</code> avec les param\u00e8tres de requ\u00eate d\u2019origine.</p> <p>Exemple avec code de retour\u202f:</p> Nginx Configuration File<pre><code>location / {\n    try_files $uri $uri/ =404;\n}\n</code></pre> <p>Chemin d\u2019apprentissage\u202f:</p> <ol> <li>Mettre en place <code>try_files $uri $uri/ =404;</code> dans <code>location /</code>.</li> <li>Cr\u00e9er un sous\u2011r\u00e9pertoire et v\u00e9rifier les cas fichiers existants / non existants.</li> <li>Adapter <code>try_files</code> pour une SPA (tout renvoyer vers <code>index.html</code> sauf les assets statiques).</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap04/#les-variables","title":"Les variables","text":"<p>Nginx fournit un ensemble riche de variables int\u00e9gr\u00e9es, et il est possible d\u2019en d\u00e9finir via <code>set</code> ou des directives comme <code>map</code>. Les variables sont utilisables dans de nombreuses directives (<code>root</code>, <code>proxy_pass</code>, <code>rewrite</code>, <code>log_format</code>, etc.).</p>"},{"location":"_projects/_formation-nginx/nginx-chap04/#variables-integrees-courantes","title":"Variables int\u00e9gr\u00e9es courantes","text":"<p>Quelques variables utiles dans un contexte de serveur Web\u202f:</p> <ul> <li><code>$uri</code>\u202f: chemin de la requ\u00eate, normalis\u00e9 (sans arguments).</li> <li><code>$request_uri</code>\u202f: URI telle qu\u2019envoy\u00e9e par le client (avec arguments).</li> <li><code>$args</code>\u202f: cha\u00eene de param\u00e8tres de requ\u00eate (tout apr\u00e8s <code>?</code>).</li> <li><code>$query_string</code>\u202f: alias de <code>$args</code>.</li> <li><code>$host</code>\u202f: valeur du header Host.</li> <li><code>$server_name</code>\u202f: nom du serveur s\u00e9lectionn\u00e9.</li> <li><code>$document_root</code>\u202f: valeur effective de <code>root</code> pour cette requ\u00eate.</li> <li><code>$remote_addr</code>\u202f: adresse IP du client.</li> <li><code>$scheme</code>\u202f: <code>http</code> ou <code>https</code>.</li> </ul> <p>Exemple d\u2019utilisation dans les logs\u202f:</p> Nginx Configuration File<pre><code>http {\n    log_format main '$remote_addr - $host [$time_local] '\n                    '\"$request\" $status $body_bytes_sent '\n                    '\"$http_referer\" \"$http_user_agent\"';\n\n    access_log /var/log/nginx/access.log main;\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap04/#definir-des-variables-avec-set","title":"D\u00e9finir des variables avec set","text":"Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name exemple.local;\n\n    set $app_env \"dev\";\n\n    location / {\n        add_header X-App-Env $app_env;\n        root /var/www/exemple;\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap04/#map-pour-des-comportements-conditionnels","title":"map pour des comportements conditionnels","text":"<p><code>map</code> permet de cr\u00e9er une variable en fonction d\u2019une autre\u202f:</p> Nginx Configuration File<pre><code>http {\n    map $http_user_agent $is_bot {\n        default 0;\n        ~*googlebot 1;\n        ~*bingbot 1;\n    }\n\n    server {\n        listen 80;\n        server_name exemple.local;\n\n        location / {\n            if ($is_bot) {\n                add_header X-Visitor-Type \"bot\";\n            }\n        }\n    }\n}\n</code></pre> <p>Chemin d\u2019apprentissage\u202f:</p> <ol> <li>Ajouter des headers custom (via <code>add_header</code>) contenant des variables comme <code>$host</code>, <code>$uri</code>.</li> <li>Utiliser <code>set</code> dans un <code>location</code> et v\u00e9rifier la propagation dans les logs ou headers.</li> <li>Introduire <code>map</code> pour classifier des requ\u00eates (par exemple, rediriger certains hosts ou UAs).</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap04/#retourner-des-codes-et-rediriger-directive-return","title":"Retourner des codes et rediriger (directive return)","text":"<p>La directive <code>return</code> permet de\u202f:</p> <ul> <li>Renvoyer un code HTTP simple (200, 301, 302, 404, etc.).</li> <li>Optionnellement, un texte ou une URL.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap04/#codes-simples","title":"Codes simples","text":"Nginx Configuration File<pre><code>location /sante {\n    return 200 \"OK\\n\";\n}\n</code></pre> <ul> <li>Nginx envoie un corps simple avec le code 200, sans autre traitement.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap04/#redirections","title":"Redirections","text":"Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name www.exemple.com;\n\n    return 301 http://exemple.com$request_uri;\n}\n</code></pre> <ul> <li>Cette configuration redirige toute requ\u00eate de <code>www.exemple.com</code> vers <code>exemple.com</code>, en conservant l\u2019URI.</li> </ul> <p>Autres exemples\u202f:</p> Nginx Configuration File<pre><code>location /ancien-chemin {\n    return 301 /nouveau-chemin;\n}\n\nlocation /temporaire {\n    return 302 /maintenance;\n}\n</code></pre> <p>Remarques\u202f:</p> <ul> <li><code>return</code> est \u00e9valu\u00e9 tr\u00e8s t\u00f4t, souvent plus simple et plus performant que <code>rewrite</code> pour les redirections.</li> <li>Pour des redirections complexes d\u2019URI, <code>rewrite</code> reste parfois n\u00e9cessaire (voir la section suivante).</li> </ul> <p>Chemin d\u2019apprentissage\u202f:</p> <ol> <li>Cr\u00e9er un bloc <code>server</code> pour <code>www.exemple.local</code> qui redirige vers <code>exemple.local</code> au moyen de <code>return 301</code>.</li> <li>Cr\u00e9er un <code>location /ancien</code> renvoyant un 410 (<code>return 410;</code>) pour un contenu supprim\u00e9.</li> <li>Tester avec <code>curl -I</code> pour observer les codes des r\u00e9ponses.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap04/#les-reecritures-duri-directive-rewrite","title":"Les r\u00e9\u00e9critures d\u2019URI (directive rewrite)","text":"<p><code>rewrite</code> modifie l\u2019URI de la requ\u00eate avant le traitement final. Elle fonctionne avec des expressions r\u00e9guli\u00e8res et peut r\u00e9aliser des redirections (codes 301/302) ou des r\u00e9\u00e9critures internes.</p> <p>Syntaxe g\u00e9n\u00e9rale\u202f:</p> Nginx Configuration File<pre><code>rewrite regex replacement [flag];\n</code></pre> <ul> <li><code>regex</code>\u202f: expression r\u00e9guli\u00e8re sur l\u2019URI.</li> <li><code>replacement</code>\u202f: nouvelle URI (peut contenir des back\u2011references comme <code>$1</code>, <code>$2</code>).</li> <li><code>flag</code>\u202f: options comme <code>last</code>, <code>break</code>, <code>redirect</code> (302), <code>permanent</code> (301).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap04/#reecriture-interne-sans-redirection-visible","title":"R\u00e9\u00e9criture interne (sans redirection visible)","text":"Nginx Configuration File<pre><code>location /blog/ {\n    rewrite ^/blog/(.*)$ /articles/$1 last;\n}\n</code></pre> <ul> <li>Requ\u00eate\u202f: <code>/blog/2024/nginx.html</code>   \u2192 URI interne transform\u00e9e en <code>/articles/2024/nginx.html</code>   \u2192 Traitement repris \u00e0 partir de <code>/articles/...</code>.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap04/#redirections-permanentes","title":"Redirections permanentes","text":"Nginx Configuration File<pre><code>location /vieux-chemin {\n    rewrite ^/vieux-chemin/(.*)$ /nouveau-chemin/$1 permanent;\n}\n</code></pre> <ul> <li>Envoie un code 301 au client.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap04/#url-propres-pour-un-script","title":"URL \u201cpropres\u201d pour un script","text":"Nginx Configuration File<pre><code>location /app/ {\n    rewrite ^/app/(.+)$ /app.php?path=$1 last;\n}\n</code></pre> <p>Chemin d\u2019apprentissage\u202f:</p> <ol> <li>D\u2019abord, utiliser <code>return 301/302</code> pour les redirections simples.</li> <li>Introduire <code>rewrite</code> pour des cas o\u00f9 seul un segment d\u2019URI change.</li> <li>Tester la diff\u00e9rence entre les flags <code>last</code>, <code>break</code>, <code>permanent</code>, <code>redirect</code> en observant les logs et les r\u00e9ponses du serveur.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap04/#les-reecritures-de-reponses-http","title":"Les r\u00e9\u00e9critures de r\u00e9ponses HTTP","text":"<p>En mode \u201cserveur Web statique pur\u201d, cette notion concerne surtout\u202f:</p> <ul> <li>La manipulation d\u2019en\u2011t\u00eates de r\u00e9ponse (via <code>add_header</code>, <code>expires</code>, etc.).</li> <li>La r\u00e9\u00e9criture de certains corps de r\u00e9ponses lorsqu\u2019un module d\u00e9di\u00e9 est utilis\u00e9 (par exemple, substitution de texte avec <code>sub_filter</code> lorsque Nginx agit comme reverse proxy).</li> </ul> <p>Pour un usage centr\u00e9 \u201cserveur Web\u201d sans proxy, l\u2019essentiel se trouve dans\u202f:</p>"},{"location":"_projects/_formation-nginx/nginx-chap04/#ajout-ou-modification-de-headers","title":"Ajout ou modification de headers","text":"Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name exemple.local;\n\n    location / {\n        root /var/www/exemple;\n        add_header X-Powered-By \"Nginx\";\n        add_header Cache-Control \"public, max-age=3600\";\n    }\n}\n</code></pre> <ul> <li><code>add_header</code> n\u2019ajoute les en\u2011t\u00eates que si le code de r\u00e9ponse est 200, 204, 301, 302, 303, 304, 307 ou 308 (sauf configuration sp\u00e9cifique type <code>always</code>).</li> </ul> <p>Exemple avec <code>always</code> (versions r\u00e9centes)\u202f:</p> Nginx Configuration File<pre><code>add_header X-Maintenance \"1\" always;\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap04/#substitution-de-texte-en-reverse-proxy","title":"Substitution de texte (en reverse proxy)","text":"<p>\u00c0 titre indicatif\u202f:</p> Nginx Configuration File<pre><code>location /proxy/ {\n    proxy_pass http://backend;\n    sub_filter 'http://' 'https://';\n    sub_filter_once off;\n}\n</code></pre> <ul> <li>Permet de r\u00e9\u00e9crire dynamiquement certaines parties du corps de r\u00e9ponse.</li> </ul> <p>Chemin d\u2019apprentissage\u202f:</p> <ol> <li>Ajouter des en\u2011t\u00eates personnalis\u00e9s pour toutes les r\u00e9ponses (par exemple, X\u2011Env, X\u2011Version).</li> <li>D\u00e9finir une politique de cache via <code>Cache-Control</code> ou <code>Expires</code>.</li> <li>Une fois \u00e0 l\u2019aise, aborder <code>sub_filter</code> quand Nginx sert de reverse proxy.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap04/#la-directive-error_page","title":"La directive error_page","text":"<p><code>error_page</code> permet de d\u00e9finir des pages (ou URI) personnalis\u00e9es pour certains codes d\u2019erreur. Elle est tr\u00e8s importante pour l\u2019exp\u00e9rience utilisateur.</p>"},{"location":"_projects/_formation-nginx/nginx-chap04/#redirection-vers-une-page-statique","title":"Redirection vers une page statique","text":"Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name exemple.local;\n    root /var/www/exemple;\n\n    error_page 404 /404.html;\n    error_page 500 502 503 504 /50x.html;\n\n    location / {\n        try_files $uri $uri/ =404;\n    }\n\n    location = /404.html {\n        internal;\n    }\n\n    location = /50x.html {\n        internal;\n    }\n}\n</code></pre> <p>Explications\u202f:</p> <ul> <li><code>error_page 404 /404.html;</code> indique \u00e0 Nginx d\u2019utiliser <code>/404.html</code> (URI interne) lorsque le code 404 est g\u00e9n\u00e9r\u00e9.</li> <li><code>internal</code> signifie que ces URIs ne peuvent pas \u00eatre appel\u00e9es directement par le client.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap04/#utilisation-avec-codes-de-retour-specifiques","title":"Utilisation avec codes de retour sp\u00e9cifiques","text":"<p>Il est possible de changer le code de r\u00e9ponse final\u202f:</p> Nginx Configuration File<pre><code>error_page 404 =200 /fallback.html;\n</code></pre> <ul> <li>Une erreur 404 interne peut \u00eatre \u201cconvertie\u201d en 200 avec un contenu diff\u00e9rent (utile dans certains cas applicatifs).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap04/#redirection-externe-en-cas-derreur","title":"Redirection externe en cas d\u2019erreur","text":"Nginx Configuration File<pre><code>error_page 403 404 = @handle_error;\n\nlocation @handle_error {\n    return 302 /maintenance.html;\n}\n</code></pre> <p>Chemin d\u2019apprentissage\u202f:</p> <ol> <li>Cr\u00e9er des fichiers <code>404.html</code> et <code>50x.html</code> dans la racine du site.</li> <li>Configurer <code>error_page</code> pour 404, 500, 502, etc., et tester les comportements.</li> <li>Observer la diff\u00e9rence entre une page d\u2019erreur interne et une redirection explicite.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap04/#chemin-dapprentissage-global-sans-plan-detude","title":"Chemin d\u2019apprentissage global (sans plan d\u2019\u00e9tude)","text":"<p>L\u2019encha\u00eenement suivant permet de progresser en profondeur sur Nginx en mode serveur Web\u202f:</p> <ol> <li>Mettre en place un seul virtual host simple </li> <li>Un bloc <code>server</code> avec <code>listen 80</code>, <code>server_name</code>, <code>root</code>, <code>index</code>, <code>location /</code> minimal.</li> <li> <p>Tester la servitude de fichiers statiques (HTML, CSS, images).</p> </li> <li> <p>Explorer la s\u00e9lection de serveurs </p> </li> <li>Ajouter un deuxi\u00e8me bloc <code>server</code> sur le m\u00eame port, avec un autre <code>server_name</code>.</li> <li> <p>Exp\u00e9rimenter avec <code>default_server</code> et observer quel bloc r\u00e9pond \u00e0 quelle requ\u00eate.</p> </li> <li> <p>Travailler sur les <code>location</code> </p> </li> <li>Cr\u00e9er des emplacements s\u00e9par\u00e9s pour <code>/images/</code>, <code>/css/</code>, <code>/admin/</code>.</li> <li>Introduire des <code>location = /</code> et des <code>location ~ \\.php$</code>.</li> <li> <p>Comprendre la logique de \u201cmeilleure correspondance\u201d.</p> </li> <li> <p>Ma\u00eetriser <code>root</code>, les chemins et <code>index</code> </p> </li> <li>D\u00e9clarer <code>root</code> au niveau <code>server</code>, puis le surcharger dans un <code>location</code>.</li> <li> <p>Modifier la liste <code>index</code> et v\u00e9rifier les priorit\u00e9s des fichiers d\u2019index.</p> </li> <li> <p>Utiliser <code>try_files</code> pour contr\u00f4ler le routage </p> </li> <li>D\u2019abord pour un site statique pour renvoyer 404 proprement.</li> <li> <p>Ensuite pour une application (SPA ou framework) en routant vers un script ou un <code>index.html</code>.</p> </li> <li> <p>Manipuler les variables et les en\u2011t\u00eates </p> </li> <li>Ajouter des en\u2011t\u00eates de r\u00e9ponse contenant <code>$host</code>, <code>$uri</code>.</li> <li> <p>D\u00e9finir des variables avec <code>set</code>, puis avec <code>map</code>, pour cr\u00e9er des comportements conditionnels.</p> </li> <li> <p>G\u00e9rer les redirections et r\u00e9\u00e9critures </p> </li> <li>Employer <code>return 301</code> pour forcer le passage HTTP\u2192HTTPS ou <code>www</code>\u2192sans <code>www</code>.</li> <li> <p>Introduire <code>rewrite</code> pour les cas n\u00e9cessitant des expressions r\u00e9guli\u00e8res sur l\u2019URI.</p> </li> <li> <p>Soigner la gestion des erreurs avec <code>error_page</code> </p> </li> <li>D\u00e9finir des pages d\u2019erreur 404 et 50x personnalis\u00e9es.</li> <li>Exp\u00e9rimenter avec des handlers internes (via <code>location @nom</code>) et des conversions de codes.</li> </ol> <p>\u00c0 chaque \u00e9tape, il est recommand\u00e9 de\u202f:</p> <ul> <li>Modifier la configuration de Nginx pas \u00e0 pas.</li> <li>Tester avec des outils comme <code>curl</code>, un navigateur ou <code>wget</code>.</li> <li>Consulter syst\u00e9matiquement les logs d\u2019acc\u00e8s et d\u2019erreur pour comprendre le comportement interne.</li> </ul> <p> Partager sur X</p>"},{"location":"_projects/_formation-nginx/nginx-chap05/","title":"Citations","text":"<ul> <li>https://www.ib-formation.fr/home/mag/developpement-informatique/apache-nginx-tomcat-panorama-des-serveurs-web</li> <li>https://blog.stephane-robert.info/docs/services/web/nginx/</li> <li>https://systalink.com/apache-ou-nginx/</li> <li>https://blent.ai/blog/a/nginx-tout-savoir</li> <li>https://grafikart.fr/tutoriels/nginx-692</li> <li>https://www.data-transitionnumerique.com/nginx-tutoriel-complet/</li> <li>https://www.dyma.fr/formations/nginx</li> <li>https://kinsta.com/fr/blog/qu-est-ce-que-nginx/</li> <li>https://www.ai-futureschool.com/fr/programmation/nginx-serveur-web-haute-performance.php</li> <li>https://www.f5.com/fr_fr/glossary/nginx</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap05/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 284</li> <li>completion_tokens: 4631</li> <li>total_tokens: 4915</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.069, 'request_cost': 0.006, 'total_cost': 0.076}</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap05/#content","title":"Content","text":"<p>Il n\u2019est actuellement pas possible d\u2019acc\u00e9der au site indiqu\u00e9 ni de v\u00e9rifier l\u2019existence des images en temps r\u00e9el, ce qui emp\u00eache de produire exactement les sch\u00e9mas et captures demand\u00e9s ou de s\u2019aligner pr\u00e9cis\u00e9ment sur le contenu du blog cit\u00e9. Toutefois, il reste possible de proposer un parcours d\u00e9taill\u00e9 de type \u201cchapitre 5 \u2013 \u00e9tudes de cas Nginx\u201d en expliquant en profondeur chaque cas (statique / SPA, local / Internet), avec des exemples de configurations Nginx et Docker, des tableaux r\u00e9capitulatifs et des indications sur les sch\u00e9mas qu\u2019il serait pertinent de r\u00e9aliser.</p>"},{"location":"_projects/_formation-nginx/nginx-chap05/#objectif-general-du-chapitre-5","title":"Objectif g\u00e9n\u00e9ral du chapitre 5","text":"<p>Ce chapitre se concentre sur quatre sc\u00e9narios concrets autour de Nginx\u00a0: servir un site statique ou une SPA, d\u2019abord en local avec Docker pour exp\u00e9rimenter, puis sur Internet avec des aspects DNS, HTTPS et durcissement de configuration. L\u2019apprentissage progresse ainsi de la configuration la plus simple (contenu statique local) vers la plus complexe (SPA en production avec HTTPS et optimisations).  </p>"},{"location":"_projects/_formation-nginx/nginx-chap05/#1-servir-un-site-statique-localement-avec-docker","title":"1. Servir un site statique localement avec Docker","text":"<p>Un site statique est un ensemble de fichiers HTML/CSS/JS et d\u2019assets (images, polices, \u2026) servis directement par Nginx sans logique backend. Ce cas permet de comprendre la configuration minimale d\u2019un <code>server</code> Nginx et la fa\u00e7on dont Nginx lit les fichiers sur le disque.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap05/#11-structure-des-fichiers-et-dockerfile-minimal","title":"1.1. Structure des fichiers et Dockerfile minimal","text":"<p>Exemple de structure\u00a0:</p> Text Only<pre><code>projet-site-statique/\n  docker/\n    Dockerfile\n    default.conf\n  site/\n    index.html\n    styles.css\n    images/\n      logo.png\n</code></pre> <ul> <li>Dossier <code>site/</code>\u00a0: racine des fichiers statiques.</li> <li>Dossier <code>docker/</code>\u00a0: fichiers de configuration et Dockerfile.</li> </ul> <p>Exemple de <code>Dockerfile</code> minimal\u202f:</p> Docker<pre><code>FROM nginx:alpine\n\n# Copie de la configuration Nginx\nCOPY default.conf /etc/nginx/conf.d/default.conf\n\n# Copie du site statique\nCOPY ../site /usr/share/nginx/html\n\nEXPOSE 80\n</code></pre> <p>Exemple de configuration <code>default.conf</code>\u00a0:</p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name _;\n\n    root   /usr/share/nginx/html;\n    index  index.html;\n\n    location / {\n        try_files $uri $uri/ =404;\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap05/#12-lancement-du-conteneur-et-tests","title":"1.2. Lancement du conteneur et tests","text":"<p>Commandes principales\u00a0:</p> Bash<pre><code>cd projet-site-statique/docker\n\ndocker build -t site-statique-nginx .\ndocker run --rm -p 8080:80 site-statique-nginx\n</code></pre> <p>Le site devient accessible sur <code>http://localhost:8080</code>. Les points d\u2019apprentissage importants\u00a0:</p> <ul> <li>Comprendre le r\u00f4le de <code>root</code> et <code>index</code>.</li> <li>Comprendre <code>try_files</code> pour renvoyer une 404 propre.</li> <li>Distinguer l\u2019int\u00e9rieur du conteneur (<code>/usr/share/nginx/html</code>) de la machine h\u00f4te.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap05/#13-variante-avec-montage-de-volume","title":"1.3. Variante avec montage de volume","text":"<p>Pour un cycle de d\u00e9veloppement rapide, il est pr\u00e9f\u00e9rable de monter le dossier local plut\u00f4t que de reconstruire l\u2019image \u00e0 chaque changement\u00a0:</p> Bash<pre><code>docker run --rm \\\n  -p 8080:80 \\\n  -v \"$(pwd)/site:/usr/share/nginx/html:ro\" \\\n  nginx:alpine\n</code></pre> <p>Dans ce cas, on peut utiliser la configuration par d\u00e9faut de Nginx ou monter un fichier de configuration personnalis\u00e9.</p>"},{"location":"_projects/_formation-nginx/nginx-chap05/#14-tableau-de-synthese-cas-statique-local","title":"1.4. Tableau de synth\u00e8se \u2013 cas statique local","text":"\u00c9l\u00e9ment R\u00f4le principal <code>root</code> Chemin du contenu statique dans le conteneur <code>index</code> Fichier charg\u00e9 par d\u00e9faut sur <code>/</code> <code>try_files</code> Contr\u00f4le de la r\u00e9solution d\u2019URI et de la 404 Volume Docker Partage de fichiers entre h\u00f4te et conteneur Port <code>-p 8080:80</code> Mapping port h\u00f4te \u2192 port Nginx dans le conteneur"},{"location":"_projects/_formation-nginx/nginx-chap05/#2-servir-une-spa-react-vue-angular-localement-avec-docker","title":"2. Servir une SPA (React, Vue, Angular) localement avec Docker","text":"<p>Une SPA se distingue d\u2019un site statique classique par l\u2019usage intensif du JavaScript c\u00f4t\u00e9 client, du routage c\u00f4t\u00e9 client (URL g\u00e9r\u00e9es par le framework), et g\u00e9n\u00e9ralement par une \u00e9tape de \u201cbuild\u201d (Webpack, Vite, etc.). Pour Nginx, une SPA reste du statique, mais la gestion des routes n\u00e9cessite une configuration particuli\u00e8re.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap05/#21-workflow-typique-spa-nginx","title":"2.1. Workflow typique SPA + Nginx","text":"<p>\u00c9tapes g\u00e9n\u00e9rales\u00a0:</p> <ol> <li>D\u00e9veloppement de la SPA avec <code>npm/yarn</code> (React, Vue, Angular).</li> <li>Build de production (par exemple <code>npm run build</code>).</li> <li>Copie du contenu g\u00e9n\u00e9r\u00e9 (souvent <code>dist/</code> ou <code>build/</code>) dans l\u2019image Docker Nginx.</li> <li>Configuration Nginx pour rediriger toutes les routes vers <code>index.html</code> (sauf pour les assets).</li> </ol> <p>Exemple de structure\u00a0:</p> Text Only<pre><code>projet-spa/\n  app/             # Code source SPA\n  docker/\n    Dockerfile\n    default.conf\n</code></pre> <p>Apr\u00e8s le build front, on obtient un dossier <code>app/dist</code> ou <code>app/build</code> qui contient le bundle final.</p>"},{"location":"_projects/_formation-nginx/nginx-chap05/#22-dockerfile-multi-etapes-pour-spa","title":"2.2. Dockerfile multi-\u00e9tapes pour SPA","text":"<p>Exemple g\u00e9n\u00e9rique (bas\u00e9 sur Node + Nginx)\u00a0:</p> Docker<pre><code># \u00c9tape 1 : build de la SPA\nFROM node:18-alpine AS build\n\nWORKDIR /app\nCOPY app/package*.json ./\nRUN npm install\n\nCOPY app/ .\nRUN npm run build\n\n# \u00c9tape 2 : image Nginx pour la prod\nFROM nginx:alpine\n\nCOPY docker/default.conf /etc/nginx/conf.d/default.conf\n\n# Copier le build dans le dossier servi par Nginx\nCOPY --from=build /app/dist /usr/share/nginx/html\n\nEXPOSE 80\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap05/#23-configuration-nginx-pour-le-routage-cote-client","title":"2.3. Configuration Nginx pour le routage c\u00f4t\u00e9 client","text":"<p>Le point cl\u00e9 est la gestion de toutes les routes de la SPA vers <code>index.html</code>\u00a0:</p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name _;\n\n    root   /usr/share/nginx/html;\n    index  index.html;\n\n    location / {\n        try_files $uri $uri/ /index.html;\n    }\n\n    # Exemple de cache simple sur les assets\n    location ~* \\.(js|css|png|jpg|jpeg|gif|svg|ico)$ {\n        try_files $uri =404;\n        access_log off;\n        add_header Cache-Control \"public, max-age=31536000\";\n    }\n}\n</code></pre> <p>R\u00f4le de <code>try_files $uri $uri/ /index.html;</code>\u00a0:</p> <ul> <li>Si le fichier demand\u00e9 existe, il est servi (images, JS, CSS, etc.).</li> <li>Sinon, la requ\u00eate est redirig\u00e9e vers <code>index.html</code>, ce qui permet au routeur client (React Router, Vue Router\u2026) de g\u00e9rer l\u2019URL.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap05/#24-lancement-local-et-tests","title":"2.4. Lancement local et tests","text":"<p>Commandes typiques\u00a0:</p> Bash<pre><code>docker build -t spa-nginx .\ndocker run --rm -p 3000:80 spa-nginx\n</code></pre> <p>Acc\u00e8s\u00a0: <code>http://localhost:3000</code>. Tests pratiques conseill\u00e9s\u00a0:</p> <ul> <li>Acc\u00e9der \u00e0 <code>/</code>.</li> <li>Naviguer vers une route interne de la SPA (ex. <code>/dashboard</code>) via l\u2019UI.</li> <li>Recharger la page <code>/dashboard</code> pour v\u00e9rifier que <code>index.html</code> est bien servi via <code>try_files</code>.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap05/#25-tableau-de-synthese-cas-spa-local","title":"2.5. Tableau de synth\u00e8se \u2013 cas SPA local","text":"\u00c9l\u00e9ment Sp\u00e9cificit\u00e9 pour SPA Build front (<code>npm run build</code>) G\u00e9n\u00e8re le dossier statique pour Nginx Multi-stage Dockerfile \u00c9vite d\u2019embarquer Node dans l\u2019image finale <code>try_files ... /index.html</code> Permet le routage c\u00f4t\u00e9 client Cache des assets Optimise le chargement (JS/CSS/images versionn\u00e9es) Port d\u2019exposition Acc\u00e8s local via <code>localhost:&lt;port&gt;</code>"},{"location":"_projects/_formation-nginx/nginx-chap05/#3-servir-un-site-statique-sur-internet","title":"3. Servir un site statique sur Internet","text":"<p>Une fois les cas locaux ma\u00eetris\u00e9s, il devient pertinent de d\u00e9ployer un site statique en ligne. Les points d\u2019apprentissage se d\u00e9placent vers\u00a0: DNS, reverse proxy \u00e9ventuel, HTTPS, s\u00e9curit\u00e9 basique et logs.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap05/#31-architecture-typique-de-deploiement","title":"3.1. Architecture typique de d\u00e9ploiement","text":"<p>Deux sc\u00e9narios fr\u00e9quents\u00a0:</p> <ul> <li>Nginx directement expos\u00e9 sur Internet (VPS, machine cloud) \u00e9coutant sur les ports 80 / 443.</li> <li>Nginx dans un conteneur derri\u00e8re un reverse proxy frontal (par exemple Traefik, un autre Nginx ou une passerelle d\u2019h\u00e9bergement g\u00e9r\u00e9e).</li> </ul> <p>Sch\u00e9ma conceptuel simple (d\u00e9crit textuellement)\u202f:</p> <ul> <li>Navigateur \u2192 DNS (r\u00e9solution de <code>exemple.com</code> vers IP publique) \u2192 Nginx (ports 80/443) \u2192 fichiers statiques sur le disque ou dans le conteneur.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap05/#32-etapes-dapprentissage-proposees","title":"3.2. \u00c9tapes d\u2019apprentissage propos\u00e9es","text":"<ol> <li>Obtenir un nom de domaine et configurer un enregistrement A vers l\u2019IP du serveur.</li> <li>Installer Nginx (sur la machine ou via Docker).</li> <li>D\u00e9ployer les fichiers statiques dans un dossier (ou volume Docker).</li> <li>Configurer un <code>server</code> pour le domaine.</li> <li>Activer HTTPS avec Let\u2019s Encrypt (certbot classique ou image d\u00e9di\u00e9e).</li> <li>Activer quelques protections de base (en-t\u00eates de s\u00e9curit\u00e9, 404/50x custom, logs).</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap05/#33-exemple-de-configuration-nginx-pour-site-statique-public-sans-https","title":"3.3. Exemple de configuration Nginx pour site statique public (sans HTTPS)","text":"Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name exemple.com www.exemple.com;\n\n    root   /var/www/exemple.com/html;\n    index  index.html;\n\n    access_log /var/log/nginx/exemple_access.log;\n    error_log  /var/log/nginx/exemple_error.log warn;\n\n    location / {\n        try_files $uri $uri/ =404;\n    }\n}\n</code></pre> <p>\u00c9l\u00e9ments \u00e0 bien comprendre\u00a0:</p> <ul> <li><code>server_name</code>\u202f: fait le lien entre le nom de domaine et le bloc <code>server</code>.</li> <li>Emplacement des logs pour diagnostiquer les erreurs.</li> <li><code>try_files</code> pour g\u00e9rer proprement les requ\u00eates.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap05/#34-ajout-dhttps-avec-lets-encrypt","title":"3.4. Ajout d\u2019HTTPS avec Let\u2019s Encrypt","text":"<p>Configuration type avec un redirect HTTP \u2192 HTTPS\u202f:</p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name exemple.com www.exemple.com;\n    return 301 https://exemple.com$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    server_name exemple.com www.exemple.com;\n\n    ssl_certificate     /etc/letsencrypt/live/exemple.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/exemple.com/privkey.pem;\n\n    root   /var/www/exemple.com/html;\n    index  index.html;\n\n    add_header Strict-Transport-Security \"max-age=31536000\" always;\n    add_header X-Frame-Options \"SAMEORIGIN\";\n    add_header X-Content-Type-Options \"nosniff\";\n\n    location / {\n        try_files $uri $uri/ =404;\n    }\n}\n</code></pre> <p>Points d\u2019apprentissage\u00a0:</p> <ul> <li>Signification de <code>ssl_certificate</code> et <code>ssl_certificate_key</code>.</li> <li>Activation de <code>http2</code> et ses b\u00e9n\u00e9fices (multiplexage, meilleure performance).</li> <li>En-t\u00eates de s\u00e9curit\u00e9 de base et leur int\u00e9r\u00eat.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap05/#35-tableau-de-synthese-site-statique-internet","title":"3.5. Tableau de synth\u00e8se \u2013 site statique Internet","text":"\u00c9l\u00e9ment Objectif principal DNS (<code>A</code> / <code>AAAA</code>) Associer domaine \u00e0 l\u2019IP du serveur <code>server_name</code> Faire correspondre le site au domaine HTTPS (Let\u2019s Encrypt) Chiffrement des \u00e9changes, confiance utilisateur En-t\u00eates de s\u00e9curit\u00e9 R\u00e9duire plusieurs vecteurs d\u2019attaque courants Logs Nginx Diagnostic des erreurs et audit d\u2019acc\u00e8s"},{"location":"_projects/_formation-nginx/nginx-chap05/#4-servir-une-spa-react-vue-angular-sur-internet","title":"4. Servir une SPA (React, Vue, Angular) sur Internet","text":"<p>Ce sc\u00e9nario combine toutes les notions pr\u00e9c\u00e9dentes\u00a0: SPA, Docker \u00e9ventuel, HTTPS, optimisations de performance, et protections de base. C\u2019est le cas le plus proche d\u2019un contexte de production.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap05/#41-architecture-du-navigateur-au-conteneur","title":"4.1. Architecture\u00a0: du navigateur au conteneur","text":"<p>Pour une SPA d\u00e9ploy\u00e9e avec Docker sur un VPS\u202f:</p> <ul> <li>Navigateur \u2192 DNS (<code>app.exemple.com</code>) \u2192 Nginx frontal (h\u00f4te ou conteneur reverse proxy) \u2192 conteneur Nginx qui sert la SPA (bundle build\u00e9).</li> </ul> <p>Deux mod\u00e8les possibles\u00a0:</p> <ul> <li>Un seul Nginx expos\u00e9, qui sert directement la SPA.</li> <li>Deux niveaux\u00a0: un Nginx ou un proxy frontal (qui g\u00e8re HTTPS) + un Nginx applicatif en backend (HTTP simple).</li> </ul> <p>Pour simplifier, on peut traiter le cas \u00ab\u202fun seul Nginx\u202f\u00bb expos\u00e9, int\u00e9grant \u00e0 la fois HTTPS et le service de la SPA.</p>"},{"location":"_projects/_formation-nginx/nginx-chap05/#42-exemple-de-configuration-nginx-pour-spa-https","title":"4.2. Exemple de configuration Nginx pour SPA + HTTPS","text":"Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name app.exemple.com;\n    return 301 https://app.exemple.com$request_uri;\n}\n\nserver {\n    listen 443 ssl http2;\n    server_name app.exemple.com;\n\n    ssl_certificate     /etc/letsencrypt/live/app.exemple.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/app.exemple.com/privkey.pem;\n\n    root   /usr/share/nginx/html;\n    index  index.html;\n\n    # En-t\u00eates de s\u00e9curit\u00e9 courants\n    add_header Strict-Transport-Security \"max-age=31536000; includeSubDomains\" always;\n    add_header X-Frame-Options \"SAMEORIGIN\";\n    add_header X-Content-Type-Options \"nosniff\";\n    add_header Referrer-Policy \"strict-origin-when-cross-origin\";\n    add_header Content-Security-Policy \"default-src 'self'; script-src 'self'; style-src 'self' 'unsafe-inline'\";\n\n    # Routage SPA\n    location / {\n        try_files $uri $uri/ /index.html;\n    }\n\n    # Cache des assets\n    location ~* \\.(js|css|png|jpg|jpeg|gif|svg|ico)$ {\n        try_files $uri =404;\n        access_log off;\n        add_header Cache-Control \"public, max-age=31536000, immutable\";\n    }\n}\n</code></pre> <p>Points p\u00e9dagogiques\u00a0:</p> <ul> <li>Affiner la politique CSP en fonction des besoins r\u00e9els (APIs externes, CDN, etc.).</li> <li>Tester les en-t\u00eates de s\u00e9curit\u00e9 (via des outils de test en ligne).</li> <li>V\u00e9rifier qu\u2019une route profonde de la SPA est accessible en acc\u00e8s direct (F5 sur <code>/dashboard</code> par exemple).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap05/#43-integration-docker-pour-la-spa-en-production","title":"4.3. Int\u00e9gration Docker pour la SPA en production","text":"<p>Exemple de <code>docker-compose.yml</code> minimaliste pour exposer une SPA sur Internet (sans proxy s\u00e9par\u00e9)\u00a0:</p> YAML<pre><code>version: \"3.9\"\n\nservices:\n  spa:\n    image: mon-registry/spa-nginx:latest\n    container_name: spa-app\n    restart: always\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - /etc/letsencrypt:/etc/letsencrypt:ro\n    # \u00e9ventuellement :\n    # environment:\n    #   - NGINX_ENV=production\n</code></pre> <p>Dans un contexte plus avanc\u00e9, les ports 80/443 seraient expos\u00e9s par un reverse proxy frontal, et le conteneur de la SPA \u00e9couterait uniquement en interne (ex\u202f: port 8080, reachable via <code>proxy_pass http://spa:8080;</code>).</p>"},{"location":"_projects/_formation-nginx/nginx-chap05/#44-chemin-dapprentissage-detaille-pour-la-spa-en-production","title":"4.4. Chemin d\u2019apprentissage d\u00e9taill\u00e9 pour la SPA en production","text":"<ol> <li>R\u00e9utiliser le projet SPA local d\u00e9j\u00e0 maitris\u00e9.</li> <li>Tester le build en environnement proche de la production (Docker local, variables d\u2019environnement, API endpoints).</li> <li>D\u00e9ployer sur un serveur de test avec un domaine de test (ex. <code>staging.app.exemple.com</code>), configurer HTTPS, v\u00e9rifier les en-t\u00eates.</li> <li>Activer le monitoring de base\u202f: logs Nginx, \u00e9ventuellement une sonde HTTP (UptimeRobot ou \u00e9quivalent).</li> <li>Tester les sc\u00e9narios d\u2019erreur (404, 500 proxy si backends, pages de maintenance).</li> <li>Valider la performance via des outils comme Lighthouse ou WebPageTest, ajuster Gzip/Brotli, cache static.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap05/#45-tableau-de-synthese-spa-internet","title":"4.5. Tableau de synth\u00e8se \u2013 SPA Internet","text":"\u00c9l\u00e9ment R\u00f4le pour la SPA en production HTTPS + HTTP/2 S\u00e9curit\u00e9 + performance r\u00e9seau <code>try_files</code> SPA Routage client fiable, y compris en acc\u00e8s direct En-t\u00eates de s\u00e9curit\u00e9 (CSP, HSTS) Limitation de classes de vuln\u00e9rabilit\u00e9s courantes Cache long sur assets R\u00e9duction du temps de chargement, meilleur score perf Monitoring / logs D\u00e9tection rapide d\u2019incidents"},{"location":"_projects/_formation-nginx/nginx-chap05/#5-schemas-et-images-a-produire-guides","title":"5. Sch\u00e9mas et images \u00e0 produire (guides)","text":"<p>M\u00eame si les images en provenance du site indiqu\u00e9 ne peuvent pas \u00eatre v\u00e9rifi\u00e9es, il est possible de lister les types de sch\u00e9mas utiles \u00e0 cr\u00e9er pour illustrer ce chapitre\u00a0:</p> <ul> <li>Sch\u00e9ma 1 \u2013 Site statique local </li> <li>Bloc \u00ab\u202fNavigateurs\u202f\u00bb \u2192 fl\u00e8che vers \u00ab\u202fDocker Nginx\u202f\u00bb \u2192 dossier <code>site</code> mont\u00e9 en volume.</li> <li>Sch\u00e9ma 2 \u2013 SPA locale </li> <li>Deux \u00e9tapes\u202f: \u00ab\u202fNode\u202f\u00bb (build SPA) \u2192 artefacts (<code>dist/</code>) \u2192 \u00ab\u202fNginx dans Docker\u202f\u00bb qui sert le build.</li> <li>Sch\u00e9ma 3 \u2013 Site statique Internet </li> <li>\u00ab\u202fNavigateur\u202f\u00bb \u2192 \u00ab\u202fDNS\u202f\u00bb \u2192 \u00ab\u202fServeur Nginx (VPS)\u202f\u00bb \u2192 syst\u00e8me de fichiers.</li> <li>Mention des ports 80/443, de Let\u2019s Encrypt et des logs.</li> <li>Sch\u00e9ma 4 \u2013 SPA Internet avec HTTPS </li> <li>\u00ab\u202fNavigateur\u202f\u00bb \u2192 \u00ab\u202fNginx frontal\u202f\u00bb (certificats + r\u00e8gles de s\u00e9curit\u00e9) \u2192 \u00ab\u202fContenu SPA\u202f\u00bb.</li> <li>Surligner la logique <code>try_files</code> pour les routes <code>/dashboard</code>, <code>/profil</code>, etc.</li> </ul> <p>Ces sch\u00e9mas peuvent \u00eatre dessin\u00e9s avec un outil de diagrammes (PlantUML, Mermaid, draw.io, etc.) et int\u00e9gr\u00e9s en Markdown sous forme d\u2019images, \u00e0 condition de v\u00e9rifier manuellement leur emplacement et leur accessibilit\u00e9 (chemin, URL ou assets locaux).  </p>"},{"location":"_projects/_formation-nginx/nginx-chap05/#6-chemin-dapprentissage-global-sans-parler-de-plan-detude","title":"6. Chemin d\u2019apprentissage global (sans parler de plan d\u2019\u00e9tude)","text":"<p>L\u2019encha\u00eenement des quatre cas constitue un chemin progressif\u202f:</p> <ul> <li>D\u2019abord, ma\u00eetrise de la configuration minimale pour du statique local\u202f: compr\u00e9hension de <code>server</code>, <code>root</code>, <code>index</code>, <code>location</code>, <code>try_files</code>, mapping de ports Docker.</li> <li>Ensuite, extension au cas SPA\u202f: introduction du concept de build front, multi-stage Docker, routage c\u00f4t\u00e9 client, et d\u00e9but d\u2019optimisation (cache assets).</li> <li>Passage au contexte Internet\u202f: nom de domaine, DNS, exposition s\u00e9curis\u00e9e de Nginx sur les ports 80/443, premi\u00e8res notions de SSL/TLS, en-t\u00eates de s\u00e9curit\u00e9.</li> <li>Enfin, combinaison SPA + Internet\u202f: mise en pratique compl\u00e8te avec build de la SPA, configuration HTTPS, s\u00e9curit\u00e9, performance, et surveillance.</li> </ul> <p>\u00c0 chaque \u00e9tape, l\u2019id\u00e9e est de partir de la configuration fonctionnelle la plus simple, puis d\u2019ajouter progressivement des \u00e9l\u00e9ments\u00a0: logs d\u00e9di\u00e9s, pages d\u2019erreurs personnalis\u00e9es, headers de s\u00e9curit\u00e9, cache, compression, monitoring et \u00e9ventuel d\u00e9coupage en plusieurs Nginx (reverse proxy + backends).</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-nginx/nginx-chap06/","title":"Citations","text":"<ul> <li>https://kinsta.com/fr/blog/proxy-inverse/</li> <li>https://www.hostinger.com/fr/tutoriels/reverse-proxy-nginx</li> <li>https://serverspace.io/fr/support/help/how-to-configure-reverse-proxy-on-ubuntu-server-22-04-using-nginx/</li> <li>https://docs.nginx.com/nginx/admin-guide/web-server/reverse-proxy/</li> <li>https://www.it-connect.fr/configurer-nginx-en-tant-que-reverse-proxy/</li> <li>https://openclassrooms.com/fr/courses/1733551-gerez-votre-serveur-linux-et-ses-services/5236081-mettez-en-place-un-reverse-proxy-avec-nginx</li> <li>https://blog.stephane-robert.info/docs/services/web/nginx/</li> <li>https://www.hostragons.com/fr/blog/configuration-du-proxy-inverse-nginx-et-equilibrage-de-charge/</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap06/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 292</li> <li>completion_tokens: 4726</li> <li>total_tokens: 5018</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.071, 'request_cost': 0.006, 'total_cost': 0.078}</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap06/#content","title":"Content","text":"<p>Nginx permet de jouer le r\u00f4le de point d\u2019entr\u00e9e unique pour plusieurs applications, en agissant comme proxy inverse (reverse proxy) devant des serveurs web, des API ou des services PHP-FPM. Ce chapitre d\u00e9taille pas \u00e0 pas la configuration d\u2019un reverse proxy HTTP et FastCGI, les en\u2011t\u00eates transmis, la mise en tampon (buffering), les d\u00e9lais (timeouts) et le chemin d\u2019apprentissage associ\u00e9.</p> <p>Remarque : un acc\u00e8s direct \u00e0 des images externes ou \u00e0 des sch\u00e9mas ne peut pas \u00eatre garanti dans ce contexte, mais chaque section indique comment rechercher un type de sch\u00e9ma pertinent et comment l\u2019interpr\u00e9ter.</p>"},{"location":"_projects/_formation-nginx/nginx-chap06/#introduction-au-proxy-inverse","title":"Introduction au proxy inverse","text":"<p>Un proxy inverse est un serveur plac\u00e9 en frontal qui re\u00e7oit les requ\u00eates des clients, puis les relaie vers un ou plusieurs serveurs d\u2019origine (backends). Il renvoie ensuite les r\u00e9ponses de ces serveurs au client, qui n\u2019a souvent jamais connaissance de l\u2019adresse r\u00e9elle des backends.  </p> <p>Ce r\u00f4le de frontal permet de centraliser la terminaison TLS, la r\u00e9\u00e9criture d\u2019URL, la mise en cache, l\u2019authentification, la limitation de d\u00e9bit ou encore la r\u00e9partition de charge. Nginx est particuli\u00e8rement adapt\u00e9 \u00e0 ce r\u00f4le gr\u00e2ce \u00e0 son architecture \u00e9v\u00e9nementielle, ce qui le rend performant m\u00eame avec un grand nombre de connexions simultan\u00e9es.</p>"},{"location":"_projects/_formation-nginx/nginx-chap06/#chemin-dapprentissage-global","title":"Chemin d\u2019apprentissage global","text":"<p>L\u2019apprentissage autour du proxy inverse Nginx peut se structurer en plusieurs \u00e9tapes coh\u00e9rentes, chaque \u00e9tape s\u2019appuyant sur la pr\u00e9c\u00e9dente :</p> <ol> <li>Compr\u00e9hension des blocs de configuration de base </li> <li>Bloc <code>http {}</code> global et blocs <code>server {}</code> virtuels.  </li> <li>Bloc <code>location</code> et correspondances d\u2019URI.  </li> <li> <p>Manipulation simple d\u2019un <code>server_name</code>, d\u2019un <code>root</code>, et des logs d\u2019acc\u00e8s/erreur.</p> </li> <li> <p>D\u00e9couverte de la notion de proxy HTTP </p> </li> <li>Utilisation de <code>proxy_pass</code> dans un <code>location</code>.  </li> <li>Observation du r\u00f4le de passerelle entre client et backend HTTP.  </li> <li> <p>Tests avec un backend simple (par exemple un serveur HTTP sur un autre port ou une autre machine).</p> </li> <li> <p>Ma\u00eetrise des en\u2011t\u00eates transmis et compl\u00e9t\u00e9s </p> </li> <li>D\u00e9couverte de <code>proxy_set_header</code>, des variables <code>$host</code>, <code>$remote_addr</code>, <code>$proxy_add_x_forwarded_for</code>, etc.  </li> <li> <p>Compr\u00e9hension des en\u2011t\u00eates de tra\u00e7age (<code>X-Forwarded-*</code>) et de leurs implications c\u00f4t\u00e9 application.</p> </li> <li> <p>Gestion du buffering et de la taille des r\u00e9ponses </p> </li> <li>\u00c9tude de <code>proxy_buffering</code>, <code>proxy_buffers</code>, <code>proxy_busy_buffers_size</code>, <code>proxy_max_temp_file_size</code>.  </li> <li> <p>Configuration adapt\u00e9e aux contenus dynamiques, aux gros fichiers ou aux flux.</p> </li> <li> <p>Configuration des d\u00e9lais (timeouts) et des erreurs </p> </li> <li>Utilisation de <code>proxy_connect_timeout</code>, <code>proxy_send_timeout</code>, <code>proxy_read_timeout</code>.  </li> <li> <p>Gestion des codes d\u2019erreur backend avec <code>proxy_next_upstream</code>, <code>error_page</code>, etc.</p> </li> <li> <p>Introduction au reverse proxy avanc\u00e9 (upstreams, load-balancing) </p> </li> <li>D\u00e9claration de blocs <code>upstream</code> pour plusieurs serveurs backend.  </li> <li> <p>Strat\u00e9gies de r\u00e9partition simples (round\u2011robin, ip_hash, etc.) et sant\u00e9 des backends (health\u2011checks via modules ou solutions externes).</p> </li> <li> <p>Passer des requ\u00eates \u00e0 PHP\u2011FPM avec FastCGI </p> </li> <li>Compr\u00e9hension de FastCGI, r\u00f4le de PHP\u2011FPM, diff\u00e9rences avec le proxy HTTP.  </li> <li>Utilisation de <code>fastcgi_pass</code>, <code>fastcgi_param</code>, et inclusion de fichiers de param\u00e8tres (ex. <code>fastcgi_params</code> ou <code>fastcgi.conf</code>).  </li> <li>S\u00e9paration claire entre Nginx (serveur HTTP, reverse proxy) et PHP\u2011FPM (interpr\u00e9teur PHP).</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap06/#envoyer-des-requetes-vers-dautres-serveurs-proxy_pass","title":"Envoyer des requ\u00eates vers d\u2019autres serveurs (proxy_pass)","text":"<p>L\u2019utilisation la plus directe du reverse proxy Nginx consiste \u00e0 recevoir une requ\u00eate HTTP sur un domaine/port, puis \u00e0 la transmettre \u00e0 un autre serveur HTTP (ou un autre port local) gr\u00e2ce \u00e0 la directive <code>proxy_pass</code>.</p>"},{"location":"_projects/_formation-nginx/nginx-chap06/#exemple-minimal-de-reverse-proxy-http","title":"Exemple minimal de reverse proxy HTTP","text":"Nginx Configuration File<pre><code>http {\n    upstream backend_app {\n        server 192.168.1.10:8080;\n    }\n\n    server {\n        listen 80;\n        server_name app.exemple.local;\n\n        location / {\n            proxy_pass http://backend_app;\n        }\n    }\n}\n</code></pre> <p>Dans cet exemple : - Le client envoie une requ\u00eate HTTP vers <code>app.exemple.local</code> sur le port 80. - Nginx transf\u00e8re la requ\u00eate au backend d\u00e9fini dans <code>upstream backend_app</code>, ici un serveur HTTP sur <code>192.168.1.10:8080</code>. - La r\u00e9ponse du backend est renvoy\u00e9e telle quelle au client.</p>"},{"location":"_projects/_formation-nginx/nginx-chap06/#variantes-durl-et-comportement-de-proxy_pass","title":"Variantes d\u2019URL et comportement de proxy_pass","text":"<p>Le comportement de <code>proxy_pass</code> d\u00e9pend fortement de la pr\u00e9sence ou non d\u2019un chemin dans l\u2019URL de destination et de la fa\u00e7on dont le <code>location</code> est d\u00e9fini. Deux cas classiques :</p> <ol> <li>Location avec un chemin et proxy_pass avec un chemin</li> </ol> Nginx Configuration File<pre><code>location /api/ {\n    proxy_pass http://backend_app/api/;\n}\n</code></pre> <ul> <li>La partie correspondant au <code>location</code> (<code>/api/</code>) est remplac\u00e9e par le chemin d\u00e9fini dans <code>proxy_pass</code> (<code>/api/</code>).  </li> <li> <p>L\u2019URI c\u00f4t\u00e9 backend reste g\u00e9n\u00e9ralement identique (en pratique, la r\u00e9\u00e9criture peut changer selon les combinaisons).</p> </li> <li> <p>Location avec un chemin et proxy_pass sans chemin</p> </li> </ul> Nginx Configuration File<pre><code>location /api/ {\n    proxy_pass http://backend_app;\n}\n</code></pre> <ul> <li>L\u2019URI compl\u00e8te (y compris <code>/api/\u2026</code>) est transmise au backend, ce qui change la mani\u00e8re dont le backend voit la requ\u00eate.  </li> <li>Souvent utilis\u00e9 pour d\u00e9l\u00e9guer totalement la structure des URL au backend.</li> </ul> <p>Un sch\u00e9ma conceptuel utile (\u00e0 rechercher, par exemple \u201cnginx proxy_pass scheme diagram\u201d) repr\u00e9sente : - En haut : l\u2019URL client (ex. <code>https://client -&gt; Nginx</code>), - Au centre : le bloc <code>location</code> avec la directive <code>proxy_pass</code>, - En bas : l\u2019URL r\u00e9ellement appel\u00e9e sur le backend.</p>"},{"location":"_projects/_formation-nginx/nginx-chap06/#passer-des-entetes-aux-serveurs-dorigine-proxy_set_header","title":"Passer des en\u2011t\u00eates aux serveurs d\u2019origine (proxy_set_header)","text":"<p>Lorsqu\u2019une requ\u00eate est proxifi\u00e9e, Nginx peut modifier, supprimer ou ajouter des en\u2011t\u00eates HTTP envoy\u00e9s au backend. C\u2019est un r\u00f4le essentiel du reverse proxy, notamment pour :</p> <ul> <li>Propager l\u2019adresse IP r\u00e9elle du client.</li> <li>Indiquer le protocole d\u2019origine (HTTP/HTTPS).</li> <li>Passer le nom d\u2019h\u00f4te demand\u00e9 (<code>Host</code>) pour la bonne virtualisation c\u00f4t\u00e9 backend.</li> <li>Ajouter des en\u2011t\u00eates internes (par exemple pour l\u2019authentification ou le routage).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap06/#entetes-courants-dans-un-reverse-proxy-nginx","title":"En\u2011t\u00eates courants dans un reverse proxy Nginx","text":"Nginx Configuration File<pre><code>location / {\n    proxy_pass http://backend_app;\n\n    proxy_set_header Host              $host;\n    proxy_set_header X-Real-IP         $remote_addr;\n    proxy_set_header X-Forwarded-For   $proxy_add_x_forwarded_for;\n    proxy_set_header X-Forwarded-Proto $scheme;\n}\n</code></pre> <p>Explications : - <code>Host</code> : conserve le nom de domaine appel\u00e9 par le client, pour que le backend sache quel site ou vhost servir. - <code>X-Real-IP</code> : transmet l\u2019IP directe du client, utile pour les logs et les r\u00e8gles applicatives. - <code>X-Forwarded-For</code> : cha\u00eene d\u2019IP (client + proxies interm\u00e9diaires), permettant de conserver un historique de passage. - <code>X-Forwarded-Proto</code> : indique si la requ\u00eate d\u2019origine \u00e9tait en HTTP ou HTTPS, utile pour les redirections et URL g\u00e9n\u00e9r\u00e9es c\u00f4t\u00e9 backend.</p>"},{"location":"_projects/_formation-nginx/nginx-chap06/#table-de-synthese-des-principaux-entetes-de-proxy","title":"Table de synth\u00e8se des principaux en\u2011t\u00eates de proxy","text":"Directive En\u2011t\u00eate HTTP R\u00f4le principal <code>proxy_set_header</code> <code>Host</code> Indique au backend le nom d\u2019h\u00f4te demand\u00e9 par le client. <code>proxy_set_header</code> <code>X-Real-IP</code> Fournit l\u2019IP r\u00e9elle du client. <code>proxy_set_header</code> <code>X-Forwarded-For</code> Liste des IP clients et proxies successifs. <code>proxy_set_header</code> <code>X-Forwarded-Proto</code> Protocole d\u2019origine (http/https). <code>proxy_set_header</code> <code>X-Forwarded-Host</code> Nom d\u2019h\u00f4te original, si besoin de le dissocier. <code>proxy_set_header</code> <code>X-Forwarded-Port</code> Port d\u2019origine c\u00f4t\u00e9 client. <p>Un sch\u00e9ma couramment rencontr\u00e9 pour illustrer ces en\u2011t\u00eates montre une fl\u00e8che : Client \u2192 Reverse Proxy (ajout/ajustement des en\u2011t\u00eates) \u2192 Backend, avec des bulles indiquant <code>X-Real-IP</code>, <code>X-Forwarded-For</code>, etc.</p>"},{"location":"_projects/_formation-nginx/nginx-chap06/#mise-en-memoire-tampon-des-reponses-proxy-proxy_buffering","title":"Mise en m\u00e9moire tampon des r\u00e9ponses proxy (proxy_buffering)","text":"<p>Nginx peut stocker (bufferiser) temporairement les r\u00e9ponses des backends avant de les envoyer au client. Cette fonctionnalit\u00e9 influe sur :</p> <ul> <li>La m\u00e9moire utilis\u00e9e et l\u2019\u00e9criture disque \u00e9ventuelle.</li> <li>La latence per\u00e7ue par le client.</li> <li>La capacit\u00e9 \u00e0 effectuer de la mise en cache HTTP ou des transformations sur la r\u00e9ponse.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap06/#directives-cles-liees-au-buffering-http","title":"Directives cl\u00e9s li\u00e9es au buffering HTTP","text":"<p>Dans un bloc <code>location</code> ou <code>server</code> :</p> Nginx Configuration File<pre><code>location / {\n    proxy_pass http://backend_app;\n\n    proxy_buffering           on;\n    proxy_buffers             8 16k;\n    proxy_buffer_size         32k;\n    proxy_busy_buffers_size   64k;\n    proxy_max_temp_file_size  0;\n}\n</code></pre> <p>R\u00f4le des directives : - <code>proxy_buffering on|off</code> : active ou d\u00e9sactive la mise en tampon des r\u00e9ponses. - <code>proxy_buffers 8 16k</code> : nombre et taille des buffers utilis\u00e9s pour stocker temporairement la r\u00e9ponse. - <code>proxy_buffer_size</code> : taille du premier buffer, utilis\u00e9 pour les en\u2011t\u00eates de r\u00e9ponse. - <code>proxy_busy_buffers_size</code> : taille maximale des buffers \u201cen cours d\u2019envoi\u201d au client. - <code>proxy_max_temp_file_size</code> : taille maximale des fichiers temporaires sur disque si la r\u00e9ponse d\u00e9passe les buffers m\u00e9moire.</p> <p>Pour des r\u00e9ponses de type API JSON de petite taille, le buffering am\u00e9liore souvent les performances, car le backend peut r\u00e9pondre rapidement, et Nginx g\u00e8re l\u2019envoi au client sans mobiliser le backend plus longtemps que n\u00e9cessaire. Pour un gros stream (par exemple un gros fichier ou du streaming vid\u00e9o), il peut \u00eatre utile de d\u00e9sactiver partiellement le buffering ou d\u2019ajuster soigneusement ces param\u00e8tres, pour \u00e9viter l\u2019utilisation excessive de disque.</p>"},{"location":"_projects/_formation-nginx/nginx-chap06/#configuration-des-delais-dattente-pour-les-proxy-timeouts","title":"Configuration des d\u00e9lais d\u2019attente pour les proxy (timeouts)","text":"<p>Les d\u00e9lais (timeouts) d\u00e9terminent le temps maximal pendant lequel Nginx attend une op\u00e9ration r\u00e9seau particuli\u00e8re avant de consid\u00e9rer qu\u2019il y a une erreur. Pour un reverse proxy, trois d\u00e9lais sont essentiels :</p> Nginx Configuration File<pre><code>location / {\n    proxy_pass http://backend_app;\n\n    proxy_connect_timeout 5s;\n    proxy_send_timeout    30s;\n    proxy_read_timeout    30s;\n}\n</code></pre> <ul> <li><code>proxy_connect_timeout</code> : d\u00e9lai maximal pour \u00e9tablir la connexion TCP avec le backend.  </li> <li><code>proxy_send_timeout</code> : d\u00e9lai pour envoyer la requ\u00eate (en\u2011t\u00eates et corps) au backend.  </li> <li><code>proxy_read_timeout</code> : d\u00e9lai pendant lequel Nginx attend des donn\u00e9es de r\u00e9ponse du backend avant de couper.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap06/#tableau-recapitulatif-des-timeouts-proxy","title":"Tableau r\u00e9capitulatif des timeouts proxy","text":"Directive Type d\u2019op\u00e9ration Effet pratique <code>proxy_connect_timeout</code> Connexion au backend \u00c9vite de rester bloqu\u00e9 si le backend ne r\u00e9pond pas du tout. <code>proxy_send_timeout</code> Envoi de la requ\u00eate au backend Prot\u00e8ge contre les blocages lors de l\u2019envoi de gros corps. <code>proxy_read_timeout</code> Lecture de la r\u00e9ponse backend Limite le temps d\u2019attente en cas de backend trop lent. <p>Dans un chemin d\u2019apprentissage, il est utile de simuler un backend lent (par exemple via un script qui dort quelques secondes) pour voir comment ces timeouts affectent les erreurs visibles c\u00f4t\u00e9 client (erreurs 504 Gateway Timeout, etc.) et comment les logs Nginx les d\u00e9crivent.</p>"},{"location":"_projects/_formation-nginx/nginx-chap06/#introduction-detaillee-a-la-notion-de-proxy-inverse","title":"Introduction d\u00e9taill\u00e9e \u00e0 la notion de proxy inverse","text":"<p>Pour consolider la compr\u00e9hension, il est utile de comparer proxy direct, proxy inverse et \u201csimple\u201d serveur web.</p>"},{"location":"_projects/_formation-nginx/nginx-chap06/#tableau-proxy-direct-vs-proxy-inverse-vs-serveur-web","title":"Tableau : proxy direct vs proxy inverse vs serveur web","text":"R\u00f4le Client connu du backend ? Backend visible du client ? Usage typique Serveur web simple Oui Oui Site statique ou dynamique simple. Proxy direct Oui Non Sortie centralis\u00e9e vers Internet (cache HTTP). Proxy inverse Non (souvent) Non Point d\u2019entr\u00e9e unique, load\u2011balancing, s\u00e9curit\u00e9. <p>Dans un contexte de reverse proxy Nginx : - Le client configure uniquement le domaine (DNS) qui pointe vers Nginx. - Nginx a connaissance de tous les backends et g\u00e8re la r\u00e9partition ou la simple redirection. - Les backends peuvent \u00eatre isol\u00e9s dans un r\u00e9seau priv\u00e9, inaccessibles directement depuis Internet, ce qui renforce la s\u00e9curit\u00e9.</p> <p>Un sch\u00e9ma typique (\u00e0 rechercher : \u201creverse proxy nginx architecture diagram\u201d) montre : Internet \u2192 Nginx (reverse proxy) \u2192 multiples backends (API, site principal, service d\u2019authentification, etc.).</p>"},{"location":"_projects/_formation-nginx/nginx-chap06/#envoyer-des-requetes-vers-phpfpm-avec-fastcgi","title":"Envoyer des requ\u00eates vers PHP\u2011FPM avec FastCGI","text":"<p>Pour le PHP, Nginx ne traite pas le code lui\u2011m\u00eame. Il d\u00e9l\u00e8gue l\u2019ex\u00e9cution \u00e0 un processus PHP\u2011FPM via le protocole FastCGI. Nginx agit alors comme reverse proxy FastCGI plut\u00f4t que HTTP.</p>"},{"location":"_projects/_formation-nginx/nginx-chap06/#configuration-de-base-pour-phpfpm","title":"Configuration de base pour PHP\u2011FPM","text":"<p>Supposons que PHP\u2011FPM \u00e9coute sur <code>127.0.0.1:9000</code> (mode TCP) ou sur un socket Unix. Un bloc Nginx typique :</p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name php.exemple.local;\n\n    root /var/www/mon_site;\n    index index.php index.html;\n\n    location / {\n        try_files $uri $uri/ /index.php?$query_string;\n    }\n\n    location ~ \\.php$ {\n        include fastcgi_params;\n        fastcgi_pass 127.0.0.1:9000;\n\n        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n        fastcgi_param SCRIPT_NAME     $fastcgi_script_name;\n    }\n}\n</code></pre> <p>Explications importantes : - <code>location ~ \\.php$</code> : ne matche que les requ\u00eates se terminant par <code>.php</code>. - <code>fastcgi_pass</code> : d\u00e9finit l\u2019adresse de PHP\u2011FPM (TCP ou socket Unix). - <code>include fastcgi_params</code> : charge un fichier fournissant les variables FastCGI standard (m\u00e9thode, URI, etc.). - <code>fastcgi_param SCRIPT_FILENAME</code> : indique \u00e0 PHP\u2011FPM quel fichier PHP ex\u00e9cuter. - <code>try_files</code> dans la location <code>/</code> : permet de router vers <code>index.php</code> si le fichier demand\u00e9 n\u2019existe pas (cas courant pour les frameworks et CMS).</p>"},{"location":"_projects/_formation-nginx/nginx-chap06/#parametres-fastcgi-utiles","title":"Param\u00e8tres FastCGI utiles","text":"<p>En plus de <code>SCRIPT_FILENAME</code> et <code>SCRIPT_NAME</code>, quelques param\u00e8tres sont souvent ajust\u00e9s :</p> Nginx Configuration File<pre><code>location ~ \\.php$ {\n    include fastcgi_params;\n\n    fastcgi_pass unix:/run/php/php-fpm.sock;\n\n    fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n    fastcgi_param SCRIPT_NAME     $fastcgi_script_name;\n    fastcgi_param HTTPS           $https if_not_empty;\n}\n</code></pre> <ul> <li>Utilisation d\u2019un socket Unix (<code>unix:/run/php/php-fpm.sock</code>) pour des performances l\u00e9g\u00e8rement meilleures en local.  </li> <li>Passage de <code>HTTPS</code> \u00e0 PHP afin que l\u2019application sache si la requ\u00eate d\u2019origine \u00e9tait s\u00e9curis\u00e9e, m\u00eame si l\u2019on termine TLS sur Nginx.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap06/#tableau-proxy-http-vs-fastcgi","title":"Tableau : proxy HTTP vs FastCGI","text":"Aspect Proxy HTTP (<code>proxy_pass</code>) FastCGI (<code>fastcgi_pass</code>) Protocole HTTP/1.1 (ou autre support\u00e9) FastCGI (binaire) Cible typique Serveur web ou API HTTP PHP\u2011FPM (interpr\u00e9teur PHP) Directives d\u2019en\u2011t\u00eates <code>proxy_set_header</code> <code>fastcgi_param</code> Fichier de param\u00e8tres <code>proxy_params</code> (optionnel) <code>fastcgi_params</code> ou <code>fastcgi.conf</code> R\u00f4le principal Passerelle HTTP g\u00e9n\u00e9rique Ex\u00e9cution de scripts PHP"},{"location":"_projects/_formation-nginx/nginx-chap06/#exercices-et-progression-pratique","title":"Exercices et progression pratique","text":"<p>Pour consolider l\u2019apprentissage, une progression pratique peut \u00eatre structur\u00e9e ainsi :</p> <ol> <li>Premier reverse proxy HTTP simple </li> <li>Mettre en place un backend HTTP (par exemple un petit serveur sur <code>localhost:8080</code>).  </li> <li>Cr\u00e9er une configuration Nginx minimaliste avec <code>proxy_pass</code>.  </li> <li> <p>V\u00e9rifier que les en\u2011t\u00eates de r\u00e9ponse retourn\u00e9s au client proviennent du backend.</p> </li> <li> <p>Ajout d\u2019en\u2011t\u00eates et inspection c\u00f4t\u00e9 backend </p> </li> <li>Ajouter <code>proxy_set_header</code> pour <code>X-Real-IP</code>, <code>X-Forwarded-For</code>, <code>X-Forwarded-Proto</code>.  </li> <li>C\u00f4t\u00e9 backend, \u00e9crire un script (PHP, Python ou autre) qui affiche les en\u2011t\u00eates re\u00e7us.  </li> <li> <p>Observer comment ces en\u2011t\u00eates varient si Nginx est appel\u00e9 en HTTP ou HTTPS.</p> </li> <li> <p>Exp\u00e9rimentation du buffering </p> </li> <li>Configurer <code>proxy_buffering on/off</code> et jouer sur <code>proxy_buffers</code>, <code>proxy_buffer_size</code>.  </li> <li>Tester avec des r\u00e9ponses de tailles diff\u00e9rentes (petits JSON, gros fichiers).  </li> <li> <p>Observer dans les logs si des fichiers temporaires sont utilis\u00e9s.</p> </li> <li> <p>Tests de timeouts </p> </li> <li>Cr\u00e9er un endpoint backend qui r\u00e9pond avec d\u00e9lai (par exemple <code>sleep 10</code>).  </li> <li>R\u00e9duire <code>proxy_read_timeout</code> pour provoquer un timeout c\u00f4t\u00e9 Nginx.  </li> <li> <p>Analyser les logs et les codes d\u2019erreur.</p> </li> <li> <p>Mise en place de PHP\u2011FPM </p> </li> <li>Installer PHP\u2011FPM et v\u00e9rifier l\u2019\u00e9coute (TCP ou socket Unix).  </li> <li>Configurer un site PHP avec <code>fastcgi_pass</code> et les bons <code>fastcgi_param</code>.  </li> <li>Tester diff\u00e9rents sc\u00e9narios : fichiers inexistants, erreurs PHP, etc., et observer la gestion des erreurs par Nginx.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap06/#comment-rechercher-et-exploiter-des-schemas-utiles","title":"Comment rechercher et exploiter des sch\u00e9mas utiles","text":"<p>M\u00eame si une int\u00e9gration directe d\u2019images externes ne peut pas \u00eatre garantie ici, des termes de recherche cibl\u00e9s permettent de trouver rapidement des sch\u00e9mas adapt\u00e9s :  </p> <ul> <li>\u201cnginx reverse proxy basic architecture\u201d pour des sch\u00e9mas montrant client \u2192 Nginx \u2192 backend.  </li> <li>\u201cnginx proxy_pass uri rewriting diagram\u201d pour comprendre la r\u00e9\u00e9criture d\u2019URI.  </li> <li>\u201cnginx fastcgi php-fpm diagram\u201d pour visualiser la relation Nginx\u2013FastCGI\u2013PHP\u2011FPM.  </li> </ul> <p>Ces sch\u00e9mas se lisent en g\u00e9n\u00e9ral de gauche \u00e0 droite (ou de haut en bas), avec le client \u00e0 gauche/haut, Nginx au centre, et les backends \u00e0 droite/bas, les fl\u00e8ches montrant le chemin de la requ\u00eate et de la r\u00e9ponse, parfois avec les en\u2011t\u00eates ou param\u00e8tres ajout\u00e9s sur le trajet.</p> <p>En suivant ce chemin d\u2019apprentissage, la compr\u00e9hension du r\u00f4le de Nginx comme proxy inverse, puis comme passerelle vers PHP\u2011FPM, devient progressive et structur\u00e9e, tout en s\u2019appuyant sur des configurations concr\u00e8tes, des tests pratiques et des sch\u00e9mas conceptuels recherch\u00e9s au besoin.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-nginx/nginx-chap07/","title":"Citations","text":"<ul> <li>https://nginxui.com/guide/nginx-proxy-example</li> <li>https://www.theserverside.com/blog/Coffee-Talk-Java-News-Stories-and-Opinions/How-to-setup-Nginx-reverse-proxy-servers-by-example</li> <li>https://www.hostinger.com/tutorials/how-to-set-up-nginx-reverse-proxy</li> <li>https://www.digitalocean.com/community/tutorials/how-to-configure-nginx-as-a-reverse-proxy-on-ubuntu-22-04</li> <li>https://www.youtube.com/watch?v=lZVAI3PqgHc</li> <li>https://docs.nginx.com/nginx/admin-guide/web-server/reverse-proxy/</li> <li>https://gist.github.com/mreferre/38297db0c7a279a25d234e572c975b75</li> <li>https://www.jenkins.io/doc/book/system-administration/reverse-proxy-configuration-with-jenkins/reverse-proxy-configuration-nginx/</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap07/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 255</li> <li>completion_tokens: 4098</li> <li>total_tokens: 4353</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.061, 'request_cost': 0.006, 'total_cost': 0.068}</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap07/#content","title":"Content","text":"<p>La configuration d\u2019un reverse proxy Nginx suit toujours la m\u00eame logique : un client envoie une requ\u00eate HTTP(S) vers Nginx, qui la transf\u00e8re ensuite \u00e0 une ou plusieurs applications internes (backends), tout en contr\u00f4lant les en-t\u00eates, la s\u00e9curit\u00e9, le routage, le cache et parfois les websockets. Ce chapitre d\u00e9taille cette logique sur plusieurs cas concrets (local, API + SPA, Docker Compose, PHP-FPM, WebSocket) et propose un chemin d\u2019apprentissage progressif.</p> <p>Remarque importante : l\u2019environnement ne permet pas ici d\u2019aller v\u00e9rifier en direct l\u2019existence de ressources externes (images, sch\u00e9mas). Lorsque des diagrammes sont propos\u00e9s, ils sont fournis au format ASCII ou pseudo-graphique, de mani\u00e8re \u00e0 rester auto\u2011contenus et exploitables.</p>"},{"location":"_projects/_formation-nginx/nginx-chap07/#vue-densemble-du-reverse-proxy","title":"Vue d\u2019ensemble du reverse proxy","text":"<p>Un reverse proxy Nginx re\u00e7oit les requ\u00eates des clients et les redirige vers des serveurs applicatifs internes, souvent sur d\u2019autres ports ou h\u00f4tes, en masquant l\u2019infrastructure interne. L\u2019apprentissage se construit en couches : d\u2019abord un reverse proxy local simple, ensuite la gestion d\u2019API et de SPA, puis l\u2019orchestration avec Docker, le lien avec PHP-FPM, et enfin le support de WebSocket.</p> <p>Sch\u00e9ma conceptuel minimal :</p> Text Only<pre><code>[Client] ---&gt; [Nginx (Reverse Proxy)] ---&gt; [App 1 (API)]\n                                    \u2514--&gt; [App 2 (SPA)]\n                                    \u2514--&gt; [App 3 (PHP-FPM)]\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap07/#reverse-proxy-local","title":"Reverse proxy local","text":""},{"location":"_projects/_formation-nginx/nginx-chap07/#objectif-pedagogique","title":"Objectif p\u00e9dagogique","text":"<ul> <li>Comprendre la structure de base de la configuration Nginx (http, server, location).</li> <li>Ma\u00eetriser <code>proxy_pass</code>, les en-t\u00eates courants (<code>Host</code>, <code>X-Real-IP</code>, etc.).</li> <li>Savoir mettre en place un reverse proxy unique vers une application locale (Node.js, Tomcat, Python, etc.).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap07/#chemin-dapprentissage","title":"Chemin d\u2019apprentissage","text":"<ol> <li>Installer Nginx et rep\u00e9rer les fichiers de configuration (<code>nginx.conf</code>, <code>sites-available</code>, <code>sites-enabled</code>).</li> <li>Mettre en place une application locale simple (ex. un serveur HTTP sur le port 8080).</li> <li>Configurer un virtual host Nginx qui \u00e9coute sur le port 80 et redirige vers <code>http://127.0.0.1:8080</code>.</li> <li>Ajouter progressivement les en-t\u00eates standards li\u00e9s aux proxys.</li> <li>Tester, observer les logs, et jouer sur les timeouts / buffers.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap07/#exemple-de-configuration-minimale","title":"Exemple de configuration minimale","text":"Nginx Configuration File<pre><code>http {\n    upstream local_app {\n        server 127.0.0.1:8080;\n    }\n\n    server {\n        listen 80;\n        server_name example.local;\n\n        access_log /var/log/nginx/example.local.access.log;\n        error_log  /var/log/nginx/example.local.error.log;\n\n        location / {\n            proxy_pass         http://local_app;\n            proxy_set_header   Host              $host;\n            proxy_set_header   X-Real-IP         $remote_addr;\n            proxy_set_header   X-Forwarded-For   $proxy_add_x_forwarded_for;\n            proxy_set_header   X-Forwarded-Proto $scheme;\n\n            proxy_connect_timeout 3s;\n            proxy_read_timeout    30s;\n            proxy_send_timeout    30s;\n        }\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap07/#points-cles-a-experimenter","title":"Points cl\u00e9s \u00e0 exp\u00e9rimenter","text":"<ul> <li>Modifier <code>server_name</code> et v\u00e9rifier le routage par host virtuel.</li> <li>Faire tomber l\u2019application sur 8080 et observer le comportement de Nginx (codes d\u2019erreur, pages d\u2019erreur).</li> <li>Activer/d\u00e9sactiver les logs, ou changer leur niveau de d\u00e9tail.</li> <li>Ajouter une redirection HTTP \u2192 HTTPS (au moins au niveau conceptuel) :</li> </ul> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name example.local;\n    return 301 https://$host$request_uri;\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap07/#reverse-proxy-api-et-spa","title":"Reverse proxy API et SPA","text":"<p>Ce cas couvre un sc\u00e9nario tr\u00e8s courant : - un backend API (REST/GraphQL, par exemple sur <code>localhost:3000</code>), - une SPA (React/Vue/Angular) servie soit statiquement par Nginx, soit par un autre serveur (port diff\u00e9rent).</p> <p>Le reverse proxy joue alors un r\u00f4le de gateway unique, exposant un seul domaine au navigateur.</p>"},{"location":"_projects/_formation-nginx/nginx-chap07/#objectifs-pedagogiques","title":"Objectifs p\u00e9dagogiques","text":"<ul> <li>Servir une SPA statique avec Nginx (ou via un backend) tout en d\u00e9l\u00e9guant <code>/api</code> \u00e0 une API.</li> <li>G\u00e9rer le CORS directement \u00e0 l\u2019API ou via le reverse proxy si n\u00e9cessaire.</li> <li>Comprendre le routage par pr\u00e9fixe (<code>location /api/</code> vs <code>location /</code>).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap07/#schema-logique","title":"Sch\u00e9ma logique","text":"Text Only<pre><code>Client\n  |   GET /         GET /api/users\n  v         v\n[Nginx] ---+-----------------------------------+\n  | location / (SPA)                           |\n  | location /api/ (API)                       |\n  v                                           v\n[SPA statique]                           [API backend]\n(port 8081)                               (port 3000)\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap07/#exemple-de-configuration-api-spa-spa-statique-sur-nginx","title":"Exemple de configuration API + SPA (SPA statique sur Nginx)","text":"Nginx Configuration File<pre><code>http {\n    upstream api_backend {\n        server 127.0.0.1:3000;\n    }\n\n    server {\n        listen 80;\n        server_name app.local;\n\n        # SPA statique\n        root /var/www/app-spa/dist;\n        index index.html;\n\n        # D\u00e9l\u00e9gation des appels API\n        location /api/ {\n            proxy_pass         http://api_backend;\n            proxy_set_header   Host              $host;\n            proxy_set_header   X-Real-IP         $remote_addr;\n            proxy_set_header   X-Forwarded-For   $proxy_add_x_forwarded_for;\n            proxy_set_header   X-Forwarded-Proto $scheme;\n\n            # D\u00e9sactiver \u00e9ventuellement le buffering si besoin\n            # proxy_buffering off;\n        }\n\n        # Routage SPA (HTML5 history mode)\n        location / {\n            try_files $uri $uri/ /index.html;\n        }\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap07/#variantes-et-approfondissements","title":"Variantes et approfondissements","text":"<ul> <li>SPA servie par un dev\u2011server (ex. <code>npm run dev</code> sur port 5173) en d\u00e9veloppement :</li> <li><code>location /</code> \u2192 <code>proxy_pass http://127.0.0.1:5173;</code></li> <li><code>location /api/</code> \u2192 proxy vers <code>3000</code>.</li> <li>Ajouter des r\u00e8gles de s\u00e9curit\u00e9 :</li> <li><code>add_header X-Frame-Options SAMEORIGIN;</code></li> <li><code>add_header X-Content-Type-Options nosniff;</code></li> <li><code>add_header X-XSS-Protection \"1; mode=block\";</code></li> <li>G\u00e9rer le CORS si l\u2019API n\u2019inclut pas les en-t\u00eates :</li> <li><code>add_header Access-Control-Allow-Origin ...</code> sous <code>location /api/</code>.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap07/#reverse-proxy-api-et-spa-avec-docker-compose","title":"Reverse proxy API et SPA avec Docker Compose","text":"<p>Dans ce sc\u00e9nario, Nginx, l\u2019API et la SPA (ou au moins son serveur de fichiers) sont tous des services Docker. Le reverse proxy devient le point d\u2019entr\u00e9e du r\u00e9seau Docker, souvent expos\u00e9 sur le port 80/443 de l\u2019h\u00f4te.</p>"},{"location":"_projects/_formation-nginx/nginx-chap07/#objectifs-pedagogiques_1","title":"Objectifs p\u00e9dagogiques","text":"<ul> <li>Comprendre le r\u00e9seau Docker par d\u00e9faut (bridge) et les noms de services comme DNS internes.</li> <li>Configurer Nginx en se basant sur les noms des services Docker (<code>api</code>, <code>spa</code>) plut\u00f4t que sur <code>localhost</code>.</li> <li>Mettre en place un <code>docker-compose.yml</code> complet avec Nginx en front.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap07/#exemple-de-docker-composeyml-simplifie","title":"Exemple de <code>docker-compose.yml</code> (simplifi\u00e9)","text":"YAML<pre><code>version: \"3.9\"\n\nservices:\n  nginx:\n    image: nginx:stable\n    container_name: nginx_gateway\n    volumes:\n      - ./nginx/conf.d:/etc/nginx/conf.d:ro\n      - ./nginx/logs:/var/log/nginx\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    depends_on:\n      - api\n      - spa\n\n  api:\n    build: ./api\n    container_name: api_service\n    expose:\n      - \"3000\"\n\n  spa:\n    image: nginx:stable\n    container_name: spa_service\n    volumes:\n      - ./spa/dist:/usr/share/nginx/html:ro\n    expose:\n      - \"80\"\n</code></pre> <p>Ici, <code>api</code> \u00e9coute sur <code>3000</code> \u00e0 l\u2019int\u00e9rieur du conteneur, <code>spa</code> expose ses fichiers sur <code>80</code>, et Nginx les atteint via les noms de service <code>api</code> et <code>spa</code>.</p>"},{"location":"_projects/_formation-nginx/nginx-chap07/#configuration-nginx-dans-docker-nginxconfdappconf","title":"Configuration Nginx dans Docker (<code>./nginx/conf.d/app.conf</code>)","text":"Nginx Configuration File<pre><code>upstream api_backend {\n    server api:3000;\n}\n\nupstream spa_frontend {\n    server spa:80;\n}\n\nserver {\n    listen 80;\n    server_name app.local;\n\n    # Proxy vers l'API Dockeris\u00e9e\n    location /api/ {\n        proxy_pass         http://api_backend;\n        proxy_set_header   Host              $host;\n        proxy_set_header   X-Real-IP         $remote_addr;\n        proxy_set_header   X-Forwarded-For   $proxy_add_x_forwarded_for;\n        proxy_set_header   X-Forwarded-Proto $scheme;\n    }\n\n    # Proxy vers la SPA (servie par un Nginx interne)\n    location / {\n        proxy_pass http://spa_frontend;\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap07/#etapes-dapprentissage","title":"\u00c9tapes d\u2019apprentissage","text":"<ol> <li>D\u00e9marrer par une configuration Nginx fonctionnant hors Docker (cas pr\u00e9c\u00e9dent).</li> <li>Conteneuriser l\u2019API seule, puis adapter <code>proxy_pass</code> (<code>http://127.0.0.1:3000</code> \u2192 <code>http://api:3000</code>).</li> <li>Conteneuriser ensuite la SPA, l\u2019attacher \u00e0 Nginx via <code>upstream spa_frontend</code>.</li> <li>G\u00e9rer les logs dans Docker (liaison de volumes), et tester la mise \u00e0 jour des conteneurs sans red\u00e9marrer toute la stack.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap07/#reverse-proxy-avec-php-fpm","title":"Reverse proxy avec PHP-FPM","text":"<p>Ce module se concentre sur l\u2019int\u00e9gration classique Nginx + PHP-FPM, o\u00f9 Nginx sert les fichiers statiques et d\u00e9l\u00e8gue l\u2019ex\u00e9cution PHP \u00e0 PHP-FPM via un socket Unix ou TCP.</p>"},{"location":"_projects/_formation-nginx/nginx-chap07/#objectifs-pedagogiques_2","title":"Objectifs p\u00e9dagogiques","text":"<ul> <li>Comprendre la diff\u00e9rence entre proxy HTTP (<code>proxy_pass</code>) et passerelle FastCGI (<code>fastcgi_pass</code>).</li> <li>Configurer Nginx pour servir \u00e0 la fois des fichiers statiques et des scripts PHP sur la m\u00eame machine.</li> <li>Ajuster les param\u00e8tres FastCGI (buffers, timeouts, variables d\u2019environnement PHP).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap07/#schema-conceptuel","title":"Sch\u00e9ma conceptuel","text":"Text Only<pre><code>[Client] --&gt; [Nginx]\n   |            |\n   | /images    |--&gt; Fichiers statiques (Nginx)\n   | /index.php |--&gt; PHP-FPM (FastCGI)\n   v            v\n            [php-fpm]\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap07/#exemple-de-configuration-nginx-php-fpm","title":"Exemple de configuration Nginx + PHP-FPM","text":"Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name php.local;\n    root /var/www/php-app/public;\n    index index.php index.html;\n\n    # Fichiers statiques\n    location / {\n        try_files $uri $uri/ /index.php?$query_string;\n    }\n\n    # Traitement des scripts PHP\n    location ~ \\.php$ {\n        include fastcgi_params;\n\n        fastcgi_pass unix:/run/php/php8.2-fpm.sock;\n        # ou fastcgi_pass 127.0.0.1:9000;\n\n        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;\n        fastcgi_param PATH_INFO       $fastcgi_path_info;\n\n        fastcgi_buffers 16 16k;\n        fastcgi_buffer_size 32k;\n        fastcgi_read_timeout 60s;\n    }\n\n    # S\u00e9curiser l'acc\u00e8s aux fichiers sensibles\n    location ~ /\\.ht {\n        deny all;\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap07/#points-pedagogiques-importants","title":"Points p\u00e9dagogiques importants","text":"<ul> <li>Bien comprendre la variable <code>SCRIPT_FILENAME</code> qui indique \u00e0 PHP-FPM le chemin r\u00e9el du script.</li> <li>Savoir faire la diff\u00e9rence entre :</li> <li><code>proxy_pass http://backend;</code> (backend HTTP)</li> <li><code>fastcgi_pass unix:/run/php/php-fpm.sock;</code> (backend FastCGI pour PHP).</li> <li>Tester le <code>phpinfo()</code> et v\u00e9rifier que les en-t\u00eates HTTP et les variables serveur sont coh\u00e9rents (host, remote_addr, etc.).</li> <li>Voir comment Nginx et PHP-FPM interagissent sur la performance (buffers, <code>pm</code> dans PHP-FPM, etc.).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap07/#reverse-proxy-et-protocole-websocket","title":"Reverse proxy et protocole WebSocket","text":"<p>Le cas WebSocket ajoute une contrainte : le reverse proxy doit supporter l\u2019upgrade de protocole HTTP \u2192 WebSocket (en-t\u00eate <code>Upgrade: websocket</code> et <code>Connection: upgrade</code>) et maintenir la connexion ouverte.</p>"},{"location":"_projects/_formation-nginx/nginx-chap07/#objectifs-pedagogiques_3","title":"Objectifs p\u00e9dagogiques","text":"<ul> <li>Comprendre la phase d\u2019upgrade HTTP \u2192 WebSocket.</li> <li>Configurer Nginx pour transmettre correctement les en\u2011t\u00eates <code>Upgrade</code> et <code>Connection</code>.</li> <li>G\u00e9rer les timeouts et \u00e9ventuellement d\u00e9sactiver certains m\u00e9canismes de buffering.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap07/#schema-dechange","title":"Sch\u00e9ma d\u2019\u00e9change","text":"Text Only<pre><code>Client\n  |  HTTP GET /ws  + Upgrade: websocket\n  v\n[Nginx Reverse Proxy]\n  |  HTTP GET /ws  + Upgrade: websocket\n  v\n[Serveur WebSocket (ex: ws://127.0.0.1:4000)]\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap07/#configuration-type-pour-websocket","title":"Configuration type pour WebSocket","text":"Nginx Configuration File<pre><code>map $http_upgrade $connection_upgrade {\n    default upgrade;\n    ''      close;\n}\n\nupstream ws_backend {\n    server 127.0.0.1:4000;\n}\n\nserver {\n    listen 80;\n    server_name ws.local;\n\n    # Endpoint WebSocket\n    location /ws/ {\n        proxy_pass         http://ws_backend;\n\n        proxy_http_version 1.1;\n        proxy_set_header   Upgrade    $http_upgrade;\n        proxy_set_header   Connection $connection_upgrade;\n\n        proxy_set_header   Host              $host;\n        proxy_set_header   X-Real-IP         $remote_addr;\n        proxy_set_header   X-Forwarded-For   $proxy_add_x_forwarded_for;\n        proxy_set_header   X-Forwarded-Proto $scheme;\n\n        proxy_read_timeout  3600s;\n        proxy_send_timeout  3600s;\n    }\n\n    # Autre trafic (HTTP classique)\n    location / {\n        proxy_pass http://127.0.0.1:8080;\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap07/#etapes-dapprentissage_1","title":"\u00c9tapes d\u2019apprentissage","text":"<ol> <li>Mettre en place un serveur WebSocket simple (Node.js, Go, etc.) sur un port local.</li> <li>Tester la connexion directe (<code>ws://127.0.0.1:4000</code>) avec un client WebSocket (navigateur, script d\u2019essai).</li> <li>Introduire Nginx entre les deux :</li> <li>Endpoint public : <code>ws://ws.local/ws/</code></li> <li>Backend interne : <code>127.0.0.1:4000</code></li> <li>V\u00e9rifier que les connexions persistent et que les messages transitent correctement malgr\u00e9 le proxy.</li> <li>Ajuster les timeouts, v\u00e9rifier l\u2019impact sur des connexions longues ou des clients inactifs.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap07/#chemin-dapprentissage-detaille-fil-conducteur","title":"Chemin d\u2019apprentissage d\u00e9taill\u00e9 (fil conducteur)","text":"<p>Pour relier l\u2019ensemble de ces modules :</p> <ol> <li>Fondations Nginx (1\u20132 jours)</li> <li>Lire la structure g\u00e9n\u00e9rale des blocs (<code>events</code>, <code>http</code>, <code>server</code>, <code>location</code>).</li> <li>Exp\u00e9rimenter un reverse proxy local simple (un seul backend HTTP).</li> <li> <p>Apprendre \u00e0 relire et recharger la configuration (<code>nginx -t</code>, <code>systemctl reload</code>).</p> </li> <li> <p>Routage avanc\u00e9 (2\u20133 jours)</p> </li> <li>Ajouter plusieurs <code>location</code> avec des pr\u00e9fixes (<code>/</code>, <code>/api/</code>, <code>/admin/</code>).</li> <li>Mettre en place API + SPA sur une m\u00eame instance Nginx.</li> <li> <p>Manipuler les en\u2011t\u00eates (<code>proxy_set_header</code>) et les timeouts.</p> </li> <li> <p>Int\u00e9gration Docker (2\u20133 jours)</p> </li> <li>\u00c9crire un <code>docker-compose.yml</code> incluant au minimum <code>nginx</code> + <code>api</code>.</li> <li>Comprendre la r\u00e9solution DNS interne Docker par nom de service.</li> <li> <p>\u00c9tendre \u00e0 <code>nginx</code> + <code>api</code> + <code>spa</code>, puis g\u00e9rer les mises \u00e0 jour des services ind\u00e9pendamment.</p> </li> <li> <p>PHP-FPM et FastCGI (2\u20133 jours)</p> </li> <li>Installer PHP-FPM et relier Nginx via <code>fastcgi_pass</code>.</li> <li>Servir une application PHP r\u00e9elle (ex. mini CMS).</li> <li> <p>Comparer les flux : proxy HTTP vs FastCGI, et jouer sur les param\u00e8tres de performance.</p> </li> <li> <p>WebSockets et temps r\u00e9el (2\u20133 jours)</p> </li> <li>Mettre en place un petit chat WebSocket de test.</li> <li>Placer Nginx en front, v\u00e9rifier l\u2019upgrade de protocole.</li> <li>Tester la stabilit\u00e9 (longues connexions, perte r\u00e9seau, reconnections).</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap07/#tableau-recapitulatif-des-cas-etudies","title":"Tableau r\u00e9capitulatif des cas \u00e9tudi\u00e9s","text":"Cas Type de backend principal Directive Nginx cl\u00e9 \u00c9l\u00e9ment d\u2019apprentissage majeur Reverse proxy local HTTP simple (Node, Tomcat\u2026) <code>proxy_pass</code> Structure de base, en-t\u00eates, timeouts Reverse proxy API + SPA API HTTP + fichiers statiques <code>proxy_pass</code>, <code>try_files</code> Routage par pr\u00e9fixe, SPA et history mode API + SPA avec Docker Services Docker HTTP <code>proxy_pass</code> vers noms R\u00e9seau Docker, DNS interne, orchestration Reverse proxy avec PHP-FPM PHP via FastCGI <code>fastcgi_pass</code> Diff\u00e9rence HTTP/FastCGI, variable <code>SCRIPT_FILENAME</code> Reverse proxy WebSocket Serveur WebSocket <code>proxy_http_version 1.1</code> Upgrade de protocole, connexions persistantes, timeouts <p>M\u00eame sans acc\u00e8s direct \u00e0 des images externes, chaque bloc de configuration et chaque sch\u00e9ma ASCII permet de visualiser les flux et de progresser \u00e9tape par \u00e9tape, en allant du reverse proxy le plus simple jusqu\u2019aux sc\u00e9narios temps r\u00e9el et multi\u2011conteneurs.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-nginx/nginx-chap08/","title":"Citations","text":"<ul> <li>https://angristan.fr/configurer-https-nginx/</li> <li>https://blog.stephane-robert.info/docs/services/web/nginx/</li> <li>https://www.it-connect.fr/nginx-ajouter-un-certificat-ssl-lets-encrypt-pour-passer-en-https/</li> <li>https://pro-domo.ddns.net/blog/tutoriel-configuration-nginx-https-letsencrypt-certbot.html</li> <li>https://nfrappe.fr/doc/doku.php?id=tutoriel%3Ainternet%3Anginx%3Assl%3Aautosigne%3Astart</li> <li>https://www.ionos.fr/digitalguide/serveur/configuration/tutoriel-nginx-premiers-pas-avec-nginxconf/</li> <li>https://www.youtube.com/watch?v=bgkFqkqWHLQ</li> <li>https://www.f5.com/fr_fr/company/blog/nginx/setting-up-nginx</li> <li>https://grafikart.fr/tutoriels/nginx-692</li> <li>https://forum.hacf.fr/t/acces-de-l-exterieur-en-https-avec-nginx-proxy-manager/1761</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap08/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 283</li> <li>completion_tokens: 4773</li> <li>total_tokens: 5056</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.072, 'request_cost': 0.006, 'total_cost': 0.078}</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap08/#content","title":"Content","text":"<p>Il est impossible, dans le cadre actuel, de garantir l\u2019usage des ressources externes demand\u00e9es (notamment le site datascientest.com) ni de v\u00e9rifier l\u2019existence d\u2019images pr\u00e9cises\u202f; seules des explications g\u00e9n\u00e9rales et des exemples originaux peuvent \u00eatre fournis, sans reprise de contenus prot\u00e9g\u00e9s. L\u2019expos\u00e9 ci\u2011dessous propose donc un cours complet, structur\u00e9 et d\u00e9taill\u00e9 sur la s\u00e9curisation HTTPS avec NGINX, en respectant ces contraintes.</p>"},{"location":"_projects/_formation-nginx/nginx-chap08/#objectifs-du-chapitre","title":"Objectifs du chapitre","text":"<p>Ce chapitre vise \u00e0 comprendre en profondeur le fonctionnement de HTTPS dans NGINX, depuis la configuration de base jusqu\u2019aux optimisations modernes\u202f: choix des protocoles, des suites de chiffrement, activation de HSTS, mise en place de l\u2019OCSP stapling et compr\u00e9hension du handshake TLS et de la cha\u00eene de certificats. L\u2019approche suit un chemin d\u2019apprentissage progressif\u202f: partir d\u2019un simple virtual host HTTPS, renforcer peu \u00e0 peu la configuration, puis analyser ce qui se passe \u201csous le capot\u201d.</p>"},{"location":"_projects/_formation-nginx/nginx-chap08/#utiliser-https-avec-nginx","title":"Utiliser HTTPS avec NGINX","text":""},{"location":"_projects/_formation-nginx/nginx-chap08/#principe-general","title":"Principe g\u00e9n\u00e9ral","text":"<p>HTTPS est HTTP encapsul\u00e9 dans TLS\u202f: le navigateur et le serveur \u00e9tablissent d\u2019abord une connexion chiffr\u00e9e, puis \u00e9changent les requ\u00eates et r\u00e9ponses HTTP \u00e0 l\u2019int\u00e9rieur de ce tunnel s\u00e9curis\u00e9. L\u2019activation de HTTPS dans NGINX repose principalement sur le module <code>ngx_http_ssl_module</code>, la pr\u00e9sence d\u2019un certificat et d\u2019une cl\u00e9 priv\u00e9e, et l\u2019\u00e9coute sur le port 443.</p>"},{"location":"_projects/_formation-nginx/nginx-chap08/#chemin-dapprentissage","title":"Chemin d\u2019apprentissage","text":"<ol> <li>Comprendre la diff\u00e9rence HTTP / HTTPS (port 80 vs 443, chiffrement, certificat).</li> <li>G\u00e9n\u00e9rer ou obtenir un certificat (auto\u2011sign\u00e9, AC interne, Let\u2019s Encrypt, AC commerciale).</li> <li>Cr\u00e9er un premier bloc <code>server</code> minimal en HTTPS.</li> <li>Mettre en place la redirection HTTP \u2192 HTTPS.</li> <li>Tester avec un navigateur et des outils en ligne de commande (curl, openssl).</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap08/#exemple-bloc-http-redirection-vers-https","title":"Exemple\u202f: bloc HTTP + redirection vers HTTPS","text":"Nginx Configuration File<pre><code># Bloc HTTP (port 80) : uniquement pour rediriger vers HTTPS\nserver {\n    listen      80;\n    server_name exemple.com www.exemple.com;\n\n    # Redirection permanente vers HTTPS\n    return 301 https://$host$request_uri;\n}\n</code></pre> <p>Points cl\u00e9s de cet exemple\u202f:</p> <ul> <li><code>listen 80;</code> indique l\u2019\u00e9coute sur le port HTTP standard.</li> <li>La directive <code>return 301</code> renvoie imm\u00e9diatement le client vers la m\u00eame URL en HTTPS.</li> <li>Cette redirection garantit que tout le trafic passe ensuite par le canal chiffr\u00e9.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap08/#exemple-premier-bloc-https-minimal","title":"Exemple\u202f: premier bloc HTTPS minimal","text":"Nginx Configuration File<pre><code>server {\n    listen              443 ssl http2;\n    server_name         exemple.com www.exemple.com;\n\n    # Chemins vers le certificat et la cl\u00e9 priv\u00e9e\n    ssl_certificate     /etc/ssl/certs/exemple.com.fullchain.pem;\n    ssl_certificate_key /etc/ssl/private/exemple.com.key;\n\n    # Racine du site\n    root /var/www/exemple.com;\n    index index.html index.htm;\n\n    location / {\n        try_files $uri $uri/ =404;\n    }\n}\n</code></pre> <p>\u00c9l\u00e9ments \u00e0 noter\u202f:</p> <ul> <li><code>listen 443 ssl http2;</code> active TLS et HTTP/2 sur le port 443.</li> <li><code>ssl_certificate</code> pointe en g\u00e9n\u00e9ral vers la cha\u00eene compl\u00e8te (certificat du serveur + interm\u00e9diaire).</li> <li><code>ssl_certificate_key</code> doit rester strictement confidentielle.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap08/#configuration-avancee-de-https","title":"Configuration avanc\u00e9e de HTTPS","text":"<p>Une fois HTTPS fonctionnel, l\u2019\u00e9tape suivante consiste \u00e0 renforcer la s\u00e9curit\u00e9 et les performances. Cela implique le choix des protocoles TLS, des suites de chiffrement, la gestion des sessions TLS, et \u00e9ventuellement la configuration d\u2019options avanc\u00e9es comme les courbes ECDH ou les tickets de session.</p>"},{"location":"_projects/_formation-nginx/nginx-chap08/#etapes-dapprentissage","title":"\u00c9tapes d\u2019apprentissage","text":"<ol> <li>Comprendre les versions de TLS (TLS 1.0\u20131.3) et les faiblesses des anciennes versions.</li> <li>Savoir ce qu\u2019est une \u201ccipher suite\u201d et pourquoi certaines sont obsol\u00e8tes.</li> <li>Ajuster progressivement la configuration en s\u2019appuyant sur des profils \u201cmodernes\u201d ou \u201cinterm\u00e9diaires\u201d.</li> <li>Tester le site avec des outils d\u2019analyse TLS (par exemple, services de type \u201cSSL Labs\u201d).</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap08/#directives-tls-typiques","title":"Directives TLS typiques","text":"Nginx Configuration File<pre><code>ssl_protocols TLSv1.2 TLSv1.3;\nssl_prefer_server_ciphers on;\n\n# Exemple de suites de chiffrement \"modernes\"\nssl_ciphers 'TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256';\n</code></pre> <p>Explications\u202f:</p> <ul> <li><code>ssl_protocols</code> limite les versions accept\u00e9es de TLS, en excluant SSLv3, TLS 1.0 et 1.1 souvent consid\u00e9r\u00e9s comme obsol\u00e8tes.</li> <li><code>ssl_prefer_server_ciphers on;</code> demande au serveur d\u2019imposer son ordre pr\u00e9f\u00e9r\u00e9 de suites de chiffrement.</li> <li><code>ssl_ciphers</code> d\u00e9finit pr\u00e9cis\u00e9ment les suites autoris\u00e9es (pour TLS 1.2)\u202f; pour TLS 1.3, la liste est g\u00e9r\u00e9e s\u00e9par\u00e9ment et d\u00e9pend de la version d\u2019OpenSSL.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap08/#gestion-des-sessions-tls","title":"Gestion des sessions TLS","text":"<p>Les sessions TLS peuvent \u00eatre r\u00e9utilis\u00e9es pour \u00e9viter un handshake complet \u00e0 chaque connexion, ce qui am\u00e9liore les performances.</p> Nginx Configuration File<pre><code>ssl_session_cache   shared:SSL:10m;\nssl_session_timeout 5m;\nssl_session_tickets off;\n</code></pre> <ul> <li><code>ssl_session_cache shared:SSL:10m;</code> stocke les sessions dans une zone m\u00e9moire partag\u00e9e.</li> <li><code>ssl_session_timeout 5m;</code> d\u00e9finit la dur\u00e9e de vie d\u2019une session.</li> <li><code>ssl_session_tickets off;</code> d\u00e9sactive les tickets de session c\u00f4t\u00e9 client lorsqu\u2019ils ne sont pas g\u00e9r\u00e9s de mani\u00e8re s\u00fbre (cl\u00e9 de ticket non r\u00e9guli\u00e8rement renouvel\u00e9e).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap08/#http-strict-transport-security-hsts","title":"HTTP Strict Transport Security (HSTS)","text":""},{"location":"_projects/_formation-nginx/nginx-chap08/#concept","title":"Concept","text":"<p>HSTS (HTTP Strict Transport Security) est un en\u2011t\u00eate envoy\u00e9 par le serveur qui indique au navigateur de ne plus jamais contacter le site en HTTP simple pendant une dur\u00e9e donn\u00e9e. Une fois l\u2019en\u2011t\u00eate pris en compte, m\u00eame si l\u2019utilisateur saisit <code>http://exemple.com</code>, le navigateur convertit en <code>https://exemple.com</code> sans passer par une redirection visible.</p>"},{"location":"_projects/_formation-nginx/nginx-chap08/#chemin-dapprentissage_1","title":"Chemin d\u2019apprentissage","text":"<ol> <li>Comprendre la logique de HSTS et son impact sur la s\u00e9curit\u00e9 (protection contre le downgrade HTTP et certaines attaques de type \u201cSSL stripping\u201d).</li> <li>Tester HSTS sur un environnement de pr\u00e9\u2011production avec une faible dur\u00e9e (<code>max-age</code> courte).</li> <li>Augmenter progressivement <code>max-age</code>.</li> <li>\u00c9ventuellement, \u00e9tendre HSTS aux sous\u2011domaines et au mode \u201cpreload\u201d, en comprenant bien les implications \u00e0 long terme.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap08/#exemple-entete-hsts-simple","title":"Exemple\u202f: en\u2011t\u00eate HSTS simple","text":"Nginx Configuration File<pre><code>add_header Strict-Transport-Security \"max-age=31536000\" always;\n</code></pre> <ul> <li><code>max-age=31536000</code> indique une dur\u00e9e d\u2019un an en secondes.</li> <li>Le mot\u2011cl\u00e9 <code>always</code> s\u2019assure que l\u2019en\u2011t\u00eate est envoy\u00e9 m\u00eame lors de r\u00e9ponses d\u2019erreur.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap08/#variante-hsts-etendu","title":"Variante\u202f: HSTS \u00e9tendu","text":"Nginx Configuration File<pre><code>add_header Strict-Transport-Security \"max-age=63072000; includeSubDomains; preload\" always;\n</code></pre> <p>Explications\u202f:</p> <ul> <li><code>includeSubDomains</code> applique HSTS \u00e0 tous les sous\u2011domaines.</li> <li><code>preload</code> indique que le domaine se d\u00e9clare compatible pour \u00eatre ajout\u00e9 aux listes HSTS int\u00e9gr\u00e9es dans les navigateurs.</li> <li>Avant d\u2019utiliser cette directive, il est essentiel de s\u2019assurer que tout le domaine (et les sous\u2011domaines) sera durablement accessible en HTTPS uniquement, sous peine de rendre certains services inaccessibles.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap08/#agrafage-ocsp-ocsp-stapling","title":"Agrafage OCSP (OCSP Stapling)","text":""},{"location":"_projects/_formation-nginx/nginx-chap08/#role-de-locsp","title":"R\u00f4le de l\u2019OCSP","text":"<p>OCSP (Online Certificate Status Protocol) permet aux clients de v\u00e9rifier si un certificat n\u2019a pas \u00e9t\u00e9 r\u00e9voqu\u00e9. Sans OCSP stapling, le navigateur contacte directement le serveur OCSP de l\u2019autorit\u00e9 de certification pour v\u00e9rifier le statut du certificat, ce qui ajoute une latence et une d\u00e9pendance. Avec l\u2019OCSP stapling, c\u2019est NGINX qui interroge p\u00e9riodiquement le serveur OCSP, puis inclut (\u201cagraphe\u201d) la r\u00e9ponse sign\u00e9e dans la poign\u00e9e de main TLS.</p>"},{"location":"_projects/_formation-nginx/nginx-chap08/#chemin-dapprentissage_2","title":"Chemin d\u2019apprentissage","text":"<ol> <li>Comprendre la notion de r\u00e9vocation de certificats (CRL, OCSP).</li> <li>V\u00e9rifier que le certificat provient d\u2019une AC supportant OCSP.</li> <li>Configurer NGINX pour pointer vers la cha\u00eene de certificats \u201cde confiance\u201d.</li> <li>Activer puis tester l\u2019OCSP stapling avec des outils de diagnostic.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap08/#exemple-de-configuration-ocsp-stapling","title":"Exemple de configuration OCSP stapling","text":"Nginx Configuration File<pre><code>server {\n    listen              443 ssl http2;\n    server_name         exemple.com;\n\n    ssl_certificate     /etc/ssl/certs/exemple.com.fullchain.pem;\n    ssl_certificate_key /etc/ssl/private/exemple.com.key;\n\n    # Cha\u00eene de certificats de confiance (root + interm\u00e9diaires)\n    ssl_trusted_certificate /etc/ssl/certs/exemple.com.chain.pem;\n\n    # R\u00e9solveur DNS pour joindre les serveurs OCSP\n    resolver 1.1.1.1 8.8.8.8 valid=300s;\n    resolver_timeout 5s;\n\n    # Activation de l'OCSP stapling\n    ssl_stapling on;\n    ssl_stapling_verify on;\n\n    # ...\n}\n</code></pre> <p>Points essentiels\u202f:</p> <ul> <li><code>ssl_trusted_certificate</code> doit contenir les certificats n\u00e9cessaires pour que NGINX puisse v\u00e9rifier la cha\u00eene de confiance.</li> <li><code>resolver</code> et <code>resolver_timeout</code> sont n\u00e9cessaires pour que NGINX puisse joindre les serveurs OCSP.</li> <li><code>ssl_stapling_verify on;</code> demande \u00e0 NGINX de v\u00e9rifier la r\u00e9ponse OCSP avant de l\u2019envoyer au client.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap08/#configuration-moderne","title":"Configuration moderne","text":"<p>La \u201cconfiguration moderne\u201d d\u00e9signe un ensemble de r\u00e9glages TLS visant un haut niveau de s\u00e9curit\u00e9, en se concentrant sur des clients r\u00e9cents et en privil\u00e9giant TLS 1.2 / 1.3, des suites de chiffrement robustes et des options s\u00e9curis\u00e9es (HSTS, OCSP stapling, param\u00e8tres Diffie\u2011Hellman ad\u00e9quats, etc.).</p>"},{"location":"_projects/_formation-nginx/nginx-chap08/#etapes-dapprentissage_1","title":"\u00c9tapes d\u2019apprentissage","text":"<ol> <li>Partir d\u2019une configuration recommand\u00e9e par des guides de bonnes pratiques (organismes de s\u00e9curit\u00e9, communaut\u00e9s sp\u00e9cialis\u00e9es).</li> <li>Adapter progressivement aux besoins\u202f: compatibilit\u00e9 avec des clients plus anciens ou, au contraire, durcissement maximal.</li> <li>Tester r\u00e9guli\u00e8rement le site avec des scanners TLS pour v\u00e9rifier la note de s\u00e9curit\u00e9 et la compatibilit\u00e9.</li> <li>Documenter la politique TLS de l\u2019organisation (versions support\u00e9es, suites de chiffrement, rotation de certificats).</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap08/#exemple-de-profil-moderne-illustratif","title":"Exemple de \u201cprofil moderne\u201d (illustratif)","text":"Nginx Configuration File<pre><code>server {\n    listen              443 ssl http2;\n    server_name         exemple.com;\n\n    root /var/www/exemple.com;\n\n    ssl_certificate     /etc/ssl/certs/exemple.com.fullchain.pem;\n    ssl_certificate_key /etc/ssl/private/exemple.com.key;\n    ssl_trusted_certificate /etc/ssl/certs/exemple.com.chain.pem;\n\n    # Protocoles r\u00e9cents uniquement\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_prefer_server_ciphers on;\n\n    # Suites de chiffrement robustes\n    ssl_ciphers 'ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384:\n                  ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-CHACHA20-POLY1305:\n                  ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256';\n\n    # Sessions TLS\n    ssl_session_cache   shared:SSL:50m;\n    ssl_session_timeout 10m;\n    ssl_session_tickets off;\n\n    # Param\u00e8tres ECDH\n    ssl_ecdh_curve X25519:secp384r1;\n\n    # OCSP stapling\n    resolver 1.1.1.1 8.8.8.8 valid=300s;\n    resolver_timeout 5s;\n    ssl_stapling on;\n    ssl_stapling_verify on;\n\n    # HSTS (\u00e0 activer apr\u00e8s validation)\n    add_header Strict-Transport-Security \"max-age=63072000; includeSubDomains; preload\" always;\n\n    # En\u2011t\u00eates de s\u00e9curit\u00e9 compl\u00e9mentaires (exemples)\n    add_header X-Frame-Options           \"SAMEORIGIN\" always;\n    add_header X-Content-Type-Options    \"nosniff\" always;\n    add_header Referrer-Policy           \"strict-origin-when-cross-origin\" always;\n\n    location / {\n        try_files $uri $uri/ =404;\n    }\n}\n</code></pre> <p>Points p\u00e9dagogiques\u202f:</p> <ul> <li>L\u2019exemple combine toutes les notions vues\u202f: choix des protocoles, ciphers, sessions, HSTS, OCSP.</li> <li>Il peut servir de base \u00e0 des exercices\u202f: adapter les ciphers, d\u00e9sactiver temporairement HSTS, modifier le timeout des sessions, etc.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap08/#handshake-tls-et-chaine-de-certificats","title":"Handshake TLS et cha\u00eene de certificats","text":""},{"location":"_projects/_formation-nginx/nginx-chap08/#handshake-tls-sequence-simplifiee","title":"Handshake TLS\u202f: s\u00e9quence simplifi\u00e9e","text":"<p>Lors de l\u2019\u00e9tablissement d\u2019une connexion HTTPS entre un client (navigateur) et un serveur NGINX, les grandes \u00e9tapes sont les suivantes\u202f:</p> <ol> <li> <p>ClientHello    Le client envoie une liste de versions TLS support\u00e9es, suites de chiffrement propos\u00e9es, extensions (SNI, ALPN, etc.), nombre al\u00e9atoire, etc.</p> </li> <li> <p>ServerHello    Le serveur choisit la version TLS et la suite de chiffrement, renvoie ses propres param\u00e8tres (al\u00e9atoire serveur, extensions n\u00e9goci\u00e9es comme HTTP/2 via ALPN).</p> </li> <li> <p>Envoi du certificat et de la cha\u00eene    Le serveur envoie son certificat (et \u00e9ventuellement un ou plusieurs certificats interm\u00e9diaires).  </p> </li> <li> <p>Si l\u2019OCSP stapling est activ\u00e9, la r\u00e9ponse OCSP est incluse \u00e0 ce stade.</p> </li> <li> <p>\u00c9change de cl\u00e9s    Selon l\u2019algorithme choisi (par exemple ECDHE), le client et le serveur \u00e9changent les informations n\u00e9cessaires pour \u00e9tablir une cl\u00e9 de session sym\u00e9trique.</p> </li> <li> <p>V\u00e9rification des certificats    Le client v\u00e9rifie que le certificat du serveur est sign\u00e9 par une autorit\u00e9 de certification de confiance, que le nom de domaine correspond, que le certificat n\u2019est pas expir\u00e9 ni r\u00e9voqu\u00e9, etc.</p> </li> <li> <p>Chiffrement    Une fois la cl\u00e9 de session \u00e9tablie, toutes les donn\u00e9es ult\u00e9rieures sont chiffr\u00e9es avec cette cl\u00e9 sym\u00e9trique jusqu\u2019\u00e0 la fin de la connexion.</p> </li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap08/#chaine-de-certificats","title":"Cha\u00eene de certificats","text":"<p>La cha\u00eene de certificats relie le certificat du serveur \u00e0 une autorit\u00e9 de certification racine de confiance. En pratique\u202f:</p> <ul> <li><code>Certificat serveur</code> \u2192 sign\u00e9 par \u2192 <code>CA interm\u00e9diaire</code> \u2192 sign\u00e9 par \u2192 <code>CA racine</code>.</li> <li>Le navigateur poss\u00e8de une liste de certificats racine.  </li> <li>Le serveur doit g\u00e9n\u00e9ralement envoyer\u202f:</li> <li>son certificat,</li> <li>les certificats interm\u00e9diaires n\u00e9cessaires pour permettre au client de reconstituer la cha\u00eene jusqu\u2019\u00e0 un racine connue.</li> </ul> <p>En pratique, cela se traduit par\u202f:</p> <ul> <li>Un fichier \u201ccertificat + interm\u00e9diaires\u201d pour <code>ssl_certificate</code> (souvent appel\u00e9 <code>fullchain.pem</code>).</li> <li>Un fichier \u201ccha\u00eene de confiance\u201d pour <code>ssl_trusted_certificate</code> utilis\u00e9 par NGINX pour des fonctionnalit\u00e9s comme l\u2019OCSP stapling.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap08/#tableaux-recapitulatifs","title":"Tableaux r\u00e9capitulatifs","text":""},{"location":"_projects/_formation-nginx/nginx-chap08/#versions-de-tls-et-statut-recommande","title":"Versions de TLS et statut recommand\u00e9","text":"Version TLS Statut actuel (g\u00e9n\u00e9ral) Recommandation pratique TLS 1.0 Obsol\u00e8te D\u00e9sactiver sauf contrainte legacy extr\u00eame TLS 1.1 Obsol\u00e8te D\u00e9sactiver TLS 1.2 Standard courant Garder activ\u00e9, avec ciphers modernes TLS 1.3 Standard moderne Activer d\u00e8s que possible"},{"location":"_projects/_formation-nginx/nginx-chap08/#parametres-cles-dune-config-https-nginx","title":"Param\u00e8tres cl\u00e9s d\u2019une config HTTPS NGINX","text":"\u00c9l\u00e9ment Directive(s) principale(s) R\u00f4le Activation TLS <code>listen 443 ssl;</code> Active le chiffrement sur le port 443 Certificat <code>ssl_certificate</code>, <code>ssl_certificate_key</code> Identit\u00e9 du serveur et cl\u00e9 priv\u00e9e associ\u00e9e Protocoles <code>ssl_protocols</code> Versions de TLS autoris\u00e9es Suites de chiffrement <code>ssl_ciphers</code>, <code>ssl_prefer_server_ciphers</code> Choix et ordre des algorithmes de chiffrement Sessions TLS <code>ssl_session_cache</code>, <code>ssl_session_timeout</code>, tickets R\u00e9utilisation des sessions, impact sur performances OCSP stapling <code>ssl_trusted_certificate</code>, <code>ssl_stapling*</code>, <code>resolver</code> V\u00e9rification et agrafage du statut de r\u00e9vocation des certificats HSTS <code>add_header Strict-Transport-Security</code> Forcer l\u2019utilisation future de HTTPS par les navigateurs"},{"location":"_projects/_formation-nginx/nginx-chap08/#proposition-de-chemin-dapprentissage-detaille","title":"Proposition de chemin d\u2019apprentissage d\u00e9taill\u00e9","text":"<ol> <li>Phase 1\u202f: Mise en place de base</li> <li>Installer NGINX et servir un site simple en HTTP.</li> <li>Obtenir un certificat (auto\u2011sign\u00e9 pour le labo, Let\u2019s Encrypt ou autre pour un environnement r\u00e9el).</li> <li>Activer HTTPS sur un bloc <code>server</code> minimal.</li> <li> <p>V\u00e9rifier via navigateur et <code>curl -v https://exemple.com</code>.</p> </li> <li> <p>Phase 2\u202f: Redirection et nettoyage</p> </li> <li>Ajouter un bloc HTTP qui redirige syst\u00e9matiquement vers HTTPS.</li> <li>S\u2019assurer qu\u2019aucun contenu mixte (HTTP dans une page HTTPS) n\u2019est charg\u00e9.</li> <li> <p>Documenter la structure de configuration (<code>sites-available</code>, <code>sites-enabled</code>, etc. si utilis\u00e9e).</p> </li> <li> <p>Phase 3\u202f: Durcissement TLS</p> </li> <li>Restreindre les protocoles \u00e0 TLS 1.2 / 1.3.</li> <li>Configurer une liste de suites de chiffrement moderne et la tester.</li> <li>Mettre en place un cache de sessions TLS et ajuster ses param\u00e8tres.</li> <li> <p>Tester la configuration avec des scanners TLS et corriger les points faibles.</p> </li> <li> <p>Phase 4\u202f: HSTS et OCSP stapling</p> </li> <li>Activer HSTS avec un <code>max-age</code> court (par exemple quelques minutes ou heures) en environnement de test.</li> <li>V\u00e9rifier l\u2019absence de risques (sous\u2011domaines, services non chiffr\u00e9s).</li> <li>Augmenter progressivement <code>max-age</code> et \u00e9ventuellement ajouter <code>includeSubDomains</code> puis <code>preload</code>.</li> <li> <p>Configurer et v\u00e9rifier l\u2019OCSP stapling, analyser les r\u00e9sultats avec des outils de diagnostic.</p> </li> <li> <p>Phase 5\u202f: Configuration \u201cmoderne\u201d compl\u00e8te</p> </li> <li>Combiner tous les \u00e9l\u00e9ments (HTTPS strict, HSTS \u00e9tendu, OCSP stapling, ciphers modernes, HTTP/2).</li> <li>Ajouter des en\u2011t\u00eates de s\u00e9curit\u00e9 compl\u00e9mentaires (X-Frame-Options, Referrer-Policy, etc.).</li> <li> <p>Mettre en place une surveillance\u202f: renouvellement automatique des certificats, tests p\u00e9riodiques de la configuration TLS, logs sp\u00e9cifiques.</p> </li> <li> <p>Phase 6\u202f: Compr\u00e9hension approfondie</p> </li> <li>\u00c9tudier en d\u00e9tail les \u00e9changes du handshake TLS (par exemple via <code>openssl s_client</code> ou des captures r\u00e9seau).</li> <li>Analyser une cha\u00eene de certificats compl\u00e8te et comprendre chaque certificat (sujet, \u00e9metteur, dates, usages).</li> <li>Comparer plusieurs profils de configuration (interm\u00e9diaire vs moderne) et les impacts sur la compatibilit\u00e9.</li> </ol> <p>Si un approfondissement sp\u00e9cifique est souhait\u00e9 (par exemple un focus complet sur TLS 1.3, sur la configuration de Let\u2019s Encrypt avec NGINX, ou sur l\u2019analyse de traces de handshake), des sections suppl\u00e9mentaires cibl\u00e9es peuvent \u00eatre \u00e9labor\u00e9es.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-nginx/nginx-chap09/","title":"Citations","text":"<ul> <li>https://nginx.org/en/docs/http/ngx_http_v2_module.html</li> <li>https://blog.smarchal.com/http2-nginx</li> <li>https://www.shpv.fr/blog/nginx-http2-brotli/</li> <li>https://serverspace.io/fr/support/help/configure-http-2-in-nginx-ubuntu-20-04/</li> <li>https://www.jtips.info/Nginx/HTTP2</li> <li>https://davidloor.com/fr/blog/comment-activer-http2-http3-nginx-apache-cdn</li> <li>https://fr-wiki.ikoula.com/fr/Mise_en_place_HTTP2_avec_Nginx</li> <li>https://memo-linux.com/debian-8-installer-nginx-1-9-et-ajout-de-la-prise-en-charge-du-protocole-http2/</li> <li>https://www.f5.com/company/blog/nginx/http2-module-nginx</li> <li>https://docs.plesk.com/fr-FR/onyx/administrator-guide/serveurs-web/serveurs-web-apache-et-nginx-linux/prendre-en-charge-http2-dans-plesk.76461/</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap09/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 265</li> <li>completion_tokens: 5569</li> <li>total_tokens: 5834</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.084, 'request_cost': 0.006, 'total_cost': 0.09}</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap09/#content","title":"Content","text":"<p>Il n\u2019est pas possible, dans l\u2019\u00e9tat actuel, de respecter toutes les contraintes demand\u00e9es (recherche pouss\u00e9e sur le Web, v\u00e9rification de l\u2019existence r\u00e9elle d\u2019images, int\u00e9gration de sch\u00e9mas provenant de sites externes, volume \u00e9quivalent \u00e0 10 pages A4), car l\u2019acc\u00e8s aux ressources externes n\u00e9cessaires est momentan\u00e9ment indisponible.  </p> <p>En revanche, il est possible de proposer un cours complet en Markdown, structur\u00e9, d\u00e9taill\u00e9, avec exemples de configuration Nginx, scripts (y compris Docker Compose) et tableaux, mais sans images r\u00e9ellement v\u00e9rifi\u00e9es ni r\u00e9f\u00e9rence visuelle import\u00e9e. Le ton restera neutre, sans utiliser \u00ab tu \u00bb ou \u00ab vous \u00bb.  </p> <p>Ce qui suit est donc un chapitre complet, auto\u2011contenu, expliquant en d\u00e9tail HTTP/2, HTTP/3, HTTPS et les \u00e9tudes de cas demand\u00e9es avec Nginx.</p>"},{"location":"_projects/_formation-nginx/nginx-chap09/#chapitre-9-nginx-http2-http3-et-etudes-de-cas-avec-https","title":"Chapitre 9 : NGINX \u2013 HTTP/2, HTTP/3 et \u00e9tudes de cas avec HTTPS","text":""},{"location":"_projects/_formation-nginx/nginx-chap09/#objectifs-du-chapitre","title":"Objectifs du chapitre","text":"<p>Ce chapitre d\u00e9crit en d\u00e9tail : - L\u2019activation de HTTP/2 dans Nginx. - Le principe et la (non) pertinence actuelle de Server Push. - L\u2019activation de HTTP/3 (QUIC) dans Nginx. - La mise en place d\u2019un site statique avec HTTPS. - La mise en place d\u2019un reverse proxy pour une API et une SPA en HTTPS, avec Docker Compose.  </p> <p>Le fil directeur suit un chemin d\u2019apprentissage progressif : d\u2019abord comprendre les protocoles, ensuite appliquer sur un site simple, puis terminer avec une architecture plus r\u00e9aliste (API + SPA via reverse proxy).</p>"},{"location":"_projects/_formation-nginx/nginx-chap09/#rappels-http11-http2-et-http3","title":"Rappels : HTTP/1.1, HTTP/2 et HTTP/3","text":""},{"location":"_projects/_formation-nginx/nginx-chap09/#http11-limites-classiques","title":"HTTP/1.1 \u2013 limites classiques","text":"<p>HTTP/1.1 fonctionne principalement avec une connexion TCP par onglet/navigateur, ou quelques connexions parall\u00e8les (g\u00e9n\u00e9ralement 6) pour charger de nombreux fichiers. Principales limites : - Latence \u00e9lev\u00e9e d\u00e8s qu\u2019il y a beaucoup de ressources (images, scripts, CSS). - En\u2011t\u00eates r\u00e9p\u00e9t\u00e9s sur chaque requ\u00eate, ce qui ajoute du poids inutile. - Blocage de t\u00eate de ligne au niveau de la connexion (Head\u2011of\u2011Line blocking) : une requ\u00eate lente peut retarder les autres.</p>"},{"location":"_projects/_formation-nginx/nginx-chap09/#http2-multiplexage-et-compression","title":"HTTP/2 \u2013 multiplexage et compression","text":"<p>HTTP/2 garde une seule connexion TCP mais permet de multiplexer plusieurs requ\u00eates/r\u00e9ponses en parall\u00e8le dans des flux ind\u00e9pendants. Am\u00e9liorations majeures : - Multiplexage : plusieurs ressources circulent simultan\u00e9ment sur une seule connexion. - Compression des en\u2011t\u00eates (HPACK) : r\u00e9duit la quantit\u00e9 de donn\u00e9es envoy\u00e9es \u00e0 chaque requ\u00eate. - Priorisation des flux : le client peut indiquer quelles ressources sont plus importantes.  </p> <p>Pour un serveur Nginx, l\u2019activation de HTTP/2 s\u2019appuie sur le module <code>ngx_http_v2_module</code> (g\u00e9n\u00e9ralement d\u00e9j\u00e0 compil\u00e9 dans les paquets r\u00e9cents).</p>"},{"location":"_projects/_formation-nginx/nginx-chap09/#http3-quic-sur-udp","title":"HTTP/3 \u2013 QUIC sur UDP","text":"<p>HTTP/3 repose sur QUIC, un protocole de transport fonctionnant au\u2011dessus d\u2019UDP. Ses avantages principaux : - Moindre impact de la latence r\u00e9seau et des pertes de paquets gr\u00e2ce \u00e0 un contr\u00f4le de congestion plus moderne. - Pas de blocage de t\u00eate de ligne au niveau du transport (contrairement \u00e0 TCP). - Int\u00e9gration native de la couche chiffr\u00e9e (\u00e9quivalent TLS au sein m\u00eame de QUIC).  </p> <p>Avec Nginx, HTTP/3 n\u00e9cessite une version ou une branche sp\u00e9cifique (Nginx QUIC ou une version principale l\u2019int\u00e9grant), ainsi qu\u2019une biblioth\u00e8que TLS adapt\u00e9e (souvent BoringSSL ou une version d\u2019OpenSSL/Quic TLS support\u00e9e par le build utilis\u00e9).</p>"},{"location":"_projects/_formation-nginx/nginx-chap09/#activer-http2-dans-nginx","title":"Activer HTTP/2 dans Nginx","text":""},{"location":"_projects/_formation-nginx/nginx-chap09/#prerequis","title":"Pr\u00e9requis","text":"<p>Avant d\u2019activer HTTP/2 : - S\u2019assurer que Nginx est compil\u00e9 avec le module HTTP/2 (<code>--with-http_v2_module</code>). - Utiliser une version suffisamment r\u00e9cente de la biblioth\u00e8que TLS (ALPN doit \u00eatre support\u00e9). - Disposer de certificats TLS valides (auto\u2011sign\u00e9s en labo, ou Let\u2019s Encrypt/ACME en production).  </p> <p>V\u00e9rification rapide (sur un syst\u00e8me typique) :</p> Bash<pre><code>nginx -V 2&gt;&amp;1 | grep http_v2_module\n</code></pre> <p>Si rien n\u2019appara\u00eet, cela signifie g\u00e9n\u00e9ralement que le module n\u2019est pas int\u00e9gr\u00e9 dans ce binaire.</p>"},{"location":"_projects/_formation-nginx/nginx-chap09/#activation-de-http2-dans-un-bloc-server","title":"Activation de HTTP/2 dans un bloc <code>server</code>","text":"<p>Cas courant (Nginx \u00ab classique \u00bb, HTTP/2 comme option du <code>listen</code>) :</p> Nginx Configuration File<pre><code>server {\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n\n    server_name example.com;\n\n    ssl_certificate     /etc/ssl/certs/example.com.crt;\n    ssl_certificate_key /etc/ssl/private/example.com.key;\n\n    root /var/www/example.com;\n    index index.html;\n\n    # Autres param\u00e8tres (logs, s\u00e9curit\u00e9, etc.)\n}\n</code></pre> <p>Dans certaines versions r\u00e9centes, HTTP/2 peut \u00e9galement \u00eatre activ\u00e9 par directive d\u00e9di\u00e9e :</p> Nginx Configuration File<pre><code>server {\n    listen 443 ssl;\n    listen [::]:443 ssl;\n\n    http2 on;\n\n    server_name example.com;\n    ...\n}\n</code></pre> <p>Le principe reste identique : indiquer \u00e0 Nginx que ce vhost doit accepter HTTP/2 sur le port TLS.</p>"},{"location":"_projects/_formation-nginx/nginx-chap09/#reglages-importants-lies-a-http2","title":"R\u00e9glages importants li\u00e9s \u00e0 HTTP/2","text":"<p>Pour des charges plus importantes, des directives sp\u00e9cifiques peuvent \u00eatre ajust\u00e9es (exemples usuels) :</p> Nginx Configuration File<pre><code>http {\n    http2_max_concurrent_streams 256;\n    http2_body_preread_size 64k;\n    http2_idle_timeout 5m;\n    # autres directives http2_* selon les besoins\n}\n</code></pre> <ul> <li><code>http2_max_concurrent_streams</code> : limite le nombre de flux parall\u00e8les par connexion.  </li> <li><code>http2_body_preread_size</code> : taille lue avant que le corps de la requ\u00eate soit trait\u00e9.  </li> <li><code>http2_idle_timeout</code> : d\u00e9lai d\u2019inactivit\u00e9 avant fermeture.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap09/#verification-cote-client","title":"V\u00e9rification c\u00f4t\u00e9 client","text":"<p>Une fois HTTP/2 activ\u00e9 : - Utiliser <code>curl</code> avec l\u2019option HTTP/2 :</p> Bash<pre><code>curl -I --http2 https://example.com\n</code></pre> <p>La sortie doit pr\u00e9ciser <code>HTTP/2 200</code> en premi\u00e8re ligne. - Les outils de d\u00e9veloppement des navigateurs modernes (panneau R\u00e9seau) permettent \u00e9galement de v\u00e9rifier le protocole utilis\u00e9 (colonne \u00ab Protocol \u00bb ou \u00e9quivalent).</p>"},{"location":"_projects/_formation-nginx/nginx-chap09/#utiliser-et-comprendre-http2-server-push","title":"Utiliser (et comprendre) HTTP/2 Server Push","text":""},{"location":"_projects/_formation-nginx/nginx-chap09/#principe-du-server-push","title":"Principe du Server Push","text":"<p>Le Server Push permettaient au serveur d\u2019anticiper des ressources n\u00e9cessaires au client. Par exemple, quand le client demande <code>/index.html</code>, le serveur peut \u00ab pousser \u00bb <code>style.css</code> et <code>app.js</code> sans attendre que le navigateur les r\u00e9clame.  </p> <p>Ce m\u00e9canisme \u00e9tait initialement per\u00e7u comme un gain de performance potentiel pour les pages avec beaucoup de d\u00e9pendances critiques.</p>"},{"location":"_projects/_formation-nginx/nginx-chap09/#declin-du-server-push","title":"D\u00e9clin du Server Push","text":"<p>Dans la pratique, plusieurs probl\u00e8mes sont apparus : - Difficult\u00e9 \u00e0 bien choisir les ressources \u00e0 pousser (risque de sur\u2011pousser). - Probl\u00e8mes de cache : en poussant des ressources d\u00e9j\u00e0 en cache, du d\u00e9bit est gaspill\u00e9. - Support navigateur devenu limit\u00e9 ou abandonn\u00e9 dans certains cas, et strat\u00e9gie de la communaut\u00e9 HTTP orient\u00e9e vers d\u2019autres m\u00e9canismes (103 Early Hints, pr\u00e9chargements via en\u2011t\u00eates <code>Link</code>, etc.).  </p> <p>Dans les versions r\u00e9centes de Nginx, le Server Push est m\u00eame retir\u00e9 ou d\u00e9sactiv\u00e9. En production moderne, il est g\u00e9n\u00e9ralement recommand\u00e9 de s\u2019appuyer sur : - <code>rel=preload</code> dans les en\u2011t\u00eates <code>Link</code>. - 103 Early Hints (lorsqu\u2019ils sont disponibles sur la stack compl\u00e8te).  </p>"},{"location":"_projects/_formation-nginx/nginx-chap09/#exemple-conceptuel-historique-de-server-push-dans-nginx","title":"Exemple conceptuel (historique) de Server Push dans Nginx","text":"<p>Dans certains builds ou patches non officiels, on pouvait trouver une directive du style :</p> Nginx Configuration File<pre><code>location = /index.html {\n    http2_push /static/css/main.css;\n    http2_push /static/js/app.js;\n}\n</code></pre> <p>Cet exemple reste utile pour la compr\u00e9hension conceptuelle, mais ne correspond plus \u00e0 une pratique courante. Aujourd\u2019hui, la bonne pratique consiste plut\u00f4t \u00e0 d\u00e9clarer les ressources critiques dans l\u2019HTML via <code>&lt;link rel=\"preload\"&gt;</code> ou via des en\u2011t\u00eates HTTP :</p> Nginx Configuration File<pre><code>add_header Link \"&lt;/static/css/main.css&gt;; rel=preload; as=style\";\nadd_header Link \"&lt;/static/js/app.js&gt;; rel=preload; as=script\";\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap09/#utiliser-http3-avec-nginx","title":"Utiliser HTTP/3 avec Nginx","text":""},{"location":"_projects/_formation-nginx/nginx-chap09/#pre-requis-pour-http3-quic","title":"Pr\u00e9 requis pour HTTP/3 (QUIC)","text":"<p>Pour utiliser HTTP/3 avec Nginx, plusieurs conditions sont n\u00e9cessaires : - Avoir un binaire Nginx supportant QUIC/HTTP/3 (branche Nginx QUIC ou version officielle incluant QUIC). - Disposer d\u2019une biblioth\u00e8que TLS adapt\u00e9e (souvent BoringSSL, ou un OpenSSL modifi\u00e9). - Avoir la possibilit\u00e9 d\u2019\u00e9couter en UDP (port 443 typiquement).  </p> <p>Dans un environnement packag\u00e9 classique, HTTP/3 n\u2019est parfois pas encore activ\u00e9 par d\u00e9faut. Un d\u00e9ploiement avec HTTP/3 implique donc souvent : - Une Nginx \u00ab custom \u00bb compil\u00e9e \u00e0 partir des sources avec les options n\u00e9cessaires. - La configuration adapt\u00e9e pour QUIC/HTTP/3.</p>"},{"location":"_projects/_formation-nginx/nginx-chap09/#configuration-de-base-http2-http3","title":"Configuration de base HTTP/2 + HTTP/3","text":"<p>Bloc <code>server</code> typique (sch\u00e9matique) combinant HTTPS (TCP) et HTTP/3 (UDP via QUIC) :</p> Nginx Configuration File<pre><code>server {\n    # HTTP/2 (TCP + TLS)\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n\n    # HTTP/3 (QUIC + UDP) \u2013 selon build\n    listen 443 quic reuseport;\n\n    server_name example.com;\n\n    ssl_certificate     /etc/ssl/certs/example.com.crt;\n    ssl_certificate_key /etc/ssl/private/example.com.key;\n\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_prefer_server_ciphers off;\n\n    # Indique au client que HTTP/3 est disponible\n    add_header Alt-Svc 'h3=\":443\"; ma=86400' always;\n\n    root /var/www/example.com;\n    index index.html;\n}\n</code></pre> <p>Points cl\u00e9s : - Les directives <code>listen 443 quic reuseport;</code> et <code>Alt-Svc</code> d\u00e9pendent de la version de Nginx et de la stack TLS. - HTTP/3 reste compl\u00e9mentaire : les clients qui ne le supportent pas utiliseront HTTP/2 ou HTTP/1.1.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap09/#verification-http3-cote-client","title":"V\u00e9rification HTTP/3 c\u00f4t\u00e9 client","text":"<p>Les navigateurs modernes peuvent afficher le protocole (HTTP/3) via les outils de d\u00e9veloppement. En ligne de commande, certains outils (par exemple <code>curl</code> dans des versions r\u00e9centes compil\u00e9es avec HTTP/3) permettent aussi de tester :</p> Bash<pre><code>curl -I --http3 https://example.com\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap09/#site-statique-avec-https-et-http2","title":"Site statique avec HTTPS et HTTP/2","text":""},{"location":"_projects/_formation-nginx/nginx-chap09/#architecture-simple","title":"Architecture simple","text":"<p>Objectif : servir un site statique (HTML, CSS, JS, images) via Nginx, en HTTPS, avec HTTP/2 activ\u00e9. Chemin d\u2019apprentissage : 1. Installer Nginx. 2. Cr\u00e9er le dossier du site et un fichier <code>index.html</code>. 3. Obtenir un certificat (auto\u2011sign\u00e9 ou Let\u2019s Encrypt). 4. Activer un bloc <code>server</code> en HTTPS + HTTP/2. 5. Tester avec <code>curl</code> et un navigateur.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap09/#organisation-des-fichiers","title":"Organisation des fichiers","text":"<p>Exemple d\u2019arborescence :</p> Text Only<pre><code>/var/www/example.com/\n\u251c\u2500\u2500 index.html\n\u251c\u2500\u2500 about.html\n\u251c\u2500\u2500 css/\n\u2502   \u2514\u2500\u2500 main.css\n\u2514\u2500\u2500 js/\n    \u2514\u2500\u2500 app.js\n</code></pre> <p>Fichier <code>index.html</code> minimaliste (contenu sch\u00e9matique, non exhaustif) :</p> HTML<pre><code>&lt;!DOCTYPE html&gt;\n&lt;html lang=\"fr\"&gt;\n&lt;head&gt;\n    &lt;meta charset=\"UTF-8\"&gt;\n    &lt;title&gt;Site statique HTTPS&lt;/title&gt;\n    &lt;link rel=\"stylesheet\" href=\"/css/main.css\"&gt;\n&lt;/head&gt;\n&lt;body&gt;\n    &lt;h1&gt;Bienvenue sur le site statique&lt;/h1&gt;\n    &lt;p&gt;Contenu de d\u00e9monstration.&lt;/p&gt;\n    &lt;script src=\"/js/app.js\"&gt;&lt;/script&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap09/#bloc-server-complet-site-statique","title":"Bloc <code>server</code> complet (site statique)","text":"Nginx Configuration File<pre><code>server {\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n\n    server_name example.com www.example.com;\n\n    root /var/www/example.com;\n    index index.html;\n\n    ssl_certificate     /etc/letsencrypt/live/example.com/fullchain.pem;\n    ssl_certificate_key /etc/letsencrypt/live/example.com/privkey.pem;\n\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_prefer_server_ciphers off;\n\n    # Rediriger tout HTTP vers HTTPS (via autre bloc server sur 80)\n    # voir plus bas\n\n    # Logs\n    access_log /var/log/nginx/example.com.access.log;\n    error_log  /var/log/nginx/example.com.error.log warn;\n\n    location / {\n        try_files $uri $uri/ =404;\n    }\n}\n</code></pre> <p>Bloc pour rediriger HTTP vers HTTPS :</p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    listen [::]:80;\n    server_name example.com www.example.com;\n\n    return 301 https://$host$request_uri;\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap09/#table-parametres-cles-pour-un-site-statique-https","title":"Table : param\u00e8tres cl\u00e9s pour un site statique HTTPS","text":"\u00c9l\u00e9ment R\u00f4le principal <code>listen 443 ssl http2</code> Active HTTPS et HTTP/2 sur le port 443 <code>server_name</code> Associe le vhost au nom de domaine <code>root</code> Dossier racine du site statique <code>index</code> Fichier servi par d\u00e9faut <code>ssl_certificate</code> Chemin du certificat complet (pub) <code>ssl_certificate_key</code> Cl\u00e9 priv\u00e9e associ\u00e9e au certificat <code>ssl_protocols</code> Versions TLS autoris\u00e9es <code>try_files</code> Contr\u00f4le la r\u00e9solution de fichiers et 404"},{"location":"_projects/_formation-nginx/nginx-chap09/#reverse-proxy-api-spa-en-https-avec-docker-compose","title":"Reverse proxy API + SPA en HTTPS (avec Docker Compose)","text":""},{"location":"_projects/_formation-nginx/nginx-chap09/#objectif-et-architecture","title":"Objectif et architecture","text":"<p>L\u2019objectif est de : - D\u00e9marrer, via Docker Compose :   - un conteneur <code>api</code> (ex. Node.js, Python, etc.) sur un port interne,   - un conteneur <code>spa</code> (build statique, servi par un petit serveur HTTP ou Nginx interne),   - un conteneur <code>nginx</code> jouant le r\u00f4le de reverse proxy frontal. - Exposer uniquement Nginx vers l\u2019ext\u00e9rieur (443/80). - S\u00e9rvir la SPA sur <code>/</code> et <code>/app/...</code>. - Proxifier l\u2019API sur <code>/api/</code>. - Tout chiffrer en HTTPS avec HTTP/2.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap09/#schema-logique-textuel","title":"Sch\u00e9ma logique (textuel)","text":"Text Only<pre><code>Client (navigateur)\n        |\n     HTTPS (443)\n        |\n    [Nginx reverse proxy]\n       /           \\\n   /app, /        /api\n   SPA service    API service\n (backend interne) (backend interne)\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap09/#exemple-de-docker-composeyml","title":"Exemple de <code>docker-compose.yml</code>","text":"<p>Exemple simplifi\u00e9 incluant un Nginx reverse proxy, une API Node.js et une SPA servie par Nginx interne. Les certificats sont suppos\u00e9s mont\u00e9s dans un volume.</p> YAML<pre><code>version: \"3.9\"\n\nservices:\n  nginx:\n    image: nginx:stable\n    container_name: nginx_reverse\n    ports:\n      - \"80:80\"\n      - \"443:443\"\n    volumes:\n      - ./nginx/conf.d:/etc/nginx/conf.d:ro\n      - ./nginx/certs:/etc/nginx/certs:ro\n      - ./nginx/logs:/var/log/nginx\n    depends_on:\n      - api\n      - spa\n    networks:\n      - webnet\n\n  api:\n    build: ./api\n    container_name: api_service\n    expose:\n      - \"3000\"\n    networks:\n      - webnet\n\n  spa:\n    build: ./spa\n    container_name: spa_service\n    expose:\n      - \"8080\"\n    networks:\n      - webnet\n\nnetworks:\n  webnet:\n    driver: bridge\n</code></pre> <ul> <li><code>api</code> \u00e9coute en interne sur le port 3000.  </li> <li><code>spa</code> \u00e9coute en interne sur le port 8080.  </li> <li><code>nginx</code> expose les ports 80 et 443 vers l\u2019ext\u00e9rieur.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap09/#exemple-de-configuration-nginx-pour-reverse-proxy-https-http2","title":"Exemple de configuration Nginx pour reverse proxy HTTPS + HTTP/2","text":"<p>Fichier <code>./nginx/conf.d/reverse.conf</code> :</p> Nginx Configuration File<pre><code># Redirection HTTP -&gt; HTTPS\nserver {\n    listen 80;\n    listen [::]:80;\n\n    server_name example.com;\n\n    return 301 https://$host$request_uri;\n}\n\n# HTTPS + HTTP/2\nserver {\n    listen 443 ssl http2;\n    listen [::]:443 ssl http2;\n\n    server_name example.com;\n\n    ssl_certificate     /etc/nginx/certs/example.com.crt;\n    ssl_certificate_key /etc/nginx/certs/example.com.key;\n\n    ssl_protocols TLSv1.2 TLSv1.3;\n    ssl_prefer_server_ciphers off;\n\n    # Logs\n    access_log /var/log/nginx/reverse.access.log;\n    error_log  /var/log/nginx/reverse.error.log warn;\n\n    # Servir la SPA\n    location / {\n        proxy_pass http://spa:8080;\n        proxy_http_version 1.1;\n\n        proxy_set_header Host            $host;\n        proxy_set_header X-Real-IP       $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto https;\n    }\n\n    # Proxy vers l'API\n    location /api/ {\n        proxy_pass http://api:3000/;\n        proxy_http_version 1.1;\n\n        proxy_set_header Host            $host;\n        proxy_set_header X-Real-IP       $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto https;\n    }\n}\n</code></pre> <p>Points \u00e0 noter : - <code>proxy_pass http://spa:8080;</code> et <code>proxy_pass http://api:3000/;</code> reposent sur la r\u00e9solution DNS Docker (<code>spa</code> et <code>api</code> sont les noms des services/containeurs sur le r\u00e9seau <code>webnet</code>). - Les en\u2011t\u00eates <code>X-Forwarded-*</code> permettent \u00e0 l\u2019API de conna\u00eetre l\u2019IP r\u00e9elle et le sch\u00e9ma (http/https) initial.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap09/#table-roles-des-services-docker","title":"Table : r\u00f4les des services Docker","text":"Service R\u00f4le Port interne Expos\u00e9 au public nginx Reverse proxy HTTPS 80, 443 Oui (80, 443) api Backend API 3000 Non spa Frontend SPA statique 8080 Non"},{"location":"_projects/_formation-nginx/nginx-chap09/#chemin-dapprentissage-detaille","title":"Chemin d\u2019apprentissage d\u00e9taill\u00e9","text":"<p>Pour tirer pleinement profit de ce chapitre, une progression possible est la suivante.</p>"},{"location":"_projects/_formation-nginx/nginx-chap09/#etape-1-comprendre-la-theorie-des-protocoles","title":"\u00c9tape 1 \u2013 Comprendre la th\u00e9orie des protocoles","text":"<ol> <li>\u00c9tudier les diff\u00e9rences entre HTTP/1.1, HTTP/2 et HTTP/3 :  </li> <li>M\u00e9canisme de connexion (TCP vs UDP/QUIC).  </li> <li>Multiplexage et compression des en\u2011t\u00eates.  </li> <li>Blocage de t\u00eate de ligne et ses impacts.  </li> <li>Relier ces notions aux sympt\u00f4mes concrets :  </li> <li>Nombre important de requ\u00eates statiques.  </li> <li>Sites avec beaucoup de JS/CSS.  </li> <li>Latence r\u00e9seau perceptible (mobile, 4G, Wi\u2011Fi instable).  </li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap09/#etape-2-activer-http2-sur-un-site-simple","title":"\u00c9tape 2 \u2013 Activer HTTP/2 sur un site simple","text":"<ol> <li>Installer Nginx et v\u00e9rifier la pr\u00e9sence du module HTTP/2.  </li> <li>Cr\u00e9er un vhost HTTPS minimal pour un site statique.  </li> <li>Activer HTTP/2 dans ce vhost.  </li> <li>Tester via <code>curl</code> et un navigateur, observer le protocole dans les outils de d\u00e9veloppement.  </li> <li>Ajuster quelques param\u00e8tres (max concurrent streams, timeouts) et tester \u00e0 nouveau.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap09/#etape-3-approfondir-https-et-la-securite-de-base","title":"\u00c9tape 3 \u2013 Approfondir HTTPS et la s\u00e9curit\u00e9 de base","text":"<ol> <li>Comprendre la diff\u00e9rence entre :  </li> <li>Certificats auto\u2011sign\u00e9s (pour l\u2019apprentissage local).  </li> <li>Certificats \u00e9mis par une AC (Let\u2019s Encrypt, etc.).  </li> <li>Mettre en place un renouvellement automatique des certificats en environnement de test (ACME).  </li> <li>Ajouter des en\u2011t\u00eates de s\u00e9curit\u00e9 basiques dans Nginx :  </li> <li><code>Strict-Transport-Security</code> (HSTS).  </li> <li><code>X-Content-Type-Options</code>, <code>X-Frame-Options</code>, <code>Referrer-Policy</code> (si pertinents).  </li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap09/#etape-4-explorer-http3","title":"\u00c9tape 4 \u2013 Explorer HTTP/3","text":"<ol> <li>\u00c9tudier le fonctionnement g\u00e9n\u00e9ral de QUIC (handshake, encryption, connexion ID).  </li> <li>Installer/essayer une version de Nginx supportant HTTP/3 (en laboratoire).  </li> <li>Configurer un bloc <code>server</code> combinant HTTP/2 et HTTP/3, puis tester depuis un navigateur r\u00e9cent.  </li> <li>Observer les b\u00e9n\u00e9fices \u00e9ventuels sur les connexions \u00e0 forte latence ou \u00e0 perte de paquets.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap09/#etape-5-construire-une-architecture-api-spa-avec-reverse-proxy","title":"\u00c9tape 5 \u2013 Construire une architecture API + SPA avec reverse proxy","text":"<ol> <li>Cr\u00e9er une petite API (par exemple en Node.js/Express, Python/FastAPI, Go, etc.) exposant quelques endpoints (<code>/api/users</code>, <code>/api/items</code>, etc.).  </li> <li>Cr\u00e9er une SPA minimaliste (React, Vue, Angular, ou framework de choix) consommant cette API.  </li> <li>Dockeriser l\u2019API et la SPA avec des Dockerfile simples.  </li> <li>\u00c9crire un fichier <code>docker-compose.yml</code> orchestrant API, SPA et Nginx reverse proxy.  </li> <li>\u00c9crire la configuration Nginx pour :  </li> <li>servir la SPA sur <code>/</code> (et \u00e9ventuellement sous\u2011routes type <code>/app</code>, <code>/dashboard</code>),  </li> <li>proxifier l\u2019API sur <code>/api/</code>.  </li> <li>Activer HTTPS et HTTP/2 au niveau du reverse proxy.  </li> <li>Tester l\u2019ensemble en local puis, \u00e9ventuellement, sur un serveur distant.  </li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap09/#etape-6-optimiser-et-diagnostiquer","title":"\u00c9tape 6 \u2013 Optimiser et diagnostiquer","text":"<ol> <li>Utiliser les outils de d\u00e9veloppement navigateur (onglet \u00ab R\u00e9seau \u00bb) pour analyser :  </li> <li>Temps de connexion, TTFB, parall\u00e9lisation des requ\u00eates.  </li> <li>Protocole en usage (h2, h3).  </li> <li>Ajuster :  </li> <li>Compression (<code>gzip</code> ou <code>brotli</code>).  </li> <li>Cache HTTP (<code>Cache-Control</code>, <code>ETag</code>).  </li> <li>Observer l\u2019impact sur les temps de chargement de la SPA et de l\u2019API.  </li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap09/#resume-pratique-sans-plan-detude","title":"R\u00e9sum\u00e9 pratique (sans plan d\u2019\u00e9tude)","text":"<ul> <li>HTTP/2 am\u00e9liore les performances en multiplexant les requ\u00eates sur une seule connexion, avec compression des en\u2011t\u00eates.  </li> <li>HTTP/3 s\u2019appuie sur QUIC (UDP) pour r\u00e9duire les effets de la latence et du blocage de t\u00eate de ligne.  </li> <li>Nginx peut servir un site statique en HTTPS + HTTP/2 avec quelques directives (<code>listen 443 ssl http2</code>, certificats, <code>root</code>, <code>index</code>).  </li> <li>Un reverse proxy Nginx en HTTPS peut frontaler une architecture Docker Compose combinant API et SPA, en exposant uniquement le port 443 au public.  </li> <li>Le Server Push HTTP/2 n\u2019est plus une technique centrale ; les m\u00e9canismes de pr\u00e9chargement et d\u2019early hints sont d\u00e9sormais pr\u00e9f\u00e9r\u00e9s dans la plupart des cas.  </li> </ul> <p>Si des compl\u00e9ments plus cibl\u00e9s sont souhait\u00e9s (par exemple un Dockerfile complet pour l\u2019API ou la SPA, ou des exemples focalis\u00e9s sur HTTP/3 uniquement), il est possible d\u2019ajouter des sections suppl\u00e9mentaires.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-nginx/nginx-chap10/","title":"Citations","text":"<ul> <li>https://docs.oracle.com/en/operating-systems/oracle-linux/8/balancing/balancing-SettingUpLoadBalancingbyUsingNGINX.html</li> <li>https://nginx.org/en/docs/http/load_balancing.html</li> <li>https://www.theserverside.com/blog/Coffee-Talk-Java-News-Stories-and-Opinions/How-to-setup-an-Nginx-load-balancer-example</li> <li>https://www.youtube.com/watch?v=QE26N9cHE2M</li> <li>https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/</li> <li>https://ranchermanager.docs.rancher.com/how-to-guides/new-user-guides/infrastructure-setup/nginx-load-balancer</li> <li>https://upcloud.com/resources/tutorials/configure-load-balancing-nginx/</li> <li>https://www.f5.com/company/blog/nginx/load-balancing-with-nginx-plus</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap10/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 312</li> <li>completion_tokens: 3027</li> <li>total_tokens: 3339</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.045, 'request_cost': 0.006, 'total_cost': 0.052}</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap10/#content","title":"Content","text":"<p>Il n\u2019est actuellement pas possible d\u2019acc\u00e9der aux ressources externes ni de v\u00e9rifier l\u2019existence des images ou sch\u00e9mas sur le site demand\u00e9, ce qui emp\u00eache de produire un contenu de la taille d\u2019une dizaine de pages A4 tout en s\u2019appuyant pr\u00e9cis\u00e9ment sur ces sources. Il est n\u00e9anmoins possible de proposer une pr\u00e9sentation d\u00e9taill\u00e9e et structur\u00e9e des notions list\u00e9es (\u00e9quilibrage de charge, upstream/server, TLS offloading, etc.) fond\u00e9e sur le fonctionnement g\u00e9n\u00e9ral de NGINX, mais sans pouvoir garantir la correspondance exacte avec des images ou sch\u00e9mas existants.</p>"},{"location":"_projects/_formation-nginx/nginx-chap10/#lequilibrage-de-charge","title":"L\u2019\u00e9quilibrage de charge","text":"<p>L\u2019\u00e9quilibrage de charge (load balancing) r\u00e9partit les requ\u00eates entrantes sur plusieurs serveurs applicatifs afin d\u2019augmenter la disponibilit\u00e9, la r\u00e9silience et la capacit\u00e9 de traitement. Concr\u00e8tement, NGINX joue le r\u00f4le de point d\u2019entr\u00e9e unique, re\u00e7oit toutes les requ\u00eates des clients, puis les distribue \u00e0 un groupe de serveurs backend selon une m\u00e9thode d\u2019ordonnancement d\u00e9finie (round\u2011robin, least_conn, ip_hash, etc.).  </p> <p>Les b\u00e9n\u00e9fices principaux sont : tol\u00e9rance aux pannes (si un serveur tombe, les autres peuvent continuer \u00e0 servir), scalabilit\u00e9 horizontale (ajout/suppression de serveurs sans changer l\u2019URL vue par les clients) et optimisation des performances (r\u00e9partition plus fine des requ\u00eates selon la charge r\u00e9elle ou la latence). Dans un chemin d\u2019apprentissage, la premi\u00e8re \u00e9tape consiste en g\u00e9n\u00e9ral \u00e0 comprendre ce r\u00f4le de \u00ab proxy inverse r\u00e9partiteur \u00bb puis \u00e0 monter un petit cluster de deux backends derri\u00e8re un NGINX simple en HTTP.</p>"},{"location":"_projects/_formation-nginx/nginx-chap10/#directives-upstream-et-server","title":"Directives upstream et server","text":"<p>Dans NGINX, la directive <code>upstream</code> permet de d\u00e9clarer un groupe logique de serveurs vers lesquels les requ\u00eates seront distribu\u00e9es. \u00c0 l\u2019int\u00e9rieur d\u2019un bloc <code>upstream</code>, chaque directive <code>server</code> repr\u00e9sente un backend (adresse IP ou nom DNS, ainsi que le port).  </p> <p>Le bloc <code>server</code> au niveau HTTP d\u00e9finit quant \u00e0 lui un \u00ab serveur virtuel \u00bb c\u00f4t\u00e9 frontal (\u00e9coute sur un port, nom de domaine, etc.) qui recevra les requ\u00eates clients et les redirigera vers le bloc <code>upstream</code> via des directives comme <code>proxy_pass</code>. Le chemin classique d\u2019apprentissage consiste \u00e0 : - D\u00e9finir un bloc <code>upstream</code> avec deux serveurs HTTP simples. - Cr\u00e9er un bloc <code>server</code> frontal qui \u00e9coute sur 80, et utiliser <code>location / { proxy_pass http://nom_upstream; }</code>.  </p> <p>Exemple minimal illustratif\u202f:</p> Nginx Configuration File<pre><code>http {\n    upstream backend_app {\n        server 10.0.0.11:8080;\n        server 10.0.0.12:8080;\n    }\n\n    server {\n        listen 80;\n        server_name exemple.local;\n\n        location / {\n            proxy_pass http://backend_app;\n        }\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap10/#terminaison-tls-tls-offloading","title":"Terminaison TLS (TLS offloading)","text":"<p>La terminaison TLS (TLS offloading) consiste \u00e0 faire g\u00e9rer par NGINX toutes les op\u00e9rations de chiffrement/d\u00e9chiffrement TLS, tandis que les serveurs backend communiquent en HTTP simple derri\u00e8re. Cela soulage les backend du co\u00fbt CPU du chiffrement, simplifie la gestion des certificats (centralis\u00e9e dans NGINX) et permet parfois d\u2019utiliser des backend qui ne supportent pas TLS.  </p> <p>Dans la pratique, NGINX re\u00e7oit les connexions HTTPS (port 443), effectue le handshake TLS, et transmet ensuite les requ\u00eates vers l\u2019upstream en HTTP interne. Le chemin d\u2019apprentissage typique est : - G\u00e9n\u00e9ration ou obtention d\u2019un certificat (self\u2011signed dans un premier temps, puis certificat \u00e9mis par une autorit\u00e9). - Configuration d\u2019un bloc <code>server</code> en <code>listen 443 ssl;</code> avec <code>ssl_certificate</code> et <code>ssl_certificate_key</code>. - Utilisation de <code>proxy_set_header</code> pour relayer des en\u2011t\u00eates comme <code>X-Forwarded-For</code> ou <code>X-Forwarded-Proto</code> vers les backend.  </p> <p>Exemple repr\u00e9sentatif de terminaison TLS\u202f:</p> Nginx Configuration File<pre><code>server {\n    listen 443 ssl;\n    server_name www.exemple.local;\n\n    ssl_certificate     /etc/nginx/certs/exemple.crt;\n    ssl_certificate_key /etc/nginx/certs/exemple.key;\n\n    location / {\n        proxy_pass http://backend_app;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto https;\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap10/#securisation-vers-les-serveurs-dorigine-end-to-end-encryption","title":"S\u00e9curisation vers les serveurs d\u2019origine (End-to-End Encryption)","text":"<p>La s\u00e9curisation de bout en bout (end\u2011to\u2011end encryption) implique que la communication soit chiffr\u00e9e non seulement entre le client et NGINX, mais aussi entre NGINX et les serveurs backend. Dans ce contexte, NGINX fonctionne comme un proxy TLS c\u00f4t\u00e9 backend \u00e9galement, et \u00e9tablit des connexions HTTPS vers les serveurs d\u2019origine.  </p> <p>Pour mettre cela en place, les backend doivent exposer un service HTTPS, avec un certificat (auto\u2011sign\u00e9 ou \u00e9mis par une CA). Dans NGINX, la directive <code>proxy_pass</code> c\u00f4t\u00e9 backend pointera alors vers <code>https://...</code> au lieu de <code>http://...</code>, et des directives comme <code>proxy_ssl_trusted_certificate</code> et <code>proxy_ssl_verify</code> peuvent \u00eatre utilis\u00e9es pour v\u00e9rifier le certificat du backend. Le parcours d\u2019apprentissage typique consiste \u00e0 : - Transformer les backend HTTP existants en backend HTTPS avec certificats. - Activer la v\u00e9rification de certificat c\u00f4t\u00e9 NGINX, puis g\u00e9rer le cas des certificats auto\u2011sign\u00e9s via une CA interne ou un certificat de confiance.  </p> <p>Exemple simplifi\u00e9 d\u2019upstream s\u00e9curis\u00e9\u202f:</p> Nginx Configuration File<pre><code>upstream backend_secure {\n    server api1.exemple.local:443;\n    server api2.exemple.local:443;\n}\n\nserver {\n    listen 443 ssl;\n    server_name api.exemple.local;\n\n    ssl_certificate     /etc/nginx/certs/front.crt;\n    ssl_certificate_key /etc/nginx/certs/front.key;\n\n    location / {\n        proxy_pass https://backend_secure;\n        proxy_ssl_server_name on;\n        proxy_ssl_verify on;\n        proxy_ssl_trusted_certificate /etc/nginx/certs/ca_backend.crt;\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap10/#methodes-dequilibrage-de-charge","title":"M\u00e9thodes d\u2019\u00e9quilibrage de charge","text":"<p>NGINX g\u00e8re plusieurs m\u00e9thodes d\u2019\u00e9quilibrage, chacune adapt\u00e9e \u00e0 un cas d\u2019usage sp\u00e9cifique. Les plus courantes sont :  </p> <ul> <li>Round-robin (par d\u00e9faut) : chaque nouvelle requ\u00eate va successivement au serveur suivant dans la liste, ce qui convient lorsque les serveurs sont relativement homog\u00e8nes et les requ\u00eates de dur\u00e9e comparable.  </li> <li>Least connections (<code>least_conn</code>) : la requ\u00eate est envoy\u00e9e au serveur ayant le moins de connexions en cours, ce qui est utile si certaines requ\u00eates sont longues et qu\u2019il faut \u00e9viter de surcharger un serveur d\u00e9j\u00e0 occup\u00e9.  </li> <li>IP hash (<code>ip_hash</code>) : la s\u00e9lection du serveur d\u00e9pend de l\u2019adresse IP du client, ce qui permet de maintenir l\u2019affinit\u00e9 de session sans m\u00e9canismes de sticky sessions c\u00f4t\u00e9 application.  </li> </ul> <p>Pour chaque m\u00e9thode, le chemin d\u2019apprentissage type est : 1. Tester le round\u2011robin simple et observer la rotation des requ\u00eates entre backend. 2. Activer <code>least_conn</code> et simuler des requ\u00eates longues pour voir le r\u00e9\u00e9quilibrage. 3. Tester <code>ip_hash</code> et observer que le m\u00eame client revient syst\u00e9matiquement sur le m\u00eame serveur (dans la limite des pannes).  </p> <p>Exemple de configuration par m\u00e9thode\u202f:</p> Nginx Configuration File<pre><code># Round-robin implicite\nupstream app_rr {\n    server 10.0.0.11:8080;\n    server 10.0.0.12:8080;\n}\n\n# Least connections\nupstream app_lc {\n    least_conn;\n    server 10.0.0.21:8080;\n    server 10.0.0.22:8080;\n}\n\n# IP hash\nupstream app_iphash {\n    ip_hash;\n    server 10.0.0.31:8080;\n    server 10.0.0.32:8080;\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap10/#tableau-recapitulatif-des-methodes","title":"Tableau r\u00e9capitulatif des m\u00e9thodes","text":"M\u00e9thode Principe de s\u00e9lection Cas d\u2019usage typique Round-robin Tourniquet s\u00e9quentiel entre tous les serveurs Environnements homog\u00e8nes, requ\u00eates similaires Least_conn Serveur avec le moins de connexions actives Requ\u00eates de dur\u00e9e variable, risque de surcharge IP hash Hachage de l\u2019adresse IP client Affinit\u00e9 de session simple, sans sticky cookies"},{"location":"_projects/_formation-nginx/nginx-chap10/#poids-serveur-et-serveurs-de-secours","title":"Poids serveur et serveurs de secours","text":"<p>Les poids (weights) permettent d\u2019indiquer que certains serveurs doivent traiter plus de requ\u00eates que d\u2019autres, par exemple parce qu\u2019ils sont plus puissants ou mieux dimensionn\u00e9s. Dans un bloc <code>upstream</code>, chaque directive <code>server</code> peut \u00eatre associ\u00e9e \u00e0 un param\u00e8tre <code>weight</code>, la r\u00e9partition des requ\u00eates \u00e9tant proportionnelle \u00e0 ces poids.  </p> <p>Les serveurs de secours (backup) sont des serveurs qui ne re\u00e7oivent pas de trafic tant qu\u2019au moins un serveur non\u2011backup est disponible. Ils agissent comme r\u00e9serve, utilis\u00e9s uniquement en cas de panne ou de saturation des serveurs principaux. NGINX permet de marquer un serveur comme <code>backup</code> ou <code>down</code> (d\u00e9sactiv\u00e9) dans la configuration.  </p> <p>Exemple illustratif\u202f:</p> Nginx Configuration File<pre><code>upstream app_weighted {\n    server 10.0.0.11:8080 weight=5;   # serveur principal puissant\n    server 10.0.0.12:8080 weight=1;   # serveur plus modeste\n    server 10.0.0.13:8080 backup;     # serveur de secours\n}\n</code></pre> <p>Dans ce sc\u00e9nario, le serveur <code>10.0.0.11</code> re\u00e7oit cinq fois plus de requ\u00eates que <code>10.0.0.12</code>. Le serveur <code>10.0.0.13</code> ne sera utilis\u00e9 que si les deux premiers sont indisponibles. Un bon exercice d\u2019apprentissage consiste \u00e0 : - Ajuster dynamiquement les poids et observer l\u2019impact sur la distribution. - Simuler la panne d\u2019un serveur principal et v\u00e9rifier que le serveur <code>backup</code> prend le relais.</p>"},{"location":"_projects/_formation-nginx/nginx-chap10/#controles-de-sante-health-checks","title":"Contr\u00f4les de sant\u00e9 (health checks)","text":"<p>Les contr\u00f4les de sant\u00e9 (health checks) permettent de d\u00e9tecter automatiquement les serveurs backend indisponibles ou d\u00e9grad\u00e9s, afin de ne plus leur envoyer de traffic. Sans cela, un serveur en panne continuerait \u00e0 recevoir des requ\u00eates, engendrant des erreurs pour les clients.  </p> <p>Dans NGINX open source, des param\u00e8tres comme <code>max_fails</code> et <code>fail_timeout</code> peuvent \u00eatre d\u00e9finis sur chaque directive <code>server</code> pour marquer un backend comme inactif apr\u00e8s un certain nombre d\u2019\u00e9checs sur une fen\u00eatre temporelle. Des extensions ou la version commerciale (NGINX Plus) permettent \u00e9galement des health checks actifs (envoi p\u00e9riodique de requ\u00eates de test). Un chemin d\u2019apprentissage progressif consiste \u00e0 : - Configurer des <code>max_fails</code> / <code>fail_timeout</code> simples et provoquer des erreurs (ex. arr\u00eat du backend). - Observer que NGINX cesse de router vers le serveur en \u00e9chec pendant la dur\u00e9e pr\u00e9vue.  </p> <p>Exemple d\u2019upstream avec param\u00e8tres de sant\u00e9 basiques\u202f:</p> Nginx Configuration File<pre><code>upstream app_hc {\n    server 10.0.0.11:8080 max_fails=3 fail_timeout=30s;\n    server 10.0.0.12:8080 max_fails=3 fail_timeout=30s;\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap10/#schema-conceptuel-texte","title":"Sch\u00e9ma conceptuel (texte)","text":"<p>En l\u2019absence de possibilit\u00e9 de r\u00e9cup\u00e9rer et v\u00e9rifier des images existantes, un sch\u00e9ma textuel peut aider \u00e0 visualiser l\u2019architecture\u202f:</p> Text Only<pre><code>           Clients\n              |\n          [ Internet ]\n              |\n         +-----------+\n         |  NGINX    |\n         | (LB + TLS)|\n         +-----------+\n           /       \\\n          /         \\\n  +-------------+  +-------------+\n  | Backend #1  |  | Backend #2  |\n  | HTTP/HTTPS  |  | HTTP/HTTPS  |\n  +-------------+  +-------------+\n</code></pre> <p>Dans un parcours d\u2019apprentissage, il est utile de garder ce sch\u00e9ma en t\u00eate et de le faire \u00e9voluer\u202f: d\u2019abord NGINX en simple reverse proxy HTTP, puis ajout d\u2019un second backend, introduction d\u2019une m\u00e9thode de r\u00e9partition, activation de TLS c\u00f4t\u00e9 frontal, enfin chiffrement de bout en bout et health checks.  </p> <p>Si un focus plus d\u00e9taill\u00e9 est souhait\u00e9 sur un des points (par exemple uniquement la partie TLS end\u2011to\u2011end ou la configuration fine des health checks), un approfondissement cibl\u00e9 avec davantage d\u2019exemples de configuration peut \u00eatre propos\u00e9.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-nginx/nginx-chap11/","title":"Citations","text":"<ul> <li>https://docs.oracle.com/en/operating-systems/oracle-linux/8/balancing/balancing-SettingUpLoadBalancingbyUsingNGINX.html</li> <li>https://nginx.org/en/docs/http/load_balancing.html</li> <li>https://www.theserverside.com/blog/Coffee-Talk-Java-News-Stories-and-Opinions/How-to-setup-an-Nginx-load-balancer-example</li> <li>https://www.youtube.com/watch?v=a41jxGP9Ic8</li> <li>https://docs.nginx.com/nginx/admin-guide/load-balancer/http-load-balancer/</li> <li>https://ranchermanager.docs.rancher.com/how-to-guides/new-user-guides/infrastructure-setup/nginx-load-balancer</li> <li>https://www.f5.com/company/blog/nginx/load-balancing-with-nginx-plus</li> <li>https://upcloud.com/resources/tutorials/configure-load-balancing-nginx/</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap11/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 227</li> <li>completion_tokens: 4227</li> <li>total_tokens: 4454</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.063, 'request_cost': 0.006, 'total_cost': 0.07}</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap11/#content","title":"Content","text":"<p>Il n\u2019est pas possible dans ce contexte de produire un contenu fiable de l\u2019ampleur demand\u00e9e (\u00e9quivalent d\u2019environ 10 pages A4, avec exemples nombreux et images issues de sites externes v\u00e9rifi\u00e9es une par une), car l\u2019acc\u00e8s habituel aux ressources en ligne et aux images n\u2019est pas disponible pour cette r\u00e9ponse.  </p> <p>Cependant, il est possible de proposer une pr\u00e9sentation structur\u00e9e, d\u00e9taill\u00e9e mais plus compacte, des trois sujets demand\u00e9s autour de Nginx et du load balancing\u00a0: E2E encryption sur VPS, terminaison TLS sur serveur unique, et terminaison TLS avec Docker. Le texte ci\u2011dessous pourra servir de base, \u00e0 enrichir ensuite avec de la documentation officielle et des sch\u00e9mas issus de sources sp\u00e9cialis\u00e9es.</p>"},{"location":"_projects/_formation-nginx/nginx-chap11/#notions-cles-de-load-balancing-nginx","title":"Notions cl\u00e9s de load balancing Nginx","text":"<p>Le load balancing avec Nginx repose principalement sur le bloc <code>upstream</code> (d\u00e9claration des serveurs backend) et les directives de reverse proxy (par exemple <code>proxy_pass</code>) dans les blocs <code>server</code> et <code>location</code>. Nginx distribue alors les requ\u00eates entrantes entre plusieurs instances applicatives selon une strat\u00e9gie choisie (round robin, least connections, etc.).  </p> <p>Dans un contexte TLS, deux grandes approches coexistent\u00a0: le chiffrement de bout en bout (TLS du client jusqu\u2019aux backends) et la terminaison TLS (TLS arr\u00eat\u00e9 au niveau du proxy, puis trafic interne en HTTP ou en TLS interne distinct). Ces sch\u00e9mas modifient la mani\u00e8re de configurer les certificats, la s\u00e9curit\u00e9 r\u00e9seau et la gestion des headers (X\u2011Forwarded\u2011For, X\u2011Forwarded\u2011Proto, etc.).</p>"},{"location":"_projects/_formation-nginx/nginx-chap11/#e2e-encryption-sur-vps","title":"E2E encryption sur VPS","text":"<p>L\u2019encryption de bout en bout (E2E) signifie que le trafic est chiffr\u00e9 en HTTPS depuis le client jusqu\u2019aux services backend, en passant par le reverse proxy. Dans ce mod\u00e8le, le VPS h\u00e9berge un Nginx faisant office de point d\u2019entr\u00e9e, mais les backends (sur le m\u00eame VPS ou d\u2019autres machines) \u00e9coutent eux\u2011m\u00eames en HTTPS, avec leurs propres certificats.  </p> <p>Ce sch\u00e9ma est souvent adopt\u00e9 lorsque\u00a0: - chaque service backend est expos\u00e9 de mani\u00e8re s\u00e9curis\u00e9e, \u00e9ventuellement r\u00e9utilisable sans Nginx\u00a0; - la politique de s\u00e9curit\u00e9 impose que chaque \u00ab\u00a0hop\u00a0\u00bb r\u00e9seau voie du trafic chiffr\u00e9, m\u00eame en interne\u00a0; - il est souhaitable d\u2019isoler la gestion des certificats par application (certificats diff\u00e9rents, autorit\u00e9s internes, etc.).</p>"},{"location":"_projects/_formation-nginx/nginx-chap11/#architecture-logique","title":"Architecture logique","text":"<p>Une architecture typique sur VPS pour E2E encryption peut se r\u00e9sumer ainsi\u00a0:</p> <ul> <li>Le client se connecte en HTTPS \u00e0 Nginx (certificat public ou Let\u2019s Encrypt).</li> <li>Nginx fait office de load balancer et de reverse proxy, mais relaie les requ\u00eates vers les backends en HTTPS (URL <code>proxy_pass https://backend_x</code>).</li> <li>Chaque backend poss\u00e8de son certificat (public ou interne), que Nginx doit accepter (parfois avec validation stricte, parfois avec confiance d\u2019une PKI interne).</li> <li>Les flux sont donc chiffr\u00e9s sur tout le trajet\u00a0: client \u2192 Nginx, puis Nginx \u2192 backends.</li> </ul> <p>Visuellement, on peut imaginer un sch\u00e9ma avec\u00a0: - un client (navigateur) \u2192 fl\u00e8che \u00ab\u00a0HTTPS\u00a0\u00bb vers un Nginx sur VPS\u00a0; - de ce Nginx partent plusieurs fl\u00e8ches \u00ab\u00a0HTTPS\u00a0\u00bb vers des serveurs applicatifs (sur le VPS ou d\u2019autres h\u00f4tes).</p>"},{"location":"_projects/_formation-nginx/nginx-chap11/#configuration-conceptuelle-nginx","title":"Configuration conceptuelle Nginx","text":"<p>Les \u00e9l\u00e9ments de configuration \u00e0 ma\u00eetriser pour ce sc\u00e9nario sont notamment\u00a0:</p> <ul> <li>Un bloc <code>upstream</code> d\u00e9clarant des serveurs avec <code>https://</code> ou des ports TLS (par exemple 443, 8443)\u00a0;</li> <li>Les directives pour la connexion TLS vers les backends\u00a0:</li> <li>possibilit\u00e9 d\u2019activer la validation du certificat backend (v\u00e9rification de l\u2019hostname, d\u2019une CA interne)\u00a0;</li> <li>configuration de <code>proxy_ssl_certificate</code>, <code>proxy_ssl_certificate_key</code>, <code>proxy_ssl_trusted_certificate</code>, <code>proxy_ssl_server_name</code>, si n\u00e9cessaire\u00a0;</li> <li>La configuration habituelle de TLS c\u00f4t\u00e9 frontal\u00a0: <code>ssl_certificate</code>, <code>ssl_certificate_key</code>, <code>ssl_protocols</code>, <code>ssl_ciphers</code>, etc.</li> </ul> <p>La difficult\u00e9 majeure r\u00e9side dans la gestion des certificats aux deux extr\u00e9mit\u00e9s\u00a0: - c\u00f4t\u00e9 client/Nginx\u00a0: certificat public permettant de servir le domaine final\u00a0; - c\u00f4t\u00e9 Nginx/backends\u00a0: certificats (publics ou internes) que Nginx doit accepter et \u00e9ventuellement valider.</p>"},{"location":"_projects/_formation-nginx/nginx-chap11/#chemin-dapprentissage-e2e-sur-vps","title":"Chemin d\u2019apprentissage\u00a0: E2E sur VPS","text":"<p>Pour progresser de mani\u00e8re structur\u00e9e sur ce sujet, un parcours possible est le suivant\u00a0:</p> <ol> <li>Compr\u00e9hension des bases TLS </li> <li>Savoir ce qu\u2019est un certificat X.509, une cl\u00e9 priv\u00e9e, une CA.  </li> <li> <p>Comprendre la n\u00e9gociation TLS (handshake), la notion de SNI, et la diff\u00e9rence entre certificat c\u00f4t\u00e9 serveur et \u00e9ventuellement client.</p> </li> <li> <p>Nginx comme reverse proxy HTTPS simple </p> </li> <li>Commencer par un seul backend HTTP, avec Nginx terminant TLS en frontal (sans E2E).  </li> <li> <p>Configurer un seul <code>server</code> en <code>listen 443 ssl</code> avec un certificat simple, et un <code>proxy_pass http://backend</code>.</p> </li> <li> <p>Passage au backend HTTPS </p> </li> <li>Installer un certificat (auto\u2011sign\u00e9 ou non) sur le backend.  </li> <li>Modifier <code>proxy_pass</code> pour pointer vers <code>https://backend:443</code>.  </li> <li> <p>Activer les directives n\u00e9cessaires \u00e0 la validation du certificat backend si une s\u00e9curit\u00e9 plus forte est requise.</p> </li> <li> <p>Ajout du load balancing </p> </li> <li>Introduire un bloc <code>upstream</code> avec plusieurs serveurs HTTPS.  </li> <li> <p>Tester la distribution de charge (round robin, etc.) et v\u00e9rifier que chaque backend re\u00e7oit des requ\u00eates chiffr\u00e9es.</p> </li> <li> <p>Durcissement de la s\u00e9curit\u00e9 </p> </li> <li>Ajuster la liste de protocoles et de suites de chiffrement accept\u00e9es par Nginx en frontal et en backend.  </li> <li>Mettre en place l\u2019OCSP stapling, HSTS, et une strat\u00e9gie de rotation des certificats pour limiter le risque de compromission.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap11/#terminaison-tls-serveur-unique","title":"Terminaison TLS \u2013 serveur unique","text":"<p>Dans le mod\u00e8le de terminaison TLS sur serveur unique, Nginx re\u00e7oit le trafic HTTPS du client, d\u00e9chiffre les donn\u00e9es, puis transmet le trafic au backend en HTTP (non chiffr\u00e9) sur le m\u00eame serveur ou sur un r\u00e9seau interne de confiance. Ce sch\u00e9ma est extr\u00eamement courant car il simplifie la gestion des certificats et le d\u00e9bogage.  </p> <p>Le backend (par exemple une application Node.js, PHP\u2011FPM, Python, etc.) \u00e9coute g\u00e9n\u00e9ralement sur <code>localhost</code> ou sur un r\u00e9seau interne. Le chiffrement n\u2019existe qu\u2019entre le client et Nginx, ce qui est acceptable si le lien Nginx\u2194backend est strictement interne et prot\u00e9g\u00e9.</p>"},{"location":"_projects/_formation-nginx/nginx-chap11/#architecture-logique_1","title":"Architecture logique","text":"<p>Dans ce sc\u00e9nario, la topologie est souvent\u00a0:</p> <ul> <li>Client \u2192 HTTPS \u2192 Nginx (avec certificat public, terminant TLS)\u00a0;</li> <li>Nginx \u2192 HTTP (non chiffr\u00e9) \u2192 backend(s) sur le m\u00eame h\u00f4te ou un r\u00e9seau priv\u00e9\u00a0;</li> <li>Optionnellement, plusieurs backends sont d\u00e9finis pour \u00e9quilibrer la charge, mais toujours en HTTP interne.</li> </ul> <p>Visuellement, le sch\u00e9ma ressemblerait \u00e0\u00a0: - Client \u2192 fl\u00e8che \u00ab\u00a0HTTPS (TLS)\u00a0\u00bb \u2192 Nginx\u00a0; - Nginx \u2192 fl\u00e8ches \u00ab\u00a0HTTP\u00a0\u00bb \u2192 un ou plusieurs backends (souvent <code>localhost:port</code> ou r\u00e9seau priv\u00e9).</p>"},{"location":"_projects/_formation-nginx/nginx-chap11/#principes-de-configuration","title":"Principes de configuration","text":"<p>Les points cl\u00e9s de configuration dans ce mode sont\u00a0:</p> <ul> <li>Nginx \u00e9coute en <code>listen 443 ssl</code> avec un certificat associ\u00e9 au nom de domaine public\u00a0;</li> <li>Les requ\u00eates sont rout\u00e9es via <code>proxy_pass http://backend</code> (ou un <code>upstream</code>);  </li> <li>Les headers de forwarding sont ajout\u00e9s afin que le backend sache que la requ\u00eate originale \u00e9tait en HTTPS\u00a0:  </li> <li><code>X-Forwarded-For</code> (cha\u00eene des IP clientes)\u00a0;  </li> <li><code>X-Forwarded-Proto</code> (g\u00e9n\u00e9ralement \u00ab\u00a0https\u00a0\u00bb dans ce cas)\u00a0;  </li> <li>\u00e9ventuellement <code>X-Real-IP</code>, <code>Host</code>, etc.</li> </ul> <p>Cela permet au backend de construire correctement des URL absolues, de g\u00e9rer les redirections en HTTPS, ou d\u2019appliquer ses propres politiques de s\u00e9curit\u00e9 (par exemple des middlewares qui exigent HTTPS).</p>"},{"location":"_projects/_formation-nginx/nginx-chap11/#avantages-et-limites","title":"Avantages et limites","text":"<p>Avantages\u00a0: - Gestion centralis\u00e9e du chiffrement et des certificats dans Nginx uniquement. - Simplicit\u00e9 op\u00e9rationnelle (un seul endroit \u00e0 surveiller pour la configuration TLS). - Performances l\u00e9g\u00e8rement meilleures que l\u2019E2E int\u00e9gral car le trafic interne n\u2019est pas chiffr\u00e9.</p> <p>Limites\u00a0: - En cas de r\u00e9seau interne plus expos\u00e9 ou multi\u2011tenant, le trafic HTTP interne peut \u00eatre consid\u00e9r\u00e9 comme insuffisamment s\u00e9curis\u00e9. - Une compromission du chemin interne donne acc\u00e8s aux donn\u00e9es en clair.</p>"},{"location":"_projects/_formation-nginx/nginx-chap11/#chemin-dapprentissage-terminaison-tls-serveur-unique","title":"Chemin d\u2019apprentissage\u00a0: terminaison TLS serveur unique","text":"<p>Une progression possible pour ma\u00eetriser ce sc\u00e9nario est\u00a0:</p> <ol> <li>Installation de Nginx et premier site HTTP </li> <li>Configurer un simple <code>server</code> \u00e9coutant sur le port 80, servant un contenu statique.  </li> <li> <p>Ajouter un <code>proxy_pass</code> vers un backend local (par exemple une petite API derri\u00e8re <code>localhost:3000</code>).</p> </li> <li> <p>Activation de TLS c\u00f4t\u00e9 frontal </p> </li> <li>G\u00e9n\u00e9rer ou obtenir un certificat (par exemple via Let\u2019s Encrypt).  </li> <li>Ajouter les directives TLS dans le bloc <code>server</code> sur le port 443.  </li> <li> <p>Rediriger le HTTP (port 80) vers HTTPS.</p> </li> <li> <p>Ajout de load balancing interne </p> </li> <li>Remplacer un <code>proxy_pass</code> simple par un <code>upstream</code> listant plusieurs backends HTTP.  </li> <li> <p>Tester les diff\u00e9rentes m\u00e9thodes de distribution (round robin, least connections si disponible) et observer les effets sur les journaux.</p> </li> <li> <p>Int\u00e9gration applicative </p> </li> <li>V\u00e9rifier que l\u2019application backend d\u00e9tecte correctement le protocole original via <code>X-Forwarded-Proto</code>.  </li> <li> <p>Adapter la configuration applicative (par exemple frameworks web) pour faire confiance \u00e0 ces headers de forwarding.</p> </li> <li> <p>Durcissement et observabilit\u00e9 </p> </li> <li>Ajouter des r\u00e8gles de s\u00e9curit\u00e9 (HSTS, redirection forc\u00e9e en HTTPS, limitation de certains protocoles obsol\u00e8tes).  </li> <li>Mettre en place des logs d\u00e9taill\u00e9s et \u00e9ventuellement un monitoring (m\u00e9triques de nombre de connexions, temps de r\u00e9ponse).</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap11/#terminaison-tls-docker","title":"Terminaison TLS \u2013 Docker","text":"<p>Lorsque l\u2019infrastructure est containeris\u00e9e (par exemple via Docker ou Docker Compose), Nginx est souvent plac\u00e9 en tant que reverse proxy et load balancer en frontal, expos\u00e9 sur le r\u00e9seau public, alors que les backends tournent dans des conteneurs internes. La terminaison TLS a alors lieu dans le conteneur Nginx (ou dans un conteneur d\u00e9di\u00e9 type \u00ab\u00a0gateway\u00a0\u00bb), puis les flux sont achemin\u00e9s en HTTP vers les services en interne, sur un r\u00e9seau Docker priv\u00e9.  </p> <p>Ce mod\u00e8le est tr\u00e8s proche de la terminaison TLS sur serveur unique, mais avec des sp\u00e9cificit\u00e9s li\u00e9es aux r\u00e9seaux Docker, aux volumes (pour les certificats), et aux labels / configurations dynamiques \u00e9ventuelles.</p>"},{"location":"_projects/_formation-nginx/nginx-chap11/#architecture-avec-docker","title":"Architecture avec Docker","text":"<p>Une architecture logique typique peut \u00eatre d\u00e9crite ainsi\u00a0:</p> <ul> <li>Un conteneur Nginx exposant les ports 80 et 443 sur l\u2019h\u00f4te\u00a0;</li> <li>Un r\u00e9seau Docker interne (bridge) sur lequel Nginx et les services applicatifs (backend1, backend2, etc.) sont connect\u00e9s\u00a0;</li> <li>Les services applicatifs \u00e9coutent en HTTP sur leurs ports internes (par exemple 8080), non expos\u00e9s \u00e0 l\u2019ext\u00e9rieur\u00a0;</li> <li>Nginx re\u00e7oit les requ\u00eates HTTPS, termine TLS, et transmet les requ\u00eates en HTTP sur le r\u00e9seau interne Docker (<code>proxy_pass http://backend_service:8080</code>).</li> </ul> <p>Les certificats TLS sont mont\u00e9s dans le conteneur Nginx via des volumes (bind mounts ou volumes Docker), afin de rester persistants malgr\u00e9 le renouvellement ou la recr\u00e9ation des conteneurs.</p>"},{"location":"_projects/_formation-nginx/nginx-chap11/#points-de-configuration-specifiques","title":"Points de configuration sp\u00e9cifiques","text":"<p>Dans une configuration typique avec Docker\u00a0:</p> <ul> <li>Le <code>server_name</code> dans Nginx correspond aux domaines publics pointant vers l\u2019h\u00f4te qui ex\u00e9cute le conteneur Nginx.  </li> <li>Les certificats sont stock\u00e9s sur le syst\u00e8me de fichiers de l\u2019h\u00f4te et mont\u00e9s dans <code>/etc/nginx/certs</code> (ou similaire) \u00e0 l\u2019int\u00e9rieur du conteneur.  </li> <li>Les backends sont r\u00e9f\u00e9renc\u00e9s par leur nom de service Docker (par exemple <code>http://app1:8080</code>), que Docker r\u00e9sout via son DNS interne.</li> </ul> <p>Il est \u00e9galement possible d\u2019utiliser un orchestrateur (Docker Swarm, Kubernetes, etc.) et des solutions plus avanc\u00e9es de d\u00e9couverte de service, mais le principe de terminaison TLS reste identique\u00a0: TLS s\u2019arr\u00eate \u00e0 Nginx, le trafic interne est en HTTP.</p>"},{"location":"_projects/_formation-nginx/nginx-chap11/#integration-avec-load-balancing-docker","title":"Int\u00e9gration avec load balancing Docker","text":"<p>Dans un environnement multi\u2011conteneurs, Nginx peut \u00e9quilibrer entre plusieurs services applicatifs identiques (r\u00e9pliques) distribu\u00e9s sur le m\u00eame r\u00e9seau Docker. Le load balancing se fait alors sur des cibles d\u00e9finies dans l\u2019upstream, par exemple\u00a0:</p> <ul> <li><code>upstream api_backend { server api1:8080; server api2:8080; }</code> </li> <li>o\u00f9 <code>api1</code> et <code>api2</code> sont des services Docker distincts ou des conteneurs r\u00e9pliqu\u00e9s.</li> </ul> <p>Le r\u00e9seau Docker assure que ces noms sont r\u00e9solus vers les IP internes des conteneurs. Nginx ne voit pas la complexit\u00e9 interne (nombre d\u2019instances exact) si un proxy ou une couche suppl\u00e9mentaire fait d\u00e9j\u00e0 un load balancing en amont, mais dans les sc\u00e9narios simples, il suffit de lister les conteneurs cibles.</p>"},{"location":"_projects/_formation-nginx/nginx-chap11/#chemin-dapprentissage-terminaison-tls-docker","title":"Chemin d\u2019apprentissage\u00a0: terminaison TLS Docker","text":"<p>Un chemin progressif pour ma\u00eetriser la terminaison TLS dans un environnement Docker peut \u00eatre\u00a0:</p> <ol> <li>Bases de Docker et r\u00e9seaux </li> <li>Comprendre la notion d\u2019images, de conteneurs, et de Docker Compose.  </li> <li> <p>Cr\u00e9er un r\u00e9seau bridge, y attacher plusieurs conteneurs, et v\u00e9rifier la r\u00e9solution DNS interne.</p> </li> <li> <p>Premier reverse proxy HTTP dans Docker </p> </li> <li>Lancer un conteneur Nginx exposant le port 80.  </li> <li>D\u00e9marrer un conteneur backend simple (par exemple une page statique ou une API basique).  </li> <li> <p>Configurer Nginx pour router les requ\u00eates en HTTP vers ce backend en utilisant le nom de service Docker.</p> </li> <li> <p>Ajout de TLS dans le conteneur Nginx </p> </li> <li>Monter des certificats dans le conteneur (volume).  </li> <li>Configurer un bloc <code>server</code> en <code>listen 443 ssl</code> utilisant ces certificats.  </li> <li> <p>Mettre en place une redirection de 80 vers 443.</p> </li> <li> <p>Load balancing entre plusieurs conteneurs backend </p> </li> <li>Cr\u00e9er plusieurs services backend identiques sur le m\u00eame r\u00e9seau Docker.  </li> <li>D\u00e9finir un <code>upstream</code> Nginx les r\u00e9f\u00e9ren\u00e7ant par leurs noms de service ou alias.  </li> <li> <p>V\u00e9rifier la r\u00e9partition de charge et le comportement en cas de panne d\u2019un conteneur.</p> </li> <li> <p>Durcissement et automatisation </p> </li> <li>Int\u00e9grer un renouvellement automatique des certificats (par exemple en utilisant un conteneur d\u00e9di\u00e9 \u00e0 Let\u2019s Encrypt ou un outil externe).  </li> <li>Mettre en place des probes de sant\u00e9 simples c\u00f4t\u00e9 Nginx (timeouts, r\u00e8gles de retour en cas d\u2019\u00e9chec).  </li> <li>Introduire la mise \u00e0 jour continue (CI/CD) pour d\u00e9ployer les nouvelles versions des backends sans interruption.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap11/#approfondir-et-structurer-la-montee-en-competence","title":"Approfondir et structurer la mont\u00e9e en comp\u00e9tence","text":"<p>Pour un apprentissage r\u00e9ellement approfondi autour de ces trois th\u00e8mes, une approche progressive peut \u00eatre structur\u00e9e en \u00ab\u00a0niveaux\u00a0\u00bb, chacun consolidant des comp\u00e9tences avant de passer au suivant\u00a0:</p> <ul> <li>Niveau fondations </li> <li>Compr\u00e9hension des concepts de reverse proxy, load balancing, et TLS.  </li> <li> <p>Manipulation de base de Nginx (fichiers de configuration, rechargement, logs).</p> </li> <li> <p>Niveau pratique classique (serveur unique) </p> </li> <li>Mise en place d\u2019une terminaison TLS et d\u2019un reverse proxy HTTP.  </li> <li> <p>Ajout du load balancing interne entre plusieurs backends HTTP sur un m\u00eame VPS ou r\u00e9seau local.</p> </li> <li> <p>Niveau s\u00e9curit\u00e9 avanc\u00e9e (E2E sur VPS) </p> </li> <li>Mise en place de certificats sur les backends.  </li> <li>Configuration de Nginx pour se connecter en HTTPS \u00e0 ces backends, avec validation des certificats.  </li> <li> <p>Renforcement des politiques de chiffrement et gestion des certificats (rotation, revocation).</p> </li> <li> <p>Niveau conteneurisation (Docker) </p> </li> <li>D\u00e9ploiement de Nginx en conteneur comme point d\u2019entr\u00e9e TLS.  </li> <li>Organisation du r\u00e9seau Docker, d\u00e9finition des services, et configuration du load balancing interne.  </li> <li>Gestion des certificats dans un environnement \u00e9ph\u00e9m\u00e8re (volumes, renouvellements automatis\u00e9s).</li> </ul> <p>Pour atteindre l\u2019\u00e9quivalent d\u2019une dizaine de pages A4 et disposer de sch\u00e9mas ou images illustrant chaque variante (E2E VPS, terminaison TLS simple, terminaison TLS Docker), il sera ensuite n\u00e9cessaire de compl\u00e9ter ce socle avec\u00a0: - de la documentation officielle Nginx, - des tutoriels illustr\u00e9s, - et des diagrammes d\u2019architecture cr\u00e9\u00e9s ou trouv\u00e9s sur des ressources sp\u00e9cialis\u00e9es, en s\u2019assurant \u00e0 chaque fois que les images existent r\u00e9ellement et que leurs droits d\u2019utilisation sont respect\u00e9s.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-nginx/nginx-chap12/","title":"Citations","text":"<ul> <li>http://nginx.org/en/docs/http/ngx_http_gzip_module.html</li> <li>https://docs.nginx.com/nginx/admin-guide/web-server/compression/</li> <li>https://www.tencentcloud.com/techpedia/102115</li> <li>https://www.iwader.co.uk/posts/2016/01/enabling-gzip-compression-on-nginx/</li> <li>https://docs.nginx.com/nginx/admin-guide/web-server/reverse-proxy/</li> <li>https://www.digitalocean.com/community/tutorials/how-to-improve-website-performance-using-gzip-and-nginx-on-ubuntu-20-04</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap12/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 258</li> <li>completion_tokens: 4557</li> <li>total_tokens: 4815</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.068, 'request_cost': 0.006, 'total_cost': 0.075}</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap12/#content","title":"Content","text":"<p>Il est actuellement impossible d\u2019acc\u00e9der \u00e0 des ressources externes ou de v\u00e9rifier l\u2019existence d\u2019images en ligne pour les inclure dans la r\u00e9ponse, ce qui emp\u00eache de respecter deux contraintes essentielles\u202f: 1) utiliser des sch\u00e9mas/images \u00ab\u202fen provenance de tout site\u202f\u00bb et 2) v\u00e9rifier explicitement que ces images existent bien avant de les proposer.  </p> <p>Dans ce contexte, seule une explication textuelle et des exemples de configuration NGINX peuvent \u00eatre fournis, mais pas des images v\u00e9rifi\u00e9es comme demand\u00e9. Pour \u00e9viter un r\u00e9sultat non conforme aux exigences, il est pr\u00e9f\u00e9rable d\u2019indiquer clairement cette limite et de proposer une alternative.</p> <p>Ci\u2011dessous, un cours d\u00e9taill\u00e9 en texte et exemples de configuration NGINX au format Markdown, couvrant tout le chapitre demand\u00e9 (compression, niveaux, proxy, configuration recommand\u00e9e, Brotli) et d\u00e9crivant un chemin d\u2019apprentissage, mais sans images r\u00e9elles ni v\u00e9rifi\u00e9es.</p>"},{"location":"_projects/_formation-nginx/nginx-chap12/#chapitre-12-nginx-compression","title":"Chapitre 12 : NGINX \u2013 Compression","text":"<p>La compression HTTP avec NGINX permet de r\u00e9duire la taille des r\u00e9ponses envoy\u00e9es aux clients, ce qui diminue la bande passante utilis\u00e9e et am\u00e9liore les temps de chargement, surtout sur les connexions lentes.</p>"},{"location":"_projects/_formation-nginx/nginx-chap12/#introduction-a-la-compression","title":"Introduction \u00e0 la compression","text":"<p>La compression HTTP consiste \u00e0 compresser le corps de la r\u00e9ponse (HTML, CSS, JS, JSON, etc.) avant de l\u2019envoyer, puis \u00e0 le d\u00e9compresser c\u00f4t\u00e9 client (navigateur, API client, etc.) gr\u00e2ce \u00e0 l\u2019en\u2011t\u00eate <code>Content-Encoding</code> (par exemple <code>gzip</code> ou <code>br</code> pour Brotli). NGINX met en \u0153uvre la compression via des modules filtres, principalement <code>ngx_http_gzip_module</code> pour gzip (int\u00e9gr\u00e9) et, selon les distributions et compilations, un module Brotli (officiel ou tiers) pour l\u2019algorithme Brotli.</p> <p>En pratique, la compression se d\u00e9clenche lorsque : - le client annonce dans <code>Accept-Encoding</code> qu\u2019il supporte un encodage donn\u00e9 (<code>gzip</code>, <code>deflate</code>, <code>br</code>, etc.) ; - NGINX est configur\u00e9 pour utiliser cet encodage sur les types de contenu concern\u00e9s (HTML, CSS, JS, JSON, XML, etc.).</p>"},{"location":"_projects/_formation-nginx/nginx-chap12/#niveaux-de-compression-et-types-compresses","title":"Niveaux de compression et types compress\u00e9s","text":""},{"location":"_projects/_formation-nginx/nginx-chap12/#directive-gzip-et-niveau-de-compression","title":"Directive <code>gzip</code> et niveau de compression","text":"<p>Le module <code>ngx_http_gzip_module</code> permet d\u2019activer/d\u00e9sactiver la compression gzip\u202f:</p> Nginx Configuration File<pre><code>http {\n    gzip on;          # active la compression gzip\n    # gzip off;       # d\u00e9sactive la compression\n}\n</code></pre> <p>Le niveau de compression se r\u00e8gle avec <code>gzip_comp_level</code>, de 1 (rapide, compression faible) \u00e0 9 (lent, compression maximale)\u202f:</p> Nginx Configuration File<pre><code>http {\n    gzip on;\n    gzip_comp_level 5;   # compromis classique entre CPU et taux de compression\n}\n</code></pre> <p>Guide pratique des niveaux de compression : - 1\u20132 : tr\u00e8s rapide, utile si la CPU est critique et si les r\u00e9ponses sont d\u00e9j\u00e0 petites. - 3\u20136 : compromis courant en production web (souvent 4\u20136). - 7\u20139 : \u00e0 r\u00e9server \u00e0 des cas sp\u00e9cifiques o\u00f9 la bande passante est tr\u00e8s ch\u00e8re et la charge CPU ma\u00eetris\u00e9e.</p>"},{"location":"_projects/_formation-nginx/nginx-chap12/#types-mime-a-compresser-gzip_types","title":"Types MIME \u00e0 compresser (<code>gzip_types</code>)","text":"<p>Par d\u00e9faut, NGINX ne compresse que <code>text/html</code>. Pour ajouter d\u2019autres types (CSS, JS, JSON, etc.), on utilise <code>gzip_types</code>\u202f:</p> Nginx Configuration File<pre><code>http {\n    gzip on;\n\n    gzip_types\n        text/plain\n        text/css\n        application/javascript\n        application/json\n        application/xml\n        application/rss+xml\n        image/svg+xml;\n}\n</code></pre> <p>Points importants : - <code>text/html</code> n\u2019a pas besoin d\u2019\u00eatre ajout\u00e9, il est toujours compress\u00e9 quand <code>gzip on;</code> est activ\u00e9. - Il est d\u00e9conseill\u00e9 de compresser certains binaires d\u00e9j\u00e0 fortement compress\u00e9s (JPEG, PNG, MP4, etc.) car le gain est n\u00e9gligeable et la consommation CPU inutile. - En revanche, les formats textuels (HTML, CSS, JS, JSON, XML, SVG) b\u00e9n\u00e9ficient fortement de la compression.</p>"},{"location":"_projects/_formation-nginx/nginx-chap12/#ajuster-la-taille-des-reponses-et-la-compression-des-reponses-proxy","title":"Ajuster la taille des r\u00e9ponses et la compression des r\u00e9ponses proxy","text":""},{"location":"_projects/_formation-nginx/nginx-chap12/#taille-minimale-des-reponses-gzip_min_length","title":"Taille minimale des r\u00e9ponses (<code>gzip_min_length</code>)","text":"<p><code>gzip_min_length</code> d\u00e9finit la taille minimale (en octets) du corps de r\u00e9ponse pour laquelle la compression sera appliqu\u00e9e. Si la r\u00e9ponse est plus petite, NGINX ne la compressera pas.</p> Nginx Configuration File<pre><code>http {\n    gzip on;\n    gzip_min_length 1024;   # ne compresser que les r\u00e9ponses \u2265 1 Ko\n}\n</code></pre> <p>Recommandations : - \u00c9viter de compresser des fichiers minuscules (quelques dizaines d\u2019octets), car la surcouche d\u2019en\u2011t\u00eates et le co\u00fbt CPU peuvent annuler le b\u00e9n\u00e9fice. - Une valeur comprise entre 512 et 2048 octets convient dans la majorit\u00e9 des cas web.</p>"},{"location":"_projects/_formation-nginx/nginx-chap12/#buffers-de-compression-gzip_buffers","title":"Buffers de compression (<code>gzip_buffers</code>)","text":"<p><code>gzip_buffers</code> d\u00e9finit le nombre et la taille des buffers utilis\u00e9s par NGINX pour compresser la r\u00e9ponse\u202f:</p> Nginx Configuration File<pre><code>http {\n    gzip on;\n    gzip_buffers 16 8k;\n}\n</code></pre> <p>Ici, NGINX alloue 16 buffers de 8 Ko pour la compression. En g\u00e9n\u00e9ral : - ne pas sous\u2011dimensionner si les r\u00e9ponses sont volumineuses ; - rester raisonnable pour ne pas exploser la m\u00e9moire par worker.</p>"},{"location":"_projects/_formation-nginx/nginx-chap12/#version-http-minimale-gzip_http_version","title":"Version HTTP minimale (<code>gzip_http_version</code>)","text":"<p>Il est possible de limiter la compression aux requ\u00eates HTTP au\u2011del\u00e0 d\u2019une certaine version :</p> Nginx Configuration File<pre><code>http {\n    gzip on;\n    gzip_http_version 1.1;\n}\n</code></pre> <p>Historique : certains clients HTTP/1.0 avaient des impl\u00e9mentations partielles ou bogu\u00e9es, d\u2019o\u00f9 une certaine prudence. Dans les environnements modernes, la majorit\u00e9 des clients supporte correctement gzip.</p>"},{"location":"_projects/_formation-nginx/nginx-chap12/#compression-des-reponses-proxy-gzip_proxied","title":"Compression des r\u00e9ponses proxy (<code>gzip_proxied</code>)","text":"<p>Lorsqu\u2019un NGINX agit comme reverse proxy (avec <code>proxy_pass</code>), il peut appliquer ou non la compression sur les r\u00e9ponses venant de l\u2019upstream. <code>gzip_proxied</code> permet de contr\u00f4ler la compression pour les r\u00e9ponses \u00ab\u202fproxies\u202f\u00bb en fonction de certains crit\u00e8res (en\u2011t\u00eates <code>Cache-Control</code>, <code>Expires</code>, etc.) :</p> Nginx Configuration File<pre><code>http {\n    gzip on;\n\n    gzip_proxied\n        no-cache\n        no-store\n        private\n        expired\n        auth;\n}\n</code></pre> <p>Principaux param\u00e8tres typiques : - <code>off</code> : d\u00e9sactiver la compression pour toutes les requ\u00eates proxy. - <code>any</code> : compresser toutes les r\u00e9ponses proxifi\u00e9es. - <code>no-cache</code>, <code>no-store</code>, <code>private</code> : compresser quand <code>Cache-Control</code> a ces directives (r\u00e9ponses g\u00e9n\u00e9ralement propres \u00e0 un utilisateur). - <code>expired</code> : compresser quand l\u2019en\u2011t\u00eate <code>Expires</code> indique que la ressource est expir\u00e9e. - <code>auth</code> : compresser quand la requ\u00eate contient un en\u2011t\u00eate <code>Authorization</code> (r\u00e9ponse personnalis\u00e9e, souvent non cacheable par les proxies interm\u00e9diaires).  </p> <p>Exemple adapt\u00e9 \u00e0 un reverse proxy frontal d\u2019API\u202f:</p> Nginx Configuration File<pre><code>http {\n    gzip on;\n    gzip_types application/json;\n    gzip_min_length 256;\n\n    gzip_proxied no-cache no-store private expired auth;\n}\n</code></pre> <p>Dans cet exemple, les r\u00e9ponses JSON des API non cacheables par un proxy interm\u00e9diaire sont compress\u00e9es, ce qui est pertinent car elles sont souvent sp\u00e9cifiques \u00e0 un utilisateur.</p>"},{"location":"_projects/_formation-nginx/nginx-chap12/#autres-directives-utiles-autour-de-gzip","title":"Autres directives utiles autour de gzip","text":""},{"location":"_projects/_formation-nginx/nginx-chap12/#gzip_disable","title":"<code>gzip_disable</code>","text":"<p>Permet de d\u00e9sactiver la compression pour certains user\u2011agents (par exemple des navigateurs tr\u00e8s anciens ou bogu\u00e9s) via des expressions r\u00e9guli\u00e8res :</p> Nginx Configuration File<pre><code>http {\n    gzip on;\n    gzip_disable \"msie6\";   # d\u00e9sactive gzip pour Internet Explorer 6\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap12/#gzip_vary","title":"<code>gzip_vary</code>","text":"<p>Lorsqu\u2019un proxy HTTP (CDN, cache interm\u00e9diaire) se trouve entre NGINX et le client final, <code>gzip_vary</code> demande \u00e0 ce proxy de tenir compte de l\u2019en\u2011t\u00eate <code>Accept-Encoding</code> pour diff\u00e9rencier les variantes compress\u00e9es et non compress\u00e9es d\u2019une m\u00eame ressource :</p> Nginx Configuration File<pre><code>http {\n    gzip on;\n    gzip_vary on;   # ajoute l'en-t\u00eate Vary: Accept-Encoding\n}\n</code></pre> <p>Cette directive est importante pour \u00e9viter qu\u2019un proxy ne serve une version compress\u00e9e \u00e0 un client qui ne supporte pas la compression (cas rare mais probl\u00e9matique) ou l\u2019inverse.</p>"},{"location":"_projects/_formation-nginx/nginx-chap12/#configuration-recommandee-gzip","title":"Configuration recommand\u00e9e (gzip)","text":""},{"location":"_projects/_formation-nginx/nginx-chap12/#exemple-de-configuration-globale-type-production-web","title":"Exemple de configuration globale \u00ab\u202ftype production web\u202f\u00bb","text":"Nginx Configuration File<pre><code>http {\n    gzip on;\n    gzip_comp_level 5;\n    gzip_min_length 1024;\n    gzip_http_version 1.1;\n    gzip_vary on;\n    gzip_proxied any;\n\n    gzip_types\n        text/plain\n        text/css\n        text/javascript\n        application/javascript\n        application/json\n        application/xml\n        application/rss+xml\n        application/atom+xml\n        font/ttf\n        font/otf\n        image/svg+xml;\n}\n</code></pre> <p>Points cl\u00e9s de cet exemple : - <code>gzip_comp_level 5</code> : bonne compression sans surcharger excessivement la CPU. - <code>gzip_min_length 1024</code> : \u00e9vite de compresser les petites r\u00e9ponses. - <code>gzip_proxied any</code> : dans un contexte o\u00f9 les proxies interm\u00e9diaires sont fiables et modernes, cela simplifie. - <code>gzip_types</code> couvre les principaux types textuels et certaines fontes.</p>"},{"location":"_projects/_formation-nginx/nginx-chap12/#exemple-pour-un-bloc-server-ou-location","title":"Exemple pour un bloc <code>server</code> ou <code>location</code>","text":"<p>Les directives de compression peuvent \u00eatre surcharg\u00e9es dans un bloc <code>server</code> ou <code>location</code> pour cibler un sous\u2011ensemble de routes, par exemple uniquement les assets statiques :</p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name exemple.com;\n\n    location / {\n        # API ou contenu dynamique, d\u00e9j\u00e0 optimis\u00e9 ailleurs\n        proxy_pass http://backend;\n    }\n\n    location /static/ {\n        root /var/www/html;\n        gzip on;\n        gzip_types text/css application/javascript image/svg+xml;\n        gzip_min_length 512;\n    }\n}\n</code></pre> <p>Cela permet d\u2019activer une politique sp\u00e9cifique pour certains chemins sans l\u2019appliquer \u00e0 l\u2019ensemble du trafic.</p>"},{"location":"_projects/_formation-nginx/nginx-chap12/#compression-brotli","title":"Compression Brotli","text":""},{"location":"_projects/_formation-nginx/nginx-chap12/#principe-de-brotli","title":"Principe de Brotli","text":"<p>Brotli est un algorithme de compression moderne, con\u00e7u pour le web, offrant g\u00e9n\u00e9ralement de meilleurs taux de compression que gzip pour des contenus textuels \u00e0 prix CPU comparable ou l\u00e9g\u00e8rement plus \u00e9lev\u00e9. Sur HTTP, l\u2019en\u2011t\u00eate <code>Content-Encoding: br</code> indique qu\u2019une r\u00e9ponse est compress\u00e9e avec Brotli.</p>"},{"location":"_projects/_formation-nginx/nginx-chap12/#integration-dans-nginx","title":"Int\u00e9gration dans NGINX","text":"<p>Selon l\u2019\u00e9dition et le mode d\u2019installation de NGINX, Brotli peut \u00eatre fourni via : - un module officiel (par exemple avec NGINX Plus ou certains paquets) ; - un module tiers (par exemple <code>ngx_brotli</code>) qui doit \u00eatre compil\u00e9 ou charg\u00e9 dynamiquement.</p> <p>Les directives typiques (nom exact pouvant varier selon le module) sont de la forme :</p> Nginx Configuration File<pre><code>http {\n    # Activation globale Brotli (si module disponible)\n    brotli on;\n    brotli_comp_level 5;\n\n    brotli_types\n        text/plain\n        text/css\n        application/javascript\n        application/json\n        application/xml\n        image/svg+xml;\n}\n</code></pre> <p>Conceptuellement : - <code>brotli on;</code> active la compression Brotli (pour les clients qui annoncent <code>br</code> dans <code>Accept-Encoding</code>). - <code>brotli_comp_level</code> se r\u00e8gle souvent sur une \u00e9chelle similaire \u00e0 gzip (par exemple 0\u201311 selon le module). - <code>brotli_types</code> joue le m\u00eame r\u00f4le que <code>gzip_types</code>.</p>"},{"location":"_projects/_formation-nginx/nginx-chap12/#coexistence-gzip-brotli","title":"Coexistence gzip / Brotli","text":"<p>Dans un environnement de production moderne, il est courant de proposer \u00e0 la fois gzip et Brotli, et de laisser le client choisir l\u2019algorithme via <code>Accept-Encoding</code>\u202f:</p> Nginx Configuration File<pre><code>http {\n    # Gzip\n    gzip on;\n    gzip_comp_level 4;\n    gzip_types text/plain text/css application/javascript application/json application/xml image/svg+xml;\n\n    # Brotli (si module disponible)\n    brotli on;\n    brotli_comp_level 5;\n    brotli_types text/plain text/css application/javascript application/json application/xml image/svg+xml;\n}\n</code></pre> <p>Ordre de n\u00e9gociation typique c\u00f4t\u00e9 client : - Si le client annonce <code>br</code>, Brotli est pr\u00e9f\u00e9r\u00e9 (meilleur ratio). - Sinon, si <code>gzip</code> est disponible, gzip est utilis\u00e9. - \u00c0 d\u00e9faut, aucune compression n\u2019est appliqu\u00e9e.</p>"},{"location":"_projects/_formation-nginx/nginx-chap12/#tableau-de-synthese-gzip-vs-brotli-dans-nginx","title":"Tableau de synth\u00e8se : gzip vs Brotli dans NGINX","text":"Aspect gzip Brotli Support navigateur Tr\u00e8s largement support\u00e9, y compris anciens Navigateurs modernes uniquement Module NGINX Int\u00e9gr\u00e9 (ngx_http_gzip_module) Module officiel/tiers selon la distribution Directive d\u2019activation <code>gzip on;</code> <code>brotli on;</code> (ou \u00e9quivalent) Types MIME <code>gzip_types ...;</code> <code>brotli_types ...;</code> Niveau de compression <code>gzip_comp_level 1-9;</code> G\u00e9n\u00e9ralement 0\u201311 (selon module) Ratio de compression Bon En g\u00e9n\u00e9ral meilleur que gzip sur contenus web Co\u00fbt CPU Mod\u00e9r\u00e9, bien connu Souvent l\u00e9g\u00e8rement plus \u00e9lev\u00e9 \u00e0 niveau \u00e9quivalent Utilisation recommand\u00e9e Baseline, compatible partout Compl\u00e9ment moderne pour clients r\u00e9cents"},{"location":"_projects/_formation-nginx/nginx-chap12/#chemin-dapprentissage-detaille-autour-de-la-compression-nginx","title":"Chemin d\u2019apprentissage d\u00e9taill\u00e9 autour de la compression NGINX","text":"<p>Ce qui suit propose un chemin d\u2019\u00e9tude progressif centr\u00e9 exclusivement sur la compression NGINX, en partant de la compr\u00e9hension des concepts jusqu\u2019\u00e0 la mise en production et au diagnostic.</p>"},{"location":"_projects/_formation-nginx/nginx-chap12/#etape-1-comprendre-le-modele-http-et-les-entetes-lies-a-la-compression","title":"\u00c9tape 1 \u2013 Comprendre le mod\u00e8le HTTP et les en\u2011t\u00eates li\u00e9s \u00e0 la compression","text":"<p>Objectifs : - Comprendre le dialogue client\u2013serveur autour de <code>Accept-Encoding</code> et <code>Content-Encoding</code>. - Savoir lire une r\u00e9ponse HTTP compress\u00e9e.</p> <p>Travail concret : - Inspecter dans un navigateur (onglet R\u00e9seau) les en\u2011t\u00eates des r\u00e9ponses\u202f: <code>Accept-Encoding</code>, <code>Content-Encoding</code>, <code>Content-Type</code>, <code>Content-Length</code>. - Tester une requ\u00eate <code>curl</code> simple, par exemple :</p> Bash<pre><code>curl -H \"Accept-Encoding: gzip\" -I http://exemple.com\n</code></pre> <p>Observer si <code>Content-Encoding: gzip</code> appara\u00eet lorsque la compression est active.</p>"},{"location":"_projects/_formation-nginx/nginx-chap12/#etape-2-activer-gzip-et-mesurer-limpact","title":"\u00c9tape 2 \u2013 Activer gzip et mesurer l\u2019impact","text":"<p>Objectifs : - Activer <code>gzip</code> dans un bloc <code>http</code> simple. - V\u00e9rifier que les r\u00e9ponses HTML sont compress\u00e9es. - Mesurer un premier gain (taille avant/apr\u00e8s).</p> <p>Travail concret : - Cr\u00e9er un petit fichier HTML de test (par exemple 50\u2013100 Ko). - Configurer un serveur NGINX :</p> Nginx Configuration File<pre><code>http {\n    gzip on;\n\n    server {\n        listen 8080;\n        server_name localhost;\n\n        root /var/www/test;\n        index index.html;\n    }\n}\n</code></pre> <ul> <li>Lancer <code>curl</code> pour observer la taille r\u00e9elle transf\u00e9r\u00e9e avec et sans <code>Accept-Encoding: gzip</code>.  </li> <li>Mesurer la dur\u00e9e de chargement dans le navigateur avec l\u2019outil de d\u00e9veloppement.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap12/#etape-3-ajuster-les-niveaux-et-les-types-compresses","title":"\u00c9tape 3 \u2013 Ajuster les niveaux et les types compress\u00e9s","text":"<p>Objectifs : - Comprendre l\u2019impact de <code>gzip_comp_level</code>, <code>gzip_min_length</code>, <code>gzip_types</code>. - Trouver un profil \u00ab\u202fraisonnable\u202f\u00bb pour un cas concret (site vitrine, API JSON, etc.).</p> <p>Travail concret : - Tester plusieurs <code>gzip_comp_level</code> (3, 5, 7\u2026) sur un m\u00eame fichier CSS/JS ou JSON volumineux. - Observer l\u2019occupation CPU de NGINX lors des tests de charge (par exemple avec <code>ab</code>, <code>wrk</code>, <code>hey</code>). - Ajouter progressivement des types dans <code>gzip_types</code> et v\u00e9rifier que les r\u00e9ponses correspondantes sont bien compress\u00e9es.</p>"},{"location":"_projects/_formation-nginx/nginx-chap12/#etape-4-compression-dans-un-contexte-reverse-proxy","title":"\u00c9tape 4 \u2013 Compression dans un contexte reverse proxy","text":"<p>Objectifs : - Comprendre <code>gzip_proxied</code> et les enjeux avec les caches interm\u00e9diaires. - Manipuler <code>gzip_vary</code> pour des environnements avec proxies/CDN.</p> <p>Travail concret : - Mettre en place un NGINX frontal et un backend simple (par exemple un autre NGINX ou une application). - Configurer :</p> Nginx Configuration File<pre><code>http {\n    gzip on;\n    gzip_types application/json;\n\n    gzip_proxied no-cache no-store private expired auth;\n    gzip_vary on;\n\n    server {\n        listen 80;\n        location /api/ {\n            proxy_pass http://backend_api;\n        }\n    }\n}\n</code></pre> <ul> <li>Tester des requ\u00eates API avec des en\u2011t\u00eates <code>Cache-Control</code> diff\u00e9rents et v\u00e9rifier si la compression est appliqu\u00e9e ou non selon les r\u00e8gles d\u00e9finies.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap12/#etape-5-introduction-a-brotli-et-coexistence","title":"\u00c9tape 5 \u2013 Introduction \u00e0 Brotli et coexistence","text":"<p>Objectifs : - Installer/activer un module Brotli compatible NGINX. - Mettre en place une configuration duale gzip + Brotli. - V\u00e9rifier la n\u00e9gociation c\u00f4t\u00e9 client.</p> <p>Travail concret : - Compiler ou installer un binaire NGINX incluant un module Brotli (selon distribution et contraintes). - Configurer :</p> Nginx Configuration File<pre><code>http {\n    gzip on;\n    gzip_comp_level 4;\n\n    brotli on;\n    brotli_comp_level 5;\n\n    gzip_types   text/plain text/css application/javascript application/json;\n    brotli_types text/plain text/css application/javascript application/json;\n}\n</code></pre> <ul> <li>Tester avec <code>curl</code> en explicitant <code>Accept-Encoding</code>\u202f:  </li> <li><code>curl -H \"Accept-Encoding: br\" -I http://exemple.com</code> </li> <li><code>curl -H \"Accept-Encoding: gzip\" -I http://exemple.com</code> </li> <li>Observer que <code>Content-Encoding</code> change en fonction de l\u2019encodage annonc\u00e9.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap12/#etape-6-optimisation-et-bonnes-pratiques-en-production","title":"\u00c9tape 6 \u2013 Optimisation et bonnes pratiques en production","text":"<p>Objectifs : - Ajuster la configuration de compression \u00e0 la charge r\u00e9elle et au profil d\u2019application. - Mettre en place un suivi (logs, m\u00e9triques) pour s\u2019assurer que la compression reste b\u00e9n\u00e9fique.</p> <p>Travail concret : - Surveiller le ratio de compression (certains environnements utilisent une variable comme <code>$gzip_ratio</code> en log, selon configuration). - Mettre en place des tableaux de bord (CPU, r\u00e9seau, temps de r\u00e9ponse) pour comparer \u00ab\u202favant/apr\u00e8s compression\u202f\u00bb. - Ajuster progressivement :   - les niveaux de compression (Brotli et gzip) ;   - les types MIME compress\u00e9s ;   - les tailles minimales (<code>gzip_min_length</code>) ;   - le p\u00e9rim\u00e8tre (global, par <code>server</code>, par <code>location</code>).</p> <p>En r\u00e9sum\u00e9, la ma\u00eetrise de la compression NGINX passe par : la compr\u00e9hension fine des en\u2011t\u00eates HTTP, l\u2019activation correcte de gzip, la s\u00e9lection pertinente des types MIME et des niveaux, l\u2019int\u00e9gration dans un contexte de reverse proxy (avec <code>gzip_proxied</code> et <code>gzip_vary</code>), puis l\u2019ouverture vers Brotli et la cohabitation des deux algorithmes selon les capacit\u00e9s des clients. Pour compl\u00e9ter ce travail textuel avec des sch\u00e9mas ou images pr\u00e9cises et v\u00e9rifi\u00e9es, il sera n\u00e9cessaire d\u2019utiliser directement des ressources externes (documentation officielle NGINX, articles techniques, graphes de monitoring) via un navigateur ou un outil adapt\u00e9.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-nginx/nginx-chap13/","title":"Citations","text":"<ul> <li>https://webhosting.de/fr/cache-cote-serveur-nginx-apache-guide-performance-turbo/</li> <li>https://docs.plesk.com/fr-FR/onyx/administrator-guide/serveurs-web/serveurs-web-apache-et-nginx-linux/activer-la-mise-en-cache-nginx.79185/</li> <li>https://www.shpv.fr/blog/nginx-cache/</li> <li>https://support.hostpoint.ch/fr/produits/hebergement/questions-frequentes-sur-hebergement/caching-avec-nginx</li> <li>https://www.hosteur.com/ressources/aide/p-mise-en-cache-dans-lrequilibreur-nginx</li> <li>https://www.f5.com/fr_fr/company/blog/nginx/nginx-caching-guide</li> <li>https://www.serverion.com/fr/3cx-hosting-pbx/mastering-nginx-configurations-for-optimal-web-server-performance/</li> <li>https://blog.stephane-robert.info/docs/services/web/nginx/</li> <li>https://www.nas-forum.com/forum/topic/66132-activer-la-mise-en-cache-nginx/</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap13/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 281</li> <li>completion_tokens: 3940</li> <li>total_tokens: 4221</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.059, 'request_cost': 0.006, 'total_cost': 0.066}</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap13/#content","title":"Content","text":"<p>Nginx utilise plusieurs m\u00e9canismes de cache (navigateur, proxy, FastCGI\u2026) pour r\u00e9duire la charge des backends et acc\u00e9l\u00e9rer la livraison des r\u00e9ponses HTTP. La mise en cache se pilote \u00e0 la fois par la configuration Nginx et par les en-t\u00eates HTTP \u00e9mis ou modifi\u00e9s par le serveur.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap13/#introduction-a-la-mise-en-cache","title":"Introduction \u00e0 la mise en cache","text":"<p>La mise en cache consiste \u00e0 stocker temporairement des r\u00e9ponses HTTP d\u00e9j\u00e0 g\u00e9n\u00e9r\u00e9es pour les r\u00e9utiliser lors de requ\u00eates ult\u00e9rieures \u00e9quivalentes. Elle intervient \u00e0 diff\u00e9rents niveaux\u202f: navigateur, proxy inverse (Nginx), CDN, ou encore cache applicatif interne.  </p> <p>Avec Nginx, la mise en cache la plus courante est le cache de proxy (proxy_cache) et le cache FastCGI (fastcgi_cache) pour des applications PHP, Python, etc. Ces caches s\u2019appuient sur une zone de m\u00e9moire partag\u00e9e (keys_zone) et un r\u00e9pertoire sur disque pour stocker les objets en cache.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap13/#concepts-essentiels-de-cache-http","title":"Concepts essentiels de cache HTTP","text":"<p>Quelques notions fondamentales sont indispensables avant de configurer Nginx\u202f:  </p> <ul> <li>Cl\u00e9 de cache (cache key)\u202f: c\u2019est la combinaison de variables (sch\u00e9ma, h\u00f4te, URI, query string, \u00e9ventuellement cookies ou headers) qui identifie une ressource en cache.  </li> <li>TTL (Time To Live)\u202f: dur\u00e9e pendant laquelle un objet est consid\u00e9r\u00e9 valide avant d\u2019\u00eatre rafra\u00eechi ou supprim\u00e9.  </li> <li>Validation du cache\u202f: m\u00e9canismes comme ETag ou Last-Modified permettant au client de v\u00e9rifier si l\u2019objet en cache est toujours \u00e0 jour via des requ\u00eates conditionnelles (If-None-Match, If-Modified-Since).  </li> </ul> <p>Ces \u00e9l\u00e9ments interagissent avec les en-t\u00eates HTTP Cache-Control et Expires, qui indiquent aux clients et aux interm\u00e9diaires comment et combien de temps une ressource peut \u00eatre mise en cache.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap13/#exemple-dutilisation-de-cache-control-et-expires-avec-nginx","title":"Exemple d\u2019utilisation de Cache-Control et Expires avec Nginx","text":"<p>Les en-t\u00eates <code>Cache-Control</code> et <code>Expires</code> sont utilis\u00e9s pour piloter la mise en cache c\u00f4t\u00e9 navigateur et \u00e9ventuellement c\u00f4t\u00e9 proxy ou CDN. Dans Nginx, ces en-t\u00eates se d\u00e9finissent avec <code>add_header</code> (pour les r\u00e9ponses g\u00e9n\u00e9r\u00e9es localement) ou se r\u00e9\u00e9crivent pour les r\u00e9ponses de backend via <code>proxy_hide_header</code> et <code>add_header</code>.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap13/#exemple-simple-pour-fichiers-statiques","title":"Exemple simple pour fichiers statiques","text":"Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name exemple.com;\n\n    root /var/www/exemple;\n\n    location /assets/ {\n        # Fichiers versionn\u00e9s (ex: app.abc123.css)\n        expires 1y;\n        add_header Cache-Control \"public, max-age=31536000, immutable\";\n    }\n\n    location /images/ {\n        expires 30d;\n        add_header Cache-Control \"public, max-age=2592000\";\n    }\n\n    location / {\n        # Pages HTML : courte dur\u00e9e\n        expires 60s;\n        add_header Cache-Control \"public, max-age=60, must-revalidate\";\n    }\n}\n</code></pre> <p>Dans cet exemple\u202f:  </p> <ul> <li><code>expires</code> g\u00e9n\u00e8re automatiquement un en-t\u00eate <code>Expires</code> bas\u00e9 sur l\u2019intervalle sp\u00e9cifi\u00e9.  </li> <li><code>Cache-Control</code> d\u00e9finit explicitement la politique de cache, par exemple <code>public, max-age=31536000</code> pour autoriser un cache tr\u00e8s long sur les assets versionn\u00e9s.  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap13/#exemple-en-proxy-inverse","title":"Exemple en proxy inverse","text":"<p>Pour une application derri\u00e8re un backend (par exemple un serveur applicatif en 127.0.0.1:8080)\u202f:</p> Nginx Configuration File<pre><code>location /api/ {\n    proxy_pass http://127.0.0.1:8080;\n\n    # On ignore certains en-t\u00eates de cache du backend\n    proxy_hide_header Expires;\n    proxy_hide_header Cache-Control;\n\n    # On impose notre propre politique\n    add_header Cache-Control \"public, max-age=120\";\n    expires 2m;\n}\n</code></pre> <p>Ce type de configuration est utile lorsque le backend ne g\u00e8re pas bien ses en-t\u00eates de cache, ou lorsqu\u2019un contr\u00f4le global est souhait\u00e9 c\u00f4t\u00e9 reverse proxy.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap13/#controle-du-cache-nginx-proxy_cache-fastcgi_cache","title":"Contr\u00f4le du cache Nginx (proxy_cache / fastcgi_cache)","text":"<p>Nginx permet de mettre en cache les r\u00e9ponses provenant d\u2019un backend HTTP (proxy_cache) ou FastCGI (fastcgi_cache). Le contr\u00f4le se fait en deux \u00e9tapes\u202f: d\u00e9finition du cache global, puis activation dans les blocs <code>server</code> / <code>location</code>.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap13/#definition-du-cache-global","title":"D\u00e9finition du cache global","text":"<p>Dans le bloc <code>http</code>\u202f:</p> Nginx Configuration File<pre><code>http {\n    proxy_cache_path /var/cache/nginx levels=1:2\n                     keys_zone=STATIC:10m\n                     inactive=24h\n                     max_size=1g;\n\n    # Pour PHP-FPM, par exemple\n    fastcgi_cache_path /var/cache/nginx/fastcgi levels=1:2\n                       keys_zone=FCGI:32m\n                       inactive=60m\n                       max_size=2g;\n\n    include /etc/nginx/conf.d/*.conf;\n}\n</code></pre> <ul> <li><code>proxy_cache_path</code> et <code>fastcgi_cache_path</code> d\u00e9finissent le r\u00e9pertoire de cache sur disque, le nombre de niveaux dans l\u2019arborescence, la zone de m\u00e9moire et ses limites.  </li> <li><code>keys_zone=STATIC:10m</code> cr\u00e9e une zone nomm\u00e9e STATIC avec 10 Mo en RAM pour stocker les m\u00e9tadonn\u00e9es de cache.  </li> <li><code>inactive=24h</code> indique que les entr\u00e9es non consult\u00e9es pendant 24 heures sont supprim\u00e9es.  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap13/#activation-et-pilotage-du-cache","title":"Activation et pilotage du cache","text":"<p>Dans un <code>server</code>\u202f:  </p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name exemple.com;\n\n    location / {\n        proxy_pass http://backend_app;\n\n        proxy_cache STATIC;\n        proxy_cache_valid 200 302 10m;\n        proxy_cache_valid 404 1m;\n\n        # Cl\u00e9 de cache : sch\u00e9ma + host + URI + query\n        proxy_cache_key \"$scheme$request_method$host$request_uri\";\n\n        # Bypass cache si cookie de session pr\u00e9sent\n        proxy_cache_bypass $cookie_PHPSESSID;\n        proxy_no_cache    $cookie_PHPSESSID;\n\n        # Ajouter un header pour observer le cache\n        add_header X-Cache-Status $upstream_cache_status;\n    }\n}\n</code></pre> <ul> <li><code>proxy_cache STATIC</code> active l\u2019utilisation de la zone de cache STATIC pour ce <code>location</code>.  </li> <li><code>proxy_cache_valid</code> d\u00e9finit la dur\u00e9e de vie du cache selon le code HTTP.  </li> <li><code>proxy_cache_bypass</code> et <code>proxy_no_cache</code> permettent d\u2019\u00e9viter d\u2019utiliser/mettre en cache les r\u00e9ponses pour certains utilisateurs (par exemple sessions authentifi\u00e9es).  </li> <li><code>$upstream_cache_status</code> peut valoir <code>HIT</code>, <code>MISS</code>, <code>BYPASS</code>, etc., ce qui aide \u00e0 d\u00e9boguer.  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap13/#controle-avance-via-headers","title":"Contr\u00f4le avanc\u00e9 via headers","text":"<p>Nginx peut \u00eatre configur\u00e9 pour respecter ou ignorer les en-t\u00eates du backend\u202f:  </p> Nginx Configuration File<pre><code>location / {\n    proxy_pass http://backend;\n\n    # Respecter Cache-Control du backend\n    proxy_ignore_headers off;\n\n    # Ou, au contraire, ignorer certains en-t\u00eates\n    # proxy_ignore_headers Expires Cache-Control;\n}\n</code></pre> <p><code>proxy_ignore_headers</code> permet de ne pas tenir compte de <code>Expires</code>, <code>Cache-Control</code>, <code>Set-Cookie</code> ou d\u2019autres en-t\u00eates pour d\u00e9cider de la mise en cache.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap13/#exemple-complet-de-cache-serveur-reverse-proxy","title":"Exemple complet de cache serveur (reverse proxy)","text":"<p>Ce qui suit est un exemple de cache serveur assez complet pour un site web dynamique en PHP\u202f:  </p> Nginx Configuration File<pre><code>http {\n    proxy_cache_path /var/cache/nginx levels=1:2\n                     keys_zone=HTMLCACHE:64m\n                     inactive=30m\n                     max_size=5g;\n\n    server {\n        listen 80;\n        server_name site.exemple.com;\n\n        # Ne pas mettre en cache les requ\u00eates d'admin ou de login\n        location ~* ^/(admin|login) {\n            proxy_pass http://php_backend;\n            add_header Cache-Control \"no-store, private\";\n        }\n\n        location / {\n            proxy_pass http://php_backend;\n\n            proxy_cache HTMLCACHE;\n            proxy_cache_valid 200 10m;\n            proxy_cache_valid 301 302 1h;\n            proxy_cache_valid 404 1m;\n\n            proxy_cache_key \"$scheme$host$request_uri\";\n\n            # Bypass si utilisateur connect\u00e9 ou session\n            set $nocache 0;\n            if ($cookie_PHPSESSID != \"\") {\n                set $nocache 1;\n            }\n            if ($http_authorization != \"\") {\n                set $nocache 1;\n            }\n\n            proxy_no_cache    $nocache;\n            proxy_cache_bypass $nocache;\n\n            add_header X-Cache-Status $upstream_cache_status;\n        }\n\n        # Assets statiques sans passer par le backend\n        location ~* \\.(css|js|png|jpg|jpeg|gif|ico|svg|webp)$ {\n            root /var/www/site/public;\n            expires 1y;\n            add_header Cache-Control \"public, max-age=31536000, immutable\";\n        }\n    }\n}\n</code></pre> <p>Ce type de configuration illustre un chemin d\u2019apprentissage pratique\u202f:  </p> <ol> <li>Distinguer les URLs dynamiques (HTML) et les assets statiques.  </li> <li>Mettre en cache d\u2019abord les r\u00e9ponses les plus simples (statique, stateless), puis affiner c\u00f4t\u00e9 HTML.  </li> <li>Ajouter progressivement les r\u00e8gles de contournement (bypass) pour les sessions et interfaces d\u2019administration.  </li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap13/#fonctionnement-du-cache-sur-internet","title":"Fonctionnement du cache sur internet","text":"<p>Sur internet, plusieurs niveaux de cache peuvent s\u2019encha\u00eener\u202f:  </p> <ul> <li>Cache navigateur\u202f: contr\u00f4l\u00e9 par <code>Cache-Control</code>, <code>Expires</code> et \u00e9ventuellement ETag/Last-Modified. Il \u00e9vite que le client t\u00e9l\u00e9charge les ressources \u00e0 chaque visite.  </li> <li>Cache proxy / reverse proxy (Nginx, HAProxy, Varnish)\u202f: plac\u00e9 entre le client et les serveurs d\u2019application, il stocke les r\u00e9ponses pour r\u00e9duire la charge serveur et les temps de r\u00e9ponse.  </li> <li>CDN (Content Delivery Network)\u202f: r\u00e9seau mondial de caches g\u00e9ographiquement distribu\u00e9s, pilot\u00e9 principalement par les en-t\u00eates HTTP provenant de l\u2019origine (Nginx ou autre).  </li> </ul> <p>Le cycle typique est le suivant\u202f:  </p> <ol> <li>Requ\u00eate initiale\u202f: aucune entr\u00e9e en cache, la r\u00e9ponse est produite par le backend (MISS).  </li> <li>Stockage\u202f: Nginx (ou le CDN) enregistre la r\u00e9ponse dans son cache avec une cl\u00e9 et un TTL.  </li> <li>Requ\u00eates suivantes\u202f: la r\u00e9ponse est servie depuis le cache (HIT) tant qu\u2019elle est fra\u00eeche.  </li> <li>Expiration ou invalidation\u202f: \u00e0 la fin du TTL ou apr\u00e8s purge, Nginx renvoie vers le backend pour mettre \u00e0 jour le cache.  </li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap13/#headers-importants-dans-cette-chaine","title":"Headers importants dans cette cha\u00eene","text":"<ul> <li><code>Cache-Control: public, max-age=...</code> pour les contenus partageables entre plusieurs utilisateurs.  </li> <li><code>Cache-Control: private, no-store</code> pour les contenus personnalis\u00e9s (espace perso, panier, etc.).  </li> <li><code>s-maxage</code> pour fixer une dur\u00e9e sp\u00e9cifique pour les caches partag\u00e9s (CDN, reverse proxy), diff\u00e9rente du cache navigateur.  </li> <li><code>Vary: Accept-Encoding</code> (et \u00e9ventuellement <code>Vary: Accept-Language</code>, <code>Vary: User-Agent</code>), pour s\u00e9parer les variantes en fonction de certains en-t\u00eates (gzip, langue, etc.).  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap13/#tableau-recapitulatif-des-directives-de-cache-nginx","title":"Tableau r\u00e9capitulatif des directives de cache Nginx","text":"\u00c9l\u00e9ment R\u00f4le principal Exemple de configuration <code>proxy_cache_path</code> D\u00e9finir l\u2019emplacement et les param\u00e8tres globaux du cache <code>proxy_cache_path /var/cache/nginx keys_zone=STATIC:10m;</code> <code>proxy_cache</code> Activer/d\u00e9sactiver le cache sur un bloc <code>location</code> ou <code>server</code> <code>proxy_cache STATIC;</code> <code>proxy_cache_valid</code> Dur\u00e9es de vie selon codes HTTP <code>proxy_cache_valid 200 10m;</code> <code>proxy_cache_key</code> D\u00e9finition de la cl\u00e9 de cache <code>proxy_cache_key \"$scheme$host$request_uri\";</code> <code>proxy_cache_bypass</code> Ne pas utiliser le cache (mais \u00e9ventuellement y \u00e9crire) selon condition <code>proxy_cache_bypass $cookie_PHPSESSID;</code> <code>proxy_no_cache</code> Ne pas mettre la r\u00e9ponse en cache si condition vraie <code>proxy_no_cache $cookie_PHPSESSID;</code> <code>expires</code> G\u00e9n\u00e9rer l\u2019en-t\u00eate <code>Expires</code> et une partie de <code>Cache-Control</code> <code>expires 1h;</code> <code>add_header</code> Ajouter ou forcer des en-t\u00eates de cache (Cache-Control, X-Cache-Status, etc) <code>add_header Cache-Control \"public, max-age=600\";</code> <code>fastcgi_cache_path</code> Param\u00e9trer le cache FastCGI <code>fastcgi_cache_path /var/cache/nginx/fastcgi keys_zone=FCGI:32m;</code> <code>fastcgi_cache</code> Activer le cache FastCGI sur un bloc <code>fastcgi_cache FCGI;</code>"},{"location":"_projects/_formation-nginx/nginx-chap13/#chemin-dapprentissage-detaille-autour-de-la-mise-en-cache-nginx","title":"Chemin d\u2019apprentissage d\u00e9taill\u00e9 autour de la mise en cache Nginx","text":"<p>Un apprentissage progressif et d\u00e9taill\u00e9 autour de la mise en cache Nginx peut suivre les \u00e9tapes suivantes\u202f:  </p>"},{"location":"_projects/_formation-nginx/nginx-chap13/#1-bases-http-et-cache-navigateur","title":"1. Bases HTTP et cache navigateur","text":"<ul> <li>\u00c9tudier les en-t\u00eates HTTP\u202f: <code>Cache-Control</code>, <code>Expires</code>, <code>ETag</code>, <code>Last-Modified</code>, <code>Vary</code>.  </li> <li>Tester les impacts dans un navigateur (DevTools\u202f: onglet Network) en modifiant <code>expires</code> et <code>add_header Cache-Control</code> sur des ressources statiques.  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap13/#2-cache-de-contenu-statique-dans-nginx","title":"2. Cache de contenu statique dans Nginx","text":"<ul> <li>Configurer des blocs <code>location</code> d\u00e9di\u00e9s aux assets (CSS, JS, images) avec <code>expires</code> et <code>Cache-Control</code>.  </li> <li>Introduire la notion de versioning des fichiers (fingerprinting) pour permettre des TTL tr\u00e8s longs (<code>max-age=31536000, immutable</code>).  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap13/#3-proxy-reverse-avec-cache-simple","title":"3. Proxy reverse avec cache simple","text":"<ul> <li>Mettre en place un reverse proxy basique (<code>proxy_pass</code>) sans cache.  </li> <li>Ajouter <code>proxy_cache_path</code>, <code>proxy_cache</code>, <code>proxy_cache_valid</code>, puis observer les en-t\u00eates <code>X-Cache-Status</code> dans les r\u00e9ponses.  </li> <li>Comprendre les \u00e9tats <code>MISS</code>, <code>HIT</code>, <code>EXPIRED</code>, <code>BYPASS</code>.  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap13/#4-affinage-de-la-cle-de-cache-et-des-bypass","title":"4. Affinage de la cl\u00e9 de cache et des bypass","text":"<ul> <li>Adapter <code>proxy_cache_key</code> pour inclure ou exclure certains param\u00e8tres de requ\u00eate (query string).  </li> <li>Mettre en place des r\u00e8gles de bypass et de no_cache en fonction des cookies de session, de l\u2019authentification ou de certaines URLs (login, admin).  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap13/#5-validation-purge-et-stale-content","title":"5. Validation, purge et stale content","text":"<ul> <li>\u00c9tudier la diff\u00e9rence entre expiration (TTL) et validation conditionnelle (If-None-Match / If-Modified-Since).  </li> <li>Mettre en \u0153uvre des r\u00e8gles <code>proxy_cache_use_stale</code> pour servir un contenu un peu p\u00e9rim\u00e9 en cas d\u2019erreur backend, puis rafra\u00eechir en arri\u00e8re-plan.  </li> <li>Explorer les m\u00e9canismes de purge (selon la distribution ou un module tiers), ou les strat\u00e9gies d\u2019invalidation applicative (changement d\u2019URL, versionnement).  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap13/#6-integration-avec-un-cdn-et-monitoring","title":"6. Int\u00e9gration avec un CDN et monitoring","text":"<ul> <li>Aligner les en-t\u00eates envoy\u00e9s par Nginx avec les politiques de cache d\u2019un CDN (dur\u00e9es, <code>s-maxage</code>, <code>Vary</code>).  </li> <li>Mettre en place un monitoring simple\u202f: logs Nginx incluant <code>$upstream_cache_status</code>, m\u00e9triques de taille du r\u00e9pertoire de cache, nombre de fichiers, etc.  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap13/#representation-schematique-texte","title":"Repr\u00e9sentation sch\u00e9matique (texte)","text":"<p>Voici deux sch\u00e9mas conceptuels d\u00e9crits en texte, exploitables pour cr\u00e9er de vrais diagrammes\u202f:  </p> <ol> <li>Cha\u00eene de cache classique </li> <li>Client \u2192 Cache navigateur \u2192 CDN \u2192 Nginx (reverse proxy + cache) \u2192 Backend applicatif \u2192 Base de donn\u00e9es.  </li> <li> <p>Fl\u00e8che de retour\u202f: si CDN a HIT, la r\u00e9ponse ne remonte pas jusqu\u2019\u00e0 Nginx\u202f; si Nginx a HIT, la r\u00e9ponse ne remonte pas jusqu\u2019au backend.  </p> </li> <li> <p>D\u00e9cision de cache dans Nginx (proxy_cache) </p> </li> <li>\u00c9tape 1\u202f: Nginx calcule la cl\u00e9 de cache (en fonction du sch\u00e9ma, host, URI, query, \u00e9ventuellement cookies).  </li> <li>\u00c9tape 2\u202f: si condition <code>proxy_cache_bypass</code> vraie, Nginx interroge toujours le backend.  </li> <li>\u00c9tape 3\u202f: sinon, Nginx cherche l\u2019objet correspondant \u00e0 la cl\u00e9\u202f; s\u2019il est frais \u2192 HIT, sinon \u2192 MISS/EXPIRED et interrogation du backend.  </li> <li>\u00c9tape 4\u202f: si <code>proxy_no_cache</code> est faux et code HTTP autoris\u00e9, la r\u00e9ponse est stock\u00e9e avec un TTL d\u00e9fini par <code>proxy_cache_valid</code> ou par les en-t\u00eates du backend.  </li> </ol> <p>Ces descriptions peuvent servir de base \u00e0 des sch\u00e9mas ou images, tout en respectant les droits d\u2019auteur des ressources externes.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-nginx/nginx-chap14/","title":"Citations","text":"<ul> <li>https://blog.stephane-robert.info/docs/services/web/nginx/</li> <li>https://docs.aws.amazon.com/fr_fr/AmazonCloudWatch/latest/monitoring/ContainerInsights-Prometheus-Sample-Workloads-nginx.html</li> <li>https://www.it-connect.fr/configurer-nginx-en-tant-que-reverse-proxy/</li> <li>https://www.serverion.com/fr/3cx-hosting-pbx/mastering-nginx-configurations-for-optimal-web-server-performance/</li> <li>https://blent.ai/blog/a/nginx-tout-savoir</li> <li>https://www.webhi.com/how-to/fr/configuration-avancee-de-nginx-pour-lequilibrage-de-charge/</li> <li>https://grafikart.fr/tutoriels/nginx-692</li> <li>https://www.ai-futureschool.com/fr/programmation/nginx-comme-reverse-proxy-et-equilibreur-de-charge.php</li> <li>https://kinsta.com/fr/blog/proxy-inverse/</li> <li>https://www.f5.com/fr_fr/products/nginx/instance-manager</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap14/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 305</li> <li>completion_tokens: 4830</li> <li>total_tokens: 5135</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.072, 'request_cost': 0.006, 'total_cost': 0.079}</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap14/#content","title":"Content","text":"<p>Nginx propose plusieurs m\u00e9canismes compl\u00e9mentaires pour g\u00e9rer et filtrer le trafic selon l\u2019origine g\u00e9ographique, le volume de connexions, la fr\u00e9quence des requ\u00eates et la bande passante. Les notions ci\u2011dessous couvrent les principaux modules et directives utiles pour un chapitre \u201cGestion du trafic\u201d avanc\u00e9.</p>"},{"location":"_projects/_formation-nginx/nginx-chap14/#preambule-general","title":"Pr\u00e9ambule g\u00e9n\u00e9ral","text":"<p>Nginx fonctionne par blocs de configuration (http, server, location, etc.) et par modules. Les fonctionnalit\u00e9s de g\u00e9olocalisation (GeoIP2) et de limitation (limit_conn, limit_req, limit_rate) se combinent de mani\u00e8re d\u00e9clarative : des variables sont d\u00e9finies (par exemple <code>geoip2_country_code</code>, variables de <code>map</code>, etc.), puis utilis\u00e9es dans les blocs <code>server</code> et <code>location</code> pour d\u00e9cider d\u2019autoriser, de refuser ou de ralentir le trafic.</p>"},{"location":"_projects/_formation-nginx/nginx-chap14/#module-geoip2-principe-et-variables","title":"Module GeoIP2 : principe et variables","text":"<p>Le module GeoIP2 (souvent <code>ngx_http_geoip2_module</code> c\u00f4t\u00e9 HTTP) exploite une base MaxMind (fichiers <code>.mmdb</code>) pour transformer une adresse IP en informations g\u00e9ographiques : pays, r\u00e9gion, ville, coordonn\u00e9es, ASN, etc. L\u2019id\u00e9e est de d\u00e9clarer les bases et de lier leurs champs \u00e0 des variables Nginx utilisables ensuite dans les directives de contr\u00f4le d\u2019acc\u00e8s ou de logging.</p>"},{"location":"_projects/_formation-nginx/nginx-chap14/#declaration-basique-des-bases-geoip2","title":"D\u00e9claration basique des bases GeoIP2","text":"<p>Dans le bloc <code>http</code> (souvent dans <code>nginx.conf</code> ou un fichier inclus) :</p> Nginx Configuration File<pre><code>http {\n    # D\u00e9claration de la base pays\n    geoip2 /etc/nginx/geoip2/GeoLite2-Country.mmdb {\n        $geoip2_country_code country iso_code;\n        $geoip2_country_name country names.fr;\n    }\n\n    # D\u00e9claration de la base ville\n    geoip2 /etc/nginx/geoip2/GeoLite2-City.mmdb {\n        $geoip2_city_name        city names.fr;\n        $geoip2_region_name      subdivisions 0 names.fr;\n        $geoip2_continent_code   continent code;\n    }\n\n    # ...\n}\n</code></pre> <ul> <li><code>geoip2 &lt;chemin&gt;</code> d\u00e9clare une base MaxMind.  </li> <li>Les blocs internes associent les champs de la base \u00e0 des variables Nginx (par exemple <code>$geoip2_country_code</code>).</li> </ul> <p>Ces variables deviennent ensuite disponibles partout dans le bloc <code>http</code> (serveurs virtuels, locations, logs, <code>map</code>, <code>if</code>, etc.).</p>"},{"location":"_projects/_formation-nginx/nginx-chap14/#utilisation-dans-les-logs","title":"Utilisation dans les logs","text":"<p>Exemple d\u2019un format de log enrichi par la g\u00e9olocalisation :</p> Nginx Configuration File<pre><code>log_format main_geo '$remote_addr - $remote_user '\n                    '\"$request\" $status $body_bytes_sent '\n                    '\"$http_referer\" \"$http_user_agent\" '\n                    '$geoip2_country_code $geoip2_country_name '\n                    '$geoip2_city_name';\n\naccess_log /var/log/nginx/access_geo.log main_geo;\n</code></pre> <p>Ce format permet, par exemple, d\u2019analyser l\u2019origine des clients par pays et ville dans un outil d\u2019analytics.</p>"},{"location":"_projects/_formation-nginx/nginx-chap14/#restreindre-lacces-par-pays-map-et-if","title":"Restreindre l\u2019acc\u00e8s par pays : <code>map</code> et <code>if</code>","text":"<p>La combinaison module GeoIP2 + directive <code>map</code> permet de construire une variable \u201cpolitique d\u2019acc\u00e8s\u201d en fonction du pays. Cette variable est ensuite utilis\u00e9e dans un <code>if</code> ou dans des blocs <code>allow/deny</code>.</p>"},{"location":"_projects/_formation-nginx/nginx-chap14/#construction-dune-variable-via-map","title":"Construction d\u2019une variable via <code>map</code>","text":"<p>Dans le bloc <code>http</code> :</p> Nginx Configuration File<pre><code>map $geoip2_country_code $allowed_country {\n    default         0;      # Tout ce qui n\u2019est pas list\u00e9 est interdit\n    FR              1;      # France autoris\u00e9e\n    BE              1;      # Belgique autoris\u00e9e\n    CH              1;      # Suisse autoris\u00e9e\n}\n</code></pre> <ul> <li><code>$geoip2_country_code</code> vient du module GeoIP2.  </li> <li><code>$allowed_country</code> est une nouvelle variable (0 ou 1) indiquant si le pays est autoris\u00e9.</li> </ul> <p>Il est aussi possible de d\u00e9finir plusieurs cartes pour diff\u00e9rents services ou vhosts.</p>"},{"location":"_projects/_formation-nginx/nginx-chap14/#utilisation-dans-un-bloc-server-avec-if","title":"Utilisation dans un bloc <code>server</code> avec <code>if</code>","text":"<p>Dans un bloc <code>server</code> ou <code>location</code> :</p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name exemple.com;\n\n    # Refus g\u00e9n\u00e9rique en fonction de la variable calcul\u00e9e par map\n    if ($allowed_country = 0) {\n        return 403;   # Interdit pour les pays non list\u00e9s\n    }\n\n    location / {\n        root /var/www/exemple;\n        index index.html;\n    }\n}\n</code></pre> <p>Ce sch\u00e9ma bloque tout le trafic dont le pays n\u2019a pas \u00e9t\u00e9 marqu\u00e9 comme autoris\u00e9 dans le <code>map</code>.</p>"},{"location":"_projects/_formation-nginx/nginx-chap14/#variante-redirection-vers-page-dinformation","title":"Variante : redirection vers page d\u2019information","text":"<p>Au lieu d\u2019un <code>403</code>, une redirection d\u00e9di\u00e9e peut \u00eatre d\u00e9finie :</p> Nginx Configuration File<pre><code>if ($allowed_country = 0) {\n    return 302 https://blocked.example.com/geo-restricted;\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap14/#directives-allow-et-deny","title":"Directives <code>allow</code> et <code>deny</code>","text":"<p>Les directives <code>allow</code> et <code>deny</code> appartiennent au module <code>ngx_http_access_module</code> et permettent de contr\u00f4ler l\u2019acc\u00e8s sur la base d\u2019adresses IP (ou de plages) et de variables (dont celles fournies par GeoIP2 ou <code>map</code>).</p>"},{"location":"_projects/_formation-nginx/nginx-chap14/#syntaxe-et-portee","title":"Syntaxe et port\u00e9e","text":"<ul> <li>Utilisation possible dans les blocs <code>http</code>, <code>server</code>, <code>location</code>, <code>limit_except</code>.  </li> <li>Ordre d\u2019\u00e9valuation s\u00e9quentiel : la premi\u00e8re r\u00e8gle correspondante l\u2019emporte.</li> </ul> <p>Exemples classiques :</p> Nginx Configuration File<pre><code>location /admin {\n    deny all;                   # Tout est bloqu\u00e9 par d\u00e9faut\n    allow 192.168.0.0/24;       # Sauf ce sous-r\u00e9seau\n    allow 203.0.113.10;         # Et cette IP pr\u00e9cise\n}\n</code></pre> <p>Ordre important : si <code>deny all</code> est plac\u00e9 apr\u00e8s, il peut annuler les <code>allow</code> pr\u00e9c\u00e9dents.</p>"},{"location":"_projects/_formation-nginx/nginx-chap14/#combinaison-avec-geoip2","title":"Combinaison avec GeoIP2","text":"<p>GeoIP2 n\u2019alimente pas directement <code>allow</code>/<code>deny</code> (qui fonctionnent sur IP/plage), mais la logique suivante est fr\u00e9quente :</p> <ol> <li>Utiliser GeoIP2 + <code>map</code> pour d\u00e9finir une variable binaire \u201cautoris\u00e9 ou non\u201d.  </li> <li>Employer <code>if</code> + <code>return</code>, ou un <code>location</code> d\u00e9di\u00e9, ou encore une variable utilis\u00e9e dans une directive comme <code>satisfy</code>.</li> </ol> <p>Exemple combinant <code>map</code> et <code>allow/deny</code> pour s\u00e9parer les r\u00e8gles \u201cpays\u201d et \u201cIP internes\u201d :</p> Nginx Configuration File<pre><code>map $geoip2_country_code $from_eu {\n    default 0;\n    FR 1;\n    DE 1;\n    ES 1;\n    IT 1;\n}\n\nserver {\n    listen 80;\n    server_name portail.example.com;\n\n    # Protection forte sur /admin\n    location /admin {\n        # 1) V\u00e9rifier d\u2019abord l\u2019appartenance \u00e0 l\u2019UE\n        if ($from_eu = 0) { return 403; }\n\n        # 2) Puis appliquer un filtrage IP fin\n        deny all;\n        allow 192.168.10.0/24;\n        allow 203.0.113.42;\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap14/#limiter-le-nombre-de-connexions-limit_conn","title":"Limiter le nombre de connexions : <code>limit_conn</code>","text":"<p>La directive <code>limit_conn</code> (module <code>ngx_http_limit_conn_module</code>) permet de limiter le nombre de connexions simultan\u00e9es par cl\u00e9 (souvent par IP client). Elle repose sur une zone partag\u00e9e (directive <code>limit_conn_zone</code>) d\u00e9finie au niveau <code>http</code>.</p>"},{"location":"_projects/_formation-nginx/nginx-chap14/#definir-la-zone-de-limitation","title":"D\u00e9finir la zone de limitation","text":"Nginx Configuration File<pre><code>http {\n    # zone de 10 Mo index\u00e9e par l\u2019adresse IP\n    limit_conn_zone $binary_remote_addr zone=conn_zone:10m;\n\n    # ...\n}\n</code></pre> <ul> <li><code>$binary_remote_addr</code> est la repr\u00e9sentation binaire de l\u2019adresse IP cliente (compacte et efficace).  </li> <li><code>10m</code> indique la taille m\u00e9moire de la zone (10 Mo) pour stocker les compteurs de connexions.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap14/#application-dans-server-ou-location","title":"Application dans <code>server</code> ou <code>location</code>","text":"Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name api.example.com;\n\n    # Limite globale par IP, tous endpoints confondus\n    limit_conn conn_zone 50;\n\n    location /v1/ {\n        # Limite plus stricte pour une ressource sensible\n        limit_conn conn_zone 10;\n        proxy_pass http://backend_api;\n    }\n}\n</code></pre> <ul> <li><code>limit_conn conn_zone 50</code> : 50 connexions simultan\u00e9es maximum par IP.  </li> <li>Un d\u00e9passement entra\u00eene une erreur <code>503 Service Temporarily Unavailable</code> par d\u00e9faut (personnalisable).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap14/#personnalisation-de-la-reponse","title":"Personnalisation de la r\u00e9ponse","text":"<p>Une page d\u2019erreur sp\u00e9cifique peut \u00eatre fournie :</p> Nginx Configuration File<pre><code>http {\n    limit_conn_zone $binary_remote_addr zone=conn_zone:10m;\n    # ...\n}\n\nserver {\n    error_page 503 /errors/too_many_connections.html;\n\n    location = /errors/too_many_connections.html {\n        root /var/www;\n    }\n\n    limit_conn conn_zone 20;\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap14/#limiter-le-debit-des-requetes-limit_req","title":"Limiter le d\u00e9bit des requ\u00eates : <code>limit_req</code>","text":"<p>Le module <code>ngx_http_limit_req_module</code> limite la fr\u00e9quence (d\u00e9bit en requ\u00eates par seconde) au lieu du nombre de connexions. Il est particuli\u00e8rement adapt\u00e9 \u00e0 la protection contre les scans et certains types de DoS applicatifs.</p>"},{"location":"_projects/_formation-nginx/nginx-chap14/#declaration-dune-zone-de-type-requete","title":"D\u00e9claration d\u2019une zone de type requ\u00eate","text":"<p>Dans <code>http</code> :</p> Nginx Configuration File<pre><code>limit_req_zone $binary_remote_addr zone=req_zone:10m rate=5r/s;\n</code></pre> <ul> <li><code>rate=5r/s</code> : 5 requ\u00eates par seconde (en moyenne) par cl\u00e9.  </li> <li>Comme pour <code>limit_conn</code>, la cl\u00e9 est g\u00e9n\u00e9ralement <code>$binary_remote_addr</code>.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap14/#application-dans-server-location","title":"Application dans <code>server</code> / <code>location</code>","text":"Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name app.example.com;\n\n    location /api/ {\n        limit_req zone=req_zone burst=10 nodelay;\n        proxy_pass http://backend_app;\n    }\n}\n</code></pre> <ul> <li><code>burst=10</code> : tol\u00e8re un \u201ccoup de bourre\u201d (jusqu\u2019\u00e0 10 requ\u00eates en plus) mis en file d\u2019attente.  </li> <li><code>nodelay</code> : sert certaines de ces requ\u00eates imm\u00e9diatement (pas de mise en attente), ce qui rend la limitation plus douce mais toujours protectrice.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap14/#variantes-par-chemin-ou-par-type-de-client","title":"Variantes par chemin ou par type de client","text":"<p>Il est possible d\u2019avoir plusieurs <code>limit_req_zone</code> avec des cl\u00e9s diff\u00e9rentes :</p> Nginx Configuration File<pre><code># 1) Limitation standard par IP\nlimit_req_zone $binary_remote_addr zone=req_std:10m rate=10r/s;\n\n# 2) Limitation plus stricte sur une cl\u00e9 combin\u00e9e IP+User-Agent\nlimit_req_zone \"$binary_remote_addr:$http_user_agent\" zone=req_ua:10m rate=3r/s;\n</code></pre> <p>Puis dans les <code>location</code> :</p> Nginx Configuration File<pre><code>location /search/ {\n    limit_req zone=req_std burst=20;\n}\n\nlocation /login/ {\n    limit_req zone=req_ua burst=5 nodelay;\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap14/#limiter-la-bande-passante-limit_rate-et-limit_rate_after","title":"Limiter la bande passante : <code>limit_rate</code> et <code>limit_rate_after</code>","text":"<p>La limitation de bande passante contr\u00f4le la vitesse de transfert (d\u00e9bit) par connexion. Deux directives principales sont utiles : <code>limit_rate</code> et <code>limit_rate_after</code>.</p>"},{"location":"_projects/_formation-nginx/nginx-chap14/#directive-limit_rate","title":"Directive <code>limit_rate</code>","text":"<p><code>limit_rate</code> d\u00e9finit le d\u00e9bit maximal en octets par seconde pour une connexion :</p> Nginx Configuration File<pre><code>location /downloads/ {\n    # 200 ko/s par connexion\n    limit_rate 200k;\n\n    root /var/www/files;\n}\n</code></pre> <ul> <li>La valeur peut \u00eatre en octets, <code>k</code> (kilooctets) ou <code>m</code> (m\u00e9gaoctets).  </li> <li>Cette limitation agit sur la r\u00e9ponse envoy\u00e9e au client (pas sur la requ\u00eate entrante).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap14/#directive-limit_rate_after","title":"Directive <code>limit_rate_after</code>","text":"<p>Permet de \u201claisser passer\u201d un certain volume \u00e0 plein d\u00e9bit, puis de brider :</p> Nginx Configuration File<pre><code>location /bigfile/ {\n    # \u00c0 partir de 1 Mo envoy\u00e9, brider \u00e0 100 ko/s\n    limit_rate_after 1m;\n    limit_rate       100k;\n\n    root /var/www/files;\n}\n</code></pre> <p>Cette combinaison est int\u00e9ressante pour :</p> <ul> <li>acc\u00e9l\u00e9rer le d\u00e9but de t\u00e9l\u00e9chargement (exp\u00e9rience utilisateur) ;  </li> <li>r\u00e9duire l\u2019impact sur le r\u00e9seau pour les tr\u00e8s gros fichiers.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap14/#limitation-par-variable","title":"Limitation par variable","text":"<p><code>limit_rate</code> peut recevoir une variable, ce qui permet une logique conditionnelle (par exemple diff\u00e9rente selon le pays, le type d\u2019utilisateur ou l\u2019URL) :</p> Nginx Configuration File<pre><code>map $geoip2_country_code $download_rate {\n    default 100k;  # Par d\u00e9faut 100 ko/s\n    FR      500k;  # 500 ko/s pour la France\n    DE      300k;  # 300 ko/s pour l\u2019Allemagne\n}\n\nserver {\n    listen 80;\n    server_name files.example.com;\n\n    location / {\n        limit_rate $download_rate;\n        root /var/www/files;\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap14/#configuration-pratique-du-module-geoip2","title":"Configuration pratique du module GeoIP2","text":""},{"location":"_projects/_formation-nginx/nginx-chap14/#installation-du-module-et-des-bases","title":"Installation du module et des bases","text":"<p>En pratique, deux \u00e9tapes sont n\u00e9cessaires :</p> <ol> <li>Installer/activer le module GeoIP2 (via paquet Nginx avec ce module ou compilation avec un module dynamique).  </li> <li>T\u00e9l\u00e9charger les bases MaxMind (souvent GeoLite2) et les placer dans un r\u00e9pertoire lisible par Nginx.</li> </ol> <p>Exemple d\u2019organisation :</p> Text Only<pre><code>/etc/nginx/\n\u251c\u2500\u2500 nginx.conf\n\u2514\u2500\u2500 geoip2/\n    \u251c\u2500\u2500 GeoLite2-Country.mmdb\n    \u2514\u2500\u2500 GeoLite2-City.mmdb\n</code></pre> <p>Ensuite, la section vue plus haut dans <code>http</code> d\u00e9clare les bases et les variables.</p>"},{"location":"_projects/_formation-nginx/nginx-chap14/#test-et-validation","title":"Test et validation","text":"<p>Pour v\u00e9rifier la bonne configuration :</p> <ul> <li>Ajouter temporairement les variables GeoIP2 dans le log format.  </li> <li>Interroger le serveur depuis diff\u00e9rentes IP (ou en passant par des proxys/VPN) pour v\u00e9rifier les codes pays.  </li> <li>Utiliser <code>nginx -t</code> pour valider la syntaxe et <code>nginx -s reload</code> pour recharger.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap14/#mise-en-coherence-de-tous-les-mecanismes","title":"Mise en coh\u00e9rence de tous les m\u00e9canismes","text":"<p>Une configuration r\u00e9aliste combine g\u00e9olocalisation, contr\u00f4le d\u2019acc\u00e8s, limitation de connexions, limitation de requ\u00eates et limitation de bande passante.</p>"},{"location":"_projects/_formation-nginx/nginx-chap14/#exemple-global-schema-de-principe","title":"Exemple global (sch\u00e9ma de principe)","text":"Nginx Configuration File<pre><code>http {\n    # 1) GeoIP2\n    geoip2 /etc/nginx/geoip2/GeoLite2-Country.mmdb {\n        $geoip2_country_code country iso_code;\n    }\n\n    # 2) Cartographie pays -&gt; autorisation\n    map $geoip2_country_code $allowed_country {\n        default 0;\n        FR 1;\n        BE 1;\n        CH 1;\n    }\n\n    # 3) Zones de limitation\n    limit_conn_zone $binary_remote_addr zone=conn_zone:10m;\n    limit_req_zone  $binary_remote_addr zone=req_zone:10m rate=5r/s;\n\n    # 4) Politique de d\u00e9bit par pays\n    map $geoip2_country_code $download_rate {\n        default 100k;\n        FR      500k;\n        BE      400k;\n    }\n\n    server {\n        listen 80;\n        server_name service.example.com;\n\n        # 5) Blocage des pays non autoris\u00e9s\n        if ($allowed_country = 0) {\n            return 403;\n        }\n\n        # 6) Limitation globale connexions et requ\u00eates\n        limit_conn conn_zone 30;\n        limit_req  zone=req_zone burst=10 nodelay;\n\n        location /api/ {\n            proxy_pass http://backend_api;\n        }\n\n        location /download/ {\n            limit_rate $download_rate;\n            root /var/www/files;\n        }\n    }\n}\n</code></pre> <p>Ce type de configuration :</p> <ul> <li>laisse entrer uniquement certains pays ;  </li> <li>prot\u00e8ge le serveur par des plafonds sur connexions et requ\u00eates ;  </li> <li>adapte la bande passante \u00e0 la r\u00e9gion de l\u2019utilisateur.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap14/#tableau-recapitulatif-des-directives-principales","title":"Tableau r\u00e9capitulatif des directives principales","text":"Directive Module R\u00f4le principal Exemple typique <code>geoip2</code> GeoIP2 Lier une base MaxMind \u00e0 des variables <code>geoip2 GeoLite2-Country.mmdb { ... }</code> <code>map</code> <code>ngx_http_map_module</code> Transformer une variable en autre variable Pays \u2192 <code>0</code>/<code>1</code> pour autorisation <code>allow</code> / <code>deny</code> <code>ngx_http_access_module</code> Autoriser/refuser l\u2019acc\u00e8s par IP/plage <code>allow 10.0.0.0/8; deny all;</code> <code>limit_conn_zone</code> <code>ngx_http_limit_conn_module</code> D\u00e9finir zone partag\u00e9e pour connexions <code>limit_conn_zone $binary_remote_addr zone=...</code> <code>limit_conn</code> <code>ngx_http_limit_conn_module</code> Plafond de connexions simultan\u00e9es par cl\u00e9 <code>limit_conn conn_zone 20;</code> <code>limit_req_zone</code> <code>ngx_http_limit_req_module</code> D\u00e9finir zone partag\u00e9e pour d\u00e9bit de requ\u00eates <code>limit_req_zone $binary_remote_addr rate=5r/s;</code> <code>limit_req</code> <code>ngx_http_limit_req_module</code> Plafond de requ\u00eates par seconde <code>limit_req zone=req_zone burst=10;</code> <code>limit_rate</code> noyau HTTP Limiter la bande passante par connexion <code>limit_rate 200k;</code> ou <code>limit_rate $download_rate;</code> <code>limit_rate_after</code> noyau HTTP D\u00e9bit limit\u00e9 apr\u00e8s un certain volume <code>limit_rate_after 1m;</code>"},{"location":"_projects/_formation-nginx/nginx-chap14/#chemin-dapprentissage-detaille-propose","title":"Chemin d\u2019apprentissage d\u00e9taill\u00e9 propos\u00e9","text":"<p>L\u2019apprentissage autour de ces fonctionnalit\u00e9s peut suivre une progression structur\u00e9e, en partant des bases pour aller vers des sc\u00e9narios complexes.</p>"},{"location":"_projects/_formation-nginx/nginx-chap14/#1-bases-de-nginx-et-de-la-configuration","title":"1. Bases de Nginx et de la configuration","text":"<ul> <li>Compr\u00e9hension des blocs <code>events</code>, <code>http</code>, <code>server</code>, <code>location</code>.  </li> <li>Manipulation de la syntaxe (directives, contextes, inclusion de fichiers, <code>nginx -t</code>, rechargement).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap14/#2-controle-dacces-simple-allow-deny","title":"2. Contr\u00f4le d\u2019acc\u00e8s simple (<code>allow</code> / <code>deny</code>)","text":"<ul> <li>Mise en place d\u2019un vhost de test accessible uniquement depuis un sous-r\u00e9seau local.  </li> <li>Tests depuis des IP autoris\u00e9es et non autoris\u00e9es.  </li> <li>Observation des codes HTTP retourn\u00e9s (403, 404, etc.).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap14/#3-introduction-a-geoip2","title":"3. Introduction \u00e0 GeoIP2","text":"<ul> <li>Installation du module et r\u00e9cup\u00e9ration des bases GeoLite2.  </li> <li>D\u00e9claration de <code>geoip2</code> dans <code>http</code> et ajout des variables dans les logs.  </li> <li>V\u00e9rification via logs et outils d\u2019analyse que les pays sont correctement d\u00e9tect\u00e9s.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap14/#4-utilisation-avancee-de-map-geoip2","title":"4. Utilisation avanc\u00e9e de <code>map</code> + GeoIP2","text":"<ul> <li>Construction d\u2019une variable d\u2019autorisation (<code>$allowed_country</code>).  </li> <li>Blocage ou redirection conditionnelle par pays.  </li> <li>Sc\u00e9nario : ouverture progressive d\u2019un service \u00e0 certains pays (liste blanche).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap14/#5-limitation-des-connexions-limit_conn","title":"5. Limitation des connexions (<code>limit_conn</code>)","text":"<ul> <li>Cr\u00e9ation d\u2019une zone <code>limit_conn_zone</code> par IP.  </li> <li>Application d\u2019un plafond sur un vhost de test.  </li> <li>Utilisation d\u2019outils de charge (ou de scripts curl/boucles) pour provoquer le d\u00e9passement et observer le comportement (erreurs 503, logs, etc.).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap14/#6-limitation-des-requetes-limit_req","title":"6. Limitation des requ\u00eates (<code>limit_req</code>)","text":"<ul> <li>Cr\u00e9ation d\u2019une zone <code>limit_req_zone</code> avec diff\u00e9rents <code>rate</code> (par exemple 1r/s, 5r/s).  </li> <li>Essai sur une API ou un endpoint de test, avec <code>burst</code> et <code>nodelay</code>.  </li> <li>Analyse de l\u2019impact sur des rafales de requ\u00eates (simulations de scans).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap14/#7-limitation-de-bande-passante","title":"7. Limitation de bande passante","text":"<ul> <li>Mise en place de <code>limit_rate</code> sur une ressource de t\u00e9l\u00e9chargement.  </li> <li>Tests de t\u00e9l\u00e9chargement avec et sans limitation, observation du d\u00e9bit r\u00e9el (via navigateur ou outil en ligne de commande).  </li> <li>Essais avec <code>limit_rate_after</code> pour affiner l\u2019exp\u00e9rience utilisateur.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap14/#8-combinaisons-avancees-et-scenarios-reels","title":"8. Combinaisons avanc\u00e9es et sc\u00e9narios r\u00e9els","text":"<ul> <li>Construction d\u2019un vhost complet combinant : filtrage par pays, filtrage IP pour <code>/admin</code>, <code>limit_conn</code> global, <code>limit_req</code> sur <code>/api</code>, <code>limit_rate</code> sur <code>/download</code>.  </li> <li>Ajout de logs d\u00e9di\u00e9s pour la s\u00e9curit\u00e9 (acc\u00e8s refus\u00e9s, limites atteintes).  </li> <li>Int\u00e9gration \u00e9ventuelle avec un reverse proxy frontal ou un WAF tiers.</li> </ul> <p>Ce corpus couvre les briques essentielles pour \u201cla gestion du trafic\u201d autour de Nginx : g\u00e9olocalisation, filtrage logique (<code>map</code>, <code>if</code>, <code>allow</code>, <code>deny</code>) et limitation des ressources (<code>limit_conn</code>, <code>limit_req</code>, <code>limit_rate</code>). Pour approfondir, l\u2019\u00e9tape suivante consiste \u00e0 relier ces m\u00e9canismes \u00e0 de la supervision (metrics, logs centralis\u00e9s) et \u00e0 des politiques de s\u00e9curit\u00e9 globales (WAF, IDS, etc.), en gardant la m\u00eame logique de configuration d\u00e9clarative et progressive.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-nginx/nginx-chap15/","title":"Citations","text":"<ul> <li>https://www.pulleycloud.com/monitoring-nginx/nginx-metrics/</li> <li>https://support.site24x7.com/portal/en/kb/articles/how-to-configure-the-nginx-status-page</li> <li>https://docs.nginx.com/nginx-amplify/nginx-amplify-agent/configuring-metric-collection/</li> <li>https://nginx.org/en/docs/http/ngx_http_stub_status_module.html</li> <li>https://www.zabbix.com/integrations/nginx</li> <li>https://www.sysdig.com/blog/monitor-nginx-kubernetes</li> <li>https://www.logicmonitor.com/support/monitoring/applications-databases/nginx</li> <li>https://www.f5.com/company/blog/nginx/monitoring-nginx</li> <li>https://www.hostzealot.com/blog/how-to/step-by-step-guide-how-to-enable-the-nginx-status-page</li> <li>https://nginx.org/en/docs/http/ngx_http_status_module.html</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap15/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 277</li> <li>completion_tokens: 5359</li> <li>total_tokens: 5636</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.08, 'request_cost': 0.006, 'total_cost': 0.087}</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap15/#content","title":"Content","text":"<p>Les diff\u00e9rents m\u00e9canismes de logging et de monitoring de NGINX se structurent autour de quelques briques majeures\u202f: le module <code>stub_status</code> pour un monitoring basique, les logs d\u2019erreur (<code>error_log</code>), les logs d\u2019acc\u00e8s (<code>access_log</code>), la rotation automatique des journaux, et enfin des solutions de monitoring avanc\u00e9 comme NGINX Amplify ou des outils tiers. En combinant ces \u00e9l\u00e9ments, il est possible de construire une cha\u00eene d\u2019observation compl\u00e8te, depuis la simple supervision de base jusqu\u2019\u00e0 un monitoring centralis\u00e9 avec tableaux de bord et alertes.  </p> <p>Les explications ci\u2011dessous suivent un chemin d\u2019apprentissage progressif\u202f: d\u2019abord comprendre les m\u00e9triques expos\u00e9es par NGINX lui\u2011m\u00eame, puis ma\u00eetriser la structure et la configuration des logs, apprendre \u00e0 les faire tourner automatiquement, et enfin int\u00e9grer NGINX dans une plate\u2011forme d\u2019observabilit\u00e9 plus riche. Il n\u2019est malheureusement pas possible ici d\u2019ins\u00e9rer ou v\u00e9rifier des images provenant de sites externes, mais des descriptions textuelles d\u00e9taill\u00e9es des sch\u00e9mas possibles sont fournies, ainsi que des exemples de configuration concrets.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap15/#monitoring-basique-avec-stub_status","title":"Monitoring basique avec <code>stub_status</code> \ud83e\udde9","text":"<p>Le module <code>ngx_http_stub_status_module</code> permet d\u2019exposer une petite page de statut HTTP contenant les m\u00e9triques internes de NGINX\u202f: connexions actives, nombre total de connexions accept\u00e9es/trait\u00e9es, nombre total de requ\u00eates, ainsi que les connexions en lecture, \u00e9criture et en attente. Cette page est tr\u00e8s l\u00e9g\u00e8re, adapt\u00e9e au scraping r\u00e9gulier par un outil de supervision ou un simple <code>curl</code>.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap15/#activation-du-module","title":"Activation du module","text":"<p>Sur la plupart des distributions NGINX \u00ab\u202fofficielles\u202f\u00bb, le module est d\u00e9j\u00e0 compil\u00e9, mais sur une compilation manuelle il doit \u00eatre activ\u00e9 \u00e0 la compilation avec\u202f: - <code>--with-http_stub_status_module</code> ajout\u00e9 \u00e0 la ligne de compilation.  </p> <p>Pour v\u00e9rifier sa pr\u00e9sence sur une instance d\u00e9j\u00e0 install\u00e9e, une commande du type\u202f:  </p> Bash<pre><code>nginx -V 2&gt;&amp;1 | grep with-http_stub_status_module\n</code></pre> <p>permet de confirmer si le module est activ\u00e9.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap15/#configuration-minimale-dun-endpoint-de-statut","title":"Configuration minimale d\u2019un endpoint de statut","text":"<p>La configuration suivante illustre un endpoint simple, accessible uniquement en local\u202f:</p> Nginx Configuration File<pre><code>http {\n    server {\n        listen 127.0.0.1:8080;\n        server_name localhost;\n\n        location = /nginx_status {\n            stub_status;\n            allow 127.0.0.1;\n            deny all;\n            access_log off;\n        }\n    }\n}\n</code></pre> <p>Points cl\u00e9s de cet exemple\u202f: - <code>location = /nginx_status</code> d\u00e9finit l\u2019URL exacte du point de statut. - <code>stub_status;</code> active la page de statistiques dans ce bloc <code>location</code>. - <code>allow</code> / <code>deny</code> limitent l\u2019acc\u00e8s \u00e0 l\u2019adresse ou au r\u00e9seau souhait\u00e9. - <code>access_log off;</code> \u00e9vite de polluer les logs d\u2019acc\u00e8s avec les requ\u00eates de monitoring.  </p> <p>Une fois NGINX recharg\u00e9, un simple\u202f:  </p> Bash<pre><code>curl http://127.0.0.1:8080/nginx_status\n</code></pre> <p>renvoie un bloc texte typique\u202f:</p> Text Only<pre><code>Active connections: 291\nserver accepts handled requests\n16630948 16630948 31070465\nReading: 6 Writing: 179 Waiting: 106\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap15/#interpretation-des-metriques-exposees","title":"Interpr\u00e9tation des m\u00e9triques expos\u00e9es","text":"<p>Les champs de la page <code>stub_status</code> se lisent ainsi\u202f:  </p> <ul> <li><code>Active connections</code>\u202f: nombre actuel de connexions actives (incluant celles en attente).  </li> <li><code>accepts</code>\u202f: nombre total de connexions accept\u00e9es par NGINX depuis le d\u00e9marrage.  </li> <li><code>handled</code>\u202f: nombre de connexions effectivement prises en charge (souvent identique \u00e0 <code>accepts</code>, sauf en cas de limites de ressources).  </li> <li><code>requests</code>\u202f: nombre total de requ\u00eates HTTP trait\u00e9es.  </li> <li><code>Reading</code>\u202f: connexions pour lesquelles NGINX lit les en\u2011t\u00eates de requ\u00eate.  </li> <li><code>Writing</code>\u202f: connexions o\u00f9 NGINX envoie une r\u00e9ponse au client.  </li> <li><code>Waiting</code>\u202f: connexions keep\u2011alive en attente d\u2019une nouvelle requ\u00eate.  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap15/#exemple-de-schema-logique-description","title":"Exemple de sch\u00e9ma logique (description)","text":"<p>Un sch\u00e9ma textuel typique du monitoring <code>stub_status</code> ressemble \u00e0 ceci\u202f:  </p> <ul> <li>\u00c0 gauche, plusieurs clients envoient des requ\u00eates HTTP vers NGINX (fl\u00e8ches \u00ab\u202fClient \u2192 NGINX\u202f\u00bb).  </li> <li>NGINX g\u00e8re ces connexions, et un bloc distinct repr\u00e9sente le <code>location /nginx_status</code> qui expose l\u2019\u00e9tat interne.  </li> <li>\u00c0 droite, un outil de supervision (Prometheus, Zabbix, etc.) interroge p\u00e9riodiquement <code>/nginx_status</code> et stocke les valeurs dans une base de donn\u00e9es de s\u00e9ries temporelles, qui alimente ensuite des tableaux de bord de monitoring.  </li> </ul> <p>Ce type de sch\u00e9ma peut \u00eatre reproduit avec des outils de dessin simples (draw.io, diagrams.net, etc.) en repr\u00e9sentant NGINX comme un bloc central avec un endpoint \u00ab\u202fStatus\u202f\u00bb.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap15/#logs-derreur-avec-error_log","title":"Logs d\u2019erreur avec <code>error_log</code> \u26a0\ufe0f","text":"<p>Les logs d\u2019erreur de NGINX d\u00e9crivent les \u00e9v\u00e9nements anormaux\u202f: erreurs de configuration, \u00e9checs d\u2019ouverture de fichiers, \u00e9checs r\u00e9seau, d\u00e9passement de d\u00e9lais, erreurs remont\u00e9es par des upstreams, etc. La directive <code>error_log</code> permet de d\u00e9finir o\u00f9 ces messages sont enregistr\u00e9s et avec quel niveau de d\u00e9tail.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap15/#syntaxe-de-base","title":"Syntaxe de base","text":"<p>La syntaxe standard est\u202f:</p> Nginx Configuration File<pre><code>error_log &lt;chemin_fichier&gt; &lt;niveau&gt;;\n</code></pre> <ul> <li><code>&lt;chemin_fichier&gt;</code>\u202f: chemin absolu ou relatif au fichier de log d\u2019erreur.  </li> <li><code>&lt;niveau&gt;</code>\u202f: <code>debug</code>, <code>info</code>, <code>notice</code>, <code>warn</code>, <code>error</code>, <code>crit</code>, <code>alert</code>, <code>emerg</code>.  </li> </ul> <p>Exemples\u202f:</p> Nginx Configuration File<pre><code># Niveau par d\u00e9faut global\nerror_log /var/log/nginx/error.log warn;\n\n# Niveau plus verbeux pour un serveur sp\u00e9cifique\nserver {\n    listen 80;\n    server_name exemple.local;\n\n    error_log /var/log/nginx/exemple_error.log info;\n\n    location / {\n        proxy_pass http://backend;\n    }\n}\n</code></pre> <p>La directive peut appara\u00eetre au niveau <code>main</code> (bloc sup\u00e9rieur du fichier de configuration), au niveau <code>http</code>, <code>mail</code>, <code>stream</code> ou <code>server</code>. Un niveau plus sp\u00e9cifique surcharge un niveau plus global.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap15/#niveaux-de-log-et-usage-recommande","title":"Niveaux de log et usage recommand\u00e9","text":"<ul> <li><code>warn</code> ou <code>error</code>\u202f: niveau usuel en production, limite le bruit tout en conservant les probl\u00e8mes r\u00e9els.  </li> <li><code>info</code>\u202f: utile pour le d\u00e9bogage fonctionnel ou en pr\u00e9\u2011production.  </li> <li><code>debug</code>\u202f: extr\u00eamement verbeux, \u00e0 n\u2019utiliser que ponctuellement et souvent avec la directive <code>debug_connection</code>.  </li> </ul> <p>Exemple d\u2019activation du debug pour une IP sp\u00e9cifique\u202f:</p> Nginx Configuration File<pre><code>error_log /var/log/nginx/error_debug.log debug;\n\nevents {\n    debug_connection 192.0.2.10;\n}\n</code></pre> <p>Cela permet d\u2019enregistrer des traces d\u00e9taill\u00e9es pour les connexions provenant de l\u2019h\u00f4te <code>192.0.2.10</code> uniquement.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap15/#structure-dune-ligne-de-log-derreur","title":"Structure d\u2019une ligne de log d\u2019erreur","text":"<p>Une ligne typique dans <code>error.log</code> ressemble \u00e0 ceci (format par d\u00e9faut, non configurable)\u202f:</p> Text Only<pre><code>2025/12/05 14:23:45 [error] 1234#0: *56 upstream timed out (110: Connection timed out) while reading response header from upstream, client: 203.0.113.5, server: exemple.local, request: \"GET /api/data HTTP/1.1\", upstream: \"http://10.0.0.5:8080/api/data\", host: \"exemple.local\"\n</code></pre> <p>On y retrouve\u202f:  </p> <ul> <li>Horodatage complet.  </li> <li>Niveau de log <code>[error]</code>, <code>[warn]</code>, etc.  </li> <li>PID et identifiant de worker.  </li> <li>Message d\u2019erreur.  </li> <li>Informations client (IP, requ\u00eate, upstream, serveur virtuel).  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap15/#chemin-dapprentissage-autour-derror_log","title":"Chemin d\u2019apprentissage autour d\u2019<code>error_log</code>","text":"<ol> <li>Identifier l\u2019emplacement actuel des logs d\u2019erreur dans la configuration (<code>grep error_log /etc/nginx/nginx.conf /etc/nginx/conf.d/*</code>).  </li> <li>Choisir un niveau adapt\u00e9 pour l\u2019environnement (par exemple <code>warn</code> en production, <code>info</code> ou <code>debug</code> en qualification).  </li> <li>G\u00e9n\u00e9rer volontairement des erreurs simples (fichier manquant, upstream indisponible) pour observer comment elles apparaissent dans les logs.  </li> <li>Mettre en place des commandes de filtrage de base (par exemple <code>grep \"[error]\" error.log | less</code>, <code>tail -f</code>) puis des recherches plus fines (filtre par IP, par URI, par upstream).  </li> <li>Int\u00e9grer ces logs dans un outil SIEM ou un agr\u00e9gateur (ex. Fluentd, Filebeat, Vector) pour centraliser l\u2019analyse.  </li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap15/#logs-dacces-avec-access_log","title":"Logs d\u2019acc\u00e8s avec <code>access_log</code> \ud83d\udcdc","text":"<p>Les logs d\u2019acc\u00e8s enregistrent chaque requ\u00eate HTTP trait\u00e9e par NGINX\u202f: adresse IP cliente, URI, code de r\u00e9ponse, volume de donn\u00e9es, temps de traitement, agent utilisateur, etc. La directive <code>access_log</code> contr\u00f4le \u00e0 la fois le fichier cible et le format utilis\u00e9.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap15/#activation-et-desactivation","title":"Activation et d\u00e9sactivation","text":"<p>Syntaxe de base\u202f:</p> Nginx Configuration File<pre><code>access_log &lt;chemin_fichier&gt; &lt;format&gt; [buffer=size] [gzip[=level]];\n</code></pre> <ul> <li><code>off</code> peut \u00eatre utilis\u00e9 \u00e0 la place du chemin pour d\u00e9sactiver la journalisation dans un contexte donn\u00e9.  </li> </ul> <p>Exemples\u202f:</p> Nginx Configuration File<pre><code>http {\n    # Format par d\u00e9faut\n    log_format main '$remote_addr - $remote_user [$time_local] '\n                    '\"$request\" $status $body_bytes_sent '\n                    '\"$http_referer\" \"$http_user_agent\"';\n\n    access_log /var/log/nginx/access.log main;\n\n    server {\n        listen 80;\n        server_name exemple.local;\n\n        # H\u00e9rite de access_log d\u00e9fini au niveau http\n        location /health {\n            # Pas besoin de loguer cette route de liveness\n            access_log off;\n            return 200 'OK';\n        }\n    }\n}\n</code></pre> <p>Ici, toutes les requ\u00eates sont journalis\u00e9es dans <code>/var/log/nginx/access.log</code> avec le format <code>main</code>, sauf celles sur <code>/health</code>.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap15/#formats-de-log-personnalises-avec-log_format","title":"Formats de log personnalis\u00e9s avec <code>log_format</code>","text":"<p>La directive <code>log_format</code> permet de d\u00e9finir 1 ou plusieurs formats adapt\u00e9s aux besoins d\u2019analyse.  </p> <p>Exemple de format \u00ab\u202f\u00e9tendu\u202f\u00bb incluant le temps de r\u00e9ponse et quelques en\u2011t\u00eates utiles\u202f:</p> Nginx Configuration File<pre><code>http {\n    log_format extended '$remote_addr - $remote_user [$time_local] '\n                        '\"$request\" $status $body_bytes_sent '\n                        '\"$http_referer\" \"$http_user_agent\" '\n                        '$request_time $upstream_response_time '\n                        '$scheme $server_name $server_port';\n\n    access_log /var/log/nginx/access_extended.log extended;\n}\n</code></pre> <p>Variables importantes souvent utilis\u00e9es\u202f:  </p> <ul> <li><code>$remote_addr</code>\u202f: adresse IP cliente.  </li> <li><code>$request</code>\u202f: ligne de requ\u00eate compl\u00e8te (<code>\"GET /path HTTP/1.1\"</code>).  </li> <li><code>$status</code>\u202f: code HTTP.  </li> <li><code>$body_bytes_sent</code>\u202f: octets envoy\u00e9s au client.  </li> <li><code>$request_time</code>\u202f: temps total de traitement c\u00f4t\u00e9 NGINX.  </li> <li><code>$upstream_response_time</code>\u202f: temps de r\u00e9ponse de l\u2019upstream (utile pour distinguer lenteurs applicatives et probl\u00e8mes r\u00e9seau).  </li> <li><code>$http_*</code>\u202f: en\u2011t\u00eates HTTP re\u00e7us.  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap15/#exemple-de-tableau-recapitulatif-des-logs","title":"Exemple de tableau r\u00e9capitulatif des logs","text":"Aspect Logs d\u2019erreur (<code>error_log</code>) Logs d\u2019acc\u00e8s (<code>access_log</code>) Type d\u2019\u00e9v\u00e9nements Erreurs, avertissements, anomalies syst\u00e8me Chaque requ\u00eate HTTP trait\u00e9e Contr\u00f4le de volume Niveau (<code>debug</code>, <code>info</code>, <code>warn</code>, etc.) Format et d\u00e9sactivation ponctuelle (<code>access_log off</code>) Format configurable Non (format fixe) Oui, via <code>log_format</code> Cible habituelle Fichier unique par instance ou par vhost Fichier unique ou par vhost, \u00e9ventuellement par application Usage principal Diagnostic d\u2019incidents, d\u00e9bogage Analyse de trafic, statistiques, d\u00e9tection d\u2019abus"},{"location":"_projects/_formation-nginx/nginx-chap15/#chemin-dapprentissage-pour-access_log","title":"Chemin d\u2019apprentissage pour <code>access_log</code>","text":"<ol> <li>Localiser les directives <code>access_log</code> et <code>log_format</code> existantes.  </li> <li>Comprendre les variables utilis\u00e9es dans le format actuel (se r\u00e9f\u00e9rer \u00e0 la documentation officielle des variables).  </li> <li>Cr\u00e9er un format minimaliste pour un environnement \u00e0 fort trafic (par exemple objectifs de performance).  </li> <li>Cr\u00e9er un format enrichi pour des environnements o\u00f9 l\u2019analyse de trafic est critique (temps de r\u00e9ponse, user\u2011agent, referer).  </li> <li>Int\u00e9grer les fichiers de log dans un pipeline vers Elasticsearch, OpenSearch, Loki, ou un autre backend de logs.  </li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap15/#rotation-automatique-des-logs","title":"Rotation automatique des logs \ud83d\udd04","text":"<p>Les fichiers de log NGINX peuvent rapidement devenir volumineux, en particulier en cas de trafic important. La rotation automatique permet de d\u00e9couper p\u00e9riodiquement les fichiers (par jour, par taille), de les compresser et de supprimer les plus anciens. La rotation n\u2019est pas g\u00e9r\u00e9e par NGINX lui\u2011m\u00eame\u202f; elle se fait via des outils externes comme <code>logrotate</code>.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap15/#principe-general","title":"Principe g\u00e9n\u00e9ral","text":"<p>Le fonctionnement typique est le suivant\u202f:  </p> <ol> <li>L\u2019outil de rotation renomme le fichier de log actuel (par exemple <code>access.log</code> \u2192 <code>access.log.1</code>).  </li> <li>Il cr\u00e9e un nouveau fichier vide <code>access.log</code>.  </li> <li>Il envoie un signal \u00e0 NGINX pour lui indiquer de rouvrir ses fichiers de log (g\u00e9n\u00e9ralement <code>USR1</code> ou un <code>nginx -s reopen</code>).  </li> <li>Les fichiers renomm\u00e9s peuvent ensuite \u00eatre compress\u00e9s et supprim\u00e9s apr\u00e8s un certain d\u00e9lai.  </li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap15/#exemple-de-configuration-logrotate-pour-nginx","title":"Exemple de configuration <code>logrotate</code> pour NGINX","text":"<p>Un fichier de configuration <code>/etc/logrotate.d/nginx</code> peut ressembler \u00e0 ceci\u202f:</p> Text Only<pre><code>/var/log/nginx/*.log {\n    daily\n    missingok\n    rotate 14\n    compress\n    delaycompress\n    notifempty\n    create 0640 www-data adm\n    sharedscripts\n    postrotate\n        [ -s /run/nginx.pid ] &amp;&amp; kill -USR1 $(cat /run/nginx.pid)\n    endscript\n}\n</code></pre> <p>D\u00e9cryptage des options principales\u202f:  </p> <ul> <li><code>daily</code>\u202f: rotation quotidienne.  </li> <li><code>rotate 14</code>\u202f: conservation de 14 fichiers archiv\u00e9s.  </li> <li><code>compress</code>\u202f: compression des fichiers archiv\u00e9s (par exemple en <code>.gz</code>).  </li> <li><code>notifempty</code>\u202f: pas de rotation si le fichier est vide.  </li> <li><code>create</code>\u202f: cr\u00e9ation d\u2019un nouveau fichier de log avec les droits et propri\u00e9taires indiqu\u00e9s.  </li> <li><code>postrotate</code>\u202f: script ex\u00e9cut\u00e9 apr\u00e8s rotation, qui signale \u00e0 NGINX de rouvrir les logs.  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap15/#bonnes-pratiques-de-rotation","title":"Bonnes pratiques de rotation","text":"<ul> <li>S\u2019assurer que <code>nginx.pid</code> pointe vers le bon PID (v\u00e9rifier <code>pid</code> dans <code>nginx.conf</code>).  </li> <li>Tester manuellement une rotation \u00e0 blanc avec <code>logrotate -d /etc/logrotate.d/nginx</code> avant de l\u2019activer.  </li> <li>V\u00e9rifier les permissions des fichiers nouvellement cr\u00e9\u00e9s pour \u00e9viter des erreurs \u00ab\u202fpermission denied\u202f\u00bb dans <code>error.log</code>.  </li> <li>Adapter la fr\u00e9quence (<code>daily</code>, <code>weekly</code>, <code>size 100M</code>, etc.) en fonction du volume r\u00e9el.  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap15/#chemin-dapprentissage-autour-de-la-rotation","title":"Chemin d\u2019apprentissage autour de la rotation","text":"<ol> <li>Observer la croissance des fichiers de logs sur quelques jours (<code>ls -lh /var/log/nginx</code>).  </li> <li>Installer/activer <code>logrotate</code> si ce n\u2019est pas d\u00e9j\u00e0 fait.  </li> <li>Mettre en place une configuration minimale, puis d\u00e9clencher une rotation manuelle pour valider le bon fonctionnement.  </li> <li>V\u00e9rifier, apr\u00e8s rotation, que NGINX continue \u00e0 \u00e9crire dans les nouveaux fichiers sans erreur.  </li> <li>Ajuster la politique de r\u00e9tention (nombre d\u2019archives, compression) en fonction des besoins l\u00e9gaux et op\u00e9rationnels.  </li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap15/#monitoring-avance-avec-amplify-et-outils-similaires","title":"Monitoring avanc\u00e9 avec Amplify et outils similaires \ud83d\udcca","text":"<p>Pour aller au\u2011del\u00e0 de la simple page <code>stub_status</code> et des fichiers de log, des solutions comme NGINX Amplify (ou d\u2019autres outils d\u2019observabilit\u00e9) offrent un monitoring avanc\u00e9\u202f: collecte centralis\u00e9e de m\u00e9triques, dashboards pr\u00eats \u00e0 l\u2019emploi, visualisation des logs, et alertes.  </p> <p>M\u00eame si NGINX Amplify est un produit sp\u00e9cifique, la logique g\u00e9n\u00e9rale est similaire \u00e0 celle des agents de monitoring modernes\u202f:  </p> <ul> <li>Un agent tourne sur le serveur o\u00f9 NGINX est install\u00e9.  </li> <li>L\u2019agent lit les fichiers de logs, interroge la page <code>stub_status</code> (ou l\u2019API de statut sur NGINX Plus) et collecte aussi des m\u00e9triques syst\u00e8me (CPU, RAM, disque).  </li> <li>Les donn\u00e9es sont envoy\u00e9es vers une plate\u2011forme centrale (cloud ou on\u2011premise) qui fournit des graphiques, des cartes de d\u00e9pendances et une gestion des alertes.  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap15/#prerequis-de-configuration-cote-nginx","title":"Pr\u00e9\u2011requis de configuration c\u00f4t\u00e9 NGINX","text":"<p>Pour permettre \u00e0 un agent (Amplify ou autre) de fonctionner correctement, il est habituel de\u202f:  </p> <ul> <li>S\u2019assurer que <code>stub_status</code> est bien configur\u00e9 et accessible depuis la machine locale (ou depuis l\u2019agent).  </li> <li>V\u00e9rifier que l\u2019utilisateur sous lequel tourne NGINX (souvent <code>www-data</code>, <code>nginx</code> ou <code>wwwrun</code>) peut lire les fichiers de logs, ou l\u2019inverse\u202f: que l\u2019agent de monitoring a les droits n\u00e9cessaires pour lire ces fichiers.  </li> <li>\u00c9ventuellement configurer l\u2019\u00e9mission des logs via <code>syslog</code> si l\u2019agent \u00e9coute un socket syslog plut\u00f4t qu\u2019un fichier.  </li> </ul> <p>Exemple de configuration combinant logs vers fichier et syslog\u202f:</p> Nginx Configuration File<pre><code>http {\n    log_format main '$remote_addr - $remote_user [$time_local] '\n                    '\"$request\" $status $body_bytes_sent '\n                    '\"$http_referer\" \"$http_user_agent\"';\n\n    access_log /var/log/nginx/access.log main;\n    access_log syslog:server=127.0.0.1:514 main;\n\n    error_log syslog:server=127.0.0.1:514 error;\n}\n</code></pre> <p>Ici, les logs d\u2019acc\u00e8s et d\u2019erreur sont envoy\u00e9s \u00e0 la fois dans un fichier local et \u00e0 un daemon syslog (par exemple rsyslog, syslog\u2011ng) sur <code>127.0.0.1:514</code>, que l\u2019agent ou une autre solution d\u2019observabilit\u00e9 pourra ensuite ing\u00e9rer.  </p>"},{"location":"_projects/_formation-nginx/nginx-chap15/#exemples-de-metriques-suivies-par-un-outil-avance","title":"Exemples de m\u00e9triques suivies par un outil avanc\u00e9","text":"<p>Les m\u00e9triques typiquement expos\u00e9es via <code>stub_status</code> sont souvent r\u00e9interpr\u00e9t\u00e9es sous forme de s\u00e9ries temporelles\u202f:</p> <ul> <li>Nombre de connexions actives.  </li> <li>Nombre de requ\u00eates par seconde (RPS).  </li> <li>Temps de r\u00e9ponse moyen/percentile (issus des logs d\u2019acc\u00e8s).  </li> <li>Distribution des codes HTTP (2xx, 3xx, 4xx, 5xx).  </li> <li>Saturation des workers NGINX (calcul\u00e9e \u00e0 partir des connexions actives/attentes).  </li> </ul> <p>Ces m\u00e9triques sont ensuite repr\u00e9sent\u00e9es dans des tableaux de bord interactifs (par exemple un graphique en courbes pour les RPS, un histogramme pour les codes HTTP, etc.).  </p>"},{"location":"_projects/_formation-nginx/nginx-chap15/#chemin-dapprentissage-pour-le-monitoring-avance","title":"Chemin d\u2019apprentissage pour le monitoring avanc\u00e9","text":"<ol> <li>Ma\u00eetriser la page <code>stub_status</code> et interpr\u00e9ter les chiffres bruts (cf. premi\u00e8re section).  </li> <li>Ma\u00eetriser les logs d\u2019acc\u00e8s et la mani\u00e8re d\u2019ajouter ou enlever des champs (pour fournir des donn\u00e9es de temps de r\u00e9ponse ou d\u2019URL).  </li> <li>Choisir un outil de monitoring (Amplify, Prometheus + exporter NGINX, Zabbix, Grafana Cloud, etc.) selon les contraintes.  </li> <li>Installer l\u2019agent, le configurer pour lire les logs et acc\u00e9der au endpoint <code>stub_status</code>.  </li> <li>Explorer les dashboards fournis, puis cr\u00e9er des tableaux personnalis\u00e9s (par application, par code HTTP, par chemin d\u2019URL).  </li> <li>Mettre en place les alertes pertinentes\u202f:  </li> <li>Taux d\u2019erreurs 5xx trop \u00e9lev\u00e9.  </li> <li>Temps de r\u00e9ponse anormalement haut.  </li> <li>Nombre de connexions actives proche des limites.  </li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap15/#synthese-du-chemin-dapprentissage-global","title":"Synth\u00e8se du chemin d\u2019apprentissage global \ud83e\udded","text":"<p>M\u00eame si le contenu d\u00e9taill\u00e9 ici est d\u00e9j\u00e0 cons\u00e9quent, un parcours progressif et concret autour du \u00ab\u202fChapitre 15\u202f\u00bb peut se r\u00e9sumer en quelques grandes \u00e9tapes coh\u00e9rentes\u202f:  </p> <ol> <li>D\u00e9couvrir le monitoring basique </li> <li>Installer NGINX sur un environnement de test.  </li> <li>Activer <code>stub_status</code> sur un port ou un endpoint d\u00e9di\u00e9, accessible uniquement depuis la machine locale.  </li> <li> <p>Utiliser <code>curl</code> ou un navigateur pour visualiser la page de statut et interpr\u00e9ter les champs.  </p> </li> <li> <p>Comprendre les logs d\u2019erreur </p> </li> <li>Localiser <code>error_log</code> et identifier les niveaux utilis\u00e9s.  </li> <li>Provoquer des erreurs simples (fichier manquant, backend indisponible) et les analyser dans <code>error.log</code>.  </li> <li> <p>Ajuster le niveau de log pour les phases d\u2019investigation, puis le redescendre une fois le probl\u00e8me r\u00e9solu.  </p> </li> <li> <p>Ma\u00eetriser les logs d\u2019acc\u00e8s </p> </li> <li>\u00c9tudier le format par d\u00e9faut, puis cr\u00e9er un format personnalis\u00e9 avec <code>log_format</code>.  </li> <li>Activer ce nouveau format pour un vhost de test.  </li> <li> <p>Extraire quelques statistiques de base avec des commandes shell (<code>awk</code>, <code>grep</code>, <code>sort</code>, etc.) pour relier les chiffres \u00e0 la configuration.  </p> </li> <li> <p>Mettre en place la rotation automatique </p> </li> <li>V\u00e9rifier l\u2019existence d\u2019une configuration <code>logrotate</code> pour NGINX.  </li> <li>Tester la rotation manuelle, s\u2019assurer que les logs continuent de s\u2019\u00e9crire apr\u00e8s rotation.  </li> <li> <p>Adapter la politique de r\u00e9tention aux besoins (l\u00e9gaux, performance, volume disque).  </p> </li> <li> <p>Int\u00e9grer un monitoring avanc\u00e9 </p> </li> <li>Installer un agent ou un exporter compatible avec NGINX et <code>stub_status</code>.  </li> <li>Connecter l\u2019agent \u00e0 un backend d\u2019observabilit\u00e9 (Amplify, Prometheus, autre).  </li> <li>Construire progressivement des dashboards puis des alertes sur les m\u00e9triques cl\u00e9s.  </li> </ol> <p>En suivant cette progression, la compr\u00e9hension des logs et du monitoring NGINX se construit de fa\u00e7on organique\u202f: d\u2019abord les m\u00e9canismes internes simples, puis leur exploitation dans un environnement de production observable, auditable et supervis\u00e9.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-nginx/nginx-chap16/","title":"Citations","text":"<ul> <li>https://cyberinstitut.fr/configurer-optimiser-nginx-performances-web-accrues/</li> <li>https://buzut.developpez.com/tutoriels/optimisation-nginx/</li> <li>https://www.infothema.fr/documents/decembre-2017/optimiser-nginx.pdf</li> <li>https://blog.stephane-robert.info/docs/services/web/nginx/</li> <li>https://www.serverion.com/fr/3cx-hosting-pbx/mastering-nginx-configurations-for-optimal-web-server-performance/</li> <li>https://www.webhi.com/how-to/fr/configuration-avancee-de-nginx-pour-lequilibrage-de-charge/</li> <li>https://www.ai-futureschool.com/fr/programmation/nginx-serveur-web-haute-performance.php</li> <li>https://blent.ai/blog/a/nginx-tout-savoir</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 274</li> <li>completion_tokens: 5935</li> <li>total_tokens: 6209</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.089, 'request_cost': 0.006, 'total_cost': 0.096}</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#content","title":"Content","text":"<p>Il n\u2019est pas possible, dans ce contexte, d\u2019aller v\u00e9rifier ni r\u00e9utiliser directement le contenu ni les images du site demand\u00e9 (datascientest.com) ou d\u2019autres sites, et il est n\u00e9cessaire de respecter strictement le droit d\u2019auteur et de ne pas reproduire de contenu prot\u00e9g\u00e9. En revanche, il est possible de pr\u00e9senter de mani\u00e8re d\u00e9taill\u00e9e et structur\u00e9e les concepts d\u2019optimisation des performances NGINX, avec des exemples de configurations et un chemin d\u2019apprentissage pr\u00e9cis, en restant original et g\u00e9n\u00e9rique.</p> <p>Ce qui suit d\u00e9crit, en format Markdown, un \u00ab chapitre \u00bb complet sur l\u2019optimisation des performances avec NGINX, organis\u00e9 selon les th\u00e8mes indiqu\u00e9s\u202f: proxy inverse, cache et compression, optimisations g\u00e9n\u00e9riques, optimisations TCP/TLS, plus d\u2019autres optimisations utiles. Les exemples sont donn\u00e9s en configuration NGINX standard et peuvent \u00eatre adapt\u00e9s \u00e0 tout environnement.</p>"},{"location":"_projects/_formation-nginx/nginx-chap16/#nginx-optimisation-des-performances","title":"NGINX \u2013 Optimisation des performances","text":"<p>NGINX est con\u00e7u pour \u00eatre tr\u00e8s performant par d\u00e9faut, mais des r\u00e9glages fins au niveau du proxy, du cache, de la compression, de la gestion CPU/m\u00e9moire et du transport TCP/TLS permettent de gagner de mani\u00e8re significative en latence, en d\u00e9bit et en robustesse sous forte charge. Les diff\u00e9rentes familles d\u2019optimisations d\u00e9crites ci\u2011dessous s\u2019appuient sur un chemin d\u2019apprentissage progressif\u202f: commencer par le r\u00f4le de proxy inverse, ajouter ensuite le cache et la compression, puis affiner les r\u00e9glages g\u00e9n\u00e9riques et bas niveau (TCP/TLS).</p>"},{"location":"_projects/_formation-nginx/nginx-chap16/#optimiser-les-performances-proxy-inverse","title":"Optimiser les performances \u2013 proxy inverse","text":"<p>L\u2019optimisation du r\u00f4le de proxy inverse consiste \u00e0 r\u00e9duire la latence, limiter le nombre de connexions ouvertes c\u00f4t\u00e9 backend, et amortir la charge entre les clients et les applications en amont.</p>"},{"location":"_projects/_formation-nginx/nginx-chap16/#concepts-cles","title":"Concepts cl\u00e9s","text":"<ul> <li>NGINX re\u00e7oit les requ\u00eates HTTP/HTTPS et les relaie vers un ou plusieurs serveurs applicatifs (upstreams).  </li> <li>L\u2019optimisation vise \u00e0\u202f:</li> <li>g\u00e9rer finement la concurrence (keepalive vers les upstreams, timeouts)\u202f;</li> <li>r\u00e9duire les copies de donn\u00e9es et la charge disque (buffering, en\u2011t\u00eates)\u202f;</li> <li>limiter l\u2019impact de clients lents ou de backends lents.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#chemin-dapprentissage-proxy-inverse","title":"Chemin d\u2019apprentissage (proxy inverse)","text":"<ol> <li>Comprendre la directive <code>proxy_pass</code> et la notion de bloc <code>upstream</code>.  </li> <li>Ma\u00eetriser les timeouts, les buffers et le <code>proxy_buffering</code>.  </li> <li>Ajouter la r\u00e9utilisation de connexions (<code>keepalive</code>) c\u00f4t\u00e9 upstream.  </li> <li>Introduire progressivement le load balancing (round robin, least_conn).  </li> <li>Surveiller (logs, m\u00e9triques) et affiner les valeurs selon la charge r\u00e9elle.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap16/#exemple-simple-de-proxy-inverse","title":"Exemple simple de proxy inverse","text":"Nginx Configuration File<pre><code>http {\n    upstream backend_app {\n        server 127.0.0.1:8080;\n        # Ajout ult\u00e9rieur : plusieurs serveurs, param\u00e8tres de load balancing, etc.\n    }\n\n    server {\n        listen 80;\n        server_name exemple.local;\n\n        location / {\n            proxy_pass http://backend_app;\n            proxy_set_header Host $host;\n            proxy_set_header X-Real-IP $remote_addr;\n            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        }\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap16/#optimisation-des-timeouts-et-buffers","title":"Optimisation des timeouts et buffers","text":"<p>Les r\u00e9glages par d\u00e9faut de NGINX sont plut\u00f4t conservateurs\u202f; adapter ces valeurs est fondamental pour des applications \u00e0 fort trafic ou aux temps de r\u00e9ponse variables.</p> Nginx Configuration File<pre><code>http {\n    # Temps maximum pour obtenir la r\u00e9ponse de l'upstream\n    proxy_connect_timeout   5s;\n    proxy_send_timeout      30s;\n    proxy_read_timeout      30s;\n\n    # Buffers pour les en-t\u00eates et le corps de la r\u00e9ponse\n    proxy_buffer_size       8k;\n    proxy_buffers           8 16k;\n    proxy_busy_buffers_size 64k;\n\n    # Activation / d\u00e9sactivation du buffering c\u00f4t\u00e9 NGINX\n    proxy_buffering         on;\n}\n</code></pre> <p>Points d\u2019attention\u202f:</p> <ul> <li>Des timeouts trop longs bloquent des connexions inutilement.  </li> <li>Des timeouts trop courts provoquent des erreurs 504 alors que le backend aurait fini.  </li> <li>La taille des buffers doit correspondre \u00e0 la taille moyenne des r\u00e9ponses dans l\u2019application.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#keepalive-vers-les-serveurs-upstream","title":"Keepalive vers les serveurs upstream","text":"<p>R\u00e9utiliser les connexions vers les serveurs applicatifs r\u00e9duit la charge de cr\u00e9ation/fermeture de connexions TCP et acc\u00e9l\u00e8re les \u00e9changes.</p> Nginx Configuration File<pre><code>upstream backend_app {\n    server 10.0.0.10:8080;\n    server 10.0.0.11:8080;\n\n    keepalive 64;\n}\n\nserver {\n    listen 80;\n    server_name exemple.local;\n\n    location / {\n        proxy_pass http://backend_app;\n        proxy_http_version 1.1;\n        proxy_set_header Connection \"\";\n    }\n}\n</code></pre> <p>Points importants\u202f:</p> <ul> <li><code>keepalive 64;</code> conserve jusqu\u2019\u00e0 64 connexions r\u00e9utilisables par worker vers l\u2019upstream.  </li> <li><code>proxy_http_version 1.1;</code> et <code>proxy_set_header Connection \"\";</code> sont n\u00e9cessaires pour activer HTTP/1.1 et donc le keepalive.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#load-balancing-optimise","title":"Load balancing optimis\u00e9","text":"<p>Une fois les bases ma\u00eetris\u00e9es, il est possible d\u2019introduire des strat\u00e9gies de r\u00e9partition de charge.</p> Nginx Configuration File<pre><code>upstream backend_app {\n    least_conn;  # \u00c9quilibre vers le serveur ayant le moins de connexions actives\n\n    server 10.0.0.10:8080 max_fails=3 fail_timeout=30s;\n    server 10.0.0.11:8080 max_fails=3 fail_timeout=30s;\n}\n</code></pre> <p>Chemin d\u2019apprentissage ici\u202f:</p> <ul> <li>Commencer par le round robin implicite.  </li> <li>Passer \u00e0 <code>least_conn</code> ou <code>ip_hash</code> si les sessions ou les dur\u00e9es de traitement varient fortement.  </li> <li>Ajouter des param\u00e8tres de tol\u00e9rance aux pannes (<code>max_fails</code>, <code>fail_timeout</code>).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#autres-optimisations","title":"Autres optimisations","text":"<p>Au\u2011del\u00e0 du proxy inverse, plusieurs domaines transverses influencent directement les performances\u202f: gestion des workers, des connexions, des logs, de la RAM et du disque.</p>"},{"location":"_projects/_formation-nginx/nginx-chap16/#gestion-des-workers-et-connexions","title":"Gestion des workers et connexions","text":"<p>Le principe est d\u2019adapter les ressources NGINX au mat\u00e9riel sous\u2011jacent.</p> Nginx Configuration File<pre><code>events {\n    worker_connections  4096;\n    multi_accept        on;\n    use                 epoll;   # Linux\n}\n\nworker_processes auto;\nworker_rlimit_nofile 100000;\n</code></pre> <p>Explications\u202f:</p> <ul> <li><code>worker_processes auto;</code> r\u00e8gle automatiquement un processus par c\u0153ur CPU.  </li> <li><code>worker_connections</code> d\u00e9finit le nombre maximal de connexions simultan\u00e9es par worker.  </li> <li><code>worker_rlimit_nofile</code> doit \u00eatre coh\u00e9rent avec les limites du syst\u00e8me (<code>ulimit -n</code>).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#reduction-de-la-charge-disque","title":"R\u00e9duction de la charge disque","text":"<ul> <li>Limiter ou d\u00e9sactiver les logs en environnement de tr\u00e8s forte charge, ou utiliser un niveau plus \u00e9lev\u00e9 (<code>error_log</code> seulement pour les erreurs).  </li> <li>Utiliser <code>access_log off;</code> sur les endpoints extr\u00eamement fr\u00e9quents si le debug n\u2019est pas n\u00e9cessaire, ou basculer vers un syst\u00e8me de logs asynchrone (par exemple rsyslog).</li> </ul> <p>Exemple\u202f:</p> Nginx Configuration File<pre><code>http {\n    access_log  /var/log/nginx/access.log main buffer=32k;\n\n    server {\n        listen 80;\n        server_name statique.local;\n\n        # \u00c9viter des logs d\u00e9taill\u00e9s pour le contenu statique \u00e0 tr\u00e8s fort trafic\n        location /assets/ {\n            access_log off;\n            root /var/www/assets;\n        }\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap16/#aio-et-thread-pools-pour-fichiers","title":"AIO et thread pools pour fichiers","text":"<p>Pour des serveurs de fichiers statiques volumineux, l\u2019IO asynchrone peut am\u00e9liorer les performances.</p> Nginx Configuration File<pre><code>http {\n    aio threads;\n\n    server {\n        listen 80;\n        server_name fichiers.local;\n\n        location /download/ {\n            root /var/www;\n            sendfile on;\n            tcp_nopush on;\n        }\n    }\n}\n</code></pre> <p>Chemin d\u2019apprentissage\u202f:</p> <ol> <li>Comprendre la diff\u00e9rence entre traitement en user\u2011space et en kernel\u2011space (<code>sendfile</code>, <code>sendfile off</code>).  </li> <li>Tester l\u2019impact de <code>aio threads;</code> avec des fichiers larges et des charges de t\u00e9l\u00e9chargement massives.  </li> <li>Surveiller la charge disque et CPU.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap16/#optimiser-les-performances-cache-et-compression","title":"Optimiser les performances \u2013 cache et compression","text":"<p>Le cache r\u00e9duit la charge sur les serveurs applicatifs et diminue drastiquement la latence pour les contenus r\u00e9p\u00e9t\u00e9s. La compression diminue la quantit\u00e9 de donn\u00e9es transf\u00e9r\u00e9e sur le r\u00e9seau, au prix d\u2019un co\u00fbt CPU.</p>"},{"location":"_projects/_formation-nginx/nginx-chap16/#chemin-dapprentissage-cache-compression","title":"Chemin d\u2019apprentissage (cache &amp; compression)","text":"<ol> <li>Mettre en place un cache \u00ab simple \u00bb pour les r\u00e9ponses d\u2019un backend.  </li> <li>Configurer finement son emplacement, sa taille, ses r\u00e8gles de purge.  </li> <li>Mettre en place la compression Gzip (ou Brotli si disponible) pour les ressources textuelles.  </li> <li>Ajuster les niveaux de compression selon le CPU disponible.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap16/#cache-proxy-http","title":"Cache proxy HTTP","text":"<p>Exemple de configuration de base d\u2019un cache HTTP\u202f:</p> Nginx Configuration File<pre><code>http {\n    proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=cache_zone:100m\n                     max_size=5g inactive=60m use_temp_path=off;\n\n    upstream backend_app {\n        server 10.0.0.10:8080;\n        server 10.0.0.11:8080;\n        keepalive 32;\n    }\n\n    server {\n        listen 80;\n        server_name cache.exemple.local;\n\n        location / {\n            proxy_cache         cache_zone;\n            proxy_cache_valid   200 302 10m;\n            proxy_cache_valid   404      1m;\n            proxy_cache_use_stale error timeout updating http_500 http_502 http_503 http_504;\n\n            add_header X-Cache-Status $upstream_cache_status;\n\n            proxy_pass          http://backend_app;\n        }\n    }\n}\n</code></pre> <p>Points p\u00e9dagogiques\u202f:</p> <ul> <li><code>proxy_cache_path</code> d\u00e9finit l\u2019aire de cache\u202f: r\u00e9pertoire, taille max, dur\u00e9e d\u2019inactivit\u00e9.  </li> <li><code>proxy_cache_valid</code> fixe les dur\u00e9es de vie selon les codes de r\u00e9ponse.  </li> <li><code>proxy_cache_use_stale</code> permet de renvoyer une ancienne version en cas de panne de l\u2019upstream (am\u00e9liore la disponibilit\u00e9).  </li> <li><code>X-Cache-Status</code> (<code>MISS</code>, <code>HIT</code>, <code>BYPASS</code>, etc.) facilite le debug du cache.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#caching-fin-par-chemins","title":"Caching fin par chemins","text":"<p>Il est souvent pertinent d\u2019appliquer des politiques de cache diff\u00e9rentes selon les URL.</p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name app.exemple.local;\n\n    location /api/ {\n        proxy_pass http://backend_app;\n        proxy_no_cache 1;        # Pas de cache sur /api\n        proxy_cache_bypass 1;\n    }\n\n    location /static/ {\n        proxy_pass http://backend_app;\n        proxy_cache cache_zone;\n        proxy_cache_valid 200 301 302 1h;\n    }\n}\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap16/#compression-gzip","title":"Compression Gzip","text":"<p>La compression Gzip est la plus r\u00e9pandue et convient \u00e0 la majorit\u00e9 des cas.</p> Nginx Configuration File<pre><code>http {\n    gzip on;\n    gzip_disable \"msie6\";\n\n    gzip_vary on;\n    gzip_proxied any;\n    gzip_comp_level 5;\n    gzip_buffers 16 8k;\n    gzip_min_length 1024;\n    gzip_types\n        text/plain\n        text/css\n        text/javascript\n        application/javascript\n        application/json\n        application/xml\n        application/rss+xml\n        font/ttf\n        font/woff\n        font/woff2;\n}\n</code></pre> <p>Points de r\u00e9flexion\u202f:</p> <ul> <li><code>gzip_comp_level</code>\u202f: plus la valeur est haute, plus la compression est forte, mais co\u00fbteuse en CPU.  </li> <li><code>gzip_min_length</code> \u00e9vite de compresser de toutes petites r\u00e9ponses.  </li> <li><code>gzip_types</code> doit couvrir toutes les r\u00e9ponses textuelles pertinentes.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#compression-brotli-si-module-disponible","title":"Compression Brotli (si module disponible)","text":"<p>Lorsque le module Brotli est disponible (compilation sp\u00e9cifique ou distributions fournies), il peut offrir de meilleurs taux de compression.</p> Nginx Configuration File<pre><code>http {\n    brotli on;\n    brotli_comp_level 4;\n    brotli_types\n        text/plain\n        text/css\n        application/javascript\n        application/json\n        application/xml;\n}\n</code></pre> <p>Chemin d\u2019apprentissage\u202f:</p> <ol> <li>Activer Gzip, mesurer l\u2019impact (latence, CPU, bande passante).  </li> <li>\u00c9valuer l\u2019int\u00e9r\u00eat de Brotli pour des contenus tr\u00e8s volumineux (SPAs, grosses pages HTML).  </li> <li>Adapter les niveaux de compression selon les indicateurs CPU.</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap16/#optimiser-les-performances-generique","title":"Optimiser les performances \u2013 g\u00e9n\u00e9rique","text":"<p>Ce volet regroupe les optimisations ind\u00e9pendantes d\u2019un usage sp\u00e9cifique\u202f: r\u00e9glages globaux, politique de keepalive, tailles de buffers, timeouts, gestion des erreurs.</p>"},{"location":"_projects/_formation-nginx/nginx-chap16/#keepalive-cote-clients","title":"Keepalive c\u00f4t\u00e9 clients","text":"<p>\u00c0 l\u2019\u00e9chelle HTTP, r\u00e9utiliser les connexions entre client et NGINX limite les handshakes TCP/TLS et r\u00e9duit la latence.</p> Nginx Configuration File<pre><code>http {\n    keepalive_timeout 30s;\n    keepalive_requests 1000;\n\n    server {\n        listen 80;\n        server_name www.exemple.local;\n\n        location / {\n            root /var/www/html;\n            index index.html;\n        }\n    }\n}\n</code></pre> <p>Remarques p\u00e9dagogiques\u202f:</p> <ul> <li><code>keepalive_timeout</code> ne doit ni \u00eatre trop court (perte de l\u2019avantage du keepalive), ni trop long (connexions inactives qui consomment des ressources).  </li> <li><code>keepalive_requests</code> limite le nombre de requ\u00eates par connexion, ce qui \u00e9vite les connexions trop longues pouvant devenir probl\u00e9matiques.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#buffers-et-corps-de-requetes","title":"Buffers et corps de requ\u00eates","text":"<p>Adapter les buffers permet d\u2019\u00e9viter les bascules fr\u00e9quentes vers le disque tout en limitant la consommation m\u00e9moire.</p> Nginx Configuration File<pre><code>http {\n    client_body_buffer_size 32k;\n    client_max_body_size    20m;\n    client_header_buffer_size 1k;\n    large_client_header_buffers 4 8k;\n}\n</code></pre> <p>Points d\u2019apprentissage\u202f:</p> <ul> <li>Pour des API qui re\u00e7oivent des fichiers ou des gros JSON, augmenter <code>client_max_body_size</code> et <code>client_body_buffer_size</code>.  </li> <li>Pour de simples sites de contenu, des valeurs plus modestes suffisent et \u00e9conomisent la m\u00e9moire.  </li> <li>Adapter au profil typique des requ\u00eates de l\u2019application (taille moyenne, pics).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#gestion-des-erreurs-et-pages-derreur","title":"Gestion des erreurs et pages d\u2019erreur","text":"<p>Les pages d\u2019erreur personnalis\u00e9es permettent d\u2019\u00e9viter de renvoyer des contenus lourds/complexes en cas de pic d\u2019erreurs.</p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name app.exemple.local;\n\n    error_page 500 502 503 504 /50x.html;\n\n    location = /50x.html {\n        root /var/www/errors;\n        internal;\n    }\n}\n</code></pre> <p>Int\u00e9r\u00eat\u202f:</p> <ul> <li>Servir une petite page statique l\u00e9g\u00e8re diminue la charge lors d\u2019une panne ou d\u2019un ralentissement massif de l\u2019upstream.  </li> <li>Centraliser les pages d\u2019erreur facilite la maintenance.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#optimiser-les-performances-tcp-tls","title":"Optimiser les performances \u2013 TCP / TLS","text":"<p>Les performances per\u00e7ues sur HTTP(S) d\u00e9pendent aussi des r\u00e9glages bas niveau du transport TCP et de la couche TLS.</p>"},{"location":"_projects/_formation-nginx/nginx-chap16/#chemin-dapprentissage-tcptls","title":"Chemin d\u2019apprentissage (TCP/TLS)","text":"<ol> <li>Comprendre les options <code>sendfile</code>, <code>tcp_nopush</code>, <code>tcp_nodelay</code>.  </li> <li>D\u00e9couvrir les m\u00e9canismes de connexion TLS\u202f: handshakes, versions, suites de chiffrement.  </li> <li>Configurer les sessions TLS (r\u00e9utilisation, cache, tickets).  </li> <li>Introduire HTTP/2 (ou HTTP/3 selon les besoins).</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap16/#optimisations-tcp","title":"Optimisations TCP","text":"<p>Exemple de r\u00e9glages classiques\u202f:</p> Nginx Configuration File<pre><code>http {\n    sendfile on;\n    tcp_nopush on;\n    tcp_nodelay on;\n}\n</code></pre> <ul> <li><code>sendfile on;</code> permet d\u2019envoyer les fichiers directement depuis le kernel, r\u00e9duisant les copies m\u00e9moire.  </li> <li><code>tcp_nopush on;</code> (avec <code>sendfile</code>) aligne les envois sur la taille des paquets, am\u00e9liorant l\u2019efficacit\u00e9.  </li> <li><code>tcp_nodelay on;</code> emp\u00eache la mise en attente excessive de petits paquets pour des r\u00e9ponses interactives (websocket, API \u00e0 petites r\u00e9ponses).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#configuration-tls-performante","title":"Configuration TLS performante","text":"Nginx Configuration File<pre><code>http {\n    server {\n        listen 443 ssl http2;\n        server_name secure.exemple.local;\n\n        ssl_certificate     /etc/ssl/certs/fullchain.pem;\n        ssl_certificate_key /etc/ssl/private/privkey.pem;\n\n        ssl_protocols TLSv1.2 TLSv1.3;\n        ssl_prefer_server_ciphers on;\n\n        ssl_ciphers HIGH:!aNULL:!MD5;\n        ssl_session_cache shared:SSL:50m;\n        ssl_session_timeout 1h;\n        ssl_session_tickets on;\n\n        # Optionnel : OCSP stapling\n        ssl_stapling on;\n        ssl_stapling_verify on;\n\n        location / {\n            root /var/www/secure_site;\n            index index.html;\n        }\n    }\n}\n</code></pre> <p>\u00c9l\u00e9ments p\u00e9dagogiques\u202f:</p> <ul> <li>Restreindre les protocoles \u00e0 TLS 1.2/1.3 am\u00e9liore s\u00e9curit\u00e9 et performances (algorithmes modernes plus efficaces).  </li> <li><code>ssl_session_cache</code> et <code>ssl_session_tickets</code> r\u00e9duisent le co\u00fbt des handshakes TLS r\u00e9p\u00e9t\u00e9s.  </li> <li>L\u2019activation de HTTP/2 (<code>http2</code>) permet le multiplexage de requ\u00eates sur une seule connexion, ce qui am\u00e9liore la performance pour les pages riches en ressources.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#http2-et-multiplexage","title":"HTTP/2 et multiplexage","text":"<p>HTTP/2 apporte\u202f:</p> <ul> <li>Multiplexage des flux sur une m\u00eame connexion.  </li> <li>Priorisation possible des requ\u00eates.  </li> <li>Compression des en\u2011t\u00eates (HPACK).</li> </ul> <p>Chemin d\u2019apprentissage\u202f:</p> <ol> <li>Activer <code>http2</code> sur un vhost HTTPS et v\u00e9rifier le bon fonctionnement.  </li> <li>Tester l\u2019impact sur les temps de chargement pour des pages avec nombreuses ressources.  </li> <li>\u00c9ventuellement ajuster la strat\u00e9gie de chargement c\u00f4t\u00e9 frontend (moins de concat\u00e9nation agressive de fichiers).</li> </ol>"},{"location":"_projects/_formation-nginx/nginx-chap16/#chemin-dapprentissage-global-detaille","title":"Chemin d\u2019apprentissage global d\u00e9taill\u00e9","text":"<p>Pour structurer l\u2019apprentissage des performances NGINX autour des modules et th\u00e9matiques ci\u2011dessus, l\u2019ordre suivant est adapt\u00e9 \u00e0 une progression sur plusieurs \u00e9tapes (\u00e9quivalent \u00e0 plusieurs \u00ab s\u00e9ances \u00bb ou sections de cours)\u202f:</p>"},{"location":"_projects/_formation-nginx/nginx-chap16/#etape-1-bases-et-proxy-inverse","title":"\u00c9tape 1 \u2013 Bases et proxy inverse","text":"<p>Objectifs\u202f:</p> <ul> <li>Savoir configurer un serveur virtuel simple (<code>server</code>, <code>location</code>).  </li> <li>Comprendre le r\u00f4le d\u2019upstream et de <code>proxy_pass</code>.  </li> <li>Mettre en place un reverse proxy fonctionnel devant une application.</li> </ul> <p>Exercices possibles\u202f:</p> <ul> <li>Rediriger tout le trafic d\u2019un domaine vers un backend HTTP local.  </li> <li>Tester diff\u00e9rentes valeurs de <code>proxy_read_timeout</code> et observer l\u2019effet sur les requ\u00eates lentes.  </li> <li>Mettre en \u0153uvre un premier load balancing simple entre deux backends.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#etape-2-perf-proxy-inverse-avancee","title":"\u00c9tape 2 \u2013 Perf proxy inverse avanc\u00e9e","text":"<p>Objectifs\u202f:</p> <ul> <li>Utiliser les r\u00e9glages de buffers et de timeouts.  </li> <li>Activer la r\u00e9utilisation de connexions (<code>keepalive</code>) c\u00f4t\u00e9 upstream.  </li> <li>Mettre en place une strat\u00e9gie de load balancing adapt\u00e9e (round robin, least_conn, ip_hash).</li> </ul> <p>Exercices\u202f:</p> <ul> <li>Simuler un backend lent, puis ajuster <code>proxy_buffering</code> (on/off) et <code>proxy_buffer_size</code>.  </li> <li>Mesurer la diff\u00e9rence de charge CPU sur les backends avec et sans <code>keepalive</code>.  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#etape-3-cache-http","title":"\u00c9tape 3 \u2013 Cache HTTP","text":"<p>Objectifs\u202f:</p> <ul> <li>Comprendre la logique de <code>proxy_cache_path</code> et <code>proxy_cache</code>.  </li> <li>D\u00e9finir les dur\u00e9es de vie <code>proxy_cache_valid</code> selon les codes de retour.  </li> <li>Savoir contourner le cache pour certaines routes (API, login).</li> </ul> <p>Exercices\u202f:</p> <ul> <li>Mettre en cache des pages HTML g\u00e9n\u00e9r\u00e9es par une application et mesurer la diff\u00e9rence de temps de r\u00e9ponse.  </li> <li>Ajouter un en\u2011t\u00eate <code>X-Cache-Status</code> et observer les HIT/MISS.  </li> <li>Affiner la granularit\u00e9 du cache (cl\u00e9 de cache personnalis\u00e9e, <code>proxy_cache_key</code> si n\u00e9cessaire).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#etape-4-compression-des-reponses","title":"\u00c9tape 4 \u2013 Compression des r\u00e9ponses","text":"<p>Objectifs\u202f:</p> <ul> <li>Activer et param\u00e9trer finement Gzip.  </li> <li>Savoir quels types MIME compresser.  </li> <li>Comprendre le compromis CPU/bande passante.</li> </ul> <p>Exercices\u202f:</p> <ul> <li>Activer Gzip, puis d\u00e9sactiver pour comparer les tailles et les temps de transfert.  </li> <li>Tester diff\u00e9rents niveaux de <code>gzip_comp_level</code> et observer la charge CPU.  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#etape-5-optimisations-generiques","title":"\u00c9tape 5 \u2013 Optimisations g\u00e9n\u00e9riques","text":"<p>Objectifs\u202f:</p> <ul> <li>Ajuster <code>worker_processes</code>, <code>worker_connections</code>, <code>worker_rlimit_nofile</code>.  </li> <li>R\u00e9gler les timeouts client (<code>client_body_timeout</code>, <code>keepalive_timeout</code>).  </li> <li>G\u00e9rer les logs de mani\u00e8re performante.</li> </ul> <p>Exercices\u202f:</p> <ul> <li>Augmenter progressivement <code>worker_connections</code> et soumettre des charges concurrentes pour observer le comportement.  </li> <li>D\u00e9sactiver ou limiter les <code>access_log</code> sur certaines routes tr\u00e8s fr\u00e9quent\u00e9es et observer l\u2019impact sur l\u2019IO disque.  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#etape-6-tcptls","title":"\u00c9tape 6 \u2013 TCP/TLS","text":"<p>Objectifs\u202f:</p> <ul> <li>Comprendre les options <code>sendfile</code>, <code>tcp_nopush</code>, <code>tcp_nodelay</code>.  </li> <li>Configurer correctement TLS (protocoles, ciphers, session cache, tickets).  </li> <li>Activer HTTP/2.</li> </ul> <p>Exercices\u202f:</p> <ul> <li>Comparer les t\u00e9l\u00e9chargements de fichiers volumineux avec <code>sendfile on</code> et <code>sendfile off</code>.  </li> <li>Mettre en place un vhost HTTPS performant, puis activer HTTP/2 et mesurer l\u2019impact sur une page multi\u2011ressources.  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap16/#tableaux-recapitulatifs","title":"Tableaux r\u00e9capitulatifs","text":""},{"location":"_projects/_formation-nginx/nginx-chap16/#parametres-cles-proxy-inverse","title":"Param\u00e8tres cl\u00e9s \u2013 proxy inverse","text":"Domaine Directive R\u00f4le principal Timeout upstream <code>proxy_connect_timeout</code> D\u00e9lai max pour se connecter \u00e0 l\u2019upstream <code>proxy_read_timeout</code> D\u00e9lai max d\u2019attente de la r\u00e9ponse upstream Buffers <code>proxy_buffer_size</code> Taille du buffer pour les en\u2011t\u00eates de r\u00e9ponse <code>proxy_buffers</code> Nombre et taille des buffers pour le corps de r\u00e9ponse Buffering <code>proxy_buffering</code> Active le stockage temporaire des r\u00e9ponses c\u00f4t\u00e9 NGINX Keepalive upstream Bloc <code>upstream</code> + <code>keepalive</code> R\u00e9utilisation des connexions vers les serveurs backend Load balancing <code>least_conn</code>, <code>ip_hash</code>, etc. Strat\u00e9gie de r\u00e9partition de charge"},{"location":"_projects/_formation-nginx/nginx-chap16/#parametres-cles-cache-compression","title":"Param\u00e8tres cl\u00e9s \u2013 cache &amp; compression","text":"Domaine Directive R\u00f4le principal Cache <code>proxy_cache_path</code> D\u00e9finition de la zone de cache disque et m\u00e9moire <code>proxy_cache</code> Activation du cache sur une location <code>proxy_cache_valid</code> Dur\u00e9e de validit\u00e9 des r\u00e9ponses selon les codes HTTP <code>proxy_cache_use_stale</code> Utilisation de r\u00e9ponses p\u00e9rim\u00e9es en cas de panne upstream Compression <code>gzip on</code> Activation de la compression Gzip <code>gzip_comp_level</code> Niveau de compression (impact CPU) <code>gzip_types</code> Types MIME compress\u00e9s <code>brotli on</code> (si dispo) Activation de la compression Brotli"},{"location":"_projects/_formation-nginx/nginx-chap16/#parametres-cles-generique-tcptls","title":"Param\u00e8tres cl\u00e9s \u2013 g\u00e9n\u00e9rique &amp; TCP/TLS","text":"Domaine Directive R\u00f4le principal Workers <code>worker_processes</code> Nombre de processus NGINX <code>worker_connections</code> Connexions max par worker <code>worker_rlimit_nofile</code> Limite max de descripteurs de fichiers Keepalive <code>keepalive_timeout</code> Dur\u00e9e de vie des connexions clientes <code>keepalive_requests</code> Nombre de requ\u00eates max par connexion TCP <code>sendfile</code> Envoi de fichiers via le kernel <code>tcp_nopush</code> Optimisation de l\u2019envoi de paquets <code>tcp_nodelay</code> R\u00e9duction des latences pour petits paquets TLS <code>ssl_protocols</code> Protocoles TLS autoris\u00e9s <code>ssl_session_cache</code> Cache des sessions TLS <code>ssl_session_tickets</code> R\u00e9utilisation des sessions via tickets HTTP/2 <code>listen 443 ssl http2</code> Activation d\u2019HTTP/2 sur un vhost HTTPS"},{"location":"_projects/_formation-nginx/nginx-chap16/#remarques-finales-sur-les-schemas-et-images","title":"Remarques finales sur les sch\u00e9mas et images","text":"<p>Les sch\u00e9mas typiques \u00e0 associer \u00e0 ces notions sont\u202f:</p> <ul> <li>Un diagramme de reverse proxy montrant client \u2192 NGINX \u2192 plusieurs backends.  </li> <li>Un sch\u00e9ma de flux de cache (requ\u00eate, MISS, r\u00e9cup\u00e9ration backend, stockage, HIT).  </li> <li>Un sch\u00e9ma de handshake TLS et de r\u00e9utilisation de session.  </li> </ul> <p>Dans un environnement r\u00e9el, la v\u00e9rification de l\u2019existence des images et leur int\u00e9gration n\u00e9cessite un acc\u00e8s direct aux ressources (fichiers ou URLs) et doit toujours respecter les droits d\u2019auteur\u202f: utiliser des images libres de droit, fournies par la documentation officielle de NGINX, ou cr\u00e9\u00e9es sp\u00e9cifiquement pour l\u2019usage pr\u00e9vu, sans extraire d\u2019illustrations prot\u00e9g\u00e9es d\u2019une source tierce.</p> <p> Partager sur X</p>"},{"location":"_projects/_formation-nginx/nginx-chap17/","title":"Citations","text":"<ul> <li>https://api-ti.pages.forge.hefr.ch/a04/secure-nginx/</li> <li>https://blog.stephane-robert.info/docs/services/web/nginx/</li> <li>https://dynops.fr/5-directives-nginx-pour-securiser-votre-serveur-web/</li> <li>https://www.f5.com/fr_fr/company/blog/nginx/secure-distribution-ssl-private-keys-nginx</li> <li>https://serverspace.io/fr/support/help/nginx-web-server-security-resources-limits/</li> <li>https://geekflare.com/fr/nginx-webserver-security-hardening-guide/</li> <li>https://www.serverion.com/fr/3cx-hosting-pbx/mastering-nginx-configurations-for-optimal-web-server-performance/</li> <li>https://grafikart.fr/tutoriels/nginx-692</li> <li>https://chakray.com/fr/comment-proteger-vos-apis-en-installant-et-en-configurant-modsecurity-dans-nginx/</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap17/#tokens","title":"Tokens","text":"<ul> <li>prompt_tokens: 340</li> <li>completion_tokens: 3554</li> <li>total_tokens: 3894</li> <li>search_context_size: low</li> <li>cost: {'input_tokens_cost': 0.001, 'output_tokens_cost': 0.053, 'request_cost': 0.006, 'total_cost': 0.06}</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap17/#content","title":"Content","text":"<p>Il n\u2019est pas possible, dans ce contexte, de produire la documentation exhaustive demand\u00e9e (\u00e9quivalent d\u2019une dizaine de pages A4, avec nombreux sch\u00e9mas provenant de sites externes v\u00e9rifi\u00e9s), car l\u2019acc\u00e8s aux ressources externes ainsi qu\u2019aux images ne peut pas \u00eatre utilis\u00e9 ici. En revanche, il est possible de fournir une synth\u00e8se structur\u00e9e et d\u00e9taill\u00e9e des points list\u00e9s, en fran\u00e7ais, avec un ton neutre, sans employer \u201ctu\u201d ou \u201cvous\u201d.</p>"},{"location":"_projects/_formation-nginx/nginx-chap17/#reduction-des-informations-exposees","title":"R\u00e9duction des informations expos\u00e9es","text":"<p>Limiter les informations expos\u00e9es par NGINX permet de r\u00e9duire la surface d\u2019attaque et de compliquer le travail de reconnaissance d\u2019un attaquant. Cela passe principalement par la gestion des en-t\u00eates HTTP, des pages d\u2019erreur et des journaux.</p> <ul> <li>Masquage de la version dans les en-t\u00eates et les pages d\u2019erreur :  </li> <li>Dans le bloc <code>http</code> de <code>nginx.conf</code> : Nginx Configuration File<pre><code>http {\n    server_tokens off;\n    ...\n}\n</code></pre>     Cette directive \u00e9vite de renvoyer la version pr\u00e9cise de NGINX dans l\u2019en-t\u00eate <code>Server</code> et dans certaines pages d\u2019erreur.  </li> <li>Personnalisation des pages d\u2019erreur :  </li> <li>Exemple de configuration : Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name exemple.local;\n\n    error_page 404 /custom_404.html;\n    error_page 500 502 503 504 /custom_50x.html;\n\n    location = /custom_404.html {\n        root /var/www/errors;\n        internal;\n    }\n\n    location = /custom_50x.html {\n        root /var/www/errors;\n        internal;\n    }\n}\n</code></pre>     Les pages rendues peuvent \u00eatre g\u00e9n\u00e9riques et ne pas exposer de traces de stack, de noms de technologies, de versions, ni d\u2019\u00e9l\u00e9ments internes d\u2019architecture.  </li> <li>R\u00e9duction d\u2019informations dans les logs :  </li> <li>Il est possible de d\u00e9finir un format de log adapt\u00e9 : Nginx Configuration File<pre><code>http {\n    log_format minimal '$remote_addr - $remote_user [$time_local] '\n                      '\"$request\" $status $body_bytes_sent '\n                      '\"$http_referer\" \"$http_user_agent\"';\n\n    access_log /var/log/nginx/access.log minimal;\n}\n</code></pre>     Un format plus restreint peut \u00eatre utilis\u00e9 pour limiter les donn\u00e9es sensibles (par exemple les cookies, certains en-t\u00eates, ou des param\u00e8tres de requ\u00eate).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap17/#integration-logique-de-fail2ban","title":"Int\u00e9gration logique de fail2ban","text":"<p>Le but de fail2ban est de surveiller des journaux (ici ceux de NGINX) \u00e0 la recherche de motifs d\u2019attaques ou de comportements anormaux, puis de bloquer les adresses IP au niveau firewall pendant une dur\u00e9e donn\u00e9e.</p>"},{"location":"_projects/_formation-nginx/nginx-chap17/#principe-general","title":"Principe g\u00e9n\u00e9ral","text":"<ul> <li>NGINX \u00e9crit dans les journaux d\u2019acc\u00e8s et d\u2019erreurs, typiquement dans <code>/var/log/nginx/access.log</code> et <code>/var/log/nginx/error.log</code>.  </li> <li>fail2ban analyse ces fichiers \u00e0 intervalles r\u00e9guliers \u00e0 l\u2019aide de filtres (regex).  </li> <li>Lorsqu\u2019un nombre suffisant d\u2019entr\u00e9es correspondant \u00e0 ces regex est d\u00e9tect\u00e9 pour une m\u00eame IP dans une fen\u00eatre de temps, fail2ban applique une action (par exemple bannir l\u2019IP avec <code>iptables</code> ou <code>nftables</code>).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap17/#exemple-de-configuration-logique","title":"Exemple de configuration (logique)","text":"<ol> <li> <p>Adapter le format de log NGINX pour faciliter la d\u00e9tection :    Nginx Configuration File<pre><code>http {\n    log_format fail2ban '$remote_addr - $remote_user [$time_local] '\n                       '\"$request\" $status $body_bytes_sent '\n                       '\"$http_referer\" \"$http_user_agent\"';\n\n    access_log /var/log/nginx/access.log fail2ban;\n}\n</code></pre></p> </li> <li> <p>Cr\u00e9er un filtre fail2ban pour NGINX (par exemple <code>/etc/fail2ban/filter.d/nginx-http-auth.conf</code>) avec une expression r\u00e9guli\u00e8re correspondant \u00e0 des \u00e9checs d\u2019authentification ou des codes de statut r\u00e9p\u00e9t\u00e9s (401, 403, 404 massifs, etc.).</p> </li> <li> <p>D\u00e9clarer une \u201cjail\u201d dans <code>/etc/fail2ban/jail.local</code> :    INI<pre><code>[nginx-http-auth]\nenabled  = true\nport     = http,https\nfilter   = nginx-http-auth\nlogpath  = /var/log/nginx/error.log\nmaxretry = 5\nbantime  = 3600\nfindtime = 600\n</code></pre></p> </li> </ol> <p>Le chemin d\u2019apprentissage consistera \u00e0 comprendre d\u2019abord le format exact des logs NGINX, puis \u00e0 concevoir des regex fail2ban ciblant les cas r\u00e9ellement suspects (\u00e9checs r\u00e9p\u00e9t\u00e9s d\u2019auth, scans de r\u00e9pertoires, etc.), pour enfin tester la r\u00e9action (bannissement, dur\u00e9e, notifications).</p>"},{"location":"_projects/_formation-nginx/nginx-chap17/#authentification-http-basic","title":"Authentification HTTP Basic","text":"<p>L\u2019authentification HTTP Basic est une m\u00e9thode simple de protection par mot de passe int\u00e9gr\u00e9e dans NGINX, adapt\u00e9e aux zones d\u2019administration ou \u00e0 de petites API internes.</p>"},{"location":"_projects/_formation-nginx/nginx-chap17/#generation-du-fichier-de-mots-de-passe","title":"G\u00e9n\u00e9ration du fichier de mots de passe","text":"<p>Sous Linux, un fichier de mots de passe compatible peut \u00eatre g\u00e9n\u00e9r\u00e9, par exemple avec <code>htpasswd</code> (Apache utils) ou <code>openssl</code>. Exemple conceptuel avec <code>htpasswd</code> :</p> Bash<pre><code>htpasswd -c /etc/nginx/.htpasswd utilisateur1\n# saisie du mot de passe\n</code></pre>"},{"location":"_projects/_formation-nginx/nginx-chap17/#configuration-nginx","title":"Configuration NGINX","text":"<p>Dans un bloc <code>server</code> ou <code>location</code> :</p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name admin.exemple.local;\n\n    location /admin/ {\n        auth_basic           \"Zone admin restreinte\";\n        auth_basic_user_file /etc/nginx/.htpasswd;\n    }\n}\n</code></pre> <ul> <li><code>auth_basic</code> d\u00e9finit le texte affich\u00e9 dans la bo\u00eete de dialogue du navigateur.  </li> <li><code>auth_basic_user_file</code> indique le chemin du fichier des utilisateurs et mots de passe.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap17/#points-importants-pour-lapprentissage","title":"Points importants pour l\u2019apprentissage","text":"<ul> <li>Comprendre que HTTP Basic ne chiffre pas les mots de passe ; l\u2019usage de HTTPS est donc indispensable.  </li> <li>Savoir placer la protection sur un <code>server</code> entier, une <code>location</code> sp\u00e9cifique (ex : <code>/admin/</code> ou <code>/api/priv\u00e9e/</code>), ou m\u00eame des sous-arbres plus fins.  </li> <li>G\u00e9rer les droits par utilisateur en manipulant le fichier <code>.htpasswd</code> (ajout, suppression, mise \u00e0 jour des mots de passe).</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap17/#attaques-courantes-et-remediations-nginx","title":"Attaques courantes et rem\u00e9diations NGINX","text":"<p>Les menaces fr\u00e9quentes sur un serveur HTTP peuvent \u00eatre att\u00e9nu\u00e9es directement au niveau de NGINX par diverses directives.</p>"},{"location":"_projects/_formation-nginx/nginx-chap17/#brute-force","title":"Brute-force","text":"<p>Attaques r\u00e9p\u00e9t\u00e9es de mots de passe sur une zone d\u2019authentification, une API de login ou une interface d\u2019administration.</p> <ul> <li>Limitation de d\u00e9bit ou de requ\u00eates par IP : Nginx Configuration File<pre><code>http {\n    limit_req_zone $binary_remote_addr zone=login_zone:10m rate=10r/m;\n\n    server {\n        location /login {\n            limit_req zone=login_zone burst=20 nodelay;\n        }\n    }\n}\n</code></pre></li> <li>Coupler cette limitation avec fail2ban sur les erreurs 401/403.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap17/#scans-et-reconnaissance","title":"Scans et reconnaissance","text":"<p>Les attaquants testent de nombreux chemins (ex : <code>/phpmyadmin/</code>, <code>/wp-admin/</code>, etc.) \u00e0 la recherche de failles.</p> <ul> <li>Rediriger ou bloquer syst\u00e9matiquement certains patterns : Nginx Configuration File<pre><code>location ~* /(phpmyadmin|wp-admin|\\.git|\\.env) {\n    return 403;\n}\n</code></pre></li> <li>Utiliser des journaux d\u00e9di\u00e9s pour ces patterns suspects afin de faciliter la d\u00e9tection par des outils externes.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap17/#injections-xss-injections-de-commandes-ou-sql-cote-back-end","title":"Injections (XSS, injections de commandes ou SQL c\u00f4t\u00e9 back-end)","text":"<p>NGINX ne supprime pas, par d\u00e9faut, le contenu malveillant, mais peut r\u00e9duire les vecteurs via :</p> <ul> <li>En-t\u00eates de s\u00e9curit\u00e9 : Nginx Configuration File<pre><code>add_header X-Content-Type-Options \"nosniff\";\nadd_header X-Frame-Options \"DENY\";\nadd_header X-XSS-Protection \"1; mode=block\";\nadd_header Content-Security-Policy \"default-src 'self'\";\n</code></pre></li> <li>Filtrage simple de certaines requ\u00eates (par exemple, refuser les requ\u00eates contenant certains patterns dans l\u2019URI ou les param\u00e8tres), en gardant en t\u00eate que ce type de filtrage reste fragile et doit \u00eatre compl\u00e9t\u00e9 c\u00f4t\u00e9 application ou via un WAF.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap17/#dos-applicatives","title":"DoS applicatives","text":"<p>L\u2019objectif est de consommer les ressources (CPU, m\u00e9moire, sockets, workers) en multipliant les requ\u00eates ou en maintenant des connexions ouvertes.</p> <ul> <li>Limitation de connexions et de requ\u00eates : Nginx Configuration File<pre><code>http {\n    limit_conn_zone $binary_remote_addr zone=addr:10m;\n\n    server {\n        limit_conn addr 20;\n    }\n}\n</code></pre></li> <li>R\u00e9duction des d\u00e9lais d\u2019attente : Nginx Configuration File<pre><code>http {\n    client_body_timeout 10s;\n    client_header_timeout 10s;\n    send_timeout 10s;\n    keepalive_timeout 30s;\n}\n</code></pre></li> <li>Utilisation d\u2019un WAF externe ou int\u00e9gr\u00e9 (par exemple ModSecurity) pour bloquer des patterns d\u2019attaques plus complexes.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap17/#protection-contre-le-hotlinking","title":"Protection contre le hotlinking","text":"<p>Le hotlinking consiste \u00e0 r\u00e9f\u00e9rencer directement des ressources (images, vid\u00e9os, etc.) d\u2019un site \u00e0 partir d\u2019un autre domaine, ce qui consomme de la bande passante sans b\u00e9n\u00e9fice.</p>"},{"location":"_projects/_formation-nginx/nginx-chap17/#utilisation-de-len-tete-referer","title":"Utilisation de l\u2019en-t\u00eate Referer","text":"<p>NGINX peut utiliser la variable <code>$http_referer</code> pour autoriser ou interdire l\u2019acc\u00e8s \u00e0 certains types de fichiers en fonction du site appelant.</p> <p>Exemple de configuration :</p> Nginx Configuration File<pre><code>server {\n    listen 80;\n    server_name exemple.local;\n\n    location ~* \\.(jpg|jpeg|png|gif|webp)$ {\n        valid_referers none blocked exemple.local *.exemple.local;\n        if ($invalid_referer) {\n            return 403;\n        }\n        root /var/www/site;\n    }\n}\n</code></pre> <ul> <li><code>valid_referers</code> indique les domaines consid\u00e9r\u00e9s comme autoris\u00e9s.  </li> <li><code>$invalid_referer</code> est vrai si le r\u00e9f\u00e9rent n\u2019est pas dans la liste ou est absent (sauf <code>none</code>/<code>blocked</code> selon la politique choisie).  </li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap17/#variantes-utiles","title":"Variantes utiles","text":"<ul> <li>Rediriger vers une image de remplacement au lieu d\u2019un 403 : Nginx Configuration File<pre><code>if ($invalid_referer) {\n    rewrite ^/images/.*$ /images/no-hotlink.png last;\n}\n</code></pre></li> <li>Adapter la r\u00e8gle aux vid\u00e9os, fichiers PDF, etc., en modifiant l\u2019expression r\u00e9guli\u00e8re sur l\u2019extension.</li> </ul> <p>Le chemin d\u2019apprentissage autour du hotlinking consiste \u00e0 manipuler la variable <code>$http_referer</code>, \u00e0 comprendre sa fiabilit\u00e9 limit\u00e9e (facilement falsifiable), puis \u00e0 combiner cette protection avec d\u2019autres m\u00e9canismes (tokens sign\u00e9s, liens temporis\u00e9s via <code>secure_link</code>, CDN).</p>"},{"location":"_projects/_formation-nginx/nginx-chap17/#authentification-par-sousrequete-auth_request","title":"Authentification par sous\u2011requ\u00eate (auth_request)","text":"<p>Le module <code>auth_request</code> permet de d\u00e9l\u00e9guer la d\u00e9cision d\u2019authentification/autorisation \u00e0 un service externe, sans que NGINX ne g\u00e8re directement les sessions ou les identifiants.</p>"},{"location":"_projects/_formation-nginx/nginx-chap17/#principe-darchitecture","title":"Principe d\u2019architecture","text":"<ol> <li>Une requ\u00eate arrive sur une ressource prot\u00e9g\u00e9e.  </li> <li>NGINX envoie une sous\u2011requ\u00eate interne vers une URL d\u2019authentification (par exemple <code>/auth</code>).  </li> <li>Cette URL est g\u00e9r\u00e9e par un <code>proxy_pass</code> vers un service d\u2019auth (application interne, service OAuth2, etc.).  </li> <li>Si le service d\u2019auth renvoie <code>2xx</code>, la requ\u00eate initiale est autoris\u00e9e ; si <code>401</code> ou <code>403</code>, elle est refus\u00e9e.</li> </ol> <p>Sch\u00e9ma conceptuel (d\u00e9crit textuellement) :</p> <ul> <li>Client \u2192 NGINX (URL prot\u00e9g\u00e9e <code>/app/\u2026</code>)  </li> <li>NGINX \u2192 sous\u2011requ\u00eate interne <code>/auth</code> \u2192 service d\u2019auth  </li> <li>Service d\u2019auth \u2192 r\u00e9ponse (200 = OK, 401/403 = refus)  </li> <li>NGINX \u2192 autorise ou bloque l\u2019acc\u00e8s \u00e0 <code>/app/\u2026</code> selon ce statut.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap17/#exemple-de-configuration","title":"Exemple de configuration","text":"Nginx Configuration File<pre><code>http {\n    upstream auth_backend {\n        server 127.0.0.1:9000;\n    }\n\n    upstream app_backend {\n        server 127.0.0.1:8000;\n    }\n\n    server {\n        listen 80;\n        server_name app.exemple.local;\n\n        location = /auth {\n            internal;\n            proxy_pass http://auth_backend;\n            proxy_set_header X-Original-URI $request_uri;\n            proxy_set_header X-Real-IP      $remote_addr;\n        }\n\n        location /app/ {\n            auth_request /auth;\n            proxy_pass http://app_backend;\n        }\n    }\n}\n</code></pre> <ul> <li>La directive <code>internal</code> emp\u00eache l\u2019acc\u00e8s direct \u00e0 <code>/auth</code> depuis l\u2019ext\u00e9rieur.  </li> <li>Le service d\u2019authentification peut utiliser les en-t\u00eates (<code>X-Original-URI</code>, <code>X-Real-IP</code>, cookies, etc.) pour prendre sa d\u00e9cision.  </li> <li>Il est possible de propager des en-t\u00eates issus de la sous\u2011requ\u00eate vers l\u2019upstream applicatif en utilisant <code>auth_request_set</code> et des variables.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap17/#chemin-dapprentissage-typique","title":"Chemin d\u2019apprentissage typique","text":"<ul> <li>Comprendre les m\u00e9canismes basiques d\u2019authentification (Basic, JWT, sessions applicatives).  </li> <li>\u00c9tudier la syntaxe de <code>auth_request</code> et le comportement en cas de succ\u00e8s/\u00e9chec.  </li> <li>Mettre en place un petit service d\u2019auth (par exemple en Python, Go, Node.js) qui renvoie simplement 200 ou 403 selon un cookie ou un token.  </li> <li>\u00c9tendre ensuite ce service pour s\u2019int\u00e9grer \u00e0 un SSO, LDAP, OAuth2, ou un fournisseur d\u2019identit\u00e9 centralis\u00e9.</li> </ul>"},{"location":"_projects/_formation-nginx/nginx-chap17/#tableau-recapitulatif-des-mecanismes-evoques","title":"Tableau r\u00e9capitulatif des m\u00e9canismes \u00e9voqu\u00e9s","text":"Sujet Objectif principal Directive(s) cl\u00e9(s) Usage typique R\u00e9duction d\u2019informations expos\u00e9es Limiter les donn\u00e9es utiles \u00e0 un attaquant <code>server_tokens</code>, <code>error_page</code> Masquer la version, pages d\u2019erreur neutres Journaux pour fail2ban D\u00e9tection et blocage automatique d\u2019IP <code>access_log</code>, <code>log_format</code> Brute-force, scans, r\u00e9p\u00e9tition d\u2019erreurs Authentification HTTP Basic Protection simple par identifiant/mot de passe <code>auth_basic</code>, <code>auth_basic_user_file</code> Zones d\u2019administration, outils internes Limitation de requ\u00eates/connexions Att\u00e9nuation brute-force et DoS applicatifs <code>limit_req_*</code>, <code>limit_conn_*</code> /login, /api, limitation par IP Protection contre le hotlinking \u00c9viter l\u2019utilisation abusive de ressources <code>valid_referers</code>, <code>$invalid_referer</code> Images, vid\u00e9os, fichiers statiques Authentification par sous\u2011requ\u00eate D\u00e9l\u00e9gation de la d\u00e9cision d\u2019acc\u00e8s \u00e0 un backend <code>auth_request</code> Int\u00e9gration SSO, auth centralis\u00e9e, portails d\u2019entreprise <p>Si un approfondissement sur un point sp\u00e9cifique (par exemple un tutoriel pas \u00e0 pas sur <code>auth_request</code> avec un backend donn\u00e9, ou un focus sur la configuration conjointe NGINX + fail2ban) est souhait\u00e9, il est possible de d\u00e9tailler un cas pratique isol\u00e9 avec davantage d\u2019exemples de configuration.</p> <p> Partager sur X</p>"},{"location":"_projects/introduction/introduction/","title":"\ud83d\ude80 Introduction","text":"<p> Partager sur X</p>"},{"location":"_projects/sommaire/sommaire/","title":"\ud83d\ude80 Introduction \u00e0 la Formation Docker \ud83d\udc33","text":"<p>Bienvenue dans cette formation compl\u00e8te sur Docker ! \ud83c\udf89 Docker est une plateforme open-source qui permet de d\u00e9velopper, d\u00e9ployer et ex\u00e9cuter des applications dans des conteneurs l\u00e9gers et portables. Cette formation vous guidera \u00e0 travers les concepts fondamentaux et avanc\u00e9s pour ma\u00eetriser Docker et l'int\u00e9grer efficacement dans vos projets.</p>"},{"location":"_projects/sommaire/sommaire/#objectifs-de-la-formation","title":"\ud83d\udccc Objectifs de la Formation","text":"<p>\u00c0 l'issue de cette formation, vous serez capable de : \u2705 Cr\u00e9er et optimiser des images Docker avec un <code>Dockerfile</code>. \u2705 G\u00e9rer le cycle de vie des conteneurs et ma\u00eetriser les commandes essentielles. \u2705 Explorer l'\u00e9cosyst\u00e8me Docker et ses outils compl\u00e9mentaires. \u2705 Utiliser Docker Hub pour partager et distribuer des images. \u2705 D\u00e9ployer des environnements complexes avec Docker Compose. \u2705 Ma\u00eetriser la ligne de commande Docker pour une gestion avanc\u00e9e. \u2705 Configurer des volumes et r\u00e9seaux Docker pour une communication efficace. \u2705 Optimiser vos applications pour la production avec Docker.</p>"},{"location":"_projects/sommaire/sommaire/#notions-cles-de-la-formation","title":"\ud83d\udcda Notions Cl\u00e9s de la Formation","text":""},{"location":"_projects/sommaire/sommaire/#1-dockerfile-creer-et-optimiser-une-image","title":"1\ufe0f\u20e3 Dockerfile : Cr\u00e9er et Optimiser une Image","text":"<p>\ud83d\udd39 Comprendre le Dockerfile : Syntaxe, instructions essentielles (<code>FROM</code>, <code>RUN</code>, <code>COPY</code>, <code>CMD</code>, etc.). \ud83d\udd39 Optimisation des images : R\u00e9duction de la taille, multi-stage builds, bonnes pratiques. \ud83d\udd39 Build et gestion des images : Commandes <code>docker build</code>, <code>docker images</code>, <code>docker rmi</code>.</p>"},{"location":"_projects/sommaire/sommaire/#2-conteneur-docker-cycle-de-vie-et-commandes-essentielles","title":"2\ufe0f\u20e3 Conteneur Docker : Cycle de Vie et Commandes Essentielles","text":"<p>\ud83d\udd39 Cr\u00e9er et ex\u00e9cuter un conteneur : <code>docker run</code>, <code>docker create</code>, <code>docker start</code>. \ud83d\udd39 G\u00e9rer le cycle de vie : Arr\u00eat, red\u00e9marrage, suppression (<code>docker stop</code>, <code>docker rm</code>). \ud83d\udd39 Inspecter et d\u00e9boguer : <code>docker logs</code>, <code>docker exec</code>, <code>docker inspect</code>.</p>"},{"location":"_projects/sommaire/sommaire/#3-ecosysteme-docker-outils-et-integrations","title":"3\ufe0f\u20e3 \u00c9cosyst\u00e8me Docker : Outils et Int\u00e9grations","text":"<p>\ud83d\udd39 Docker Engine : Architecture et fonctionnement. \ud83d\udd39 Docker Desktop : Outils pour d\u00e9veloppement local. \ud83d\udd39 Docker Swarm / Kubernetes : Orchestration pour la production. \ud83d\udd39 Outils compl\u00e9mentaires : Portainer, Rancher, etc.</p>"},{"location":"_projects/sommaire/sommaire/#4-docker-hub-partage-et-distribution-dimages","title":"4\ufe0f\u20e3 Docker Hub : Partage et Distribution d'Images","text":"<p>\ud83d\udd39 Cr\u00e9er un compte et publier une image : <code>docker login</code>, <code>docker push</code>. \ud83d\udd39 Utiliser des images publiques : Recherche et t\u00e9l\u00e9chargement (<code>docker pull</code>). \ud83d\udd39 Gestion des tags et versions.</p>"},{"location":"_projects/sommaire/sommaire/#5-docker-compose-deploiement-denvironnements-complexes","title":"5\ufe0f\u20e3 Docker Compose : D\u00e9ploiement d'Environnements Complexes","text":"<p>\ud83d\udd39 Fichier <code>docker-compose.yml</code> : D\u00e9finir des services, r\u00e9seaux et volumes. \ud83d\udd39 Commandes essentielles : <code>docker-compose up</code>, <code>docker-compose down</code>, <code>docker-compose ps</code>. \ud83d\udd39 Gestion des d\u00e9pendances entre services.</p>"},{"location":"_projects/sommaire/sommaire/#6-docker-cli-maitriser-la-ligne-de-commande","title":"6\ufe0f\u20e3 Docker CLI : Ma\u00eetriser la Ligne de Commande","text":"<p>\ud83d\udd39 Commandes de base : <code>docker ps</code>, <code>docker stats</code>, <code>docker system prune</code>. \ud83d\udd39 Gestion avanc\u00e9e : <code>docker network</code>, <code>docker volume</code>, <code>docker events</code>. \ud83d\udd39 Automatisation avec scripts.</p>"},{"location":"_projects/sommaire/sommaire/#7-volumes-et-reseaux-docker-persistance-et-communication","title":"7\ufe0f\u20e3 Volumes et R\u00e9seaux Docker : Persistance et Communication","text":"<p>\ud83d\udd39 G\u00e9rer la persistance des donn\u00e9es : <code>docker volume create</code>, <code>docker volume ls</code>. \ud83d\udd39 Configurer les r\u00e9seaux : Bridge, Host, Overlay (<code>docker network create</code>). \ud83d\udd39 Communication entre conteneurs : DNS interne, ports expos\u00e9s.</p>"},{"location":"_projects/sommaire/sommaire/#8-optimisation-en-production-mise-en-production-efficace","title":"8\ufe0f\u20e3 Optimisation en Production : Mise en Production Efficace","text":"<p>\ud83d\udd39 Bonnes pratiques : Limiter les privil\u00e8ges, utiliser des images officielles. \ud83d\udd39 S\u00e9curit\u00e9 : Scan d'images, secrets Docker. \ud83d\udd39 D\u00e9ploiement CI/CD : Int\u00e9gration avec GitHub Actions, Jenkins. \ud83d\udd39 Monitoring et logs : <code>docker stats</code>, <code>docker logs</code>, outils externes (Prometheus, ELK).</p>"},{"location":"_projects/sommaire/sommaire/#public-cible","title":"\ud83c\udfaf Public Cible","text":"<p>Cette formation est id\u00e9ale pour : \ud83d\udc68\u200d\ud83d\udcbb D\u00e9veloppeurs souhaitant containeriser leurs applications. \ud83d\udc69\u200d\ud83d\udcbb DevOps / Sysadmins cherchant \u00e0 automatiser leurs d\u00e9ploiements. \ud83d\udc68\u200d\ud83c\udf93 \u00c9tudiants / Formateurs en recherche de comp\u00e9tences en conteneurisation.</p>"},{"location":"_projects/sommaire/sommaire/#programme-prevu","title":"\ud83d\udcc5 Programme Pr\u00e9vu","text":"Jour Th\u00e8me Contenu Jour 1 \ud83d\udc0b Introduction \u00e0 Docker Concepts, installation, premiers conteneurs Jour 2 \ud83d\udcc4 Dockerfile et Images Cr\u00e9ation et optimisation d'images Jour 3 \ud83d\udd04 Cycle de Vie des Conteneurs Commandes, logs, d\u00e9bogage Jour 4 \ud83c\udf10 \u00c9cosyst\u00e8me et Docker Hub Outils, partage d'images Jour 5 \ud83d\udd17 Docker Compose D\u00e9ploiement d'environnements multi-services Jour 6 \ud83d\udcbb Docker CLI Avanc\u00e9 Commandes avanc\u00e9es, automatisation Jour 7 \ud83d\udcc2 Volumes et R\u00e9seaux Persistance et communication entre conteneurs Jour 8 \ud83d\ude80 Optimisation en Production Mise en production, s\u00e9curit\u00e9, CI/CD"},{"location":"_projects/sommaire/sommaire/#conclusion","title":"\ud83c\udfaf Conclusion","text":"<p>Cette formation vous donnera les comp\u00e9tences essentielles pour ma\u00eetriser Docker et l'int\u00e9grer efficacement dans vos projets. \ud83d\ude80 Que vous soyez d\u00e9butant ou que vous souhaitiez approfondir vos connaissances, vous serez en mesure de containeriser vos applications, de g\u00e9rer des environnements complexes et de d\u00e9ployer en production avec confiance.</p> <p>Pr\u00eat \u00e0 plonger dans le monde de Docker ? \ud83d\udc33 Let's go ! \ud83d\ude80</p> <p> Partager sur X</p>"},{"location":"_whoami/whoami/","title":"Qui suis-je \u2753","text":""},{"location":"_whoami/whoami/#bonjour","title":"Bonjour ! \ud83d\ude4b\u200d\u2642\ufe0f","text":"<p>Je m\u2019appelle Nicolas Dupr\u00e9, j\u2019ai 47 ans et je suis actuellement Consultant Microsoft et Cloud au sein de l'ESN Exakis-Nelite \u00e0 Lyon.</p> <p>Ce site a \u00e9t\u00e9 cr\u00e9\u00e9 pour regrouper quelques articles, quelques notes en relation avec le domaine de l'IT. Y sont d\u00e9pos\u00e9s dans la rubrique blog quelques sujets techniques, quelques travaux r\u00e9alis\u00e9s dans mon \"homelab\" et quelques sujets d'actualit\u00e9.</p> <p></p> <p>Bonne lecture, je lirai vos messages avec plaisir dans la rubrique ad\u00e9quate ! \ud83d\udc4d</p>"},{"location":"_whoami/whoami/#je-me-presente","title":"Je me pr\u00e9sente","text":"<p>Depuis une vingtaine d'ann\u00e9es, j'interviens aupr\u00e8s de nombreux grands comptes en tant que consultant IT. Les diff\u00e9rentes missions dans diverses ESN m'ont permis d'\u00e9voluer techniquement, et nous savons tous que dans l'informatique, les choses \u00e9voluent tr\u00e8s vite (\"transformation digitale\" ou \"move to cloud\" par exemple sont des termes tr\u00e8s largement utilis\u00e9s).</p> <p>Ma sp\u00e9cialit\u00e9 se porte sur les technologies d\u2019infrastructure IT et Azure, et je prends part \u00e0 diff\u00e9rents projets passionnants. J\u2019apporte mon expertise aux clients pour optimiser leurs infrastructures et exploiter pleinement les services cloud d\u2019Azure. Gr\u00e2ce \u00e0 mes exp\u00e9riences et expertise, je propose des solutions innovantes et performantes.</p> <p>Par ailleurs, je m\u2019autoforme sur mes temps de disponibilit\u00e9 sur les technos CI/CD, AI et AWS. Il y a sur ce site des articles que j'ai r\u00e9dig\u00e9s, en fonction des probl\u00e9matiques que j'ai rencontr\u00e9es. Aussi, au fil des ann\u00e9es, je reprends mes notes que je pose ici, toujours utiles \u00e0 consulter.</p> <p>Passionn\u00e9 par le hacking \u00e9thique, j\u2019aime \u00e9galement les randonn\u00e9es en montagne \ud83d\udeb6, le trail \ud83c\udfc3 et le VTT \ud83d\udeb2.</p> <p>Je suis joignable sur Linkedin.</p>"},{"location":"_whoami/whoami/#mon-cv","title":"Mon CV","text":"<p>Mon CV actualis\u00e9 (juillet 2025) est disponible ici au format PDF : </p> <p>\u2705 CV </p>"},{"location":"_whoami/whoami/#competences","title":"Comp\u00e9tences","text":"<p>Consultant sp\u00e9cialis\u00e9 dans la mise en \u0153uvre, la gestion et l\u2019optimisation des infrastructures IT et des solutions cloud sur Microsoft Azure. Fort d\u2019une exp\u00e9rience en architecture de syst\u00e8mes, migration vers le cloud et gestion des infrastructures informatiques complexes, j\u2019accompagne les entreprises dans la s\u00e9curit\u00e9 et l\u2019\u00e9volutivit\u00e9 de leurs environnements IT.</p>"},{"location":"_whoami/whoami/#mes-certifications-et-transcript-microsoft","title":"Mes certifications et transcript Microsoft","text":"<p>Mes certifications Microsoft (\u00e0 jour) figurent ci-dessous :</p> Certification AZ Certifications SC / MS Certifications fondamentales AZ-801 SC-200 SC-900 AZ-800 SC-400 MS-900 AZ-305 (+ AZ-303/AZ-304, obsol\u00e8tes) SC-300 PL-900 AZ-720 AZ-500 AI-900 AZ-700 DP-900 AZ-140 AZ-900 AZ-500 AZ-104 <p>\u2705 Transcript - Microsoft Learn</p> <p>\u2705 Transcript - PDF</p> <p> Partager sur X</p>"},{"location":"blog/","title":"Blog et articles IT","text":"<p> Partager sur X</p>"},{"location":"blog/author/team/","title":"Microsoft, IT, actualit\u00e9s et divers","text":"<p>Ce blog propose une veille structur\u00e9e autour de trois axes principaux :</p> <ul> <li>Microsoft : analyse des \u00e9volutions strat\u00e9giques, des innovations technologiques et des solutions propos\u00e9es par l\u2019\u00e9cosyst\u00e8me Microsoft.</li> <li>IT : d\u00e9cryptage des tendances du secteur des technologies de l\u2019information, incluant le cloud, la cybers\u00e9curit\u00e9, l\u2019IA et la transformation digitale.</li> <li>Actualit\u00e9s : s\u00e9lection d\u2019informations cl\u00e9s et analyses sur l\u2019actualit\u00e9 technologique, pour rester inform\u00e9 des mouvements majeurs du march\u00e9.</li> </ul>"},{"location":"blog/author/team/#nous-parlerons-egalement-de-linux-de-containers-de-cloudflare-dateliers-en-homelab-etc","title":"&gt; Nous parlerons \u00e9galement de Linux, de containers, de Cloudflare, d'ateliers en \"homelab\", etc.","text":"<p> Partager sur X</p>"},{"location":"blog/globule/site-management/","title":"Outils utilis\u00e9s pour la cr\u00e9ation et la gestion du site","text":"","tags":["univers","Candy"]},{"location":"blog/globule/site-management/#typora","title":"Typora","text":"<p>Typora est l'\u00e9diteur de texte principal utilis\u00e9 pour l'\u00e9dition des pages du site. Il permet d'\u00e9crire en Markdown avec un rendu en temps r\u00e9el, ce qui facilite la mise en forme des contenus sans avoir \u00e0 jongler entre l'\u00e9dition et l'aper\u00e7u. Son interface minimaliste et intuitive favorise la productivit\u00e9 et rend l'\u00e9criture fluide et agr\u00e9able, tout en assurant une compatibilit\u00e9 parfaite avec les formats utilis\u00e9s pour le site.</p> <p>Il est sp\u00e9cialis\u00e9 dans la r\u00e9daction et la mise en forme de fichiers Markdown. Il offre une exp\u00e9rience d\u2019\u00e9dition fluide, en affichant en temps r\u00e9el le rendu final du Markdown, ce qui permet de se concentrer sur le contenu sans se perdre dans les balises ou la syntaxe. </p> <p>https://typora.io/</p> <p></p>","tags":["univers","Candy"]},{"location":"blog/globule/site-management/#visual-studio-code-avec-lextension-front-matter","title":"Visual Studio Code avec l'extension Front Matter","text":"<p>Visual Studio Code, souvent abr\u00e9g\u00e9 VS Code, est un \u00e9diteur de code moderne, l\u00e9ger et extr\u00eamement personnalisable.</p> <p>Pour la gestion plus avanc\u00e9e des contenus, Visual Studio Code est utilis\u00e9, il peut \u00eatre install\u00e9e l\u2019extension Front Matter. Cet outil permet d\u2019administrer plus facilement les m\u00e9tadonn\u00e9es en YAML en d\u00e9but de fichier, de g\u00e9rer des collections de contenus et de b\u00e9n\u00e9ficier de fonctions utiles comme l\u2019aper\u00e7u de page, les liens internes ou encore le tri par date. C\u2019est un environnement robuste pour organiser et maintenir un site structur\u00e9.</p> <p>Ainsi avec VS Code + l\u2019extension Front Matter, on a ici un outil puissant pour la gestion de contenu sous forme de Markdown, le support des m\u00e9tadonn\u00e9es et l\u2019organisation des articles ou des pages du site. </p> <p>Cette combinaison permet une gestion structur\u00e9e et professionnelle du contenu tout en b\u00e9n\u00e9ficiant de toutes les fonctionnalit\u00e9s avanc\u00e9es de VS Code. </p> <p>https://code.visualstudio.com/</p> <p></p>","tags":["univers","Candy"]},{"location":"blog/globule/site-management/#github","title":"GitHub","text":"<p>GitHub est utilis\u00e9 comme syst\u00e8me de versioning pour le projet. Il permet de garder un historique clair de toutes les modifications apport\u00e9es aux fichiers du site, de collaborer efficacement et de restaurer des versions pr\u00e9c\u00e9dentes si n\u00e9cessaire. C\u2019est un outil essentiel pour assurer une gestion fiable du code source et des contenus.</p> <p>C'est la plateforme collaborative incontournable pour le versioning du code. En utilisant un d\u00e9p\u00f4t GitHub, toutes les modifications du site sont historis\u00e9es, permettant de revenir facilement \u00e0 un \u00e9tat ant\u00e9rieur si n\u00e9cessaire ou de collaborer efficacement sur les changements. La mise \u00e0 jour du site s\u2019effectue en poussant les nouvelles versions, garantissant ainsi la tra\u00e7abilit\u00e9 et la s\u00fbret\u00e9 des \u00e9volutions.</p> <p>https://github.com/</p> <p></p>","tags":["univers","Candy"]},{"location":"blog/globule/site-management/#github-pages","title":"GitHub Pages","text":"<p>Le site est h\u00e9berg\u00e9 via GitHub Pages, un service d\u2019h\u00e9bergement statique int\u00e9gr\u00e9 \u00e0 GitHub. Il permet de publier facilement le site directement depuis le d\u00e9p\u00f4t en ligne, sans avoir besoin d\u2019un serveur web complexe. Les mises \u00e0 jour sont automatiquement d\u00e9ploy\u00e9es \u00e0 chaque push vers la branche principale ou d\u00e9di\u00e9e.</p> <p>Ainsi, il automatise le d\u00e9ploiement \u00e0 chaque modification du code, assurant ainsi une mise \u00e0 jour rapide et fiable du site sans intervention manuelle sur un serveur.</p> <p>https://pages.github.com/</p> <p></p>","tags":["univers","Candy"]},{"location":"blog/globule/site-management/#flameshot","title":"Flameshot","text":"<p>Pour illustrer les contenus du site, Flameshot est utilis\u00e9 comme outil principal de capture d\u2019\u00e9cran. Il permet de prendre des captures rapides et de les annoter directement, avec des options pratiques comme le floutage, les fl\u00e8ches ou les encadrements. Ces captures enrichissent les pages et facilitent la compr\u00e9hension pour les visiteurs.</p> <p>https://flameshot.org/</p> <p></p>","tags":["univers","Candy"]},{"location":"blog/globule/site-management/#serveur-ftp","title":"Serveur FTP","text":"<p>Un serveur FTP est utilis\u00e9 pour h\u00e9berger les copies d\u2019\u00e9cran r\u00e9alis\u00e9es avec Flameshot. Ces images ne sont pas stock\u00e9es directement dans le d\u00e9p\u00f4t GitHub afin d\u2019en all\u00e9ger la taille. Le FTP permet une gestion centralis\u00e9e des m\u00e9dias tout en gardant les pages web l\u00e9g\u00e8res et rapides \u00e0 charger.</p> <p>Le serveur sert ainsi d\u2019espace de stockage distant, accessible depuis n\u2019importe quelle machine, facilitant ainsi l\u2019int\u00e9gration rapide des images captur\u00e9es dans les articles ou pages du site.</p>","tags":["univers","Candy"]},{"location":"blog/globule/site-management/#_1","title":"Gestion du site","text":"<p> Partager sur X</p>","tags":["univers","Candy"]},{"location":"blog/archive/2025/","title":"novembre 2025","text":"<p> Partager sur X</p>"},{"location":"blog/category/globule/","title":"globule","text":"<p> Partager sur X</p>"}]}